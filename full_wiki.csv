en,simple
"Biology is the scientific study of life. It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field. For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life. Energy processing is also important to life as it allows organisms to move, grow, and reproduce. Finally, all organisms are able to regulate their own internal environments.Biologists are able to study life at multiple levels of organization, from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations. Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use. Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.Life on Earth, which emerged more than 3.7 billion years ago, is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.  History  The earliest of roots of science, which included medicine, can be traced to ancient Egypt and Mesopotamia in around 3000 to 1200 BCE. Their contributions shaped ancient Greek natural philosophy. Ancient Greek philosophers such as Aristotle (384–322 BCE) contributed extensively to the development of biological knowledge. He explored biological causation and the diversity of life. His successor, Theophrastus, began the scientific study of plants. Scholars of the medieval Islamic world who wrote on biology included al-Jahiz (781–869), Al-Dīnawarī (828–896), who wrote on botany, and Rhazes (865–925) who wrote on anatomy and physiology. Medicine was especially well studied by Islamic scholars working in Greek philosopher traditions, while natural history drew heavily on Aristotelian thought. Biology began to quickly develop with Anton van Leeuwenhoek\'s dramatic improvement of the microscope. It was then that scholars discovered spermatozoa, bacteria, infusoria and the diversity of microscopic life. Investigations by Jan Swammerdam led to new interest in entomology and helped to develop techniques of microscopic dissection and staining. Advances in microscopy had a profound impact on biological thinking. In the early 19th century, biologists pointed to the central importance of the cell. In 1838, Schleiden and Schwann began promoting the now universal ideas that (1) the basic unit of organisms is the cell and (2) that individual cells have all the characteristics of life, although they opposed the idea that (3) all cells come from the division of other cells, continuing to support spontaneous generation. However, Robert Remak and Rudolf Virchow were able to reify the third tenet, and by the 1860s most biologists accepted all three tenets which consolidated into cell theory.Meanwhile, taxonomy and classification became the focus of natural historians. Carl Linnaeus published a basic taxonomy for the natural world in 1735, and in the 1750s introduced scientific names for all his species. Georges-Louis Leclerc, Comte de Buffon, treated species as artificial categories and living forms as malleable—even suggesting the possibility of common descent. Serious evolutionary thinking originated with the works of Jean-Baptiste Lamarck, who presented a coherent theory of evolution. The British naturalist Charles Darwin, combining the biogeographical approach of Humboldt, the uniformitarian geology of Lyell, Malthus\'s writings on population growth, and his own morphological expertise and extensive natural observations, forged a more successful evolutionary theory based on natural selection; similar reasoning and evidence led Alfred Russel Wallace to independently reach the same conclusions.The basis for modern genetics began with the work of Gregor Mendel in 1865. This outlined the principles of biological inheritance. However, the significance of his work was not realized until the early 20th century when evolution became a unified theory as the modern synthesis reconciled Darwinian evolution with classical genetics. In the 1940s and early 1950s, a series of experiments by Alfred Hershey and Martha Chase pointed to DNA as the component of chromosomes that held the trait-carrying units that had become known as genes. A focus on new kinds of model organisms such as viruses and bacteria, along with the discovery of the double-helical structure of DNA by James Watson and Francis Crick in 1953, marked the transition to the era of molecular genetics. From the 1950s onwards, biology has been vastly extended in the molecular domain. The genetic code was cracked by Har Gobind Khorana, Robert W. Holley and Marshall Warren Nirenberg after DNA was understood to contain codons. The Human Genome Project was launched in 1990 to map the human genome.  Chemical basis   Atoms and molecules  All organisms are made up of chemical elements; oxygen, carbon, hydrogen, and nitrogen account for most (96%) of the mass of all organisms, with calcium, phosphorus, sulfur, sodium, chlorine, and magnesium constituting essentially all the remainder. Different elements can combine to form compounds such as water, which is fundamental to life. Biochemistry is the study of chemical processes within and relating to living organisms. Molecular biology is the branch of biology that seeks to understand the molecular basis of biological activity in and between cells, including molecular synthesis, modification, mechanisms, and interactions.  Water  Life arose from the Earth\'s first ocean, which formed some 3.8 billion years ago. Since then, water continues to be the most abundant molecule in every organism. Water is important to life because it is an effective solvent, capable of dissolving solutes such as sodium and chloride ions or other small molecules to form an aqueous solution. Once dissolved in water, these solutes are more likely to come in contact with one another and therefore take part in chemical reactions that sustain life. In terms of its molecular structure, water is a small polar molecule with a bent shape formed by the polar covalent bonds of two hydrogen (H) atoms to one oxygen (O) atom (H2O). Because the O–H bonds are polar, the oxygen atom has a slight negative charge and the two hydrogen atoms have a slight positive charge. This polar property of water allows it to attract other water molecules via hydrogen bonds, which makes water cohesive. Surface tension results from the cohesive force due to the attraction between molecules at the surface of the liquid. Water is also adhesive as it is able to adhere to the surface of any polar or charged non-water molecules. Water is denser as a liquid than it is as a solid (or ice). This unique property of water allows ice to float above liquid water such as ponds, lakes, and oceans, thereby insulating the liquid below from the cold air above. Water has the capacity to absorb energy, giving it a higher specific heat capacity than other solvents such as ethanol. Thus, a large amount of energy is needed to break the hydrogen bonds between water molecules to convert liquid water into water vapor. As a molecule, water is not completely stable as each water molecule continuously dissociates into hydrogen and hydroxyl ions before reforming into a water molecule again. In pure water, the number of hydrogen ions balances (or equals) the number of hydroxyl ions, resulting in a pH that is neutral.  Organic compounds  Organic compounds are molecules that contain carbon bonded to another element such as hydrogen. With the exception of water, nearly all the molecules that make up each organism contain carbon. Carbon can form covalent bonds with up to four other atoms, enabling it to form diverse, large, and complex molecules. For example, a single carbon atom can form four single covalent bonds such as in methane, two double covalent bonds such as in carbon dioxide (CO2), or a triple covalent bond such as in carbon monoxide (CO). Moreover, carbon can form very long chains of interconnecting carbon–carbon bonds such as octane or ring-like structures such as glucose. The simplest form of an organic molecule is the hydrocarbon, which is a large family of organic compounds that are composed of hydrogen atoms bonded to a chain of carbon atoms. A hydrocarbon backbone can be substituted by other elements such as oxygen (O), hydrogen (H), phosphorus (P), and sulfur (S), which can change the chemical behavior of that compound. Groups of atoms that contain these elements (O-, H-, P-, and S-) and are bonded to a central carbon atom or skeleton are called functional groups. There are six prominent functional groups that can be found in organisms: amino group, carboxyl group, carbonyl group, hydroxyl group, phosphate group, and sulfhydryl group.In 1953, the Miller-Urey experiment showed that organic compounds could be synthesized abiotically within a closed system mimicking the conditions of early Earth, thus suggesting that complex organic molecules could have arisen spontaneously in early Earth (see abiogenesis).  Macromolecules  Macromolecules are large molecules made up of smaller subunits or monomers. Monomers include sugars, amino acids, and nucleotides. Carbohydrates include monomers and polymers of sugars. Lipids are the only class of macromolecules that are not made up of polymers. They include steroids, phospholipids, and fats, largely nonpolar and hydrophobic (water-repelling) substances. Proteins are the most diverse of the macromolecules. They include enzymes, transport proteins, large signaling molecules, antibodies, and structural proteins. The basic unit (or monomer) of a protein is an amino acid. Twenty amino acids are used in proteins. Nucleic acids are polymers of nucleotides. Their function is to store, transmit, and express hereditary information.  Cells  Cell theory states that cells are the fundamental units of life, that all living things are composed of one or more cells, and that all cells arise from preexisting cells through cell division. Most cells are very small, with diameters ranging from 1 to 100 micrometers and are therefore only visible under a light or electron microscope. There are generally two types of cells: eukaryotic cells, which contain a nucleus, and prokaryotic cells, which do not. Prokaryotes are single-celled organisms such as bacteria, whereas eukaryotes can be single-celled or multicellular. In multicellular organisms, every cell in the organism\'s body is derived ultimately from a single cell in a fertilized egg.  Cell structure  Every cell is enclosed within a cell membrane that separates its cytoplasm from the extracellular space. A cell membrane consists of a lipid bilayer, including cholesterols that sit between phospholipids to maintain their fluidity at various temperatures. Cell membranes are semipermeable, allowing small molecules such as oxygen, carbon dioxide, and water to pass through while restricting the movement of larger molecules and charged particles such as ions. Cell membranes also contains membrane proteins, including integral membrane proteins that go across the membrane serving as membrane transporters, and peripheral proteins that loosely attach to the outer side of the cell membrane, acting as enzymes shaping the cell. Cell membranes are involved in various cellular processes such as cell adhesion, storing electrical energy, and cell signalling and serve as the attachment surface for several extracellular structures such as a cell wall, glycocalyx, and cytoskeleton. Within the cytoplasm of a cell, there are many biomolecules such as proteins and nucleic acids. In addition to biomolecules, eukaryotic cells have specialized structures called organelles that have their own lipid bilayers or are spatially units. These organelles include the cell nucleus, which contains most of the cell\'s DNA, or mitochondria, which generates adenosine triphosphate (ATP) to power cellular processes. Other organelles such as endoplasmic reticulum and Golgi apparatus play a role in the synthesis and packaging of proteins, respectively. Biomolecules such as proteins can be engulfed by lysosomes, another specialized organelle. Plant cells have additional organelles that distinguish them from animal cells such as a cell wall that provides support for the plant cell, chloroplasts that harvest sunlight energy to produce sugar, and vacuoles that provide storage and structural support as well as being involved in reproduction and breakdown of plant seeds. Eukaryotic cells also have cytoskeleton that is made up of microtubules, intermediate filaments, and microfilaments, all of which provide support for the cell and are involved in the movement of the cell and its organelles. In terms of their structural composition, the microtubules are made up of tubulin (e.g., α-tubulin and β-tubulin whereas intermediate filaments are made up of fibrous proteins. Microfilaments are made up of actin molecules that interact with other strands of proteins.  Metabolism  All cells require energy to sustain cellular processes. Metabolism is the set of chemical reactions in an organism. The three main purposes of metabolism are: the conversion of food to energy to run cellular processes; the conversion of food/fuel to monomer building blocks; and the elimination of metabolic wastes. These enzyme-catalyzed reactions allow organisms to grow and reproduce, maintain their structures, and respond to their environments. Metabolic reactions may be categorized as catabolic—the breaking down of compounds (for example, the breaking down of glucose to pyruvate by cellular respiration); or anabolic—the building up (synthesis) of compounds (such as proteins, carbohydrates, lipids, and nucleic acids). Usually, catabolism releases energy, and anabolism consumes energy. The chemical reactions of metabolism are organized into metabolic pathways, in which one chemical is transformed through a series of steps into another chemical, each step being facilitated by a specific enzyme. Enzymes are crucial to metabolism because they allow organisms to drive desirable reactions that require energy that will not occur by themselves, by coupling them to spontaneous reactions that release energy. Enzymes act as catalysts—they allow a reaction to proceed more rapidly without being consumed by it—by reducing the amount of activation energy needed to convert reactants into products. Enzymes also allow the regulation of the rate of a metabolic reaction, for example in response to changes in the cell\'s environment or to signals from other cells.  Cellular respiration  Cellular respiration is a set of metabolic reactions and processes that take place in cells to convert chemical energy from nutrients into adenosine triphosphate (ATP), and then release waste products. The reactions involved in respiration are catabolic reactions, which break large molecules into smaller ones, releasing energy. Respiration is one of the key ways a cell releases chemical energy to fuel cellular activity. The overall reaction occurs in a series of biochemical steps, some of which are redox reactions. Although cellular respiration is technically a combustion reaction, it clearly does not resemble one when it occurs in a cell because of the slow, controlled release of energy from the series of reactions. Sugar in the form of glucose is the main nutrient used by animal and plant cells in respiration. Cellular respiration involving oxygen is called aerobic respiration, which has four stages: glycolysis, citric acid cycle (or Krebs cycle), electron transport chain, and oxidative phosphorylation. Glycolysis is a metabolic process that occurs in the cytoplasm whereby glucose is converted into two pyruvates, with two net molecules of ATP being produced at the same time. Each pyruvate is then oxidized into acetyl-CoA by the pyruvate dehydrogenase complex, which also generates NADH and carbon dioxide. Acetyl-Coa enters the citric acid cycle, which takes places inside the mitochondrial matrix. At the end of the cycle, the total yield from 1 glucose (or 2 pyruvates) is 6 NADH, 2 FADH2, and 2 ATP molecules. Finally, the next stage is oxidative phosphorylation, which in eukaryotes, occurs in the mitochondrial cristae. Oxidative phosphorylation comprises the electron transport chain, which is a series of four protein complexes that transfer electrons from one complex to another, thereby releasing energy from NADH and FADH2 that is coupled to the pumping of protons (hydrogen ions) across the inner mitochondrial membrane (chemiosmosis), which generates a proton motive force. Energy from the proton motive force drives the enzyme ATP synthase to synthesize more ATPs by phosphorylating ADPs. The transfer of electrons terminates with molecular oxygen being the final electron acceptor. If oxygen were not present, pyruvate would not be metabolized by cellular respiration but undergoes a process of fermentation. The pyruvate is not transported into the mitochondrion but remains in the cytoplasm, where it is converted to waste products that may be removed from the cell. This serves the purpose of oxidizing the electron carriers so that they can perform glycolysis again and removing the excess pyruvate. Fermentation oxidizes NADH to NAD+ so it can be re-used in glycolysis. In the absence of oxygen, fermentation prevents the buildup of NADH in the cytoplasm and provides NAD+ for glycolysis. This waste product varies depending on the organism. In skeletal muscles, the waste product is lactic acid. This type of fermentation is called lactic acid fermentation. In strenuous exercise, when energy demands exceed energy supply, the respiratory chain cannot process all of the hydrogen atoms joined by NADH. During anaerobic glycolysis, NAD+ regenerates when pairs of hydrogen combine with pyruvate to form lactate. Lactate formation is catalyzed by lactate dehydrogenase in a reversible reaction. Lactate can also be used as an indirect precursor for liver glycogen. During recovery, when oxygen becomes available, NAD+ attaches to hydrogen from lactate to form ATP. In yeast, the waste products are ethanol and carbon dioxide. This type of fermentation is known as alcoholic or ethanol fermentation. The ATP generated in this process is made by substrate-level phosphorylation, which does not require oxygen.  Photosynthesis  Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organism\'s metabolic activities via cellular respiration. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water. In most cases, oxygen is released as a waste product. Most plants, algae, and cyanobacteria perform photosynthesis, which is largely responsible for producing and maintaining the oxygen content of the Earth\'s atmosphere, and supplies most of the energy necessary for life on Earth.Photosynthesis has four stages: Light absorption, electron transport, ATP synthesis, and carbon fixation. Light absorption is the initial step of photosynthesis whereby light energy is absorbed by chlorophyll pigments attached to proteins in the thylakoid membranes. The absorbed light energy is used to remove electrons from a donor (water) to a primary electron acceptor, a quinone designated as Q. In the second stage, electrons move from the quinone primary electron acceptor through a series of electron carriers until they reach a final electron acceptor, which is usually the oxidized form of NADP+, which is reduced to NADPH, a process that takes place in a protein complex called photosystem I (PSI). The transport of electrons is coupled to the movement of protons (or hydrogen) from the stroma to the thylakoid membrane, which forms a pH gradient across the membrane as hydrogen becomes more concentrated in the lumen than in the stroma. This is analogous to the proton-motive force generated across the inner mitochondrial membrane in aerobic respiration.During the third stage of photosynthesis, the movement of protons down their concentration gradients from the thylakoid lumen to the stroma through the ATP synthase is coupled to the synthesis of ATP by that same ATP synthase. The NADPH and ATPs generated by the light-dependent reactions in the second and third stages, respectively, provide the energy and electrons to drive the synthesis of glucose by fixing atmospheric carbon dioxide into existing organic carbon compounds, such as ribulose bisphosphate (RuBP) in a sequence of light-independent (or dark) reactions called the Calvin cycle.  Cell signaling  Cell signaling (or communication) is the ability of cells to receive, process, and transmit signals with its environment and with itself. Signals can be non-chemical such as light, electrical impulses, and heat, or chemical signals (or ligands) that interact with receptors, which can be found embedded in the cell membrane of another cell or located deep inside a cell. There are generally four types of chemical signals: autocrine, paracrine, juxtacrine, and hormones. In autocrine signaling, the ligand affects the same cell that releases it. Tumor cells, for example, can reproduce uncontrollably because they release signals that initiate their own self-division. In paracrine signaling, the ligand diffuses to nearby cells and affects them. For example, brain cells called neurons release ligands called neurotransmitters that diffuse across a synaptic cleft to bind with a receptor on an adjacent cell such as another neuron or muscle cell. In juxtacrine signaling, there is direct contact between the signaling and responding cells. Finally, hormones are ligands that travel through the circulatory systems of animals or vascular systems of plants to reach their target cells. Once a ligand binds with a receptor, it can influence the behavior of another cell, depending on the type of receptor. For instance, neurotransmitters that bind with an inotropic receptor can alter the excitability of a target cell. Other types of receptors include protein kinase receptors (e.g., receptor for the hormone insulin) and G protein-coupled receptors. Activation of G protein-coupled receptors can initiate second messenger cascades. The process by which a chemical or physical signal is transmitted through a cell as a series of molecular events is called signal transduction  Cell cycle  The cell cycle is a series of events that take place in a cell that cause it to divide into two daughter cells. These events include the duplication of its DNA and some of its organelles, and the subsequent partitioning of its cytoplasm into two daughter cells in a process called cell division. In eukaryotes (i.e., animal, plant, fungal, and protist cells), there are two distinct types of cell division: mitosis and meiosis. Mitosis is part of the cell cycle, in which replicated chromosomes are separated into two new nuclei. Cell division gives rise to genetically identical cells in which the total number of chromosomes is maintained. In general, mitosis (division of the nucleus) is preceded by the S stage of interphase (during which the DNA is replicated) and is often followed by telophase and cytokinesis; which divides the cytoplasm, organelles and cell membrane of one cell into two new cells containing roughly equal shares of these cellular components. The different stages of mitosis all together define the mitotic phase of an animal cell cycle—the division of the mother cell into two genetically identical daughter cells. The cell cycle is a vital process by which a single-celled fertilized egg develops into a mature organism, as well as the process by which hair, skin, blood cells, and some internal organs are renewed. After cell division, each of the daughter cells begin the interphase of a new cycle. In contrast to mitosis, meiosis results in four haploid daughter cells by undergoing one round of DNA replication followed by two divisions. Homologous chromosomes are separated in the first division (meiosis I), and sister chromatids are separated in the second division (meiosis II). Both of these cell division cycles are used in the process of sexual reproduction at some point in their life cycle. Both are believed to be present in the last eukaryotic common ancestor. Prokaryotes (i.e., archaea and bacteria) can also undergo cell division (or binary fission). Unlike the processes of mitosis and meiosis in eukaryotes, binary fission takes in prokaryotes takes place without the formation of a spindle apparatus on the cell. Before binary fission, DNA in the bacterium is tightly coiled. After it has uncoiled and duplicated, it is pulled to the separate poles of the bacterium as it increases the size to prepare for splitting. Growth of a new cell wall begins to separate the bacterium (triggered by FtsZ polymerization and ""Z-ring"" formation) The new cell wall (septum) fully develops, resulting in the complete split of the bacterium. The new daughter cells have tightly coiled DNA rods, ribosomes, and plasmids.  Genetics   Inheritance  Genetics is the scientific study of inheritance. Mendelian inheritance, specifically, is the process by which genes and traits are passed on from parents to offspring. It has several principles. The first is that genetic characteristics, alleles, are discrete and have alternate forms (e.g., purple vs. white or tall vs. dwarf), each inherited from one of two parents. Based on the law of dominance and uniformity, which states that some alleles are dominant while others are recessive; an organism with at least one dominant allele will display the phenotype of that dominant allele. During gamete formation, the alleles for each gene segregate, so that each gamete carries only one allele for each gene. Heterozygotic individuals produce gametes with an equal frequency of two alleles. Finally, the law of independent assortment, states that genes of different traits can segregate independently during the formation of gametes, i.e., genes are unlinked. An exception to this rule would include traits that are sex-linked. Test crosses can be performed to experimentally determine the underlying genotype of an organism with a dominant phenotype. A Punnett square can be used to predict the results of a test cross. The chromosome theory of inheritance, which states that genes are found on chromosomes, was supported by Thomas Morgans\'s experiments with fruit flies, which established the sex linkage between eye color and sex in these insects.  Genes and DNA  A gene is a unit of heredity that corresponds to a region of deoxyribonucleic acid (DNA) that carries genetic information that controls form or function of an organism. DNA is composed of two polynucleotide chains that coil around each other to form a double helix. It is found as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. The set of chromosomes in a cell is collectively known as its genome. In eukaryotes, DNA is mainly in the cell nucleus. In prokaryotes, the DNA is held within the nucleoid. The genetic information is held within genes, and the complete assemblage in an organism is called its genotype.DNA replication is a semiconservative process whereby each strand serves as a template for a new strand of DNA. Mutations are heritable changes in DNA. They can arise spontaneously as a result of replication errors that were not corrected by proofreading or can be induced by an environmental mutagen such as a chemical (e.g., nitrous acid, benzopyrene) or radiation (e.g., x-ray, gamma ray, ultraviolet radiation, particles emitted by unstable isotopes). Mutations can lead to phenotypic effects such as loss-of-function, gain-of-function, and conditional mutations. Some mutations are beneficial, as they are a source of genetic variation for evolution. Others are harmful if they were to result in a loss of function of genes needed for survival. Mutagens such as carcinogens are typically avoided as a matter of public health policy goals.  Gene expression  Gene expression is the molecular process by which a genotype encoded in DNA gives rise to an observable phenotype in the proteins of an organism\'s body. This process is summarized by the central dogma of molecular biology, which was formulated by Francis Crick in 1958. According to the Central Dogma, genetic information flows from DNA to RNA to protein. There are two gene expression processes: transcription (DNA to RNA) and translation (RNA to protein).  Gene regulation  The regulation of gene expression by environmental factors and during different stages of development can occur at each step of the process such as transcription, RNA splicing, translation, and post-translational modification of a protein. Gene expression can be influenced by positive or negative regulation, depending on which of the two types of regulatory proteins called transcription factors bind to the DNA sequence close to or at a promoter. A cluster of genes that share the same promoter is called an operon, found mainly in prokaryotes and some lower eukaryotes (e.g., Caenorhabditis elegans). In positive regulation of gene expression, the activator is the transcription factor that stimulates transcription when it binds to the sequence near or at the promoter. Negative regulation occurs when another transcription factor called a repressor binds to a DNA sequence called an operator, which is part of an operon, to prevent transcription. Repressors can be inhibited by compounds called inducers (e.g., allolactose), thereby allowing transcription to occur. Specific genes that can be activated by inducers are called inducible genes, in contrast to constitutive genes that are almost constantly active. In contrast to both, structural genes encode proteins that are not involved in gene regulation. In addition to regulatory events involving the promoter, gene expression can also be regulated by epigenetic changes to chromatin, which is a complex of DNA and protein found in eukaryotic cells.  Genes, development, and evolution  Development is the process by which a multicellular organism (plant or animal) goes through a series of changes, starting from a single cell, and taking on various forms that are characteristic of its life cycle. There are four key processes that underlie development: Determination, differentiation, morphogenesis, and growth. Determination sets the developmental fate of a cell, which becomes more restrictive during development. Differentiation is the process by which specialized cells from less specialized cells such as stem cells. Stem cells are undifferentiated or partially differentiated cells that can differentiate into various types of cells and proliferate indefinitely to produce more of the same stem cell. Cellular differentiation dramatically changes a cell\'s size, shape, membrane potential, metabolic activity, and responsiveness to signals, which are largely due to highly controlled modifications in gene expression and epigenetics. With a few exceptions, cellular differentiation almost never involves a change in the DNA sequence itself. Thus, different cells can have very different physical characteristics despite having the same genome. Morphogenesis, or the development of body form, is the result of spatial differences in gene expression. A small fraction of the genes in an organism\'s genome called the developmental-genetic toolkit control the development of that organism. These toolkit genes are highly conserved among phyla, meaning that they are ancient and very similar in widely separated groups of animals. Differences in deployment of toolkit genes affect the body plan and the number, identity, and pattern of body parts. Among the most important toolkit genes are the Hox genes. Hox genes determine where repeating parts, such as the many vertebrae of snakes, will grow in a developing embryo or larva.  Evolution   Evolutionary processes  Evolution is a central organizing concept in biology. It is the change in heritable characteristics of populations over successive generations. In artificial selection, animals were selectively bred for specific traits. Given that traits are inherited, populations contain a varied mix of traits, and reproduction is able to increase any population, Darwin argued that in the natural world, it was nature that played the role of humans in selecting for specific traits. Darwin inferred that individuals who possessed heritable traits better adapted to their environments are more likely to survive and produce more offspring than other individuals. He further inferred that this would lead to the accumulation of favorable traits over successive generations, thereby increasing the match between the organisms and their environment.  Speciation  A species is a group of organisms that mate with one another and speciation is the process by which one lineage splits into two lineages as a result of having evolved independently from each other. For speciation to occur, there has to be reproductive isolation. Reproductive isolation can result from incompatibilities between genes as described by Bateson–Dobzhansky–Muller model. Reproductive isolation also tends to increase with genetic divergence. Speciation can occur when there are physical barriers that divide an ancestral species, a process known as allopatric speciation.  Phylogeny  A phylogeny is an evolutionary history of a specific group of organisms or their genes. It can be represented using a phylogenetic tree, a diagram showing lines of descent among organisms or their genes. Each line drawn on the time axis of a tree represents a lineage of descendants of a particular species or population. When a lineage divides into two, it is represented as a fork or split on the phylogenetic tree. Phylogenetic trees are the basis for comparing and grouping different species. Different species that share a feature inherited from a common ancestor are described as having homologous features (or synapomorphy). Phylogeny provides the basis of biological classification. This classification system is rank-based, with the highest rank being the domain followed by kingdom, phylum, class, order, family, genus, and species. All organisms can be classified as belonging to one of three domains: Archaea (originally Archaebacteria); bacteria (originally eubacteria), or eukarya (includes the protist, fungi, plant, and animal kingdoms).  History of life  The history of life on Earth traces how organisms have evolved from the earliest emergence of life to present day. Earth formed about 4.5 billion years ago and all life on Earth, both living and extinct, descended from a last universal common ancestor that lived about 3.5 billion years ago. Geologists have developed a geologic time scale that divides the history of the Earth into major divisions, starting with four eons (Hadean, Archean, Proterozoic, and Phanerozoic), the first three of which are collectively known as the Precambrian, which lasted approximately 4 billion years. Each eon can be divided into eras, with the Phanerozoic eon that began 539 million years ago being subdivided into Paleozoic, Mesozoic, and Cenozoic eras. These three eras together comprise eleven periods (Cambrian, Ordovician, Silurian, Devonian, Carboniferous, Permian, Triassic, Jurassic, Cretaceous, Tertiary, and Quaternary).The similarities among all known present-day species indicate that they have diverged through the process of evolution from their common ancestor. Biologists regard the ubiquity of the genetic code as evidence of universal common descent for all bacteria, archaea, and eukaryotes. Microbal mats of coexisting bacteria and archaea were the dominant form of life in the early Archean epoch and many of the major steps in early evolution are thought to have taken place in this environment. The earliest evidence of eukaryotes dates from 1.85 billion years ago, and while they may have been present earlier, their diversification accelerated when they started using oxygen in their metabolism. Later, around 1.7 billion years ago, multicellular organisms began to appear, with differentiated cells performing specialised functions.Algae-like multicellular land plants are dated back even to about 1 billion years ago, although evidence suggests that microorganisms formed the earliest terrestrial ecosystems, at least 2.7 billion years ago. Microorganisms are thought to have paved the way for the inception of land plants in the Ordovician period. Land plants were so successful that they are thought to have contributed to the Late Devonian extinction event.Ediacara biota appear during the Ediacaran period, while vertebrates, along with most other modern phyla originated about 525 million years ago during the Cambrian explosion. During the Permian period, synapsids, including the ancestors of mammals, dominated the land, but most of this group became extinct in the Permian–Triassic extinction event 252 million years ago. During the recovery from this catastrophe, archosaurs became the most abundant land vertebrates; one archosaur group, the dinosaurs, dominated the Jurassic and Cretaceous periods. After the Cretaceous–Paleogene extinction event 66 million years ago killed off the non-avian dinosaurs, mammals increased rapidly in size and diversity. Such mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.  Diversity   Bacteria and Archaea  Bacteria are a type of cell that constitute a large domain of prokaryotic microorganisms. Typically a few micrometers in length, bacteria have a number of shapes, ranging from spheres to rods and spirals. Bacteria were among the first life forms to appear on Earth, and are present in most of its habitats. Bacteria inhabit soil, water, acidic hot springs, radioactive waste, and the deep biosphere of the earth\'s crust. Bacteria also live in symbiotic and parasitic relationships with plants and animals. Most bacteria have not been characterised, and only about 27 percent of the bacterial phyla have species that can be grown in the laboratory. Archaea constitute the other domain of prokaryotic cells and were initially classified as bacteria, receiving the name archaebacteria (in the Archaebacteria kingdom), a term that has fallen out of use. Archaeal cells have unique properties separating them from the other two domains, Bacteria and Eukaryota. Archaea are further divided into multiple recognized phyla. Archaea and bacteria are generally similar in size and shape, although a few archaea have very different shapes, such as the flat and square cells of Haloquadratum walsbyi. Despite this morphological similarity to bacteria, archaea possess genes and several metabolic pathways that are more closely related to those of eukaryotes, notably for the enzymes involved in transcription and translation. Other aspects of archaeal biochemistry are unique, such as their reliance on ether lipids in their cell membranes, including archaeols. Archaea use more energy sources than eukaryotes: these range from organic compounds, such as sugars, to ammonia, metal ions or even hydrogen gas. Salt-tolerant archaea (the Haloarchaea) use sunlight as an energy source, and other species of archaea fix carbon, but unlike plants and cyanobacteria, no known species of archaea does both. Archaea reproduce asexually by binary fission, fragmentation, or budding; unlike bacteria, no known species of Archaea form endospores. The first observed archaea were extremophiles, living in extreme environments, such as hot springs and salt lakes with no other organisms. Improved molecular detection tools led to the discovery of archaea in almost every habitat, including soil, oceans, and marshlands. Archaea are particularly numerous in the oceans, and the archaea in plankton may be one of the most abundant groups of organisms on the planet. Archaea are a major part of Earth\'s life. They are part of the microbiota of all organisms. In the human microbiome, they are important in the gut, mouth, and on the skin. Their morphological, metabolic, and geographical diversity permits them to play multiple ecological roles: carbon fixation; nitrogen cycling; organic compound turnover; and maintaining microbial symbiotic and syntrophic communities, for example.  Eukaryotes  Eukaryotes are hypothesized to have split from archaea, which was followed by their endosymbioses with bacteria (or symbiogenesis) that gave rise to mitochondria and chloroplasts, both of which are now part of modern-day eukaryotic cells. The major lineages of eukaryotes diversified in the Precambrian about 1.5 billion years ago and can be classified into eight major clades: alveolates, excavates, stramenopiles, plants, rhizarians, amoebozoans, fungi, and animals. Five of these clades are collectively known as protists, which are mostly microscopic eukaryotic organisms that are not plants, fungi, or animals. While it is likely that protists share a common ancestor (the last eukaryotic common ancestor), protists by themselves do not constitute a separate clade as some protists may be more closely related to plants, fungi, or animals than they are to other protists. Like groupings such as algae, invertebrates, or protozoans, the protist grouping is not a formal taxonomic group but is used for convenience. Most protists are unicellular; these are called microbial eukaryotes.Plants are mainly multicellular organisms, predominantly photosynthetic eukaryotes of the kingdom Plantae, which would exclude fungi and some algae. Plant cells were derived by endosymbiosis of a cyanobacterium into an early eukaryote about one billion years ago, which gave rise to chloroplasts. The first several clades that emerged following primary endosymbiosis were aquatic and most of the aquatic photosynthetic eukaryotic organisms are collectively described as algae, which is a term of convenience as not all algae are closely related. Algae comprise several distinct clades such as glaucophytes, which are microscopic freshwater algae that may have resembled in form to the early unicellular ancestor of Plantae. Unlike glaucophytes, the other algal clades such as red and green algae are multicellular. Green algae comprise three major clades: chlorophytes, coleochaetophytes, and stoneworts.Fungi are eukaryotes that digest foods outside their bodies, secreting digestive enzymes that break down large food molecules before absorbing them through their cell membranes. Many fungi are also saprobes, feeding on dead organic matter, making them important decomposers in ecological systems.Animals are multicellular eukaryotes. With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Over 1.5 million living animal species have been described—of which around 1 million are insects—but it has been estimated there are over 7 million animal species in total. They have complex interactions with each other and their environments, forming intricate food webs.  Viruses  Viruses are submicroscopic infectious agents that replicate inside the cells of organisms. Viruses infect all types of life forms, from animals and plants to microorganisms, including bacteria and archaea. More than 6,000 virus species have been described in detail. Viruses are found in almost every ecosystem on Earth and are the most numerous type of biological entity.The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity in a way analogous to sexual reproduction. Because viruses possess some but not all characteristics of life, they have been described as ""organisms at the edge of life"", and as self-replicators.  Ecology  Ecology is the study of the distribution and abundance of life, the interaction between organisms and their environment.  Ecosystems  The community of living (biotic) organisms in conjunction with the nonliving (abiotic) components (e.g., water, light, radiation, temperature, humidity, atmosphere, acidity, and soil) of their environment is called an ecosystem. These biotic and abiotic components are linked together through nutrient cycles and energy flows. Energy from the sun enters the system through photosynthesis and is incorporated into plant tissue. By feeding on plants and on one another, animals move matter and energy through the system. They also influence the quantity of plant and microbial biomass present. By breaking down dead organic matter, decomposers release carbon back to the atmosphere and facilitate nutrient cycling by converting nutrients stored in dead biomass back to a form that can be readily used by plants and other microbes.  Populations  A population is the group of organisms of the same species that occupies an area and reproduce from generation to generation. Population size can be estimated by multiplying population density by the area or volume. The carrying capacity of an environment is the maximum population size of a species that can be sustained by that specific environment, given the food, habitat, water, and other resources that are available. The carrying capacity of a population can be affected by changing environmental conditions such as changes in the availability resources and the cost of maintaining them. In human populations, new technologies such as the Green revolution have helped increase the Earth\'s carrying capacity for humans over time, which has stymied the attempted predictions of impending population decline, the most famous of which was by Thomas Malthus in the 18th century.  Communities  A community is a group of populations of species occupying the same geographical area at the same time. A biological interaction is the effect that a pair of organisms living together in a community have on each other. They can be either of the same species (intraspecific interactions), or of different species (interspecific interactions). These effects may be short-term, like pollination and predation, or long-term; both often strongly influence the evolution of the species involved. A long-term interaction is called a symbiosis. Symbioses range from mutualism, beneficial to both partners, to competition, harmful to both partners. Every species participates as a consumer, resource, or both in consumer–resource interactions, which form the core of food chains or food webs. There are different trophic levels within any food web, with the lowest level being the primary producers (or autotrophs) such as plants and algae that convert energy and inorganic material into organic compounds, which can then be used by the rest of the community. At the next level are the heterotrophs, which are the species that obtain energy by breaking apart organic compounds from other organisms. Heterotrophs that consume plants are primary consumers (or herbivores) whereas heterotrophs that consume herbivores are secondary consumers (or carnivores). And those that eat secondary consumers are tertiary consumers and so on. Omnivorous heterotrophs are able to consume at multiple levels. Finally, there are decomposers that feed on the waste products or dead bodies of organisms. On average, the total amount of energy incorporated into the biomass of a trophic level per unit of time is about one-tenth of the energy of the trophic level that it consumes. Waste and dead material used by decomposers as well as heat lost from metabolism make up the other ninety percent of energy that is not consumed by the next trophic level.  Biosphere  In the global ecosystem or biosphere, matter exists as different interacting compartments, which can be biotic or abiotic as well as accessible or inaccessible, depending on their forms and locations. For example, matter from terrestrial autotrophs are both biotic and accessible to other organisms whereas the matter in rocks and minerals are abiotic and inaccessible. A biogeochemical cycle is a pathway by which specific elements of matter are turned over or moved through the biotic (biosphere) and the abiotic (lithosphere, atmosphere, and hydrosphere) compartments of Earth. There are biogeochemical cycles for nitrogen, carbon, and water.  Conservation  Conservation biology is the study of the conservation of Earth\'s biodiversity with the aim of protecting species, their habitats, and ecosystems from excessive rates of extinction and the erosion of biotic interactions.","Biology is the science that studies life, living things, and the evolution of life. Living things include animals, plants, fungi (such as mushrooms), and microorganisms such as bacteria and archaea. The term 'biology' is relatively modern. It was introduced in 1799 by a physician, Thomas Beddoes.People who study biology are called biologists. Biology looks at how animals and other living things behave and work, and what they are like. Biology also studies how organisms react with each other and the environment. It has existed as a science for about 200 years, and before that it was called ""natural history"". Biology has many research fields and branches. Like all sciences, biology uses the scientific method. This means that biologists must be able to show evidence for their ideas and that other biologists must be able to test the ideas for themselves. Biology attempts to answer questions such as: ""What are the characteristics of this living thing?"" (comparative anatomy) ""How do the parts work?"" (physiology) ""How should we group living things?"" (classification, taxonomy) ""What does this living thing do?"" (behaviour, growth) ""How does inheritance work?"" (genetics) ""What is the history of life?"" (palaeontology) ""How do living things relate to their environment?"" (ecology)Modern biology is influenced by evolution, which answers the question: ""How has the living world come to be as it is?""  History  The word biology comes from the Greek word βίος (bios), ""life"", and the suffix -λογία (logia), ""study of"".  Branches  Algalogy Anatomy Arachnology Bacteriology Biochemistry Biogeography Biophysics Botany Bryology Cell biology Cytology Dendrology Developmental biology Ecology Endocrinology Entomology Embryology Ethology Evolution / Evolutionary biology Genetics / Genomics Herpetology Histology Human biology / Anthropology / Primatology Ichthyology Limnology Mammalology Marine biology Microbiology / Bacteriology Molecular biology Morphology Mycology / Lichenology Ornithology Palaeontology Parasitology Phycology Phylogenetics Physiology Taxonomy Virology Zoology  References "
"Chemistry is the scientific study of the properties and behavior of matter. It is a physical science under natural sciences that covers the elements that make up matter to the compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during a reaction with other substances. Chemistry also addresses the nature of chemical bonds in chemical compounds. In the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the moon (cosmochemistry), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics). Chemistry is a study that has existed since ancient times. Over this time frame, it has evolved, and now chemistry encompasses various areas of specialisation, or subdisciplines, that continue to increase in number and interrelate to create further interdisciplinary fields of study. The applications of various fields of chemistry are used frequently for economic purposes in the chemical industry.  Etymology  The word chemistry comes from a modification during the Renaissance of the word alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism and medicine. Alchemy is often associated with the quest to turn lead or other base metals into gold, though alchemists were also interested in many of the questions of modern chemistry.The modern word alchemy in turn is derived from the Arabic word al-kīmīā (الكیمیاء). This may have Egyptian origins since al-kīmīā is derived from the Ancient Greek χημία, which is in turn derived from the word Kemet, which is the ancient name of Egypt in the Egyptian language. Alternately, al-kīmīā may derive from χημεία 'cast together'.  Modern principles  The current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. Matter can be studied in solid, liquid, gas and plasma states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory. The chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental (as well as applied/industrial) chemistry is done without it. A chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws. Energy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:  Matter  In chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well – not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.  Atom  The atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space occupied by an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the positive charge of the protons. The nucleus is dense; the mass of a nucleon is approximately 1,836 times that of an electron, yet the radius of an atom is about 10,000 times that of its nucleus.The atom is also the smallest entity that can be envisaged to retain the chemical properties of the element, such as electronegativity, ionization potential, preferred oxidation state(s), coordination number, and preferred types of bonds to form (e.g., metallic, ionic, covalent).  Element  A chemical element is a pure substance which is composed of a single type of atom, characterized by its particular number of protons in the nuclei of its atoms, known as the atomic number and represented by the symbol Z. The mass number is the sum of the number of protons and neutrons in a nucleus. Although all the nuclei of all atoms belonging to one element will have the same atomic number, they may not necessarily have the same mass number; atoms of an element which have different mass numbers are known as isotopes. For example, all atoms with 6 protons in their nuclei are atoms of the chemical element carbon, but atoms of carbon may have mass numbers of 12 or 13.The standard presentation of the chemical elements is in the periodic table, which orders elements by atomic number. The periodic table is arranged in groups, or columns, and periods, or rows. The periodic table is useful in identifying periodic trends.  Compound  A compound is a pure chemical substance composed of more than one element. The properties of a compound bear little similarity to those of its elements. The standard nomenclature of compounds is set by the International Union of Pure and Applied Chemistry (IUPAC). Organic compounds are named according to the organic nomenclature system. The names for inorganic compounds are created according to the inorganic nomenclature system. When a compound has more than one component, then they are divided into two classes, the electropositive and the electronegative components. In addition the Chemical Abstracts Service has devised a method to index chemical substances. In this scheme each chemical substance is identifiable by a number known as its CAS registry number.  Molecule  A molecule is the smallest indivisible portion of a pure chemical substance that has its unique set of chemical properties, that is, its potential to undergo a certain set of chemical reactions with other substances. However, this definition only works well for substances that are composed of molecules, which is not true of many substances (see below). Molecules are typically a set of atoms bound together by covalent bonds, such that the structure is electrically neutral and all valence electrons are paired with other electrons either in bonds or in lone pairs. Thus, molecules exist as electrically neutral units, unlike ions. When this rule is broken, giving the ""molecule"" a charge, the result is sometimes named a molecular ion or a polyatomic ion. However, the discrete and separate nature of the molecular concept usually requires that molecular ions be present only in well-separated form, such as a directed beam in a vacuum in a mass spectrometer. Charged polyatomic collections residing in solids (for example, common sulfate or nitrate ions) are generally not considered ""molecules"" in chemistry. Some molecules contain one or more unpaired electrons, creating radicals. Most radicals are comparatively reactive, but some, such as nitric oxide (NO) can be stable. The ""inert"" or noble gas elements (helium, neon, argon, krypton, xenon and radon) are composed of lone atoms as their smallest discrete unit, but the other isolated chemical elements consist of either molecules or networks of atoms bonded to each other in some way. Identifiable molecules compose familiar substances such as water, air, and many organic compounds like alcohol, sugar, gasoline, and the various pharmaceuticals. However, not all substances or chemical compounds consist of discrete molecules, and indeed most of the solid substances that make up the solid crust, mantle, and core of the Earth are chemical compounds without molecules. These other types of substances, such as ionic compounds and network solids, are organized in such a way as to lack the existence of identifiable molecules per se. Instead, these substances are discussed in terms of formula units or unit cells as the smallest repeating structure within the substance. Examples of such substances are mineral salts (such as table salt), solids like carbon and diamond, metals, and familiar silica and silicate minerals such as quartz and granite. One of the main characteristics of a molecule is its geometry often called its structure. While the structure of diatomic, triatomic or tetra-atomic molecules may be trivial, (linear, angular pyramidal etc.) the structure of polyatomic molecules, that are constituted of more than six atoms (of several elements) can be crucial for its chemical nature.  Substance and mixture  A chemical substance is a kind of matter with a definite composition and set of properties. A collection of substances is called a mixture. Examples of mixtures are air and alloys.  Mole and amount of substance  The mole is a unit of measurement that denotes an amount of substance (also called chemical amount). One mole is defined to contain exactly 6.02214076×1023 particles (atoms, molecules, ions, or electrons), where the number of particles per mole is known as the Avogadro constant. Molar concentration is the amount of a particular substance per volume of solution, and is commonly reported in mol/dm3.  Phase  In addition to the specific chemical properties that distinguish different chemical classifications, chemicals can exist in several phases. For the most part, the chemical classifications are independent of these bulk phase classifications; however, some more exotic phases are incompatible with certain chemical properties. A phase is a set of states of a chemical system that have similar bulk structural properties, over a range of conditions, such as pressure or temperature. Physical properties, such as density and refractive index tend to fall within values characteristic of the phase. The phase of matter is defined by the phase transition, which is when energy put into or taken out of the system goes into rearranging the structure of the system, instead of changing the bulk conditions. Sometimes the distinction between phases can be continuous instead of having a discrete boundary' in this case the matter is considered to be in a supercritical state. When three states meet based on the conditions, it is known as a triple point and since this is invariant, it is a convenient way to define a set of conditions. The most familiar examples of phases are solids, liquids, and gases. Many substances exhibit multiple solid phases. For example, there are three phases of solid iron (alpha, gamma, and delta) that vary based on temperature and pressure. A principal difference between solid phases is the crystal structure, or arrangement, of the atoms. Another phase commonly encountered in the study of chemistry is the aqueous phase, which is the state of substances dissolved in aqueous solution (that is, in water). Less familiar phases include plasmas, Bose–Einstein condensates and fermionic condensates and the paramagnetic and ferromagnetic phases of magnetic materials. While most familiar phases deal with three-dimensional systems, it is also possible to define analogs in two-dimensional systems, which has received attention for its relevance to systems in biology.  Bonding  Atoms sticking together in molecules or crystals are said to be bonded with one another. A chemical bond may be visualized as the multipole balance between the positive charges in the nuclei and the negative charges oscillating about them. More than simple attraction and repulsion, the energies and distributions characterize the availability of an electron to bond to another atom. The chemical bond can be a covalent bond, an ionic bond, a hydrogen bond or just because of Van der Waals force. Each of these kinds of bonds is ascribed to some potential. These potentials create the interactions which hold atoms together in molecules or crystals. In many simple compounds, valence bond theory, the Valence Shell Electron Pair Repulsion model (VSEPR), and the concept of oxidation number can be used to explain molecular structure and composition. An ionic bond is formed when a metal loses one or more of its electrons, becoming a positively charged cation, and the electrons are then gained by the non-metal atom, becoming a negatively charged anion. The two oppositely charged ions attract one another, and the ionic bond is the electrostatic force of attraction between them. For example, sodium (Na), a metal, loses one electron to become an Na+ cation while chlorine (Cl), a non-metal, gains this electron to become Cl−. The ions are held together due to electrostatic attraction, and that compound sodium chloride (NaCl), or common table salt, is formed. In a covalent bond, one or more pairs of valence electrons are shared by two atoms: the resulting electrically neutral group of bonded atoms is termed a molecule. Atoms will share valence electrons in such a way as to create a noble gas electron configuration (eight electrons in their outermost shell) for each atom. Atoms that tend to combine in such a way that they each have eight electrons in their valence shell are said to follow the octet rule. However, some elements like hydrogen and lithium need only two electrons in their outermost shell to attain this stable configuration; these atoms are said to follow the duet rule, and in this way they are reaching the electron configuration of the noble gas helium, which has two electrons in its outer shell. Similarly, theories from classical physics can be used to predict many ionic structures. With more complicated compounds, such as metal complexes, valence bond theory is less applicable and alternative approaches, such as the molecular orbital theory, are generally used. See diagram on electronic orbitals.  Energy  In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structures, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor e − E / k T {displaystyle e^{-E/kT}} – that is the probability of a molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force in the form of ultrasound.A related concept free energy, which also incorporates entropy considerations, is a very useful means for predicting the feasibility of a reaction and determining the state of equilibrium of a chemical reaction, in chemical thermodynamics. A reaction is feasible only if the total change in the Gibbs free energy is negative, Δ G ≤ 0 {displaystyle Delta Gleq 0,} ; if it is equal to zero the chemical reaction is said to be at equilibrium. There exist only limited possible states of energy for electrons, atoms and molecules. These are determined by the rules of quantum mechanics, which require quantization of energy of a bound system. The atoms/molecules in a higher energy state are said to be excited. The molecules/atoms of substance in an excited energy state are often much more reactive; that is, more amenable to chemical reactions. The phase of a substance is invariably determined by its energy and the energy of its surroundings. When the intermolecular forces of a substance are such that the energy of the surroundings is not sufficient to overcome them, it occurs in a more ordered phase like liquid or solid as is the case with water (H2O); a liquid at room temperature because its molecules are bound by hydrogen bonds. Whereas hydrogen sulfide (H2S) is a gas at room temperature and standard pressure, as its molecules are bound by weaker dipole-dipole interactions. The transfer of energy from one chemical substance to another depends on the size of energy quanta emitted from one substance. However, heat energy is often transferred more easily from almost any substance to another because the phonons responsible for vibrational and rotational energy levels in a substance have much less energy than photons invoked for the electronic energy transfer. Thus, because vibrational and rotational energy levels are more closely spaced than electronic energy levels, heat is more easily transferred between substances relative to light or other forms of electronic energy. For example, ultraviolet electromagnetic radiation is not transferred with as much efficacy from one substance to another as thermal or electrical energy. The existence of characteristic energy levels for different chemical substances is useful for their identification by the analysis of spectral lines. Different kinds of spectra are often used in chemical spectroscopy, e.g. IR, microwave, NMR, ESR, etc. Spectroscopy is also used to identify the composition of remote objects – like stars and distant galaxies – by analyzing their radiation spectra. The term chemical energy is often used to indicate the potential of a chemical substance to undergo a transformation through a chemical reaction or to transform other chemical substances.  Reaction  When a chemical substance is transformed as a result of its interaction with another substance or with energy, a chemical reaction is said to have occurred. A chemical reaction is therefore a concept related to the ""reaction"" of a substance when it comes in close contact with another, whether as a mixture or a solution; exposure to some form of energy, or both. It results in some energy exchange between the constituents of the reaction as well as with the system environment, which may be designed vessels—often laboratory glassware. Chemical reactions can result in the formation or dissociation of molecules, that is, molecules breaking apart to form two or more molecules or rearrangement of atoms within or across molecules. Chemical reactions usually involve the making or breaking of chemical bonds. Oxidation, reduction, dissociation, acid–base neutralization and molecular rearrangement are some examples of common chemical reactions. A chemical reaction can be symbolically depicted through a chemical equation. While in a non-nuclear chemical reaction the number and kind of atoms on both sides of the equation are equal, for a nuclear reaction this holds true only for the nuclear particles viz. protons and neutrons.The sequence of steps in which the reorganization of chemical bonds may be taking place in the course of a chemical reaction is called its mechanism. A chemical reaction can be envisioned to take place in a number of steps, each of which may have a different speed. Many reaction intermediates with variable stability can thus be envisaged during the course of a reaction. Reaction mechanisms are proposed to explain the kinetics and the relative product mix of a reaction. Many physical chemists specialize in exploring and proposing the mechanisms of various chemical reactions. Several empirical rules, like the Woodward–Hoffmann rules often come in handy while proposing a mechanism for a chemical reaction. According to the IUPAC gold book, a chemical reaction is ""a process that results in the interconversion of chemical species."" Accordingly, a chemical reaction may be an elementary reaction or a stepwise reaction. An additional caveat is made, in that this definition includes cases where the interconversion of conformers is experimentally observable. Such detectable chemical reactions normally involve sets of molecular entities as indicated by this definition, but it is often conceptually convenient to use the term also for changes involving single molecular entities (i.e. 'microscopic chemical events').  Ions and salts  An ion is a charged species, an atom or a molecule, that has lost or gained one or more electrons. When an atom loses an electron and thus has more protons than electrons, the atom is a positively charged ion or cation. When an atom gains an electron and thus has more electrons than protons, the atom is a negatively charged ion or anion. Cations and anions can form a crystalline lattice of neutral salts, such as the Na+ and Cl− ions forming sodium chloride, or NaCl. Examples of polyatomic ions that do not split up during acid–base reactions are hydroxide (OH−) and phosphate (PO43−). Plasma is composed of gaseous matter that has been completely ionized, usually through high temperature.  Acidity and basicity  A substance can often be classified as an acid or a base. There are several different theories which explain acid–base behavior. The simplest is Arrhenius theory, which states that acid is a substance that produces hydronium ions when it is dissolved in water, and a base is one that produces hydroxide ions when dissolved in water. According to Brønsted–Lowry acid–base theory, acids are substances that donate a positive hydrogen ion to another substance in a chemical reaction; by extension, a base is the substance which receives that hydrogen ion. A third common theory is Lewis acid–base theory, which is based on the formation of new chemical bonds. Lewis theory explains that an acid is a substance which is capable of accepting a pair of electrons from another substance during the process of bond formation, while a base is a substance which can provide a pair of electrons to form a new bond. There are several other ways in which a substance may be classified as an acid or a base, as is evident in the history of this concept.Acid strength is commonly measured by two methods. One measurement, based on the Arrhenius definition of acidity, is pH, which is a measurement of the hydronium ion concentration in a solution, as expressed on a negative logarithmic scale. Thus, solutions that have a low pH have a high hydronium ion concentration and can be said to be more acidic. The other measurement, based on the Brønsted–Lowry definition, is the acid dissociation constant (Ka), which measures the relative ability of a substance to act as an acid under the Brønsted–Lowry definition of an acid. That is, substances with a higher Ka are more likely to donate hydrogen ions in chemical reactions than those with lower Ka values.  Redox  Redox (reduction-oxidation) reactions include all chemical reactions in which atoms have their oxidation state changed by either gaining electrons (reduction) or losing electrons (oxidation). Substances that have the ability to oxidize other substances are said to be oxidative and are known as oxidizing agents, oxidants or oxidizers. An oxidant removes electrons from another substance. Similarly, substances that have the ability to reduce other substances are said to be reductive and are known as reducing agents, reductants, or reducers. A reductant transfers electrons to another substance and is thus oxidized itself. And because it ""donates"" electrons it is also called an electron donor. Oxidation and reduction properly refer to a change in oxidation number—the actual transfer of electrons may never occur. Thus, oxidation is better defined as an increase in oxidation number, and reduction as a decrease in oxidation number.  Equilibrium  Although the concept of equilibrium is widely used across sciences, in the context of chemistry, it arises whenever a number of different states of the chemical composition are possible, as for example, in a mixture of several chemical compounds that can react with one another, or when a substance can be present in more than one kind of phase. A system of chemical substances at equilibrium, even though having an unchanging composition, is most often not static; molecules of the substances continue to react with one another thus giving rise to a dynamic equilibrium. Thus the concept describes the state in which the parameters such as chemical composition remain unchanged over time.  Chemical laws  Chemical reactions are governed by certain laws, which have become fundamental concepts in chemistry. Some of them are:  History  The history of chemistry spans a period from very old times to the present. Since several millennia BC, civilizations were using technologies that would eventually form the basis of the various branches of chemistry. Examples include extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass, and making alloys like bronze. Chemistry was preceded by its protoscience, alchemy, which operated a non-scientific approach to understanding the constituents of matter and their interactions. Despite being unsuccessful in explaining the nature of matter and its transformations, alchemists set the stage for modern chemistry by performing experiments and recording the results. Robert Boyle, although skeptical of elements and convinced of alchemy, played a key part in elevating the ""sacred art"" as an independent, fundamental and philosophical discipline in his work The Sceptical Chymist (1661).While both alchemy and chemistry are concerned with matter and its transformations, the crucial difference was given by the scientific method that chemists employed in their work. Chemistry, as a body of knowledge distinct from alchemy, became an established science with the work of Antoine Lavoisier, who developed a law of conservation of mass that demanded careful measurement and quantitative observations of chemical phenomena. The history of chemistry afterwards is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.  Definition  The definition of chemistry has changed over time, as new discoveries and theories add to the functionality of the science. The term ""chymistry"", in the view of noted scientist Robert Boyle in 1661, meant the subject of the material principles of mixed bodies. In 1663, the chemist Christopher Glaser described ""chymistry"" as a scientific art, by which one learns to dissolve bodies, and draw from them the different substances on their composition, and how to unite them again, and exalt them to a higher perfection.The 1730 definition of the word ""chemistry"", as used by Georg Ernst Stahl, meant the art of resolving mixed, compound, or aggregate bodies into their principles; and of composing such bodies from those principles. In 1837, Jean-Baptiste Dumas considered the word ""chemistry"" to refer to the science concerned with the laws and effects of molecular forces. This definition further evolved until, in 1947, it came to mean the science of substances: their structure, their properties, and the reactions that change them into other substances – a characterization accepted by Linus Pauling. More recently, in 1998, Professor Raymond Chang broadened the definition of ""chemistry"" to mean the study of matter and the changes it undergoes.  Background  Early civilizations, such as the Egyptians Babylonians and Indians amassed practical knowledge concerning the arts of metallurgy, pottery and dyes, but didn't develop a systematic theory. A basic chemical hypothesis first emerged in Classical Greece with the theory of four elements as propounded definitively by Aristotle stating that fire, air, earth and water were the fundamental elements from which everything is formed as a combination. Greek atomism dates back to 440 BC, arising in works by philosophers such as Democritus and Epicurus. In 50 BCE, the Roman philosopher Lucretius expanded upon the theory in his book De rerum natura (On The Nature of Things). Unlike modern concepts of science, Greek atomism was purely philosophical in nature, with little concern for empirical observations and no concern for chemical experiments.An early form of the idea of conservation of mass is the notion that ""Nothing comes from nothing"" in Ancient Greek philosophy, which can be found in Empedocles (approx. 4th century BC): ""For it is impossible for anything to come to be from what is not, and it cannot be brought about or heard of that what is should be utterly destroyed."" and Epicurus (3rd century BC), who, describing the nature of the Universe, wrote that ""the totality of things was always such as it is now, and always will be"". In the Hellenistic world the art of alchemy first proliferated, mingling magic and occultism into the study of natural substances with the ultimate goal of transmuting elements into gold and discovering the elixir of eternal life. Work, particularly the development of distillation, continued in the early Byzantine period with the most famous practitioner being the 4th century Greek-Egyptian Zosimos of Panopolis. Alchemy continued to be developed and practised throughout the Arab world after the Muslim conquests, and from there, and from the Byzantine remnants, diffused into medieval and Renaissance Europe through Latin translations. The Arabic works attributed to Jabir ibn Hayyan introduced a systematic classification of chemical substances, and provided instructions for deriving an inorganic compound (sal ammoniac or ammonium chloride) from organic substances (such as plants, blood, and hair) by chemical means. Some Arabic Jabirian works (e.g., the ""Book of Mercy"", and the ""Book of Seventy"") were later translated into Latin under the Latinized name ""Geber"", and in 13th-century Europe an anonymous writer, usually referred to as pseudo-Geber, started to produce alchemical and metallurgical writings under this name. Later influential Muslim philosophers, such as Abū al-Rayhān al-Bīrūnī and Avicenna disputed the theories of alchemy, particularly the theory of the transmutation of metals. Under the influence of the new empirical methods propounded by Sir Francis Bacon and others, a group of chemists at Oxford, Robert Boyle, Robert Hooke and John Mayow began to reshape the old alchemical traditions into a scientific discipline. Boyle in particular questioned some commonly held chemical theories and argued for chemical practitioners to be more ""philosophical"" and less commercially focused in The Sceptical Chemyst. He formulated Boyle's law, rejected the classical ""four elements"" and proposed a mechanistic alternative of atoms and chemical reactions that could be subject to rigorous experiment. In the following decades, many important discoveries were made, such as the nature of 'air' which was discovered to be composed of many different gases. The Scottish chemist Joseph Black and the Flemish Jan Baptist van Helmont discovered carbon dioxide, or what Black called 'fixed air' in 1754; Henry Cavendish discovered hydrogen and elucidated its properties and Joseph Priestley and, independently, Carl Wilhelm Scheele isolated pure oxygen. The theory of phlogiston (a substance at the root of all combustion) was propounded by the German Georg Ernst Stahl in the early 18th century and was only overturned by the end of the century by the French chemist Antoine Lavoisier, the chemical analogue of Newton in physics. Lavoisier did more than any other to establish the new science on proper theoretical footing, by elucidating the principle of conservation of mass and developing a new system of chemical nomenclature used to this day.English scientist John Dalton proposed the modern theory of atoms; that all substances are composed of indivisible 'atoms' of matter and that different atoms have varying atomic weights. The development of the electrochemical theory of chemical combinations occurred in the early 19th century as the result of the work of two scientists in particular, Jöns Jacob Berzelius and Humphry Davy, made possible by the prior invention of the voltaic pile by Alessandro Volta. Davy discovered nine new elements including the alkali metals by extracting them from their oxides with electric current. British William Prout first proposed ordering all the elements by their atomic weight as all atoms had a weight that was an exact multiple of the atomic weight of hydrogen. J.A.R. Newlands devised an early table of elements, which was then developed into the modern periodic table of elements in the 1860s by Dmitri Mendeleev and independently by several other scientists including Julius Lothar Meyer. The inert gases, later called the noble gases were discovered by William Ramsay in collaboration with Lord Rayleigh at the end of the century, thereby filling in the basic structure of the table. At the turn of the twentieth century the theoretical underpinnings of chemistry were finally understood due to a series of remarkable discoveries that succeeded in probing and discovering the very nature of the internal structure of atoms. In 1897, J.J. Thomson of the University of Cambridge discovered the electron and soon after the French scientist Becquerel as well as the couple Pierre and Marie Curie investigated the phenomenon of radioactivity. In a series of pioneering scattering experiments Ernest Rutherford at the University of Manchester discovered the internal structure of the atom and the existence of the proton, classified and explained the different types of radioactivity and successfully transmuted the first element by bombarding nitrogen with alpha particles. His work on atomic structure was improved on by his students, the Danish physicist Niels Bohr, the Englishman Henry Moseley and the German Otto Hahn, who went on to father the emerging nuclear chemistry and discovered nuclear fission. The electronic theory of chemical bonds and molecular orbitals was developed by the American scientists Linus Pauling and Gilbert N. Lewis. The year 2011 was declared by the United Nations as the International Year of Chemistry. It was an initiative of the International Union of Pure and Applied Chemistry, and of the United Nations Educational, Scientific, and Cultural Organization and involves chemical societies, academics, and institutions worldwide and relied on individual initiatives to organize local and regional activities. Organic chemistry was developed by Justus von Liebig and others, following Friedrich Wöhler's synthesis of urea. Other crucial 19th century advances were; an understanding of valence bonding (Edward Frankland in 1852) and the application of thermodynamics to chemistry (J. W. Gibbs and Svante Arrhenius in the 1870s).  Practice   Subdisciplines  Chemistry is typically divided into several major sub-disciplines. There are also several main cross-disciplinary and more specialized fields of chemistry. Analytical chemistry is the analysis of material samples to gain an understanding of their chemical composition and structure. Analytical chemistry incorporates standardized experimental methods in chemistry. These methods may be used in all subdisciplines of chemistry, excluding purely theoretical chemistry. Biochemistry is the study of the chemicals, chemical reactions and interactions that take place in living organisms. Biochemistry and organic chemistry are closely related, as in medicinal chemistry or neurochemistry. Biochemistry is also associated with molecular biology and genetics. Inorganic chemistry is the study of the properties and reactions of inorganic compounds. The distinction between organic and inorganic disciplines is not absolute and there is much overlap, most importantly in the sub-discipline of organometallic chemistry. Materials chemistry is the preparation, characterization, and understanding of substances with a useful function. The field is a new breadth of study in graduate programs, and it integrates elements from all classical areas of chemistry with a focus on fundamental issues that are unique to materials. Primary systems of study include the chemistry of condensed phases (solids, liquids, polymers) and interfaces between different phases. Neurochemistry is the study of neurochemicals; including transmitters, peptides, proteins, lipids, sugars, and nucleic acids; their interactions, and the roles they play in forming, maintaining, and modifying the nervous system. Nuclear chemistry is the study of how subatomic particles come together and make nuclei. Modern Transmutation is a large component of nuclear chemistry, and the table of nuclides is an important result and tool for this field. Organic chemistry is the study of the structure, properties, composition, mechanisms, and reactions of organic compounds. An organic compound is defined as any compound based on a carbon skeleton. Physical chemistry is the study of the physical and fundamental basis of chemical systems and processes. In particular, the energetics and dynamics of such systems and processes are of interest to physical chemists. Important areas of study include chemical thermodynamics, chemical kinetics, electrochemistry, statistical mechanics, spectroscopy, and more recently, astrochemistry. Physical chemistry has large overlap with molecular physics. Physical chemistry involves the use of infinitesimal calculus in deriving equations. It is usually associated with quantum chemistry and theoretical chemistry. Physical chemistry is a distinct discipline from chemical physics, but again, there is very strong overlap. Theoretical chemistry is the study of chemistry via fundamental theoretical reasoning (usually within mathematics or physics). In particular the application of quantum mechanics to chemistry is called quantum chemistry. Since the end of the Second World War, the development of computers has allowed a systematic development of computational chemistry, which is the art of developing and applying computer programs for solving chemical problems. Theoretical chemistry has large overlap with (theoretical and experimental) condensed matter physics and molecular physics.Others subdivisions include electrochemistry, femtochemistry, flavor chemistry, flow chemistry, immunohistochemistry, hydrogenation chemistry, mathematical chemistry, molecular mechanics, natural product chemistry, organometallic chemistry, petrochemistry, photochemistry, physical organic chemistry, polymer chemistry, radiochemistry, sonochemistry, supramolecular chemistry, synthetic chemistry, and many others.  Interdisciplinary  Interdisciplinary fields include agrochemistry, astrochemistry (and cosmochemistry), atmospheric chemistry, chemical engineering, chemical biology, chemo-informatics, environmental chemistry, geochemistry, green chemistry, immunochemistry, marine chemistry, materials science, mechanochemistry, medicinal chemistry, molecular biology, nanotechnology, oenology, pharmacology, phytochemistry, solid-state chemistry, surface science, thermochemistry, and many others.  Industry  The chemical industry represents an important economic activity worldwide. The global top 50 chemical producers in 2013 had sales of US$980.5 billion with a profit margin of 10.3%.  Professional societies   See also   References   Bibliography   Further reading  Popular reading Atkins, P.W. Galileo's Finger (Oxford University Press) ISBN 0-19-860941-8 Atkins, P.W. Atkins' Molecules (Cambridge University Press) ISBN 0-521-82397-8 Kean, Sam. The Disappearing Spoon – and Other True Tales from the Periodic Table (Black Swan) London, 2010 ISBN 978-0-552-77750-6 Levi, Primo The Periodic Table (Penguin Books) [1975] translated from the Italian by Raymond Rosenthal (1984) ISBN 978-0-14-139944-7 Stwertka, A. A Guide to the Elements (Oxford University Press) ISBN 0-19-515027-9 ""Dictionary of the History of Ideas"". Archived from the original on 10 March 2008. ""Chemistry"" . Encyclopædia Britannica. Vol. 6 (11th ed.). 1911. pp. 33–76.Introductory undergraduate textbooks Atkins, P.W., Overton, T., Rourke, J., Weller, M. and Armstrong, F. Shriver and Atkins Inorganic Chemistry (4th ed.) 2006 (Oxford University Press) ISBN 0-19-926463-5 Chang, Raymond. Chemistry 6th ed. Boston: James M. Smith, 1998. ISBN 0-07-115221-0. Clayden, Jonathan; Greeves, Nick; Warren, Stuart; Wothers, Peter (2001). Organic Chemistry (1st ed.). Oxford University Press. ISBN 978-0-19-850346-0. Voet and Voet. Biochemistry (Wiley) ISBN 0-471-58651-XAdvanced undergraduate-level or graduate textbooks Atkins, P. W. Physical Chemistry (Oxford University Press) ISBN 0-19-879285-9 Atkins, P. W. et al. Molecular Quantum Mechanics (Oxford University Press) McWeeny, R. Coulson's Valence (Oxford Science Publications) ISBN 0-19-855144-4 Pauling, L. The Nature of the chemical bond (Cornell University Press) ISBN 0-8014-0333-2 Pauling, L., and Wilson, E.B. Introduction to Quantum Mechanics with Applications to Chemistry (Dover Publications) ISBN 0-486-64871-0 Smart and Moore. Solid State Chemistry: An Introduction (Chapman and Hall) ISBN 0-412-40040-5 Stephenson, G. Mathematical Methods for Science Students (Longman) ISBN 0-582-44416-0  External links  General Chemistry principles, patterns and applications.","Chemistry is a branch of science that deals with chemical elements and compounds, and how they work together and change. In other words, chemistry is the branch of science about fundamental properties of matter and chemical reactions. Chemistry is the study of the substances and their transformations (or change).  History  Before 1600, people studied substances to figure out how to do things such as turn lead into gold, but no one managed to do that. This was called alchemy. After 1600, using the scientific method alchemists became chemists. Chemists separated the air into many parts and isolated the noble gases from it. They also processed special minerals from a mine in Sweden to get rare earth metals. Radioactivity was also discovered. 118 different elements have been found. Some are very common, like oxygen. Many are very rare and expensive, like platinum. Some cannot be found on earth and can only be made in labs, like rutherfordium. Since the 1920s, the increased understanding of physics has changed chemists' theories about chemical reactions. With smaller and faster computers, chemists have built better tools for analyzing substances. These tools have been sent to study chemicals on Mars. Police also use those tools to study evidence from crime scenes.  Types of chemistry  There are several types of chemistry. Analytical chemistry looks at which chemicals are in things. For example, looking at how much arsenic is in food. Organic chemistry looks at things that have carbon in them. For example, making acetylene. Inorganic chemistry looks at things that do not have carbon in them. One example is making an integrated circuit. Theoretical chemistry tries to explain chemical data with mathematics and computers. A large area of chemistry is polymer chemistry. This looks at plastics. One example is making nylon. Because plastics are made of carbon, polymer chemistry is part of organic chemistry. Another area is biochemistry. This looks at the chemistry of living things. An example would be seeing how arsenic poisons people. Biochemistry is also part of organic chemistry. There are many other small branches of chemistry.  Concepts of chemistry   Basic concepts  The basic unit of an element is called an atom. An atom is the smallest building block that you can cut an element into without the element breaking down (turning into a lighter element, for example through nuclear fission or radioactive decay). A chemical compound is a substance made up of two or more elements. In a compound, two or more atoms are joined to form a molecule. The tiniest speck of dust or drop of liquid, that one can see is made up of many millions or billions of these molecules. Mixtures are substances where chemicals are mixed but not reacted. An example would be mixing sand and salt. This can be undone again to produce salt and sand separately. Chemical compounds are changed by a chemical reaction. An example would be heating sodium bicarbonate, common baking soda. It will make water, carbon dioxide, and sodium carbonate. This reaction cannot be undone. One very important concept in chemistry is that different atoms interact with one another in very specific proportions. For example, two hydrogen atoms interacting with one oxygen atom lead to the water molecule, H2O. This relationship is known as the ""Law of constant proportions"" and leads to the idea of ""stoichiometry"", a term that refers to the ratios of different atoms in chemical compounds. For example, in water, there are always exactly 2 hydrogen atoms to 1 oxygen atom. In carbon dioxide, there are exactly 2 oxygen atoms for 1 carbon atom. These relationships are described using chemical formulas such as H2O (two hydrogen atoms and one oxygen atom) and CO2 (one carbon atom and two oxygen atoms).  Mole  Because atoms of different elements react with one another in very specific proportions but atoms of different elements have different weights, chemists often describe the number of different elements and compounds in terms of the number of ""moles"". A ""mole"" of any element contains the same number of atoms: 602,214,150,000,000,000,000,000 atoms. The atomic mass of an element can be used to see how much of the element makes a mole. For example, the atomic mass of copper is about 63.55. That means about 63.55 grams of copper metal has a mole of atoms. The atomic mass of chlorine is about 35.45. That means 35.45 grams of chlorine has a mole of atoms in it. Moles can be used to see how many molecules are in chemical compounds, too. Copper(II) chloride is an example. CuCl2 is its chemical formula. There is one copper atom (63.55) and two chlorine atoms (35.45 · 2  70.90). Add all the molar masses of the elements together to get the molar mass of the chemical compound (63.55 + 70.90  134.45). That means in 134.45 grams of copper(II) chloride, there is one mole of copper(II) chloride molecules. This concept is used to calculate how much chemicals are needed in a chemical reaction if no reactants (chemicals that are reacted) should be left. If too much reactant is used, there will be some reactants left in the chemical reaction.  Acids and bases  Acids and bases are common chemicals. Acids release H+ ions when in water, and bases release OH− ions when in water. Acids can react with bases. The H+ ion is taken from the acid by the base. This makes water, H2O. A salt is also made when an acid and a base react together. An example would be reacting hydrochloric acid (HCl) and sodium hydroxide (NaOH). Hydrochloric acid releases H+ and Cl- ions in water. The base releases Na+ and OH- ions. The H+ and the OH- react to make water. There is a solution of sodium chloride (NaCl) left. Sodium chloride is a salt.  Usefulness  Chemistry is very useful in everyday life and makes up the foundation of many branches of science. Most objects are made by chemists (people who do chemistry). Chemists are constantly working to find new and useful substances. Chemists make new drugs and materials like paints that we use every day.  Safety  Many chemicals are harmless, but there are some chemicals that are dangerous. For example, mercury(II) chloride is very toxic. Chromates can cause cancer. Tin(II) chloride pollutes water easily. Hydrochloric acid can cause bad burns. Some chemicals like hydrogen can explode or catch fire. To stay safe, chemists experiment with chemicals in a chemical lab. They use special equipment and clothing to do reactions and keep the chemicals contained. The chemicals used in drugs and in things like bleach have been tested to make sure they are safe if used correctly.  Related pages  Periodic table List of common elements Laboratory techniques Aerosol  References "
"Medicine is the science and practice of caring for a patient, managing the diagnosis, prognosis, prevention, treatment, palliation of their injury or disease, and promoting their health. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.Medicine has been practiced since prehistoric times, and for most of this time it was an art (an area of creativity and skill), frequently having connections to the religious and philosophical beliefs of local culture. For example, a medicine man would apply herbs and say prayers for healing, or an ancient philosopher and physician would apply bloodletting according to the theories of humorism. In recent centuries, since the advent of modern science, most medicine has become a combination of art and science (both basic and applied, under the umbrella of medical science). For example, while stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science. Prescientific forms of medicine, now known as traditional medicine or folk medicine, remain commonly used in the absence of scientific medicine, and are thus called alternative medicine. Alternative treatments outside of scientific medicine with safety and efficacy concerns are termed quackery.  Etymology  Medicine (UK: (listen), US: (listen)) is the science and practice of the diagnosis, prognosis, treatment, and prevention of disease. The word ""medicine"" is derived from Latin medicus, meaning ""a physician"".  Clinical practice  Medical availability and clinical practice varies across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners.In the developed world, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.In modern clinical practice, physicians and physician assistants personally assess patients to diagnose, prognose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins an interaction with an examination of the patient\'s medical history and medical record, followed by a medical interview and a physical examination. Basic diagnostic medical devices (e.g. stethoscope, tongue depressor) are typically used. After examination for signs and interviewing for symptoms, the doctor may order medical tests (e.g. blood tests), take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions. Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks depending upon the complexity of the issue. The components of the medical interview and encounter are: Chief complaint (CC): the reason for the current medical visit. These are the symptoms. They are in the patient\'s own words and are recorded along with the duration of each one. Also called chief concern or presenting complaint. Current activity: occupation, hobbies, what the patient actually does. Family history (FH): listing of diseases in the family that may impact the patient. A family tree is sometimes used. History of present illness (HPI): the chronological order of events of symptoms and further clarification of each symptom. Distinguishable from history of previous illness, often called past medical history (PMH). Medical history comprises HPI and PMH. Medications (Rx): what drugs the patient takes including prescribed, over-the-counter, and home remedies, as well as alternative and herbal medicines or remedies. Allergies are also recorded. Past medical history (PMH/PMHx): concurrent medical problems, past hospitalizations and operations, injuries, past infectious diseases or vaccinations, history of known allergies. Review of systems (ROS) or systems inquiry: a set of additional questions to ask, which may be missed on HPI: a general enquiry (have you noticed any weight loss, change in sleep quality, fevers, lumps and bumps? etc.), followed by questions on the body\'s main organ systems (heart, lungs, digestive tract, urinary tract, etc.). Social history (SH): birthplace, residences, marital history, social and economic status, habits (including diet, medications, tobacco, alcohol).The physical examination is the examination of the patient for medical signs of disease, which are objective and observable, in contrast to symptoms that are volunteered by the patient and not necessarily objectively observable. The healthcare provider uses sight, hearing, touch, and sometimes smell (e.g., in infection, uremia, diabetic ketoacidosis). Four actions are the basis of physical examination: inspection, palpation (feel), percussion (tap to determine resonance characteristics), and auscultation (listen), generally in that order although auscultation occurs prior to percussion and palpation for abdominal assessments.The clinical examination involves the study of: Abdomen and rectum Cardiovascular (heart and blood vessels) General appearance of the patient and specific indicators of disease (nutritional status, presence of jaundice, pallor or clubbing) Genitalia (and pregnancy if the patient is or could be pregnant) Head, eye, ear, nose, and throat (HEENT) Musculoskeletal (including spine and extremities) Neurological (consciousness, awareness, brain, vision, cranial nerves, spinal cord and peripheral nerves) Psychiatric (orientation, mental state, mood, evidence of abnormal perception or thought). Respiratory (large airways and lungs) Skin Vital signs including height, weight, body temperature, blood pressure, pulse, respiration rate, and hemoglobin oxygen saturationIt is to likely focus on areas of interest highlighted in the medical history and may not include everything listed above. The treatment plan may include ordering additional medical laboratory tests and medical imaging studies, starting therapy, referral to a specialist, or watchful observation. Follow-up may be advised. Depending upon the health insurance plan and the managed care system, various forms of ""utilization review"", such as prior authorization of tests, may place barriers on accessing expensive services.The medical decision-making (MDM) process involves analysis and synthesis of all the above data to come up with a list of possible diagnoses (the differential diagnoses), along with an idea of what needs to be done to obtain a definitive diagnosis that would explain the patient\'s problem. On subsequent visits, the process may be repeated in an abbreviated manner to obtain any new history, symptoms, physical findings, and lab or imaging results or specialist consultations.  Institutions  Contemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided. From ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world. Advanced industrial countries (with the exception of the United States) and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three. Most tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it (either directly or as part of an employment contract) or who may be covered by care financed by the government or tribe directly. Transparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness, new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other. The health professionals who provide care in medicine comprise multiple professions such as medics, nurses, physio therapists, and psychologists. These professions will have their own ethical standards, professional education, and bodies. The medical profession have been conceptualized from a sociological perspective.  Delivery  Provision of medical care is classified into primary, secondary, and tertiary care categories. Primary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care. These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes. Secondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient. Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting. Tertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc. Modern medical care also depends on information – still delivered in many health care settings on paper records, but increasingly nowadays by electronic means. In low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that ""user fees"" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.Separation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries, it is traditional for physicians to also provide drugs.  Branches  Working together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, medical physicists, surgeons, surgeon\'s assistant, surgical technologist. The scope and sciences underpinning human medicine overlap many other fields. A patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments. Physicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in. The main branches of medicine are: Basic sciences of medicine; this is what every physician is educated in, and some return to in biomedical research. Interdisciplinary fields, where different medical specialties are mixed to function in certain occasions. Medical specialties  Basic sciences  Anatomy is the study of the physical structure of organisms. In contrast to macroscopic or gross anatomy, cytology and histology are concerned with microscopic structures. Biochemistry is the study of the chemistry taking place in living organisms, especially the structure and function of their chemical components. Biomechanics is the study of the structure and function of biological systems by means of the methods of Mechanics. Biophysics is an interdisciplinary science that uses the methods of physics and physical chemistry to study biological systems. Biostatistics is the application of statistics to biological fields in the broadest sense. A knowledge of biostatistics is essential in the planning, evaluation, and interpretation of medical research. It is also fundamental to epidemiology and evidence-based medicine. Cytology is the microscopic study of individual cells. Embryology is the study of the early development of organisms. Endocrinology is the study of hormones and their effect throughout the body of animals. Epidemiology is the study of the demographics of disease processes, and includes, but is not limited to, the study of epidemics. Genetics is the study of genes, and their role in biological inheritance. Gynecology is the study of female reproductive system. Histology is the study of the structures of biological tissues by light microscopy, electron microscopy and immunohistochemistry. Immunology is the study of the immune system, which includes the innate and adaptive immune system in humans, for example. Lifestyle medicine is the study of the chronic conditions, and how to prevent, treat and reverse them. Medical physics is the study of the applications of physics principles in medicine. Microbiology is the study of microorganisms, including protozoa, bacteria, fungi, and viruses. Molecular biology is the study of molecular underpinnings of the process of replication, transcription and translation of the genetic material. Neuroscience includes those disciplines of science that are related to the study of the nervous system. A main focus of neuroscience is the biology and physiology of the human brain and spinal cord. Some related clinical specialties include neurology, neurosurgery and psychiatry. Nutrition science (theoretical focus) and dietetics (practical focus) is the study of the relationship of food and drink to health and disease, especially in determining an optimal diet. Medical nutrition therapy is done by dietitians and is prescribed for diabetes, cardiovascular diseases, weight and eating disorders, allergies, malnutrition, and neoplastic diseases. Pathology as a science is the study of disease – the causes, course, progression and resolution thereof. Pharmacology is the study of drugs and their actions. Photobiology is the study of the interactions between non-ionizing radiation and living organisms. Physiology is the study of the normal functioning of the body and the underlying regulatory mechanisms. Radiobiology is the study of the interactions between ionizing radiation and living organisms. Toxicology is the study of hazardous effects of drugs and poisons.  Specialties  In the broadest meaning of ""medicine"", there are many different specialties. In the UK, most specialities have their own body or college, which has its own entrance examination. These are collectively known as the Royal Colleges, although not all currently use the term ""Royal"". The development of a speciality is often driven by new technology (such as the development of effective anaesthetics) or ways of working (such as emergency departments); the new specialty leads to the formation of a unifying body of doctors and the prestige of administering their own examination. Within medical circles, specialities usually fit into one of two broad categories: ""Medicine"" and ""Surgery"". ""Medicine"" refers to the practice of non-operative medicine, and most of its subspecialties require preliminary training in Internal Medicine. In the UK, this was traditionally evidenced by passing the examination for the Membership of the Royal College of Physicians (MRCP) or the equivalent college in Scotland or Ireland. ""Surgery"" refers to the practice of operative medicine, and most subspecialties in this area require preliminary training in General Surgery, which in the UK leads to membership of the Royal College of Surgeons of England (MRCS). At present, some specialties of medicine do not fit easily into either of these categories, such as radiology, pathology, or anesthesia. Most of these have branched from one or other of the two camps above; for example anaesthesia developed first as a faculty of the Royal College of Surgeons (for which MRCS/FRCS would have been required) before becoming the Royal College of Anaesthetists and membership of the college is attained by sitting for the examination of the Fellowship of the Royal College of Anesthetists (FRCA).  Surgical specialty  Surgery is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas (for example, a perforated ear drum). Surgeons must also manage pre-operative, post-operative, and potential surgical candidates on the hospital wards. In some centers, anesthesiology is part of the division of surgery (for historical and logistical reasons), although it is not a surgical discipline. Other medical specialties may employ surgical procedures, such as ophthalmology and dermatology, but are not considered surgical sub-specialties per se. Surgical training in the U.S. requires a minimum of five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last an additional one to three years. Because post-residency fellowships can be competitive, many trainees devote two additional years to research. Thus in some cases surgical training will not finish until more than a decade after medical school. Furthermore, surgical training can be very difficult and time-consuming. Surgical subspecialties include those a physician may specialize in after undergoing general surgery residency training as well as several surgical fields with separate residency training. Surgical subspecialties that one may pursue following general surgery residency training: Bariatric surgery Cardiovascular surgery – may also be pursued through a separate cardiovascular surgery residency track Colorectal surgery Endocrine surgery General surgery Hand surgery Hepatico-Pancreatico-Biliary Surgery Minimally invasive surgery Pediatric surgery Plastic surgery – may also be pursued through a separate plastic surgery residency track Surgical critical care Surgical oncology Transplant surgery Trauma surgery Vascular surgery – may also be pursued through a separate vascular surgery residency trackOther surgical specialties within medicine with their own individual residency training: Dermatology Neurosurgery Ophthalmology Oral and maxillofacial surgery Orthopedic surgery Otorhinolaryngology Podiatric surgery – do not undergo medical school training, but rather separate training in podiatry school Urology  Internal medicine specialty  Internal medicine is the medical specialty dealing with the prevention, diagnosis, and treatment of adult diseases. According to some sources, an emphasis on internal structures is implied. In North America, specialists in internal medicine are commonly called ""internists"". Elsewhere, especially in Commonwealth nations, such specialists are often called physicians. These terms, internist or physician (in the narrow sense, common outside North America), generally exclude practitioners of gynecology and obstetrics, pathology, psychiatry, and especially surgery and its subspecialities. Because their patients are often seriously ill or require complex investigations, internists do much of their work in hospitals. Formerly, many internists were not subspecialized; such general physicians would see any complex nonsurgical problem; this style of practice has become much less common. In modern urban practice, most internists are subspecialists: that is, they generally limit their medical practice to problems of one organ system or to one particular area of medical knowledge. For example, gastroenterologists and nephrologists specialize respectively in diseases of the gut and the kidneys.In the Commonwealth of Nations and some other countries, specialist pediatricians and geriatricians are also described as specialist physicians (or internists) who have subspecialized by age of patient rather than by organ system. Elsewhere, especially in North America, general pediatrics is often a form of primary care. There are many subspecialities (or subdisciplines) of internal medicine: Training in internal medicine (as opposed to surgical training), varies considerably across the world: see the articles on medical education for more details. In North America, it requires at least three years of residency training after medical school, which can then be followed by a one- to three-year fellowship in the subspecialties listed above. In general, resident work hours in medicine are less than those in surgery, averaging about 60 hours per week in the US. This difference does not apply in the UK where all doctors are now required by law to work less than 48 hours per week on average.  Diagnostic specialties  Clinical laboratory sciences are the clinical diagnostic services that apply laboratory techniques to diagnosis and management of patients. In the United States, these services are supervised by a pathologist. The personnel that work in these medical laboratory departments are technically trained staff who do not hold medical degrees, but who usually hold an undergraduate medical technology degree, who actually perform the tests, assays, and procedures needed for providing the specific services. Subspecialties include transfusion medicine, cellular pathology, clinical chemistry, hematology, clinical microbiology and clinical immunology. Clinical neurophysiology is concerned with testing the physiology or function of the central and peripheral aspects of the nervous system. These kinds of tests can be divided into recordings of: (1) spontaneous or continuously running electrical activity, or (2) stimulus evoked responses. Subspecialties include electroencephalography, electromyography, evoked potential, nerve conduction study and polysomnography. Sometimes these tests are performed by techs without a medical degree, but the interpretation of these tests is done by a medical professional. Diagnostic radiology is concerned with imaging of the body, e.g. by x-rays, x-ray computed tomography, ultrasonography, and nuclear magnetic resonance tomography. Interventional radiologists can access areas in the body under imaging for an intervention or diagnostic sampling. Nuclear medicine is concerned with studying human organ systems by administering radiolabelled substances (radiopharmaceuticals) to the body, which can then be imaged outside the body by a gamma camera or a PET scanner. Each radiopharmaceutical consists of two parts: a tracer that is specific for the function under study (e.g., neurotransmitter pathway, metabolic pathway, blood flow, or other), and a radionuclide (usually either a gamma-emitter or a positron emitter). There is a degree of overlap between nuclear medicine and radiology, as evidenced by the emergence of combined devices such as the PET/CT scanner. Pathology as a medical specialty is the branch of medicine that deals with the study of diseases and the morphologic, physiologic changes produced by them. As a diagnostic specialty, pathology can be considered the basis of modern scientific medical knowledge and plays a large role in evidence-based medicine. Many modern molecular tests such as flow cytometry, polymerase chain reaction (PCR), immunohistochemistry, cytogenetics, gene rearrangements studies and fluorescent in situ hybridization (FISH) fall within the territory of pathology.  Other major specialties  The following are some major medical specialties that do not directly fit into any of the above-mentioned groups: Anesthesiology (also known as anaesthetics): concerned with the perioperative management of the surgical patient. The anesthesiologist\'s role during surgery is to prevent derangement in the vital organs\' (i.e. brain, heart, kidneys) functions and postoperative pain. Outside of the operating room, the anesthesiology physician also serves the same function in the labor and delivery ward, and some are specialized in critical medicine. Emergency medicine is concerned with the diagnosis and treatment of acute or life-threatening conditions, including trauma, surgical, medical, pediatric, and psychiatric emergencies. Family medicine, family practice, general practice or primary care is, in many countries, the first port-of-call for patients with non-emergency medical problems. Family physicians often provide services across a broad range of settings including office based practices, emergency department coverage, inpatient care, and nursing home care. Medical genetics is concerned with the diagnosis and management of hereditary disorders. Neurology is concerned with diseases of the nervous system. In the UK, neurology is a subspecialty of general medicine. Obstetrics and gynecology (often abbreviated as OB/GYN (American English) or Obs & Gynae (British English)) are concerned respectively with childbirth and the female reproductive and associated organs. Reproductive medicine and fertility medicine are generally practiced by gynecological specialists. Pediatrics (AE) or paediatrics (BE) is devoted to the care of infants, children, and adolescents. Like internal medicine, there are many pediatric subspecialties for specific age ranges, organ systems, disease classes, and sites of care delivery. Pharmaceutical medicine is the medical scientific discipline concerned with the discovery, development, evaluation, registration, monitoring and medical aspects of marketing of medicines for the benefit of patients and public health. Physical medicine and rehabilitation (or physiatry) is concerned with functional improvement after injury, illness, or congenital disorders. Podiatric medicine is the study of, diagnosis, and medical & surgical treatment of disorders of the foot, ankle, lower limb, hip and lower back. Preventive medicine is the branch of medicine concerned with preventing disease. Community health or public health is an aspect of health services concerned with threats to the overall health of a community based on population health analysis. Psychiatry is the branch of medicine concerned with the bio-psycho-social study of the etiology, diagnosis, treatment and prevention of cognitive, perceptual, emotional and behavioral disorders. Related fields include psychotherapy and clinical psychology.  Interdisciplinary fields  Some interdisciplinary sub-specialties of medicine include: Addiction medicine deals with the treatment of addiction. Aerospace medicine deals with medical problems related to flying and space travel. Biomedical Engineering is a field dealing with the application of engineering principles to medical practice. Clinical pharmacology is concerned with how systems of therapeutics interact with patients. Conservation medicine studies the relationship between human and animal health, and environmental conditions. Also known as ecological medicine, environmental medicine, or medical geology. Disaster medicine deals with medical aspects of emergency preparedness, disaster mitigation and management. Diving medicine (or hyperbaric medicine) is the prevention and treatment of diving-related problems. Evolutionary medicine is a perspective on medicine derived through applying evolutionary theory. Forensic medicine deals with medical questions in legal context, such as determination of the time and cause of death, type of weapon used to inflict trauma, reconstruction of the facial features using remains of deceased (skull) thus aiding identification. Gender-based medicine studies the biological and physiological differences between the human sexes and how that affects differences in disease. Health informatics is a relatively recent field that deal with the application of computers and information technology to medicine. Hospice and Palliative Medicine is a relatively modern branch of clinical medicine that deals with pain and symptom relief and emotional support in patients with terminal illnesses including cancer and heart failure. Hospital medicine is the general medical care of hospitalized patients. Physicians whose primary professional focus is hospital medicine are called hospitalists in the United States and Canada. The term Most Responsible Physician (MRP) or attending physician is also used interchangeably to describe this role. Laser medicine involves the use of lasers in the diagnostics or treatment of various conditions. Many other health science fields, e.g. dietetics Medical ethics deals with ethical and moral principles that apply values and judgments to the practice of medicine. Medical humanities includes the humanities (literature, philosophy, ethics, history and religion), social science (anthropology, cultural studies, psychology, sociology), and the arts (literature, theater, film, and visual arts) and their application to medical education and practice. Nosokinetics is the science/subject of measuring and modelling the process of care in health and social care systems. Nosology is the classification of diseases for various purposes. Occupational medicine is the provision of health advice to organizations and individuals to ensure that the highest standards of health and safety at work can be achieved and maintained. Pain management (also called pain medicine, or algiatry) is the medical discipline concerned with the relief of pain. Pharmacogenomics is a form of individualized medicine. Podiatric medicine is the study of, diagnosis, and medical treatment of disorders of the foot, ankle, lower limb, hip and lower back. Sexual medicine is concerned with diagnosing, assessing and treating all disorders related to sexuality. Sports medicine deals with the treatment and prevention and rehabilitation of sports/exercise injuries such as muscle spasms, muscle tears, injuries to ligaments (ligament tears or ruptures) and their repair in athletes, amateur and professional. Therapeutics is the field, more commonly referenced in earlier periods of history, of the various remedies that can be used to treat disease and promote health. Travel medicine or emporiatrics deals with health problems of international travelers or travelers across highly different environments. Tropical medicine deals with the prevention and treatment of tropical diseases. It is studied separately in temperate climates where those diseases are quite unfamiliar to medical practitioners and their local clinical needs. Urgent care focuses on delivery of unscheduled, walk-in care outside of the hospital emergency department for injuries and illnesses that are not severe enough to require care in an emergency department. In some jurisdictions this function is combined with the emergency department. Veterinary medicine; veterinarians apply similar techniques as physicians to the care of animals. Wilderness medicine entails the practice of medicine in the wild, where conventional medical facilities may not be available.  Education and legal controls  Medical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university. Since knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs. A database of objectives covering medical knowledge, as suggested by national societies across the United States, can be searched at http://data.medobjectives.marian.edu/. In most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in ""evidence based"", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health. In the European Union, the profession of doctor of medicine is regulated. A profession is said to be regulated when access and exercise is subject to the possession of a specific professional qualification. The regulated professions database contains a list of regulated professions for doctor of medicine in the EU member states, EEA countries and Switzerland. This list is covered by the Directive 2005/36/EC. Doctors who are negligent or intentionally harmful in their care of patients can face charges of medical malpractice and be subject to civil, criminal, or professional sanctions.  Medical ethics  Medical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are: autonomy – the patient has the right to refuse or choose their treatment. (Latin: Voluntas aegroti suprema lex.) beneficence – a practitioner should act in the best interest of the patient. (Latin: Salus aegroti suprema lex.) justice – concerns the distribution of scarce health resources, and the decision of who gets what treatment (fairness and equality). non-maleficence – ""first, do no harm"" (Latin: primum non-nocere). respect for persons – the patient (and the person treating the patient) have the right to be treated with dignity. truthfulness and honesty – the concept of informed consent has increased in importance since the historical events of the Doctors\' Trial of the Nuremberg trials, Tuskegee syphilis experiment, and others.Values such as these do not give answers as to how to handle a particular situation, but provide a useful framework for understanding conflicts. When moral values are in conflict, the result may be an ethical dilemma or crisis. Sometimes, no good solution to a dilemma in medical ethics exists, and occasionally, the values of the medical community (i.e., the hospital and its staff) conflict with the values of the individual patient, family, or larger non-medical community. Conflicts can also arise between health care providers, or among family members. For example, some argue that the principles of autonomy and beneficence clash when patients refuse blood transfusions, considering them life-saving; and truth-telling was not emphasized to a large extent before the HIV era.  History   Ancient world  Prehistoric medicine incorporated plants (herbalism), animal parts, and minerals. In many cases these materials were used ritually as magical substances by priests, shamans, or medicine men. Well-known spiritual systems include animism (the notion of inanimate objects having spirits), spiritualism (an appeal to gods or communion with ancestor spirits); shamanism (the vesting of an individual with mystic powers); and divination (magically obtaining the truth). The field of medical anthropology examines the ways in which culture and society are organized around or impacted by issues of health, health care and related issues. Early records on medicine have been discovered from ancient Egyptian medicine, Babylonian Medicine, Ayurvedic medicine (in the Indian subcontinent), classical Chinese medicine (predecessor to the modern traditional Chinese medicine), and ancient Greek medicine and Roman medicine. In Egypt, Imhotep (3rd millennium BCE) is the first physician in history known by name. The oldest Egyptian medical text is the Kahun Gynaecological Papyrus from around 2000 BCE, which describes gynaecological diseases. The Edwin Smith Papyrus dating back to 1600 BCE is an early work on surgery, while the Ebers Papyrus dating back to 1500 BCE is akin to a textbook on medicine.In China, archaeological evidence of medicine in Chinese dates back to the Bronze Age Shang Dynasty, based on seeds for herbalism and tools presumed to have been used for surgery. The Huangdi Neijing, the progenitor of Chinese medicine, is a medical text written beginning in the 2nd century BCE and compiled in the 3rd century.In India, the surgeon Sushruta described numerous surgical operations, including the earliest forms of plastic surgery. Earliest records of dedicated hospitals come from Mihintale in Sri Lanka where evidence of dedicated medicinal treatment facilities for patients are found. In Greece, the ancient Greek physician Hippocrates, the ""father of modern medicine"", laid the foundation for a rational approach to medicine. Hippocrates introduced the Hippocratic Oath for physicians, which is still relevant and in use today, and was the first to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, ""exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence"". The Greek physician Galen was also one of the greatest surgeons of the ancient world and performed many audacious operations, including brain and eye surgeries. After the fall of the Western Roman Empire and the onset of the Early Middle Ages, the Greek tradition of medicine went into decline in Western Europe, although it continued uninterrupted in the Eastern Roman (Byzantine) Empire. Most of our knowledge of ancient Hebrew medicine during the 1st millennium BC comes from the Torah, i.e. the Five Books of Moses, which contain various health related laws and rituals. The Hebrew contribution to the development of modern medicine started in the Byzantine Era, with the physician Asaph the Jew.  Middle Ages  The concept of hospital as institution to offer medical care and possibility of a cure for the patients due to the ideals of Christian charity, rather than just merely a place to die, appeared in the Byzantine Empire.Although the concept of uroscopy was known to Galen, he did not see the importance of using it to localize the disease. It was under the Byzantines with physicians such of Theophilus Protospatharius that they realized the potential in uroscopy to determine disease in a time when no microscope or stethoscope existed. That practice eventually spread to the rest of Europe.After 750 CE, the Muslim world had the works of Hippocrates, Galen and Sushruta translated into Arabic, and Islamic physicians engaged in some significant medical research. Notable Islamic medical pioneers include the Persian polymath, Avicenna, who, along with Imhotep and Hippocrates, has also been called the ""father of medicine"". He wrote The Canon of Medicine which became a standard medical text at many medieval European universities, considered one of the most famous books in the history of medicine. Others include Abulcasis, Avenzoar, Ibn al-Nafis, and Averroes. Persian physician Rhazes was one of the first to question the Greek theory of humorism, which nevertheless remained influential in both medieval Western and medieval Islamic medicine. Some volumes of Rhazes\'s work Al-Mansuri, namely ""On Surgery"" and ""A General Book on Therapy"", became part of the medical curriculum in European universities. Additionally, he has been described as a doctor\'s doctor, the father of pediatrics, and a pioneer of ophthalmology. For example, he was the first to recognize the reaction of the eye\'s pupil to light. The Persian Bimaristan hospitals were an early example of public hospitals.In Europe, Charlemagne decreed that a hospital should be attached to each cathedral and monastery and the historian Geoffrey Blainey likened the activities of the Catholic Church in health care during the Middle Ages to an early version of a welfare state: ""It conducted hospitals for the old and orphanages for the young; hospices for the sick of all ages; places for the lepers; and hostels or inns where pilgrims could buy a cheap bed and meal"". It supplied food to the population during famine and distributed food to the poor. This welfare system the church funded through collecting taxes on a large scale and possessing large farmlands and estates. The Benedictine order was noted for setting up hospitals and infirmaries in their monasteries, growing medical herbs and becoming the chief medical care givers of their districts, as at the great Abbey of Cluny. The Church also established a network of cathedral schools and universities where medicine was studied. The Schola Medica Salernitana in Salerno, looking to the learning of Greek and Arab physicians, grew to be the finest medical school in Medieval Europe. However, the fourteenth and fifteenth century Black Death devastated both the Middle East and Europe, and it has even been argued that Western Europe was generally more effective in recovering from the pandemic than the Middle East. In the early modern period, important early figures in medicine and anatomy emerged in Europe, including Gabriele Falloppio and William Harvey. The major shift in medical thinking was the gradual rejection, especially during the Black Death in the 14th and 15th centuries, of what may be called the ""traditional authority"" approach to science and medicine. This was the notion that because some prominent person in the past said something must be so, then that was the way it was, and anything one observed to the contrary was an anomaly (which was paralleled by a similar shift in European society in general – see Copernicus\'s rejection of Ptolemy\'s theories on astronomy). Physicians like Vesalius improved upon or disproved some of the theories from the past. The main tomes used both by medicine students and expert physicians were Materia Medica and Pharmacopoeia. Andreas Vesalius was the author of De humani corporis fabrica, an important book on human anatomy. Bacteria and microorganisms were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field microbiology. Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the ""Manuscript of Paris"" in 1546, and later published in the theological work for which he paid with his life in 1553. Later this was described by Renaldus Columbus and Andrea Cesalpino. Herman Boerhaave is sometimes referred to as a ""father of physiology"" due to his exemplary teaching in Leiden and textbook \'Institutiones medicae\' (1708). Pierre Fauchard has been called ""the father of modern dentistry"".  Modern  Veterinary medicine was, for the first time, truly separated from human medicine in 1761, when the French veterinarian Claude Bourgelat founded the world\'s first veterinary school in Lyon, France. Before this, medical doctors treated both humans and other animals. Modern scientific biomedical research (where results are testable and reproducible) began to replace early Western traditions based on herbalism, the Greek ""four humours"" and other such pre-modern notions. The modern era really began with Edward Jenner\'s discovery of the smallpox vaccine at the end of the 18th century (inspired by the method of inoculation earlier practiced in Asia), Robert Koch\'s discoveries around 1880 of the transmission of disease by bacteria, and then the discovery of antibiotics around 1900. The post-18th century modernity period brought more groundbreaking researchers from Europe. From Germany and Austria, doctors Rudolf Virchow, Wilhelm Conrad Röntgen, Karl Landsteiner and Otto Loewi made notable contributions. In the United Kingdom, Alexander Fleming, Joseph Lister, Francis Crick and Florence Nightingale are considered important. Spanish doctor Santiago Ramón y Cajal is considered the father of modern neuroscience. From New Zealand and Australia came Maurice Wilkins, Howard Florey, and Frank Macfarlane Burnet. Others that did significant work include William Williams Keen, William Coley, James D. Watson (United States); Salvador Luria (Italy); Alexandre Yersin (Switzerland); Kitasato Shibasaburō (Japan); Jean-Martin Charcot, Claude Bernard, Paul Broca (France); Adolfo Lutz (Brazil); Nikolai Korotkov (Russia); Sir William Osler (Canada); and Harvey Cushing (United States). As science and technology developed, medicine became more reliant upon medications. Throughout history and in Europe right until the late 18th century, not only animal and plant products were used as medicine, but also human body parts and fluids. Pharmacology developed in part from herbalism and some drugs are still derived from plants (atropine, ephedrine, warfarin, aspirin, digoxin, vinca alkaloids, taxol, hyoscine, etc.). Vaccines were discovered by Edward Jenner and Louis Pasteur. The first antibiotic was arsphenamine (Salvarsan) discovered by Paul Ehrlich in 1908 after he observed that bacteria took up toxic dyes that human cells did not. The first major class of antibiotics was the sulfa drugs, derived by German chemists originally from azo dyes. Pharmacology has become increasingly sophisticated; modern biotechnology allows drugs targeted towards specific physiological processes to be developed, sometimes designed for compatibility with the body to reduce side-effects. Genomics and knowledge of human genetics and human evolution is having increasingly significant influence on medicine, as the causative genes of most monogenic genetic disorders have now been identified, and the development of techniques in molecular biology, evolution, and genetics are influencing medical technology, practice and decision-making. Evidence-based medicine is a contemporary movement to establish the most effective algorithms of practice (ways of doing things) through the use of systematic reviews and meta-analysis.","Medicine is the science that deals with diseases (illnesses) in humans. Medical workers treat injuries. Medicine also helps people with disease prevention and the best ways to return to a healthy condition.People who practice medicine are most often called medical doctors or physicians. Often doctors work closely with nurses and many other types of health care workers. Many doctors specialize in one kind of medical work. For example, pediatrics is the medical specialty about the health of children.  Specialties in Medicine   Anaesthesiology  In this specialty, the doctor is trained to provide anaesthesia and sedation. This is important for surgeries and certain medical procedures. Anaesthesiologists also provide pre-operative assessments, ensuring the patient is safe during the operation and successfully awakens from anaesthesia after the operation. They assess for medical conditions and suitability for anaesthesia. They screen for risk factors prior to surgery and try to optimize the operative environment for the patient and the surgeon. They are the doctors who give epidurals during labor and delivery, provide spinal blocks, local nerve blocks, and general anaesthesia for procedures. They are the doctors who are especially trained in intubation (putting a tube into the lungs to help a person artificially breathe when the person is paralyzed and asleep during surgery). Hence, due to their skill in intubation, they are often the first line responders for emergencies. They help people who are in distress with their breathing, who have lost their airway or when their airway has become obstructed.  Cardiology  A cardiologist is a doctor with special training on the heart. The doctor in this field ensures the heart is healthy and functions properly. The heart is a vital organ whose role is to pump blood to the rest of the body. The purpose of blood is to deliver oxygen to the tissues. Without the heart functioning well, our tissues and organs would die and not function properly. Cardiologists treat heart attacks, sudden cardiac arrests, arrhythmias (rhythm issues related to a faulty electrical system of the heart), heart failure (where the heart fails to pump blood forward properly) and many other heart related illnesses. They specialize in life saving procedures like cardiac stents and cardiac ablation. There is a subspecialty within cardiology called ""Interventional cardiology."" These are cardiologists who specialize in interventions or procedures to save the function of the heart, such as cardiac stenting or angiography.  Cardiovascular surgery  This specialty consists of well trained doctors who practice cardiac surgery. They are best known for their role in cardiac bypass surgeries. In cardiac bypass, the surgeon restores blood flow to the area of the heart that was deficient due to a blocked coronary artery. This is usually done by taking a vein, most commonly the saphenous vein from the leg, to create a pathway of blood flow to the heart region that needs it. Dermatology  Emergency Medicine  Emergency room doctors are in charge of sudden important or life-threatening emergencies. In addition to dealing with heart attacks, strokes, traumas, issues that require immediate medical attention or surgeries, they also deal with a wide range of other health conditions, such as mental health and drug overdoses. Their training is broad and diverse as anyone can walk through the door seeking help. They see patients of all ages and walks of life. However, unlike a general practitioner or family doctor, their immediate goal is to make sure the patient is stable and exclude any serious or life-threatening diseases or conditions.  Family medicine  A family doctor, otherwise known as general practitioner, is trained to provide medical service to people of all ages, demographics, and walks of life. Their training is diverse to deal with a variety of conditions including all non surgical specialties. They also follow the patient from birth to death and are trained to treat an individual as a whole, in the context of their social setting and also their family situation and mental health. Unlike specialists who mainly deal with problems of one organ or system, family doctors deal with all parts of the body and synthesize this information for the patient's general health. They provide a global perspective of the person's health in the patient's unique life situation. They are an individual's regular doctor who knows the patient in their social and family context. They can refer to specialists for issues that require more detailed or specialized treatments unavailable to them as an outpatient or beyond their expertise.  Gastroenterology  Gastroenterologists are doctors who specialize in the gastrointestinal (GI) tract and upper abdominal organs. The GI tract is consists of the esophagus all the way down to the anus. The upper abdominal organs include the liver, gallbladder, pancreas and spleen. In addition to dealing with medical conditions associated with these organs, doctors in this speciality also perform endoscopies. This is where a camera is placed to visualize the esophagus and stomach (upper endoscopy) or the colon (lower endoscopy or colonoscopy). Gastroenterologists that specialize in the liver is called a Hepatologist. They are responsible for treating patients with liver failure or cirrhosis. They also treat patients with viral Hepatitis (A,B,C) and many other forms of liver disease.  Infectious Disease  Infectious disease specialists are MDs who study and treat difficult infections, such as rare tropical diseases, antibiotic resistant bacterial infections, dangerous viruses and other highly contagious diseases.  Internal Medicine  Doctors in this specialty are trained to recognize and treat a variety of different conditions involving the internal organs. They have wide knowledge in a number of specialties including, but not limited to: Respirology, Nephrology, Gastroenterology, Cardiology. Doctors who practice broadly in this field are known as General Internists (or General Internal Medicine doctors). Internists can go to receive further training beyond residency in a particular field. For example, Gastroenterologists are internists that have chosen to specialize in GI medicine. Internal medicine doctors are in charge of inpatient units when patients are admitted for a general reason. Unlike family doctors and emergency doctors, although their training is diverse and they have broad knowledge in many organ systems, they do not treat or manage children, babies, or pregnant women. (Those patients are instead cared for by Pediatricians and Obstetrics/gynecology, respectively.)  Gynecology and obstetrics  Doctors in this field, abbreviated OBGYN or Obs/Gyn, specialize in women's health covering conditions of the female reproductive organs, and pregnancy care and delivery. Some examples of gynecological issues they deal with include contraceptive medicine, fertility workup and treatments, prolapse and incontinence, sexual health, ovarian tumors/ cysts, gynecological oncology. They are also surgeons in their fields, capable of performing numerous gynecological surgeries. Doctors in this field also practice obstetrical medicine, specializing in maternal fetal care and deliveries, complications related to deliveries, assisted deliveries (such as vacuum and forceps deliveries) and Caesarian sections.  Nephrology  Nephrologists are MDs who specialize in health and diseases of the kidneys.  Neurology  Neurologists are MDs who study and treat the nervous system, which includes the brain, the spinal cord and it's branches.  Oncology  Oncology is the field of medicine that studies and treats cancer.  Ophthalmology  This medical specialty consists of well trained doctors who recognize and treat medical conditions associated with the eyes. Some common complaints they see include red eye, eye pain, visual changes and trauma. They deal with many eye diseases including conjunctivitis, iritis, blepharitis, hordeolum, chalazion, glaucoma, cataracts, macular degeneration, retinal detachments, papilloedema, central retinary artery occlusion. They are trained to perform surgery.  Orthopedics  Orthopedists are bone doctors. They treat broken bones, musculo-skeletal and other bone problems such as osteoporosis.  Otolaryngology  These are doctors with special training to treat the ears, nose and throat. These are the doctors who will very commonly remove an organ called the ""tonsils"" from a patient.  Pathology  Pathologist study the reasons things go wrong with the body. They examine tissue samples, look for cancer cell types under a microscope, evaluate DNA samples and many other specimens with advanced laboratory techniques.  Psychiatry  Psychiatrists are MDs who study and treat behavioral and thinking disorders.  Pulmonary  This medical area, commonly known as chest medicine or respiratory medicine, deals with the respiratory system. It usually involves patients who require intensive care including life support and mechanical ventilation. Doctors of this field usually are knowledgeable in diseases and conditions of the chest, such as pneumonia or asthma. Doctors in this field tend to perform minor procedures in surgery of the respiratory tract. Pulmonary specialists often practice critical care medicine. They also manage complicated chest infections.  Radiology  Radiologists are physicians who read and explain medical images such as x-ray pictures, CT scans, MRIs, Ultrasound images and other diagnostic movies and pictures. They also direct radiation treatments for cancer patients and others.  Urology  Urologists are doctors who study and treat the urinary tract.  Related pages  Health Health care Public health Medical school  References "
"Diarrhea, also spelled diarrhoea or diarrhœa, is the condition of having at least three loose, liquid, or watery bowel movements each day. It often lasts for a few days and can result in dehydration due to fluid loss. Signs of dehydration often begin with loss of the normal stretchiness of the skin and irritable behaviour. This can progress to decreased urination, loss of skin color, a fast heart rate, and a decrease in responsiveness as it becomes more severe. Loose but non-watery stools in babies who are exclusively breastfed, however, are normal.The most common cause is an infection of the intestines due to either a virus, bacterium, or parasite—a condition also known as gastroenteritis. These infections are often acquired from food or water that has been contaminated by feces, or directly from another person who is infected. The three types of diarrhea are: short duration watery diarrhea, short duration bloody diarrhea, and persistent diarrhea (lasting more than two weeks, which can be either watery or bloody). The short duration watery diarrhea may be due to cholera, although this is rare in the developed world. If blood is present, it is also known as dysentery. A number of non-infectious causes can result in diarrhea. These include lactose intolerance, irritable bowel syndrome, non-celiac gluten sensitivity, celiac disease, inflammatory bowel disease such as ulcerative colitis, hyperthyroidism, bile acid diarrhea, and a number of medications. In most cases, stool cultures to confirm the exact cause are not required.Diarrhea can be prevented by improved sanitation, clean drinking water, and hand washing with soap. Breastfeeding for at least six months and vaccination against rotavirus is also recommended. Oral rehydration solution (ORS)—clean water with modest amounts of salts and sugar—is the treatment of choice. Zinc tablets are also recommended. These treatments have been estimated to have saved 50 million children in the past 25 years. When people have diarrhea it is recommended that they continue to eat healthy food and babies continue to be breastfed. If commercial ORS is not available, homemade solutions may be used. In those with severe dehydration, intravenous fluids may be required. Most cases, however, can be managed well with fluids by mouth. Antibiotics, while rarely used, may be recommended in a few cases such as those who have bloody diarrhea and a high fever, those with severe diarrhea following travelling, and those who grow specific bacteria or parasites in their stool. Loperamide may help decrease the number of bowel movements but is not recommended in those with severe disease.About 1.7 to 5 billion cases of diarrhea occur per year. It is most common in developing countries, where young children get diarrhea on average three times a year. Total deaths from diarrhea are estimated at 1.53 million in 2019—down from 2.9 million in 1990. In 2012, it was the second most common cause of deaths in children younger than five (0.76 million or 11%). Frequent episodes of diarrhea are also a common cause of malnutrition and the most common cause in those younger than five years of age. Other long term problems that can result include stunted growth and poor intellectual development.  Definition  Diarrhea is defined by the World Health Organization as having three or more loose or liquid stools per day, or as having more stools than is normal for that person.Acute diarrhea is defined as an abnormally frequent discharge of semisolid or fluid fecal matter from the bowel, lasting less than 14 days, by World Gastroenterology Organization. Acute diarrhea that is watery may be known as AWD (Acute Watery Diarrhoea.)  Secretory  Secretory diarrhea means that there is an increase in the active secretion, or there is an inhibition of absorption. There is little to no structural damage. The most common cause of this type of diarrhea is a cholera toxin that stimulates the secretion of anions, especially chloride ions (Cl–). Therefore, to maintain a charge balance in the gastrointestinal tract, sodium (Na+) is carried with it, along with water. In this type of diarrhea intestinal fluid secretion is isotonic with plasma even during fasting. It continues even when there is no oral food intake.  Osmotic  Osmotic diarrhea occurs when too much water is drawn into the bowels. If a person drinks solutions with excessive sugar or excessive salt, these can draw water from the body into the bowel and cause osmotic diarrhea. Osmotic diarrhea can also result from maldigestion, e.g. pancreatic disease or coeliac disease, in which the nutrients are left in the lumen to pull in water. Or it can be caused by osmotic laxatives (which work to alleviate constipation by drawing water into the bowels). In healthy individuals, too much magnesium or vitamin C or undigested lactose can produce osmotic diarrhea and distention of the bowel. A person who has lactose intolerance can have difficulty absorbing lactose after an extraordinarily high intake of dairy products. In persons who have fructose malabsorption, excess fructose intake can also cause diarrhea. High-fructose foods that also have a high glucose content are more absorbable and less likely to cause diarrhea. Sugar alcohols such as sorbitol (often found in sugar-free foods) are difficult for the body to absorb and, in large amounts, may lead to osmotic diarrhea. In most of these cases, osmotic diarrhea stops when the offending agent, e.g. milk or sorbitol, is stopped.  Exudative  Exudative diarrhea occurs with the presence of blood and pus in the stool. This occurs with inflammatory bowel diseases, such as Crohn's disease or ulcerative colitis, and other severe infections such as E. coli or other forms of food poisoning.  Inflammatory  Inflammatory diarrhea occurs when there is damage to the mucosal lining or brush border, which leads to a passive loss of protein-rich fluids and a decreased ability to absorb these lost fluids. Features of all three of the other types of diarrhea can be found in this type of diarrhea. It can be caused by bacterial infections, viral infections, parasitic infections, or autoimmune problems such as inflammatory bowel diseases. It can also be caused by tuberculosis, colon cancer, and enteritis.  Dysentery  If there is blood visible in the stools, it is also known as dysentery. The blood is a trace of an invasion of bowel tissue. Dysentery is a symptom of, among others, Shigella, Entamoeba histolytica, and Salmonella.  Health effects  Diarrheal disease may have a negative impact on both physical fitness and mental development. ""Early childhood malnutrition resulting from any cause reduces physical fitness and work productivity in adults,"" and diarrhea is a primary cause of childhood malnutrition. Further, evidence suggests that diarrheal disease has significant impacts on mental development and health; it has been shown that, even when controlling for helminth infection and early breastfeeding, children who had experienced severe diarrhea had significantly lower scores on a series of tests of intelligence.Diarrhea can cause electrolyte imbalances, kidney impairment, dehydration, and defective immune system responses. When oral drugs are administered, the efficiency of the drug is to produce a therapeutic effect and the lack of this effect may be due to the medication travelling too quickly through the digestive system, limiting the time that it can be absorbed. Clinicians try to treat the diarrheas by reducing the dosage of medication, changing the dosing schedule, discontinuation of the drug, and rehydration. The interventions to control the diarrhea are not often effective. Diarrhea can have a profound effect on the quality of life because fecal incontinence is one of the leading factors for placing older adults in long term care facilities (nursing homes).  Causes  In the latter stages of human digestion, ingested materials are inundated with water and digestive fluids such as gastric acid, bile, and digestive enzymes in order to break them down into their nutrient components, which are then absorbed into the bloodstream via the intestinal tract in the small intestine. Prior to defecation, the large intestine reabsorbs the water and other digestive solvents in the waste product in order to maintain proper hydration and overall equilibrium. Diarrhea occurs when the large intestine is prevented, for any number of reasons, from sufficiently absorbing the water or other digestive fluids from fecal matter, resulting in a liquid, or ""loose"", bowel movement.Acute diarrhea is most commonly due to viral gastroenteritis with rotavirus, which accounts for 40% of cases in children under five. In travelers, however, bacterial infections predominate. Various toxins such as mushroom poisoning and drugs can also cause acute diarrhea. Chronic diarrhea can be the part of the presentations of a number of chronic medical conditions affecting the intestine. Common causes include ulcerative colitis, Crohn's disease, microscopic colitis, celiac disease, irritable bowel syndrome, and bile acid malabsorption.  Infections  There are many causes of infectious diarrhea, which include viruses, bacteria and parasites. Infectious diarrhea is frequently referred to as gastroenteritis. Norovirus is the most common cause of viral diarrhea in adults, but rotavirus is the most common cause in children under five years old. Adenovirus types 40 and 41, and astroviruses cause a significant number of infections. Shiga-toxin producing Escherichia coli, such as E coli o157:h7, are the most common cause of infectious bloody diarrhea in the United States.Campylobacter spp. are a common cause of bacterial diarrhea, but infections by Salmonella spp., Shigella spp. and some strains of Escherichia coli are also a frequent cause.In the elderly, particularly those who have been treated with antibiotics for unrelated infections, a toxin produced by Clostridioides difficile often causes severe diarrhea.Parasites, particularly protozoa e.g., Cryptosporidium spp., Giardia spp., Entamoeba histolytica, Blastocystis spp., Cyclospora cayetanensis, are frequently the cause of diarrhea that involves chronic infection. The broad-spectrum antiparasitic agent nitazoxanide has shown efficacy against many diarrhea-causing parasites.Other infectious agents, such as parasites or bacterial toxins, may exacerbate symptoms. In sanitary living conditions where there is ample food and a supply of clean water, an otherwise healthy person usually recovers from viral infections in a few days. However, for ill or malnourished individuals, diarrhea can lead to severe dehydration and can become life-threatening.  Sanitation  Open defecation is a leading cause of infectious diarrhea leading to death.Poverty is a good indicator of the rate of infectious diarrhea in a population. This association does not stem from poverty itself, but rather from the conditions under which impoverished people live. The absence of certain resources compromises the ability of the poor to defend themselves against infectious diarrhea. ""Poverty is associated with poor housing, crowding, dirt floors, lack of access to clean water or to sanitary disposal of fecal waste (sanitation), cohabitation with domestic animals that may carry human pathogens, and a lack of refrigerated storage for food, all of which increase the frequency of diarrhea ... Poverty also restricts the ability to provide age-appropriate, nutritionally balanced diets or to modify diets when diarrhea develops so as to mitigate and repair nutrient losses. The impact is exacerbated by the lack of adequate, available, and affordable medical care.""One of the most common causes of infectious diarrhea is a lack of clean water. Often, improper fecal disposal leads to contamination of groundwater. This can lead to widespread infection among a population, especially in the absence of water filtration or purification. Human feces contains a variety of potentially harmful human pathogens.  Nutrition  Proper nutrition is important for health and functioning, including the prevention of infectious diarrhea. It is especially important to young children who do not have a fully developed immune system. Zinc deficiency, a condition often found in children in developing countries can, even in mild cases, have a significant impact on the development and proper functioning of the human immune system. Indeed, this relationship between zinc deficiency and reduced immune functioning corresponds with an increased severity of infectious diarrhea. Children who have lowered levels of zinc have a greater number of instances of diarrhea, severe diarrhea, and diarrhea associated with fever. Similarly, vitamin A deficiency can cause an increase in the severity of diarrheal episodes. However, there is some discrepancy when it comes to the impact of vitamin A deficiency on the rate of disease. While some argue that a relationship does not exist between the rate of disease and vitamin A status, Others suggest an increase in the rate associated with deficiency. Given that estimates suggest 127 million preschool children worldwide are vitamin A deficient, this population has the potential for increased risk of disease contraction.  Malabsorption  Malabsorption is the inability to absorb food fully, mostly from disorders in the small bowel, but also due to maldigestion from diseases of the pancreas. Causes include: enzyme deficiencies or mucosal abnormality, as in food allergy and food intolerance, e.g. celiac disease (gluten intolerance), lactose intolerance (intolerance to milk sugar, common in non-Europeans), and fructose malabsorption. pernicious anemia, or impaired bowel function due to the inability to absorb vitamin B12, loss of pancreatic secretions, which may be due to cystic fibrosis or pancreatitis, structural defects, like short bowel syndrome (surgically removed bowel) and radiation fibrosis, such as usually follows cancer treatment and other drugs, including agents used in chemotherapy; and certain drugs, like orlistat, which inhibits the absorption of fat.  Inflammatory bowel disease  The two overlapping types here are of unknown origin: Ulcerative colitis is marked by chronic bloody diarrhea and inflammation mostly affects the distal colon near the rectum. Crohn's disease typically affects fairly well demarcated segments of bowel in the colon and often affects the end of the small bowel.  Irritable bowel syndrome  Another possible cause of diarrhea is irritable bowel syndrome (IBS), which usually presents with abdominal discomfort relieved by defecation and unusual stool (diarrhea or constipation) for at least three days a week over the previous three months. Symptoms of diarrhea-predominant IBS can be managed through a combination of dietary changes, soluble fiber supplements and medications such as loperamide or codeine. About 30% of patients with diarrhea-predominant IBS have bile acid malabsorption diagnosed with an abnormal SeHCAT test.  Other diseases  Diarrhea can be caused by other diseases and conditions, namely: Chronic ethanol ingestion Hyperthyroidism Certain medications Bile acid malabsorption Ischemic bowel disease: This usually affects older people and can be due to blocked arteries. Microscopic colitis, a type of inflammatory bowel disease where changes are seen only on histological examination of colonic biopsies. Bile salt malabsorption (primary bile acid diarrhea) where excessive bile acids in the colon produce a secretory diarrhea. Hormone-secreting tumors: some hormones, e.g. serotonin, can cause diarrhea if secreted in excess (usually from a tumor). Chronic mild diarrhea in infants and toddlers may occur with no obvious cause and with no other ill effects; this condition is called toddler's diarrhea. Environmental enteropathy Radiation enteropathy following treatment for pelvic and abdominal cancers.  Medications  Some medications, such as the penicillin can cause diarrhea. Over 700 medications are known to cause diarrhea. The classes of medications that are known to cause diarrhea are laxatives, antacids, heartburn medications, antibiotics, anti-neoplastic drugs, anti-inflammatories as well as many dietary supplements.  Pathophysiology   Evolution  According to two researchers, Nesse and Williams, diarrhea may function as an evolved expulsion defense mechanism. As a result, if it is stopped, there might be a delay in recovery. They cite in support of this argument research published in 1973 that found that treating Shigella with the anti-diarrhea drug (Co-phenotrope, Lomotil) caused people to stay feverish twice as long as those not so treated. The researchers indeed themselves observed that: ""Lomotil may be contraindicated in shigellosis. Diarrhea may represent a defense mechanism"".  Diagnostic approach  The following types of diarrhea may indicate further investigation is needed: In infants Moderate or severe diarrhea in young children Associated with blood Continues for more than two days Associated non-cramping abdominal pain, fever, weight loss, etc. In travelers In food handlers, because of the potential to infect others; In institutions such as hospitals, child care centers, or geriatric and convalescent homes.A severity score is used to aid diagnosis in children.  Chronic diarrhea  When diarrhea lasts for more than four weeks a number of further tests may be recommended including: Complete blood count and a ferritin if anemia is present Thyroid stimulating hormone Tissue transglutaminase for celiac disease Fecal calprotectin to exclude inflammatory bowel disease Stool tests for ova and parasites as well as for Clostridioides difficile A colonoscopy or fecal immunochemical testing for cancer, including biopsies to detect microscopic colitis Testing for bile acid diarrhea with SeHCAT, 7α-hydroxy-4-cholesten-3-one or fecal bile acids depending on availability Hydrogen breath test looking for lactose intolerance Further tests if immunodeficiency, pelvic radiation disease or small intestinal bacterial overgrowth suspected.A 2019 guideline recommended that testing for ova and parasites was only needed in people who are at high risk though they recommend routine testing for giardia. Erythrocyte sedimentation rate (ESR) and C-reactive protein (CRP) were not recommended.  Prevention   Sanitation  Numerous studies have shown that improvements in drinking water and sanitation (WASH) lead to decreased risks of diarrhoea. Such improvements might include for example use of water filters, provision of high-quality piped water and sewer connections.In institutions, communities, and households, interventions that promote hand washing with soap lead to significant reductions in the incidence of diarrhea. The same applies to preventing open defecation at a community-wide level and providing access to improved sanitation. This includes use of toilets and implementation of the entire sanitation chain connected to the toilets (collection, transport, disposal or reuse of human excreta). There is limited evidence that safe disposal of child or adult feces can prevent diarrheal disease.  Hand washing  Basic sanitation techniques can have a profound effect on the transmission of diarrheal disease. The implementation of hand washing using soap and water, for example, has been experimentally shown to reduce the incidence of disease by approximately 30–48%. Hand washing in developing countries, however, is compromised by poverty as acknowledged by the CDC: ""Handwashing is integral to disease prevention in all parts of the world; however, access to soap and water is limited in a number of less developed countries. This lack of access is one of many challenges to proper hygiene in less developed countries."" Solutions to this barrier require the implementation of educational programs that encourage sanitary behaviours.  Water  Given that water contamination is a major means of transmitting diarrheal disease, efforts to provide clean water supply and improved sanitation have the potential to dramatically cut the rate of disease incidence. In fact, it has been proposed that we might expect an 88% reduction in child mortality resulting from diarrheal disease as a result of improved water sanitation and hygiene. Similarly, a meta-analysis of numerous studies on improving water supply and sanitation shows a 22–27% reduction in disease incidence, and a 21–30% reduction in mortality rate associated with diarrheal disease.Chlorine treatment of water, for example, has been shown to reduce both the risk of diarrheal disease, and of contamination of stored water with diarrheal pathogens.  Vaccination  Immunization against the pathogens that cause diarrheal disease is a viable prevention strategy, however it does require targeting certain pathogens for vaccination. In the case of Rotavirus, which was responsible for around 6% of diarrheal episodes and 20% of diarrheal disease deaths in the children of developing countries, use of a Rotavirus vaccine in trials in 1985 yielded a slight (2–3%) decrease in total diarrheal disease incidence, while reducing overall mortality by 6–10%. Similarly, a Cholera vaccine showed a strong reduction in morbidity and mortality, though the overall impact of vaccination was minimal as Cholera is not one of the major causative pathogens of diarrheal disease. Since this time, more effective vaccines have been developed that have the potential to save many thousands of lives in developing nations, while reducing the overall cost of treatment, and the costs to society.Rotavirus vaccine decreases the rates of diarrhea in a population. New vaccines against rotavirus, Shigella, Enterotoxigenic Escherichia coli (ETEC), and cholera are under development, as well as other causes of infectious diarrhea.  Nutrition  Dietary deficiencies in developing countries can be combated by promoting better eating practices. Zinc supplementation proved successful showing a significant decrease in the incidence of diarrheal disease compared to a control group. The majority of the literature suggests that vitamin A supplementation is advantageous in reducing disease incidence. Development of a supplementation strategy should take into consideration the fact that vitamin A supplementation was less effective in reducing diarrhea incidence when compared to vitamin A and zinc supplementation, and that the latter strategy was estimated to be significantly more cost effective.  Breastfeeding  Breastfeeding practices have been shown to have a dramatic effect on the incidence of diarrheal disease in poor populations. Studies across a number of developing nations have shown that those who receive exclusive breastfeeding during their first 6 months of life are better protected against infection with diarrheal diseases. One study in Brazil found that non-breastfed infants were 14 times more likely to die from diarrhea than exclusively breastfed infants. Exclusive breastfeeding is currently recommended for the first six months of an infant's life by the WHO, with continued breastfeeding until at least two years of age.  Others  Probiotics decrease the risk of diarrhea in those taking antibiotics. Insecticide spraying may reduce fly numbers and the risk of diarrhea in children in a setting where there is seasonal variations in fly numbers throughout the year.  Management  In many cases of diarrhea, replacing lost fluid and salts is the only treatment needed. This is usually by mouth – oral rehydration therapy – or, in severe cases, intravenously. Diet restrictions such as the BRAT diet are no longer recommended. Research does not support the limiting of milk to children as doing so has no effect on duration of diarrhea. To the contrary, WHO recommends that children with diarrhea continue to eat as sufficient nutrients are usually still absorbed to support continued growth and weight gain, and that continuing to eat also speeds up recovery of normal intestinal functioning. CDC recommends that children and adults with cholera also continue to eat. There is no evidence that early refeeding in children can cause an increase in inappropriate use of intravenous fluid, episodes of vomiting, and risk of having persistent diarrhea.Medications such as loperamide (Imodium) and bismuth subsalicylate may be beneficial; however they may be contraindicated in certain situations.  Fluids  Oral rehydration solution (ORS) (a slightly sweetened and salty water) can be used to prevent dehydration. Standard home solutions such as salted rice water, salted yogurt drinks, vegetable and chicken soups with salt can be given. Home solutions such as water in which cereal has been cooked, unsalted soup, green coconut water, weak tea (unsweetened), and unsweetened fresh fruit juices can have from half a teaspoon to full teaspoon of salt (from one-and-a-half to three grams) added per liter. Clean plain water can also be one of several fluids given. There are commercial solutions such as Pedialyte, and relief agencies such as UNICEF widely distribute packets of salts and sugar. A WHO publication for physicians recommends a homemade ORS consisting of one liter water with one teaspoon salt (3 grams) and two tablespoons sugar (18 grams) added (approximately the ""taste of tears""). Rehydration Project recommends adding the same amount of sugar but only one-half a teaspoon of salt, stating that this more dilute approach is less risky with very little loss of effectiveness. Both agree that drinks with too much sugar or salt can make dehydration worse.Appropriate amounts of supplemental zinc and potassium should be added if available. But the availability of these should not delay rehydration. As WHO points out, the most important thing is to begin preventing dehydration as early as possible. In another example of prompt ORS hopefully preventing dehydration, CDC recommends for the treatment of cholera continuing to give Oral Rehydration Solution during travel to medical treatment.Vomiting often occurs during the first hour or two of treatment with ORS, especially if a child drinks the solution too quickly, but this seldom prevents successful rehydration since most of the fluid is still absorbed. WHO recommends that if a child vomits, to wait five or ten minutes and then start to give the solution again more slowly.Drinks especially high in simple sugars, such as soft drinks and fruit juices, are not recommended in children under five as they may increase dehydration. A too rich solution in the gut draws water from the rest of the body, just as if the person were to drink sea water. Plain water may be used if more specific and effective ORT preparations are unavailable or are not palatable. Additionally, a mix of both plain water and drinks perhaps too rich in sugar and salt can alternatively be given to the same person, with the goal of providing a medium amount of sodium overall. A nasogastric tube can be used in young children to administer fluids if warranted.  Eating  The WHO recommends a child with diarrhea continue to be fed. Continued feeding speeds the recovery of normal intestinal function. In contrast, children whose food is restricted have diarrhea of longer duration and recover intestinal function more slowly. The WHO states ""Food should never be withheld and the child's usual foods should not be diluted. Breastfeeding should always be continued."" In the specific example of cholera, the CDC makes the same recommendation. Breast-fed infants with diarrhea often choose to breastfeed more, and should be encouraged to do so. In young children who are not breast-fed and live in the developed world, a lactose-free diet may be useful to speed recovery. Eating food containing fibers may help.  Medications  Antidiarrheal agents can be classified into four different groups: antimotility, antisecretory, adsorbent, and anti-infectious. While antibiotics are beneficial in certain types of acute diarrhea, they are usually not used except in specific situations. There are concerns that antibiotics may increase the risk of hemolytic uremic syndrome in people infected with Escherichia coli O157:H7. In resource-poor countries, treatment with antibiotics may be beneficial. However, some bacteria are developing antibiotic resistance, particularly Shigella. Antibiotics can also cause diarrhea, and antibiotic-associated diarrhea is the most common adverse effect of treatment with general antibiotics. While bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness. Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease. These agents should be used only if bloody diarrhea is not present.Diosmectite, a natural aluminomagnesium silicate clay, is effective in alleviating symptoms of acute diarrhea in children, and also has some effects in chronic functional diarrhea, radiation-induced diarrhea, and chemotherapy-induced diarrhea. Another absorbent agent used for the treatment of mild diarrhea is kaopectate. Racecadotril an antisecretory medication may be used to treat diarrhea in children and adults. It has better tolerability than loperamide, as it causes less constipation and flatulence. However, it has little benefit in improving acute diarrhea in children.Bile acid sequestrants such as cholestyramine can be effective in chronic diarrhea due to bile acid malabsorption. Therapeutic trials of these drugs are indicated in chronic diarrhea if bile acid malabsorption cannot be diagnosed with a specific test, such as SeHCAT retention.  Alternative therapies  Zinc supplementation may benefit children over six months old with diarrhea in areas with high rates of malnourishment or zinc deficiency. This supports the World Health Organization guidelines for zinc, but not in the very young. A Cochrane Review from 2020 concludes that probiotics make little or no difference to people who have diarrhoea lasting 2 days or longer and that there is no proof that they reduce its duration. The probiotic lactobacillus can help prevent antibiotic-associated diarrhea in adults but possibly not children. For those with lactose intolerance, taking digestive enzymes containing lactase when consuming dairy products often improves symptoms.  Epidemiology  Worldwide in 2004, approximately 2.5 billion cases of diarrhea occurred, which resulted in 1.5 million deaths among children under the age of five. Greater than half of these were in Africa and South Asia. This is down from a death rate of 4.5 million in 1980 for gastroenteritis. Diarrhea remains the second leading cause of infant mortality (16%) after pneumonia (17%) in this age group.The majority of such cases occur in the developing world, with over half of the recorded cases of childhood diarrhea occurring in Africa and Asia, with 696 million and 1.2 billion cases, respectively, compared to only 480 million in the rest of the world.Infectious diarrhea resulted in about 0.7 million deaths in children under five years old in 2011 and 250 million lost school days. In the Americas, diarrheal disease accounts for a total of 10% of deaths among children aged 1–59 months while in South East Asia, it accounts for 31.3% of deaths. It is estimated that around 21% of child mortalities in developing countries are due to diarrheal disease.  Terminology  The word diarrhea is from the Ancient Greek διάρροια from διά dia ""through"" and ῥέω rheo ""flow"". Diarrhea is the spelling in American English, whereas diarrhoea is the spelling in British English. Slang terms for the condition include ""the runs"", ""the squirts"" (or ""squits"" in Britain) and ""the trots"".  See also  Dysentery Travelers' diarrhea  References ","Diarrhea (DIE-uh-REE-uh), also spelled diarrhoea, happens when the body makes more watery feces than normal. Diarrhea can occur in humans as well as most other mammals.  Causes  Diarrhea is not a disease. But it may be a symptom of a disease. The most common causes of diarrhea are: Viruses, like Norovirus (the most common cause of viral gastroenteritis—""stomach flu""—in humans) Bacteria, like E. coli or C. diff Some medicines, especially antibiotics Food poisoning Lactose intolerance Artificial sweeteners, like sorbitol and mannitol, which are in many sugar-free food products like sugarless gum Other problems with the intestines, like Crohn's disease and irritable bowel syndrome  Child death  In developing nations, diarrheal diseases are the second most common cause of death in children under age 5. Every year in the world, diarrhea kills around 760,000 children under age 5.In developing countries, diarrhea is also one of the most common causes of malnutrition in children under age 5.When children die from diarrhea, the cause is often dehydration (losing too much water from the body). Because diarrhea is watery, it takes away a lot of the water. It also takes away electrolytes—important salts that the body needs to survive. Dehydration is extra dangerous for small children because they have less water in their bodies to begin with. This means they cannot lose as much water as adults before they start to have serious health problems.  Causes  In developing countries, diarrhea is usually caused by an infection in the intestines. These infections can be caused by bacteria, viruses, or parasites. These infections spread easily in some developing countries because of the following reasons: Unsafe drinking water. Bacteria, viruses, and parasites often get into the water, which people then have to drink. Anyone who drinks the water can then get an infection that causes diarrhea. Sanitation, with clean toilets, is often not available. This makes it easier for infections to spread. Clean water and soap for washing hands are often not available, either. If people cannot wash their hands, bacteria, viruses, or parasites can stay on their hands. These microbes can then enter the mouth or get spread to other people with handshaking.  Preventing child deaths  Child deaths from diarrhea can be prevented in different ways.  Re-hydration  When a child is sick with diarrhea, the best way to keep them from dying is to rehydrate them (give them the water and electrolytes (salts) they are losing by having diarrhea). If the child can go to a clinic or hospital, this can be done by giving water and salts intravenously (through a needle placed into a vein). If the child cannot go to a clinic or hospital, oral rehydration solution can be used. (""Oral"" means ""given by mouth""; a ""solution"" is a mixture.) Oral rehydration solution is a mixture of the most important things the body loses when it is dehydrated. These things are clean water, salt, and sugar. Some oral rehydration solutions have extra electrolytes, like potassium, in them also. Some oral rehydration solutions come in packets and just need to be mixed with clean water. Oral rehydration solution can also be made at home. If the water in the area is not safe, it can be boiled to make it safe. (Boiling the water will kill any bacteria, viruses, or parasites in the water.) Salt and sugar are then mixed into the water. Drinking this mixture, after the water cools, will re-hydrate the child, if he drinks enough. Adding a banana or orange juice can add potassium to the mixture.Breast milk will also re-hydrate a child with diarrhea.  Preventing diarrhea  There are some ways to prevent diarrhea, or the spread of diseases that cause diarrhea. However, some of these ways are expensive and difficult to do. These include: Making drinking water safe Making sanitation better Making clean water and soap available for hand washing  Related pages  Feces  References "
"Anatomy (from Ancient Greek ἀνατομή (anatomḗ) 'dissection') is the branch of biology concerned with the study of the structure of organisms and their parts. Anatomy is a branch of natural science that deals with the structural organization of living things. It is an old science, having its beginnings in prehistoric times. Anatomy is inherently tied to developmental biology, embryology, comparative anatomy, evolutionary biology, and phylogeny, as these are the processes by which anatomy is generated, both over immediate and long-term timescales. Anatomy and physiology, which study the structure and function of organisms and their parts respectively, make a natural pair of related disciplines, and are often studied together. Human anatomy is one of the essential basic sciences that are applied in medicine.Anatomy is a complex and dynamic field that is constantly evolving as new discoveries are made. In recent years, there has been a significant increase in the use of advanced imaging techniques, such as MRI and CT scans, which allow for more detailed and accurate visualizations of the body's structures. The discipline of anatomy is divided into macroscopic and microscopic. Macroscopic anatomy, or gross anatomy, is the examination of an animal's body parts using unaided eyesight. Gross anatomy also includes the branch of superficial anatomy. Microscopic anatomy involves the use of optical instruments in the study of the tissues of various structures, known as histology, and also in the study of cells. The history of anatomy is characterized by a progressive understanding of the functions of the organs and structures of the human body. Methods have also improved dramatically, advancing from the examination of animals by dissection of carcasses and cadavers (corpses) to 20th century medical imaging techniques, including X-ray, ultrasound, and magnetic resonance imaging.  Etymology and definition  Derived from the Greek ἀνατομή anatomē ""dissection"" (from ἀνατέμνω anatémnō ""I cut up, cut open"" from ἀνά aná ""up,"" and τέμνω témnō ""I cut""), anatomy is the scientific study of the structure of organisms including their systems, organs and tissues. It includes the appearance and position of the various parts, the materials from which they are composed, and their relationships with other parts. Anatomy is quite distinct from physiology and biochemistry, which deal respectively with the functions of those parts and the chemical processes involved. For example, an anatomist is concerned with the shape, size, position, structure, blood supply and innervation of an organ such as the liver; while a physiologist is interested in the production of bile, the role of the liver in nutrition and the regulation of bodily functions.The discipline of anatomy can be subdivided into a number of branches, including gross or macroscopic anatomy and microscopic anatomy. Gross anatomy is the study of structures large enough to be seen with the naked eye, and also includes superficial anatomy or surface anatomy, the study by sight of the external body features. Microscopic anatomy is the study of structures on a microscopic scale, along with histology (the study of tissues), and embryology (the study of an organism in its immature condition). Regional anatomy is the study of the interrelationships of all of the structures in a specific body region, such as the abdomen. In contrast, systemic anatomy is the study of the structures that make up a discrete body system—that is, a group of structures that work together to perform a unique body function, such as the digestive system.Anatomy can be studied using both invasive and non-invasive methods with the goal of obtaining information about the structure and organization of organs and systems. Methods used include dissection, in which a body is opened and its organs studied, and endoscopy, in which a video camera-equipped instrument is inserted through a small incision in the body wall and used to explore the internal organs and other structures. Angiography using X-rays or magnetic resonance angiography are methods to visualize blood vessels.The term ""anatomy"" is commonly taken to refer to human anatomy. However, substantially similar structures and tissues are found throughout the rest of the animal kingdom, and the term also includes the anatomy of other animals. The term zootomy is also sometimes used to specifically refer to non-human animals. The structure and tissues of plants are of a dissimilar nature and they are studied in plant anatomy.  Animal tissues  The kingdom Animalia contains multicellular organisms that are heterotrophic and motile (although some have secondarily adopted a sessile lifestyle). Most animals have bodies differentiated into separate tissues and these animals are also known as eumetazoans. They have an internal digestive chamber, with one or two openings; the gametes are produced in multicellular sex organs, and the zygotes include a blastula stage in their embryonic development. Metazoans do not include the sponges, which have undifferentiated cells.Unlike plant cells, animal cells have neither a cell wall nor chloroplasts. Vacuoles, when present, are more in number and much smaller than those in the plant cell. The body tissues are composed of numerous types of cell, including those found in muscles, nerves and skin. Each typically has a cell membrane formed of phospholipids, cytoplasm and a nucleus. All of the different cells of an animal are derived from the embryonic germ layers. Those simpler invertebrates which are formed from two germ layers of ectoderm and endoderm are called diploblastic and the more developed animals whose structures and organs are formed from three germ layers are called triploblastic. All of a triploblastic animal's tissues and organs are derived from the three germ layers of the embryo, the ectoderm, mesoderm and endoderm. Animal tissues can be grouped into four basic types: connective, epithelial, muscle and nervous tissue.  Connective tissue  Connective tissues are fibrous and made up of cells scattered among inorganic material called the extracellular matrix. Connective tissue gives shape to organs and holds them in place. The main types are loose connective tissue, adipose tissue, fibrous connective tissue, cartilage and bone. The extracellular matrix contains proteins, the chief and most abundant of which is collagen. Collagen plays a major part in organizing and maintaining tissues. The matrix can be modified to form a skeleton to support or protect the body. An exoskeleton is a thickened, rigid cuticle which is stiffened by mineralization, as in crustaceans or by the cross-linking of its proteins as in insects. An endoskeleton is internal and present in all developed animals, as well as in many of those less developed.  Epithelium  Epithelial tissue is composed of closely packed cells, bound to each other by cell adhesion molecules, with little intercellular space. Epithelial cells can be squamous (flat), cuboidal or columnar and rest on a basal lamina, the upper layer of the basement membrane, the lower layer is the reticular lamina lying next to the connective tissue in the extracellular matrix secreted by the epithelial cells. There are many different types of epithelium, modified to suit a particular function. In the respiratory tract there is a type of ciliated epithelial lining; in the small intestine there are microvilli on the epithelial lining and in the large intestine there are intestinal villi. Skin consists of an outer layer of keratinized stratified squamous epithelium that covers the exterior of the vertebrate body. Keratinocytes make up to 95% of the cells in the skin. The epithelial cells on the external surface of the body typically secrete an extracellular matrix in the form of a cuticle. In simple animals this may just be a coat of glycoproteins. In more advanced animals, many glands are formed of epithelial cells.  Muscle tissue  Muscle cells (myocytes) form the active contractile tissue of the body. Muscle tissue functions to produce force and cause motion, either locomotion or movement within internal organs. Muscle is formed of contractile filaments and is separated into three main types; smooth muscle, skeletal muscle and cardiac muscle. Smooth muscle has no striations when examined microscopically. It contracts slowly but maintains contractibility over a wide range of stretch lengths. It is found in such organs as sea anemone tentacles and the body wall of sea cucumbers. Skeletal muscle contracts rapidly but has a limited range of extension. It is found in the movement of appendages and jaws. Obliquely striated muscle is intermediate between the other two. The filaments are staggered and this is the type of muscle found in earthworms that can extend slowly or make rapid contractions. In higher animals striated muscles occur in bundles attached to bone to provide movement and are often arranged in antagonistic sets. Smooth muscle is found in the walls of the uterus, bladder, intestines, stomach, oesophagus, respiratory airways, and blood vessels. Cardiac muscle is found only in the heart, allowing it to contract and pump blood round the body.  Nervous tissue  Nervous tissue is composed of many nerve cells known as neurons which transmit information. In some slow-moving radially symmetrical marine animals such as ctenophores and cnidarians (including sea anemones and jellyfish), the nerves form a nerve net, but in most animals they are organized longitudinally into bundles. In simple animals, receptor neurons in the body wall cause a local reaction to a stimulus. In more complex animals, specialized receptor cells such as chemoreceptors and photoreceptors are found in groups and send messages along neural networks to other parts of the organism. Neurons can be connected together in ganglia. In higher animals, specialized receptors are the basis of sense organs and there is a central nervous system (brain and spinal cord) and a peripheral nervous system. The latter consists of sensory nerves that transmit information from sense organs and motor nerves that influence target organs. The peripheral nervous system is divided into the somatic nervous system which conveys sensation and controls voluntary muscle, and the autonomic nervous system which involuntarily controls smooth muscle, certain glands and internal organs, including the stomach.  Vertebrate anatomy  All vertebrates have a similar basic body plan and at some point in their lives, mostly in the embryonic stage, share the major chordate characteristics: a stiffening rod, the notochord; a dorsal hollow tube of nervous material, the neural tube; pharyngeal arches; and a tail posterior to the anus. The spinal cord is protected by the vertebral column and is above the notochord, and the gastrointestinal tract is below it. Nervous tissue is derived from the ectoderm, connective tissues are derived from mesoderm, and gut is derived from the endoderm. At the posterior end is a tail which continues the spinal cord and vertebrae but not the gut. The mouth is found at the anterior end of the animal, and the anus at the base of the tail. The defining characteristic of a vertebrate is the vertebral column, formed in the development of the segmented series of vertebrae. In most vertebrates the notochord becomes the nucleus pulposus of the intervertebral discs. However, a few vertebrates, such as the sturgeon and the coelacanth, retain the notochord into adulthood. Jawed vertebrates are typified by paired appendages, fins or legs, which may be secondarily lost. The limbs of vertebrates are considered to be homologous because the same underlying skeletal structure was inherited from their last common ancestor. This is one of the arguments put forward by Charles Darwin to support his theory of evolution.  Fish anatomy  The body of a fish is divided into a head, trunk and tail, although the divisions between the three are not always externally visible. The skeleton, which forms the support structure inside the fish, is either made of cartilage, in cartilaginous fish, or bone in bony fish. The main skeletal element is the vertebral column, composed of articulating vertebrae which are lightweight yet strong. The ribs attach to the spine and there are no limbs or limb girdles. The main external features of the fish, the fins, are composed of either bony or soft spines called rays, which with the exception of the caudal fins, have no direct connection with the spine. They are supported by the muscles which compose the main part of the trunk. The heart has two chambers and pumps the blood through the respiratory surfaces of the gills and on round the body in a single circulatory loop. The eyes are adapted for seeing underwater and have only local vision. There is an inner ear but no external or middle ear. Low frequency vibrations are detected by the lateral line system of sense organs that run along the length of the sides of fish, and these respond to nearby movements and to changes in water pressure.Sharks and rays are basal fish with numerous primitive anatomical features similar to those of ancient fish, including skeletons composed of cartilage. Their bodies tend to be dorso-ventrally flattened, they usually have five pairs of gill slits and a large mouth set on the underside of the head. The dermis is covered with separate dermal placoid scales. They have a cloaca into which the urinary and genital passages open, but not a swim bladder. Cartilaginous fish produce a small number of large, yolky eggs. Some species are ovoviviparous and the young develop internally but others are oviparous and the larvae develop externally in egg cases.The bony fish lineage shows more derived anatomical traits, often with major evolutionary changes from the features of ancient fish. They have a bony skeleton, are generally laterally flattened, have five pairs of gills protected by an operculum, and a mouth at or near the tip of the snout. The dermis is covered with overlapping scales. Bony fish have a swim bladder which helps them maintain a constant depth in the water column, but not a cloaca. They mostly spawn a large number of small eggs with little yolk which they broadcast into the water column.  Amphibian anatomy  Amphibians are a class of animals comprising frogs, salamanders and caecilians. They are tetrapods, but the caecilians and a few species of salamander have either no limbs or their limbs are much reduced in size. Their main bones are hollow and lightweight and are fully ossified and the vertebrae interlock with each other and have articular processes. Their ribs are usually short and may be fused to the vertebrae. Their skulls are mostly broad and short, and are often incompletely ossified. Their skin contains little keratin and lacks scales, but contains many mucous glands and in some species, poison glands. The hearts of amphibians have three chambers, two atria and one ventricle. They have a urinary bladder and nitrogenous waste products are excreted primarily as urea. Amphibians breathe by means of buccal pumping, a pump action in which air is first drawn into the buccopharyngeal region through the nostrils. These are then closed and the air is forced into the lungs by contraction of the throat. They supplement this with gas exchange through the skin which needs to be kept moist.In frogs the pelvic girdle is robust and the hind legs are much longer and stronger than the forelimbs. The feet have four or five digits and the toes are often webbed for swimming or have suction pads for climbing. Frogs have large eyes and no tail. Salamanders resemble lizards in appearance; their short legs project sideways, the belly is close to or in contact with the ground and they have a long tail. Caecilians superficially resemble earthworms and are limbless. They burrow by means of zones of muscle contractions which move along the body and they swim by undulating their body from side to side.  Reptile anatomy  Reptiles are a class of animals comprising turtles, tuataras, lizards, snakes and crocodiles. They are tetrapods, but the snakes and a few species of lizard either have no limbs or their limbs are much reduced in size. Their bones are better ossified and their skeletons stronger than those of amphibians. The teeth are conical and mostly uniform in size. The surface cells of the epidermis are modified into horny scales which create a waterproof layer. Reptiles are unable to use their skin for respiration as do amphibians and have a more efficient respiratory system drawing air into their lungs by expanding their chest walls. The heart resembles that of the amphibian but there is a septum which more completely separates the oxygenated and deoxygenated bloodstreams. The reproductive system has evolved for internal fertilization, with a copulatory organ present in most species. The eggs are surrounded by amniotic membranes which prevents them from drying out and are laid on land, or develop internally in some species. The bladder is small as nitrogenous waste is excreted as uric acid.Turtles are notable for their protective shells. They have an inflexible trunk encased in a horny carapace above and a plastron below. These are formed from bony plates embedded in the dermis which are overlain by horny ones and are partially fused with the ribs and spine. The neck is long and flexible and the head and the legs can be drawn back inside the shell. Turtles are vegetarians and the typical reptile teeth have been replaced by sharp, horny plates. In aquatic species, the front legs are modified into flippers.Tuataras superficially resemble lizards but the lineages diverged in the Triassic period. There is one living species, Sphenodon punctatus. The skull has two openings (fenestrae) on either side and the jaw is rigidly attached to the skull. There is one row of teeth in the lower jaw and this fits between the two rows in the upper jaw when the animal chews. The teeth are merely projections of bony material from the jaw and eventually wear down. The brain and heart are more primitive than those of other reptiles, and the lungs have a single chamber and lack bronchi. The tuatara has a well-developed parietal eye on its forehead.Lizards have skulls with only one fenestra on each side, the lower bar of bone below the second fenestra having been lost. This results in the jaws being less rigidly attached which allows the mouth to open wider. Lizards are mostly quadrupeds, with the trunk held off the ground by short, sideways-facing legs, but a few species have no limbs and resemble snakes. Lizards have moveable eyelids, eardrums are present and some species have a central parietal eye.Snakes are closely related to lizards, having branched off from a common ancestral lineage during the Cretaceous period, and they share many of the same features. The skeleton consists of a skull, a hyoid bone, spine and ribs though a few species retain a vestige of the pelvis and rear limbs in the form of pelvic spurs. The bar under the second fenestra has also been lost and the jaws have extreme flexibility allowing the snake to swallow its prey whole. Snakes lack moveable eyelids, the eyes being covered by transparent ""spectacle"" scales. They do not have eardrums but can detect ground vibrations through the bones of their skull. Their forked tongues are used as organs of taste and smell and some species have sensory pits on their heads enabling them to locate warm-blooded prey.Crocodilians are large, low-slung aquatic reptiles with long snouts and large numbers of teeth. The head and trunk are dorso-ventrally flattened and the tail is laterally compressed. It undulates from side to side to force the animal through the water when swimming. The tough keratinized scales provide body armour and some are fused to the skull. The nostrils, eyes and ears are elevated above the top of the flat head enabling them to remain above the surface of the water when the animal is floating. Valves seal the nostrils and ears when it is submerged. Unlike other reptiles, crocodilians have hearts with four chambers allowing complete separation of oxygenated and deoxygenated blood.  Bird anatomy  Birds are tetrapods but though their hind limbs are used for walking or hopping, their front limbs are wings covered with feathers and adapted for flight. Birds are endothermic, have a high metabolic rate, a light skeletal system and powerful muscles. The long bones are thin, hollow and very light. Air sac extensions from the lungs occupy the centre of some bones. The sternum is wide and usually has a keel and the caudal vertebrae are fused. There are no teeth and the narrow jaws are adapted into a horn-covered beak. The eyes are relatively large, particularly in nocturnal species such as owls. They face forwards in predators and sideways in ducks.The feathers are outgrowths of the epidermis and are found in localized bands from where they fan out over the skin. Large flight feathers are found on the wings and tail, contour feathers cover the bird's surface and fine down occurs on young birds and under the contour feathers of water birds. The only cutaneous gland is the single uropygial gland near the base of the tail. This produces an oily secretion that waterproofs the feathers when the bird preens. There are scales on the legs, feet and claws on the tips of the toes.  Mammal anatomy  Mammals are a diverse class of animals, mostly terrestrial but some are aquatic and others have evolved flapping or gliding flight. They mostly have four limbs, but some aquatic mammals have no limbs or limbs modified into fins, and the forelimbs of bats are modified into wings. The legs of most mammals are situated below the trunk, which is held well clear of the ground. The bones of mammals are well ossified and their teeth, which are usually differentiated, are coated in a layer of prismatic enamel. The teeth are shed once (milk teeth) during the animal's lifetime or not at all, as is the case in cetaceans. Mammals have three bones in the middle ear and a cochlea in the inner ear. They are clothed in hair and their skin contains glands which secrete sweat. Some of these glands are specialized as mammary glands, producing milk to feed the young. Mammals breathe with lungs and have a muscular diaphragm separating the thorax from the abdomen which helps them draw air into the lungs. The mammalian heart has four chambers, and oxygenated and deoxygenated blood are kept entirely separate. Nitrogenous waste is excreted primarily as urea.Mammals are amniotes, and most are viviparous, giving birth to live young. Exceptions to this are the egg-laying monotremes, the platypus and the echidnas of Australia. Most other mammals have a placenta through which the developing foetus obtains nourishment, but in marsupials, the foetal stage is very short and the immature young is born and finds its way to its mother's pouch where it latches on to a nipple and completes its development.  Human anatomy  Humans have the overall body plan of a mammal. Humans have a head, neck, trunk (which includes the thorax and abdomen), two arms and hands, and two legs and feet. Generally, students of certain biological sciences, paramedics, prosthetists and orthotists, physiotherapists, occupational therapists, nurses, podiatrists, and medical students learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures and tutorials and in addition, medical students generally also learn gross anatomy through practical experience of dissection and inspection of cadavers. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope.Human anatomy, physiology and biochemistry are complementary basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems. The major anatomy textbook, Gray's Anatomy, has been reorganized from a systems format to a regional format, in line with modern teaching methods. A thorough working knowledge of anatomy is required by physicians, especially surgeons and doctors working in some diagnostic specialties, such as histopathology and radiology. Academic anatomists are usually employed by universities, medical schools or teaching hospitals. They are often involved in teaching anatomy, and research into certain systems, organs, tissues or cells.  Invertebrate anatomy  Invertebrates constitute a vast array of living organisms ranging from the simplest unicellular eukaryotes such as Paramecium to such complex multicellular animals as the octopus, lobster and dragonfly. They constitute about 95% of the animal species. By definition, none of these creatures has a backbone. The cells of single-cell protozoans have the same basic structure as those of multicellular animals but some parts are specialized into the equivalent of tissues and organs. Locomotion is often provided by cilia or flagella or may proceed via the advance of pseudopodia, food may be gathered by phagocytosis, energy needs may be supplied by photosynthesis and the cell may be supported by an endoskeleton or an exoskeleton. Some protozoans can form multicellular colonies.Metazoans are a multicellular organism, with different groups of cells serving different functions. The most basic types of metazoan tissues are epithelium and connective tissue, both of which are present in nearly all invertebrates. The outer surface of the epidermis is normally formed of epithelial cells and secretes an extracellular matrix which provides support to the organism. An endoskeleton derived from the mesoderm is present in echinoderms, sponges and some cephalopods. Exoskeletons are derived from the epidermis and is composed of chitin in arthropods (insects, spiders, ticks, shrimps, crabs, lobsters). Calcium carbonate constitutes the shells of molluscs, brachiopods and some tube-building polychaete worms and silica forms the exoskeleton of the microscopic diatoms and radiolaria. Other invertebrates may have no rigid structures but the epidermis may secrete a variety of surface coatings such as the pinacoderm of sponges, the gelatinous cuticle of cnidarians (polyps, sea anemones, jellyfish) and the collagenous cuticle of annelids. The outer epithelial layer may include cells of several types including sensory cells, gland cells and stinging cells. There may also be protrusions such as microvilli, cilia, bristles, spines and tubercles.Marcello Malpighi, the father of microscopical anatomy, discovered that plants had tubules similar to those he saw in insects like the silk worm. He observed that when a ring-like portion of bark was removed on a trunk a swelling occurred in the tissues above the ring, and he unmistakably interpreted this as growth stimulated by food coming down from the leaves, and being captured above the ring.  Arthropod anatomy  Arthropods comprise the largest phylum in the animal kingdom with over a million known invertebrate species.Insects possess segmented bodies supported by a hard-jointed outer covering, the exoskeleton, made mostly of chitin. The segments of the body are organized into three distinct parts, a head, a thorax and an abdomen. The head typically bears a pair of sensory antennae, a pair of compound eyes, one to three simple eyes (ocelli) and three sets of modified appendages that form the mouthparts. The thorax has three pairs of segmented legs, one pair each for the three segments that compose the thorax and one or two pairs of wings. The abdomen is composed of eleven segments, some of which may be fused and houses the digestive, respiratory, excretory and reproductive systems. There is considerable variation between species and many adaptations to the body parts, especially wings, legs, antennae and mouthparts.Spiders a class of arachnids have four pairs of legs; a body of two segments—a cephalothorax and an abdomen. Spiders have no wings and no antennae. They have mouthparts called chelicerae which are often connected to venom glands as most spiders are venomous. They have a second pair of appendages called pedipalps attached to the cephalothorax. These have similar segmentation to the legs and function as taste and smell organs. At the end of each male pedipalp is a spoon-shaped cymbium that acts to support the copulatory organ.  Other branches of anatomy  Superficial or surface anatomy is important as the study of anatomical landmarks that can be readily seen from the exterior contours of the body. It enables physicians or veterinary surgeons to gauge the position and anatomy of the associated deeper structures. Superficial is a directional term that indicates that structures are located relatively close to the surface of the body. Comparative anatomy relates to the comparison of anatomical structures (both gross and microscopic) in different animals. Artistic anatomy relates to anatomic studies for artistic reasons.  History   Ancient  In 1600 BCE, the Edwin Smith Papyrus, an Ancient Egyptian medical text, described the heart and its vessels, as well as the brain and its meninges and cerebrospinal fluid, and the liver, spleen, kidneys, uterus and bladder, and it showed the blood vessels diverging from the heart. The Ebers Papyrus (c. 1550 BCE) features a ""treatise on the heart"", with vessels carrying all the body's fluids to or from every member of the body.Ancient Greek anatomy and physiology underwent great changes and advances throughout the early medieval world. Over time, this medical practice expanded by a continually developing understanding of the functions of organs and structures in the body. Phenomenal anatomical observations of the human body were made, which have contributed towards the understanding of the brain, eye, liver, reproductive organs and the nervous system. The Hellenistic Egyptian city of Alexandria was the stepping-stone for Greek anatomy and physiology. Alexandria not only housed the biggest library for medical records and books of the liberal arts in the world during the time of the Greeks, but was also home to many medical practitioners and philosophers. Great patronage of the arts and sciences from the Ptolemy rulers helped raise Alexandria up, further rivalling the cultural and scientific achievements of other Greek states. Some of the most striking advances in early anatomy and physiology took place in Hellenistic Alexandria. Two of the most famous anatomists and physiologists of the third century were Herophilus and Erasistratus. These two physicians helped pioneer human dissection for medical research, using the cadavers of condemned criminals, which was considered taboo until the Renaissance—Herophilus was recognized as the first person to perform systematic dissections. Herophilus became known for his anatomical works making impressing contributions to many branches of anatomy and many other aspects of medicine. Some of the works included classifying the system of the pulse, the discovery that human arteries had thicker walls than veins, and that the atria were parts of the heart. Herophilus's knowledge of the human body has provided vital input towards understanding the brain, eye, liver, reproductive organs and nervous system, and characterizing the course of disease. Erasistratus accurately described the structure of the brain, including the cavities and membranes, and made a distinction between its cerebrum and cerebellum During his study in Alexandria, Erasistratus was particularly concerned with studies of the circulatory and nervous systems. He was able to distinguish the sensory and the motor nerves in the human body and believed that air entered the lungs and heart, which was then carried throughout the body. His distinction between the arteries and veins—the arteries carrying the air through the body, while the veins carried the blood from the heart was a great anatomical discovery. Erasistratus was also responsible for naming and describing the function of the epiglottis and the valves of the heart, including the tricuspid. During the third century, Greek physicians were able to differentiate nerves from blood vessels and tendons and to realize that the nerves convey neural impulses. It was Herophilus who made the point that damage to motor nerves induced paralysis. Herophilus named the meninges and ventricles in the brain, appreciated the division between cerebellum and cerebrum and recognized that the brain was the ""seat of intellect"" and not a ""cooling chamber"" as propounded by Aristotle Herophilus is also credited with describing the optic, oculomotor, motor division of the trigeminal, facial, vestibulocochlear and hypoglossal nerves. Great feats were made during the third century BCE in both the digestive and reproductive systems. Herophilus was able to discover and describe not only the salivary glands, but the small intestine and liver. He showed that the uterus is a hollow organ and described the ovaries and uterine tubes. He recognized that spermatozoa were produced by the testes and was the first to identify the prostate gland.The anatomy of the muscles and skeleton is described in the Hippocratic Corpus, an Ancient Greek medical work written by unknown authors. Aristotle described vertebrate anatomy based on animal dissection. Praxagoras identified the difference between arteries and veins. Also in the 4th century BCE, Herophilos and Erasistratus produced more accurate anatomical descriptions based on vivisection of criminals in Alexandria during the Ptolemaic dynasty.In the 2nd century, Galen of Pergamum, an anatomist, clinician, writer and philosopher, wrote the final and highly influential anatomy treatise of ancient times. He compiled existing knowledge and studied anatomy through dissection of animals. He was one of the first experimental physiologists through his vivisection experiments on animals. Galen's drawings, based mostly on dog anatomy, became effectively the only anatomical textbook for the next thousand years. His work was known to Renaissance doctors only through Islamic Golden Age medicine until it was translated from the Greek some time in the 15th century.  Medieval to early modern  Anatomy developed little from classical times until the sixteenth century; as the historian Marie Boas writes, ""Progress in anatomy before the sixteenth century is as mysteriously slow as its development after 1500 is startlingly rapid"".: 120–121 Between 1275 and 1326, the anatomists Mondino de Luzzi, Alessandro Achillini and Antonio Benivieni at Bologna carried out the first systematic human dissections since ancient times. Mondino's Anatomy of 1316 was the first textbook in the medieval rediscovery of human anatomy. It describes the body in the order followed in Mondino's dissections, starting with the abdomen, then the thorax, then the head and limbs. It was the standard anatomy textbook for the next century.Leonardo da Vinci (1452–1519) was trained in anatomy by Andrea del Verrocchio. He made use of his anatomical knowledge in his artwork, making many sketches of skeletal structures, muscles and organs of humans and other vertebrates that he dissected.Andreas Vesalius (1514–1564), professor of anatomy at the University of Padua, is considered the founder of modern human anatomy. Originally from Brabant, Vesalius published the influential book De humani corporis fabrica (""the structure of the human body""), a large format book in seven volumes, in 1543. The accurate and intricately detailed illustrations, often in allegorical poses against Italianate landscapes, are thought to have been made by the artist Jan van Calcar, a pupil of Titian.In England, anatomy was the subject of the first public lectures given in any science; these were given by the Company of Barbers and Surgeons in the 16th century, joined in 1583 by the Lumleian lectures in surgery at the Royal College of Physicians.  Late modern  In the United States, medical schools began to be set up towards the end of the 18th century. Classes in anatomy needed a continual stream of cadavers for dissection and these were difficult to obtain. Philadelphia, Baltimore and New York were all renowned for body snatching activity as criminals raided graveyards at night, removing newly buried corpses from their coffins. A similar problem existed in Britain where demand for bodies became so great that grave-raiding and even anatomy murder were practised to obtain cadavers. Some graveyards were in consequence protected with watchtowers. The practice was halted in Britain by the Anatomy Act of 1832, while in the United States, similar legislation was enacted after the physician William S. Forbes of Jefferson Medical College was found guilty in 1882 of ""complicity with resurrectionists in the despoliation of graves in Lebanon Cemetery"".The teaching of anatomy in Britain was transformed by Sir John Struthers, Regius Professor of Anatomy at the University of Aberdeen from 1863 to 1889. He was responsible for setting up the system of three years of ""pre-clinical"" academic teaching in the sciences underlying medicine, including especially anatomy. This system lasted until the reform of medical training in 1993 and 2003. As well as teaching, he collected many vertebrate skeletons for his museum of comparative anatomy, published over 70 research papers, and became famous for his public dissection of the Tay Whale. From 1822 the Royal College of Surgeons regulated the teaching of anatomy in medical schools. Medical museums provided examples in comparative anatomy, and were often used in teaching. Ignaz Semmelweis investigated puerperal fever and he discovered how it was caused. He noticed that the frequently fatal fever occurred more often in mothers examined by medical students than by midwives. The students went from the dissecting room to the hospital ward and examined women in childbirth. Semmelweis showed that when the trainees washed their hands in chlorinated lime before each clinical examination, the incidence of puerperal fever among the mothers could be reduced dramatically. Before the modern medical era, the main means for studying the internal structures of the body were dissection of the dead and inspection, palpation and auscultation of the living. It was the advent of microscopy that opened up an understanding of the building blocks that constituted living tissues. Technical advances in the development of achromatic lenses increased the resolving power of the microscope and around 1839, Matthias Jakob Schleiden and Theodor Schwann identified that cells were the fundamental unit of organization of all living things. Study of small structures involved passing light through them and the microtome was invented to provide sufficiently thin slices of tissue to examine. Staining techniques using artificial dyes were established to help distinguish between different types of tissue. Advances in the fields of histology and cytology began in the late 19th century along with advances in surgical techniques allowing for the painless and safe removal of biopsy specimens. The invention of the electron microscope brought a great advance in resolution power and allowed research into the ultrastructure of cells and the organelles and other structures within them. About the same time, in the 1950s, the use of X-ray diffraction for studying the crystal structures of proteins, nucleic acids and other biological molecules gave rise to a new field of molecular anatomy.Equally important advances have occurred in non-invasive techniques for examining the interior structures of the body. X-rays can be passed through the body and used in medical radiography and fluoroscopy to differentiate interior structures that have varying degrees of opaqueness. Magnetic resonance imaging, computed tomography, and ultrasound imaging have all enabled examination of internal structures in unprecedented detail to a degree far beyond the imagination of earlier generations.  See also  Anatomical model Bibliography of biology#Anatomy Outline of human anatomy Plastination Anatomy portal  References   External links  Anatomy at Curlie Anatomy, In Our Time. BBC Radio 4. Melvyn Bragg with guests Ruth Richardson, Andrew Cunningham and Harold Ellis. ""Anatomy of the Human Body"". 20th edition. 1918. Henry Gray Parsons, Frederick Gymer (1911). ""Anatomy"" . Encyclopædia Britannica. Vol. 1 (11th ed.). pp. 920–943. Anatomia Collection: anatomical plates 1522 to 1867 (digitized books and images) Lyman, Henry Munson. The Book of Health (1898). Science History Institute Digital Collections Archived 2 February 2019 at the Wayback Machine. Gunther von Hagens True Anatomy for New Ways of Teaching.  Source  This article incorporates text from a free content work. Licensed under CC BY 4.0. Text taken from Openstax Anatomy and Physiology​, J. Gordon Betts et al, Openstax. To learn how to add open license text to Wikipedia articles, please see this how-to page. For information on reusing text from Wikipedia, please see the terms of use.","Anatomy is the study of the bodies of people and other animals. Anatomy is the study of the inside of the body and outside the body. Anatomy notes the position and structure of organs such as muscles, glands and bones. A person who studies anatomy is an anatomist. The history of anatomy dates back to 1600 BC when Egyptians began studying human anatomy. They discovered the functions of many organs like the liver, spleen, kidneys, heart etc. and were the first to discover the structure and functions of the lymphatic system. For long periods the dissection of deceased people was forbidden, and correct ideas about human anatomy was a long time coming.Academic human anatomists are usually employed by universities, medical schools and teaching hospitals. They are often involved in teaching and research. Gross anatomy studies parts of the body that are big enough to see. Micro-anatomy studies smaller parts.  Body systems  There are different organ systems, such as the cardiovascular system, also known as the circulatory system (the system that gets blood around the body), the muscular system (the system that contains muscles), the nervous system (the system that controls the nerves,and the brain) and the skeleton (the bones). Anatomy, physiology and biochemistry are similar basic medical sciences.  Related pages  Anatomical terms of location Medicine Zoology Comparative anatomy Organ (anatomy) Gray's Anatomy Vesalius William Harvey  References "
"A disease is a particular abnormal condition that negatively affects the structure or function of all or part of an organism, and that is not immediately due to any external injury. Diseases are often known to be medical conditions that are associated with specific signs and symptoms. A disease may be caused by external factors such as pathogens or by internal dysfunctions. For example, internal dysfunctions of the immune system can produce a variety of different diseases, including various forms of immunodeficiency, hypersensitivity, allergies and autoimmune disorders. In humans, disease is often used more broadly to refer to any condition that causes pain, dysfunction, distress, social problems, or death to the person affected, or similar problems for those in contact with the person. In this broader sense, it sometimes includes injuries, disabilities, disorders, syndromes, infections, isolated symptoms, deviant behaviors, and atypical variations of structure and function, while in other contexts and for other purposes these may be considered distinguishable categories. Diseases can affect people not only physically, but also mentally, as contracting and living with a disease can alter the affected person's perspective on life. Death due to disease is called death by natural causes. There are four main types of disease: infectious diseases, deficiency diseases, hereditary diseases (including both genetic diseases and non-genetic hereditary diseases), and physiological diseases. Diseases can also be classified in other ways, such as communicable versus non-communicable diseases. The deadliest diseases in humans are coronary artery disease (blood flow obstruction), followed by cerebrovascular disease and lower respiratory infections. In developed countries, the diseases that cause the most sickness overall are neuropsychiatric conditions, such as depression and anxiety. The study of disease is called pathology, which includes the study of etiology, or cause.  Terminology   Concepts  In many cases, terms such as disease, disorder, morbidity, sickness and illness are used interchangeably; however, there are situations when specific terms are considered preferable. Disease The term disease broadly refers to any condition that impairs the normal functioning of the body. For this reason, diseases are associated with the dysfunction of the body's normal homeostatic processes. Commonly, the term is used to refer specifically to infectious diseases, which are clinically evident diseases that result from the presence of pathogenic microbial agents, including viruses, bacteria, fungi, protozoa, multicellular organisms, and aberrant proteins known as prions. An infection or colonization that does not and will not produce clinically evident impairment of normal functioning, such as the presence of the normal bacteria and yeasts in the gut, or of a passenger virus, is not considered a disease. By contrast, an infection that is asymptomatic during its incubation period, but expected to produce symptoms later, is usually considered a disease. Non-infectious diseases are all other diseases, including most forms of cancer, heart disease, and genetic disease. Acquired disease An acquired disease is one that began at some point during one's lifetime, as opposed to disease that was already present at birth, which is congenital disease. Acquired sounds like it could mean ""caught via contagion"", but it simply means acquired sometime after birth. It also sounds like it could imply secondary disease, but acquired disease can be primary disease. Acute disease An acute disease is one of a short-term nature (acute); the term sometimes also connotes a fulminant nature Chronic condition or chronic disease A chronic disease is one that persists over time, often for at least six months, but may also include illnesses that are expected to last for the entirety of one's natural life. Congenital disorder or congenital disease A congenital disorder is one that is present at birth. It is often a genetic disease or disorder and can be inherited. It can also be the result of a vertically transmitted infection from the mother, such as HIV/AIDS. Genetic disease A genetic disorder or disease is caused by one or more genetic mutations. It is often inherited, but some mutations are random and de novo. Hereditary or inherited disease A hereditary disease is a type of genetic disease caused by genetic mutations that are hereditary (and can run in families) Iatrogenic disease An iatrogenic disease or condition is one that is caused by medical intervention, whether as a side effect of a treatment or as an inadvertent outcome. Idiopathic disease An idiopathic disease has an unknown cause or source. As medical science has advanced, many diseases with entirely unknown causes have had some aspects of their sources explained and therefore shed their idiopathic status. For example, when germs were discovered, it became known that they were a cause of infection, but particular germs and diseases had not been linked. In another example, it is known that autoimmunity is the cause of some forms of diabetes mellitus type 1, even though the particular molecular pathways by which it works are not yet understood. It is also common to know certain factors are associated with certain diseases; however, association does not necessarily imply causality. For example, a third factor might be causing both the disease, and the associated phenomenon. Incurable disease A disease that cannot be cured. Incurable diseases are not necessarily terminal diseases, and sometimes a disease's symptoms can be treated sufficiently for the disease to have little or no impact on quality of life. Primary disease A primary disease is a disease that is due to a root cause of illness, as opposed to secondary disease, which is a sequela, or complication that is caused by the primary disease. For example, a common cold is a primary disease, where rhinitis is a possible secondary disease, or sequela. A doctor must determine what primary disease, a cold or bacterial infection, is causing a patient's secondary rhinitis when deciding whether or not to prescribe antibiotics. Secondary disease A secondary disease is a disease that is a sequela or complication of a prior, causal disease, which is referred to as the primary disease or simply the underlying cause (root cause). For example, a bacterial infection can be primary, wherein a healthy person is exposed to bacteria and becomes infected, or it can be secondary to a primary cause, that predisposes the body to infection. For example, a primary viral infection that weakens the immune system could lead to a secondary bacterial infection. Similarly, a primary burn that creates an open wound could provide an entry point for bacteria, and lead to a secondary bacterial infection. Terminal disease A terminal disease is one that is expected to have the inevitable result of death. Previously, AIDS was a terminal disease; it is now incurable, but can be managed indefinitely using medications. Illness The terms illness and sickness are both generally used as synonyms for disease; however, the term illness is occasionally used to refer specifically to the patient's personal experience of his or her disease. In this model, it is possible for a person to have a disease without being ill (to have an objectively definable, but asymptomatic, medical condition, such as a subclinical infection, or to have a clinically apparent physical impairment but not feel sick or distressed by it), and to be ill without being diseased (such as when a person perceives a normal experience as a medical condition, or medicalizes a non-disease situation in his or her life – for example, a person who feels unwell as a result of embarrassment, and who interprets those feelings as sickness rather than normal emotions). Symptoms of illness are often not directly the result of infection, but a collection of evolved responses – sickness behavior by the body – that helps clear infection and promote recovery. Such aspects of illness can include lethargy, depression, loss of appetite, sleepiness, hyperalgesia, and inability to concentrate. Disorder A disorder is a functional abnormality or disturbance. Medical disorders can be categorized into mental disorders, physical disorders, genetic disorders, emotional and behavioral disorders, and functional disorders. The term disorder is often considered more value-neutral and less stigmatizing than the terms disease or illness, and therefore is preferred terminology in some circumstances. In mental health, the term mental disorder is used as a way of acknowledging the complex interaction of biological, social, and psychological factors in psychiatric conditions; however, the term disorder is also used in many other areas of medicine, primarily to identify physical disorders that are not caused by infectious organisms, such as metabolic disorders. Medical condition or health condition A medical condition or health condition is a broad concept that includes all diseases, lesions, disorders, or nonpathologic condition that normally receives medical treatment, such as pregnancy or childbirth. While the term medical condition generally includes mental illnesses, in some contexts the term is used specifically to denote any illness, injury, or disease except for mental illnesses. The Diagnostic and Statistical Manual of Mental Disorders (DSM), the widely used psychiatric manual that defines all mental disorders, uses the term general medical condition to refer to all diseases, illnesses, and injuries except for mental disorders. This usage is also commonly seen in the psychiatric literature. Some health insurance policies also define a medical condition as any illness, injury, or disease except for psychiatric illnesses. As it is more value-neutral than terms like disease, the term medical condition is sometimes preferred by people with health issues that they do not consider deleterious. On the other hand, by emphasizing the medical nature of the condition, this term is sometimes rejected, such as by proponents of the autism rights movement. The term medical condition is also a synonym for medical state, in which case it describes an individual patient's current state from a medical standpoint. This usage appears in statements that describe a patient as being in critical condition, for example. Morbidity Morbidity (from Latin morbidus 'sick, unhealthy') is a diseased state, disability, or poor health due to any cause. The term may refer to the existence of any form of disease, or to the degree that the health condition affects the patient. Among severely ill patients, the level of morbidity is often measured by ICU scoring systems. Comorbidity, or co-existing disease, is the simultaneous presence of two or more medical conditions, such as schizophrenia and substance abuse. In epidemiology and actuarial science, the term morbidity (also morbidity rate or morbidity frequency) can refer to either the incidence rate, the prevalence of a disease or medical condition, or the percentage of people who experience a given condition within a given timeframe (e.g., 20% of people will get influenza in a year). This measure of sickness is contrasted with the mortality rate of a condition, which is the proportion of people dying during a given time interval. Morbidity rates are used in actuarial professions, such as health insurance, life insurance, and long-term care insurance, to determine the correct premiums to charge to customers. Morbidity rates help insurers predict the likelihood that an insured will contract or develop any number of specified diseases. Pathosis or pathology Pathosis (plural pathoses) is synonymous with disease. The word pathology also has this sense, in which it is commonly used by physicians in the medical literature, although some editors prefer to reserve pathology to its other senses. Sometimes a slight connotative shade causes preference for pathology or pathosis implying ""some [as yet poorly analyzed] pathophysiologic process"" rather than disease implying ""a specific disease entity as defined by diagnostic criteria being already met"". This is hard to quantify denotatively, but it explains why cognitive synonymy is not invariable. Syndrome A syndrome is the association of several signs and symptoms, or other characteristics that often occur together, regardless of whether the cause is known. Some syndromes such as Down syndrome are known to have only one cause (an extra chromosome at birth). Others such as Parkinsonian syndrome are known to have multiple possible causes. Acute coronary syndrome, for example, is not a single disease itself but is rather the manifestation of any of several diseases including myocardial infarction secondary to coronary artery disease. In yet other syndromes, however, the cause is unknown. A familiar syndrome name often remains in use even after an underlying cause has been found or when there are a number of different possible primary causes. Examples of the first-mentioned type are that Turner syndrome and DiGeorge syndrome are still often called by the ""syndrome"" name despite that they can also be viewed as disease entities and not solely as sets of signs and symptoms. Predisease Predisease is a subclinical or prodromal vanguard of a disease. Prediabetes and prehypertension are common examples. The nosology or epistemology of predisease is contentious, though, because there is seldom a bright line differentiating a legitimate concern for subclinical/prodromal/premonitory status, on one hand, and conflict of interest–driven medicalization (e.g. by Pharmaceutical manufacturers) or demedicalization (e.g. by medical and disability insurers), on the other hand. Identifying legitimate predisease can result in useful preventive measures, such as motivating the person to get a healthy amount of physical exercise, but labeling a healthy person with an unfounded notion of predisease can result in overtreatment, such as taking drugs that only help people with severe disease or paying for drug prescription instances whose benefit–cost ratio is minuscule (placing it in the waste category of CMS' ""waste, fraud, and abuse"" classification). On the other hand, failing to identify pre-disease, can result in undertreatment and failure to prevent disease which can cause tremendous waste of resources as well as patient suffering. Prevention is generally significantly more effective, safe and cost-effective than treatment once a disease has manifested. One review proposed three criteria for predisease: a high risk for progression to disease making one ""far more likely to develop"" it than others are- for example, a pre-cancer will almost certainly turn into cancer over time actionability for risk reduction – for example, removal of the precancerous tissue prevents it from turning into a potentially deadly cancer benefit that outweighs the harm of any interventions taken – removing the precancerous tissue prevents cancer, and thus prevents a potential death from cancer.  Types by body system  Mental Mental illness is a broad, generic label for a category of illnesses that may include affective or emotional instability, behavioral dysregulation, cognitive dysfunction or impairment. Specific illnesses known as mental illnesses include major depression, generalized anxiety disorders, schizophrenia, and attention deficit hyperactivity disorder, to name a few. Mental illness can be of biological (e.g., anatomical, chemical, or genetic) or psychological (e.g., trauma or conflict) origin. It can impair the affected person's ability to work or study and can harm interpersonal relationships. The term insanity is used technically as a legal term. Organic An organic disease is one caused by a physical or physiological change to some tissue or organ of the body. The term sometimes excludes infections. It is commonly used in contrast with mental disorders. It includes emotional and behavioral disorders if they are due to changes to the physical structures or functioning of the body, such as after a stroke or a traumatic brain injury, but not if they are due to psychosocial issues.  Stages  In an infectious disease, the incubation period is the time between infection and the appearance of symptoms. The latency period is the time between infection and the ability of the disease to spread to another person, which may precede, follow, or be simultaneous with the appearance of symptoms. Some viruses also exhibit a dormant phase, called viral latency, in which the virus hides in the body in an inactive state. For example, varicella zoster virus causes chickenpox in the acute phase; after recovery from chickenpox, the virus may remain dormant in nerve cells for many years, and later cause herpes zoster (shingles). Acute disease An acute disease is a short-lived disease, like the common cold. Chronic disease A chronic disease is one that lasts for a long time, usually at least six months. During that time, it may be constantly present, or it may go into remission and periodically relapse. A chronic disease may be stable (does not get any worse) or it may be progressive (gets worse over time). Some chronic diseases can be permanently cured. Most chronic diseases can be beneficially treated, even if they cannot be permanently cured. Clinical disease One that has clinical consequences; in other words, the stage of the disease that produces the characteristic signs and symptoms of that disease. AIDS is the clinical disease stage of HIV infection. Cure A cure is the end of a medical condition or a treatment that is very likely to end it, while remission refers to the disappearance, possibly temporarily, of symptoms. Complete remission is the best possible outcome for incurable diseases. Flare-up A flare-up can refer to either the recurrence of symptoms or an onset of more severe symptoms. Progressive disease Progressive disease is a disease whose typical natural course is the worsening of the disease until death, serious debility, or organ failure occurs. Slowly progressive diseases are also chronic diseases; many are also degenerative diseases. The opposite of progressive disease is stable disease or static disease: a medical condition that exists, but does not get better or worse. Refractory disease A refractory disease is a disease that resists treatment, especially an individual case that resists treatment more than is normal for the specific disease in question. Subclinical disease Also called silent disease, silent stage, or asymptomatic disease. This is a stage in some diseases before the symptoms are first noted. Terminal phase If a person will die soon from a disease, regardless of whether that disease typically causes death, then the stage between the earlier disease process and active dying is the terminal phase. Recovery Recovery can refer to the repairing of physical processes (tissues, organs etc.) and the resumption of healthy functioning after damage causing processes have been cured.  Extent  Localized disease A localized disease is one that affects only one part of the body, such as athlete's foot or an eye infection. Disseminated disease A disseminated disease has spread to other parts; with cancer, this is usually called metastatic disease. Systemic disease A systemic disease is a disease that affects the entire body, such as influenza or high blood pressure.  Classification  Diseases may be classified by cause, pathogenesis (mechanism by which the disease is caused), or by symptom(s). Alternatively, diseases may be classified according to the organ system involved, though this is often complicated since many diseases affect more than one organ. A chief difficulty in nosology is that diseases often cannot be defined and classified clearly, especially when cause or pathogenesis are unknown. Thus diagnostic terms often only reflect a symptom or set of symptoms (syndrome). Classical classification of human disease derives from the observational correlation between pathological analysis and clinical syndromes. Today it is preferred to classify them by their cause if it is known.The most known and used classification of diseases is the World Health Organization's ICD. This is periodically updated. Currently, the last publication is the ICD-11.  Causes  Only some diseases such as influenza are contagious and commonly believed infectious. The microorganisms that cause these diseases are known as pathogens and include varieties of bacteria, viruses, protozoa, and fungi. Infectious diseases can be transmitted, e.g. by hand-to-mouth contact with infectious material on surfaces, by bites of insects or other carriers of the disease, and from contaminated water or food (often via fecal contamination), etc. Also, there are sexually transmitted diseases. In some cases, microorganisms that are not readily spread from person to person play a role, while other diseases can be prevented or ameliorated with appropriate nutrition or other lifestyle changes. Some diseases, such as most (but not all) forms of cancer, heart disease, and mental disorders, are non-infectious diseases. Many non-infectious diseases have a partly or completely genetic basis (see genetic disorder) and may thus be transmitted from one generation to another. Social determinants of health are the social conditions in which people live that determine their health. Illnesses are generally related to social, economic, political, and environmental circumstances. Social determinants of health have been recognized by several health organizations such as the Public Health Agency of Canada and the World Health Organization to greatly influence collective and personal well-being. The World Health Organization's Social Determinants Council also recognizes Social determinants of health in poverty. When the cause of a disease is poorly understood, societies tend to mythologize the disease or use it as a metaphor or symbol of whatever that culture considers evil. For example, until the bacterial cause of tuberculosis was discovered in 1882, experts variously ascribed the disease to heredity, a sedentary lifestyle, depressed mood, and overindulgence in sex, rich food, or alcohol, all of which were social ills at the time.When a disease is caused by a pathogenic organism (e.g., when malaria is caused by Plasmodium), one should not confuse the pathogen (the cause of the disease) with disease itself. For example, West Nile virus (the pathogen) causes West Nile fever (the disease). The misuse of basic definitions in epidemiology is frequent in scientific publications.  Types of causes  Airborne An airborne disease is any disease that is caused by pathogens and transmitted through the air. Foodborne Foodborne illness or food poisoning is any illness resulting from the consumption of food contaminated with pathogenic bacteria, toxins, viruses, prions or parasites. Infectious Infectious diseases, also known as transmissible diseases or communicable diseases, comprise clinically evident illness (i.e., characteristic medical signs or symptoms of disease) resulting from the infection, presence and growth of pathogenic biological agents in an individual host organism. Included in this category are contagious diseases – an infection, such as influenza or the common cold, that commonly spreads from one person to another – and communicable diseases – a disease that can spread from one person to another, but does not necessarily spread through everyday contact. Lifestyle A lifestyle disease is any disease that appears to increase in frequency as countries become more industrialized and people live longer, especially if the risk factors include behavioral choices like a sedentary lifestyle or a diet high in unhealthful foods such as refined carbohydrates, trans fats, or alcoholic beverages. Non-communicable A non-communicable disease is a medical condition or disease that is non-transmissible. Non-communicable diseases cannot be spread directly from one person to another. Heart disease and cancer are examples of non-communicable diseases in humans.  Prevention  Many diseases and disorders can be prevented through a variety of means. These include sanitation, proper nutrition, adequate exercise, vaccinations and other self-care and public health measures, such as obligatory face mask mandates.  Treatments  Medical therapies or treatments are efforts to cure or improve a disease or other health problems. In the medical field, therapy is synonymous with the word treatment. Among psychologists, the term may refer specifically to psychotherapy or ""talk therapy"". Common treatments include medications, surgery, medical devices, and self-care. Treatments may be provided by an organized health care system, or informally, by the patient or family members. Preventive healthcare is a way to avoid an injury, sickness, or disease in the first place. A treatment or cure is applied after a medical problem has already started. A treatment attempts to improve or remove a problem, but treatments may not produce permanent cures, especially in chronic diseases. Cures are a subset of treatments that reverse diseases completely or end medical problems permanently. Many diseases that cannot be completely cured are still treatable. Pain management (also called pain medicine) is that branch of medicine employing an interdisciplinary approach to the relief of pain and improvement in the quality of life of those living with pain.Treatment for medical emergencies must be provided promptly, often through an emergency department or, in less critical situations, through an urgent care facility.  Epidemiology  Epidemiology is the study of the factors that cause or encourage diseases. Some diseases are more common in certain geographic areas, among people with certain genetic or socioeconomic characteristics, or at different times of the year. Epidemiology is considered a cornerstone methodology of public health research and is highly regarded in evidence-based medicine for identifying risk factors for diseases. In the study of communicable and non-communicable diseases, the work of epidemiologists ranges from outbreak investigation to study design, data collection, and analysis including the development of statistical models to test hypotheses and the documentation of results for submission to peer-reviewed journals. Epidemiologists also study the interaction of diseases in a population, a condition known as a syndemic. Epidemiologists rely on a number of other scientific disciplines such as biology (to better understand disease processes), biostatistics (the current raw information available), Geographic Information Science (to store data and map disease patterns) and social science disciplines (to better understand proximate and distal risk factors). Epidemiology can help identify causes as well as guide prevention efforts. In studying diseases, epidemiology faces the challenge of defining them. Especially for poorly understood diseases, different groups might use significantly different definitions. Without an agreed-on definition, different researchers may report different numbers of cases and characteristics of the disease.Some morbidity databases are compiled with data supplied by states and territories health authorities, at national levels or larger scale (such as European Hospital Morbidity Database (HMDB)) which may contain hospital discharge data by detailed diagnosis, age and sex. The European HMDB data was submitted by European countries to the World Health Organization Regional Office for Europe.  Burdens of disease  Disease burden is the impact of a health problem in an area measured by financial cost, mortality, morbidity, or other indicators. There are several measures used to quantify the burden imposed by diseases on people. The years of potential life lost (YPLL) is a simple estimate of the number of years that a person's life was shortened due to a disease. For example, if a person dies at the age of 65 from a disease, and would probably have lived until age 80 without that disease, then that disease has caused a loss of 15 years of potential life. YPLL measurements do not account for how disabled a person is before dying, so the measurement treats a person who dies suddenly and a person who died at the same age after decades of illness as equivalent. In 2004, the World Health Organization calculated that 932 million years of potential life were lost to premature death.The quality-adjusted life year (QALY) and disability-adjusted life year (DALY) metrics are similar but take into account whether the person was healthy after diagnosis. In addition to the number of years lost due to premature death, these measurements add part of the years lost to being sick. Unlike YPLL, these measurements show the burden imposed on people who are very sick, but who live a normal lifespan. A disease that has high morbidity, but low mortality, has a high DALY and a low YPLL. In 2004, the World Health Organization calculated that 1.5 billion disability-adjusted life years were lost to disease and injury. In the developed world, heart disease and stroke cause the most loss of life, but neuropsychiatric conditions like major depressive disorder cause the most years lost to being sick.  Society and culture  How a society responds to diseases is the subject of medical sociology. A condition may be considered a disease in some cultures or eras but not in others. For example, obesity can represent wealth and abundance, and is a status symbol in famine-prone areas and some places hard-hit by HIV/AIDS. Epilepsy is considered a sign of spiritual gifts among the Hmong people.Sickness confers the social legitimization of certain benefits, such as illness benefits, work avoidance, and being looked after by others. The person who is sick takes on a social role called the sick role. A person who responds to a dreaded disease, such as cancer, in a culturally acceptable fashion may be publicly and privately honored with higher social status. In return for these benefits, the sick person is obligated to seek treatment and work to become well once more. As a comparison, consider pregnancy, which is not interpreted as a disease or sickness, even if the mother and baby may both benefit from medical care. Most religions grant exceptions from religious duties to people who are sick. For example, one whose life would be endangered by fasting on Yom Kippur or during Ramadan is exempted from the requirement, or even forbidden from participating. People who are sick are also exempted from social duties. For example, ill health is the only socially acceptable reason for an American to refuse an invitation to the White House.The identification of a condition as a disease, rather than as simply a variation of human structure or function, can have significant social or economic implications. The controversial recognition of diseases such as repetitive stress injury (RSI) and post-traumatic stress disorder (PTSD) has had a number of positive and negative effects on the financial and other responsibilities of governments, corporations, and institutions towards individuals, as well as on the individuals themselves. The social implication of viewing aging as a disease could be profound, though this classification is not yet widespread. Lepers were people who were historically shunned because they had an infectious disease, and the term ""leper"" still evokes social stigma. Fear of disease can still be a widespread social phenomenon, though not all diseases evoke extreme social stigma. Social standing and economic status affect health. Diseases of poverty are diseases that are associated with poverty and low social status; diseases of affluence are diseases that are associated with high social and economic status. Which diseases are associated with which states vary according to time, place, and technology. Some diseases, such as diabetes mellitus, may be associated with both poverty (poor food choices) and affluence (long lifespans and sedentary lifestyles), through different mechanisms. The term lifestyle diseases describes diseases associated with longevity and that are more common among older people. For example, cancer is far more common in societies in which most members live until they reach the age of 80 than in societies in which most members die before they reach the age of 50.  Language of disease  An illness narrative is a way of organizing a medical experience into a coherent story that illustrates the sick individual's personal experience. People use metaphors to make sense of their experiences with disease. The metaphors move disease from an objective thing that exists to an affective experience. The most popular metaphors draw on military concepts: Disease is an enemy that must be feared, fought, battled, and routed. The patient or the healthcare provider is a warrior, rather than a passive victim or bystander. The agents of communicable diseases are invaders; non-communicable diseases constitute internal insurrection or civil war. Because the threat is urgent, perhaps a matter of life and death, unthinkably radical, even oppressive, measures are society's and the patient's moral duty as they courageously mobilize to struggle against destruction. The War on Cancer is an example of this metaphorical use of language. This language is empowering to some patients, but leaves others feeling like they are failures.Another class of metaphors describes the experience of illness as a journey: The person travels to or from a place of disease, and changes himself, discovers new information, or increases his experience along the way. He may travel ""on the road to recovery"" or make changes to ""get on the right track"" or choose ""pathways"". Some are explicitly immigration-themed: the patient has been exiled from the home territory of health to the land of the ill, changing identity and relationships in the process. This language is more common among British healthcare professionals than the language of physical aggression.Some metaphors are disease-specific. Slavery is a common metaphor for addictions: The alcoholic is enslaved by drink, and the smoker is captive to nicotine. Some cancer patients treat the loss of their hair from chemotherapy as a metonymy or metaphor for all the losses caused by the disease.Some diseases are used as metaphors for social ills: ""Cancer"" is a common description for anything that is endemic and destructive in society, such as poverty, injustice, or racism. AIDS was seen as a divine judgment for moral decadence, and only by purging itself from the ""pollution"" of the ""invader"" could society become healthy again. More recently, when AIDS seemed less threatening, this type of emotive language was applied to avian flu and type 2 diabetes mellitus. Authors in the 19th century commonly used tuberculosis as a symbol and a metaphor for transcendence. People with the disease were portrayed in literature as having risen above daily life to become ephemeral objects of spiritual or artistic achievement. In the 20th century, after its cause was better understood, the same disease became the emblem of poverty, squalor, and other social problems.  See also   References   External links  ""Man and Disease"", BBC Radio 4 discussion with Anne Hardy, David Bradley & Chris Dye (In Our Time, 15 December 2002) CTD The Comparative Toxicogenomics Database is a scientific resource connecting chemicals, genes, and human diseases. Free online health-risk assessment by Your Disease Risk at Washington University in St Louis Health Topics A–Z, fact sheets about many common diseases at Centers for Disease Control Health Topics, MedlinePlus descriptions of most diseases, with access to current research articles. NLM Comprehensive database from the US National Library of Medicine OMIM Comprehensive information on genes that cause disease at Online Mendelian Inheritance in Man Report: The global burden of disease from World Health Organization (WHO), 2004 The Merck Manual containing detailed description of most diseases","A disease or medical condition is an unhealthy state where something bad happens to the body or mind. Diseases can cause pain, parts of the body to stop working the right way, or death. The word disease is sometimes used to include: parts of the body being hurt, not having the usual abilities, medical problems or syndromes, infections by microorganisms, feeling unhealthy, such as having pain or feeling hot (called 'symptoms'), unusual shapes of body parts.  Causes  A disease can be caused by many things. Sometimes germs enter our body through food, water or air. A person can be infected by infectious agents like bacteria, viruses or fungus. Disease can also be caused by eating bad or old foods. There are small germs in old foods that can cause diseases. Sometimes the germs produce chemicals or toxins which causes the disease. One of the most common causes of disease is poor sanitation and lack of clean water. Some deadly diseases like malaria in tropical parts of the world are spread by a mosquito. Animals that spread disease are called vectors. There are many vectors, including snails, ticks, and fleas. Some people are born with 'genetic diseases'. These are diseases because of an error or mutation in a person's DNA. An example of a mutation is cancer. Living or working in an unhealthy environment can also be a cause for diseases. Diseases are more common in older people.  Treatments  Some diseases can be helped with medicine. Infections can often be cured by antibiotics, though resistance to antibiotics is a problem. Some disease may be helped by surgery. Not every disease can be helped with medicine or surgery, though. Some diseases must be treated during the whole life; they are chronic (long-lasting) diseases. An example of a chronic disease is diabetes mellitus. Diabetes can be treated (made better) but it can not yet be cured (made to totally go away). People who usually treat diseases are called doctors or physicians.  Prevention  Some diseases that are common or very bad are tested for even in people who do not show any symptoms. If these diseases are found early they can be treated before they cause problems. An example would be checking a woman for cervical cancer with a test called a pap smear. If cervical cancer is found early it can be cured. If it is found later it usually causes death. Another example is immunization. The basic idea is to make the body ready for a disease. The body has its own defense against disease called the immune system. One special characteristic of the immune system is its ability to remember some diseases. If a person is sick and recovers, the immune system will produce a substance called antibodies which fight the disease if it comes back to the person. The antibody is specific to a particular disease or antigen. An example of this is measles which is a virus. A person (usually a child) who had never been sick with measles is given a milder form of the virus, this causes the immune system to produce antibodies against the virus. If this person is exposed to the same virus in the future, the person's immune system will remember and will fight the virus. For general prevention to be useful: The disease must be found and stopped in early stage. The disease should be common or be easy to recognize. The test for the disease should be easy, work all the time, and not hurt people. The society is well-trained and can recognize most common symptoms on some diseases. The treatment for the disease should be safe and be easy for people to get.  Epidemiology  Epidemiology is the study of the cause of disease. Some diseases are more popular for people with common characteristics, like similar origins, sociological background, food or nationality. Without good epidemiological research some diseases can be hard to track and to name. Some diseases can be taken for something else. This is why epidemiology takes a huge part in understanding how to protect ourselves against viruses, toxins and bacteria.  Related pages  Health Healthy lifestyle Viruses  References "
"A therapy or medical treatment (often abbreviated tx, Tx, or Tx) is the attempted remediation of a health problem, usually following a medical diagnosis. As a rule, each therapy has indications and contraindications. There are many different types of therapy. Not all therapies are effective. Many therapies can produce unwanted adverse effects. Medical treatment and therapy are generally considered synonyms. However, in the context of mental health, the term therapy may refer specifically to psychotherapy.  History  Before the creating of therapy as a formal procedure, people told stories to one another to inform and assist about the world. The term ""healing through words"" was used over 3,500 years ago in Greek and Egyptian writing. The term psychotherapy was invented in the 19th century, and psychoanalysis was founded by Sigmund Freud under a decade later.  Semantic field  The words care, therapy, treatment, and intervention overlap in a semantic field, and thus they can be synonymous depending on context. Moving rightward through that order, the connotative level of holism decreases and the level of specificity (to concrete instances) increases. Thus, in health care contexts (where its senses are always noncount), the word care tends to imply a broad idea of everything done to protect or improve someone's health (for example, as in the terms preventive care and primary care, which connote ongoing action), although it sometimes implies a narrower idea (for example, in the simplest cases of wound care or postanesthesia care, a few particular steps are sufficient, and the patient's interaction with that provider is soon finished). In contrast, the word intervention tends to be specific and concrete, and thus the word is often countable; for example, one instance of cardiac catheterization is one intervention performed, and coronary care (noncount) can require a series of interventions (count). At the extreme, the piling on of such countable interventions amounts to interventionism, a flawed model of care lacking holistic circumspection—merely treating discrete problems (in billable increments) rather than maintaining health. Therapy and treatment, in the middle of the semantic field, can connote either the holism of care or the discreteness of intervention, with context conveying the intent in each use. Accordingly, they can be used in both noncount and count senses (for example, therapy for chronic kidney disease can involve several dialysis treatments per week). The words aceology and iamatology are obscure and obsolete synonyms referring to the study of therapies. The English word therapy comes via Latin therapīa from Greek: θεραπεία and literally means ""curing"" or ""healing"".  Types of therapies  Therapy comes in different forms. These include, cognitive behavioral therapy, dialectical behavior therapy, mindful based cognitive therapy, physical therapy, etc. Therapists are here for use and used daily by many people. Therapist are trained to provide treatment to an individual or group. Therapy was invented in the 1800s and the founder was Franz Mesmer, the ""Father of Western Psychotherapy"". Sigmund Freud then comes into play and shows us the understanding depth of all the different types included in therapy. Therapy is used in many ways to shape and help reform a person. This type of treatment allows individuals to regain gain goals lost or wanting to accomplish. Many individuals come into therapy looking for ways to cope with issues and to receive an emotional release. For example, healing from trauma, in need of support, emotional issues, and many more. Allowing yourself to express your thoughts and feelings go a long way in therapy recovery, this is called the therapeutic process.  By chronology, priority, or intensity   Levels of care  Levels of care classify health care into categories of chronology, priority, or intensity, as follows: Emergency care handles medical emergencies and is a first point of contact or intake for less serious problems, which can be referred to other levels of care as appropriate. Intensive care, also called critical care, is care for extremely ill or injured patients. It thus requires high resource intensity, knowledge, and skill, as well as quick decision making. Ambulatory care is care provided on an outpatient basis. Typically patients can walk into and out of the clinic under their own power (hence ""ambulatory""), usually on the same day. Home care is care at home, including care from providers (such as physicians, nurses, and home health aides) making house calls, care from caregivers such as family members, and patient self-care. Primary care is meant to be the main kind of care in general, and ideally a medical home that unifies care across referred providers. Secondary care is care provided by medical specialists and other health professionals who generally do not have first contact with patients, for example, cardiologists, urologists and dermatologists. A patient reaches secondary care as a next step from primary care, typically by provider referral although sometimes by patient self-initiative. Tertiary care is specialized consultative care, usually for inpatients and on referral from a primary or secondary health professional, in a facility that has personnel and facilities for advanced medical investigation and treatment, such as a tertiary referral hospital. Follow-up care is additional care during or after convalescence. Aftercare is generally synonymous with follow-up care. End-of-life care is care near the end of one's life. It often includes the following: Palliative care is supportive care, most especially (but not necessarily) near the end of life. Hospice care is palliative care very near the end of life when cure is very unlikely. Its main goal is comfort, both physical and mental.  Lines of therapy  Treatment decisions often follow formal or informal algorithmic guidelines. Treatment options can often be ranked or prioritized into lines of therapy: first-line therapy, second-line therapy, third-line therapy, and so on. First-line therapy (sometimes referred to as induction therapy, primary therapy, or front-line therapy) is the first therapy that will be tried. Its priority over other options is usually either: (1) formally recommended on the basis of clinical trial evidence for its best-available combination of efficacy, safety, and tolerability or (2) chosen based on the clinical experience of the physician. If a first-line therapy either fails to resolve the issue or produces intolerable side effects, additional (second-line) therapies may be substituted or added to the treatment regimen, followed by third-line therapies, and so on. An example of a context in which the formalization of treatment algorithms and the ranking of lines of therapy is very extensive is chemotherapy regimens. Because of the great difficulty in successfully treating some forms of cancer, one line after another may be tried. In oncology the count of therapy lines may reach 10 or even 20. Often multiple therapies may be tried simultaneously (combination therapy or polytherapy). Thus combination chemotherapy is also called polychemotherapy, whereas chemotherapy with one agent at a time is called single-agent therapy or monotherapy. Adjuvant therapy is therapy given in addition to the primary, main, or initial treatment, but simultaneously (as opposed to second-line therapy). Neoadjuvant therapy is therapy that is begun before the main therapy. Thus one can consider surgical excision of a tumor as the first-line therapy for a certain type and stage of cancer even though radiotherapy is used before it; the radiotherapy is neoadjuvant (chronologically first but not primary in the sense of the main event). Premedication is conceptually not far from this, but the words are not interchangeable; cytotoxic drugs to put a tumor ""on the ropes"" before surgery delivers the ""knockout punch"" are called neoadjuvant chemotherapy, not premedication, whereas things like anesthetics or prophylactic antibiotics before dental surgery are called premedication. Step therapy or stepladder therapy is a specific type of prioritization by lines of therapy. It is controversial in American health care because unlike conventional decision-making about what constitutes first-line, second-line, and third-line therapy, which in the U.S. reflects safety and efficacy first and cost only according to the patient's wishes, step therapy attempts to mix cost containment by someone other than the patient (third-party payers) into the algorithm. Therapy freedom and the negotiation between individual and group rights are involved.  By intent   By therapy composition  Treatments can be classified according to the method of treatment:  By matter  by drugs: pharmacotherapy, chemotherapy (also, medical therapy often means specifically pharmacotherapy) by medical devices: implantation cardiac resynchronization therapy by specific molecules: molecular therapy (although most drugs are specific molecules, molecular medicine refers in particular to medicine relying on molecular biology) by specific biomolecular targets: targeted therapy molecular chaperone therapy by chelation: chelation therapy by specific chemical elements: by metals: by heavy metals: by gold: chrysotherapy (aurotherapy) by platinum-containing drugs: platin therapy by biometals by lithium: lithium therapy by potassium: potassium supplementation by magnesium: magnesium supplementation by chromium: chromium supplementation; phonemic neurological hypochromium therapy by copper: copper supplementation by nonmetals: by diatomic oxygen: oxygen therapy, hyperbaric oxygen therapy (hyperbaric medicine) transdermal continuous oxygen therapy by triatomic oxygen (ozone): ozone therapy by fluoride: fluoride therapy by other gases: medical gas therapy by water: hydrotherapy aquatic therapy rehydration therapy oral rehydration therapy water cure (therapy) by biological materials (biogenic substances, biomolecules, biotic materials, natural products), including their synthetic equivalents: biotherapy by whole organisms by viruses: virotherapy by bacteriophages: phage therapy by animal interaction: see animal interaction section by constituents or products of organisms by plant parts or extracts (but many drugs are derived from plants, even when the term phytotherapy is not used) scientific type: phytotherapy traditional (prescientific) type: herbalism by animal parts: quackery involving shark fins, tiger parts, and so on, often driving threat or endangerment of species by genes: gene therapy gene therapy for epilepsy gene therapy for osteoarthritis gene therapy for color blindness gene therapy of the human retina gene therapy in Parkinson's disease by epigenetics: epigenetic therapy by proteins: protein therapy (but many drugs are proteins despite not being called protein therapy) by enzymes: enzyme replacement therapy by hormones: hormone therapy hormonal therapy (oncology) hormone replacement therapy estrogen replacement therapy androgen replacement therapy hormone replacement therapy (menopause) transgender hormone therapy feminizing hormone therapy masculinizing hormone therapy antihormone therapy androgen deprivation therapy by whole cells: cell therapy (cytotherapy) by stem cells: stem cell therapy by immune cells: see immune system products below by immune system products: immunotherapy, host modulatory therapy by immune cells: T-cell vaccination cell transfer therapy autologous immune enhancement therapy TK cell therapy by humoral immune factors: antibody therapy by whole serum: serotherapy, including antiserum therapy by immunoglobulins: immunoglobulin therapy by monoclonal antibodies: monoclonal antibody therapy by urine: urine therapy (some scientific forms; many prescientific or pseudoscientific forms) by food and dietary choices: medical nutrition therapy grape therapy (quackery) by salts (but many drugs are the salts of organic acids, even when drug therapy is not called by names reflecting that) by salts in the air by natural dry salt air: ""taking the cure"" in desert locales (especially common in prescientific medicine; for example, one 19th-century way to treat tuberculosis) by artificial dry salt air: low-humidity forms of speleotherapy negative air ionization therapy by moist salt air: by natural moist salt air: seaside cure (especially common in prescientific medicine) by artificial moist salt air: water vapor forms of speleotherapy by salts in the water by mineral water: spa cure (""taking the waters"") (especially common in prescientific medicine) by seawater: seaside cure (especially common in prescientific medicine) by aroma: aromatherapy by other materials with mechanism of action unknown by occlusion with duct tape: duct tape occlusion therapy  By energy  by electric energy as electric current: electrotherapy, electroconvulsive therapy Transcranial magnetic stimulation Vagus nerve stimulation by magnetic energy: magnet therapy pulsed electromagnetic field therapy magnetic resonance therapy by electromagnetic radiation (EMR): by light: light therapy (phototherapy) ultraviolet light therapy PUVA therapy photodynamic therapy photothermal therapy cytoluminescent therapy blood irradiation therapy by darkness: dark therapy by lasers: laser therapy low level laser therapy by gamma rays: radiosurgery Gamma Knife radiosurgery stereotactic radiation therapy cobalt therapy by radiation generally: radiation therapy (radiotherapy) intraoperative radiation therapy by EMR particles: particle therapy proton therapy electron therapy intraoperative electron radiation therapy Auger therapy neutron therapy fast neutron therapy neutron capture therapy of cancer by radioisotopes emitting EMR: by nuclear medicine by brachytherapy quackery type: electromagnetic therapy (alternative medicine) by mechanical: manual therapy as massotherapy and therapy by exercise as in physical therapy inversion therapy by sound: by ultrasound: ultrasonic lithotripsy extracorporeal shockwave therapy sonodynamic therapy by music: music therapy by temperature by heat: heat therapy (thermotherapy) by moderately elevated ambient temperatures: hyperthermia therapy by dry warm surroundings: Waon therapy by dry or humid warm surroundings: sauna, including infrared sauna, for sweat therapy by cold: by extreme cold to specific tissue volumes: cryotherapy by ice and compression: cold compression therapy by ambient cold: hypothermia therapy for neonatal encephalopathy by hot and cold alternation: contrast bath therapy  By procedure and human interaction  Surgery by counseling, such as psychotherapy (see also: list of psychotherapies) systemic therapy by group psychotherapy by cognitive behavioral therapy by cognitive therapy by behaviour therapy by dialectical behavior therapy by cognitive emotional behavioral therapy by cognitive rehabilitation therapy by family therapy by education by psychoeducation by information therapy by speech therapy, physical therapy, occupational therapy, vision therapy, massage therapy, chiropractic or acupuncture by lifestyle modifications, such as avoiding unhealthy food or maintaining a predictable sleep schedule by coaching  By animal interaction  by pets, assistance animals, or working animals: animal-assisted therapy by horses: equine therapy, hippotherapy by dogs: pet therapy with therapy dogs, including grief therapy dogs by cats: pet therapy with therapy cats by fish: ichthyotherapy (wading with fish), aquarium therapy (watching fish) by maggots: maggot therapy by worms: by internal worms: helminthic therapy by leeches: leech therapy by immersion: animal bath  By meditation  by mindfulness: mindfulness-based cognitive therapy  By reading  by bibliotherapy  By creativity  by expression: expressive therapy by writing: writing therapy journal therapy by play: play therapy by art: art therapy sensory art therapy comic book therapy by gardening: horticultural therapy by dance: dance therapy by drama: drama therapy by recreation: recreational therapy by music: music therapy  By sleeping and waking  by deep sleep: deep sleep therapy by sleep deprivation: wake therapy  See also  Biophilia hypothesis Classification of Pharmaco-Therapeutic Referrals Cure Interventionism (medicine) Inverse benefit law List of therapies Greyhound therapy Mature minor doctrine Medicine Medication Nutraceutical Prevention Psychotherapy Treatment as prevention Therapeutic inertia Therapeutic nihilism, the idea that treatment is useless  References   External links  Media related to Therapies at Wikimedia Commons The dictionary definition of therapy at Wiktionary ""Chapter Nine of the Book of Medicine Dedicated to Mansur, with the Commentary of Sillanus de Nigris"" is a Latin book by Rhazes, from 1483, that is known for its ninth chapter, which is about therapeutics Benefits of Online family therapy","Therapy, in the medical field also called treatment, is what people do to try to solve or care for a health problem, physical or mental. When a person is ill or injured, a doctor may make a medical diagnosis and then recommend a therapy to try to make the person well. The therapy can be, for example, medications (drugs), surgery or a change of diet. Therapy may be offered at work to help people with stress.A person who does therapy as a job is called a therapist. There are many kinds of therapists. for example: Group therapist Hypnotherapist Occupational therapist Physiotherapist Psychotherapist Speech therapist  Therapeutic effects  Medical treatments may have four results: No effect at all. A therapeutic effect is a good result. An adverse effect is a bad result. A side-effect is an unwanted effect from therapy. For example, taking medications as tablets or injections may cause many sorts of side-effects. Examples are headaches, nausea, rash, constipation, blurred vision and others. Radiotherapy can also cause side effects of nausea, rash on the skin, and vomiting, for example.  Related pages  Chemotherapy Pharmacotheraphy Radiotherapy  References   Other websites  ""Chapter Nine of the Book of Medicine Dedicated to Mansur, with the Commentary of Sillanus de Nigris"" is an old book written in Latin. It was written in 1483. It has parts about therapy in it."
"Medical diagnosis (abbreviated Dx, Dx, or Ds) is the process of determining which disease or condition explains a person's symptoms and signs. It is most often referred to as diagnosis with the medical context being implicit. The information required for diagnosis is typically collected from a history and physical examination of the person seeking medical care. Often, one or more diagnostic procedures, such as medical tests, are also done during the process. Sometimes posthumous diagnosis is considered a kind of medical diagnosis. Diagnosis is often challenging because many signs and symptoms are nonspecific. For example, redness of the skin (erythema), by itself, is a sign of many disorders and thus does not tell the healthcare professional what is wrong. Thus differential diagnosis, in which several possible explanations are compared and contrasted, must be performed. This involves the correlation of various pieces of information followed by the recognition and differentiation of patterns. Occasionally the process is made easy by a sign or symptom (or a group of several) that is pathognomonic. Diagnosis is a major component of the procedure of a doctor's visit. From the point of view of statistics, the diagnostic procedure involves classification tests.  Medical uses  A diagnosis, in the sense of diagnostic procedure, can be regarded as an attempt at classification of an individual's condition into separate and distinct categories that allow medical decisions about treatment and prognosis to be made. Subsequently, a diagnostic opinion is often described in terms of a disease or other condition. (In the case of a wrong diagnosis, however, the individual's actual disease or condition is not the same as the individual's diagnosis.) A diagnostic procedure may be performed by various healthcare professionals such as a physician, physiotherapist, dentist, podiatrist, optometrist, nurse practitioner, healthcare scientist or physician assistant. This article uses diagnostician as any of these person categories. A diagnostic procedure (as well as the opinion reached thereby) does not necessarily involve elucidation of the etiology of the diseases or conditions of interest, that is, what caused the disease or condition. Such elucidation can be useful to optimize treatment, further specify the prognosis or prevent recurrence of the disease or condition in the future. The initial task is to detect a medical indication to perform a diagnostic procedure. Indications include: Detection of any deviation from what is known to be normal, such as can be described in terms of, for example, anatomy (the structure of the human body), physiology (how the body works), pathology (what can go wrong with the anatomy and physiology), psychology (thought and behavior) and human homeostasis (regarding mechanisms to keep body systems in balance). Knowledge of what is normal and measuring of the patient's current condition against those norms can assist in determining the patient's particular departure from homeostasis and the degree of departure, which in turn can assist in quantifying the indication for further diagnostic processing. A complaint expressed by a patient. The fact that a patient has sought a diagnostician can itself be an indication to perform a diagnostic procedure. For example, in a doctor's visit, the physician may already start performing a diagnostic procedure by watching the gait of the patient from the waiting room to the doctor's office even before she or he has started to present any complaints.Even during an already ongoing diagnostic procedure, there can be an indication to perform another, separate, diagnostic procedure for another, potentially concomitant, disease or condition. This may occur as a result of an incidental finding of a sign unrelated to the parameter of interest, such as can occur in comprehensive tests such as radiological studies like magnetic resonance imaging or blood test panels that also include blood tests that are not relevant for the ongoing diagnosis.  Procedure  General components which are present in a diagnostic procedure in most of the various available methods include: Complementing the already given information with further data gathering, which may include questions of the medical history (potentially from other people close to the patient as well), physical examination and various diagnostic tests. A diagnostic test is any kind of medical test performed to aid in the diagnosis or detection of disease. Diagnostic tests can also be used to provide prognostic information on people with established disease. Processing of the answers, findings or other results. Consultations with other providers and specialists in the field may be sought.There are a number of methods or techniques that can be used in a diagnostic procedure, including performing a differential diagnosis or following medical algorithms.: 198 In reality, a diagnostic procedure may involve components of multiple methods.: 204  Differential diagnosis  The method of differential diagnosis is based on finding as many candidate diseases or conditions as possible that can possibly cause the signs or symptoms, followed by a process of elimination or at least of rendering the entries more or less probable by further medical tests and other processing, aiming to reach the point where only one candidate disease or condition remains as probable. The result may also remain a list of possible conditions, ranked in order of probability or severity. Such a list is often generated by computer-aided diagnosis systems.The resultant diagnostic opinion by this method can be regarded more or less as a diagnosis of exclusion. Even if it does not result in a single probable disease or condition, it can at least rule out any imminently life-threatening conditions. Unless the provider is certain of the condition present, further medical tests, such as medical imaging, are performed or scheduled in part to confirm or disprove the diagnosis but also to document the patient's status and keep the patient's medical history up to date. If unexpected findings are made during this process, the initial hypothesis may be ruled out and the provider must then consider other hypotheses.  Pattern recognition  In a pattern recognition method the provider uses experience to recognize a pattern of clinical characteristics.: 198, It is mainly based on certain symptoms or signs being associated with certain diseases or conditions, not necessarily involving the more cognitive processing involved in a differential diagnosis. This may be the primary method used in cases where diseases are ""obvious"", or the provider's experience may enable him or her to recognize the condition quickly. Theoretically, a certain pattern of signs or symptoms can be directly associated with a certain therapy, even without a definite decision regarding what is the actual disease, but such a compromise carries a substantial risk of missing a diagnosis which actually has a different therapy so it may be limited to cases where no diagnosis can be made.  Diagnostic criteria  The term diagnostic criteria designates the specific combination of signs and symptoms, and test results that the clinician uses to attempt to determine the correct diagnosis. Some examples of diagnostic criteria, also known as clinical case definitions, are: Amsterdam criteria for hereditary nonpolyposis colorectal cancer McDonald criteria for multiple sclerosis ACR criteria for systemic lupus erythematosus Centor criteria for strep throat  Clinical decision support system  Clinical decision support systems are interactive computer programs designed to assist health professionals with decision-making tasks. The clinician interacts with the software utilizing both the clinician's knowledge and the software to make a better analysis of the patients data than either human or software could make on their own. Typically the system makes suggestions for the clinician to look through and the clinician picks useful information and removes erroneous suggestions. Some programs attempt to do this by replacing the clinician, such as reading the output of a heart monitor. Such automated processes are usually deemed a ""device"" by the FDA and require regulatory approval. In contrast, clinical decision support systems that ""support"" but do not replace the clinician are deemed to be ""Augmented Intelligence"" if it meets the FDA criteria that (1) it reveals the underlying data, (2) reveals the underlying logic, and (3) leaves the clinician in charge to shape and make the decision.  Other diagnostic procedure methods  Other methods that can be used in performing a diagnostic procedure include: Usage of medical algorithms An ""exhaustive method"", in which every possible question is asked and all possible data is collected.: 198  Adverse effects  Diagnosis problems are the dominant cause of medical malpractice payments, accounting for 35% of total payments in a study of 25 years of data and 350,000 claims.  Overdiagnosis  Overdiagnosis is the diagnosis of ""disease"" that will never cause symptoms or death during a patient's lifetime. It is a problem because it turns people into patients unnecessarily and because it can lead to economic waste (overutilization) and treatments that may cause harm. Overdiagnosis occurs when a disease is diagnosed correctly, but the diagnosis is irrelevant. A correct diagnosis may be irrelevant because treatment for the disease is not available, not needed, or not wanted.  Errors  Most people will experience at least one diagnostic error in their lifetime, according to a 2015 report by the National Academies of Sciences, Engineering, and Medicine.Causes and factors of error in diagnosis are: the manifestation of disease are not sufficiently noticeable a disease is omitted from consideration too much significance is given to some aspect of the diagnosis the condition is a rare disease with symptoms suggestive of many other conditions the condition has a rare presentation  Lag time  When making a medical diagnosis, a lag time is a delay in time until a step towards diagnosis of a disease or condition is made. Types of lag times are mainly: Onset-to-medical encounter lag time, the time from onset of symptoms until visiting a health care provider Encounter-to-diagnosis lag time, the time from first medical encounter to diagnosisLag time due to delays in reading x-rays have been cited as a major challenge in care delivery. The Department of Health and Human Services has reportedly found that interpretation of x-rays is rarely available to emergency room physicians prior to patient discharge.Long lag times are often called ""diagnostic odyssey"".  History  The first recorded examples of medical diagnosis are found in the writings of Imhotep (2630–2611 BC) in ancient Egypt (the Edwin Smith Papyrus). A Babylonian medical textbook, the Diagnostic Handbook written by Esagil-kin-apli (fl.1069–1046 BC), introduced the use of empiricism, logic and rationality in the diagnosis of an illness or disease. Traditional Chinese Medicine, as described in the Yellow Emperor's Inner Canon or Huangdi Neijing, specified four diagnostic methods: inspection, auscultation-olfaction, interrogation, and palpation. Hippocrates was known to make diagnoses by tasting his patients' urine and smelling their sweat.  Word  Medical diagnosis or the actual process of making a diagnosis is a cognitive process. A clinician uses several sources of data and puts the pieces of the puzzle together to make a diagnostic impression. The initial diagnostic impression can be a broad term describing a category of diseases instead of a specific disease or condition. After the initial diagnostic impression, the clinician obtains follow up tests and procedures to get more data to support or reject the original diagnosis and will attempt to narrow it down to a more specific level. Diagnostic procedures are the specific tools that the clinicians use to narrow the diagnostic possibilities. The plural of diagnosis is diagnoses. The verb is to diagnose, and a person who diagnoses is called a diagnostician.  Etymology  The word diagnosis is derived through Latin from the Greek word διάγνωσις (diágnōsis) from διαγιγνώσκειν (diagignṓskein), meaning ""to discern, distinguish"".  Society and culture   Social context  Diagnosis can take many forms. It might be a matter of naming the disease, lesion, dysfunction or disability. It might be a management-naming or prognosis-naming exercise. It may indicate either degree of abnormality on a continuum or kind of abnormality in a classification. It is influenced by non-medical factors such as power, ethics and financial incentives for patient or doctor. It can be a brief summation or an extensive formulation, even taking the form of a story or metaphor. It might be a means of communication such as a computer code through which it triggers payment, prescription, notification, information or advice. It might be pathogenic or salutogenic. It is generally uncertain and provisional. Once a diagnostic opinion has been reached, the provider is able to propose a management plan, which will include treatment as well as plans for follow-up. From this point on, in addition to treating the patient's condition, the provider can educate the patient about the etiology, progression, prognosis, other outcomes, and possible treatments of her or his ailments, as well as providing advice for maintaining health. A treatment plan is proposed which may include therapy and follow-up consultations and tests to monitor the condition and the progress of the treatment, if needed, usually according to the medical guidelines provided by the medical field on the treatment of the particular illness. Relevant information should be added to the medical record of the patient. A failure to respond to treatments that would normally work may indicate a need for review of the diagnosis. Nancy McWilliams identifies five reasons that determine the necessity for diagnosis: diagnosis for treatment planning; information contained in it related to prognosis; protecting interests of patients; a diagnosis might help the therapist to empathize with his patient; might reduce the likelihood that some fearful patients will go-by the treatment.  Types  Sub-types of diagnoses include: Clinical diagnosis A diagnosis made on the basis of medical signs and reported symptoms, rather than diagnostic tests Laboratory diagnosis A diagnosis based significantly on laboratory reports or test results, rather than the physical examination of the patient. For instance, a proper diagnosis of infectious diseases usually requires both an examination of signs and symptoms, as well as laboratory test results and characteristics of the pathogen involved. Radiology diagnosis A diagnosis based primarily on the results from medical imaging studies. Greenstick fractures are common radiological diagnoses. Electrography diagnosis A diagnosis based on measurement and recording of electrophysiologic activity. Tissue diagnosis A diagnosis based on the macroscopic, microscopic, and molecular examination of tissues such as biopsies or whole organs. For example, a definitive diagnosis of cancer is made via tissue examination by a pathologist. Principal diagnosis The single medical diagnosis that is most relevant to the patient's chief complaint or need for treatment. Many patients have additional diagnoses. Admitting diagnosis The diagnosis given as the reason why the patient was admitted to the hospital; it may differ from the actual problem or from the discharge diagnoses, which are the diagnoses recorded when the patient is discharged from the hospital. Differential diagnosis A process of identifying all of the possible diagnoses that could be connected to the signs, symptoms, and lab findings, and then ruling out diagnoses until a final determination can be made. Diagnostic criteria Designates the combination of signs, symptoms, and test results that the clinician uses to attempt to determine the correct diagnosis. They are standards, normally published by international committees, and they are designed to offer the best sensitivity and specificity possible, respect the presence of a condition, with the state-of-the-art technology. Prenatal diagnosis Diagnosis work done before birth Diagnosis of exclusion A medical condition whose presence cannot be established with complete confidence from history, examination or testing. Diagnosis is therefore by elimination of all other reasonable possibilities. Dual diagnosis The diagnosis of two related, but separate, medical conditions or comorbidities. The term almost always referred to a diagnosis of a serious mental illness and a substance use disorder, however, the increasing prevalence of genetic testing has revealed many cases of patients with multiple concomitant genetic disorders. Self-diagnosis The diagnosis or identification of a medical conditions in oneself. Self-diagnosis is very common. Remote diagnosis A type of telemedicine that diagnoses a patient without being physically in the same room as the patient. Nursing diagnosis Rather than focusing on biological processes, a nursing diagnosis identifies people's responses to situations in their lives, such as a readiness to change or a willingness to accept assistance. Computer-aided diagnosis Providing symptoms allows the computer to identify the problem and diagnose the user to the best of its ability. Health screening begins by identifying the part of the body where the symptoms are located; the computer cross-references a database for the corresponding disease and presents a diagnosis. Overdiagnosis The diagnosis of ""disease"" that will never cause symptoms, distress, or death during a patient's lifetime Wastebasket diagnosis A vague, or even completely fake, medical or psychiatric label given to the patient or to the medical records department for essentially non-medical reasons, such as to reassure the patient by providing an official-sounding label, to make the provider look effective, or to obtain approval for treatment. This term is also used as a derogatory label for disputed, poorly described, overused, or questionably classified diagnoses, such as pouchitis and senility, or to dismiss diagnoses that amount to overmedicalization, such as the labeling of normal responses to physical hunger as reactive hypoglycemia. Retrospective diagnosis The labeling of an illness in a historical figure or specific historical event using modern knowledge, methods and disease classifications.  See also   Lists  List of diagnostic classification and rating scales used in psychiatry List of diseases List of disorders List of medical symptoms Category:Diseases  References   External links  Media related to Medical diagnosis at Wikimedia Commons","A medical diagnosis (an. Greek δια-γνωστικος — able to recognize) is when a doctor finds out what is making someone sick. Sometimes doctors can diagnose a sickness by asking the person questions and looking at the person's body. Sometimes doctors do tests. Tests can mean taking a small bit of blood, urine, or tissue which is sent to a hospital laboratory where it is tested. X-rays are another form of test. Tests are ways to see how the body is working. When a diagnosis has been made, the doctor may recommend treatment.  Process  The process of diagnosis begins from the very beginning of the patient's examination in a medical institution or during a call to the doctor at the patient's place of residence. Diagnosis of the disease begins with the collection of medical history. After collecting the anamnesis, the doctor examines the patient, during which he performs percussion and auscultation of the patient, palpation of the disease, measures the patient's blood pressure, heart rate and respiration rate, and measures the patient's body temperature. Laboratory examination methods include general clinical tests, which include a general blood test, a general urine test, and a stool test. Laboratory methods of examination also include biochemical methods of examination, during which the level of glucose, creatinine, urea, bilirubin, liver enzymes, blood lipids is determined; coagulogram, which analyzes the indicators of blood clotting; blood hormone tests; determination of tumor markers; tests of blood and other biological materials for infectious diseases; allergological, toxicological, cytological and parasitological examinations. Instrumental methods of examination include X-ray, endoscopic, ultrasound, methods of recording the electrical activity of organs (including ECG and EEG) and a number of other methods of examination. To diagnose disorders of some systems and organs, methods of recording the electrical activity of organs are used, which include, in particular, ECG and EEG.  References "
"A cough is a sudden expulsion of air through the large breathing passages which can help clear them of fluids, irritants, foreign particles and microbes. As a protective reflex, coughing can be repetitive with the cough reflex following three phases: an inhalation, a forced exhalation against a closed glottis, and a violent release of air from the lungs following opening of the glottis, usually accompanied by a distinctive sound.Frequent coughing usually indicates the presence of a disease. Many viruses and bacteria benefit, from an evolutionary perspective, by causing the host to cough, which helps to spread the disease to new hosts. Most of the time, irregular coughing is caused by a respiratory tract infection but can also be triggered by choking, smoking, air pollution, asthma, gastroesophageal reflux disease, post-nasal drip, chronic bronchitis, lung tumors, heart failure and medications such as angiotensin-converting-enzyme inhibitors (ACE inhibitors) and beta blockers.Treatment should target the cause; for example, smoking cessation or discontinuing ACE inhibitors. Cough suppressants such as codeine or dextromethorphan are frequently prescribed, but have been demonstrated to have little effect. Other treatment options may target airway inflammation or may promote mucus expectoration. As it is a natural protective reflex, suppressing the cough reflex might have damaging effects, especially if the cough is productive.  Presentation   Complications  The complications of coughing can be classified as either acute or chronic. Acute complications include cough syncope (fainting spells due to decreased blood flow to the brain when coughs are prolonged and forceful), insomnia, cough-induced vomiting, subconjunctival hemorrhage or ""red eye"", coughing defecation and in women with a prolapsed uterus, cough urination. Chronic complications are common and include abdominal or pelvic hernias, fatigue fractures of lower ribs and costochondritis. Chronic or violent coughing can contribute to damage to the pelvic floor and a possible cystocele.  Differential diagnosis  A cough in children may be either a normal physiological reflex or due to an underlying cause. In healthy children it may be normal in the absence of any disease to cough ten times a day. The most common cause of an acute or subacute cough is a viral respiratory tract infection. A healthy adult also coughs 18.8 times a day on average, but in the population with respiratory disease the geometric mean frequency is 275 times a day. In adults with a chronic cough, i.e. a cough longer than 8 weeks, more than 90% of cases are due to post-nasal drip, asthma, eosinophilic bronchitis, and gastroesophageal reflux disease. The causes of chronic cough are similar in children with the addition of bacterial bronchitis.  Infections  A cough can be the result of a respiratory tract infection such as the common cold, COVID-19, acute bronchitis, pneumonia, pertussis, or tuberculosis. In the vast majority of cases, acute coughs, i.e. coughs shorter than 3 weeks, are due to the common cold. In people with a normal chest X-ray, tuberculosis is a rare finding. Pertussis is increasingly being recognised as a cause of troublesome coughing in adults. After a respiratory tract infection has cleared, the person may be left with a postinfectious cough. This typically is a dry, non-productive cough that produces no phlegm. Symptoms may include a tightness in the chest, and a tickle in the throat. This cough may often persist for weeks after an illness. The cause of the cough may be inflammation similar to that observed in repetitive stress disorders such as carpal tunnel syndrome. The repetition of coughing produces inflammation which produces discomfort, which in turn produces more coughing. Postinfectious cough typically does not respond to conventional cough treatments. Medication used for postinfectious coughs may include ipratropium to treat the inflammation, as well as cough suppressants to reduce frequency of the cough until inflammation clears. Inflammation may increase sensitivity to other existing issues such as allergies, and treatment of other causes of coughs (such as use of an air purifier or allergy medicines) may help speed recovery.  Reactive airway disease  When coughing is the only complaint of a person who meets the criteria for asthma (bronchial hyperresponsiveness and reversibility), this is termed cough-variant asthma. Atopic cough and eosinophilic bronchitis are related conditions. Atopic cough occurs in individuals with a family history of atopy (an allergic condition), abundant eosinophils in the sputum, but with normal airway function and responsiveness. Eosinophilic bronchitis is characterized by eosinophils in sputum and in bronchoalveolar lavage fluid without airway hyperresponsiveness or an atopic background. This condition responds to treatment with corticosteroids. Cough can also worsen in an acute exacerbation of chronic obstructive pulmonary disease. Asthma is a common cause of chronic cough in adults and children. Coughing may be the only symptom the person has from their asthma, or asthma symptoms may also include wheezing, shortness of breath, and a tight feeling in their chest. Depending on how severe the asthma is, it can be treated with bronchodilators (medicine which causes the airways to open up) or inhaled steroids. Treatment of the asthma should make the cough go away. Chronic bronchitis is defined clinically as a persistent cough that produces sputum (phlegm) and mucus, for at least three months in two consecutive years. Chronic bronchitis is often the cause of ""smoker's cough"". The tobacco smoke causes inflammation, secretion of mucus into the airway, and difficulty clearing that mucus out of the airways. Coughing helps clear those secretions out. May be treated by quitting smoking. May also be caused by pneumoconiosis and long-term fume inhalation.  Gastroesophageal reflux  In people with unexplained cough, gastroesophageal reflux disease should be considered. This occurs when acidic contents of the stomach come back up into the esophagus. Symptoms usually associated with GERD include heartburn, sour taste in the mouth, or a feeling of acid reflux in the chest, although, more than half of the people with cough from GERD do not have any other symptoms. An esophageal pH monitor can confirm the diagnosis of GERD. Sometimes GERD can complicate respiratory ailments related to cough, such as asthma or bronchitis. The treatment involves anti-acid medications and lifestyle changes with surgery indicated in cases not manageable with conservative measures.  Air pollution  Coughing may be caused by air pollution including tobacco smoke, particulate matter, irritant gases, and dampness in a home. The human health effects of poor air quality are far reaching, but principally affect the body's respiratory system and the cardiovascular system. Individual reactions to air pollutants depend on the type of pollutant a person is exposed to, the degree of exposure, the individual's health status and genetics. People who exercise outdoors on hot, smoggy days, for example, increase their exposure to pollutants in the air.  Foreign body  A foreign body can sometimes be suspected, for example if the cough started suddenly when the patient was eating. Rarely, sutures left behind inside the airway branches can cause coughing. A cough can be triggered by dryness from mouth breathing or recurrent aspiration of food into the windpipe in people with swallowing difficulties.  Drug-induced cough  Drugs used for treatments other than coughs, such as ACE inhibitors which are often used to treat high blood pressure, can sometimes cause cough as a side effect, and stopping their use will stop the cough. Beta blockers similarly cause cough as an adverse event.  Tic cough  A tic cough, previously called a habit cough, is one that responds to behavioral or psychiatric therapy after organic causes have been excluded. Absence of the cough during sleep is common, but not diagnostic. A tic cough is thought to be more common in children than in adults. A similar disorder is the somatic cough syndrome previously called the psychogenic cough.  Neurogenic cough  Some cases of chronic cough may be attributed to a sensory neuropathic disorder. Treatment for neurogenic cough may include the use of certain neuralgia medications. Coughing may occur in tic disorders such as Tourette syndrome, although it should be distinguished from throat-clearing in this disorder.  Other  Cough may also be caused by conditions affecting the lung tissue such as bronchiectasis, cystic fibrosis, interstitial lung diseases and sarcoidosis. Coughing can also be triggered by benign or malignant lung tumors or mediastinal masses. Through irritation of the nerve, diseases of the external auditory canal (wax, for example) can also cause cough. Cardiovascular diseases associated with cough are heart failure, pulmonary infarction and aortic aneurysm. Nocturnal cough is associated with heart failure, as the heart does not compensate for the increased volume shift to the pulmonary circulation, in turn causing pulmonary edema and resultant cough. Other causes of nocturnal cough include asthma, post-nasal drip and gastroesophageal reflux disease (GERD). Another cause of cough occurring preferentially in supine position is recurrent aspiration.Given its irritant nature to mammal tissues, capsaicin is widely used to determine the cough threshold and as a tussive stimulant in clinical research of cough suppressants. Capsaicin is what makes chili peppers spicy, and might explain why workers in factories with these fruits can develop a cough. Coughing may also be used for social reasons, and as such is not always involuntary. A voluntary cough, often written as ""ahem"", can be used to attract attention or express displeasure, as a form of nonverbal, paralingual metacommunication.  Airway clearance  Coughing, and huffing are important ways of removing mucus as sputum in many conditions such as cystic fibrosis, and chronic bronchitis.  Pathophysiology  A cough is a protective reflex in healthy individuals which is influenced by psychological factors. The cough reflex is initiated by stimulation of two different classes of afferent nerves, namely the myelinated rapidly adapting receptors, and nonmyelinated C-fibers with endings in the lung.  Diagnostic approach  The type of cough may help in the diagnosis. For instance, an inspiratory ""whooping"" sound on coughing almost doubles the likelihood that the illness is pertussis. Blood may occur in small amounts with severe cough of many causes, but larger amounts suggests bronchitis, bronchiectasis, tuberculosis, or primary lung cancer.Further workup may include labs, x-rays, and spirometry.  Classification  A cough can be classified by its duration, character, quality, and timing. The duration can be either acute (of sudden onset) if it is present less than three weeks, subacute if it is present between three or eight weeks, and chronic when lasting longer than eight weeks. A cough can be non-productive (dry) or productive (when phlegm is produced that may be coughed up as sputum). It may occur only at night (then called nocturnal cough), during both night and day, or just during the day.A number of characteristic coughs exist. While these have not been found to be diagnostically useful in adults, they are of use in children. A barky cough is part of the common presentation of croup. A staccato cough has been classically described with neonatal chlamydial pneumonia.  Treatment  The treatment of a cough in children is based on the underlying cause. In children half of cases go away without treatment in 10 days and 90% in 25 days.According to the American Academy of Pediatrics the use of cough medicine to relieve cough symptoms is supported by little evidence and thus not recommended for treating cough symptoms in children. There is tentative evidence that the use of honey is better than no treatment or diphenhydramine in decreasing coughing. It does not alleviate coughing to the same extent as dextromethorphan but it shortens the cough duration better than placebo and salbutamol. A trial of antibiotics or inhaled corticosteroids may be tried in children with a chronic cough in an attempt to treat protracted bacterial bronchitis or asthma respectively. There is insufficient evidence to recommend treating children who have a cough that is not related to a specific condition with inhaled anti-cholinergics.Because coughing can spread disease through infectious aerosol droplets, it is recommended to cover one's mouth and nose with the forearm, the inside of the elbow, a tissue or a handkerchief while coughing.  Epidemiology  A cough is the most common reason for visiting a primary care physician in the United States.  Other animals  Marine mammals such as dolphins and whales cannot cough. Some invertebrates such as insects and spiders cannot cough or sneeze. Domestic animals and vertebrates such as dogs and cats can cough, because of diseases, allergies, dust or choking. In particular, cats are known for coughing before spitting up a hairball.In other domestic animals, horses can cough because of infections, or due to poor ventilation and dust in enclosed spaces. Kennel cough in dogs can result from a viral or bacterial infection. Deer can cough similarly to humans as a result of respiratory tract infections, such as parasitic bronchitis caused by a species of Dictyocaulus.  References  As of this edit, this article uses content from ""Acute cough: a diagnostic and therapeutic challenge"", which is licensed in a way that permits reuse under the Creative Commons Attribution-ShareAlike 3.0 Unported License, but not under the GFDL. All relevant terms must be followed.  Further reading  Carroll, Thomas L., ed. (2019). Chronic Cough. Plural Publishing. ISBN 9781635500707. LCCN 2018055141.  External links ","A cough, also known as tussis, is an action the body takes to get rid of anything that irritates the lungs or throat. To do this, muscles in the thoracic cavity contract to make air leave the lungs with a lot of force. Coughs often happen quickly and more than once, and are usually accompanied by a unique sound, also called a cough. Coughs are more likely to happen when a person is sick, because infections often irritate breathing passages. Another cause of coughs is a person breathing air that is not clean, like air with dust or smoke.  Causes  Lung cancer Influenza Sarcoidosis Pneumonia Tuberculosis Common cold Smoking  Related pages  Flu  References "
"A virus is a submicroscopic infectious agent that replicates only inside the living cells of an organism. Viruses infect all life forms, from animals and plants to microorganisms, including bacteria and archaea. Since Dmitri Ivanovsky\'s 1892 article describing a non-bacterial pathogen infecting tobacco plants and the discovery of the tobacco mosaic virus by Martinus Beijerinck in 1898, more than 11,000 of the millions of virus species have been described in detail. Viruses are found in almost every ecosystem on Earth and are the most numerous type of biological entity. The study of viruses is known as virology, a subspeciality of microbiology. When infected, a host cell is often forced to rapidly produce thousands of copies of the original virus. When not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent viral particles, or virions, consisting of (i) the genetic material, i.e., long molecules of DNA or RNA that encode the structure of the proteins by which the virus acts; (ii) a protein coat, the capsid, which surrounds and protects the genetic material; and in some cases (iii) an outside envelope of lipids. The shapes of these virus particles range from simple helical and icosahedral forms to more complex structures. Most virus species have virions too small to be seen with an optical microscope and are one-hundredth the size of most bacteria. The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity in a way analogous to sexual reproduction. Viruses are considered by some biologists to be a life form, because they carry genetic material, reproduce, and evolve through natural selection, although they lack the key characteristics, such as cell structure, that are generally considered necessary criteria for defining life. Because they possess some but not all such qualities, viruses have been described as ""organisms at the edge of life"" and as replicators.Viruses spread in many ways. One transmission pathway is through disease-bearing organisms known as vectors: for example, viruses are often transmitted from plant to plant by insects that feed on plant sap, such as aphids; and viruses in animals can be carried by blood-sucking insects. Many viruses, including influenza viruses, SARS-CoV-2, chickenpox, smallpox, and measles, spread in the air by coughing and sneezing. Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal–oral route, passed by hand-to-mouth contact or in food or water. The infectious dose of norovirus required to produce infection in humans is fewer than 100 particles. HIV is one of several viruses transmitted through sexual contact and by exposure to infected blood. The variety of host cells that a virus can infect is called its host range. This can be narrow, meaning a virus is capable of infecting few species, or broad, meaning it is capable of infecting many.Viral infections in animals provoke an immune response that usually eliminates the infecting virus. Immune responses can also be produced by vaccines, which confer an artificially acquired immunity to the specific viral infection. Some viruses, including those that cause HIV/AIDS, HPV infection, and viral hepatitis, evade these immune responses and result in chronic infections. Several classes of antiviral drugs have been developed.  Etymology  The word is from the Latin neuter vīrus referring to poison and other noxious liquids, from the same Indo-European base as Sanskrit viṣa, Avestan vīša, and ancient Greek ἰός (all meaning \'poison\'), first attested in English in 1398 in John Trevisa\'s translation of Bartholomeus Anglicus\'s De Proprietatibus Rerum. Virulent, from Latin virulentus (\'poisonous\'), dates to c. 1400. A meaning of \'agent that causes infectious disease\' is first recorded in 1728, long before the discovery of viruses by Dmitri Ivanovsky in 1892. The English plural is viruses (sometimes also vira), whereas the Latin word is a mass noun, which has no classically attested plural (vīra is used in Neo-Latin). The adjective viral dates to 1948. The term virion (plural virions), which dates from 1959, is also used to refer to a single viral particle that is released from the cell and is capable of infecting other cells of the same type.  Origins  Viruses are found wherever there is life and have probably existed since living cells first evolved. The origin of viruses is unclear because they do not form fossils, so molecular techniques are used to investigate how they arose. In addition, viral genetic material occasionally integrates into the germline of the host organisms, by which they can be passed on vertically to the offspring of the host for many generations. This provides an invaluable source of information for paleovirologists to trace back ancient viruses that have existed up to millions of years ago. There are three main hypotheses that aim to explain the origins of viruses: Regressive hypothesis Viruses may have once been small cells that parasitised larger cells. Over time, genes not required by their parasitism were lost. The bacteria rickettsia and chlamydia are living cells that, like viruses, can reproduce only inside host cells. They lend support to this hypothesis, as their dependence on parasitism is likely to have caused the loss of genes that enabled them to survive outside a cell. This is also called the \'degeneracy hypothesis\', or \'reduction hypothesis\'. Cellular origin hypothesis Some viruses may have evolved from bits of DNA or RNA that ""escaped"" from the genes of a larger organism. The escaped DNA could have come from plasmids (pieces of naked DNA that can move between cells) or transposons (molecules of DNA that replicate and move around to different positions within the genes of the cell). Once called jumping genes, transposons are examples of mobile genetic elements and could be the origin of some viruses. They were discovered in maize by Barbara McClintock in 1950. This is sometimes called the \'vagrancy hypothesis\', or the \'escape hypothesis\'. Co-evolution hypothesis This is also called the \'virus-first hypothesis\' and proposes that viruses may have evolved from complex molecules of protein and nucleic acid at the same time that cells first appeared on Earth and would have been dependent on cellular life for billions of years. Viroids are molecules of RNA that are not classified as viruses because they lack a protein coat. They have characteristics that are common to several viruses and are often called subviral agents. Viroids are important pathogens of plants. They do not code for proteins but interact with the host cell and use the host machinery for their replication. The hepatitis delta virus of humans has an RNA genome similar to viroids but has a protein coat derived from hepatitis B virus and cannot produce one of its own. It is, therefore, a defective virus. Although hepatitis delta virus genome may replicate independently once inside a host cell, it requires the help of hepatitis B virus to provide a protein coat so that it can be transmitted to new cells. In similar manner, the sputnik virophage is dependent on mimivirus, which infects the protozoan Acanthamoeba castellanii. These viruses, which are dependent on the presence of other virus species in the host cell, are called \'satellites\' and may represent evolutionary intermediates of viroids and viruses.In the past, there were problems with all of these hypotheses: the regressive hypothesis did not explain why even the smallest of cellular parasites do not resemble viruses in any way. The escape hypothesis did not explain the complex capsids and other structures on virus particles. The virus-first hypothesis contravened the definition of viruses in that they require host cells. Viruses are now recognised as ancient and as having origins that pre-date the divergence of life into the three domains. This discovery has led modern virologists to reconsider and re-evaluate these three classical hypotheses.The evidence for an ancestral world of RNA cells and computer analysis of viral and host DNA sequences are giving a better understanding of the evolutionary relationships between different viruses and may help identify the ancestors of modern viruses. To date, such analyses have not proved which of these hypotheses is correct. It seems unlikely that all currently known viruses have a common ancestor, and viruses have probably arisen numerous times in the past by one or more mechanisms.  Microbiology   Life properties  Scientific opinions differ on whether viruses are a form of life or organic structures that interact with living organisms. They have been described as ""organisms at the edge of life"", since they resemble organisms in that they possess genes, evolve by natural selection, and reproduce by creating multiple copies of themselves through self-assembly. Although they have genes, they do not have a cellular structure, which is often seen as the basic unit of life. Viruses do not have their own metabolism and require a host cell to make new products. They therefore cannot naturally reproduce outside a host cell—although some bacteria such as rickettsia and chlamydia are considered living organisms despite the same limitation. Accepted forms of life use cell division to reproduce, whereas viruses spontaneously assemble within cells. They differ from autonomous growth of crystals as they inherit genetic mutations while being subject to natural selection. Virus self-assembly within host cells has implications for the study of the origin of life, as it lends further credence to the hypothesis that life could have started as self-assembling organic molecules.  Structure  Viruses display a wide diversity of sizes and shapes, called \'morphologies\'. In general, viruses are much smaller than bacteria and more than a thousand bacteriophage viruses would fit inside an Escherichia coli bacterium\'s cell. Many viruses that have been studied are spherical and have a diameter between 20 and 300 nanometres. Some filoviruses, which are filaments, have a total length of up to 1400 nm; their diameters are only about 80 nm. Most viruses cannot be seen with an optical microscope, so scanning and transmission electron microscopes are used to visualise them. To increase the contrast between viruses and the background, electron-dense ""stains"" are used. These are solutions of salts of heavy metals, such as tungsten, that scatter the electrons from regions covered with the stain. When virions are coated with stain (positive staining), fine detail is obscured. Negative staining overcomes this problem by staining the background only.A complete virus particle, known as a virion, consists of nucleic acid surrounded by a protective coat of protein called a capsid. These are formed from protein subunits called capsomeres. Viruses can have a lipid ""envelope"" derived from the host cell membrane. The capsid is made from proteins encoded by the viral genome and its shape serves as the basis for morphological distinction. Virally-coded protein subunits will self-assemble to form a capsid, in general requiring the presence of the virus genome. Complex viruses code for proteins that assist in the construction of their capsid. Proteins associated with nucleic acid are known as nucleoproteins, and the association of viral capsid proteins with viral nucleic acid is called a nucleocapsid. The capsid and entire virus structure can be mechanically (physically) probed through atomic force microscopy. In general, there are five main morphological virus types: Helical These viruses are composed of a single type of capsomere stacked around a central axis to form a helical structure, which may have a central cavity, or tube. This arrangement results in virions which can be short and highly rigid rods, or long and very flexible filaments. The genetic material (typically single-stranded RNA, but single-stranded DNA in some cases) is bound into the protein helix by interactions between the negatively charged nucleic acid and positive charges on the protein. Overall, the length of a helical capsid is related to the length of the nucleic acid contained within it, and the diameter is dependent on the size and arrangement of capsomeres. The well-studied tobacco mosaic virus and inovirus are examples of helical viruses.Icosahedral Most animal viruses are icosahedral or near-spherical with chiral icosahedral symmetry. A regular icosahedron is the optimum way of forming a closed shell from identical subunits. The minimum number of capsomeres required for each triangular face is 3, which gives 60 for the icosahedron. Many viruses, such as rotavirus, have more than 60 capsomers and appear spherical but they retain this symmetry. To achieve this, the capsomeres at the apices are surrounded by five other capsomeres and are called pentons. Capsomeres on the triangular faces are surrounded by six others and are called hexons. Hexons are in essence flat and pentons, which form the 12 vertices, are curved. The same protein may act as the subunit of both the pentamers and hexamers or they may be composed of different proteins.Prolate This is an icosahedron elongated along the fivefold axis and is a common arrangement of the heads of bacteriophages. This structure is composed of a cylinder with a cap at either end.Enveloped Some species of virus envelop themselves in a modified form of one of the cell membranes, either the outer membrane surrounding an infected host cell or internal membranes such as a nuclear membrane or endoplasmic reticulum, thus gaining an outer lipid bilayer known as a viral envelope. This membrane is studded with proteins coded for by the viral genome and host genome; the lipid membrane itself and any carbohydrates present originate entirely from the host. Influenza virus, HIV (which causes AIDS), and severe acute respiratory syndrome coronavirus 2 (which causes COVID-19) use this strategy. Most enveloped viruses are dependent on the envelope for their infectivity.Complex These viruses possess a capsid that is neither purely helical nor purely icosahedral, and that may possess extra structures such as protein tails or a complex outer wall. Some bacteriophages, such as Enterobacteria phage T4, have a complex structure consisting of an icosahedral head bound to a helical tail, which may have a hexagonal base plate with protruding protein tail fibres. This tail structure acts like a molecular syringe, attaching to the bacterial host and then injecting the viral genome into the cell.The poxviruses are large, complex viruses that have an unusual morphology. The viral genome is associated with proteins within a central disc structure known as a nucleoid. The nucleoid is surrounded by a membrane and two lateral bodies of unknown function. The virus has an outer envelope with a thick layer of protein studded over its surface. The whole virion is slightly pleomorphic, ranging from ovoid to brick-shaped.  Giant viruses  Mimivirus is one of the largest characterised viruses, with a capsid diameter of 400 nm. Protein filaments measuring 100 nm project from the surface. The capsid appears hexagonal under an electron microscope, therefore the capsid is probably icosahedral. In 2011, researchers discovered the largest then known virus in samples of water collected from the ocean floor off the coast of Las Cruces, Chile. Provisionally named Megavirus chilensis, it can be seen with a basic optical microscope. In 2013, the Pandoravirus genus was discovered in Chile and Australia, and has genomes about twice as large as Megavirus and Mimivirus. All giant viruses have dsDNA genomes and they are classified into several families: Mimiviridae, Pithoviridae, Pandoraviridae, Phycodnaviridae, and the Mollivirus genus.Some viruses that infect Archaea have complex structures unrelated to any other form of virus, with a wide variety of unusual shapes, ranging from spindle-shaped structures to viruses that resemble hooked rods, teardrops or even bottles. Other archaeal viruses resemble the tailed bacteriophages, and can have multiple tail structures.  Genome  An enormous variety of genomic structures can be seen among viral species; as a group, they contain more structural genomic diversity than plants, animals, archaea, or bacteria. There are millions of different types of viruses, although fewer than 7,000 types have been described in detail. As of January 2021, the NCBI Virus genome database has more than 193,000 complete genome sequences, but there are doubtlessly many more to be discovered.A virus has either a DNA or an RNA genome and is called a DNA virus or an RNA virus, respectively. The vast majority of viruses have RNA genomes. Plant viruses tend to have single-stranded RNA genomes and bacteriophages tend to have double-stranded DNA genomes.Viral genomes are circular, as in the polyomaviruses, or linear, as in the adenoviruses. The type of nucleic acid is irrelevant to the shape of the genome. Among RNA viruses and certain DNA viruses, the genome is often divided up into separate parts, in which case it is called segmented. For RNA viruses, each segment often codes for only one protein and they are usually found together in one capsid. All segments are not required to be in the same virion for the virus to be infectious, as demonstrated by brome mosaic virus and several other plant viruses.A viral genome, irrespective of nucleic acid type, is almost always either single-stranded (ss) or double-stranded (ds). Single-stranded genomes consist of an unpaired nucleic acid, analogous to one-half of a ladder split down the middle. Double-stranded genomes consist of two complementary paired nucleic acids, analogous to a ladder. The virus particles of some virus families, such as those belonging to the Hepadnaviridae, contain a genome that is partially double-stranded and partially single-stranded.For most viruses with RNA genomes and some with single-stranded DNA (ssDNA) genomes, the single strands are said to be either positive-sense (called the \'plus-strand\') or negative-sense (called the \'minus-strand\'), depending on if they are complementary to the viral messenger RNA (mRNA). Positive-sense viral RNA is in the same sense as viral mRNA and thus at least a part of it can be immediately translated by the host cell. Negative-sense viral RNA is complementary to mRNA and thus must be converted to positive-sense RNA by an RNA-dependent RNA polymerase before translation. DNA nomenclature for viruses with genomic ssDNA is similar to RNA nomenclature, in that positive-strand viral ssDNA is identical in sequence to the viral mRNA and is thus a coding strand, while negative-sense viral ssDNA is complementary to the viral mRNA and is thus a template strand. Several types of ssDNA and ssRNA viruses have genomes that are ambisense in that transcription can occur off both strands in a double-stranded replicative intermediate. Examples include geminiviruses, which are ssDNA plant viruses and arenaviruses, which are ssRNA viruses of animals.  Genome size  Genome size varies greatly between species. The smallest—the ssDNA circoviruses, family Circoviridae—code for only two proteins and have a genome size of only two kilobases; the largest—the pandoraviruses—have genome sizes of around two megabases which code for about 2500 proteins. Virus genes rarely have introns and often are arranged in the genome so that they overlap.In general, RNA viruses have smaller genome sizes than DNA viruses because of a higher error-rate when replicating, and have a maximum upper size limit. Beyond this, errors when replicating render the virus useless or uncompetitive. To compensate, RNA viruses often have segmented genomes—the genome is split into smaller molecules—thus reducing the chance that an error in a single-component genome will incapacitate the entire genome. In contrast, DNA viruses generally have larger genomes because of the high fidelity of their replication enzymes. Single-strand DNA viruses are an exception to this rule, as mutation rates for these genomes can approach the extreme of the ssRNA virus case.  Genetic mutation and recombination  Viruses undergo genetic change by several mechanisms. These include a process called antigenic drift where individual bases in the DNA or RNA mutate to other bases. Most of these point mutations are ""silent""—they do not change the protein that the gene encodes—but others can confer evolutionary advantages such as resistance to antiviral drugs. Antigenic shift occurs when there is a major change in the genome of the virus. This can be a result of recombination or reassortment. When this happens with influenza viruses, pandemics might result. RNA viruses often exist as quasispecies or swarms of viruses of the same species but with slightly different genome nucleoside sequences. Such quasispecies are a prime target for natural selection.Segmented genomes confer evolutionary advantages; different strains of a virus with a segmented genome can shuffle and combine genes and produce progeny viruses (or offspring) that have unique characteristics. This is called reassortment or \'viral sex\'.Genetic recombination is a process by which a strand of DNA (or RNA) is broken and then joined to the end of a different DNA (or RNA) molecule. This can occur when viruses infect cells simultaneously and studies of viral evolution have shown that recombination has been rampant in the species studied. Recombination is common to both RNA and DNA viruses.Coronaviruses have a single-strand positive-sense RNA genome. Replication of the genome is catalyzed by an RNA-dependent RNA polymerase. The mechanism of recombination used by coronaviruses likely involves template switching by the polymerase during genome replication. This process appears to be an adaptation for coping with genome damage.  Replication cycle  Viral populations do not grow through cell division, because they are acellular. Instead, they use the machinery and metabolism of a host cell to produce multiple copies of themselves, and they assemble in the cell. When infected, the host cell is forced to rapidly produce thousands of copies of the original virus.Their life cycle differs greatly between species, but there are six basic stages in their life cycle:Attachment is a specific binding between viral capsid proteins and specific receptors on the host cellular surface. This specificity determines the host range and type of host cell of a virus. For example, HIV infects a limited range of human leucocytes. This is because its surface protein, gp120, specifically interacts with the CD4 molecule—a chemokine receptor—which is most commonly found on the surface of CD4+ T-Cells. This mechanism has evolved to favour those viruses that infect only cells in which they are capable of replication. Attachment to the receptor can induce the viral envelope protein to undergo changes that result in the fusion of viral and cellular membranes, or changes of non-enveloped virus surface proteins that allow the virus to enter.Penetration or viral entry follows attachment: Virions enter the host cell through receptor-mediated endocytosis or membrane fusion. The infection of plant and fungal cells is different from that of animal cells. Plants have a rigid cell wall made of cellulose, and fungi one of chitin, so most viruses can get inside these cells only after trauma to the cell wall. Nearly all plant viruses (such as tobacco mosaic virus) can also move directly from cell to cell, in the form of single-stranded nucleoprotein complexes, through pores called plasmodesmata. Bacteria, like plants, have strong cell walls that a virus must breach to infect the cell. Given that bacterial cell walls are much thinner than plant cell walls due to their much smaller size, some viruses have evolved mechanisms that inject their genome into the bacterial cell across the cell wall, while the viral capsid remains outside.Uncoating is a process in which the viral capsid is removed: This may be by degradation by viral enzymes or host enzymes or by simple dissociation; the end-result is the releasing of the viral genomic nucleic acid.Replication of viruses involves primarily multiplication of the genome. Replication involves the synthesis of viral messenger RNA (mRNA) from ""early"" genes (with exceptions for positive-sense RNA viruses), viral protein synthesis, possible assembly of viral proteins, then viral genome replication mediated by early or regulatory protein expression. This may be followed, for complex viruses with larger genomes, by one or more further rounds of mRNA synthesis: ""late"" gene expression is, in general, of structural or virion proteins.Assembly – Following the structure-mediated self-assembly of the virus particles, some modification of the proteins often occurs. In viruses such as HIV, this modification (sometimes called maturation) occurs after the virus has been released from the host cell.Release – Viruses can be released from the host cell by lysis, a process that kills the cell by bursting its membrane and cell wall if present: this is a feature of many bacterial and some animal viruses. Some viruses undergo a lysogenic cycle where the viral genome is incorporated by genetic recombination into a specific place in the host\'s chromosome. The viral genome is then known as a ""provirus"" or, in the case of bacteriophages a ""prophage"". Whenever the host divides, the viral genome is also replicated. The viral genome is mostly silent within the host. At some point, the provirus or prophage may give rise to the active virus, which may lyse the host cells. Enveloped viruses (e.g., HIV) typically are released from the host cell by budding. During this process, the virus acquires its envelope, which is a modified piece of the host\'s plasma or other, internal membrane.  Genome replication  The genetic material within virus particles, and the method by which the material is replicated, varies considerably between different types of viruses. DNA viruses The genome replication of most DNA viruses takes place in the cell\'s nucleus. If the cell has the appropriate receptor on its surface, these viruses enter the cell either by direct fusion with the cell membrane (e.g., herpesviruses) or—more usually—by receptor-mediated endocytosis. Most DNA viruses are entirely dependent on the host cell\'s DNA and RNA synthesising machinery and RNA processing machinery. Viruses with larger genomes may encode much of this machinery themselves. In eukaryotes, the viral genome must cross the cell\'s nuclear membrane to access this machinery, while in bacteria it need only enter the cell.RNA viruses Replication of RNA viruses usually takes place in the cytoplasm. RNA viruses can be placed into four different groups depending on their modes of replication. The polarity (whether or not it can be used directly by ribosomes to make proteins) of single-stranded RNA viruses largely determines the replicative mechanism; the other major criterion is whether the genetic material is single-stranded or double-stranded. All RNA viruses use their own RNA replicase enzymes to create copies of their genomes.Reverse transcribing viruses Reverse transcribing viruses have ssRNA (Retroviridae, Metaviridae, Pseudoviridae) or dsDNA (Caulimoviridae, and Hepadnaviridae) in their particles. Reverse transcribing viruses with RNA genomes (retroviruses) use a DNA intermediate to replicate, whereas those with DNA genomes (pararetroviruses) use an RNA intermediate during genome replication. Both types use a reverse transcriptase, or RNA-dependent DNA polymerase enzyme, to carry out the nucleic acid conversion. Retroviruses integrate the DNA produced by reverse transcription into the host genome as a provirus as a part of the replication process; pararetroviruses do not, although integrated genome copies of especially plant pararetroviruses can give rise to infectious virus. They are susceptible to antiviral drugs that inhibit the reverse transcriptase enzyme, e.g. zidovudine and lamivudine. An example of the first type is HIV, which is a retrovirus. Examples of the second type are the Hepadnaviridae, which includes Hepatitis B virus.  Cytopathic effects on the host cell  The range of structural and biochemical effects that viruses have on the host cell is extensive. These are called \'cytopathic effects\'. Most virus infections eventually result in the death of the host cell. The causes of death include cell lysis, alterations to the cell\'s surface membrane and apoptosis. Often cell death is caused by cessation of its normal activities because of suppression by virus-specific proteins, not all of which are components of the virus particle. The distinction between cytopathic and harmless is gradual. Some viruses, such as Epstein–Barr virus, can cause cells to proliferate without causing malignancy, while others, such as papillomaviruses, are established causes of cancer.  Dormant and latent infections  Some viruses cause no apparent changes to the infected cell. Cells in which the virus is latent and inactive show few signs of infection and often function normally. This causes persistent infections and the virus is often dormant for many months or years. This is often the case with herpes viruses.  Host range  Viruses are by far the most abundant biological entities on Earth and they outnumber all the others put together. They infect all types of cellular life including animals, plants, bacteria and fungi. Different types of viruses can infect only a limited range of hosts and many are species-specific. Some, such as smallpox virus for example, can infect only one species—in this case humans, and are said to have a narrow host range. Other viruses, such as rabies virus, can infect different species of mammals and are said to have a broad range. The viruses that infect plants are harmless to animals, and most viruses that infect other animals are harmless to humans. The host range of some bacteriophages is limited to a single strain of bacteria and they can be used to trace the source of outbreaks of infections by a method called phage typing. The complete set of viruses in an organism or habitat is called the virome; for example, all human viruses constitute the human virome.  Novel viruses  A novel virus is one that has not previously been recorded. It can be a virus that is isolated from its natural reservoir or isolated as the result of spread to an animal or human host where the virus had not been identified before. It can be an emergent virus, one that represents a new virus, but it can also be an extant virus that has not been previously identified. The SARS-CoV-2 coronavirus that caused the pandemic of covid disease is an example of a novel virus.  Classification  Classification seeks to describe the diversity of viruses by naming and grouping them on the basis of similarities. In 1962, André Lwoff, Robert Horne, and Paul Tournier were the first to develop a means of virus classification, based on the Linnaean hierarchical system. This system based classification on phylum, class, order, family, genus, and species. Viruses were grouped according to their shared properties (not those of their hosts) and the type of nucleic acid forming their genomes. In 1966, the International Committee on Taxonomy of Viruses (ICTV) was formed. The system proposed by Lwoff, Horne and Tournier was initially not accepted by the ICTV because the small genome size of viruses and their high rate of mutation made it difficult to determine their ancestry beyond order. As such, the Baltimore classification system has come to be used to supplement the more traditional hierarchy. Starting in 2018, the ICTV began to acknowledge deeper evolutionary relationships between viruses that have been discovered over time and adopted a 15-rank classification system ranging from realm to species. Additionally, some species within the same genus are grouped into a genogroup.  ICTV classification  The ICTV developed the current classification system and wrote guidelines that put a greater weight on certain virus properties to maintain family uniformity. A unified taxonomy (a universal system for classifying viruses) has been established. Only a small part of the total diversity of viruses has been studied. As of 2022, 6 realms, 10 kingdoms, 17 phyla, 2 subphyla, 40 classes, 72 orders, 8 suborders, 264 families, 182 subfamilies, 2,818 genera, 84 subgenera, and 11,273 species of viruses have been defined by the ICTV.The general taxonomic structure of taxon ranges and the suffixes used in taxonomic names are shown hereafter. As of 2022, the ranks of subrealm, subkingdom, and subclass are unused, whereas all other ranks are in use. Realm (-viria) Subrealm (-vira) Kingdom (-virae) Subkingdom (-virites) Phylum (-viricota) Subphylum (-viricotina) Class (-viricetes) Subclass (-viricetidae) Order (-virales) Suborder (-virineae) Family (-viridae) Subfamily (-virinae) Genus (-virus) Subgenus (-virus) Species  Baltimore classification  The Nobel Prize-winning biologist David Baltimore devised the Baltimore classification system. The ICTV classification system is used in conjunction with the Baltimore classification system in modern virus classification.The Baltimore classification of viruses is based on the mechanism of mRNA production. Viruses must generate mRNAs from their genomes to produce proteins and replicate themselves, but different mechanisms are used to achieve this in each virus family. Viral genomes may be single-stranded (ss) or double-stranded (ds), RNA or DNA, and may or may not use reverse transcriptase (RT). In addition, ssRNA viruses may be either sense (+) or antisense (−). This classification places viruses into seven groups: I: dsDNA viruses (e.g. Adenoviruses, Herpesviruses, Poxviruses) II: ssDNA viruses (+ strand or ""sense"") DNA (e.g. Parvoviruses) III: dsRNA viruses (e.g. Reoviruses) IV:(+)ssRNA viruses (+ strand or sense) RNA (e.g. Coronaviruses, Picornaviruses, Togaviruses) V: (−)ssRNA viruses (− strand or antisense) RNA (e.g. Orthomyxoviruses, Rhabdoviruses) VI: ssRNA-RT viruses (+ strand or sense) RNA with DNA intermediate in life-cycle (e.g. Retroviruses) VII: dsDNA-RT viruses DNA with RNA intermediate in life-cycle (e.g. Hepadnaviruses)  Role in human disease  Examples of common human diseases caused by viruses include the common cold, influenza, chickenpox, and cold sores. Many serious diseases such as rabies, Ebola virus disease, AIDS (HIV), avian influenza, and SARS are caused by viruses. The relative ability of viruses to cause disease is described in terms of virulence. Other diseases are under investigation to discover if they have a virus as the causative agent, such as the possible connection between human herpesvirus 6 (HHV6) and neurological diseases such as multiple sclerosis and chronic fatigue syndrome. There is controversy over whether the bornavirus, previously thought to cause neurological diseases in horses, could be responsible for psychiatric illnesses in humans.Viruses have different mechanisms by which they produce disease in an organism, which depends largely on the viral species. Mechanisms at the cellular level primarily include cell lysis, the breaking open and subsequent death of the cell. In multicellular organisms, if enough cells die, the whole organism will start to suffer the effects. Although viruses cause disruption of healthy homeostasis, resulting in disease, they may exist relatively harmlessly within an organism. An example would include the ability of the herpes simplex virus, which causes cold sores, to remain in a dormant state within the human body. This is called latency and is a characteristic of the herpes viruses, including Epstein–Barr virus, which causes glandular fever, and varicella zoster virus, which causes chickenpox and shingles. Most people have been infected with at least one of these types of herpes virus. These latent viruses might sometimes be beneficial, as the presence of the virus can increase immunity against bacterial pathogens, such as Yersinia pestis.Some viruses can cause lifelong or chronic infections, where the viruses continue to replicate in the body despite the host\'s defence mechanisms. This is common in hepatitis B virus and hepatitis C virus infections. People chronically infected are known as carriers, as they serve as reservoirs of infectious virus. In populations with a high proportion of carriers, the disease is said to be endemic.  Epidemiology  Viral epidemiology is the branch of medical science that deals with the transmission and control of virus infections in humans. Transmission of viruses can be vertical, which means from mother to child, or horizontal, which means from person to person. Examples of vertical transmission include hepatitis B virus and HIV, where the baby is born already infected with the virus. Another, more rare, example is the varicella zoster virus, which, although causing relatively mild infections in children and adults, can be fatal to the foetus and newborn baby.Horizontal transmission is the most common mechanism of spread of viruses in populations. Horizontal transmission can occur when body fluids are exchanged during sexual activity, by exchange of saliva or when contaminated food or water is ingested. It can also occur when aerosols containing viruses are inhaled or by insect vectors such as when infected mosquitoes penetrate the skin of a host. Most types of viruses are restricted to just one or two of these mechanisms and they are referred to as ""respiratory viruses"" or ""enteric viruses"" and so forth. The rate or speed of transmission of viral infections depends on factors that include population density, the number of susceptible individuals, (i.e., those not immune), the quality of healthcare and the weather.Epidemiology is used to break the chain of infection in populations during outbreaks of viral diseases. Control measures are used that are based on knowledge of how the virus is transmitted. It is important to find the source, or sources, of the outbreak and to identify the virus. Once the virus has been identified, the chain of transmission can sometimes be broken by vaccines. When vaccines are not available, sanitation and disinfection can be effective. Often, infected people are isolated from the rest of the community, and those that have been exposed to the virus are placed in quarantine. To control the outbreak of foot-and-mouth disease in cattle in Britain in 2001, thousands of cattle were slaughtered. Most viral infections of humans and other animals have incubation periods during which the infection causes no signs or symptoms. Incubation periods for viral diseases range from a few days to weeks, but are known for most infections. Somewhat overlapping, but mainly following the incubation period, there is a period of communicability—a time when an infected individual or animal is contagious and can infect another person or animal. This, too, is known for many viral infections, and knowledge of the length of both periods is important in the control of outbreaks. When outbreaks cause an unusually high proportion of cases in a population, community, or region, they are called epidemics. If outbreaks spread worldwide, they are called pandemics.  Epidemics and pandemics  A pandemic is a worldwide epidemic. The 1918 flu pandemic, which lasted until 1919, was a category 5 influenza pandemic caused by an unusually severe and deadly influenza A virus. The victims were often healthy young adults, in contrast to most influenza outbreaks, which predominantly affect juvenile, elderly, or otherwise-weakened patients. Older estimates say it killed 40–50 million people, while more recent research suggests that it may have killed as many as 100 million people, or 5% of the world\'s population in 1918.Although viral pandemics are rare events, HIV—which evolved from viruses found in monkeys and chimpanzees—has been pandemic since at least the 1980s. During the 20th century there were four pandemics caused by influenza virus and those that occurred in 1918, 1957 and 1968 were severe. Most researchers believe that HIV originated in sub-Saharan Africa during the 20th century; it is now a pandemic, with an estimated 37.9 million people now living with the disease worldwide. There were about 770,000 deaths from AIDS in 2018. The Joint United Nations Programme on HIV/AIDS (UNAIDS) and the World Health Organization (WHO) estimate that AIDS has killed more than 25 million people since it was first recognised on 5 June 1981, making it one of the most destructive epidemics in recorded history. In 2007 there were 2.7 million new HIV infections and 2 million HIV-related deaths. Several highly lethal viral pathogens are members of the Filoviridae. Filoviruses are filament-like viruses that cause viral hemorrhagic fever, and include ebolaviruses and marburgviruses. Marburg virus, first discovered in 1967, attracted widespread press attention in April 2005 for an outbreak in Angola. Ebola virus disease has also caused intermittent outbreaks with high mortality rates since 1976 when it was first identified. The worst and most recent one is the 2013–2016 West Africa epidemic.Except for smallpox, most pandemics are caused by newly evolved viruses. These ""emergent"" viruses are usually mutants of less harmful viruses that have circulated previously either in humans or other animals.Severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) are caused by new types of coronaviruses. Other coronaviruses are known to cause mild infections in humans, so the virulence and rapid spread of SARS infections—that by July 2003 had caused around 8,000 cases and 800 deaths—was unexpected and most countries were not prepared.A related coronavirus, severe acute respiratory syndrome coronavirus 2 (SARS-Cov-2), thought to have originated in bats, emerged in Wuhan, China in November 2019 and spread rapidly around the world. Infections with the virus caused the COVID-19 pandemic that started in 2020. Unprecedented restrictions in peacetime were placed on international travel, and curfews were imposed in several major cities worldwide in response to the pandemic.  Cancer  Viruses are an established cause of cancer in humans and other species. Viral cancers occur only in a minority of infected persons (or animals). Cancer viruses come from a range of virus families, including both RNA and DNA viruses, and so there is no single type of ""oncovirus"" (an obsolete term originally used for acutely transforming retroviruses). The development of cancer is determined by a variety of factors such as host immunity and mutations in the host. Viruses accepted to cause human cancers include some genotypes of human papillomavirus, hepatitis B virus, hepatitis C virus, Epstein–Barr virus, Kaposi\'s sarcoma-associated herpesvirus and human T-lymphotropic virus. The most recently discovered human cancer virus is a polyomavirus (Merkel cell polyomavirus) that causes most cases of a rare form of skin cancer called Merkel cell carcinoma. Hepatitis viruses can develop into a chronic viral infection that leads to liver cancer. Infection by human T-lymphotropic virus can lead to tropical spastic paraparesis and adult T-cell leukaemia. Human papillomaviruses are an established cause of cancers of cervix, skin, anus, and penis. Within the Herpesviridae, Kaposi\'s sarcoma-associated herpesvirus causes Kaposi\'s sarcoma and body-cavity lymphoma, and Epstein–Barr virus causes Burkitt\'s lymphoma, Hodgkin\'s lymphoma, B lymphoproliferative disorder, and nasopharyngeal carcinoma. Merkel cell polyomavirus closely related to SV40 and mouse polyomaviruses that have been used as animal models for cancer viruses for over 50 years.  Host defence mechanisms  The body\'s first line of defence against viruses is the innate immune system. This comprises cells and other mechanisms that defend the host from infection in a non-specific manner. This means that the cells of the innate system recognise, and respond to, pathogens in a generic way, but, unlike the adaptive immune system, it does not confer long-lasting or protective immunity to the host.RNA interference is an important innate defence against viruses. Many viruses have a replication strategy that involves double-stranded RNA (dsRNA). When such a virus infects a cell, it releases its RNA molecule or molecules, which immediately bind to a protein complex called a dicer that cuts the RNA into smaller pieces. A biochemical pathway—the RISC complex—is activated, which ensures cell survival by degrading the viral mRNA. Rotaviruses have evolved to avoid this defence mechanism by not uncoating fully inside the cell, and releasing newly produced mRNA through pores in the particle\'s inner capsid. Their genomic dsRNA remains protected inside the core of the virion.When the adaptive immune system of a vertebrate encounters a virus, it produces specific antibodies that bind to the virus and often render it non-infectious. This is called humoral immunity. Two types of antibodies are important. The first, called IgM, is highly effective at neutralising viruses but is produced by the cells of the immune system only for a few weeks. The second, called IgG, is produced indefinitely. The presence of IgM in the blood of the host is used to test for acute infection, whereas IgG indicates an infection sometime in the past. IgG antibody is measured when tests for immunity are carried out.Antibodies can continue to be an effective defence mechanism even after viruses have managed to gain entry to the host cell. A protein that is in cells, called TRIM21, can attach to the antibodies on the surface of the virus particle. This primes the subsequent destruction of the virus by the enzymes of the cell\'s proteosome system. A second defence of vertebrates against viruses is called cell-mediated immunity and involves immune cells known as T cells. The body\'s cells constantly display short fragments of their proteins on the cell\'s surface, and, if a T cell recognises a suspicious viral fragment there, the host cell is destroyed by \'killer T\' cells and the virus-specific T-cells proliferate. Cells such as the macrophage are specialists at this antigen presentation. The production of interferon is an important host defence mechanism. This is a hormone produced by the body when viruses are present. Its role in immunity is complex; it eventually stops the viruses from reproducing by killing the infected cell and its close neighbours.Not all virus infections produce a protective immune response in this way. HIV evades the immune system by constantly changing the amino acid sequence of the proteins on the surface of the virion. This is known as ""escape mutation"" as the viral epitopes escape recognition by the host immune response. These persistent viruses evade immune control by sequestration, blockade of antigen presentation, cytokine resistance, evasion of natural killer cell activities, escape from apoptosis, and antigenic shift. Other viruses, called \'neurotropic viruses\', are disseminated by neural spread where the immune system may be unable to reach them due to immune privilege.  Prevention and treatment  Because viruses use vital metabolic pathways within host cells to replicate, they are difficult to eliminate without using drugs that cause toxic effects to host cells in general. The most effective medical approaches to viral diseases are vaccinations to provide immunity to infection, and antiviral drugs that selectively interfere with viral replication.  Vaccines  Vaccination is a cheap and effective way of preventing infections by viruses. Vaccines were used to prevent viral infections long before the discovery of the actual viruses. Their use has resulted in a dramatic decline in morbidity (illness) and mortality (death) associated with viral infections such as polio, measles, mumps and rubella. Smallpox infections have been eradicated. Vaccines are available to prevent over thirteen viral infections of humans, and more are used to prevent viral infections of animals. Vaccines can consist of live-attenuated or killed viruses, viral proteins (antigens), or RNA. Live vaccines contain weakened forms of the virus, which do not cause the disease but, nonetheless, confer immunity. Such viruses are called attenuated. Live vaccines can be dangerous when given to people with a weak immunity (who are described as immunocompromised), because in these people, the weakened virus can cause the original disease. Biotechnology and genetic engineering techniques are used to produce subunit vaccines. These vaccines use only the capsid proteins of the virus. Hepatitis B vaccine is an example of this type of vaccine. Subunit vaccines are safe for immunocompromised patients because they cannot cause the disease. The yellow fever virus vaccine, a live-attenuated strain called 17D, is probably the safest and most effective vaccine ever generated.","A virus is a tiny parasite. Virology is the study of viruses. Viruses can only be seen under an electron microscope. Viruses are not free-living: they can only be parasites. They always reproduce inside other living things. All viruses infect living organisms, and may cause disease. The virus make copies of itself inside another organism's cells. Viruses are a strand of nucleic acid with a protein coat. Usually the nucleic acid is RNA; sometimes it is DNA. Viruses cause many types of diseases, such as polio, ebola and hepatitis. Viruses reproduce by getting their nucleic acid strand into a prokaryote or eukaryote cell. The RNA or DNA strand then takes over the cell machinery to reproduce copies of itself and the protein coat. The cell then bursts open, spreading the newly created viruses. All viruses reproduce this way, and there are no free-living viruses. Viruses are everywhere in the environment, and all organisms can be infected by them.Most viruses are much smaller than bacteria. They were not visible until the invention of the electron microscope. A virus has a simple structure. It has just a protein coat which covers a string of nucleic acid. Viruses live and reproduce inside the cells of other living organisms. With eukaryotic cells, the virus protein coat is able to enter the target cells by certain cell membrane receptors. With prokaryote bacteria cells, the bacteriophage physically injects the nucleic acid strand into the host cell. Viruses have the following characteristics: They outnumber all other forms of life on the planet by a long way. They are infectious particles, causing many types of disease; They contain a nucleic acid core of RNA or DNA; They are surrounded by a protective protein coat;When the host cell has finished making more viruses, it undergoes lysis, or breaks apart. The viruses are released and are then able to infect other cells. Viruses can remain ""silent"" (inactive) for a long time, and will infect cells when the time and conditions are right. Some special viruses are worth noting. Bacteriophages have evolved to enter bacterial cells, which have a different type of cell wall from eukaryote cell membranes. Envelope viruses, when they reproduce, cover themselves with a modified form of the host cell membrane, thus gaining an outer lipid layer that helps entry. Some of our most difficult-to-combat viruses, like influenza and HIV, use this method. Viral infections in animals trigger an immune response which usually kills the infecting virus. Vaccines can also produce immune responses. They give an artificially acquired immunity to the specific viral infection. However, some viruses (including those causing AIDS and viral hepatitis) escape from these immune responses and cause chronic infections. Antibiotics have no effect on viruses, but there are some other drugs which can be used against viruses.  Genome  There are many genomic structures in viruses. As a group they are more diverse than plants, animals, archaea, or bacteria. There are millions of different types of viruses, but only about 7,000 of them have been described in detail.49A virus has either RNA or DNA genes and so is called an RNA virus or a DNA virus. The vast majority of viruses have RNA genomes. Plant viruses usually have single-stranded RNA genomes and bacteriophages usually have double-stranded DNA genomes.96/99Fewer than 7,000 types have been described in detail. but there are doubtlessly many more to be discovered.  Replication cycle  Viral populations do not grow through cell division, because they do not have cells. Instead, they use the machinery and metabolism of a host cell to produce many copies of themselves, and they assemble (put together) in the cell. The life cycle of viruses differs greatly between species but there are six basic stages in the life cycle of viruses:75/91 Attachment is a binding between viral capsid proteins and specific receptors on the host cellular surface. Penetration follows attachment: Virions (single virus particles) enter the host cell by receptor-mediated endocytosis or fusion with the lipid bilayer. This is called viral entry. The infection of plant and fungal cells is different from that of animal cells. Plants have a rigid cell wall made of cellulose, and fungi one of chitin. This means most viruses can only get inside these cells by force.70 An example would be: a virus travels on an insect vector which feeds on plant sap. The damage done to cell walls would let the virus get in. Bacteria, like plants, have strong cell walls that a virus must get through to infect the cell. However, bacterial cell walls are much thinner than plant cell walls, and some viruses have mechanisms that inject their genome into the bacterial cell, while the viral capsid remains outside.71 Uncoating is how the viral capsid is removed: This may be by viral enzymes or host enzymes or by simple dissociation; the end-result is the releasing of the viral nucleic acid. Replication of viruses is multiplying the genome. This usually means production of viral messenger RNA (mRNA) from ""early"" genes. This may be followed, for complex viruses, by one or more further rounds of mRNA synthesis: ""late"" gene expression is of structural or virion proteins. After the self-assembly of the virus particles, some modification of the proteins often occurs. In viruses such as HIV, this modification (sometimes called maturation) occurs after the virus has been released from the host cell. Viruses can be released from the host cell by lysis, a process that kills the cell by bursting its membrane and cell wall. This is a feature of many bacterial and some animal viruses. In some viruses the viral genome is put by genetic recombination into a specific place in the host's chromosome. The viral genome is then known as a ""provirus"" or, in the case of bacteriophages a ""prophage"".60 Whenever the host divides, the viral genome is also replicated. The viral genome is mostly silent within the host; however, at some point, the provirus or prophage may give rise to active virus, which may lyse the host cells.chapter 15 Enveloped viruses (e.g. HIV) typically are released from the host cell after the virus acquires its envelope. The envelope is a modified piece of the host's plasma membrane.185/7  Genetic material and replication  The genetic material within virus particles, and the method by which the material is replicated, varies considerably between different types of viruses. RNA viruses Replication usually takes place in the cytoplasm. RNA viruses can be placed into four different groups depending on their modes of replication. All RNA viruses use their own RNA replicase enzymes to create copies of their genomes.79DNA viruses The genome replication of most DNA viruses takes place in the cell's nucleus. Most DNA viruses are entirely dependent on the host cell's DNA and RNA synthesising machinery, and RNA processing machinery. Viruses with larger genomes may encode much of this machinery themselves. In eukaryotes the viral genome must cross the cell's nuclear membrane to access this machinery, while in bacteria it need only enter the cell.5478Reverse transcribing viruses Reverse transcribing viruses with RNA genomes (retroviruses) use a DNA intermediate to replicate. Those with DNA genomes (pararetroviruses) use an RNA intermediate during genome replication. They are susceptible to antiviral drugs that inhibit the reverse transcriptase enzyme. An example of the first type is HIV, which is a retrovirus. Examples of the second type are the Hepadnaviridae, which includes Hepatitis B virus.88/9  Host defence mechanisms   Innate immune system  The body's first line of defence against viruses is the innate immune system. This has cells and other mechanisms which defend the host from any infection. The cells of the innate system recognise, and respond to, pathogens in a general way.RNA interference is an important innate defence against viruses. Many viruses have a replication strategy that involves double-stranded RNA (dsRNA). When such a virus infects a cell, it releases its RNA molecule. A protein complex called dicer sticks to it and chops the RNA into pieces. Then a biochemical pathway, called the RISC complex, starts up. This attacks the viral mRNA, and the cell survives the infection. Rotaviruses avoid this by not uncoating fully inside the cell and by releasing newly produced mRNA through pores in the particle's inner capsid. The genomic dsRNA remains protected inside the core of the virion.The production of interferon is an important host defence mechanism. This is a hormone produced by the body when viruses are present. Its role in immunity is complex; it eventually stops the viruses from reproducing by killing the infected cell and its close neighbours.  Adaptive immune system  Vertebrates have a second, more specific, immune system. It is called the adaptive immune system. When it meets a virus, it produces specific antibodies that bind to the virus and render it non-infectious. Two types of antibodies are important. The first, called IgM, is highly effective at neutralizing viruses but is produced by the cells of the immune system only for a few weeks. The second, called IgG, is produced indefinitely. The presence of IgM in the blood of the host is used to test for acute infection, whereas IgG indicates an infection sometime in the past. IgG antibody is measured when tests for immunity are carried out.Another vertebrate defence against viruses involves immune cells known as T cells. The body's cells constantly display short fragments of their proteins on the cell's surface, and, if a T cell recognises a suspicious viral fragment there, the host cell is destroyed by killer T cells and the virus-specific T-cells proliferate. Cells such as macrophages are specialists at this antigen presentation.  Evading the immune system  Not all virus infections produce a protective immune response. These persistent viruses evade immune control by sequestration (hiding away); cytokine resistance; evading natural killer cell activity; escape from apoptosis (cell death), and antigenic shift (changing surface proteins). HIV evades the immune system by constantly changing the amino acid sequence of the proteins on the surface of the virion. Other viruses move along nerves to places the immune system cannot reach.  Evolution  Viruses do not belong to any of the six kingdoms. They do not meet all the requirements for being classified as a living organism because they are not active until the point of infection. However, that is just a verbal point. Obviously, their structure and mode of operation means they have evolved from other living things, and the loss of normal structure occurs in many endoparasites. The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids – pieces of DNA that can move between cells – while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity.  Recent discoveries  A recent project discovered nearly 1500 new RNA viruses by sampling over 200 invertebrate species. ""The research team... extracted their RNA and, using next-generation sequencing, deciphered the sequence of a staggering six trillion letters present in the invertebrate RNA libraries"". The research showed that viruses changed bits and pieces of their RNA by a variety of genetic mechanisms. ""The invertebrate virome [shows] remarkable genomic flexibility that includes frequent recombination, lateral gene transfer among viruses and hosts, gene gain and loss, and complex genomic rearrangements"".  How bacteria and archaea deal with viruses  Viruses have been on this planet a long time. We now know that bacteria and archaea had to deal with them first, before our type of cellular life evolved. Details of the defence mechanisms used by archaea and bacteria are discussed on the page CRISPR, which briefly introduces the topic of early defences against viruses.  Largest virus  A group of large viruses infect amoebae. The largest is Pithovirus. Others in order of size are Pandoravirus, then Megavirus, then Mimivirus. They are bigger than some bacteria, and visible under a light microscope.  Viruses in the sea  Viruses are everywhere in the sea. They may outnumber all other forms of marine life by at least an order of magnitude. Through selective infection, viruses influence nutrient cycling and evolution in the ocean.  Uses  Viruses are used widely in cell biology. Geneticists often use viruses as vectors to introduce genes into cells that they are studying. This is useful for making the cell produce a foreign substance, or to study the effect of introducing a new gene into the genome. Eastern European scientists have used phage therapy as an alternative to antibiotics for some time, and interest in this approach is increasing, because of the high level of antibiotic resistance now found in some pathogenic bacteria.  References "
"Bacteria ( (listen); singular: bacterium) are ubiquitous, mostly free-living organisms often consisting of one biological cell. They constitute a large domain of prokaryotic microorganisms. Typically a few micrometres in length, bacteria were among the first life forms to appear on Earth, and are present in most of its habitats. Bacteria inhabit soil, water, acidic hot springs, radioactive waste, and the deep biosphere of Earth\'s crust. Bacteria play a vital role in many stages of the nutrient cycle by recycling nutrients and the fixation of nitrogen from the atmosphere. The nutrient cycle includes the decomposition of dead bodies; bacteria are responsible for the putrefaction stage in this process. In the biological communities surrounding hydrothermal vents and cold seeps, extremophile bacteria provide the nutrients needed to sustain life by converting dissolved compounds, such as hydrogen sulphide and methane, to energy. Bacteria also live in symbiotic and parasitic relationships with plants and animals. Most bacteria have not been characterised and there are many species that cannot be grown in the laboratory. The study of bacteria is known as bacteriology, a branch of microbiology. Humans and most other animals carry vast numbers (approximately 1013 to 1014) of bacteria. Most are in the gut, and there are many on the skin. Most of the bacteria in and on the body are harmless or rendered so by the protective effects of the immune system, and many are beneficial, particularly the ones in the gut. However, several species of bacteria are pathogenic and cause infectious diseases, including cholera, syphilis, anthrax, leprosy, tuberculosis, tetanus and bubonic plague. The most common fatal bacterial diseases are respiratory infections. Antibiotics are used to treat bacterial infections and are also used in farming, making antibiotic resistance a growing problem. Bacteria are important in sewage treatment and the breakdown of oil spills, the production of cheese and yogurt through fermentation, the recovery of gold, palladium, copper and other metals in the mining sector, as well as in biotechnology, and the manufacture of antibiotics and other chemicals. Once regarded as plants constituting the class Schizomycetes (""fission fungi""), bacteria are now classified as prokaryotes. Unlike cells of animals and other eukaryotes, bacterial cells do not contain a nucleus and rarely harbour membrane-bound organelles. Although the term bacteria traditionally included all prokaryotes, the scientific classification changed after the discovery in the 1990s that prokaryotes consist of two very different groups of organisms that evolved from an ancient common ancestor. These evolutionary domains are called Bacteria and Archaea.  Etymology  The word bacteria is the plural of the Neo-Latin bacterium, which is the latinisation of the Ancient Greek βακτήριον (baktḗrion), the diminutive of βακτηρία (baktēría), meaning ""staff, cane"", because the first ones to be discovered were rod-shaped.  Origin and early evolution  The ancestors of bacteria were unicellular microorganisms that were the first forms of life to appear on Earth, about 4 billion years ago. For about 3 billion years, most organisms were microscopic, and bacteria and archaea were the dominant forms of life. Although bacterial fossils exist, such as stromatolites, their lack of distinctive morphology prevents them from being used to examine the history of bacterial evolution, or to date the time of origin of a particular bacterial species. However, gene sequences can be used to reconstruct the bacterial phylogeny, and these studies indicate that bacteria diverged first from the archaeal/eukaryotic lineage. The most recent common ancestor of bacteria and archaea was probably a hyperthermophile that lived about 2.5 billion–3.2 billion years ago. The earliest life on land may have been bacteria some 3.22 billion years ago.Bacteria were also involved in the second great evolutionary divergence, that of the archaea and eukaryotes. Here, eukaryotes resulted from the entering of ancient bacteria into endosymbiotic associations with the ancestors of eukaryotic cells, which were themselves possibly related to the Archaea. This involved the engulfment by proto-eukaryotic cells of alphaproteobacterial symbionts to form either mitochondria or hydrogenosomes, which are still found in all known Eukarya (sometimes in highly reduced form, e.g. in ancient ""amitochondrial"" protozoa). Later, some eukaryotes that already contained mitochondria also engulfed cyanobacteria-like organisms, leading to the formation of chloroplasts in algae and plants. This is known as primary endosymbiosis.  Habitat  Bacteria are ubiquitous, living in every possible habitat on the planet including soil, underwater, deep in Earth\'s crust and even such extreme environments as acidic hot springs and radioactive waste. There are approximately 2×1030 bacteria on Earth, forming a biomass that is only exceeded by plants. They are abundant in lakes and oceans, in arctic ice, and geothermal springs where they provide the nutrients needed to sustain life by converting dissolved compounds, such as hydrogen sulphide and methane, to energy. They live on and in plants and animals. Most do not cause diseases, are beneficial to their environments, and are essential for life. The soil is a rich source of bacteria and a few grams contain around a thousand million of them. They are all essential to soil ecology, breaking down toxic waste and recycling nutrients. They are even found in the atmosphere and one cubic metre of air holds around one hundred million bacterial cells. The oceans and seas harbour around 3 x 1026 bacteria which provide up to 50% of the oxygen humans breathe. Only around 2% of bacterial species have been fully studied.  Morphology  Size. Bacteria display a wide diversity of shapes and sizes. Bacterial cells are about one-tenth the size of eukaryotic cells and are typically 0.5–5.0 micrometres in length. However, a few species are visible to the unaided eye—for example, Thiomargarita namibiensis is up to half a millimetre long, Epulopiscium fishelsoni reaches 0.7 mm, and Thiomargarita magnifica can reach even 2 cm in length, which is 50 times larger than other known bacteria. Among the smallest bacteria are members of the genus Mycoplasma, which measure only 0.3 micrometres, as small as the largest viruses. Some bacteria may be even smaller, but these ultramicrobacteria are not well-studied.Shape. Most bacterial species are either spherical, called cocci (singular coccus, from Greek kókkos, grain, seed), or rod-shaped, called bacilli (sing. bacillus, from Latin baculus, stick). Some bacteria, called vibrio, are shaped like slightly curved rods or comma-shaped; others can be spiral-shaped, called spirilla, or tightly coiled, called spirochaetes. A small number of other unusual shapes have been described, such as star-shaped bacteria. This wide variety of shapes is determined by the bacterial cell wall and cytoskeleton and is important because it can influence the ability of bacteria to acquire nutrients, attach to surfaces, swim through liquids and escape predators. Multicellularity. Most bacterial species exist as single cells; others associate in characteristic patterns: Neisseria forms diploids (pairs), streptococci form chains, and staphylococci group together in ""bunch of grapes"" clusters. Bacteria can also group to form larger multicellular structures, such as the elongated filaments of Actinomycetota species, the aggregates of Myxobacteria species, and the complex hyphae of Streptomyces species. These multicellular structures are often only seen in certain conditions. For example, when starved of amino acids, myxobacteria detect surrounding cells in a process known as quorum sensing, migrate towards each other, and aggregate to form fruiting bodies up to 500 micrometres long and containing approximately 100,000 bacterial cells. In these fruiting bodies, the bacteria perform separate tasks; for example, about one in ten cells migrate to the top of a fruiting body and differentiate into a specialised dormant state called a myxospore, which is more resistant to drying and other adverse environmental conditions.Biofilms. Bacteria often attach to surfaces and form dense aggregations called biofilms, and larger formations known as microbial mats. These biofilms and mats can range from a few micrometres in thickness to up to half a metre in depth, and may contain multiple species of bacteria, protists and archaea. Bacteria living in biofilms display a complex arrangement of cells and extracellular components, forming secondary structures, such as microcolonies, through which there are networks of channels to enable better diffusion of nutrients. In natural environments, such as soil or the surfaces of plants, the majority of bacteria are bound to surfaces in biofilms. Biofilms are also important in medicine, as these structures are often present during chronic bacterial infections or in infections of implanted medical devices, and bacteria protected within biofilms are much harder to kill than individual isolated bacteria.  Cellular structure   Intracellular structures  The bacterial cell is surrounded by a cell membrane, which is made primarily of phospholipids. This membrane encloses the contents of the cell and acts as a barrier to hold nutrients, proteins and other essential components of the cytoplasm within the cell. Unlike eukaryotic cells, bacteria usually lack large membrane-bound structures in their cytoplasm such as a nucleus, mitochondria, chloroplasts and the other organelles present in eukaryotic cells. However, some bacteria have protein-bound organelles in the cytoplasm which compartmentalize aspects of bacterial metabolism, such as the carboxysome. Additionally, bacteria have a multi-component cytoskeleton to control the localisation of proteins and nucleic acids within the cell, and to manage the process of cell division.Many important biochemical reactions, such as energy generation, occur due to concentration gradients across membranes, creating a potential difference analogous to a battery. The general lack of internal membranes in bacteria means these reactions, such as electron transport, occur across the cell membrane between the cytoplasm and the outside of the cell or periplasm. However, in many photosynthetic bacteria, the plasma membrane is highly folded and fills most of the cell with layers of light-gathering membrane. These light-gathering complexes may even form lipid-enclosed structures called chlorosomes in green sulfur bacteria. Bacteria do not have a membrane-bound nucleus, and their genetic material is typically a single circular bacterial chromosome of DNA located in the cytoplasm in an irregularly shaped body called the nucleoid. The nucleoid contains the chromosome with its associated proteins and RNA. Like all other organisms, bacteria contain ribosomes for the production of proteins, but the structure of the bacterial ribosome is different from that of eukaryotes and archaea.Some bacteria produce intracellular nutrient storage granules, such as glycogen, polyphosphate, sulfur or polyhydroxyalkanoates. Bacteria such as the photosynthetic cyanobacteria, produce internal gas vacuoles, which they use to regulate their buoyancy, allowing them to move up or down into water layers with different light intensities and nutrient levels.  Extracellular structures  Around the outside of the cell membrane is the cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi, which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of achaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, and the antibiotic penicillin (produced by a fungus called Penicillium) is able to kill bacteria by inhibiting a step in the synthesis of peptidoglycan.There are broadly speaking two different types of cell wall in bacteria, that classify bacteria into Gram-positive bacteria and Gram-negative bacteria. The names originate from the reaction of cells to the Gram stain, a long-standing test for the classification of bacterial species.Gram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. In contrast, Gram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the Gram-negative cell wall, and only members of the Bacillota group and actinomycetota (previously known as the low G+C and high G+C Gram-positive bacteria, respectively) have the alternative Gram-positive arrangement. These differences in structure can produce differences in antibiotic susceptibility; for instance, vancomycin can kill only Gram-positive bacteria and is ineffective against Gram-negative pathogens, such as Haemophilus influenzae or Pseudomonas aeruginosa. Some bacteria have cell wall structures that are neither classically Gram-positive or Gram-negative. This includes clinically important bacteria such as mycobacteria which have a thick peptidoglycan cell wall like a Gram-positive bacterium, but also a second outer layer of lipids.In many bacteria, an S-layer of rigidly arrayed protein molecules covers the outside of the cell. This layer provides chemical and physical protection for the cell surface and can act as a macromolecular diffusion barrier. S-layers have diverse functions and are known to act as virulence factors in Campylobacter species and contain surface enzymes in Bacillus stearothermophilus. Flagella are rigid protein structures, about 20 nanometres in diameter and up to 20 micrometres in length, that are used for motility. Flagella are driven by the energy released by the transfer of ions down an electrochemical gradient across the cell membrane.Fimbriae (sometimes called ""attachment pili"") are fine filaments of protein, usually 2–10 nanometres in diameter and up to several micrometres in length. They are distributed over the surface of the cell, and resemble fine hairs when seen under the electron microscope. Fimbriae are believed to be involved in attachment to solid surfaces or to other cells, and are essential for the virulence of some bacterial pathogens. Pili (sing. pilus) are cellular appendages, slightly larger than fimbriae, that can transfer genetic material between bacterial cells in a process called conjugation where they are called conjugation pili or sex pili (see bacterial genetics, below). They can also generate movement where they are called type IV pili.Glycocalyx is produced by many bacteria to surround their cells, and varies in structural complexity: ranging from a disorganised slime layer of extracellular polymeric substances to a highly structured capsule. These structures can protect cells from engulfment by eukaryotic cells such as macrophages (part of the human immune system). They can also act as antigens and be involved in cell recognition, as well as aiding attachment to surfaces and the formation of biofilms.The assembly of these extracellular structures is dependent on bacterial secretion systems. These transfer proteins from the cytoplasm into the periplasm or into the environment around the cell. Many types of secretion systems are known and these structures are often essential for the virulence of pathogens, so are intensively studied.  Endospores  Some genera of Gram-positive bacteria, such as Bacillus, Clostridium, Sporohalobacter, Anaerobacter, and Heliobacterium, can form highly resistant, dormant structures called endospores. Endospores develop within the cytoplasm of the cell; generally, a single endospore develops in each cell. Each endospore contains a core of DNA and ribosomes surrounded by a cortex layer and protected by a multilayer rigid coat composed of peptidoglycan and a variety of proteins.Endospores show no detectable metabolism and can survive extreme physical and chemical stresses, such as high levels of UV light, gamma radiation, detergents, disinfectants, heat, freezing, pressure, and desiccation. In this dormant state, these organisms may remain viable for millions of years. Endospores even allow bacteria to survive exposure to the vacuum and radiation of outer space, leading to the possibility that bacteria could be distributed throughout the Universe by space dust, meteoroids, asteroids, comets, planetoids, or directed panspermia.Endospore-forming bacteria can cause disease; for example, anthrax can be contracted by the inhalation of Bacillus anthracis endospores, and contamination of deep puncture wounds with Clostridium tetani endospores causes tetanus, which, like botulism, is caused by a toxin released by the bacteria that grow from the spores. Clostridioides difficile infection, a common problem in healthcare settings, is caused by spore-forming bacteria.  Metabolism  Bacteria exhibit an extremely wide variety of metabolic types. The distribution of metabolic traits within a group of bacteria has traditionally been used to define their taxonomy, but these traits often do not correspond with modern genetic classifications. Bacterial metabolism is classified into nutritional groups on the basis of three major criteria: the source of energy, the electron donors used, and the source of carbon used for growth.Phototrophic bacteria derive energy from light using photosynthesis, while chemotrophic bacteria breaking down chemical compounds through oxidation, driving metabolism by transferring electrons from a given electron donor to a terminal electron acceptor in a redox reaction. Chemotrophs are further divided by the types of compounds they use to transfer electrons. Bacteria that derive electrons from inorganic compounds such as hydrogen, carbon monoxide, or ammonia are called lithotrophs, while those that use organic compounds are called organotrophs. Still, more specifically, aerobic organisms use oxygen as the terminal electron acceptor, while anaerobic organisms use other compounds such as nitrate, sulfate, or carbon dioxide.Many bacteria, called heterotrophs, derive their carbon from other organic carbon. Others, such as cyanobacteria and some purple bacteria, are autotrophic, meaning they obtain cellular carbon by fixing carbon dioxide. In unusual circumstances, the gas methane can be used by methanotrophic bacteria as both a source of electrons and a substrate for carbon anabolism. In many ways, bacterial metabolism provides traits that are useful for ecological stability and for human society. For example, diazotrophs have the ability to fix nitrogen gas using the enzyme nitrogenase. This trait, which can be found in bacteria of most metabolic types listed above, leads to the ecologically important processes of denitrification, sulfate reduction, and acetogenesis, respectively. Bacterial metabolic processes are important drivers in biological responses to pollution; for example, sulfate-reducing bacteria are largely responsible for the production of the highly toxic forms of mercury (methyl- and dimethylmercury) in the environment. Nonrespiratory anaerobes use fermentation to generate energy and reducing power, secreting metabolic by-products (such as ethanol in brewing) as waste. Facultative anaerobes can switch between fermentation and different terminal electron acceptors depending on the environmental conditions in which they find themselves.  Growth and reproduction  Unlike in multicellular organisms, increases in cell size (cell growth) and reproduction by cell division are tightly linked in unicellular organisms. Bacteria grow to a fixed size and then reproduce through binary fission, a form of asexual reproduction. Under optimal conditions, bacteria can grow and divide extremely rapidly, and some bacterial populations can double as quickly as every 17 minutes. In cell division, two identical clone daughter cells are produced. Some bacteria, while still reproducing asexually, form more complex reproductive structures that help disperse the newly formed daughter cells. Examples include fruiting body formation by myxobacteria and aerial hyphae formation by Streptomyces species, or budding. Budding involves a cell forming a protrusion that breaks away and produces a daughter cell.In the laboratory, bacteria are usually grown using solid or liquid media. Solid growth media, such as agar plates, are used to isolate pure cultures of a bacterial strain. However, liquid growth media are used when the measurement of growth or large volumes of cells are required. Growth in stirred liquid media occurs as an even cell suspension, making the cultures easy to divide and transfer, although isolating single bacteria from liquid media is difficult. The use of selective media (media with specific nutrients added or deficient, or with antibiotics added) can help identify specific organisms.Most laboratory techniques for growing bacteria use high levels of nutrients to produce large amounts of cells cheaply and quickly. However, in natural environments, nutrients are limited, meaning that bacteria cannot continue to reproduce indefinitely. This nutrient limitation has led the evolution of different growth strategies (see r/K selection theory). Some organisms can grow extremely rapidly when nutrients become available, such as the formation of algal and cyanobacterial blooms that often occur in lakes during the summer. Other organisms have adaptations to harsh environments, such as the production of multiple antibiotics by Streptomyces that inhibit the growth of competing microorganisms. In nature, many organisms live in communities (e.g., biofilms) that may allow for increased supply of nutrients and protection from environmental stresses. These relationships can be essential for growth of a particular organism or group of organisms (syntrophy).Bacterial growth follows four phases. When a population of bacteria first enter a high-nutrient environment that allows growth, the cells need to adapt to their new environment. The first phase of growth is the lag phase, a period of slow growth when the cells are adapting to the high-nutrient environment and preparing for fast growth. The lag phase has high biosynthesis rates, as proteins necessary for rapid growth are produced. The second phase of growth is the logarithmic phase, also known as the exponential phase. The log phase is marked by rapid exponential growth. The rate at which cells grow during this phase is known as the growth rate (k), and the time it takes the cells to double is known as the generation time (g). During log phase, nutrients are metabolised at maximum speed until one of the nutrients is depleted and starts limiting growth. The third phase of growth is the stationary phase and is caused by depleted nutrients. The cells reduce their metabolic activity and consume non-essential cellular proteins. The stationary phase is a transition from rapid growth to a stress response state and there is increased expression of genes involved in DNA repair, antioxidant metabolism and nutrient transport. The final phase is the death phase where the bacteria run out of nutrients and die.  Genetics  Most bacteria have a single circular chromosome that can range in size from only 160,000 base pairs in the endosymbiotic bacteria Carsonella ruddii, to 12,200,000 base pairs (12.2 Mbp) in the soil-dwelling bacteria Sorangium cellulosum. There are many exceptions to this; for example, some Streptomyces and Borrelia species contain a single linear chromosome, while some Vibrio species contain more than one chromosome. Some bacteria contain plasmids, small extra-chromosomal molecules of DNA that may contain genes for various useful functions such as antibiotic resistance, metabolic capabilities, or various virulence factors.Bacteria genomes usually encode a few hundred to a few thousand genes. The genes in bacterial genomes are usually a single continuous stretch of DNA. Although several different types of introns do exist in bacteria, these are much rarer than in eukaryotes.Bacteria, as asexual organisms, inherit an identical copy of the parent\'s genome and are clonal. However, all bacteria can evolve by selection on changes to their genetic material DNA caused by genetic recombination or mutations. Mutations arise from errors made during the replication of DNA or from exposure to mutagens. Mutation rates vary widely among different species of bacteria and even among different clones of a single species of bacteria. Genetic changes in bacterial genomes emerge from either random mutation during replication or ""stress-directed mutation"", where genes involved in a particular growth-limiting process have an increased mutation rate.Some bacteria transfer genetic material between cells. This can occur in three main ways. First, bacteria can take up exogenous DNA from their environment in a process called transformation. Many bacteria can naturally take up DNA from the environment, while others must be chemically altered in order to induce them to take up DNA. The development of competence in nature is usually associated with stressful environmental conditions and seems to be an adaptation for facilitating repair of DNA damage in recipient cells. Second, bacteriophages can integrate into the bacterial chromosome, introducing foreign DNA in a process known as transduction. Many types of bacteriophage exist; some infect and lyse their host bacteria, while others insert into the bacterial chromosome. Bacteria resist phage infection through restriction modification systems that degrade foreign DNA, and a system that uses CRISPR sequences to retain fragments of the genomes of phage that the bacteria have come into contact with in the past, which allows them to block virus replication through a form of RNA interference. Third, bacteria can transfer genetic material through direct cell contact via conjugation.In ordinary circumstances, transduction, conjugation, and transformation involve transfer of DNA between individual bacteria of the same species, but occasionally transfer may occur between individuals of different bacterial species, and this may have significant consequences, such as the transfer of antibiotic resistance. In such cases, gene acquisition from other bacteria or the environment is called horizontal gene transfer and may be common under natural conditions.  Behaviour   Movement  Many bacteria are motile (able to move themselves) and do so using a variety of mechanisms. The best studied of these are flagella, long filaments that are turned by a motor at the base to generate propeller-like movement. The bacterial flagellum is made of about 20 proteins, with approximately another 30 proteins required for its regulation and assembly. The flagellum is a rotating structure driven by a reversible motor at the base that uses the electrochemical gradient across the membrane for power. Bacteria can use flagella in different ways to generate different kinds of movement. Many bacteria (such as E. coli) have two distinct modes of movement: forward movement (swimming) and tumbling. The tumbling allows them to reorient and makes their movement a three-dimensional random walk. Bacterial species differ in the number and arrangement of flagella on their surface; some have a single flagellum (monotrichous), a flagellum at each end (amphitrichous), clusters of flagella at the poles of the cell (lophotrichous), while others have flagella distributed over the entire surface of the cell (peritrichous). The flagella of a unique group of bacteria, the spirochaetes, are found between two membranes in the periplasmic space. They have a distinctive helical body that twists about as it moves.Two other types of bacterial motion are called twitching motility that relies on a structure called the type IV pilus, and gliding motility, that uses other mechanisms. In twitching motility, the rod-like pilus extends out from the cell, binds some substrate, and then retracts, pulling the cell forward.Motile bacteria are attracted or repelled by certain stimuli in behaviours called taxes: these include chemotaxis, phototaxis, energy taxis, and magnetotaxis. In one peculiar group, the myxobacteria, individual bacteria move together to form waves of cells that then differentiate to form fruiting bodies containing spores. The myxobacteria move only when on solid surfaces, unlike E. coli, which is motile in liquid or solid media.Several Listeria and Shigella species move inside host cells by usurping the cytoskeleton, which is normally used to move organelles inside the cell. By promoting actin polymerisation at one pole of their cells, they can form a kind of tail that pushes them through the host cell\'s cytoplasm.  Communication  A few bacteria have chemical systems that generate light. This bioluminescence often occurs in bacteria that live in association with fish, and the light probably serves to attract fish or other large animals.Bacteria often function as multicellular aggregates known as biofilms, exchanging a variety of molecular signals for intercell communication and engaging in coordinated multicellular behaviour.The communal benefits of multicellular cooperation include a cellular division of labour, accessing resources that cannot effectively be used by single cells, collectively defending against antagonists, and optimising population survival by differentiating into distinct cell types. For example, bacteria in biofilms can have more than five hundred times increased resistance to antibacterial agents than individual ""planktonic"" bacteria of the same species.One type of intercellular communication by a molecular signal is called quorum sensing, which serves the purpose of determining whether the local population density is sufficient to support investment in processes that are only successful if large numbers of similar organisms behave similarly, such as excreting digestive enzymes or emitting light. Quorum sensing enables bacteria to coordinate gene expression and to produce, release, and detect autoinducers or pheromones that accumulate with the growth in cell population.  Classification and identification  Classification seeks to describe the diversity of bacterial species by naming and grouping organisms based on similarities. Bacteria can be classified on the basis of cell structure, cellular metabolism or on differences in cell components, such as DNA, fatty acids, pigments, antigens and quinones. While these schemes allowed the identification and classification of bacterial strains, it was unclear whether these differences represented variation between distinct species or between strains of the same species. This uncertainty was due to the lack of distinctive structures in most bacteria, as well as lateral gene transfer between unrelated species. Due to lateral gene transfer, some closely related bacteria can have very different morphologies and metabolisms. To overcome this uncertainty, modern bacterial classification emphasises molecular systematics, using genetic techniques such as guanine cytosine ratio determination, genome-genome hybridisation, as well as sequencing genes that have not undergone extensive lateral gene transfer, such as the rRNA gene. Classification of bacteria is determined by publication in the International Journal of Systematic Bacteriology, and Bergey\'s Manual of Systematic Bacteriology. The International Committee on Systematic Bacteriology (ICSB) maintains international rules for the naming of bacteria and taxonomic categories and for the ranking of them in the International Code of Nomenclature of Bacteria.Historically, bacteria were considered a part of the Plantae, the Plant kingdom, and were called ""Schizomycetes"" (fission-fungi). For this reason, collective bacteria and other microorganisms in a host are often called ""flora"". The term ""bacteria"" was traditionally applied to all microscopic, single-cell prokaryotes. However, molecular systematics showed prokaryotic life to consist of two separate domains, originally called Eubacteria and Archaebacteria, but now called Bacteria and Archaea that evolved independently from an ancient common ancestor. The archaea and eukaryotes are more closely related to each other than either is to the bacteria. These two domains, along with Eukarya, are the basis of the three-domain system, which is currently the most widely used classification system in microbiology. However, due to the relatively recent introduction of molecular systematics and a rapid increase in the number of genome sequences that are available, bacterial classification remains a changing and expanding field. For example, Cavalier-Smith argued that the Archaea and Eukaryotes evolved from Gram-positive bacteria.The identification of bacteria in the laboratory is particularly relevant in medicine, where the correct treatment is determined by the bacterial species causing an infection. Consequently, the need to identify human pathogens was a major impetus for the development of techniques to identify bacteria.The Gram stain, developed in 1884 by Hans Christian Gram, characterises bacteria based on the structural characteristics of their cell walls. The thick layers of peptidoglycan in the ""Gram-positive"" cell wall stain purple, while the thin ""Gram-negative"" cell wall appears pink. By combining morphology and Gram-staining, most bacteria can be classified as belonging to one of four groups (Gram-positive cocci, Gram-positive bacilli, Gram-negative cocci and Gram-negative bacilli). Some organisms are best identified by stains other than the Gram stain, particularly mycobacteria or Nocardia, which show acid fastness on Ziehl–Neelsen or similar stains. Other organisms may need to be identified by their growth in special media, or by other techniques, such as serology.Culture techniques are designed to promote the growth and identify particular bacteria while restricting the growth of the other bacteria in the sample. Often these techniques are designed for specific specimens; for example, a sputum sample will be treated to identify organisms that cause pneumonia, while stool specimens are cultured on selective media to identify organisms that cause diarrhea while preventing growth of non-pathogenic bacteria. Specimens that are normally sterile, such as blood, urine or spinal fluid, are cultured under conditions designed to grow all possible organisms. Once a pathogenic organism has been isolated, it can be further characterised by its morphology, growth patterns (such as aerobic or anaerobic growth), patterns of hemolysis, and staining.As with bacterial classification, identification of bacteria is increasingly using molecular methods, and mass spectroscopy. Most bacteria have not been characterised and there are many species that cannot be grown in the laboratory. Diagnostics using DNA-based tools, such as polymerase chain reaction, are increasingly popular due to their specificity and speed, compared to culture-based methods. These methods also allow the detection and identification of ""viable but nonculturable"" cells that are metabolically active but non-dividing. However, even using these improved methods, the total number of bacterial species is not known and cannot even be estimated with any certainty. Following present classification, there are a little less than 9,300 known species of prokaryotes, which includes bacteria and archaea; but attempts to estimate the true number of bacterial diversity have ranged from 107 to 109 total species—and even these diverse estimates may be off by many orders of magnitude.  Phyla  The following phyla have been validly published according to the Bacteriological Code:  Interactions with other organisms  Despite their apparent simplicity, bacteria can form complex associations with other organisms. These symbiotic associations can be divided into parasitism, mutualism and commensalism.  Commensals  The word ""commensalism"" is derived from the word ""commensal"", meaning ""eating at the same table"" and all plants and animals are colonised by commensal bacteria. In humans and other animals, millions of them live on the skin, the airways, the gut and other orifices. Referred to as ""normal flora"", or ""commensals"", these bacteria usually cause no harm but may occasionally invade other sites of the body and cause infection. Escherichia coli is a commensal in the human gut but can cause urinary tract infections. Similarly, streptococci, which are part of the normal flora of the human mouth, can cause heart disease.  Predators  Some species of bacteria kill and then consume other microorganisms, these species are called predatory bacteria. These include organisms such as Myxococcus xanthus, which forms swarms of cells that kill and digest any bacteria they encounter. Other bacterial predators either attach to their prey in order to digest them and absorb nutrients or invade another cell and multiply inside the cytosol. These predatory bacteria are thought to have evolved from saprophages that consumed dead microorganisms, through adaptations that allowed them to entrap and kill other organisms.  Mutualists  Certain bacteria form close spatial associations that are essential for their survival. One such mutualistic association, called interspecies hydrogen transfer, occurs between clusters of anaerobic bacteria that consume organic acids, such as butyric acid or propionic acid, and produce hydrogen, and methanogenic archaea that consume hydrogen. The bacteria in this association are unable to consume the organic acids as this reaction produces hydrogen that accumulates in their surroundings. Only the intimate association with the hydrogen-consuming archaea keeps the hydrogen concentration low enough to allow the bacteria to grow.In soil, microorganisms that reside in the rhizosphere (a zone that includes the root surface and the soil that adheres to the root after gentle shaking) carry out nitrogen fixation, converting nitrogen gas to nitrogenous compounds. This serves to provide an easily absorbable form of nitrogen for many plants, which cannot fix nitrogen themselves. Many other bacteria are found as symbionts in humans and other organisms. For example, the presence of over 1,000 bacterial species in the normal human gut flora of the intestines can contribute to gut immunity, synthesise vitamins, such as folic acid, vitamin K and biotin, convert sugars to lactic acid (see Lactobacillus), as well as fermenting complex undigestible carbohydrates. The presence of this gut flora also inhibits the growth of potentially pathogenic bacteria (usually through competitive exclusion) and these beneficial bacteria are consequently sold as probiotic dietary supplements.Nearly all animal life is dependent on bacteria for survival as only bacteria and some archaea possess the genes and enzymes necessary to synthesize vitamin B12, also known as cobalamin, and provide it through the food chain. Vitamin B12 is a water-soluble vitamin that is involved in the metabolism of every cell of the human body. It is a cofactor in DNA synthesis and in both fatty acid and amino acid metabolism. It is particularly important in the normal functioning of the nervous system via its role in the synthesis of myelin.  Pathogens  The body is continually exposed to many species of bacteria, including beneficial commensals, which grow on the skin and mucous membranes, and saprophytes, which grow mainly in the soil and in decaying matter. The blood and tissue fluids contain nutrients sufficient to sustain the growth of many bacteria. The body has defence mechanisms that enable it to resist microbial invasion of its tissues and give it a natural immunity or innate resistance against many microorganisms. Unlike some viruses, bacteria evolve relatively slowly so many bacterial diseases also occur in other animals.If bacteria form a parasitic association with other organisms, they are classed as pathogens. Pathogenic bacteria are a major cause of human death and disease and cause infections such as tetanus (caused by Clostridium tetani), typhoid fever, diphtheria, syphilis, cholera, foodborne illness, leprosy (caused by Mycobacterium leprae) and tuberculosis (caused by Mycobacterium tuberculosis). A pathogenic cause for a known medical disease may only be discovered many years later, as was the case with Helicobacter pylori and peptic ulcer disease. Bacterial diseases are also important in agriculture, and bacteria cause leaf spot, fire blight and wilts in plants, as well as Johne\'s disease, mastitis, salmonella and anthrax in farm animals. Each species of pathogen has a characteristic spectrum of interactions with its human hosts. Some organisms, such as Staphylococcus or Streptococcus, can cause skin infections, pneumonia, meningitis and sepsis, a systemic inflammatory response producing shock, massive vasodilation and death. Yet these organisms are also part of the normal human flora and usually exist on the skin or in the nose without causing any disease at all. Other organisms invariably cause disease in humans, such as Rickettsia, which are obligate intracellular parasites able to grow and reproduce only within the cells of other organisms. One species of Rickettsia causes typhus, while another causes Rocky Mountain spotted fever. Chlamydia, another phylum of obligate intracellular parasites, contains species that can cause pneumonia or urinary tract infection and may be involved in coronary heart disease. Some species, such as Pseudomonas aeruginosa, Burkholderia cenocepacia, and Mycobacterium avium, are opportunistic pathogens and cause disease mainly in people who are immunosuppressed or have cystic fibrosis. Some bacteria produce toxins, which cause diseases. These are endotoxins, which come from broken bacterial cells, and exotoxins, which are produced by bacteria and released into the environment. The bacterium Clostridium botulinum for example, produces a powerful exotoxin that cause respiratory paralysis, and Salmonellae produce an endotoxin that causes gastroenteritis. Some exotoxins can be converted to toxoids, which are used as vaccines to prevent the disease.Bacterial infections may be treated with antibiotics, which are classified as bacteriocidal if they kill bacteria or bacteriostatic if they just prevent bacterial growth. There are many types of antibiotics, and each class inhibits a process that is different in the pathogen from that found in the host. An example of how antibiotics produce selective toxicity are chloramphenicol and puromycin, which inhibit the bacterial ribosome, but not the structurally different eukaryotic ribosome. Antibiotics are used both in treating human disease and in intensive farming to promote animal growth, where they may be contributing to the rapid development of antibiotic resistance in bacterial populations. Infections can be prevented by antiseptic measures such as sterilising the skin prior to piercing it with the needle of a syringe, and by proper care of indwelling catheters. Surgical and dental instruments are also sterilised to prevent contamination by bacteria. Disinfectants such as bleach are used to kill bacteria or other pathogens on surfaces to prevent contamination and further reduce the risk of infection.  Significance in technology and industry  Bacteria, often lactic acid bacteria, such as Lactobacillus species and Lactococcus species, in combination with yeasts and moulds, have been used for thousands of years in the preparation of fermented foods, such as cheese, pickles, soy sauce, sauerkraut, vinegar, wine, and yogurt.The ability of bacteria to degrade a variety of organic compounds is remarkable and has been used in waste processing and bioremediation. Bacteria capable of digesting the hydrocarbons in petroleum are often used to clean up oil spills. Fertiliser was added to some of the beaches in Prince William Sound in an attempt to promote the growth of these naturally occurring bacteria after the 1989 Exxon Valdez oil spill. These efforts were effective on beaches that were not too thickly covered in oil. Bacteria are also used for the bioremediation of industrial toxic wastes. In the chemical industry, bacteria are most important in the production of enantiomerically pure chemicals for use as pharmaceuticals or agrichemicals.Bacteria can also be used in place of pesticides in biological pest control. This commonly involves Bacillus thuringiensis (also called BT), a Gram-positive, soil-dwelling bacterium. Subspecies of this bacteria are used as Lepidopteran-specific insecticides under trade names such as Dipel and Thuricide. Because of their specificity, these pesticides are regarded as environmentally friendly, with little or no effect on humans, wildlife, pollinators, and most other beneficial insects.Because of their ability to quickly grow and the relative ease with which they can be manipulated, bacteria are the workhorses for the fields of molecular biology, genetics, and biochemistry. By making mutations in bacterial DNA and examining the resulting phenotypes, scientists can determine the function of genes, enzymes, and metabolic pathways in bacteria, then apply this knowledge to more complex organisms. This aim of understanding the biochemistry of a cell reaches its most complex expression in the synthesis of huge amounts of enzyme kinetic and gene expression data into mathematical models of entire organisms. This is achievable in some well-studied bacteria, with models of Escherichia coli metabolism now being produced and tested. This understanding of bacterial metabolism and genetics allows the use of biotechnology to bioengineer bacteria for the production of therapeutic proteins, such as insulin, growth factors, or antibodies.Because of their importance for research in general, samples of bacterial strains are isolated and preserved in Biological Resource Centers. This ensures the availability of the strain to scientists worldwide.  History of bacteriology  Bacteria were first observed by the Dutch microscopist Antonie van Leeuwenhoek in 1676, using a single-lens microscope of his own design. He then published his observations in a series of letters to the Royal Society of London. Bacteria were Leeuwenhoek\'s most remarkable microscopic discovery. Their size was just at the limit of what his simple lenses could resolve, and, in one of the most striking hiatuses in the history of science, no one else would see them again for over a century. His observations also included protozoans which he called animalcules, and his findings were looked at again in the light of the more recent findings of cell theory.Christian Gottfried Ehrenberg introduced the word ""bacterium"" in 1828. In fact, his Bacterium was a genus that contained non-spore-forming rod-shaped bacteria, as opposed to Bacillus, a genus of spore-forming rod-shaped bacteria defined by Ehrenberg in 1835.Louis Pasteur demonstrated in 1859 that the growth of microorganisms causes the fermentation process and that this growth is not due to spontaneous generation (yeasts and molds, commonly associated with fermentation, are not bacteria, but rather fungi). Along with his contemporary Robert Koch, Pasteur was an early advocate of the germ theory of disease. Before them, Ignaz Semmelweis and Joseph Lister had realised the importance of sanitized hands in medical work. Semmelweis, who in the 1840s formulated his rules for handwashing in the hospital, prior to the advent of germ theory, attributed disease to ""decomposing animal organic matter."" His ideas were rejected and his book on the topic condemned by the medical community. After Lister, however, doctors started sanitizing their hands in the 1870s.Robert Koch, a pioneer in medical microbiology, worked on cholera, anthrax and tuberculosis. In his research into tuberculosis, Koch finally proved the germ theory, for which he received a Nobel Prize in 1905. In Koch\'s postulates, he set out criteria to test if an organism is the cause of a disease, and these postulates are still used today.Ferdinand Cohn is said to be a founder of bacteriology, studying bacteria from 1870. Cohn was the first to classify bacteria based on their morphology.Though it was known in the nineteenth century that bacteria are the cause of many diseases, no effective antibacterial treatments were available. In 1910, Paul Ehrlich developed the first antibiotic, by changing dyes that selectively stained Treponema pallidum—the spirochaete that causes syphilis—into compounds that selectively killed the pathogen. Ehrlich, who had been awarded a 1908 Nobel Prize for his work on immunology, pioneered the use of stains to detect and identify bacteria, with his work being the basis of the Gram stain and the Ziehl–Neelsen stain.A major step forward in the study of bacteria came in 1977 when Carl Woese recognised that archaea have a separate line of evolutionary descent from bacteria. This new phylogenetic taxonomy depended on the sequencing of 16S ribosomal RNA and divided prokaryotes into two evolutionary domains, as part of the three-domain system.","Bacteria (singular: bacterium) are very small organisms. They are prokaryotic microorganisms. Bacterial cells do not have a nucleus, and most have no organelles with membranes around them. Most have a cell wall. They do have DNA, and their biochemistry is basically the same as other living things. They are amongst the simplest and the oldest organisms. Almost all bacteria are so tiny they can only be seen through a microscope. Bacteria are made up of one cell, so they are a kind of unicellular organism. They were one of the earliest forms of life, and are simple single-celled organisms. They include extremophiles, which live in extreme habitats. There are probably more individual bacteria than any other sort of organism on the planet, except viruses. Most bacteria live in the ground or in water, but many live inside or on the skin of other organisms, including humans. There are about as many bacterial cells as human cells in each of our bodies. Some bacteria cause diseases, but others help us in everyday activities like digesting food (gut flora). Some we use in factories to make cheese and yogurt. The founder of bacteriology was a German biologist called Ferdinand Cohn (1828–1898). He published the first biological classification of bacteria, based on their appearance.  Reproduction and gene transfer  A bacterium reproduces (creates more bacteria) by dividing in half and creating two ""daughter"" cells. Each daughter is identical in shape to the parent. Bacteria do not have sexes, but they do transmit DNA by several kinds of horizontal gene transfer. This is how they share resistance to antibiotics from one strain to another. The complete DNA sequence is known for many bacterial strains. Each bacterium has only one chromosome.  Shape  Bacteria vary widely in size and shape, but in general they are at least ten times larger than viruses. A typical bacterium is about 1 µm (one micrometer) in diameter, so a thousand bacteria lined up would be one millimeter long. There are about five nonillion (5×1030) bacteria on Earth.Bacteria are identified and grouped by their shapes. Bacilli are rod-shaped, cocci are ball-shaped, spirilla are spiral-shaped, and vibrio are shaped like a comma or a boomerang.  Pathogens  Pathogenic bacteria, the harmful kind, enter the human body from the air, water or food. Once inside, these bacteria attach themselves to or invade specific cells in our respiratory system, digestive tract or in any open wound. There they begin to reproduce and spread while using your body's food and nutrients to give them energy to help them reproduce.  Extremophiles  Some bacteria are extremophiles. Some microbes thrive inside rocks up to 580 meters below the sea floor under 2.6 kilometers of ocean off the Pacific Northwest of the United States. According to one of the researchers, ""You can find microbes everywhere — they're extremely adaptable to conditions, and survive wherever they are.""  Viruses  Viruses were the first and are the most serious enemies of bacteria. Everywhere bacteria are, they get attacked by viruses. The viruses which attack bacteria are called bacteriophages. Something is now known about how bacteria protect themselves against viruses. Most bacteria have CRISPR–Cas systems as an adaptive defence against viruses. These keep sections of viral DNA. These are used to target and destroy later infections by the virus. The process is similar to RNA interference.  History of their classification  All modern ideas start with the sequence analysis of DNA and RNA. In 1987, Carl Woese, the forerunner of the molecular phylogeny revolution, divided bacteria into 11 divisions based on 16S ribosomal RNA (SSU) sequences: Proteobacteria: Purple bacteria and their relatives Alpha subdivision: purple non-sulfur bacteria, rhizobacteria, Agrobacterium, Bartonella, Rickettsiae, Nitrobacter) Beta subdivision: (Rhodocyclus, (some) Thiobacillus, Alcaligenes, Spirillum, Nitrosovibrio Gamma subdivision: enterics, fluorescent pseudomonads, purple sulfur bacteria, Legionella, (some) Beggiatoa Delta subdivision: Sulfur and sulfate reducers (Desulfovibrio), Myxobacteria, Bdellovibrio Gram-positive Eubacteria High-G+C species - Actinobacteria (Actinomyces, Streptomyces, Arthrobacter, Micrococcus, Bifidobacterium) Low-G+C species - Firmicutes (Clostridium, Peptococcus, Bacillus, Mycoplasma) Photosynthetic species (Heliobacterium) Species with gram-negative walls (Megasphaera, Sporomusa) Cyanobacteria and chloroplasts (Aphanocapsa, Oscillatoria, Nostoc, Synechococcus, Gleoebacter, Prochloron) Spirochaetes and relatives Spirochetes (Spirochaeta, Treponema, Borrelia) Leptospiras (Leptospira, Leptonema) Green sulfur bacteria (Chlorobium, Chloroherpeton) Bacteroides, Flavobacteria and relatives Bacteroides (Bacteroides, Fusobacterium) Flavobacterium group (Flavobacterium, Cytophaga, Saprospira, Flexibacter) Planctomyces and relatives Planctomyces group (Planctomyces, Pasteuria) Thermophiles (Isocystis pallida) Chlamydiae (Chlamydia psittaci, Chlamydia trachomatis) Radioresistant micrococci and relatives Deinococcus group (Deinococcus radiodurans) Thermophiles (Thermus aquaticus) Green non-sulfur bacteria and relatives Chloroflexus group (Chloroflexus, Herpetosiphon) Thermomicrobium group (Thermomicrobium roseum) Thermotogae  Related pages  Antibiotics Enterococcus Mycoplasma Microorganism Archaea Virus  References "
"An infection is the invasion of tissues by pathogens, their multiplication, and the reaction of host tissues to the infectious agent and the toxins they produce. An infectious disease, also known as a transmissible disease or communicable disease, is an illness resulting from an infection. Infections can be caused by a wide range of pathogens, most prominently bacteria and viruses. Hosts can fight infections using their immune system. Mammalian hosts react to infections with an innate response, often involving inflammation, followed by an adaptive response. Specific medications used to treat infections include antibiotics, antivirals, antifungals, antiprotozoals, and antihelminthics. Infectious diseases resulted in 9.2 million deaths in 2013 (about 17% of all deaths). The branch of medicine that focuses on infections is referred to as infectious diseases.  Types  Infections are caused by infectious agents (pathogens) including: Bacteria (e.g. Mycobacterium tuberculosis, Staphylococcus aureus, Escherichia coli, Clostridium botulinum, and Salmonella spp.) Viruses and related agents such as viroids. (E.g. HIV, Rhinovirus, Lyssaviruses such as Rabies virus, Ebolavirus and Severe acute respiratory syndrome coronavirus 2) Fungi, further subclassified into: Ascomycota, including yeasts such as Candida (the most common fungal infection); filamentous fungi such as Aspergillus; Pneumocystis species; and dermatophytes, a group of organisms causing infection of skin and other superficial structures in humans. Basidiomycota, including the human-pathogenic genus Cryptococcus. Parasites, which are usually divided into:Unicellular organisms (e.g. malaria, Toxoplasma, Babesia) Macroparasites (worms or helminths) including nematodes such as parasitic roundworms and pinworms, tapeworms (cestodes), and flukes (trematodes, such as schistosomes). Diseases caused by helminths are sometimes termed infestations, but are sometimes called infections. Arthropods such as ticks, mites, fleas, and lice, can also cause human disease, which conceptually are similar to infections, but invasion of a human or animal body by these macroparasites is usually termed infestation. Prions (although they do not secrete toxins)  Signs and symptoms  The signs and symptoms of an infection depend on the type of disease. Some signs of infection affect the whole body generally, such as fatigue, loss of appetite, weight loss, fevers, night sweats, chills, aches and pains. Others are specific to individual body parts, such as skin rashes, coughing, or a runny nose.In certain cases, infectious diseases may be asymptomatic for much or even all of their course in a given host. In the latter case, the disease may only be defined as a ""disease"" (which by definition means an illness) in hosts who secondarily become ill after contact with an asymptomatic carrier. An infection is not synonymous with an infectious disease, as some infections do not cause illness in a host.  Bacterial or viral  As bacterial and viral infections can both cause the same kinds of symptoms, it can be difficult to distinguish which is the cause of a specific infection. Distinguishing the two is important, since viral infections cannot be cured by antibiotics whereas bacterial infections can.  Pathophysiology  There is a general chain of events that applies to infections, sometimes called the chain of infection. The chain of events involves several steps – which include the infectious agent, reservoir, entering a susceptible host, exit and transmission to new hosts. Each of the links must be present in a chronological order for an infection to develop. Understanding these steps helps health care workers target the infection and prevent it from occurring in the first place.  Colonization  Infection begins when an organism successfully enters the body, grows and multiplies. This is referred to as colonization. Most humans are not easily infected. Those with compromised or weakened immune systems have an increased susceptibility to chronic or persistent infections. Individuals who have a suppressed immune system are particularly susceptible to opportunistic infections. Entrance to the host at host-pathogen interface, generally occurs through the mucosa in orifices like the oral cavity, nose, eyes, genitalia, anus, or the microbe can enter through open wounds. While a few organisms can grow at the initial site of entry, many migrate and cause systemic infection in different organs. Some pathogens grow within the host cells (intracellular) whereas others grow freely in bodily fluids.Wound colonization refers to non-replicating microorganisms within the wound, while in infected wounds, replicating organisms exist and tissue is injured. All multicellular organisms are colonized to some degree by extrinsic organisms, and the vast majority of these exist in either a mutualistic or commensal relationship with the host. An example of the former is the anaerobic bacteria species, which colonizes the mammalian colon, and an example of the latter are the various species of staphylococcus that exist on human skin. Neither of these colonizations are considered infections. The difference between an infection and a colonization is often only a matter of circumstance. Non-pathogenic organisms can become pathogenic given specific conditions, and even the most virulent organism requires certain circumstances to cause a compromising infection. Some colonizing bacteria, such as Corynebacteria sp. and Viridans streptococci, prevent the adhesion and colonization of pathogenic bacteria and thus have a symbiotic relationship with the host, preventing infection and speeding wound healing. The variables involved in the outcome of a host becoming inoculated by a pathogen and the ultimate outcome include: the route of entry of the pathogen and the access to host regions that it gains the intrinsic virulence of the particular organism the quantity or load of the initial inoculant the immune status of the host being colonizedAs an example, several staphylococcal species remain harmless on the skin, but, when present in a normally sterile space, such as in the capsule of a joint or the peritoneum, multiply without resistance and cause harm.An interesting fact that gas chromatography–mass spectrometry, 16S ribosomal RNA analysis, omics, and other advanced technologies have made more apparent to humans in recent decades is that microbial colonization is very common even in environments that humans think of as being nearly sterile. Because it is normal to have bacterial colonization, it is difficult to know which chronic wounds can be classified as infected and how much risk of progression exists. Despite the huge number of wounds seen in clinical practice, there are limited quality data for evaluated symptoms and signs. A review of chronic wounds in the Journal of the American Medical Association\'s ""Rational Clinical Examination Series"" quantified the importance of increased pain as an indicator of infection. The review showed that the most useful finding is an increase in the level of pain [likelihood ratio (LR) range, 11–20] makes infection much more likely, but the absence of pain (negative likelihood ratio range, 0.64–0.88) does not rule out infection (summary LR 0.64–0.88).  Disease  Disease can arise if the host\'s protective immune mechanisms are compromised and the organism inflicts damage on the host. Microorganisms can cause tissue damage by releasing a variety of toxins or destructive enzymes. For example, Clostridium tetani releases a toxin that paralyzes muscles, and staphylococcus releases toxins that produce shock and sepsis. Not all infectious agents cause disease in all hosts. For example, less than 5% of individuals infected with polio develop disease. On the other hand, some infectious agents are highly virulent. The prion causing mad cow disease and Creutzfeldt–Jakob disease invariably kills all animals and people that are infected.Persistent infections occur because the body is unable to clear the organism after the initial infection. Persistent infections are characterized by the continual presence of the infectious organism, often as latent infection with occasional recurrent relapses of active infection. There are some viruses that can maintain a persistent infection by infecting different cells of the body. Some viruses once acquired never leave the body. A typical example is the herpes virus, which tends to hide in nerves and become reactivated when specific circumstances arise.Persistent infections cause millions of deaths globally each year. Chronic infections by parasites account for a high morbidity and mortality in many underdeveloped countries.  Transmission  For infecting organisms to survive and repeat the infection cycle in other hosts, they (or their progeny) must leave an existing reservoir and cause infection elsewhere. Infection transmission can take place via many potential routes:Droplet contact, also known as the respiratory route, and the resultant infection can be termed airborne disease. If an infected person coughs or sneezes on another person the microorganisms, suspended in warm, moist droplets, may enter the body through the nose, mouth or eye surfaces. Fecal-oral transmission, wherein foodstuffs or water become contaminated (by people not washing their hands before preparing food, or untreated sewage being released into a drinking water supply) and the people who eat and drink them become infected. Common fecal-oral transmitted pathogens include Vibrio cholerae, Giardia species, rotaviruses, Entameba histolytica, Escherichia coli, and tape worms. Most of these pathogens cause gastroenteritis. Sexual transmission, with the resulting disease being called sexually transmitted disease Oral transmission, diseases that are transmitted primarily by oral means may be caught through direct oral contact such as kissing, or by indirect contact such as by sharing a drinking glass or a cigarette. Transmission by direct contact, Some diseases that are transmissible by direct contact include athlete\'s foot, impetigo and warts. Vehicle transmission, transmission by an inanimate reservoir (food, water, soil) Vertical transmission, directly from the mother to an embryo, fetus or baby during pregnancy or childbirth. It can occur as a result of a pre-existing infection or one acquired during pregnancy. Iatrogenic transmission, due to medical procedures such as injection or transplantation of infected material. Vector-borne transmission, transmitted by a vector, which is an organism that does not cause disease itself but that transmits infection by conveying pathogens from one host to another.The relationship between virulence versus transmissibility is complex; with studies have shown that there were no clear relationship between the two. There is still a small number of evidence that partially suggests a link between virulence and transmissibility.  Diagnosis  Diagnosis of infectious disease sometimes involves identifying an infectious agent either directly or indirectly. In practice most minor infectious diseases such as warts, cutaneous abscesses, respiratory system infections and diarrheal diseases are diagnosed by their clinical presentation and treated without knowledge of the specific causative agent. Conclusions about the cause of the disease are based upon the likelihood that a patient came in contact with a particular agent, the presence of a microbe in a community, and other epidemiological considerations. Given sufficient effort, all known infectious agents can be specifically identified. The benefits of identification, however, are often greatly outweighed by the cost, as often there is no specific treatment, the cause is obvious, or the outcome of an infection is benign. Diagnosis of infectious disease is nearly always initiated by medical history and physical examination. More detailed identification techniques involve the culture of infectious agents isolated from a patient. Culture allows identification of infectious organisms by examining their microscopic features, by detecting the presence of substances produced by pathogens, and by directly identifying an organism by its genotype. Other techniques (such as X-rays, CAT scans, PET scans or NMR) are used to produce images of internal abnormalities resulting from the growth of an infectious agent. The images are useful in detection of, for example, a bone abscess or a spongiform encephalopathy produced by a prion.  Symptomatic diagnostics  The diagnosis is aided by the presenting symptoms in any individual with an infectious disease, yet it usually needs additional diagnostic techniques to confirm the suspicion. Some signs are specifically characteristic and indicative of a disease and are called pathognomonic signs; but these are rare. Not all infections are symptomatic.In children the presence of cyanosis, rapid breathing, poor peripheral perfusion, or a petechial rash increases the risk of a serious infection by greater than 5 fold. Other important indicators include parental concern, clinical instinct, and temperature greater than 40 °C.  Microbial culture  Many diagnostic approaches depend on microbiological culture to isolate a pathogen from the appropriate clinical specimen. In a microbial culture, a growth medium is provided for a specific agent. A sample taken from potentially diseased tissue or fluid is then tested for the presence of an infectious agent able to grow within that medium. Many pathogenic bacteria are easily grown on nutrient agar, a form of solid medium that supplies carbohydrates and proteins necessary for growth, along with copious amounts of water. A single bacterium will grow into a visible mound on the surface of the plate called a colony, which may be separated from other colonies or melded together into a ""lawn"". The size, color, shape and form of a colony is characteristic of the bacterial species, its specific genetic makeup (its strain), and the environment that supports its growth. Other ingredients are often added to the plate to aid in identification. Plates may contain substances that permit the growth of some bacteria and not others, or that change color in response to certain bacteria and not others. Bacteriological plates such as these are commonly used in the clinical identification of infectious bacterium. Microbial culture may also be used in the identification of viruses: the medium, in this case, being cells grown in culture that the virus can infect, and then alter or kill. In the case of viral identification, a region of dead cells results from viral growth, and is called a ""plaque"". Eukaryotic parasites may also be grown in culture as a means of identifying a particular agent.In the absence of suitable plate culture techniques, some microbes require culture within live animals. Bacteria such as Mycobacterium leprae and Treponema pallidum can be grown in animals, although serological and microscopic techniques make the use of live animals unnecessary. Viruses are also usually identified using alternatives to growth in culture or animals. Some viruses may be grown in embryonated eggs. Another useful identification method is Xenodiagnosis, or the use of a vector to support the growth of an infectious agent. Chagas disease is the most significant example, because it is difficult to directly demonstrate the presence of the causative agent, Trypanosoma cruzi in a patient, which therefore makes it difficult to definitively make a diagnosis. In this case, xenodiagnosis involves the use of the vector of the Chagas agent T. cruzi, an uninfected triatomine bug, which takes a blood meal from a person suspected of having been infected. The bug is later inspected for growth of T. cruzi within its gut.  Microscopy  Another principal tool in the diagnosis of infectious disease is microscopy. Virtually all of the culture techniques discussed above rely, at some point, on microscopic examination for definitive identification of the infectious agent. Microscopy may be carried out with simple instruments, such as the compound light microscope, or with instruments as complex as an electron microscope. Samples obtained from patients may be viewed directly under the light microscope, and can often rapidly lead to identification. Microscopy is often also used in conjunction with biochemical staining techniques, and can be made exquisitely specific when used in combination with antibody based techniques. For example, the use of antibodies made artificially fluorescent (fluorescently labeled antibodies) can be directed to bind to and identify a specific antigens present on a pathogen. A fluorescence microscope is then used to detect fluorescently labeled antibodies bound to internalized antigens within clinical samples or cultured cells. This technique is especially useful in the diagnosis of viral diseases, where the light microscope is incapable of identifying a virus directly.Other microscopic procedures may also aid in identifying infectious agents. Almost all cells readily stain with a number of basic dyes due to the electrostatic attraction between negatively charged cellular molecules and the positive charge on the dye. A cell is normally transparent under a microscope, and using a stain increases the contrast of a cell with its background. Staining a cell with a dye such as Giemsa stain or crystal violet allows a microscopist to describe its size, shape, internal and external components and its associations with other cells. The response of bacteria to different staining procedures is used in the taxonomic classification of microbes as well. Two methods, the Gram stain and the acid-fast stain, are the standard approaches used to classify bacteria and to diagnosis of disease. The Gram stain identifies the bacterial groups Bacillota and Actinomycetota, both of which contain many significant human pathogens. The acid-fast staining procedure identifies the Actinomycetota genera Mycobacterium and Nocardia.  Biochemical tests  Biochemical tests used in the identification of infectious agents include the detection of metabolic or enzymatic products characteristic of a particular infectious agent. Since bacteria ferment carbohydrates in patterns characteristic of their genus and species, the detection of fermentation products is commonly used in bacterial identification. Acids, alcohols and gases are usually detected in these tests when bacteria are grown in selective liquid or solid media.The isolation of enzymes from infected tissue can also provide the basis of a biochemical diagnosis of an infectious disease. For example, humans can make neither RNA replicases nor reverse transcriptase, and the presence of these enzymes are characteristic., of specific types of viral infections. The ability of the viral protein hemagglutinin to bind red blood cells together into a detectable matrix may also be characterized as a biochemical test for viral infection, although strictly speaking hemagglutinin is not an enzyme and has no metabolic function.Serological methods are highly sensitive, specific and often extremely rapid tests used to identify microorganisms. These tests are based upon the ability of an antibody to bind specifically to an antigen. The antigen, usually a protein or carbohydrate made by an infectious agent, is bound by the antibody. This binding then sets off a chain of events that can be visibly obvious in various ways, dependent upon the test. For example, ""Strep throat"" is often diagnosed within minutes, and is based on the appearance of antigens made by the causative agent, S. pyogenes, that is retrieved from a patient\'s throat with a cotton swab. Serological tests, if available, are usually the preferred route of identification, however the tests are costly to develop and the reagents used in the test often require refrigeration. Some serological methods are extremely costly, although when commonly used, such as with the ""strep test"", they can be inexpensive.Complex serological techniques have been developed into what are known as immunoassays. Immunoassays can use the basic antibody – antigen binding as the basis to produce an electro-magnetic or particle radiation signal, which can be detected by some form of instrumentation. Signal of unknowns can be compared to that of standards allowing quantitation of the target antigen. To aid in the diagnosis of infectious diseases, immunoassays can detect or measure antigens from either infectious agents or proteins generated by an infected organism in response to a foreign agent. For example, immunoassay A may detect the presence of a surface protein from a virus particle. Immunoassay B on the other hand may detect or measure antibodies produced by an organism\'s immune system that are made to neutralize and allow the destruction of the virus. Instrumentation can be used to read extremely small signals created by secondary reactions linked to the antibody – antigen binding. Instrumentation can control sampling, reagent use, reaction times, signal detection, calculation of results, and data management to yield a cost-effective automated process for diagnosis of infectious disease.  PCR-based diagnostics  Technologies based upon the polymerase chain reaction (PCR) method will become nearly ubiquitous gold standards of diagnostics of the near future, for several reasons. First, the catalog of infectious agents has grown to the point that virtually all of the significant infectious agents of the human population have been identified. Second, an infectious agent must grow within the human body to cause disease; essentially it must amplify its own nucleic acids in order to cause a disease. This amplification of nucleic acid in infected tissue offers an opportunity to detect the infectious agent by using PCR. Third, the essential tools for directing PCR, primers, are derived from the genomes of infectious agents, and with time those genomes will be known, if they are not already.Thus, the technological ability to detect any infectious agent rapidly and specifically are currently available. The only remaining blockades to the use of PCR as a standard tool of diagnosis are in its cost and application, neither of which is insurmountable. The diagnosis of a few diseases will not benefit from the development of PCR methods, such as some of the clostridial diseases (tetanus and botulism). These diseases are fundamentally biological poisonings by relatively small numbers of infectious bacteria that produce extremely potent neurotoxins. A significant proliferation of the infectious agent does not occur, this limits the ability of PCR to detect the presence of any bacteria.  Metagenomic sequencing  Given the wide range of bacterial, viral, fungal, protozoal, and helminthic pathogens that cause debilitating and life-threatening illnesses, the ability to quickly identify the cause of infection is important yet often challenging. For example, more than half of cases of encephalitis, a severe illness affecting the brain, remain undiagnosed, despite extensive testing using the standard of care (microbiological culture) and state-of-the-art clinical laboratory methods. Metagenomic sequencing-based diagnostic tests are currently being developed for clinical use and show promise as a sensitive, specific, and rapid way to diagnose infection using a single all-encompassing test. This test is similar to current PCR tests; however, an untargeted whole genome amplification is used rather than primers for a specific infectious agent. This amplification step is followed by next-generation sequencing or third-generation sequencing, alignment comparisons, and taxonomic classification using large databases of thousands of pathogen and commensal reference genomes. Simultaneously, antimicrobial resistance genes within pathogen and plasmid genomes are sequenced and aligned to the taxonomically classified pathogen genomes to generate an antimicrobial resistance profile – analogous to antibiotic sensitivity testing – to facilitate antimicrobial stewardship and allow for the optimization of treatment using the most effective drugs for a patient\'s infection. Metagenomic sequencing could prove especially useful for diagnosis when the patient is immunocompromised. An ever-wider array of infectious agents can cause serious harm to individuals with immunosuppression, so clinical screening must often be broader. Additionally, the expression of symptoms is often atypical, making a clinical diagnosis based on presentation more difficult. Thirdly, diagnostic methods that rely on the detection of antibodies are more likely to fail. A rapid, sensitive, specific, and untargeted test for all known human pathogens that detects the presence of the organism\'s DNA rather than antibodies is therefore highly desirable.  Indication of tests  There is usually an indication for a specific identification of an infectious agent only when such identification can aid in the treatment or prevention of the disease, or to advance knowledge of the course of an illness prior to the development of effective therapeutic or preventative measures. For example, in the early 1980s, prior to the appearance of AZT for the treatment of AIDS, the course of the disease was closely followed by monitoring the composition of patient blood samples, even though the outcome would not offer the patient any further treatment options. In part, these studies on the appearance of HIV in specific communities permitted the advancement of hypotheses as to the route of transmission of the virus. By understanding how the disease was transmitted, resources could be targeted to the communities at greatest risk in campaigns aimed at reducing the number of new infections. The specific serological diagnostic identification, and later genotypic or molecular identification, of HIV also enabled the development of hypotheses as to the temporal and geographical origins of the virus, as well as a myriad of other hypothesis. The development of molecular diagnostic tools have enabled physicians and researchers to monitor the efficacy of treatment with anti-retroviral drugs. Molecular diagnostics are now commonly used to identify HIV in healthy people long before the onset of illness and have been used to demonstrate the existence of people who are genetically resistant to HIV infection. Thus, while there still is no cure for AIDS, there is great therapeutic and predictive benefit to identifying the virus and monitoring the virus levels within the blood of infected individuals, both for the patient and for the community at large.  Classification   Subclinical versus clinical (latent versus apparent)  Symptomatic infections are apparent and clinical, whereas an infection that is active but does not produce noticeable symptoms may be called inapparent, silent, subclinical, or occult. An infection that is inactive or dormant is called a latent infection. An example of a latent bacterial infection is latent tuberculosis. Some viral infections can also be latent, examples of latent viral infections are any of those from the Herpesviridae family.The word infection can denote any presence of a particular pathogen at all (no matter how little) but also is often used in a sense implying a clinically apparent infection (in other words, a case of infectious disease). This fact occasionally creates some ambiguity or prompts some usage discussion; to get around this it is common for health professionals to speak of colonization (rather than infection) when they mean that some of the pathogens are present but that no clinically apparent infection (no disease) is present.  Course of infection  Different terms are used to describe how and where infections present over time. In an acute infection, symptoms develop rapidly; its course can either be rapid or protracted. In chronic infection, symptoms usually develop gradually over weeks or months and are slow to resolve. In subacute infections, symptoms take longer to develop than in acute infections but arise more quickly than those of chronic infections. A focal infection is an initial site of infection from which organisms travel via the bloodstream to another area of the body.  Primary versus opportunistic  Among the many varieties of microorganisms, relatively few cause disease in otherwise healthy individuals. Infectious disease results from the interplay between those few pathogens and the defenses of the hosts they infect. The appearance and severity of disease resulting from any pathogen depend upon the ability of that pathogen to damage the host as well as the ability of the host to resist the pathogen. However, a host\'s immune system can also cause damage to the host itself in an attempt to control the infection. Clinicians, therefore, classify infectious microorganisms or microbes according to the status of host defenses – either as primary pathogens or as opportunistic pathogens.  Primary pathogens  Primary pathogens cause disease as a result of their presence or activity within the normal, healthy host, and their intrinsic virulence (the severity of the disease they cause) is, in part, a necessary consequence of their need to reproduce and spread. Many of the most common primary pathogens of humans only infect humans, however, many serious diseases are caused by organisms acquired from the environment or that infect non-human hosts.  Opportunistic pathogens  Opportunistic pathogens can cause an infectious disease in a host with depressed resistance (immunodeficiency) or if they have unusual access to the inside of the body (for example, via trauma). Opportunistic infection may be caused by microbes ordinarily in contact with the host, such as pathogenic bacteria or fungi in the gastrointestinal or the upper respiratory tract, and they may also result from (otherwise innocuous) microbes acquired from other hosts (as in Clostridium difficile colitis) or from the environment as a result of traumatic introduction (as in surgical wound infections or compound fractures). An opportunistic disease requires impairment of host defenses, which may occur as a result of genetic defects (such as chronic granulomatous disease), exposure to antimicrobial drugs or immunosuppressive chemicals (as might occur following poisoning or cancer chemotherapy), exposure to ionizing radiation, or as a result of an infectious disease with immunosuppressive activity (such as with measles, malaria or HIV disease). Primary pathogens may also cause more severe disease in a host with depressed resistance than would normally occur in an immunosufficient host.  Secondary infection  While a primary infection can practically be viewed as the root cause of an individual\'s current health problem, a secondary infection is a sequela or complication of that root cause. For example, an infection due to a burn or penetrating trauma (the root cause) is a secondary infection. Primary pathogens often cause primary infection and often cause secondary infection. Usually, opportunistic infections are viewed as secondary infections (because immunodeficiency or injury was the predisposing factor).  Other types of infection  Other types of infection consist of mixed, iatrogenic, nosocomial, and community-acquired infection. A mixed infection is an infection that is caused by two or more pathogens. An example of this is appendicitis, which is caused by Bacteroides fragilis and Escherichia coli. The second is an iatrogenic infection. This type of infection is one that is transmitted from a health care worker to a patient. A nosocomial infection is also one that occurs in a health care setting. Nosocomial infections are those that are acquired during a hospital stay. Lastly, a community-acquired infection is one in which the infection is acquired from a whole community.  Infectious or not  One manner of proving that a given disease is infectious, is to satisfy Koch\'s postulates (first proposed by Robert Koch), which require that first, the infectious agent be identifiable only in patients who have the disease, and not in healthy controls, and second, that patients who contract the infectious agent also develop the disease. These postulates were first used in the discovery that Mycobacteria species cause tuberculosis.However, Koch\'s postulates cannot usually be tested in modern practice for ethical reasons. Proving them would require experimental infection of a healthy individual with a pathogen produced as a pure culture. Conversely, even clearly infectious diseases do not always meet the infectious criteria; for example, Treponema pallidum, the causative spirochete of syphilis, cannot be cultured in vitro – however the organism can be cultured in rabbit testes. It is less clear that a pure culture comes from an animal source serving as host than it is when derived from microbes derived from plate culture.Epidemiology, or the study and analysis of who, why and where disease occurs, and what determines whether various populations have a disease, is another important tool used to understand infectious disease. Epidemiologists may determine differences among groups within a population, such as whether certain age groups have a greater or lesser rate of infection; whether groups living in different neighborhoods are more likely to be infected; and by other factors, such as gender and race. Researchers also may assess whether a disease outbreak is sporadic, or just an occasional occurrence; endemic, with a steady level of regular cases occurring in a region; epidemic, with a fast arising, and unusually high number of cases in a region; or pandemic, which is a global epidemic. If the cause of the infectious disease is unknown, epidemiology can be used to assist with tracking down the sources of infection.  Contagiousness  Infectious diseases are sometimes called contagious diseases when they are easily transmitted by contact with an ill person or their secretions (e.g., influenza). Thus, a contagious disease is a subset of infectious disease that is especially infective or easily transmitted. Other types of infectious, transmissible, or communicable diseases with more specialized routes of infection, such as vector transmission or sexual transmission, are usually not regarded as ""contagious"", and often do not require medical isolation (sometimes loosely called quarantine) of those affected. However, this specialized connotation of the word ""contagious"" and ""contagious disease"" (easy transmissibility) is not always respected in popular use. Infectious diseases are commonly transmitted from person to person through direct contact. The types of contact are through person to person and droplet spread. Indirect contact such as airborne transmission, contaminated objects, food and drinking water, animal person contact, animal reservoirs, insect bites, and environmental reservoirs are another way infectious diseases are transmitted.  By anatomic location  Infections can be classified by the anatomic location or organ system infected, including: Urinary tract infection Skin infection Respiratory tract infection Odontogenic infection (an infection that originates within a tooth or in the closely surrounding tissues) Vaginal infections Intra-amniotic infectionIn addition, locations of inflammation where infection is the most common cause include pneumonia, meningitis and salpingitis.  Prevention  Techniques like hand washing, wearing gowns, and wearing face masks can help prevent infections from being passed from one person to another. Aseptic technique was introduced in medicine and surgery in the late 19th century and greatly reduced the incidence of infections caused by surgery. Frequent hand washing remains the most important defense against the spread of unwanted organisms. There are other forms of prevention such as avoiding the use of illicit drugs, using a condom, wearing gloves, and having a healthy lifestyle with a balanced diet and regular exercise. Cooking foods well and avoiding foods that have been left outside for a long time is also important.Antimicrobial substances used to prevent transmission of infections include: antiseptics, which are applied to living tissue/skin disinfectants, which destroy microorganisms found on non-living objects. antibiotics, called prophylactic when given as prevention rather as treatment of infection. However, long term use of antibiotics leads to resistance of bacteria. While humans do not become immune to antibiotics, the bacteria does. Thus, avoiding using antibiotics longer than necessary helps preventing bacteria from forming mutations that aide in antibiotic resistance.One of the ways to prevent or slow down the transmission of infectious diseases is to recognize the different characteristics of various diseases. Some critical disease characteristics that should be evaluated include virulence, distance traveled by those affected, and level of contagiousness. The human strains of Ebola virus, for example, incapacitate those infected extremely quickly and kill them soon after. As a result, those affected by this disease do not have the opportunity to travel very far from the initial infection zone. Also, this virus must spread through skin lesions or permeable membranes such as the eye. Thus, the initial stage of Ebola is not very contagious since its victims experience only internal hemorrhaging. As a result of the above features, the spread of Ebola is very rapid and usually stays within a relatively confined geographical area. In contrast, the human immunodeficiency virus (HIV) kills its victims very slowly by attacking their immune system. As a result, many of its victims transmit the virus to other individuals before even realizing that they are carrying the disease. Also, the relatively low virulence allows its victims to travel long distances, increasing the likelihood of an epidemic.Another effective way to decrease the transmission rate of infectious diseases is to recognize the effects of small-world networks. In epidemics, there are often extensive interactions within hubs or groups of infected individuals and other interactions within discrete hubs of susceptible individuals. Despite the low interaction between discrete hubs, the disease can jump and spread in a susceptible hub via a single or few interactions with an infected hub. Thus, infection rates in small-world networks can be reduced somewhat if interactions between individuals within infected hubs are eliminated (Figure 1). However, infection rates can be drastically reduced if the main focus is on the prevention of transmission jumps between hubs. The use of needle exchange programs in areas with a high density of drug users with HIV is an example of the successful implementation of this treatment method. Another example is the use of ring culling or vaccination of potentially susceptible livestock in adjacent farms to prevent the spread of the foot-and-mouth virus in 2001.A general method to prevent transmission of vector-borne pathogens is pest control. In cases where infection is merely suspected, individuals may be quarantined until the incubation period has passed and the disease manifests itself or the person remains healthy. Groups may undergo quarantine, or in the case of communities, a cordon sanitaire may be imposed to prevent infection from spreading beyond the community, or in the case of protective sequestration, into a community. Public health authorities may implement other forms of social distancing, such as school closings, lockdowns or temporary restrictions (e.g. circuit breakers) to control an epidemic.  Immunity  Infection with most pathogens does not result in death of the host and the offending organism is ultimately cleared after the symptoms of the disease have waned. This process requires immune mechanisms to kill or inactivate the inoculum of the pathogen. Specific acquired immunity against infectious diseases may be mediated by antibodies and/or T lymphocytes. Immunity mediated by these two factors may be manifested by: a direct effect upon a pathogen, such as antibody-initiated complement-dependent bacteriolysis, opsonoization, phagocytosis and killing, as occurs for some bacteria, neutralization of viruses so that these organisms cannot enter cells, or by T lymphocytes, which will kill a cell parasitized by a microorganism.The immune system response to a microorganism often causes symptoms such as a high fever and inflammation, and has the potential to be more devastating than direct damage caused by a microbe.Resistance to infection (immunity) may be acquired following a disease, by asymptomatic carriage of the pathogen, by harboring an organism with a similar structure (crossreacting), or by vaccination. Knowledge of the protective antigens and specific acquired host immune factors is more complete for primary pathogens than for opportunistic pathogens. There is also the phenomenon of herd immunity which offers a measure of protection to those otherwise vulnerable people when a large enough proportion of the population has acquired immunity from certain infections.Immune resistance to an infectious disease requires a critical level of either antigen-specific antibodies and/or T cells when the host encounters the pathogen. Some individuals develop natural serum antibodies to the surface polysaccharides of some agents although they have had little or no contact with the agent, these natural antibodies confer specific protection to adults and are passively transmitted to newborns.  Host genetic factors  The organism that is the target of an infecting action of a specific infectious agent is called the host. The host harbouring an agent that is in a mature or sexually active stage phase is called the definitive host. The intermediate host comes in contact during the larvae stage. A host can be anything living and can attain to asexual and sexual reproduction. The clearance of the pathogens, either treatment-induced or spontaneous, it can be influenced by the genetic variants carried by the individual patients. For instance, for genotype 1 hepatitis C treated with Pegylated interferon-alpha-2a or Pegylated interferon-alpha-2b (brand names Pegasys or PEG-Intron) combined with ribavirin, it has been shown that genetic polymorphisms near the human IL28B gene, encoding interferon lambda 3, are associated with significant differences in the treatment-induced clearance of the virus. This finding, originally reported in Nature, showed that genotype 1 hepatitis C patients carrying certain genetic variant alleles near the IL28B gene are more possibly to achieve sustained virological response after the treatment than others. Later report from Nature demonstrated that the same genetic variants are also associated with the natural clearance of the genotype 1 hepatitis C virus.  Treatments  When infection attacks the body, anti-infective drugs can suppress the infection. Several broad types of anti-infective drugs exist, depending on the type of organism targeted; they include antibacterial (antibiotic; including antitubercular), antiviral, antifungal and antiparasitic (including antiprotozoal and antihelminthic) agents. Depending on the severity and the type of infection, the antibiotic may be given by mouth or by injection, or may be applied topically. Severe infections of the brain are usually treated with intravenous antibiotics. Sometimes, multiple antibiotics are used in case there is resistance to one antibiotic. Antibiotics only work for bacteria and do not affect viruses. Antibiotics work by slowing down the multiplication of bacteria or killing the bacteria. The most common classes of antibiotics used in medicine include penicillin, cephalosporins, aminoglycosides, macrolides, quinolones and tetracyclines.Not all infections require treatment, and for many self-limiting infections the treatment may cause more side-effects than benefits. Antimicrobial stewardship is the concept that healthcare providers should treat an infection with an antimicrobial that specifically works well for the target pathogen for the shortest amount of time and to only treat when there is a known or highly suspected pathogen that will respond to the medication.  Susceptibility to infection  Pandemics such as COVID-19 show that people dramatically differ in their susceptibility to infection. This may be because of general health, age, or their immune status, e.g. when they have been infected previously. However, it also has become clear that there are genetic factor which determine susceptibility to infection. For instance, up to 40% of SARS-CoV-2 infections may be asymptomatic, suggesting that many people are naturally protected from disease. Large genetic studies have defined risk factors for severe SARS-CoV-2 infections, and genome sequences from 659 patients with severe COVID-19 revealed genetic variants that appear to be associated with life-threatening disease. One gene identified in these studies is type I interferon (IFN). Autoantibodies against type I IFNs were found in up to 13.7% of patients with life-threatening COVID-19, indicating that a complex interaction between genetics and the immune system is important for natural resistance to Covid.Similarly, mutations in the ERAP2 gene, encoding endoplasmic reticulum aminopeptidase 2, seem to increase the susceptibility to the plague, the disease caused by an infection with the bacteria Yersinia pestis. People who inherited two copies of a complete variant of the gene were twice as likely to have survived the plague as those who inherited two copies of a truncated variant.Susceptibility also determined the epidemiology of infection, given that different populations have different genetic and environmental conditions that affect infections.  Epidemiology  In 2010, about 10 million people died of infectious diseases.The World Health Organization collects information on global deaths by International Classification of Disease (ICD) code categories. The following table lists the top infectious disease by number of deaths in 2002. 1993 data is included for comparison. The top three single agent/disease killers are HIV/AIDS, TB and malaria. While the number of deaths due to nearly every disease have decreased, deaths due to HIV/AIDS have increased fourfold. Childhood diseases include pertussis, poliomyelitis, diphtheria, measles and tetanus. Children also make up a large percentage of lower respiratory and diarrheal deaths. In 2012, approximately 3.1 million people have died due to lower respiratory infections, making it the number 4 leading cause of death in the world.  Historic pandemics  With their potential for unpredictable and explosive impacts, infectious diseases have been major actors in human history. A pandemic (or global epidemic) is a disease that affects people over an extensive geographical area. For example: Plague of Justinian, from 541 to 542, killed between 50% and 60% of Europe\'s population. The Black Death of 1347 to 1352 killed 25 million in Europe over five years. The plague reduced the old world population from an estimated 450 million to between 350 and 375 million in the 14th century. The introduction of smallpox, measles, and typhus to the areas of Central and South America by European explorers during the 15th and 16th centuries caused pandemics among the native inhabitants. Between 1518 and 1568 disease pandemics are said to have caused the population of Mexico to fall from 20 million to 3 million. The first European influenza epidemic occurred between 1556 and 1560, with an estimated mortality rate of 20%. Smallpox killed an estimated 60 million Europeans during the 18th century (approximately 400,000 per year). Up to 30% of those infected, including 80% of the children under 5 years of age, died from the disease, and one-third of the survivors went blind. In the 19th century, tuberculosis killed an estimated one-quarter of the adult population of Europe; by 1918 one in six deaths in France were still caused by TB. The Influenza Pandemic of 1918 (or the Spanish flu) killed 25–50 million people (about 2% of world population of 1.7 billion). Today Influenza kills about 250,000 to 500,000 worldwide each year.  Emerging diseases  In most cases, microorganisms live in harmony with their hosts via mutual or commensal interactions. Diseases can emerge when existing parasites become pathogenic or when new pathogenic parasites enter a new host. Coevolution between parasite and host can lead to hosts becoming resistant to the parasites or the parasites may evolve greater virulence, leading to immunopathological disease. Human activity is involved with many emerging infectious diseases, such as environmental change enabling a parasite to occupy new niches. When that happens, a pathogen that had been confined to a remote habitat has a wider distribution and possibly a new host organism. Parasites jumping from nonhuman to human hosts are known as zoonoses. Under disease invasion, when a parasite invades a new host species, it may become pathogenic in the new host.Several human activities have led to the emergence of zoonotic human pathogens, including viruses, bacteria, protozoa, and rickettsia, and spread of vector-borne diseases, see also globalization and disease and wildlife disease: Encroachment on wildlife habitats. The construction of new villages and housing developments in rural areas force animals to live in dense populations, creating opportunities for microbes to mutate and emerge. Changes in agriculture.","Infection is the invasion of an organism's body tissues by disease-causing agents. The disease is caused by the invading agents multiplying. As they multiply, they produce toxins and damage host tissues. Infectious disease, also known as 'transmissible disease' or 'communicable disease', is illness resulting from an infection.  Common infectious diseases   Diseases caused by bacteria  Tuberculosis - also called TB. Bubonic plague Pertussis - also called whooping cough leprosy  Diseases caused by viruses  AIDS/HIV Hepatitis B Polio Colds Influenza - also called the flu. COVID-19  Diseases caused by fungus  Thrush Ringworm Cryptococcosis Candidiadis Athlete's foot  Diseases caused by parasites  Malaria (carried by mosquitos) Schistosomiasis (flat worms) Chagas disease  Diseases caused by proteins  Prions are proteins which act as infectious diseases.  Diseases caused by many infectious agents  Some infections are caused by different infectious agents at different times. For example, some diarrhea is caused by bacteria. Some is caused by viruses. Diarrhea Pneumonia MeningitisThis is a very short list. There are many more diseases from infection and other causes: common diseases.  Getting infectious disease  Some diseases can be passed from one person to another easily. Other infectious diseases are harder to get. If a person kisses or touches another person who is infected with the flu, a cold, measles, or a sore throat, he or she may get their disease. They may also give the person their disease if they cough on them. Other medical conditions such as AIDS, herpes, and hepatitis B, are only passed by closer contact. Having sex with an infected person, blood transfusions, or touching their blood or urine can sometimes pass on these conditions or diseases.  Stopping infectious disease  People can stop disease by: Covering the mouth every time during coughing Only drinking clean water Only eating very cooked meat Using a condom during sex  Treating infectious disease  Bacteria are usually treated with antibiotic medicines like Tetracycline and Penicillin. Viruses will not be killed by antibiotics. They must be treated with special medicines called antivirals. Medicines to treat HIV/AIDS like zidovudine are antivirals. Antifungals like miconazole and fluconazole treat infections from fungus. Anti-parasitic medicines like Praziquantel and mebendazole. Some infectious diseases have no treatments that work well. For example, there is no medicine that works well to cure West Nile Virus and Rabies. So it is important to avoid getting these diseases. Some infectious disease goes away on its own. These mild diseases do not need to be treated. For example, colds are caused by viruses and they do not need medicines. Some diseases can be prevented by immunizations. Immunizations try to make a person have an immune reaction to an infectious agent. This is usually done before the person gets the disease. Examples of diseases prevented by immunizations are: polio, tetanus, and pertussis. In some cases, if all of the disease can be removed from society, we can get rid of the disease completely. An example of this is smallpox. This virus used to kill people, cause blindness, and bad scars. Now there has not been a person who had smallpox in over thirty years.  Related pages  Social distancing Vaccine Vector (biology) Zoonosis  References   Other websites  World Health Organization Report on Infectious Disease - 2002"
"Allergies, also known as allergic diseases, refer to a number of conditions caused by the hypersensitivity of the immune system to typically harmless substances in the environment. These diseases include hay fever, food allergies, atopic dermatitis, allergic asthma, and anaphylaxis. Symptoms may include red eyes, an itchy rash, sneezing, coughing, a runny nose, shortness of breath, or swelling. Note that food intolerances and food poisoning are separate conditions.Common allergens include pollen and certain foods. Metals and other substances may also cause such problems. Food, insect stings, and medications are common causes of severe reactions. Their development is due to both genetic and environmental factors. The underlying mechanism involves immunoglobulin E antibodies (IgE), part of the body's immune system, binding to an allergen and then to a receptor on mast cells or basophils where it triggers the release of inflammatory chemicals such as histamine. Diagnosis is typically based on a person's medical history. Further testing of the skin or blood may be useful in certain cases. Positive tests, however, may not necessarily mean there is a significant allergy to the substance in question.Early exposure of children to potential allergens may be protective. Treatments for allergies include avoidance of known allergens and the use of medications such as steroids and antihistamines. In severe reactions, injectable adrenalin (epinephrine) is recommended. Allergen immunotherapy, which gradually exposes people to larger and larger amounts of allergen, is useful for some types of allergies such as hay fever and reactions to insect bites. Its use in food allergies is unclear.Allergies are common. In the developed world, about 20% of people are affected by allergic rhinitis, about 6% of people have at least one food allergy, and about 20% have or have had atopic dermatitis at some point in time. Depending on the country, about 1–18% of people have asthma. Anaphylaxis occurs in between 0.05–2% of people. Rates of many allergic diseases appear to be increasing. The word ""allergy"" was first used by Clemens von Pirquet in 1906.  Signs and symptoms  Many allergens such as dust or pollen are airborne particles. In these cases, symptoms arise in areas in contact with air, such as the eyes, nose, and lungs. For instance, allergic rhinitis, also known as hay fever, causes irritation of the nose, sneezing, itching, and redness of the eyes. Inhaled allergens can also lead to increased production of mucus in the lungs, shortness of breath, coughing, and wheezing.Aside from these ambient allergens, allergic reactions can result from foods, insect stings, and reactions to medications like aspirin and antibiotics such as penicillin. Symptoms of food allergy include abdominal pain, bloating, vomiting, diarrhea, itchy skin, and hives. Food allergies rarely cause respiratory (asthmatic) reactions, or rhinitis. Insect stings, food, antibiotics, and certain medicines may produce a systemic allergic response that is also called anaphylaxis; multiple organ systems can be affected, including the digestive system, the respiratory system, and the circulatory system. Depending on the severity, anaphylaxis can include skin reactions, bronchoconstriction, swelling, low blood pressure, coma, and death. This type of reaction can be triggered suddenly, or the onset can be delayed. The nature of anaphylaxis is such that the reaction can seem to be subsiding but may recur throughout a period of time.  Skin  Substances that come into contact with the skin, such as latex, are also common causes of allergic reactions, known as contact dermatitis or eczema. Skin allergies frequently cause rashes, or swelling and inflammation within the skin, in what is known as a ""weal and flare"" reaction characteristic of hives and angioedema.With insect stings, a large local reaction may occur in the form of an area of skin redness greater than 10 cm in size that can last one to two days. This reaction may also occur after immunotherapy.  Cause  Risk factors for allergies can be placed in two broad categories, namely host and environmental factors. Host factors include heredity, sex, race, and age, with heredity being by far the most significant. However, there have been recent increases in the incidence of allergic disorders that cannot be explained by genetic factors alone. Four major environmental candidates are alterations in exposure to infectious diseases during early childhood, environmental pollution, allergen levels, and dietary changes.  Dust mites  Dust mite allergy, also known as house dust allergy, is a sensitization and allergic reaction to the droppings of house dust mites. The allergy is common and can trigger allergic reactions such as asthma, eczema, or itching. It is the manifestation of a parasitosis. The mite's gut contains potent digestive enzymes (notably peptidase 1) that persist in their feces and are major inducers of allergic reactions such as wheezing. The mite's exoskeleton can also contribute to allergic reactions. Unlike scabies mites or skin follicle mites, house dust mites do not burrow under the skin and are not parasitic.  Foods  A wide variety of foods can cause allergic reactions, but 90% of allergic responses to foods are caused by cow's milk, soy, eggs, wheat, peanuts, tree nuts, fish, and shellfish. Other food allergies, affecting less than 1 person per 10,000 population, may be considered ""rare"". The use of hydrolyzed milk baby formula versus standard milk baby formula does not appear to affect the risk.The most common food allergy in the US population is a sensitivity to crustacea. Although peanut allergies are notorious for their severity, peanut allergies are not the most common food allergy in adults or children. Severe or life-threatening reactions may be triggered by other allergens and are more common when combined with asthma.Rates of allergies differ between adults and children. Children can sometimes outgrow peanut allergies. Egg allergies affect one to two percent of children but are outgrown by about two-thirds of children by the age of 5. The sensitivity is usually to proteins in the white, rather than the yolk.Milk-protein allergies are most common in children. Approximately 60% of milk-protein reactions are immunoglobulin E-mediated, with the remaining usually attributable to inflammation of the colon. Some people are unable to tolerate milk from goats or sheep as well as from cows, and many are also unable to tolerate dairy products such as cheese. Roughly 10% of children with a milk allergy will have a reaction to beef. Beef contains small amounts of proteins that are present in greater abundance in cow's milk. Lactose intolerance, a common reaction to milk, is not a form of allergy at all, but due to the absence of an enzyme in the digestive tract.Those with tree nut allergies may be allergic to one or to many tree nuts, including pecans, pistachios, pine nuts, and walnuts. In addition, seeds, including sesame seeds and poppy seeds, contain oils in which protein is present, which may elicit an allergic reaction.Allergens can be transferred from one food to another through genetic engineering; however genetic modification can also remove allergens. Little research has been done on the natural variation of allergen concentrations in unmodified crops.  Latex  Latex can trigger an IgE-mediated cutaneous, respiratory, and systemic reaction. The prevalence of latex allergy in the general population is believed to be less than one percent. In a hospital study, 1 in 800 surgical patients (0.125 percent) reported latex sensitivity, although the sensitivity among healthcare workers is higher, between seven and ten percent. Researchers attribute this higher level to the exposure of healthcare workers to areas with significant airborne latex allergens, such as operating rooms, intensive-care units, and dental suites. These latex-rich environments may sensitize healthcare workers who regularly inhale allergenic proteins.The most prevalent response to latex is an allergic contact dermatitis, a delayed hypersensitive reaction appearing as dry, crusted lesions. This reaction usually lasts 48–96 hours. Sweating or rubbing the area under the glove aggravates the lesions, possibly leading to ulcerations. Anaphylactic reactions occur most often in sensitive patients who have been exposed to a surgeon's latex gloves during abdominal surgery, but other mucosal exposures, such as dental procedures, can also produce systemic reactions.Latex and banana sensitivity may cross-react. Furthermore, those with latex allergy may also have sensitivities to avocado, kiwifruit, and chestnut. These people often have perioral itching and local urticaria. Only occasionally have these food-induced allergies induced systemic responses. Researchers suspect that the cross-reactivity of latex with banana, avocado, kiwifruit, and chestnut occurs because latex proteins are structurally homologous with some other plant proteins.  Medications  About 10% of people report that they are allergic to penicillin; however, 90% turn out not to be. Serious allergies only occur in about 0.03%.  Insect stings  Typically, insects which generate allergic responses are either stinging insects (wasps, bees, hornets and ants) or biting insects (mosquitoes, ticks). Stinging insects inject venom into their victims, whilst biting insects normally introduce anti-coagulants.  Toxins interacting with proteins  Another non-food protein reaction, urushiol-induced contact dermatitis, originates after contact with poison ivy, eastern poison oak, western poison oak, or poison sumac. Urushiol, which is not itself a protein, acts as a hapten and chemically reacts with, binds to, and changes the shape of integral membrane proteins on exposed skin cells. The immune system does not recognize the affected cells as normal parts of the body, causing a T-cell-mediated immune response. Of these poisonous plants, sumac is the most virulent. The resulting dermatological response to the reaction between urushiol and membrane proteins includes redness, swelling, papules, vesicles, blisters, and streaking.Estimates vary on the percentage of the population that will have an immune system response. Approximately 25 percent of the population will have a strong allergic response to urushiol. In general, approximately 80 percent to 90 percent of adults will develop a rash if they are exposed to .0050 milligrams (7.7×10−5 gr) of purified urushiol, but some people are so sensitive that it takes only a molecular trace on the skin to initiate an allergic reaction.  Genetics  Allergic diseases are strongly familial: identical twins are likely to have the same allergic diseases about 70% of the time; the same allergy occurs about 40% of the time in non-identical twins. Allergic parents are more likely to have allergic children, and those children's allergies are likely to be more severe than those in children of non-allergic parents. Some allergies, however, are not consistent along genealogies; parents who are allergic to peanuts may have children who are allergic to ragweed. The likelihood of developing allergies is inherited and related to an irregularity in the immune system, but the specific allergen is not.The risk of allergic sensitization and the development of allergies varies with age, with young children most at risk. Several studies have shown that IgE levels are highest in childhood and fall rapidly between the ages of 10 and 30 years. The peak prevalence of hay fever is highest in children and young adults and the incidence of asthma is highest in children under 10.Ethnicity may play a role in some allergies; however, racial factors have been difficult to separate from environmental influences and changes due to migration. It has been suggested that different genetic loci are responsible for asthma, to be specific, in people of European, Hispanic, Asian, and African origins.  Hygiene hypothesis  Allergic diseases are caused by inappropriate immunological responses to harmless antigens driven by a TH2-mediated immune response. Many bacteria and viruses elicit a TH1-mediated immune response, which down-regulates TH2 responses. The first proposed mechanism of action of the hygiene hypothesis was that insufficient stimulation of the TH1 arm of the immune system leads to an overactive TH2 arm, which in turn leads to allergic disease. In other words, individuals living in too sterile an environment are not exposed to enough pathogens to keep the immune system busy. Since our bodies evolved to deal with a certain level of such pathogens, when they are not exposed to this level, the immune system will attack harmless antigens, and thus normally benign microbial objects—like pollen—will trigger an immune response.The hygiene hypothesis was developed to explain the observation that hay fever and eczema, both allergic diseases, were less common in children from larger families, which were, it is presumed, exposed to more infectious agents through their siblings, than in children from families with only one child. The hygiene hypothesis has been extensively investigated by immunologists and epidemiologists and has become an important theoretical framework for the study of allergic disorders. It is used to explain the increase in allergic diseases that have been seen since industrialization, and the higher incidence of allergic diseases in more developed countries. The hygiene hypothesis has now expanded to include exposure to symbiotic bacteria and parasites as important modulators of immune system development, along with infectious agents.Epidemiological data support the hygiene hypothesis. Studies have shown that various immunological and autoimmune diseases are much less common in the developing world than the industrialized world, and that immigrants to the industrialized world from the developing world increasingly develop immunological disorders in relation to the length of time since arrival in the industrialized world. Longitudinal studies in the third world demonstrate an increase in immunological disorders as a country grows more affluent and, it is presumed, cleaner. The use of antibiotics in the first year of life has been linked to asthma and other allergic diseases. The use of antibacterial cleaning products has also been associated with higher incidence of asthma, as has birth by Caesarean section rather than vaginal birth.  Stress  Chronic stress can aggravate allergic conditions. This has been attributed to a T helper 2 (TH2)-predominant response driven by suppression of interleukin 12 by both the autonomic nervous system and the hypothalamic–pituitary–adrenal axis. Stress management in highly susceptible individuals may improve symptoms.  Other environmental factors  Allergic diseases are more common in industrialized countries than in countries that are more traditional or agricultural, and there is a higher rate of allergic disease in urban populations versus rural populations, although these differences are becoming less defined. Historically, the trees planted in urban areas were predominantly male to prevent litter from seeds and fruits, but the high ratio of male trees causes high pollen counts, a phenomenon that horticulturist Tom Ogren has called ""botanical sexism"".Alterations in exposure to microorganisms is another plausible explanation, at present, for the increase in atopic allergy. Endotoxin exposure reduces release of inflammatory cytokines such as TNF-α, IFNγ, interleukin-10, and interleukin-12 from white blood cells (leukocytes) that circulate in the blood. Certain microbe-sensing proteins, known as Toll-like receptors, found on the surface of cells in the body are also thought to be involved in these processes.Gutworms and similar parasites are present in untreated drinking water in developing countries, and were present in the water of developed countries until the routine chlorination and purification of drinking water supplies. Recent research has shown that some common parasites, such as intestinal worms (e.g., hookworms), secrete chemicals into the gut wall (and, hence, the bloodstream) that suppress the immune system and prevent the body from attacking the parasite. This gives rise to a new slant on the hygiene hypothesis theory—that co-evolution of humans and parasites has led to an immune system that functions correctly only in the presence of the parasites. Without them, the immune system becomes unbalanced and oversensitive. In particular, research suggests that allergies may coincide with the delayed establishment of gut flora in infants. However, the research to support this theory is conflicting, with some studies performed in China and Ethiopia showing an increase in allergy in people infected with intestinal worms. Clinical trials have been initiated to test the effectiveness of certain worms in treating some allergies. It may be that the term 'parasite' could turn out to be inappropriate, and in fact a hitherto unsuspected symbiosis is at work. For more information on this topic, see Helminthic therapy.  Pathophysiology   Acute response  In the initial stages of allergy, a type I hypersensitivity reaction against an allergen encountered for the first time and presented by a professional antigen-presenting cell causes a response in a type of immune cell called a TH2 lymphocyte, a subset of T cells that produce a cytokine called interleukin-4 (IL-4). These TH2 cells interact with other lymphocytes called B cells, whose role is production of antibodies. Coupled with signals provided by IL-4, this interaction stimulates the B cell to begin production of a large amount of a particular type of antibody known as IgE. Secreted IgE circulates in the blood and binds to an IgE-specific receptor (a kind of Fc receptor called FcεRI) on the surface of other kinds of immune cells called mast cells and basophils, which are both involved in the acute inflammatory response. The IgE-coated cells, at this stage, are sensitized to the allergen.If later exposure to the same allergen occurs, the allergen can bind to the IgE molecules held on the surface of the mast cells or basophils. Cross-linking of the IgE and Fc receptors occurs when more than one IgE-receptor complex interacts with the same allergenic molecule and activates the sensitized cell. Activated mast cells and basophils undergo a process called degranulation, during which they release histamine and other inflammatory chemical mediators (cytokines, interleukins, leukotrienes, and prostaglandins) from their granules into the surrounding tissue causing several systemic effects, such as vasodilation, mucous secretion, nerve stimulation, and smooth muscle contraction. This results in rhinorrhea, itchiness, dyspnea, and anaphylaxis. Depending on the individual, allergen, and mode of introduction, the symptoms can be system-wide (classical anaphylaxis) or localized to specific body systems. Asthma is localized to the respiratory system and eczema is localized to the dermis.  Late-phase response  After the chemical mediators of the acute response subside, late-phase responses can often occur. This is due to the migration of other leukocytes such as neutrophils, lymphocytes, eosinophils, and macrophages to the initial site. The reaction is usually seen 2–24 hours after the original reaction. Cytokines from mast cells may play a role in the persistence of long-term effects. Late-phase responses seen in asthma are slightly different from those seen in other allergic responses, although they are still caused by release of mediators from eosinophils and are still dependent on activity of TH2 cells.  Allergic contact dermatitis  Although allergic contact dermatitis is termed an ""allergic"" reaction (which usually refers to type I hypersensitivity), its pathophysiology involves a reaction that more correctly corresponds to a type IV hypersensitivity reaction. In type IV hypersensitivity, there is activation of certain types of T cells (CD8+) that destroy target cells on contact, as well as activated macrophages that produce hydrolytic enzymes.  Diagnosis  Effective management of allergic diseases relies on the ability to make an accurate diagnosis. Allergy testing can help confirm or rule out allergies. Correct diagnosis, counseling, and avoidance advice based on valid allergy test results reduce the incidence of symptoms and need for medications, and improve quality of life. To assess the presence of allergen-specific IgE antibodies, two different methods can be used: a skin prick test, or an allergy blood test. Both methods are recommended, and they have similar diagnostic value.Skin prick tests and blood tests are equally cost-effective, and health economic evidence shows that both tests were cost-effective compared with no test. Early and more accurate diagnoses save cost due to reduced consultations, referrals to secondary care, misdiagnosis, and emergency admissions.Allergy undergoes dynamic changes over time. Regular allergy testing of relevant allergens provides information on if and how patient management can be changed to improve health and quality of life. Annual testing is often the practice for determining whether allergy to milk, egg, soy, and wheat have been outgrown, and the testing interval is extended to 2–3 years for allergy to peanut, tree nuts, fish, and crustacean shellfish. Results of follow-up testing can guide decision-making regarding whether and when it is safe to introduce or re-introduce allergenic food into the diet.  Skin prick testing  Skin testing is also known as ""puncture testing"" and ""prick testing"" due to the series of tiny punctures or pricks made into the patient's skin. Tiny amounts of suspected allergens and/or their extracts (e.g., pollen, grass, mite proteins, peanut extract) are introduced to sites on the skin marked with pen or dye (the ink/dye should be carefully selected, lest it cause an allergic response itself). A small plastic or metal device is used to puncture or prick the skin. Sometimes, the allergens are injected ""intradermally"" into the patient's skin, with a needle and syringe. Common areas for testing include the inside forearm and the back. If the patient is allergic to the substance, then a visible inflammatory reaction will usually occur within 30 minutes. This response will range from slight reddening of the skin to a full-blown hive (called ""wheal and flare"") in more sensitive patients similar to a mosquito bite. Interpretation of the results of the skin prick test is normally done by allergists on a scale of severity, with +/− meaning borderline reactivity, and 4+ being a large reaction. Increasingly, allergists are measuring and recording the diameter of the wheal and flare reaction. Interpretation by well-trained allergists is often guided by relevant literature. Some patients may believe they have determined their own allergic sensitivity from observation, but a skin test has been shown to be much better than patient observation to detect allergy.If a serious life-threatening anaphylactic reaction has brought a patient in for evaluation, some allergists will prefer an initial blood test prior to performing the skin prick test. Skin tests may not be an option if the patient has widespread skin disease or has taken antihistamines in the last several days.  Patch testing  Patch testing is a method used to determine if a specific substance causes allergic inflammation of the skin. It tests for delayed reactions. It is used to help ascertain the cause of skin contact allergy or contact dermatitis. Adhesive patches, usually treated with several common allergic chemicals or skin sensitizers, are applied to the back. The skin is then examined for possible local reactions at least twice, usually at 48 hours after application of the patch, and again two or three days later.  Blood testing  An allergy blood test is quick and simple and can be ordered by a licensed health care provider (e.g., an allergy specialist) or general practitioner. Unlike skin-prick testing, a blood test can be performed irrespective of age, skin condition, medication, symptom, disease activity, and pregnancy. Adults and children of any age can get an allergy blood test. For babies and very young children, a single needle stick for allergy blood testing is often gentler than several skin pricks. An allergy blood test is available through most laboratories. A sample of the patient's blood is sent to a laboratory for analysis, and the results are sent back a few days later. Multiple allergens can be detected with a single blood sample. Allergy blood tests are very safe since the person is not exposed to any allergens during the testing procedure. The test measures the concentration of specific IgE antibodies in the blood. Quantitative IgE test results increase the possibility of ranking how different substances may affect symptoms. A rule of thumb is that the higher the IgE antibody value, the greater the likelihood of symptoms. Allergens found at low levels that today do not result in symptoms cannot help predict future symptom development. The quantitative allergy blood result can help determine what a patient is allergic to, help predict and follow the disease development, estimate the risk of a severe reaction, and explain cross-reactivity.A low total IgE level is not adequate to rule out sensitization to commonly inhaled allergens. Statistical methods, such as ROC curves, predictive value calculations, and likelihood ratios have been used to examine the relationship of various testing methods to each other. These methods have shown that patients with a high total IgE have a high probability of allergic sensitization, but further investigation with allergy tests for specific IgE antibodies for a carefully chosen of allergens is often warranted. Laboratory methods to measure specific IgE antibodies for allergy testing include enzyme-linked immunosorbent assay (ELISA, or EIA), radioallergosorbent test (RAST) and fluorescent enzyme immunoassay (FEIA).  Other testing  Challenge testing: Challenge testing is when tiny amounts of a suspected allergen are introduced to the body orally, through inhalation, or via other routes. Except for testing food and medication allergies, challenges are rarely performed. When this type of testing is chosen, it must be closely supervised by an allergist. Elimination/challenge tests: This testing method is used most often with foods or medicines. A patient with a suspected allergen is instructed to modify his diet to totally avoid that allergen for a set time. If the patient experiences significant improvement, he may then be ""challenged"" by reintroducing the allergen, to see if symptoms are reproduced. Unreliable tests: There are other types of allergy testing methods that are unreliable, including applied kinesiology (allergy testing through muscle relaxation), cytotoxicity testing, urine autoinjection, skin titration (Rinkel method), and provocative and neutralization (subcutaneous) testing or sublingual provocation.  Differential diagnosis  Before a diagnosis of allergic disease can be confirmed, other plausible causes of the presenting symptoms should be considered. Vasomotor rhinitis, for example, is one of many illnesses that share symptoms with allergic rhinitis, underscoring the need for professional differential diagnosis. Once a diagnosis of asthma, rhinitis, anaphylaxis, or other allergic disease has been made, there are several methods for discovering the causative agent of that allergy.  Prevention  Giving peanut products early may decrease the risk of allergies while only breastfeeding during at least the first few months of life may decrease the risk of dermatitis. There is no good evidence that a mother's diet during pregnancy or breastfeeding affects the risk of allergies, nor is there evidence that delayed introduction of certain foods is useful. Early exposure to potential allergens may actually be protective.Fish oil supplementation during pregnancy is associated with a lower risk. Probiotic supplements during pregnancy or infancy may help to prevent atopic dermatitis.  Management  Management of allergies typically involves avoiding the allergy trigger and taking medications to improve the symptoms. Allergen immunotherapy may be useful for some types of allergies.  Medication  Several medications may be used to block the action of allergic mediators, or to prevent activation of cells and degranulation processes. These include antihistamines, glucocorticoids, epinephrine (adrenaline), mast cell stabilizers, and antileukotriene agents are common treatments of allergic diseases. Anticholinergics, decongestants, and other compounds thought to impair eosinophil chemotaxis are also commonly used. Although rare, the severity of anaphylaxis often requires epinephrine injection, and where medical care is unavailable, a device known as an epinephrine autoinjector may be used.  Immunotherapy  Allergen immunotherapy is useful for environmental allergies, allergies to insect bites, and asthma. Its benefit for food allergies is unclear and thus not recommended. Immunotherapy involves exposing people to larger and larger amounts of allergen in an effort to change the immune system's response.Meta-analyses have found that injections of allergens under the skin is effective in the treatment in allergic rhinitis in children and in asthma. The benefits may last for years after treatment is stopped. It is generally safe and effective for allergic rhinitis and conjunctivitis, allergic forms of asthma, and stinging insects.To a lesser extent, the evidence also supports the use of sublingual immunotherapy for rhinitis and asthma. For seasonal allergies the benefit is small. In this form the allergen is given under the tongue and people often prefer it to injections. Immunotherapy is not recommended as a stand-alone treatment for asthma.  Alternative medicine  An experimental treatment, enzyme potentiated desensitization (EPD), has been tried for decades but is not generally accepted as effective. EPD uses dilutions of allergen and an enzyme, beta-glucuronidase, to which T-regulatory lymphocytes are supposed to respond by favoring desensitization, or down-regulation, rather than sensitization. EPD has also been tried for the treatment of autoimmune diseases, but evidence does not show effectiveness.A review found no effectiveness of homeopathic treatments and no difference compared with placebo. The authors concluded that based on rigorous clinical trials of all types of homeopathy for childhood and adolescence ailments, there is no convincing evidence that supports the use of homeopathic treatments.According to the National Center for Complementary and Integrative Health, U.S., the evidence is relatively strong that saline nasal irrigation and butterbur are effective, when compared to other alternative medicine treatments, for which the scientific evidence is weak, negative, or nonexistent, such as honey, acupuncture, omega 3's, probiotics, astragalus, capsaicin, grape seed extract, Pycnogenol, quercetin, spirulina, stinging nettle, tinospora, or guduchi.  Epidemiology  The allergic diseases—hay fever and asthma—have increased in the Western world over the past 2–3 decades. Increases in allergic asthma and other atopic disorders in industrialized nations, it is estimated, began in the 1960s and 1970s, with further increases occurring during the 1980s and 1990s, although some suggest that a steady rise in sensitization has been occurring since the 1920s. The number of new cases per year of atopy in developing countries has, in general, remained much lower.  Changing frequency  Although genetic factors govern susceptibility to atopic disease, increases in atopy have occurred within too short a period to be explained by a genetic change in the population, thus pointing to environmental or lifestyle changes. Several hypotheses have been identified to explain this increased rate. Increased exposure to perennial allergens may be due to housing changes and increased time spent indoors, and a decreased activation of a common immune control mechanism may be caused by changes in cleanliness or hygiene, and exacerbated by dietary changes, obesity, and decline in physical exercise. The hygiene hypothesis maintains that high living standards and hygienic conditions exposes children to fewer infections. It is thought that reduced bacterial and viral infections early in life direct the maturing immune system away from TH1 type responses, leading to unrestrained TH2 responses that allow for an increase in allergy.Changes in rates and types of infection alone, however, have been unable to explain the observed increase in allergic disease, and recent evidence has focused attention on the importance of the gastrointestinal microbial environment. Evidence has shown that exposure to food and fecal-oral pathogens, such as hepatitis A, Toxoplasma gondii, and Helicobacter pylori (which also tend to be more prevalent in developing countries), can reduce the overall risk of atopy by more than 60%, and an increased rate of parasitic infections has been associated with a decreased prevalence of asthma. It is speculated that these infections exert their effect by critically altering TH1/TH2 regulation. Important elements of newer hygiene hypotheses also include exposure to endotoxins, exposure to pets and growing up on a farm.  History  Some symptoms attributable to allergic diseases are mentioned in ancient sources. Particularly, three members of the Roman Julio-Claudian dynasty (Augustus, Claudius and Britannicus) are suspected to have a family history of atopy. The concept of ""allergy"" was originally introduced in 1906 by the Viennese pediatrician Clemens von Pirquet, after he noticed that patients who had received injections of horse serum or smallpox vaccine usually had quicker, more severe reactions to second injections. Pirquet called this phenomenon ""allergy"" from the Ancient Greek words ἄλλος allos meaning ""other"" and ἔργον ergon meaning ""work"".All forms of hypersensitivity used to be classified as allergies, and all were thought to be caused by an improper activation of the immune system. Later, it became clear that several different disease mechanisms were implicated, with a common link to a disordered activation of the immune system. In 1963, a new classification scheme was designed by Philip Gell and Robin Coombs that described four types of hypersensitivity reactions, known as Type I to Type IV hypersensitivity. With this new classification, the word allergy, sometimes clarified as a true allergy, was restricted to type I hypersensitivities (also called immediate hypersensitivity), which are characterized as rapidly developing reactions involving IgE antibodies.A major breakthrough in understanding the mechanisms of allergy was the discovery of the antibody class labeled immunoglobulin E (IgE). IgE was simultaneously discovered in 1966–67 by two independent groups: Ishizaka's team at the Children's Asthma Research Institute and Hospital in Denver, USA, and by Gunnar Johansson and Hans Bennich in Uppsala, Sweden. Their joint paper was published in April 1969.  Diagnosis  Radiometric assays include the radioallergosorbent test (RAST test) method, which uses IgE-binding (anti-IgE) antibodies labeled with radioactive isotopes for quantifying the levels of IgE antibody in the blood. Other, newer methods use colorimetric or fluorescence-labeled technology in the place of radioactive isotopes.The RAST methodology was invented and marketed in 1974 by Pharmacia Diagnostics AB, Uppsala, Sweden, and the acronym RAST is actually a brand name. In 1989, Pharmacia Diagnostics AB replaced it with a superior test named the ImmunoCAP Specific IgE blood test, which uses the newer fluorescence-labeled technology.American College of Allergy Asthma and Immunology (ACAAI) and the American Academy of Allergy Asthma and Immunology (AAAAI) issued the Joint Task Force Report ""Pearls and pitfalls of allergy diagnostic testing"" in 2008, and is firm in its statement that the term RAST is now obsolete: The term RAST became a colloquialism for all varieties of (in vitro allergy) tests. This is unfortunate because it is well recognized that there are well-performing tests and some that do not perform so well, yet they are all called RASTs, making it difficult to distinguish which is which. For these reasons, it is now recommended that use of RAST as a generic descriptor of these tests be abandoned. The updated version, the ImmunoCAP Specific IgE blood test, is the only specific IgE assay to receive Food and Drug Administration approval to quantitatively report to its detection limit of 0.1kU/L.  Medical specialty  An allergist is a physician specially trained to manage and treat allergies, asthma, and the other allergic diseases. In the United States physicians holding certification by the American Board of Allergy and Immunology (ABAI) have successfully completed an accredited educational program and evaluation process, including a proctored examination to demonstrate knowledge, skills, and experience in patient care in allergy and immunology. Becoming an allergist/immunologist requires completion of at least nine years of training. After completing medical school and graduating with a medical degree, a physician will undergo three years of training in internal medicine (to become an internist) or pediatrics (to become a pediatrician). Once physicians have finished training in one of these specialties, they must pass the exam of either the American Board of Pediatrics (ABP), the American Osteopathic Board of Pediatrics (AOBP), the American Board of Internal Medicine (ABIM), or the American Osteopathic Board of Internal Medicine (AOBIM). Internists or pediatricians wishing to focus on the sub-specialty of allergy-immunology then complete at least an additional two years of study, called a fellowship, in an allergy/immunology training program. Allergist/immunologists listed as ABAI-certified have successfully passed the certifying examination of the ABAI following their fellowship.In the United Kingdom, allergy is a subspecialty of general medicine or pediatrics. After obtaining postgraduate exams (MRCP or MRCPCH), a doctor works for several years as a specialist registrar before qualifying for the General Medical Council specialist register. Allergy services may also be delivered by immunologists. A 2003 Royal College of Physicians report presented a case for improvement of what were felt to be inadequate allergy services in the UK. In 2006, the House of Lords convened a subcommittee. It concluded likewise in 2007 that allergy services were insufficient to deal with what the Lords referred to as an ""allergy epidemic"" and its social cost; it made several recommendations.  Research  Low-allergen foods are being developed, as are improvements in skin prick test predictions; evaluation of the atopy patch test, wasp sting outcomes predictions, a rapidly disintegrating epinephrine tablet, and anti-IL-5 for eosinophilic diseases.  See also  Allergic shiner GWAS in allergy Histamine intolerance List of allergens Oral allergy syndrome  References   External links  ""Allergy"". MedlinePlus. U.S. National Library of Medicine. Allergy at Curlie","An allergy is something which triggers an allergic reaction. This is the immune system defending the body against attack by bacteria and viruses. Sometimes the system goes wrong, and is triggered by some quite normal food, or flares up when the family pet comes into the room. This is what the ordinary person calls an 'allergy'.  Allergic reactions  When people come in contact with something they are allergic to, there can be many different reactions. These reactions include itchy eyes, drippy or stuffy noses, swollen faces, hives, sneezing, and coughing. If it is a food allergy, the person may get an upset stomach. Sometimes a person's oesophagus, or throat, may swell up so much that the person can no longer breathe. This is called anaphylaxis. When this happens, a doctor must give the person a medicine called epinephrine to make the swelling go down. Some people with allergies to very common things, like bee stings or fish, carry this medicine with them so it can be used quickly in an emergency. The device they use to inject the medicine is called an epinephrine autoinjector.  Common allergies  Some common food allergies are: Nuts, especially peanuts Fish or shellfish Dairy products Eggs Soy products Wheat Fruits (kiwis and bananas)Some common environmental allergies are: Latex Pollen Ragweed Mold Furry pets Bee or wasp stings Dust mites Tobacco smoke Pollution  References  ""Are you aware of your allergic symptoms?"". Retrieved 28 November 2007."
"Antihistamines are drugs which treat allergic rhinitis, common cold, influenza, and other allergies. Typically, people take antihistamines as an inexpensive, generic (not patented) drug that can be bought without a prescription and provides relief from nasal congestion, sneezing, or hives caused by pollen, dust mites, or animal allergy with few side effects. Antihistamines are usually for short-term treatment. Chronic allergies increase the risk of health problems which antihistamines might not treat, including asthma, sinusitis, and lower respiratory tract infection. Consultation of a medical professional is recommended for those who intend to take antihistamines for longer-term use.Although people typically use the word ""antihistamine"" to describe drugs for treating allergies, doctors and scientists use the term to describe a class of drug that opposes the activity of histamine receptors in the body. In this sense of the word, antihistamines are subclassified according to the histamine receptor that they act upon. The two largest classes of antihistamines are H1-antihistamines and H2-antihistamines. H1-antihistamines work by binding to histamine H1 receptors in mast cells, smooth muscle, and endothelium in the body as well as in the tuberomammillary nucleus in the brain. Antihistamines that target the histamine H1-receptor are used to treat allergic reactions in the nose (e.g., itching, runny nose, and sneezing). In addition, they may be used to treat insomnia, motion sickness, or vertigo caused by problems with the inner ear. H2-antihistamines bind to histamine H2 receptors in the upper gastrointestinal tract, primarily in the stomach. Antihistamines that target the histamine H2-receptor are used to treat gastric acid conditions (e.g., peptic ulcers and acid reflux). Other antihistamines also target H3 receptors and H4 receptors. Histamine receptors exhibit constitutive activity, so antihistamines can function as either a neutral receptor antagonist or an inverse agonist at histamine receptors. Only a few currently marketed H1-antihistamines are known to function as inverse agonists.  Medical uses  Histamine makes blood vessels more permeable (vascular permeability), causing fluid to escape from capillaries into tissues, which leads to the classic symptoms of an allergic reaction — a runny nose and watery eyes. Histamine also promotes angiogenesis.Antihistamines suppress the histamine-induced wheal response (swelling) and flare response (vasodilation) by blocking the binding of histamine to its receptors or reducing histamine receptor activity on nerves, vascular smooth muscle, glandular cells, endothelium, and mast cells. Antihistamines can also help correct Eustachian Tube dysfunction, thereby helping correct problems such as muffled hearing, fullness in the ear and even tinnitus.Itching, sneezing, and inflammatory responses are suppressed by antihistamines that act on H1-receptors. In 2014, antihistamines such as desloratadine were found to be effective to complement standardized treatment of acne due to their anti-inflammatory properties and their ability to suppress sebum production.  Types   H1-antihistamines  H1-antihistamines refer to compounds that inhibit the activity of the H1 receptor. Since the H1 receptor exhibits constitutive activity, H1-antihistamines can be either neutral receptor antagonists or inverse agonists. Normally, histamine binds to the H1 receptor and heightens the receptor's activity; the receptor antagonists work by binding to the receptor and blocking the activation of the receptor by histamine; by comparison, the inverse agonists bind to the receptor and both block the binding of histamine, and reduce its constitutive activity, an effect which is opposite to histamine's. Most antihistamines are inverse agonists at the H1 receptor, but it was previously thought that they were antagonists.Clinically, H1-antihistamines are used to treat allergic reactions and mast cell-related disorders. Sedation is a common side effect of H1-antihistamines that readily cross the blood–brain barrier; some of these drugs, such as diphenhydramine and doxylamine, may therefore be used to treat insomnia. H1-antihistamines can also reduce inflammation, since the expression of NF-κB, the transcription factor the regulates inflammatory processes, is promoted by both the receptor's constitutive activity and agonist (i.e., histamine) binding at the H1 receptor.A combination of these effects, and in some cases metabolic ones as well, lead to most first-generation antihistamines having analgesic-sparing (potentiating) effects on opioid analgesics and to some extent with non-opioid ones as well. The most common antihistamines utilized for this purpose include hydroxyzine, promethazine (enzyme induction especially helps with codeine and similar prodrug opioids), phenyltoloxamine, orphenadrine, and tripelennamine; some may also have intrinsic analgesic properties of their own, orphenadrine being an example. Second-generation antihistamines cross the blood–brain barrier to a much lesser extent than the first-generation antihistamines. They minimize sedatory effects due to their focused effect on peripheral histamine receptors. However, upon high doses second-generation antihistamines will begin to act on the central nervous system and thus can induce drowsiness when ingested in higher quantity. Additionally, some second-generation antihistamines, notably cetirizine, can interact with CNS psychoactive drugs such as bupropion and benzodiazepines.  H1 antagonists/inverse agonists  Acrivastine Alimemazine (a phenothiazine used as antipruritic, antiemetic and sedative) Amitriptyline (tricyclic antidepressant) Amoxapine (tricyclic antidepressant) Aripiprazole (atypical antipsychotic, trade name: Abilify) Azelastine Bilastine Bromodiphenhydramine (Bromazine) Brompheniramine Buclizine Carbinoxamine Cetirizine (Zyrtec) Chlophedianol (Clofedanol) Chlorodiphenhydramine Chlorpheniramine Chlorpromazine (low-potency typical antipsychotic, also used as an antiemetic) Chlorprothixene (low-potency typical antipsychotic, trade name: Truxal) Chloropyramine (first generation antihistamine marketed in Eastern Europe) Cinnarizine (also used for motion sickness and vertigo) Clemastine Clomipramine (tricyclic antidepressant) Clozapine (atypical antipsychotic; trade name: Clozaril) Cyclizine Cyproheptadine Desloratadine Dexbrompheniramine Dexchlorpheniramine Dimenhydrinate (used as an antiemetic and for motion sickness) Dimetindene Diphenhydramine (Benadryl) Dosulepin (tricyclic antidepressant) Doxepin (tricyclic antidepressant) Doxylamine (most commonly used as an over-the-counter drug sedative) Ebastine Embramine Fexofenadine (Allegra/Telfast) Fluoxetine Hydroxyzine (also used as an anxiolytic and for motion sickness; trade names: Atarax, Vistaril) Imipramine (tricyclic antidepressant) Ketotifen Levocabastine (Livostin/Livocab) Levocetirizine (Xyzal) Levomepromazine (low-potency typical antipsychotic) Loratadine (Claritin) Maprotiline (tetracyclic antidepressant) Meclizine (most commonly used as an antiemetic) Mianserin (tetracyclic antidepressant) Mirtazapine (tetracyclic antidepressant, also has antiemetic and appetite-stimulating effects; trade name: Remeron) Olanzapine (atypical antipsychotic; trade name: Zyprexa) Olopatadine (used locally) Orphenadrine (a close relative of diphenhydramine used mainly as a skeletal muscle relaxant and anti-Parkinsons agent) Periciazine (low-potency typical antipsychotic) Phenindamine Pheniramine Phenyltoloxamine Promethazine (Phenergan) Pyrilamine (crosses the blood–brain barrier; produces drowsiness) Quetiapine (atypical antipsychotic; trade name: Seroquel) Rupatadine (Alergoliber) Setastine (Loderix) Setiptiline (or teciptiline, a tetracyclic antidepressant, trade name: Tecipul) Trazodone (SARI antidepressant/anxiolytic/hypnotic with mild H1 blockade action) Tripelennamine Triprolidine  H2-antihistamines  H2-antihistamines, like H1-antihistamines, exist as inverse agonists and neutral antagonists. They act on H2 histamine receptors found mainly in the parietal cells of the gastric mucosa, which are part of the endogenous signaling pathway for gastric acid secretion. Normally, histamine acts on H2 to stimulate acid secretion; drugs that inhibit H2 signaling thus reduce the secretion of gastric acid. H2-antihistamines are among first-line therapy to treat gastrointestinal conditions including peptic ulcers and gastroesophageal reflux disease. Some formulations are available over the counter. Most side effects are due to cross-reactivity with unintended receptors. Cimetidine, for example, is notorious for antagonizing androgenic testosterone and DHT receptors at high doses. Examples include: Cimetidine Famotidine Lafutidine Nizatidine Ranitidine Roxatidine Tiotidine  H3-antihistamines  An H3-antihistamine is a classification of drugs used to inhibit the action of histamine at the H3 receptor. H3 receptors are primarily found in the brain and are inhibitory autoreceptors located on histaminergic nerve terminals, which modulate the release of histamine. Histamine release in the brain triggers secondary release of excitatory neurotransmitters such as glutamate and acetylcholine via stimulation of H1 receptors in the cerebral cortex. Consequently, unlike the H1-antihistamines which are sedating, H3-antihistamines have stimulant and cognition-modulating effects. Examples of selective H3-antihistamines include: Clobenpropit ABT-239 Ciproxifan Conessine A-349,821. Thioperamide  H4-antihistamines  H4-antihistamines inhibit the activity of the H4 receptor. Examples: Thioperamide JNJ 7777120 VUF-6002  Atypical antihistamines   Histidine decarboxylase inhibitors  Inhibit the action of histidine decarboxylase: Tritoqualine Catechin  Mast cell stabilizers  Mast cell stabilizers are drugs which prevent mast cell degranulation. cromolyn sodium Nedocromil β-agonists  History  The first H1 receptor antagonists were discovered in the 1930s and were marketed in the 1940s. Piperoxan was discovered in 1933 and was the first compound with antihistamine effects to be identified. Piperoxan and its analogues were too toxic to be used in humans. Phenbenzamine (Antergan) was the first clinically useful antihistamine and was introduced for medical use in 1942. Subsequently, many other antihistamines were developed and marketed. Diphenhydramine (Benadryl) was synthesized in 1943, tripelennamine (Pyribenzamine) was patented in 1946, and promethazine (Phenergan) was synthesized in 1947 and launched in 1949. By 1950, at least 20 antihistamines had been marketed. Chlorphenamine (Piriton), a less sedating antihistamine, was synthesized in 1951, and hydroxyzine (Atarax, Vistaril), an antihistamine used specifically as a sedative and tranquilizer, was developed in 1956. The first non-sedating antihistamine was terfenadine (Seldane) and was developed in 1973. Subsequently, other non-sedating antihistamines like loratadine (Claritin), cetirizine (Zyrtec), and fexofenadine (Allegra) were developed and introduced.The introduction of the first-generation antihistamines marked the beginning of medical treatment of nasal allergies. Research into these drugs led to the discovery that they were H1 receptor antagonists and also to the development of H2 receptor antagonists, where H1-antihistamines affected the nose and the H2-antihistamines affected the stomach. This history has led to contemporary research into drugs which are H3 receptor antagonists and which affect the H4 receptor antagonists. Most people who use an H1 receptor antagonist to treat allergies use a second-generation drug.  Society and culture  The United States government removed two second generation antihistamines, terfenadine and astemizole, from the market based on evidence that they could cause heart problems.  Research  Not much published research exists which compares the efficacy and safety of the various antihistamines available. The research which does exist is mostly short-term studies or studies which look at too few people to make general assumptions. Another gap in the research is in information reporting the health effects for individuals with long-term allergies who take antihistamines for a long period of time. Newer antihistamines have been demonstrated to be effective in treating hives. However, there is no research comparing the relative efficacy of these drugs.  Special populations  In 2020, the UK National Health Service wrote that ""[m]ost people can safely take antihistamines"" but that ""[s]ome antihistamines may not be suitable"" for young children, the pregnant or breastfeeding, for those taking other medicines, or people with conditions ""such as heart disease, liver disease, kidney disease or epilepsy"".Most studies of antihistamines reported on people who are younger, so the effects on people over age 65 are not as well understood. Older people are more likely to experience drowsiness from antihistamine use than younger people. Continuous and/or cumulative use of anticholinergic medications, including first-generation antihistamines, is associated with higher risk for cognitive decline and dementia in older people.Also, most of the research has been on caucasians and other ethnic groups are not as represented in the research. The evidence does not report how antihistamines affect women differently than men. Different studies have reported on antihistamine use in children, with various studies finding evidence that certain antihistamines could be used by children 2 years of age, and other drugs being safer for younger or older children.  Potential uses studied  Research regarding the effects of commonly used medications upon certain cancer therapies has suggested that when consumed in conjunction with immune checkpoint inhibitors some may influence the response of subjects to that particular treatment whose T-cell functions were failing in anti-tumor activity. Upon study of records in mouse studies associated with 40 common medications ranging from antibiotics, antihistamines, aspirin, and hydrocortisone, that for subjects with melanoma and lung cancers, fexofenadine, one of three medications, along with loratadine, and cetirizine, that target histamine receptor H1 (HRH1), demonstrated significantly higher survival rates and had experienced restored T-cell anti-tumor activity, ultimately inhibiting tumor growth in the subject animals. Such results encourage further study in order to see whether results in humans is similar in combating resistance to immunotherapy.  See also  Antileukotriene Immunotherapy  References   External links  Histamine+antagonist at the U.S. National Library of Medicine Medical Subject Headings (MeSH) Antihistamine information at Allergy UK","Antihistamines are drugs which treat allergic rhinitis and other allergies.Usually people take antihistamines as an over-the-counter drug , with few side effects. It is for relief from nasal congestion, sneezing, or hives. These symptoms may be caused by pollen, dust mites, or allergy to animals.Antihistamines are usually for short-term treatment. Chronic allergies increase the risk of health problems which antihistamines might not treat, including asthma, sinusitis, and respiratory tract infections near the lungs. Consultation of a medical professional is recommended for those who intend to take antihistamines for longer-term use.Although people use the word “antihistamine” to describe drugs for treating allergies, doctors and scientists use the term to describe a class of drug that opposes the activity of histamine receptors in the body. In this sense of the word, antihistamines are subclassified according to which histamine receptor they act upon.  References "
"Ibuprofen is a nonsteroidal anti-inflammatory drug (NSAID) that is used to relieve pain, fever, and inflammation. This includes painful menstrual periods, migraines, and rheumatoid arthritis. It may also be used to close a patent ductus arteriosus in a premature baby. It can be used by mouth or intravenously. It typically begins working within an hour.Common side effects include heartburn and a rash. Compared to other NSAIDs, it may have other side effects such as gastrointestinal bleeding. It increases the risk of heart failure, kidney failure, and liver failure. At low doses, it does not appear to increase the risk of heart attack; however, at higher doses it may. Ibuprofen can also worsen asthma. While its safety in early pregnancy is unclear, it appears to be harmful in later pregnancy, so is not recommended. Like other NSAIDs, it works by inhibiting the production of prostaglandins by decreasing the activity of the enzyme cyclooxygenase (COX). Ibuprofen is a weaker anti-inflammatory agent than other NSAIDs.Ibuprofen was discovered in 1961 by Stewart Adams and John Nicholson while working at Boots UK Limited and initially marketed as Brufen. It is available under a number of trade names, including Nurofen, Advil, and Motrin. Ibuprofen was first marketed in 1969 in the United Kingdom and in 1974 in the United States. It is on the World Health Organization's List of Essential Medicines. It is available as a generic medication. In 2020, it was the 38th-most commonly prescribed medication in the United States, with more than 16 million prescriptions.  Medical uses  Ibuprofen is used primarily to treat fever (including postvaccination fever), mild to moderate pain (including pain relief after surgery), painful menstruation, osteoarthritis, dental pain, headaches, and pain from kidney stones. About 60% of people respond to any NSAID; those who do not respond well to a particular one may respond to another. A Cochran medical review of 51 trials of NSAIDS for the treatment of lower back pain found that, ""NSAIDs are effective for short-term symptomatic relief in patients with acute low back pain"".It is used for inflammatory diseases such as juvenile idiopathic arthritis and rheumatoid arthritis. It is also used for pericarditis and patent ductus arteriosus.  Ibuprofen lysine  In some countries, ibuprofen lysine (the lysine salt of ibuprofen, sometimes called ""ibuprofen lysinate"") is licensed for treatment of the same conditions as ibuprofen; the lysine salt is used because it is more water-soluble.Ibuprofen lysine is sold for rapid pain relief; given in form of a lysine salt, absorption is much quicker (35 minutes compared to 90–120 minutes). However, a clinical trial with 351 participants in 2020, funded by Sanofi, found no significant difference between ibuprofen and ibuprofen lysine concerning the eventual onset of action or analgesic efficacy.In 2006, ibuprofen lysine was approved in the U.S. by the Food and Drug Administration (FDA) for closure of patent ductus arteriosus in premature infants weighing between 500 and 1,500 g (1 and 3 lb), who are no more than 32 weeks' gestational age when usual medical management (such as fluid restriction, diuretics, and respiratory support) is not effective.  Adverse effects  Adverse effects include nausea, indigestion, diarrhea, constipation, gastrointestinal ulceration/bleeding, headache, dizziness, rash, salt and fluid retention, and high blood pressure.Infrequent adverse effects include esophageal ulceration, heart failure, high blood levels of potassium, kidney impairment, confusion, and bronchospasm. Ibuprofen can exacerbate asthma, sometimes fatally.Allergic reactions, including anaphylaxis and anaphylactic shock, may occur. Ibuprofen may be quantified in blood, plasma, or serum to demonstrate the presence of the drug in a person having experienced an anaphylactic reaction, confirm a diagnosis of poisoning in people who are hospitalized, or assist in a medicolegal death investigation. A monograph relating ibuprofen plasma concentration, time since ingestion, and risk of developing renal toxicity in people who have overdosed has been published.In October 2020, the US FDA required the drug label to be updated for all NSAID medications to describe the risk of kidney problems in unborn babies that result in low amniotic fluid.  Cardiovascular risk  Along with several other NSAIDs, chronic ibuprofen use has been found correlated with risk of progression to hypertension in women, though less than for acetaminophen, and myocardial infarction (heart attack), particularly among those chronically using higher doses. On 9 July 2015, the US FDA toughened warnings of increased heart attack and stroke risk associated with ibuprofen and related NSAIDs; the NSAID aspirin is not included in this warning. The European Medicines Agency (EMA) issued similar warnings in 2015.  Skin  Along with other NSAIDs, ibuprofen has been associated with the onset of bullous pemphigoid or pemphigoid-like blistering. As with other NSAIDs, ibuprofen has been reported to be a photosensitising agent, but it is considered a weak photosensitising agent compared to other members of the 2-arylpropionic acid class. Like other NSAIDs, ibuprofen is an extremely rare cause of the autoimmune disease Stevens–Johnson syndrome (SJS). Ibuprofen is also an extremely rare cause of toxic epidermal necrolysis.  Interactions   Alcohol  Drinking alcohol when taking ibuprofen may increase the risk of stomach bleeding.  Aspirin  According to the FDA, ""ibuprofen can interfere with the antiplatelet effect of low-dose aspirin, potentially rendering aspirin less effective when used for cardioprotection and stroke prevention"". Allowing sufficient time between doses of ibuprofen and immediate-release (IR) aspirin can avoid this problem. The recommended elapsed time between a dose of ibuprofen and a dose of aspirin depends on which is taken first. It would be 30 minutes or more for ibuprofen taken after IR aspirin, and 8 hours or more for ibuprofen taken before IR aspirin. However, this timing cannot be recommended for enteric-coated aspirin. If ibuprofen is taken only occasionally without the recommended timing, though, the reduction of the cardioprotection and stroke prevention of a daily aspirin regimen is minimal.  Paracetamol  Ibuprofen combined with paracetamol is considered generally safe in children for short-term usage.  Overdose  Ibuprofen overdose has become common since it was licensed for OTC use. Many overdose experiences are reported in the medical literature, although the frequency of life-threatening complications from ibuprofen overdose is low. Human responses in cases of overdose range from an absence of symptoms to a fatal outcome despite intensive-care treatment. Most symptoms are an excess of the pharmacological action of ibuprofen, and include abdominal pain, nausea, vomiting, drowsiness, dizziness, headache, ear ringing, and nystagmus. Rarely, more severe symptoms, such as gastrointestinal bleeding, seizures, metabolic acidosis, hyperkalemia, low blood pressure, slow heart rate, fast heart rate, atrial fibrillation, coma, liver dysfunction, acute kidney failure, cyanosis, respiratory depression, and cardiac arrest have been reported. The severity of symptoms varies with the ingested dose and the time elapsed; however, individual sensitivity also plays an important role. Generally, the symptoms observed with an overdose of ibuprofen are similar to the symptoms caused by overdoses of other NSAIDs. Correlation between severity of symptoms and measured ibuprofen plasma levels is weak. Toxic effects are unlikely at doses below 100 mg/kg, but can be severe above 400 mg/kg (around 150 tablets of 200 mg units for an average man); however, large doses do not indicate the clinical course is likely to be lethal. A precise lethal dose is difficult to determine, as it may vary with age, weight, and concomitant conditions of the individual person. Treatment to address an ibuprofen overdose is based on how the symptoms present. In cases presenting early, decontamination of the stomach is recommended. This is achieved using activated charcoal; charcoal absorbs the drug before it can enter the bloodstream. Gastric lavage is now rarely used, but can be considered if the amount ingested is potentially life-threatening, and it can be performed within 60 minutes of ingestion. Purposeful vomiting is not recommended. Most ibuprofen ingestions produce only mild effects, and the management of overdose is straightforward. Standard measures to maintain normal urine output should be instituted and kidney function monitored. Since ibuprofen has acidic properties and is also excreted in the urine, forced alkaline diuresis is theoretically beneficial. However, because ibuprofen is highly protein-bound in the blood, the kidneys' excretion of unchanged drug is minimal. Forced alkaline diuresis is, therefore, of limited benefit.  Miscarriage  A Canadian study of pregnant women suggests that those taking any type or amount of NSAIDs (including ibuprofen, diclofenac, and naproxen) were 2.4 times more likely to miscarry than those not taking the medications. However, an Israeli study found no increased risk of miscarriage in the group of mothers using NSAIDs.  Pharmacology  NSAIDs such as ibuprofen work by inhibiting the cyclooxygenase (COX) enzymes, which convert arachidonic acid to prostaglandin H2 (PGH2). PGH2, in turn, is converted by other enzymes to several other prostaglandins (which are mediators of pain, inflammation, and fever) and to thromboxane A2 (which stimulates platelet aggregation, leading to the formation of blood clots). Like aspirin and indomethacin, ibuprofen is a nonselective COX inhibitor, in that it inhibits two isoforms of cyclooxygenase, COX-1 and COX-2. The analgesic, antipyretic, and anti-inflammatory activity of NSAIDs appears to operate mainly through inhibition of COX-2, which decreases the synthesis of prostaglandins involved in mediating inflammation, pain, fever, and swelling. Antipyretic effects may be due to action on the hypothalamus, resulting in an increased peripheral blood flow, vasodilation, and subsequent heat dissipation. Inhibition of COX-1 instead would be responsible for unwanted effects on the gastrointestinal tract. However, the role of the individual COX isoforms in the analgesic, anti-inflammatory, and gastric damage effects of NSAIDs is uncertain, and different compounds cause different degrees of analgesia and gastric damage.Ibuprofen is administered as a racemic mixture. The R-enantiomer undergoes extensive interconversion to the S-enantiomer in vivo. The S-enantiomer is believed to be the more pharmacologically active enantiomer. The R-enantiomer is converted through a series of three main enzymes. These enzymes include acyl-CoA-synthetase, which converts the R-enantiomer to (−)-R-ibuprofen I-CoA; 2-arylpropionyl-CoA epimerase, which converts (−)-R-ibuprofen I-CoA to (+)-S-ibuprofen I-CoA; and hydrolase, which converts (+)-S-ibuprofen I-CoA to the S-enantiomer. In addition to the conversion of ibuprofen to the S-enantiomer, the body can metabolize ibuprofen to several other compounds, including numerous hydroxyl, carboxyl and glucuronyl metabolites. Virtually all of these have no pharmacological effects.Unlike most other NSAIDs, ibuprofen also acts as an inhibitor of Rho kinase and may be useful in recovery from spinal-cord injury.  Pharmacokinetics  After oral administration, peak serum concentration is reached after 1–2 hours, and up to 99% of the drug is bound to plasma proteins. The majority of ibuprofen is metabolized and eliminated within 24 hours in the urine; however, 1% of the unchanged drug is removed through biliary excretion.  Chemistry  Ibuprofen is practically insoluble in water, but very soluble in most organic solvents like ethanol (66.18 g/100 mL at 40 °C for 90% EtOH), methanol, acetone and dichloromethane.The original synthesis of ibuprofen by the Boots Group started with the compound 2-methylpropylbenzene. The synthesis took six steps. A modern, greener technique for the synthesis involves only three steps.  Stereochemistry  Ibuprofen, like other 2-arylpropionate derivatives such as ketoprofen, flurbiprofen and naproxen, contains a stereocenter in the α-position of the propionate moiety. The product sold in pharmacies is a racemic mixture of the S and R-isomers. The S (dextrorotatory) isomer is the more biologically active; this isomer has been isolated and used medically (see dexibuprofen for details).The isomerase enzyme, alpha-methylacyl-CoA racemase, converts (R)-ibuprofen into the (S)-enantiomer.The (S)- ibuprofen, the eutomer, harbors the desired therapeutic activity. Interestingly, the inactive (R)-enantiomer, the distomer, undergoes a unidirectional chiral inversion to offer the active (S)-enantiomer. That is, when the ibuprofen is administered as a racemate the distomer is converted in vivo into the eutomer while the latter is unaffected.  History  Ibuprofen was derived from propionic acid by the research arm of Boots Group during the 1960s. The name is derived from the 3 functional groups: isobutyl (ibu) propionic acid (pro) phenyl (fen). Its discovery was the result of research during the 1950s and 1960s to find a safer alternative to aspirin. The molecule was discovered and synthesized by a team led by Stewart Adams, with a patent application filed in 1961. Adams initially tested the drug as treatment for his hangover. In 1985, Boots' worldwide patent for ibuprofen expired and generic products were launched.The drug was launched as a treatment for rheumatoid arthritis in the United Kingdom in 1969, and in the United States in 1974. Later, in 1983 and 1984, it became the first NSAID (other than aspirin) to be available over the counter (OTC) in these two countries. Boots was awarded the Queen's Award for Technical Achievement in 1985 for the development of the drug. Dr. Adams was subsequently made an Officer of the Order of the British Empire (OBE) in 1987. In November 2013, work on ibuprofen was recognized by the erection of a Royal Society of Chemistry blue plaque at Boots' Beeston Factory site in Nottingham, which reads: In recognition of the work during the 1980s by The Boots Company PLC on the development of ibuprofen which resulted in its move from prescription only status to over the counter sale, therefore expanding its use to millions of people worldwide and another at BioCity Nottingham, the site of the original laboratory, which reads: In recognition of the pioneering research work, here on Pennyfoot Street, by Dr Stewart Adams and Dr John Nicholson in the Research Department of Boots which led to the discovery of ibuprofen used by millions worldwide for the relief of pain.  Society and culture   Availability  Ibuprofen was made available by prescription in the United Kingdom in 1969 and in the United States in 1974. Since then, it has become available over the counter around the world in pharmacies, supermarkets, and other stores, because it is well tolerated and because there is extensive experience of it in the population and in phase-IV trials (postapproval studies). Ibuprofen is the International nonproprietary name (INN), British Approved Name (BAN), Australian Approved Name (AAN) and United States Adopted Name (USAN). In the United States, it has been sold under the brand-names Motrin and Advil since 1974 and 1984, respectively. Ibuprofen is commonly available in the United States up to the FDA's 1984 dose limit OTC, rarely used higher by prescription.In 2009, the first injectable formulation of ibuprofen was approved in the United States, under the trade name Caldolor.  Route  Ibuprofen can be taken by mouth (as a tablet, a capsule, or a suspension) and intravenously.  Research  Ibuprofen is sometimes used for the treatment of acne because of its anti-inflammatory properties, and has been sold in Japan in topical form for adult acne. As with other NSAIDs, ibuprofen may be useful in the treatment of severe orthostatic hypotension (low blood pressure when standing up). NSAIDs are of unclear utility in the prevention and treatment of Alzheimer's disease.Ibuprofen has been associated with a lower risk of Parkinson's disease and may delay or prevent it. Aspirin, other NSAIDs, and paracetamol (acetaminophen) had no effect on the risk for Parkinson's. In March 2011, researchers at Harvard Medical School announced in Neurology that ibuprofen had a neuroprotective effect against the risk of developing Parkinson's disease. People regularly consuming ibuprofen were reported to have a 38% lower risk of developing Parkinson's disease, but no such effect was found for other pain relievers, such as aspirin and paracetamol. Use of ibuprofen to lower the risk of Parkinson's disease in the general population would not be problem-free, given the possibility of adverse effects on the urinary and digestive systems.Some dietary supplements might be dangerous to take along with ibuprofen and other NSAIDs, but as of 2016 more research needs to be conducted to be certain. These supplements include those that can prevent platelet aggregation, including ginkgo, garlic, ginger, bilberry, dong quai, feverfew, ginseng, turmeric, meadowsweet (Filipendula ulmaria), and willow (Salix spp.); those that contain coumarin, including chamomile, horse chestnut, fenugreek and red clover; and those that increase the risk of bleeding, like tamarind.  References   External links  ""Ibuprofen"". Drug Information Portal. U.S. National Library of Medicine. GB patent 971700, Stewart Sanders Adams & John Stuart Nicholson, ""Anti-Inflammatory Agents"", published 1964-09-30, assigned to Boots Pure Drug Co Ltd ""Evidence for the efficacy of pain medications"" (PDF). National Safety Council (NSC). 26 August 2020.","Ibuprofen is a non-steroidal anti-inflammatory drug (NSAID) created by British chemist Stewart Adams. It is used to stop pain, help reduce fevers, relieve arthritis pain, and acts as an inflammatory part. Ibuprofen is used to relieve pain from various conditions such as headache, dental pain, menstrual cramps, muscle aches, or arthritis. It is also used to reduce fever and to relieve minor aches and pain due to the common cold. If you are treating a chronic condition such as arthritis, ask your doctor about non-drug treatments and/or using other medications to treat your pain. See also Warning section. Check the ingredients on the label even if you have used the product before. The manufacturer may have changed the ingredients. Also, products with similar names may contain different ingredients meant for different purposes. Taking the wrong product could harm you. If you are taking the over-the-counter product, read all directions on the product package before taking this medication. If your doctor has prescribed this medication, read the Medication Guide provided by your pharmacist before you start taking ibuprofen and each time you get a refill. If you have any questions, ask your doctor or pharmacist. Take this medication by mouth, usually every 4 to 6 hours with a full glass of water (8 ounces/240 milliliters) unless your doctor directs you otherwise. Do not lie down for at least 10 minutes after taking this drug. If you have stomach upset while taking this medication, take it with food, milk, or an antacid. The dosage is based on your medical condition and response to treatment. To reduce your risk of stomach bleeding and other side effects, take this medication at the lowest effective dose for the shortest possible time. Do not increase your dose or take this drug more often than directed by your doctor or the package label. For ongoing conditions such as arthritis, continue taking this medication as directed by your doctor. When ibuprofen is used by children, the dose is based on the child's weight. Read the package directions to find the proper dose for your child's weight. Consult the pharmacist or doctor if you have questions or if you need help choosing a nonprescription product. For certain conditions (such as arthritis), it may take up to two weeks of taking this drug regularly until you get the full benefit. If you are taking this drug ""as needed"" (not on a regular schedule), remember that pain medications work best if they are used as the first signs of pain occur. If you wait until the pain has worsened, the medication may not work as well. If your condition persists or worsens, or if you think you may have a serious medical problem, get medical help right away. If you are using the nonprescription product to treat yourself or a child for fever or pain, consult the doctor right away if fever worsens or lasts more than 3 days, or if pain worsens or lasts more than 10 days.  References "
"Cardiology (from Ancient Greek καρδίᾱ (kardiā) 'heart', and -λογία (-logia) 'study') is the study of the heart. Cardiology is a branch of medicine that deals with disorders of the heart and the cardiovascular system. The field includes medical diagnosis and treatment of congenital heart defects, coronary artery disease, heart failure, valvular heart disease and electrophysiology. Physicians who specialize in this field of medicine are called cardiologists, a speciality of internal medicine. Pediatric cardiologists are pediatricians who specialize in cardiology. Physicians who specialize in cardiac surgery are called cardiothoracic surgeons or cardiac surgeons, a speciality of general surgery.  Specializations  All cardiologists in the branch of medicine study the disorders of the heart, but the study of adult and child heart disorders each require different training pathways. Therefore, an adult cardiologist (often simply called ""cardiologist"") is inadequately trained to take care of children, and pediatric cardiologists are not trained to treat adult heart disease. Surgical aspects are not included in cardiology and are in the domain of cardiothoracic surgery. For example, coronary artery bypass surgery (CABG), cardiopulmonary bypass and valve replacement are surgical procedures performed by surgeons, not cardiologists. However, some minimally invasive procedures such as cardiac catheterization and pacemaker implantation are performed by cardiologists who have additional training in non-surgical interventions (interventional cardiology and electrophysiology respectively).  Adult cardiology  Cardiology is a specialty of internal medicine. To be a cardiologist in the United States, a three-year residency in internal medicine is followed by a three-year fellowship in cardiology. It is possible to specialize further in a sub-specialty. Recognized sub-specialties in the U.S. by the Accreditation Council for Graduate Medical Education are cardiac electrophysiology, echocardiography, interventional cardiology, and nuclear cardiology. Recognized subspecialties in the U.S. by the American Osteopathic Association Bureau of Osteopathic Specialists include clinical cardiac electrophysiology and interventional cardiology. In India, a three-year residency in General Medicine or Pediatrics after M.B.B.S. and then three years of residency in cardiology are needed to be a D.M./Diplomate of National Board (DNB) in Cardiology.Per Doximity, adult cardiologists earn an average of $436,849 per year in the U.S.  Cardiac electrophysiology  Cardiac electrophysiology is the science of elucidating, diagnosing, and treating the electrical activities of the heart. The term is usually used to describe studies of such phenomena by invasive (intracardiac) catheter recording of spontaneous activity as well as of cardiac responses to programmed electrical stimulation (PES). These studies are performed to assess complex arrhythmias, elucidate symptoms, evaluate abnormal electrocardiograms, assess risk of developing arrhythmias in the future, and design treatment. These procedures increasingly include therapeutic methods (typically radiofrequency ablation, or cryoablation) in addition to diagnostic and prognostic procedures. Other therapeutic modalities employed in this field include antiarrhythmic drug therapy and implantation of pacemakers and automatic implantable cardioverter-defibrillators (AICD).The cardiac electrophysiology study typically measures the response of the injured or cardiomyopathic myocardium to PES on specific pharmacological regimens in order to assess the likelihood that the regimen will successfully prevent potentially fatal sustained ventricular tachycardia (VT) or ventricular fibrillation (VF) in the future. Sometimes a series of electrophysiology-study drug trials must be conducted to enable the cardiologist to select the one regimen for long-term treatment that best prevents or slows the development of VT or VF following PES. Such studies may also be conducted in the presence of a newly implanted or newly replaced cardiac pacemaker or AICD.  Clinical cardiac electrophysiology  Clinical cardiac electrophysiology is a branch of the medical specialty of cardiology and is concerned with the study and treatment of rhythm disorders of the heart. Cardiologists with expertise in this area are usually referred to as electrophysiologists. Electrophysiologists are trained in the mechanism, function, and performance of the electrical activities of the heart. Electrophysiologists work closely with other cardiologists and cardiac surgeons to assist or guide therapy for heart rhythm disturbances (arrhythmias). They are trained to perform interventional and surgical procedures to treat cardiac arrhythmia.The training required to become an electrophysiologist is long and requires 8 years after medical school (within the U.S.). Three years of internal medicine residency, three years of cardiology fellowship, and two years of clinical cardiac electrophysiology.  Cardiogeriatrics  Cardiogeriatrics, or geriatric cardiology, is the branch of cardiology and geriatric medicine that deals with the cardiovascular disorders in elderly people. Cardiac disorders such as coronary heart disease, including myocardial infarction, heart failure, cardiomyopathy, and arrhythmias such as atrial fibrillation, are common and are a major cause of mortality in elderly people. Vascular disorders such as atherosclerosis and peripheral arterial disease cause significant morbidity and mortality in aged people.  Imaging  Cardiac imaging includes echocardiography (echo), cardiac magnetic resonance imaging (CMR), and computed tomography of the heart. Those who specialize in cardiac imaging may undergo more training in all imaging modes or focus on a single imaging modality. Echocardiography (or ""echo"") uses standard two-dimensional, three-dimensional, and Doppler ultrasound to create images of the heart. Those who specialize in echo may spend a significant amount of their clinical time reading echos and performing transesophageal echo, in particular using the latter during procedures such as insertion of a left atrial appendage occlusion device. Cardiac MRI utilizes special protocols to image heart structure and function with specific sequences for certain diseases such as hemochromatosis and amyloidosis. Cardiac CT utilizes special protocols to image heart structure and function with particular emphasis on coronary arteries.  Interventional cardiology  Interventional cardiology is a branch of cardiology that deals specifically with the catheter based treatment of structural heart diseases. A large number of procedures can be performed on the heart by catheterization, including angiogram, angioplasty, atherectomy, and stent implantation. These procedures all involve insertion of a sheath into the femoral artery or radial artery (but, in practice, any large peripheral artery or vein) and cannulating the heart under X-ray visualization (most commonly fluoroscopy). This cannulation allows indirect access to the heart, bypassing the trauma caused by surgical opening of the chest. The main advantages of using the interventional cardiology or radiology approach are the avoidance of the scars and pain, and long post-operative recovery. Additionally, interventional cardiology procedure of primary angioplasty is now the gold standard of care for an acute myocardial infarction. This procedure can also be done proactively, when areas of the vascular system become occluded from atherosclerosis. The Cardiologist will thread this sheath through the vascular system to access the heart. This sheath has a balloon and a tiny wire mesh tube wrapped around it, and if the cardiologist finds a blockage or stenosis, they can inflate the balloon at the occlusion site in the vascular system to flatten or compress the plaque against the vascular wall. Once that is complete a stent is placed as a type of scaffold to hold the vasculature open permanently.  Cardiomyopathy/heart failure  Specialization of general cardiology to just that of the cardiomyopathies leads to also specializing in heart transplant and pulmonary hypertension. Cardiomyopathy is a heart disease of the heart muscle, where the heart muscle becomes inflamed and thick.  Cardiooncology  A recent specialization of cardiology is that of cardiooncology. This area specializes in the cardiac management in those with cancer and, in particular, those with plans for chemotherapy or whom have experienced cardiac complications of chemotherapy.  Preventive cardiology and cardiac rehabilitation  In recent times, the focus is gradually shifting to preventive cardiology due to increased cardiovascular disease burden at an early age. According to the WHO, 37% of all premature deaths are due to cardiovascular diseases and out of this, 82% are in low and middle income countries. Clinical cardiology is the sub specialty of cardiology which looks after preventive cardiology and cardiac rehabilitation. Preventive cardiology also deals with routine preventive checkup though noninvasive tests, specifically electrocardiography, fasegraphy, stress tests, lipid profile and general physical examination to detect any cardiovascular diseases at an early age, while cardiac rehabilitation is the upcoming branch of cardiology which helps a person regain their overall strength and live a normal life after a cardiovascular event. A subspecialty of preventive cardiology is sports cardiology. Because heart disease is the leading cause of death in the world including United States (cdc.gov), national health campaigns and randomized control research has developed to improve heart health.  Pediatric cardiology  Helen B. Taussig is known as the founder of pediatric cardiology. She became famous through her work with Tetralogy congenital heart defect in which oxygenated and deoxygenated blood enters the circulatory system resulting from a ventricular septal defect (VSD) right beneath the aorta. This condition causes newborns to have a bluish-tint, cyanosis, and have a deficiency of oxygen to their tissues, hypoxemia. She worked with Alfred Blalock and Vivien Thomas at the Johns Hopkins Hospital where they experimented with dogs to look at how they would attempt to surgically cure these ""blue babies."" They eventually figured out how to do just that by the anastomosis of the systemic artery to the pulmonary artery and called this the Blalock-Taussig Shunt.Tetralogy of Fallot, pulmonary atresia, double outlet right ventricle, transposition of the great arteries, persistent truncus arteriosus, and Ebstein's anomaly are various congenital cyanotic heart diseases, in which the blood of the newborn is not oxygenated efficiently, due to the heart defect.  Adult congenital heart disease  As more children with congenital heart disease are surviving into adulthood, a hybrid of adult & pediatric cardiology has emerged called adult congenital heart disease (ACHD). This field can be entered as either adult or pediatric cardiology. ACHD specializes in congenital diseases in the setting of adult diseases (e.g., coronary artery disease, COPD, diabetes) that is, otherwise, atypical for adult or pediatric cardiology.  The heart  As the center focus of cardiology, the heart has numerous anatomical features (e.g., atria, ventricles, heart valves) and numerous physiological features (e.g., systole, heart sounds, afterload) that have been encyclopedically documented for many centuries. Disorders of the heart lead to heart disease and cardiovascular disease and can lead to a significant number of deaths: cardiovascular disease is the leading cause of death in the U.S. and caused 24.95% of total deaths in 2008.The primary responsibility of the heart is to pump blood throughout the body. It pumps blood from the body — called the systemic circulation — through the lungs — called the pulmonary circulation — and then back out to the body. This means that the heart is connected to and affects the entirety of the body. Simplified, the heart is a circuit of the circulation. While plenty is known about the healthy heart, the bulk of study in cardiology is in disorders of the heart and restoration, and where possible, of function. The heart is a muscle that squeezes blood and functions like a pump. The heart's systems can be classified as either electrical or mechanical, and both of these systems are susceptible to failure or dysfunction. The electrical system of the heart is centered on the periodic contraction (squeezing) of the muscle cells that is caused by the cardiac pacemaker located in the sinoatrial node. The study of the electrical aspects is a sub-field of electrophysiology called cardiac electrophysiology and is epitomized with the electrocardiogram (ECG/EKG). The action potentials generated in the pacemaker propagate throughout the heart in a specific pattern. The system that carries this potential is called the electrical conduction system. Dysfunction of the electrical system manifests in many ways and may include Wolff–Parkinson–White syndrome, ventricular fibrillation, and heart block.The mechanical system of the heart is centered on the fluidic movement of blood and the functionality of the heart as a pump. The mechanical part is ultimately the purpose of the heart and many of the disorders of the heart disrupt the ability to move blood. Heart failure is one condition in which the mechanical properties of the heart have failed or are failing, which means insufficient blood is being circulated. Failure to move a sufficient amount of blood through the body can cause damage or failure of other organs and may result in death if severe.  Coronary circulation  Coronary circulation is the circulation of blood in the blood vessels of the heart muscle (the myocardium). The vessels that deliver oxygen-rich blood to the myocardium are known as coronary arteries. The vessels that remove the deoxygenated blood from the heart muscle are known as cardiac veins. These include the great cardiac vein, the middle cardiac vein, the small cardiac vein and the anterior cardiac veins. As the left and right coronary arteries run on the surface of the heart, they can be called epicardial coronary arteries. These arteries, when healthy, are capable of autoregulation to maintain coronary blood flow at levels appropriate to the needs of the heart muscle. These relatively narrow vessels are commonly affected by atherosclerosis and can become blocked, causing angina or myocardial infarction (a.k.a a heart attack). The coronary arteries that run deep within the myocardium are referred to as subendocardial. The coronary arteries are classified as ""end circulation"", since they represent the only source of blood supply to the myocardium; there is very little redundant blood supply, which is why blockage of these vessels can be so critical.  Cardiac examination  The cardiac examination (also called the ""precordial exam""), is performed as part of a physical examination, or when a patient presents with chest pain suggestive of a cardiovascular pathology. It would typically be modified depending on the indication and integrated with other examinations especially the respiratory examination.Like all medical examinations, the cardiac examination follows the standard structure of inspection, palpation and auscultation.  Heart disorders  Cardiology is concerned with the normal functionality of the heart and the deviation from a healthy heart. Many disorders involve the heart itself, but some are outside of the heart and in the vascular system. Collectively, the two are jointly termed the cardiovascular system, and diseases of one part tend to affect the other.  Coronary artery disease  Coronary artery disease, also known as ""ischemic heart disease"", is a group of diseases that includes: stable angina, unstable angina, myocardial infarction, and is one of the causes of sudden cardiac death. It is within the group of cardiovascular diseases of which it is the most common type. A common symptom is chest pain or discomfort which may travel into the shoulder, arm, back, neck, or jaw. Occasionally it may feel like heartburn. Usually symptoms occur with exercise or emotional stress, last less than a few minutes, and get better with rest. Shortness of breath may also occur and sometimes no symptoms are present. The first sign is occasionally a heart attack. Other complications include heart failure or an irregular heartbeat.Risk factors include: high blood pressure, smoking, diabetes, lack of exercise, obesity, high blood cholesterol, poor diet, and excessive alcohol, among others. Other risks include depression. The underlying mechanism involves atherosclerosis of the arteries of the heart. A number of tests may help with diagnoses including: electrocardiogram, cardiac stress testing, coronary computed tomographic angiography, and coronary angiogram, among others.Prevention is by eating a healthy diet, regular exercise, maintaining a healthy weight and not smoking. Sometimes medication for diabetes, high cholesterol, or high blood pressure are also used. There is limited evidence for screening people who are at low risk and do not have symptoms. Treatment involves the same measures as prevention. Additional medications such as antiplatelets including aspirin, beta blockers, or nitroglycerin may be recommended. Procedures such as percutaneous coronary intervention (PCI) or coronary artery bypass surgery (CABG) may be used in severe disease. In those with stable CAD it is unclear if PCI or CABG in addition to the other treatments improve life expectancy or decreases heart attack risk.In 2013 CAD was the most common cause of death globally, resulting in 8.14 million deaths (16.8%) up from 5.74 million deaths (12%) in 1990. The risk of death from CAD for a given age has decreased between 1980 and 2010 especially in developed countries. The number of cases of CAD for a given age has also decreased between 1990 and 2010. In the U.S. in 2010 about 20% of those over 65 had CAD, while it was present in 7% of those 45 to 64, and 1.3% of those 18 to 45. Rates are higher among men than women of a given age.  Cardiomyopathy  Heart failure or formally cardiomyopathy, is the impaired function of the heart and there are numerous causes and forms of heart failure.  Cardiac arrhythmia  Cardiac arrhythmia, also known as ""cardiac dysrhythmia"" or ""irregular heartbeat"", is a group of conditions in which the heartbeat is too fast, too slow, or irregular in its rhythm. A heart rate that is too fast – above 100 beats per minute in adults – is called tachycardia. A heart rate that is too slow – below 60 beats per minute – is called bradycardia. Many types of arrhythmia present no symptoms. When symptoms are present, they may include palpitations, or feeling a pause between heartbeats. More serious symptoms may include lightheadedness, passing out, shortness of breath, or chest pain. While most types of arrhythmia are not serious, some predispose a person to complications such as stroke or heart failure. Others may result in cardiac arrest.There are four main types of arrhythmia: extra beats, supraventricular tachycardias, ventricular arrhythmias, and bradyarrhythmias. Extra beats include premature atrial contractions, premature ventricular contractions, and premature junctional contractions. Supraventricular tachycardias include atrial fibrillation, atrial flutter, and paroxysmal supraventricular tachycardia. Ventricular arrhythmias include ventricular fibrillation and ventricular tachycardia. Arrhythmias are due to problems with the electrical conduction system of the heart. Arrhythmias may occur in children; however, the normal range for the heart rate is different and depends on age. A number of tests can help diagnose arrhythmia, including an electrocardiogram and Holter monitor.Most arrhythmias can be effectively treated. Treatments may include medications, medical procedures such as a pacemaker, and surgery. Medications for a fast heart rate may include beta blockers or agents that attempt to restore a normal heart rhythm such as procainamide. This later group may have more significant side effects especially if taken for a long period of time. Pacemakers are often used for slow heart rates. Those with an irregular heartbeat are often treated with blood thinners to reduce the risk of complications. Those who have severe symptoms from an arrhythmia may receive urgent treatment with a jolt of electricity in the form of cardioversion or defibrillation.Arrhythmia affects millions of people. In Europe and North America, as of 2014, atrial fibrillation affects about 2% to 3% of the population. Atrial fibrillation and atrial flutter resulted in 112,000 deaths in 2013, up from 29,000 in 1990. Sudden cardiac death is the cause of about half of deaths due to cardiovascular disease or about 15% of all deaths globally. About 80% of sudden cardiac death is the result of ventricular arrhythmias. Arrhythmias may occur at any age but are more common among older people.  Cardiac arrest  Cardiac arrest is a sudden stop in effective blood flow due to the failure of the heart to contract effectively. Symptoms include loss of consciousness and abnormal or absent breathing. Some people may have chest pain, shortness of breath, or nausea before this occurs. If not treated within minutes, death usually occurs.The most common cause of cardiac arrest is coronary artery disease. Less common causes include major blood loss, lack of oxygen, very low potassium, heart failure, and intense physical exercise. A number of inherited disorders may also increase the risk including long QT syndrome. The initial heart rhythm is most often ventricular fibrillation. The diagnosis is confirmed by finding no pulse. While a cardiac arrest may be caused by heart attack or heart failure these are not the same.Prevention includes not smoking, physical activity, and maintaining a healthy weight. Treatment for cardiac arrest is immediate cardiopulmonary resuscitation (CPR) and, if a shockable rhythm is present, defibrillation. Among those who survive targeted temperature management may improve outcomes. An implantable cardiac defibrillator may be placed to reduce the chance of death from recurrence.In the United States, cardiac arrest outside of hospital occurs in about 13 per 10,000 people per year (326,000 cases). In hospital cardiac arrest occurs in an additional 209,000 Cardiac arrest becomes more common with age. It affects males more often than females. The percentage of people who survive with treatment is about 8%. Many who survive have significant disability. Many U.S. television shows, however, have portrayed unrealistically high survival rates of 67%.  Hypertension  Hypertension, also known as ""high blood pressure"", is a long term medical condition in which the blood pressure in the arteries is persistently elevated. High blood pressure usually does not cause symptoms. Long term high blood pressure, however, is a major risk factor for coronary artery disease, stroke, heart failure, peripheral vascular disease, vision loss, and chronic kidney disease.Lifestyle factors can increase the risk of hypertension. These include excess salt in the diet, excess body weight, smoking, and alcohol consumption. Hypertension can also be caused by other diseases, or occur as a side-effect of drugs.Blood pressure is expressed by two measurements, the systolic and diastolic pressures, which are the maximum and minimum pressures, respectively. Normal blood pressure when at rest is within the range of 100–140 millimeters mercury (mmHg) systolic and 60–90 mmHg diastolic. High blood pressure is present if the resting blood pressure is persistently at or above 140/90 mmHg for most adults. Different numbers apply to children. When diagnosing high blood pressure, ambulatory blood pressure monitoring over a 24-hour period appears to be more accurate than ""in-office"" blood pressure measurement at a physician's office or other blood pressure screening location.Lifestyle changes and medications can lower blood pressure and decrease the risk of health complications. Lifestyle changes include weight loss, decreased salt intake, physical exercise, and a healthy diet. If changes in lifestyle are insufficient, blood pressure medications may be used. A regimen of up to three medications effectively controls blood pressure in 90% of people. The treatment of moderate to severe high arterial blood pressure (defined as >160/100 mmHg) with medication is associated with an improved life expectancy and reduced morbidity. The effect of treatment for blood pressure between 140/90 mmHg and 160/100 mmHg is less clear, with some studies finding benefits while others do not. High blood pressure affects between 16% and 37% of the population globally. In 2010, hypertension was believed to have been a factor in 18% (9.4 million) deaths.  Essential vs Secondary hypertension  Essential hypertension is the form of hypertension that by definition has no identifiable cause. It is the most common type of hypertension, affecting 95% of hypertensive patients, it tends to be familial and is likely to be the consequence of an interaction between environmental and genetic factors. Prevalence of essential hypertension increases with age, and individuals with relatively high blood pressure at younger ages are at increased risk for the subsequent development of hypertension. Hypertension can increase the risk of cerebral, cardiac, and renal events.Secondary hypertension is a type of hypertension which is caused by an identifiable underlying secondary cause. It is much less common than essential hypertension, affecting only 5% of hypertensive patients. It has many different causes including endocrine diseases, kidney diseases, and tumors. It also can be a side effect of many medications.  Complications of hypertension  Complications of hypertension are clinical outcomes that result from persistent elevation of blood pressure. Hypertension is a risk factor for all clinical manifestations of atherosclerosis since it is a risk factor for atherosclerosis itself.It is an independent predisposing factor for heart failure, coronary artery disease, stroke, renal disease, and peripheral arterial disease. It is the most important risk factor for cardiovascular morbidity and mortality, in industrialized countries.  Congenital heart defects  A congenital heart defect, also known as a ""congenital heart anomaly"" or ""congenital heart disease"", is a problem in the structure of the heart that is present at birth. Signs and symptoms depend on the specific type of problem. Symptoms can vary from none to life-threatening. When present they may include rapid breathing, bluish skin, poor weight gain, and feeling tired. It does not cause chest pain. Most congenital heart problems do not occur with other diseases. Complications that can result from heart defects include heart failure.The cause of a congenital heart defect is often unknown. Certain cases may be due to infections during pregnancy such as rubella, use of certain medications or drugs such as alcohol or tobacco, parents being closely related, or poor nutritional status or obesity in the mother. Having a parent with a congenital heart defect is also a risk factor. A number of genetic conditions are associated with heart defects including Down syndrome, Turner syndrome, and Marfan syndrome. Congenital heart defects are divided into two main groups: cyanotic heart defects and non-cyanotic heart defects, depending on whether the child has the potential to turn bluish in color. The problems may involve the interior walls of the heart, the heart valves, or the large blood vessels that lead to and from the heart.Congenital heart defects are partly preventable through rubella vaccination, the adding of iodine to salt, and the adding of folic acid to certain food products. Some defects do not need treatment. Other may be effectively treated with catheter based procedures or heart surgery. Occasionally a number of operations may be needed. Occasionally heart transplantation is required. With appropriate treatment outcomes, even with complex problems, are generally good.Heart defects are the most common birth defect. In 2013 they were present in 34.3 million people globally. They affect between 4 and 75 per 1,000 live births depending upon how they are diagnosed. About 6 to 19 per 1,000 cause a moderate to severe degree of problems. Congenital heart defects are the leading cause of birth defect-related deaths. In 2013 they resulted in 323,000 deaths down from 366,000 deaths in 1990.  Tetralogy of Fallot  Tetralogy of Fallot is the most common congenital heart disease arising in 1–3 cases per 1,000 births. The cause of this defect is a ventricular septal defect (VSD) and an overriding aorta. These two defects combined causes deoxygenated blood to bypass the lungs and going right back into the circulatory system. The modified Blalock-Taussig shunt is usually used to fix the circulation. This procedure is done by placing a graft between the subclavian artery and the ipsilateral pulmonary artery to restore the correct blood flow.  Pulmonary atresia  Pulmonary atresia happens in 7–8 per 100,000 births and is characterized by the aorta branching out of the right ventricle. This causes the deoxygenated blood to bypass the lungs and enter the circulatory system. Surgeries can fix this by redirecting the aorta and fixing the right ventricle and pulmonary artery connection. There are two types of pulmonary atresia, classified by whether or not the baby also has a ventricular septal defect. Pulmonary atresia with an intact ventricular septum: This type of pulmonary atresia is associated with complete and intact septum between the ventricles. Pulmonary atresia with a ventricular septal defect: This type of pulmonary atresia happens when a ventricular septal defect allows blood to flow into and out of the right ventricle.  Double outlet right ventricle  Double outlet right ventricle (DORV) is when both great arteries, the pulmonary artery and the aorta, are connected to the right ventricle. There is usually a VSD in different particular places depending on the variations of DORV, typically 50% are subaortic and 30%. The surgeries that can be done to fix this defect can vary due to the different physiology and blood flow in the defected heart. One way it can be cured is by a VSD closure and placing conduits to restart the blood flow between the left ventricle and the aorta and between the right ventricle and the pulmonary artery. Another way is systemic-to-pulmonary artery shunt in cases associated with pulmonary stenosis. Also, a balloon atrial septostomy can be done to relieve hypoxemia caused by DORV with the Taussig-Bing anomaly while surgical correction is awaited.  Transposition of great arteries  There are two different types of transposition of the great arteries, Dextro-transposition of the great arteries and Levo-transposition of the great arteries, depending on where the chambers and vessels connect. Dextro-transposition happens in about 1 in 4,000 newborns and is when the right ventricle pumps blood into the aorta and deoxygenated blood enters the bloodstream. The temporary procedure is to create an atrial septal defect. A permanent fix is more complicated and involves redirecting the pulmonary return to the right atrium and the systemic return to the left atrium, which is known as the Senning procedure. The Rastelli procedure can also be done by rerouting the left ventricular outflow, dividing the pulmonary trunk, and placing a conduit in between the right ventricle and pulmonary trunk. Levo-transposition happens in about 1 in 13,000 newborns and is characterized by the left ventricle pumping blood into the lungs and the right ventricle pumping the blood into the aorta. This may not produce problems at the beginning, but will eventually due to the different pressures each ventricle uses to pump blood. Switching the left ventricle to be the systemic ventricle and the right ventricle to pump blood into the pulmonary artery can repair levo-transposition.  Persistent truncus arteriosus  Persistent truncus arteriosus is when the truncus arteriosus fails to split into the aorta and pulmonary trunk. This occurs in about 1 in 11,000 live births and allows both oxygenated and deoxygenated blood into the body. The repair consists of a VSD closure and the Rastelli procedure.  Ebstein anomaly  Ebstein's anomaly is characterized by a right atrium that is significantly enlarged and a heart that is shaped like a box. This is very rare and happens in less than 1% of congenital heart disease cases. The surgical repair varies depending on the severity of the disease.Pediatric cardiology is a sub-specialty of pediatrics. To become a pediatric cardiologist in the U.S., one must complete a three-year residency in pediatrics, followed by a three-year fellowship in pediatric cardiology. Per doximity, pediatric cardiologists make an average of $303,917 in the U.S.  Diagnostic tests in cardiology  Diagnostic tests in cardiology are the methods of identifying heart conditions associated with healthy vs. unhealthy, pathologic heart function. The starting point is obtaining a medical history, followed by Auscultation. Then blood tests, electrophysiological procedures, and cardiac imaging can be ordered for further analysis. Electrophysiological procedures include electrocardiogram, cardiac monitoring, cardiac stress testing, and the electrophysiology study.  Trials  Cardiology is known for randomized controlled trials that guide clinical treatment of cardiac diseases. While dozens are published every year, there are landmark trials that shift treatment significantly. Trials often have an acronym of the trial name, and this acronym is used to reference the trial and its results. Some of these landmark trials include: V-HeFT (1986) — use of vasodilators (hydralazine & isosorbide dinitrate) in heart failure ISIS-2 (1988) — use of aspirin in myocardial infarction CASE I (1991) — use of antiarrhythmic agents after a heart attack increases mortality SOLVD (1991) — use of ACE inhibitors in heart failure 4S (1994) — statins reduce risk of heart disease CURE (1991) — use of dual antiplatelet therapy in NSTEMI MIRACLE (2002) — use of cardiac resynchronization therapy in heart failure SCD-HeFT (2005) — the use of implantable cardioverter-defibrillator in heart failure RELY (2009), ROCKET-AF (2011), ARISTOTLE (2011) — use of DOACs in atrial fibrillation instead of warfarin ISCHEMIA (2020) — medical therapy is as good as coronary stents in stable heart disease  Cardiology community   Associations  American College of Cardiology American Heart Association European Society of Cardiology Heart Rhythm Society Canadian Cardiovascular Society Indian Heart Association National Heart Foundation of Australia Cardiology Society of India  Journals  Acta Cardiologica American Journal of Cardiology Annals of Cardiac Anaesthesia Current Research: Cardiology Cardiology in Review Circulation Circulation Research Clinical and Experimental Hypertension Clinical Cardiology EP – Europace European Heart Journal Heart Heart Rhythm International Journal of Cardiology Journal of the American College of Cardiology Pacing and Clinical Electrophysiology Indian Heart Journal  Cardiologists  Robert Atkins (1930–2003), known for the Atkins diet Eugene Braunwald (born 1929), editor of Braunwald's Heart Disease and 1000+ publications Wallace Brigden (1916–2008), identified cardiomyopathy Manoj Durairaj (1971– ), cardiologist from Pune, India who received Pro Ecclesia et Pontifice Willem Einthoven (1860–1927), a physiologist who built the first practical ECG and won the 1924 Nobel Prize in Physiology or Medicine (""for the discovery of the mechanism of the electrocardiogram"") Werner Forssmann (1904–1979), who infamously performed the first human catheterization on himself that led to him being let go from Berliner Charité Hospital, quitting cardiology as a speciality, and then winning the 1956 Nobel Prize in Physiology or Medicine (""for their discoveries concerning heart catheterization and pathological changes in the circulatory system"") Andreas Gruentzig (1939–1985), first developed balloon angioplasty William Harvey (1578–1657), wrote Exercitatio Anatomica de Motu Cordis et Sanguinis in Animalibus that first described the closed circulatory system and whom Forssmann described as founding cardiology in his Nobel lecture Murray S. Hoffman (born 1924) As president of the Colorado Heart Association, he initiated one of the first jogging programs promoting cardiac health Max Holzmann (1899–1994), co-founder of the Swiss Society of Cardiology, president from 1952 to 1955 Samuel A. Levine (1891–1966), recognized the sign known as Levine's sign as well as the current grading of the intensity of heart murmurs, known as the Levine scale Henry Joseph Llewellyn ""Barney"" Marriott (1917–2007), ECG interpretation and Practical Electrocardiography Bernard Lown (born 1921), original developer of the defibrillator Woldemar Mobitz (1889–1951), described and classified the two types of second-degree atrioventricular block often called ""Mobitz Type I"" and ""Mobitz Type II"" Jacqueline Noonan (born 1928), discoverer of Noonan syndrome that is the top syndromic cause of congenital heart disease John Parkinson (1885–1976), known for Wolff–Parkinson–White syndrome Helen B. Taussig (1898–1986), founder of pediatric cardiology and extensively worked on blue baby syndrome Paul Dudley White (1886–1973), known for Wolff–Parkinson–White syndrome Fredrick Arthur Willius (1888-1872), founder of the cardiology department at the Mayo Clinic and an early pioneer of electrocardiography Louis Wolff (1898–1972), known for Wolff–Parkinson–White syndrome Karel Frederik Wenckebach (1864–1940), first described what is now called type I second-degree atrioventricular block in 1898  See also  Glossary of medicine List of cardiac pharmaceutical agents Outline of cardiology  References   Sources  Braunwald, Eugene, ed. (2019). Braunwald's Heart Disease:A Textbook of Cardiovascular Medicine. Elsevier. ISBN 978-0-323-46299-0. Ramrakha, Punit; Hill, Jonathan, eds. (2012). Oxford Handbook of Cardiology (2nd ed.). Oxford University Press. ISBN 978-0-19-964321-9.  External links  American Heart Association 8+ Exercises To Keep Your Heart Healthy","Cardiology (from Greek καρδίᾱ, kardiā, ""heart""; and -λογία, -logia) is a medical field that deals with disorders of the heart and blood vessels. Physicians in this field are called cardiologists. Cardiologists are different from cardiac surgeons who do cardiac surgery.  Other websites  American College of Cardiology"
"Physiology (; from Ancient Greek φύσις (phúsis) 'nature, origin', and -λογία (-logía) 'study of') is the scientific study of functions and mechanisms in a living system. As a sub-discipline of biology, physiology focuses on how organisms, organ systems, individual organs, cells, and biomolecules carry out the chemical and physical functions in a living system. According to the classes of organisms, the field can be divided into medical physiology, animal physiology, plant physiology, cell physiology, and comparative physiology.Central to physiological functioning are biophysical and biochemical processes, homeostatic control mechanisms, and communication between cells. Physiological state is the condition of normal function. In contrast, pathological state refers to abnormal conditions, including human diseases. The Nobel Prize in Physiology or Medicine is awarded by the Royal Swedish Academy of Sciences for exceptional scientific achievements in physiology related to the field of medicine.  Foundations  Physiology is the branch of biology that focuses on the study of the functions and mechanisms of living organisms, from the molecular and cellular level to the level of whole organisms and populations. The foundations of physiology lie in several key areas, including anatomy, biochemistry, biophysics, genetics, and evolution. Anatomy is the study of the structure and organization of living organisms, from the microscopic level of cells and tissues to the macroscopic level of organs and systems. An understanding of anatomy is essential for understanding the physiological functions of organisms, as the structure of an organism often dictates its function. Biochemistry is the study of the chemical processes and substances that occur within living organisms. It provides the foundation for understanding the metabolic processes that are essential for life, such as the conversion of food into energy and the synthesis of molecules necessary for cellular function. Biophysics is the study of the physical properties of living organisms and their interactions with the environment. It helps to explain how organisms sense and respond to different stimuli, such as light, sound, and temperature, and how they maintain homeostasis, or a stable internal environment. Genetics is the study of heredity and the variation of traits within and between populations. It provides insights into the genetic basis of physiological processes and the ways in which genes interact with the environment to influence an organism's phenotype. Evolutionary biology is the study of the processes that have led to the diversity of life on Earth. It helps to explain the origin and adaptive significance of physiological processes and the ways in which organisms have evolved to cope with their environment. Together, these foundational areas provide the basis for understanding the functions and mechanisms of living organisms at all levels of organization, from the molecular to the ecological.  Cells  Although there are differences between animal, plant, and microbial cells, the basic physiological functions of cells can be divided into the processes of cell division, cell signaling, cell growth, and cell metabolism.  Plants  Plant physiology is a subdiscipline of botany concerned with the functioning of plants. Closely related fields include plant morphology, plant ecology, phytochemistry, cell biology, genetics, biophysics, and molecular biology. Fundamental processes of plant physiology include photosynthesis, respiration, plant nutrition, tropisms, nastic movements, photoperiodism, photomorphogenesis, circadian rhythms, seed germination, dormancy, and stomata function and transpiration. Absorption of water by roots, production of food in the leaves, and growth of shoots towards light are examples of plant physiology.  Animals   Humans  Human physiology is the study of how the human body's systems and functions work together to maintain a stable internal environment. It includes the study of the nervous, endocrine, cardiovascular, respiratory, digestive, and urinary systems, as well as cellular and exercise physiology. Understanding human physiology is essential for diagnosing and treating health conditions and promoting overall wellbeing. It seeks to understand the mechanisms that work to keep the human body alive and functioning, through scientific enquiry into the nature of mechanical, physical, and biochemical functions of humans, their organs, and the cells of which they are composed. The principal level of focus of physiology is at the level of organs and systems within systems. The endocrine and nervous systems play major roles in the reception and transmission of signals that integrate function in animals. Homeostasis is a major aspect with regard to such interactions within plants as well as animals. The biological basis of the study of physiology, integration refers to the overlap of many functions of the systems of the human body, as well as its accompanied form. It is achieved through communication that occurs in a variety of ways, both electrical and chemical.Changes in physiology can impact the mental functions of individuals. Examples of this would be the effects of certain medications or toxic levels of substances. Change in behavior as a result of these substances is often used to assess the health of individuals.Much of the foundation of knowledge in human physiology was provided by animal experimentation. Due to the frequent connection between form and function, physiology and anatomy are intrinsically linked and are studied in tandem as part of a medical curriculum.  Comparative physiology  Involving evolutionary physiology and environmental physiology, comparative physiology considers the diversity of functional characteristics across organisms.  History   The classical era  The study of human physiology as a medical field originates in classical Greece, at the time of Hippocrates (late 5th century BC). Outside of Western tradition, early forms of physiology or anatomy can be reconstructed as having been present at around the same time in China, India and elsewhere. Hippocrates incorporated the theory of humorism, which consisted of four basic substances: earth, water, air and fire. Each substance is known for having a corresponding humor: black bile, phlegm, blood, and yellow bile, respectively. Hippocrates also noted some emotional connections to the four humors, on which Galen would later expand. The critical thinking of Aristotle and his emphasis on the relationship between structure and function marked the beginning of physiology in Ancient Greece. Like Hippocrates, Aristotle took to the humoral theory of disease, which also consisted of four primary qualities in life: hot, cold, wet and dry. Galen (c. 130–200 AD) was the first to use experiments to probe the functions of the body. Unlike Hippocrates, Galen argued that humoral imbalances can be located in specific organs, including the entire body. His modification of this theory better equipped doctors to make more precise diagnoses. Galen also played off of Hippocrates' idea that emotions were also tied to the humors, and added the notion of temperaments: sanguine corresponds with blood; phlegmatic is tied to phlegm; yellow bile is connected to choleric; and black bile corresponds with melancholy. Galen also saw the human body consisting of three connected systems: the brain and nerves, which are responsible for thoughts and sensations; the heart and arteries, which give life; and the liver and veins, which can be attributed to nutrition and growth. Galen was also the founder of experimental physiology. And for the next 1,400 years, Galenic physiology was a powerful and influential tool in medicine.  Early modern period  Jean Fernel (1497–1558), a French physician, introduced the term ""physiology"". Galen, Ibn al-Nafis, Michael Servetus, Realdo Colombo, Amato Lusitano and William Harvey, are credited as making important discoveries in the circulation of the blood. Santorio Santorio in 1610s was the first to use a device to measure the pulse rate (the pulsilogium), and a thermoscope to measure temperature.In 1791 Luigi Galvani described the role of electricity in nerves of dissected frogs. In 1811, César Julien Jean Legallois studied respiration in animal dissection and lesions and found the center of respiration in the medulla oblongata. In the same year, Charles Bell finished work on what would later become known as the Bell–Magendie law, which compared functional differences between dorsal and ventral roots of the spinal cord. In 1824, François Magendie described the sensory roots and produced the first evidence of the cerebellum's role in equilibration to complete the Bell–Magendie law. In the 1820s, the French physiologist Henri Milne-Edwards introduced the notion of physiological division of labor, which allowed to ""compare and study living things as if they were machines created by the industry of man."" Inspired in the work of Adam Smith, Milne-Edwards wrote that the ""body of all living beings, whether animal or plant, resembles a factory ... where the organs, comparable to workers, work incessantly to produce the phenomena that constitute the life of the individual."" In more differentiated organisms, the functional labor could be apportioned between different instruments or systems (called by him as appareils).In 1858, Joseph Lister studied the cause of blood coagulation and inflammation that resulted after previous injuries and surgical wounds. He later discovered and implemented antiseptics in the operating room, and as a result, decreased death rate from surgery by a substantial amount.The Physiological Society was founded in London in 1876 as a dining club. The American Physiological Society (APS) is a nonprofit organization that was founded in 1887. The Society is, ""devoted to fostering education, scientific research, and dissemination of information in the physiological sciences.""In 1891, Ivan Pavlov performed research on ""conditional responses"" that involved dogs' saliva production in response to a bell and visual stimuli.In the 19th century, physiological knowledge began to accumulate at a rapid rate, in particular with the 1838 appearance of the Cell theory of Matthias Schleiden and Theodor Schwann. It radically stated that organisms are made up of units called cells. Claude Bernard's (1813–1878) further discoveries ultimately led to his concept of milieu interieur (internal environment), which would later be taken up and championed as ""homeostasis"" by American physiologist Walter B. Cannon in 1929. By homeostasis, Cannon meant ""the maintenance of steady states in the body and the physiological processes through which they are regulated."" In other words, the body's ability to regulate its internal environment. William Beaumont was the first American to utilize the practical application of physiology. Nineteenth-century physiologists such as Michael Foster, Max Verworn, and Alfred Binet, based on Haeckel's ideas, elaborated what came to be called ""general physiology"", a unified science of life based on the cell actions, later renamed in the 20th century as cell biology.  Late modern period  In the 20th century, biologists became interested in how organisms other than human beings function, eventually spawning the fields of comparative physiology and ecophysiology. Major figures in these fields include Knut Schmidt-Nielsen and George Bartholomew. Most recently, evolutionary physiology has become a distinct subdiscipline.In 1920, August Krogh won the Nobel Prize for discovering how, in capillaries, blood flow is regulated.In 1954, Andrew Huxley and Hugh Huxley, alongside their research team, discovered the sliding filaments in skeletal muscle, known today as the sliding filament theory.Recently, there have been intense debates about the vitality of physiology as a discipline (Is it dead or alive?). If physiology is perhaps less visible nowadays than during the golden age of the 19th century, it is in large part because the field has given birth to some of the most active domains of today's biological sciences, such as neuroscience, endocrinology, and immunology. Furthermore, physiology is still often seen as an integrative discipline, which can put together into a coherent framework data coming from various different domains.  Notable physiologists   Women in physiology  Initially, women were largely excluded from official involvement in any physiological society. The American Physiological Society, for example, was founded in 1887 and included only men in its ranks. In 1902, the American Physiological Society elected Ida Hyde as the first female member of the society. Hyde, a representative of the American Association of University Women and a global advocate for gender equality in education, attempted to promote gender equality in every aspect of science and medicine. Soon thereafter, in 1913, J.S. Haldane proposed that women be allowed to formally join The Physiological Society, which had been founded in 1876. On 3 July 1915, six women were officially admitted: Florence Buchanan, Winifred Cullis, Ruth C. Skelton, Sarah C. M. Sowton, Constance Leetham Terry, and Enid M. Tribe. The centenary of the election of women was celebrated in 2015 with the publication of the book ""Women Physiologists: Centenary Celebrations And Beyond For The Physiological Society."" (ISBN 978-0-9933410-0-7) Prominent women physiologists include: Bodil Schmidt-Nielsen, the first woman president of the American Physiological Society in 1975. Gerty Cori, along with husband Carl Cori, received the Nobel Prize in Physiology or Medicine in 1947 for their discovery of the phosphate-containing form of glucose known as glycogen, as well as its function within eukaryotic metabolic mechanisms for energy production. Moreover, they discovered the Cori cycle, also known as the Lactic acid cycle, which describes how muscle tissue converts glycogen into lactic acid via lactic acid fermentation. Barbara McClintock was rewarded the 1983 Nobel Prize in Physiology or Medicine for the discovery of genetic transposition. McClintock is the only female recipient who has won an unshared Nobel Prize. Gertrude Elion, along with George Hitchings and Sir James Black, received the Nobel Prize for Physiology or Medicine in 1988 for their development of drugs employed in the treatment of several major diseases, such as leukemia, some autoimmune disorders, gout, malaria, and viral herpes. Linda B. Buck, along with Richard Axel, received the Nobel Prize in Physiology or Medicine in 2004 for their discovery of odorant receptors and the complex organization of the olfactory system. Françoise Barré-Sinoussi, along with Luc Montagnier, received the Nobel Prize in Physiology or Medicine in 2008 for their work on the identification of the Human Immunodeficiency Virus (HIV), the cause of Acquired Immunodeficiency Syndrome (AIDS). Elizabeth Blackburn, along with Carol W. Greider and Jack W. Szostak, was awarded the 2009 Nobel Prize for Physiology or Medicine for the discovery of the genetic composition and function of telomeres and the enzyme called telomerase.  Subdisciplines  There are many ways to categorize the subdisciplines of physiology: based on the taxa studied: human physiology, animal physiology, plant physiology, microbial physiology, viral physiology based on the level of organization: cell physiology, molecular physiology, systems physiology, organismal physiology, ecological physiology, integrative physiology based on the process that causes physiological variation: developmental physiology, environmental physiology, evolutionary physiology based on the ultimate goals of the research: applied physiology (e.g., medical physiology), non-applied (e.g., comparative physiology)  Physiological societies  Transnational physiological societies include: American Physiological Society International Union of Physiological Sciences The Physiological SocietyNational physiological societies include: Brazilian Society of Physiology  See also   References   Bibliography  Human physiology Hall, John (2011). Guyton and Hall textbook of medical physiology (12th ed.). Philadelphia, Pa.: Saunders/Elsevier. ISBN 978-1-4160-4574-8. Widmaier, E.P., Raff, H., Strang, K.T. Vander's Human Physiology. 11th Edition, McGraw-Hill, 2009. Marieb, E.N. Essentials of Human Anatomy and Physiology. 10th Edition, Benjamin Cummings, 2012.Animal physiology Hill, R.W., Wyse, G.A., Anderson, M. Animal Physiology, 3rd ed. Sinauer Associates, Sunderland, 2012. Moyes, C.D., Schulte, P.M. Principles of Animal Physiology, second edition. Pearson/Benjamin Cummings. Boston, MA, 2008. Randall, D., Burggren, W., and French, K. Eckert Animal Physiology: Mechanism and Adaptation, 5th Edition. W.H. Freeman and Company, 2002. Schmidt-Nielsen, K. Animal Physiology: Adaptation and Environment. Cambridge & New York: Cambridge University Press, 1997. Withers, P.C. Comparative animal physiology. Saunders College Publishing, New York, 1992.Plant physiology Larcher, W. Physiological plant ecology (4th ed.). Springer, 2001. Salisbury, F.B, Ross, C.W. Plant physiology. Brooks/Cole Pub Co., 1992 Taiz, L., Zieger, E. Plant Physiology (5th ed.), Sunderland, Massachusetts: Sinauer, 2010.Fungal physiology Griffin, D.H. Fungal Physiology, Second Edition. Wiley-Liss, New York, 1994.Protistan physiology Levandowsky, M. Physiological Adaptations of Protists. In: Cell physiology sourcebook: essentials of membrane biophysics. Amsterdam; Boston: Elsevier/AP, 2012. Levandowski, M., Hutner, S.H. (eds). Biochemistry and physiology of protozoa. Volumes 1, 2, and 3. Academic Press: New York, NY, 1979; 2nd ed. Laybourn-Parry J. A Functional Biology of Free-Living Protozoa. Berkeley, California: University of California Press; 1984.Algal physiology Lobban, C.S., Harrison, P.J. Seaweed ecology and physiology. Cambridge University Press, 1997. Stewart, W. D. P. (ed.). Algal Physiology and Biochemistry. Blackwell Scientific Publications, Oxford, 1974.Bacterial physiology El-Sharoud, W. (ed.). Bacterial Physiology: A Molecular Approach. Springer-Verlag, Berlin-Heidelberg, 2008. Kim, B.H., Gadd, M.G. Bacterial Physiology and Metabolism. Cambridge, 2008. Moat, A.G., Foster, J.W., Spector, M.P. Microbial Physiology, 4th ed. Wiley-Liss, Inc. New York, NY, 2002.  External links  Media related to Physiology at Wikimedia Commons physiologyINFO.org public information site sponsored by The American Physiological Society","Physiology is the study of how living things work. Physiologists can study how organs of an organism work together to make things happen. In human beings, for example, the digestion of food hormones and other chemicals are made by the stomach, liver, and pancreas. Muscle contraction happens because of chemical messages made by nerves of that muscle. By learning how the body functions normally, physiologists and physicians can better understand what happens when organs do not function normally. For example, an understanding of how the thyroid gland functions has helped in treating goitre. Studies of the circulatory system and the nervous system have helped physicians understand and treat such illnesses like heart disease, stroke, and high blood pressure. The field is usually divided into human physiology, animal physiology, and plant physiology.  References   Other websites  The Physiological Society Developmental physiology The American Physiological Society"
"An organism (from Ancient Greek ὄργανον (órganon) 'instrument, implement, tool', and -ισμός (-ismós)) is any biological living system that functions as an individual life form. All organisms are composed of cells (cell theory). The idea of organism is based on the concept of minimal functional unit of life. Three traits have been proposed to play the main role in qualification as an organism: noncompartmentability – structure that cannot be divided without its functionality loss, individuality – the entity has simultaneous holding of genetic uniqueness, genetic homogeneity and autonomy, distinctness – genetic information has to maintain open-system (a cell).Organisms include multicellular animals, plants, and fungi; or unicellular microorganisms such as protists, bacteria, and archaea. All types of organisms are capable of reproduction, growth and development, maintenance, and some degree of response to stimuli. Most multicellular organisms differentiate into specialized tissues and organs during their development. A unicellular organism may be either a prokaryote or a eukaryote. Prokaryotes are represented by two separate domains – bacteria and archaea. Eukaryotic organisms are characterized by the presence of a membrane-bound cell nucleus and contain additional membrane-bound compartments called organelles (such as mitochondria in animals and plants and plastids in plants and algae, all generally considered to be derived from endosymbiotic bacteria). Fungi, animals and plants are examples of kingdoms of organisms within the eukaryotes. Estimates on the number of Earth's current species range from 2 million to 1 trillion, of which over 1.7 million have been documented. More than 99% of all species, amounting to over five billion species, that ever lived are estimated to be extinct.In 2016, a set of 355 genes from the last universal common ancestor (LUCA) of all organisms from Earth was identified.  Etymology  The term ""organism"" (from Greek ὀργανισμός, organismos, from ὄργανον, organon, i.e. ""instrument, implement, tool, organ of sense or apprehension"") first appeared in the English language in 1703 and took on its current definition by 1834 (Oxford English Dictionary). It is directly related to the term ""organization"". There is a long tradition of defining organisms as self-organizing beings, going back at least to Immanuel Kant's 1790 Critique of Judgment.  Definitions  An organism may be defined as an assembly of molecules functioning as a more or less stable whole that exhibits the properties of life. Dictionary definitions can be broad, using phrases such as ""any living structure, such as a plant, animal, fungus or bacterium, capable of growth and reproduction"". Many definitions exclude viruses and possible man-made non-organic life forms, as viruses are dependent on the biochemical machinery of a host cell for reproduction. A superorganism is an organism consisting of many individuals working together as a single functional or social unit.There has been controversy about the best way to define the organism, and from a philosophical point of view, whether such a definition is necessary. Problematic cases include colonial organisms: for instance, a colony of eusocial insects fulfils criteria such as adaptive organisation and germ-soma specialisation. If so, the same argument would include some mutualistic and sexual partnerships as organisms. If group selection occurs, then a group could be viewed as a superorganism, optimised by group adaptation. Another view is that attributes like autonomy, genetic homogeneity and genetic uniqueness should be examined separately rather than demanding that an organism should have all of them; if so, there are multiple dimensions to biological individuality, resulting in several types of organism.Other views include the idea that an individual is distinguished by its immune response, separating self from foreign; that ""anti-entropy"", the ability to maintain order, is what distinguishes an organism; or that Shannon's information theory can be used to identify organisms as capable of self-maintaining their information content. Finally, it may be that the concept of the organism is inadequate in biology.  Viruses  Viruses are not typically considered to be organisms because they are incapable of autonomous reproduction, growth or metabolism. Although some organisms are also incapable of independent survival and live as obligatory intracellular parasites, they are capable of independent metabolism and procreation. Although viruses have a few enzymes and molecules characteristic of living organisms, they have no metabolism of their own; they cannot synthesize and organize the organic compounds from which they are formed. Naturally, this rules out autonomous reproduction: they can only be passively replicated by the machinery of the host cell. In this sense, they are similar to inanimate matter. Viruses have their own genes, and they evolve. Thus, an argument that viruses should be classed as living organisms is their ability to undergo evolution and replicate through self-assembly. However, some scientists argue that viruses neither evolve nor self-reproduce. Instead, viruses are evolved by their host cells, meaning that there was co-evolution of viruses and host cells. If host cells did not exist, viral evolution would be impossible. This is not true for cells. If viruses did not exist, the direction of cellular evolution could be different, but cells would nevertheless be able to evolve. As for reproduction, viruses rely on hosts' machinery to replicate. The discovery of viruses with genes coding for energy metabolism and protein synthesis fuelled the debate about whether viruses are living organisms. The presence of these genes suggested that viruses were once able to metabolize. However, it was found later that the genes coding for energy and protein metabolism have a cellular origin. Most likely, these genes were acquired through horizontal gene transfer from viral hosts.  Chemistry  Organisms are complex chemical systems, organized in ways that promote reproduction and some measure of sustainability or survival. The same laws that govern non-living chemistry govern the chemical processes of life. It is generally the phenomena of entire organisms that determine their fitness to an environment and therefore the survival of their DNA-based genes.Organisms clearly owe their origin, metabolism, and many other internal functions to chemical phenomena, especially the chemistry of large organic molecules. Organisms are complex systems of chemical compounds that, through interaction and environment, play a wide variety of roles.{[cn}} Organisms are semi-closed chemical systems. Although they are individual units of life (as the definition requires), they are not closed to the environment around them. To operate, they constantly take in and release energy. Autotrophs produce usable energy (in the form of organic compounds) using light from the Sun or inorganic compounds, while heterotrophs take in organic compounds from the environment. The primary chemical element in these compounds is carbon. The chemical properties of this element such as its great affinity for bonding with other small atoms, including other carbon atoms, and its small size making it capable of forming multiple bonds, make it ideal as the basis of organic life. It is able to form small three-atom compounds (such as carbon dioxide), as well as large chains of many thousands of atoms that can store data (nucleic acids), hold cells together, and transmit information (protein).  Macromolecules  Compounds that make up organisms may be divided into macromolecules and other, smaller molecules. The four groups of macromolecule are nucleic acids, proteins, carbohydrates and lipids. Nucleic acids (specifically deoxyribonucleic acid, or DNA) store genetic data as a sequence of nucleotides. The particular sequence of the four different types of nucleotides (adenine, cytosine, guanine, and thymine) dictate many characteristics that constitute the organism. The sequence is divided up into codons, each of which is a particular sequence of three nucleotides and corresponds to a particular amino acid. Thus, a sequence of DNA codes for a particular protein that, due to the chemical properties of the amino acids it is made from, folds in a particular manner and so performs a particular function.These protein functions have been recognized: Enzymes, which catalyze the reactions of metabolism Structural proteins, such as tubulin, or collagen Regulatory proteins, such as transcription factors or cyclins that regulate the cell cycle Signaling molecules or their receptors, such as some hormones and their receptors Defensive proteins, which can include everything from antibodies of the immune system, to toxins (e.g., dendrotoxins of snakes), to proteins that include unusual amino acids like canavanineA bilayer of phospholipids makes up the membrane of cells that constitutes a barrier, containing everything within a cell and preventing compounds from freely passing into, and out of, the cell. Due to the selective permeability of the phospholipid membrane, only specific compounds can pass through it.  Structure  All organisms consist of structural units called cells; some contain a single cell (unicellular) and others contain many units (multicellular). Multicellular organisms are able to specialize cells to perform specific functions. A group of such cells is a tissue, and in animals these occur as four basic types, namely epithelium, nervous tissue, muscle tissue, and connective tissue. Several types of tissue work together in the form of an organ to produce a particular function (such as the pumping of the blood by the heart, or as a barrier to the environment as the skin). This pattern continues to a higher level with several organs functioning as an organ system such as the reproductive system, and digestive system. Many multicellular organisms consist of several organ systems, which coordinate to allow for life.  Cell  The cell theory, first developed in 1839 by Schleiden and Schwann, states that all organisms are composed of one or more cells; all cells come from preexisting cells, and cells contain the hereditary information necessary for regulating cell functions and for transmitting information to the next generation of cells. There are two types of cells, eukaryotic and prokaryotic. Prokaryotic cells are usually singletons, while eukaryotic cells are usually found in multicellular organisms. Prokaryotic cells lack a nuclear membrane so DNA is unbound within the cell; eukaryotic cells have nuclear membranes. All cells, whether prokaryotic or eukaryotic, have a membrane, which envelops the cell, separates its interior from its environment, regulates what moves in and out, and maintains the electric potential of the cell. Inside the membrane, a salty cytoplasm takes up most of the cell volume. All cells possess DNA, the hereditary material of genes, and RNA, containing the information necessary to build various proteins such as enzymes, the cell's primary machinery. There are also other kinds of biomolecules in cells. All cells share several similar characteristics of: Reproduction by cell division (binary fission, mitosis or meiosis). Use of enzymes and other proteins coded by DNA genes and made via messenger RNA intermediates and ribosomes. Metabolism, including taking in raw materials, building cell components, converting energy, molecules and releasing by-products. The functioning of a cell depends upon its ability to extract and use chemical energy stored in organic molecules. This energy is derived from metabolic pathways. Response to external and internal stimuli such as changes in temperature, pH or nutrient levels. Cell contents are contained within a cell surface membrane that contains proteins and a lipid bilayer.  Evolutionary history   Last universal common ancestor  The last universal common ancestor (LUCA) is the most recent organism from which all organisms now living on Earth descend. Thus, it is the most recent common ancestor of all current life on Earth. The LUCA is estimated to have lived some 3.5 to 3.8 billion years ago (sometime in the Paleoarchean era). The earliest evidence for life on Earth is graphite found to be biogenic in 3.7 billion-year-old metasedimentary rocks discovered in Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone discovered in Western Australia. Although more than 99 percent of all species that ever lived on the planet are estimated to be extinct, it is likely that more than a billion species of life exist on Earth currently, with the highest estimates and projections reaching one trillion species.Information about the early development of life includes input from many different fields, including geology and planetary science. These sciences provide information about the history of the Earth and the changes produced by life. However, a great deal of information about the early Earth has been destroyed by geological processes over the course of time. All organisms are descended from a common ancestor or ancestral gene pool. Evidence for common descent may be found in traits shared between all living organisms. In Darwin's day, the evidence of shared traits was based solely on visible observation of morphologic similarities, such as the fact that all birds have wings, even those that do not fly. There is strong evidence from genetics that all organisms have a common ancestor. For example, every living cell makes use of nucleic acids as its genetic material, and uses the same twenty amino acids as the building blocks for proteins. All organisms use the same genetic code (with some extremely rare and minor deviations) to translate nucleic acid sequences into proteins. The universality of these traits strongly suggests common ancestry, because the selection of many of these traits seems arbitrary. Horizontal gene transfer makes it more difficult to study the last universal ancestor. However, the universal use of the same genetic code, same nucleotides, and same amino acids makes the existence of such an ancestor overwhelmingly likely. The first organisms were possibly anaerobic and thermophilic chemolithoautotrophis that evolved within inorganic compartments at geothermal environments.  Phylogeny   Location of the root  The most commonly accepted location of the root of the tree of life is between a monophyletic domain Bacteria and a clade formed by Archaea and Eukaryota of what is referred to as the ""traditional tree of life"" based on several molecular studies. A very small minority of studies have concluded differently, namely that the root is in the domain Bacteria, either in the phylum Bacillota or that the phylum Chloroflexota is basal to a clade with Archaea and Eukaryotes and the rest of Bacteria as proposed by Thomas Cavalier-Smith.Research published in 2016, by William F. Martin, by genetically analyzing 6.1 million protein-coding genes from sequenced prokaryotic genomes of various phylogenetic trees, identified 355 protein clusters from amongst 286,514 protein clusters that were probably common to the LUCA. The results ""depict LUCA as anaerobic, CO2-fixing, H2-dependent with a Wood–Ljungdahl pathway (the reductive acetyl-coenzyme A pathway), N2-fixing and thermophilic. LUCA's biochemistry was replete with FeS clusters and radical reaction mechanisms. Its cofactors reveal dependence upon transition metals, flavins, S-adenosyl methionine, coenzyme A, ferredoxin, molybdopterin, corrins and selenium. Its genetic code required nucleoside modifications and S-adenosylmethionine-dependent methylations."" The results depict methanogenic clostria as a basal clade in the 355 lineages examined, and suggest that the LUCA inhabited an anaerobic hydrothermal vent setting in a geochemically active environment rich in H2, CO2, and iron. However, the identification of these genes as being present in LUCA was criticized, suggesting that many of the proteins assumed to be present in LUCA represent later horizontal gene transfers between archaea and bacteria.  Reproduction  Sexual reproduction is widespread among current eukaryotes, and was likely present in the last common ancestor. This is suggested by the finding of a core set of genes for meiosis in the descendants of lineages that diverged early from the eukaryotic evolutionary tree. and Malik et al. It is further supported by evidence that eukaryotes previously regarded as ""ancient asexuals"", such as Amoeba, were likely sexual in the past, and that most present day asexual amoeboid lineages likely arose recently and independently.In prokaryotes, natural bacterial transformation involves the transfer of DNA from one bacterium to another and integration of the donor DNA into the recipient chromosome by recombination. Natural bacterial transformation is considered to be a primitive sexual process and occurs in both bacteria and archaea, although it has been studied mainly in bacteria. Transformation is clearly a bacterial adaptation and not an accidental occurrence, because it depends on numerous gene products that specifically interact with each other to enter a state of natural competence to perform this complex process. Transformation is a common mode of DNA transfer among prokaryotes.  Horizontal gene transfer  The ancestry of living organisms has traditionally been reconstructed from morphology, but is increasingly supplemented with phylogenetics – the reconstruction of phylogenies by the comparison of genetic (DNA) sequence. Sequence comparisons suggest recent horizontal transfer of many genes among diverse species including across the boundaries of phylogenetic ""domains"". Thus determining the phylogenetic history of a species can not be done conclusively by determining evolutionary trees for single genes. Biologist Peter Gogarten suggests ""the original metaphor of a tree no longer fits the data from recent genome research"", therefore ""biologists (should) use the metaphor of a mosaic to describe the different histories combined in individual genomes and use (the) metaphor of a net to visualize the rich exchange and cooperative effects of HGT among microbes.""  Future of life (cloning and synthetic organisms)  Modern biotechnology is challenging traditional concepts of organisms and species. Cloning is the process of creating a new multicellular organism, genetically identical to another, with the potential of creating entirely new species of organisms. Cloning is the subject of much ethical debate. In 2008, the J. Craig Venter Institute assembled a synthetic bacterial genome, Mycoplasma genitalium, by using recombination in yeast of 25 overlapping DNA fragments in a single step. The use of yeast recombination greatly simplifies the assembly of large DNA molecules from both synthetic and natural fragments. Other companies, such as Synthetic Genomics, have already been formed to take advantage of the many commercial uses of custom designed genomes.  See also  Earliest known life forms  References   Further reading   External links  ""The Tree of Life"". Tree of Life Web Project. ""Indexing the world's known species"". Species 2000. Species 2000 has the objective of enumerating all known species of plants, animals, fungi and microbes on Earth as the baseline dataset for studies of global biodiversity. It will also provide a simple access point enabling users to link from here to other data systems for all groups of organisms, using direct species-links.","An organism is an individual living thing. It is easy to recognize a living thing, but not so easy to define it. Animals and plants are organisms, obviously. Organisms are a biotic, or living, part of the environment. Rocks and sunshine are parts of the non-living environment. Organisms usually have six basic needs to continue their metabolism. They need air, water, nutrient (food), energy, a place to live, and homeostatsis (being able to maintain itself). However, not all living things need all these at the same time. Some organisms do not need access to air at all. The characteristics of living things are if they have cells, take and use energy, grow and develop, share similar chemicals, sense and resond to change (stimulus), and if they reproduce. A little thought is needed about viruses. There is no agreement as to whether they should be regarded as living. They are made of protein and nucleic acid, and they evolve, which is a really important fact. However, they exist in two quite different phases. One phase is dormant, not active. The other is inside a living cell of some other organism. Then the virus is very active reproducing itself. Consider the parallel with a computer program. When in use it is active; when it is not, it is completely inactive. It is still a program all the same. Another example from biology is the spore, which is a distribution phase of a bacteria, fungus or some plants. They are not active until they get to the right situation. They have all the working parts to build a complete organism, but for the moment it is switched off. Some organisms are made up of millions of cells. They are multicellular organisms. Many can be seen without using a microscope. Most organisms are so small that they cannot be seen with the naked eye. You need a microscope to see them. They are called microorganisms. Organisms can be made up of just one cell. They are called unicellular organisms or single celled organisms. Examples include bacteria, and protozoa such as the Amoeba and Paramecium.  Origin  The Tree of Life project works on the relationships between living things. Identifying a LUCA (last universal common ancestor) is one of its main aims. The LUCA is estimated to have lived some 3.8 billion years ago (sometime in the Palaeoarchaean era). A universal common ancestor is at least 102860 times more probable than having multiple ancestors. A model with a single common ancestor but allowing for some gene swapping among species was... 103489 times more probable than the best multi-ancestor model...The idea came from Charles Darwin's On the Origin of Species, ""Therefore... probably all the organic beings which have ever lived on this earth have descended from some one primordial form...""  Related pages  Earliest known life forms Origin of life Morphology (biology)  References   Other websites  Official website About the Tree of Life Web Project Maddison D.R. et al 2007. The Tree of Life Web Project. Pages 19-40 in: Zhang Z.-Q. & Shear W.A., eds. Linnaeus Tercentenary: progress in invertebrate taxonomy. Zootaxa 1668:1-766. Open Access PDF"
"Animals are multicellular, eukaryotic organisms in the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. As of 2022, 2.16 million living animal species have been described—of which around 1.05 million are insects, over 85,000 are molluscs, and around 65,000 are vertebrates—but it has been estimated there are around 7.77 million animal species in total. Animals range in length from 8.5 micrometres (0.00033 in) to 33.6 metres (110 ft). They have complex interactions with each other and their environments, forming intricate food webs. The scientific study of animals is known as zoology. Most living animal species are in Bilateria, a clade whose members have a bilaterally symmetric body plan. The Bilateria include the protostomes, containing animals such as nematodes, arthropods, flatworms, annelids and molluscs, and the deuterostomes, containing the echinoderms and the chordates, the latter including the vertebrates. Life forms interpreted as early animals were present in the Ediacaran biota of the late Precambrian. Many modern animal phyla became clearly established in the fossil record as marine species during the Cambrian explosion, which began around 539 million years ago. 6,331 groups of genes common to all living animals have been identified; these may have arisen from a single common ancestor that lived 650 million years ago. Historically, Aristotle divided animals into those with blood and those without. Carl Linnaeus created the first hierarchical biological classification for animals in 1758 with his Systema Naturae, which Jean-Baptiste Lamarck expanded into 14 phyla by 1809. In 1874, Ernst Haeckel divided the animal kingdom into the multicellular Metazoa (now synonymous with Animalia) and the Protozoa, single-celled organisms no longer considered animals. In modern times, the biological classification of animals relies on advanced techniques, such as molecular phylogenetics, which are effective at demonstrating the evolutionary relationships between taxa. Humans make use of many animal species, such as for food (including meat, milk, and eggs), for materials (such as leather and wool), as pets, and as working animals including for transport. Dogs have been used in hunting, as have birds of prey, while many terrestrial and aquatic animals were hunted for sports. Nonhuman animals have appeared in art from the earliest times and are featured in mythology and religion.  Etymology  The word ""animal"" comes from the Latin animalis, meaning 'having breath', 'having soul' or 'living being'. The biological definition includes all members of the kingdom Animalia. In colloquial usage, the term animal is often used to refer only to nonhuman animals. The term ""metazoa"" is derived from the Ancient Greek μετα (meta, meaning ""later"") and ζῷᾰ (zōia, plural of ζῷον zōion, meaning animal).  Characteristics  Animals have several characteristics that set them apart from other living things. Animals are eukaryotic and multicellular. Unlike plants and algae, which produce their own nutrients, animals are heterotrophic, feeding on organic material and digesting it internally. With very few exceptions, animals respire aerobically. All animals are motile (able to spontaneously move their bodies) during at least part of their life cycle, but some animals, such as sponges, corals, mussels, and barnacles, later become sessile. The blastula is a stage in embryonic development that is unique to animals, allowing cells to be differentiated into specialised tissues and organs.  Structure  All animals are composed of cells, surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins. During development, the animal extracellular matrix forms a relatively flexible framework upon which cells can move about and be reorganised, making the formation of complex structures possible. This may be calcified, forming structures such as shells, bones, and spicules. In contrast, the cells of other multicellular organisms (primarily algae, plants, and fungi) are held in place by cell walls, and so develop by progressive growth. Animal cells uniquely possess the cell junctions called tight junctions, gap junctions, and desmosomes.With few exceptions—in particular, the sponges and placozoans—animal bodies are differentiated into tissues. These include muscles, which enable locomotion, and nerve tissues, which transmit signals and coordinate the body. Typically, there is also an internal digestive chamber with either one opening (in Ctenophora, Cnidaria, and flatworms) or two openings (in most bilaterians).  Reproduction and development  Nearly all animals make use of some form of sexual reproduction. They produce haploid gametes by meiosis; the smaller, motile gametes are spermatozoa and the larger, non-motile gametes are ova. These fuse to form zygotes, which develop via mitosis into a hollow sphere, called a blastula. In sponges, blastula larvae swim to a new location, attach to the seabed, and develop into a new sponge. In most other groups, the blastula undergoes more complicated rearrangement. It first invaginates to form a gastrula with a digestive chamber and two separate germ layers, an external ectoderm and an internal endoderm. In most cases, a third germ layer, the mesoderm, also develops between them. These germ layers then differentiate to form tissues and organs.Repeated instances of mating with a close relative during sexual reproduction generally leads to inbreeding depression within a population due to the increased prevalence of harmful recessive traits. Animals have evolved numerous mechanisms for avoiding close inbreeding.Some animals are capable of asexual reproduction, which often results in a genetic clone of the parent. This may take place through fragmentation; budding, such as in Hydra and other cnidarians; or parthenogenesis, where fertile eggs are produced without mating, such as in aphids.  Ecology  Animals are categorised into ecological groups depending on how they obtain or consume organic material, including carnivores, herbivores, omnivores, detritivores, and parasites. Interactions between animals form complex food webs. In carnivorous or omnivorous species, predation is a consumer–resource interaction where a predator feeds on another organism (called its prey). Selective pressures imposed on one another lead to an evolutionary arms race between predator and prey, resulting in various anti-predator adaptations. Almost all multicellular predators are animals. Some consumers use multiple methods; for example, in parasitoid wasps, the larvae feed on the hosts' living tissues, killing them in the process, but the adults primarily consume nectar from flowers. Other animals may have very specific feeding behaviours, such as hawksbill sea turtles primarily eating sponges. Most animals rely on the biomass and energy produced by plants through photosynthesis. Herbivores eat plant material directly, while carnivores, and other animals on higher trophic levels typically acquire it indirectly by eating other animals. Animals oxidize carbohydrates, lipids, proteins, and other biomolecules, which allows the animal to grow and to sustain biological processes such as locomotion. Animals living close to hydrothermal vents and cold seeps on the dark sea floor consume organic matter of archaea and bacteria produced in these locations through chemosynthesis (by oxidizing inorganic compounds, such as hydrogen sulfide).Animals originally evolved in the sea. Lineages of arthropods colonised land around the same time as land plants, probably between 510 and 471 million years ago during the Late Cambrian or Early Ordovician. Vertebrates such as the lobe-finned fish Tiktaalik started to move on to land in the late Devonian, about 375 million years ago. Animals occupy virtually all of earth's habitats and microhabitats, including salt water, hydrothermal vents, fresh water, hot springs, swamps, forests, pastures, deserts, air, and the interiors of other animals, plants, fungi, and rocks. Animals are however not particularly heat tolerant; very few of them can survive at constant temperatures above 50 °C (122 °F). Only very few species of animals (mostly nematodes) inhabit the most extreme cold deserts of continental Antarctica.  Diversity   Size  The blue whale (Balaenoptera musculus) is the largest animal that has ever lived, weighing up to 190 tonnes and measuring up to 33.6 metres (110 ft) long. The largest extant terrestrial animal is the African bush elephant (Loxodonta africana), weighing up to 12.25 tonnes and measuring up to 10.67 metres (35.0 ft) long. The largest terrestrial animals that ever lived were titanosaur sauropod dinosaurs such as Argentinosaurus, which may have weighed as much as 73 tonnes, and Supersaurus which may have reached 39 meters. Several animals are microscopic; some Myxozoa (obligate parasites within the Cnidaria) never grow larger than 20 µm, and one of the smallest species (Myxobolus shekel) is no more than 8.5 µm when fully grown.  Numbers and habitats  The following table lists estimated numbers of described extant species for all the animal groups, along with their principal habitats (terrestrial, fresh water, and marine), and free-living or parasitic ways of life. Species estimates shown here are based on numbers described scientifically; much larger estimates have been calculated based on various means of prediction, and these can vary wildly. For instance, around 25,000–27,000 species of nematodes have been described, while published estimates of the total number of nematode species include 10,000–20,000; 500,000; 10 million; and 100 million. Using patterns within the taxonomic hierarchy, the total number of animal species—including those not yet described—was calculated to be about 7.77 million in 2011.  Evolutionary origin  Animals are found as long ago as the Ediacaran biota, towards the end of the Precambrian, and possibly somewhat earlier. It had long been doubted whether these life-forms included animals, but the discovery of the animal lipid cholesterol in fossils of Dickinsonia establishes their nature. Animals are thought to have originated under low-oxygen conditions, suggesting that they were capable of living entirely by anaerobic respiration, but as they became specialized for aerobic metabolism they became fully dependent on oxygen in their environments.Many animal phyla first appear in the fossil record during the Cambrian explosion, starting about 539 million years ago, in beds such as the Burgess shale. Extant phyla in these rocks include molluscs, brachiopods, onychophorans, tardigrades, arthropods, echinoderms and hemichordates, along with numerous now-extinct forms such as the predatory Anomalocaris. The apparent suddenness of the event may however be an artefact of the fossil record, rather than showing that all these animals appeared simultaneously. That view is supported by the discovery of Auroralumina attenboroughii, the earliest known Ediacaran crown-group cnidarian (557–562 mya, some 20 million years before the Cambrian explosion) from Charnwood Forest, England. It is thought to be one of the earliest predators, catching small prey with its nematocysts as modern cnidarians do.Some palaeontologists have suggested that animals appeared much earlier than the Cambrian explosion, possibly as early as 1 billion years ago. Early fossils that might represent animals appear for example in the 665-million-year-old rocks of the Trezona Formation of South Australia. These fossils are interpreted as most probably being early sponges.Trace fossils such as tracks and burrows found in the Tonian period (from 1 gya) may indicate the presence of triploblastic worm-like animals, roughly as large (about 5 mm wide) and complex as earthworms. However, similar tracks are produced today by the giant single-celled protist Gromia sphaerica, so the Tonian trace fossils may not indicate early animal evolution. Around the same time, the layered mats of microorganisms called stromatolites decreased in diversity, perhaps due to grazing by newly evolved animals. Objects such as sediment-filled tubes that resemble trace fossils of the burrows of wormlike animals have been found in 1.2 gya rocks in North America, in 1.5 gya rocks in Australia and North America, and in 1.7 gya rocks in Australia. Their interpretation as having an animal origin is disputed, as they might be water-escape or other structures.  Phylogeny  Animals are monophyletic, meaning they are derived from a common ancestor. Animals are sister to the Choanoflagellata, with which they form the Choanozoa. The most basal animals, the Porifera, Ctenophora, Cnidaria, and Placozoa, have body plans that lack bilateral symmetry. Their relationships are still disputed; the sister group to all other animals could be the Porifera or the Ctenophora, both of which lack hox genes, important in body plan development.These genes are found in the Placozoa and the higher animals, the Bilateria. 6,331 groups of genes common to all living animals have been identified; these may have arisen from a single common ancestor that lived 650 million years ago in the Precambrian. 25 of these are novel core gene groups, found only in animals; of those, 8 are for essential components of the Wnt and TGF-beta signalling pathways which may have enabled animals to become multicellular by providing a pattern for the body's system of axes (in three dimensions), and another 7 are for transcription factors including homeodomain proteins involved in the control of development.The phylogenetic tree indicates approximately how many millions of years ago (mya) the lineages split.  Non-bilateria  Several animal phyla lack bilateral symmetry. Among these, the sponges (Porifera) probably diverged first, representing the oldest animal phylum. Sponges lack the complex organization found in most other animal phyla; their cells are differentiated, but in most cases not organised into distinct tissues. They typically feed by drawing in water through pores.The Ctenophora (comb jellies) and Cnidaria (which includes jellyfish, sea anemones, and corals) are radially symmetric and have digestive chambers with a single opening, which serves as both mouth and anus. They are sometimes placed together in the group Coelenterata because of common traits, not because of close relationships. Animals in both phyla have distinct tissues, but these are not organised into organs. They are diploblastic, having only two main germ layers, ectoderm and endoderm. The tiny placozoans are similar, but they do not have a permanent digestive chamber.  Bilateria  The remaining animals, the great majority—comprising some 29 phyla and over a million species—form a clade, the Bilateria, which have a bilaterally symmetric body plan. The Bilateria are triploblastic, with three well-developed germ layers, and their tissues form distinct organs. The digestive chamber has two openings, a mouth and an anus, and there is an internal body cavity, a coelom or pseudocoelom. These animals have a head end (anterior) and a tail end (posterior), a back (dorsal) surface and a belly (ventral) surface, and a left and a right side.Having a front end means that this part of the body encounters stimuli, such as food, favouring cephalisation, the development of a head with sense organs and a mouth. Many bilaterians have a combination of circular muscles that constrict the body, making it longer, and an opposing set of longitudinal muscles, that shorten the body; these enable soft-bodied animals with a hydrostatic skeleton to move by peristalsis. They also have a gut that extends through the basically cylindrical body from mouth to anus. Many bilaterian phyla have primary larvae which swim with cilia and have an apical organ containing sensory cells. However, over evolutionary time, descendant spaces have evolved which have lost one or more of each of these characteristics. For example, adult echinoderms are radially symmetric (unlike their larvae), while some parasitic worms have extremely simplified body structures.Genetic studies have considerably changed zoologists' understanding of the relationships within the Bilateria. Most appear to belong to two major lineages, the protostomes and the deuterostomes. The basalmost bilaterians are the Xenacoelomorpha.  Protostomes and deuterostomes  Protostomes and deuterostomes differ in several ways. Early in development, deuterostome embryos undergo radial cleavage during cell division, while many protostomes (the Spiralia) undergo spiral cleavage. Animals from both groups possess a complete digestive tract, but in protostomes the first opening of the embryonic gut develops into the mouth, and the anus forms secondarily. In deuterostomes, the anus forms first while the mouth develops secondarily. Most protostomes have schizocoelous development, where cells simply fill in the interior of the gastrula to form the mesoderm. In deuterostomes, the mesoderm forms by enterocoelic pouching, through invagination of the endoderm.The main deuterostome phyla are the Echinodermata and the Chordata. Echinoderms are exclusively marine and include starfish, sea urchins, and sea cucumbers. The chordates are dominated by the vertebrates (animals with backbones), which consist of fishes, amphibians, reptiles, birds, and mammals. The deuterostomes also include the Hemichordata (acorn worms).  Ecdysozoa  The Ecdysozoa are protostomes, named after their shared trait of ecdysis, growth by moulting. They include the largest animal phylum, the Arthropoda, which contains insects, spiders, crabs, and their kin. All of these have a body divided into repeating segments, typically with paired appendages. Two smaller phyla, the Onychophora and Tardigrada, are close relatives of the arthropods and share these traits. The ecdysozoans also include the Nematoda or roundworms, perhaps the second largest animal phylum. Roundworms are typically microscopic, and occur in nearly every environment where there is water; some are important parasites. Smaller phyla related to them are the Nematomorpha or horsehair worms, and the Kinorhyncha, Priapulida, and Loricifera. These groups have a reduced coelom, called a pseudocoelom.  Spiralia  The Spiralia are a large group of protostomes that develop by spiral cleavage in the early embryo. The Spiralia's phylogeny has been disputed, but it contains a large clade, the superphylum Lophotrochozoa, and smaller groups of phyla such as the Rouphozoa which includes the gastrotrichs and the flatworms. All of these are grouped as the Platytrochozoa, which has a sister group, the Gnathifera, which includes the rotifers.The Lophotrochozoa includes the molluscs, annelids, brachiopods, nemerteans, bryozoa and entoprocts. The molluscs, the second-largest animal phylum by number of described species, includes snails, clams, and squids, while the annelids are the segmented worms, such as earthworms, lugworms, and leeches. These two groups have long been considered close relatives because they share trochophore larvae.  History of classification  In the classical era, Aristotle divided animals, based on his own observations, into those with blood (roughly, the vertebrates) and those without. The animals were then arranged on a scale from man (with blood, 2 legs, rational soul) down through the live-bearing tetrapods (with blood, 4 legs, sensitive soul) and other groups such as crustaceans (no blood, many legs, sensitive soul) down to spontaneously generating creatures like sponges (no blood, no legs, vegetable soul). Aristotle was uncertain whether sponges were animals, which in his system ought to have sensation, appetite, and locomotion, or plants, which did not: he knew that sponges could sense touch, and would contract if about to be pulled off their rocks, but that they were rooted like plants and never moved about.In 1758, Carl Linnaeus created the first hierarchical classification in his Systema Naturae. In his original scheme, the animals were one of three kingdoms, divided into the classes of Vermes, Insecta, Pisces, Amphibia, Aves, and Mammalia. Since then the last four have all been subsumed into a single phylum, the Chordata, while his Insecta (which included the crustaceans and arachnids) and Vermes have been renamed or broken up. The process was begun in 1793 by Jean-Baptiste de Lamarck, who called the Vermes une espèce de chaos (a chaotic mess) and split the group into three new phyla: worms, echinoderms, and polyps (which contained corals and jellyfish). By 1809, in his Philosophie Zoologique, Lamarck had created 9 phyla apart from vertebrates (where he still had 4 phyla: mammals, birds, reptiles, and fish) and molluscs, namely cirripedes, annelids, crustaceans, arachnids, insects, worms, radiates, polyps, and infusorians.In his 1817 Le Règne Animal, Georges Cuvier used comparative anatomy to group the animals into four embranchements (""branches"" with different body plans, roughly corresponding to phyla), namely vertebrates, molluscs, articulated animals (arthropods and annelids), and zoophytes (radiata) (echinoderms, cnidaria and other forms). This division into four was followed by the embryologist Karl Ernst von Baer in 1828, the zoologist Louis Agassiz in 1857, and the comparative anatomist Richard Owen in 1860.In 1874, Ernst Haeckel divided the animal kingdom into two subkingdoms: Metazoa (multicellular animals, with five phyla: coelenterates, echinoderms, articulates, molluscs, and vertebrates) and Protozoa (single-celled animals), including a sixth animal phylum, sponges. The protozoa were later moved to the former kingdom Protista, leaving only the Metazoa as a synonym of Animalia.  In human culture   Practical uses  The human population exploits a large number of other animal species for food, both of domesticated livestock species in animal husbandry and, mainly at sea, by hunting wild species. Marine fish of many species are caught commercially for food. A smaller number of species are farmed commercially. Humans and their livestock make up more than 90% of the biomass of all terrestrial vertebrates, and almost as much as all insects combined.Invertebrates including cephalopods, crustaceans, and bivalve or gastropod molluscs are hunted or farmed for food. Chickens, cattle, sheep, pigs, and other animals are raised as livestock for meat across the world. Animal fibres such as wool are used to make textiles, while animal sinews have been used as lashings and bindings, and leather is widely used to make shoes and other items. Animals have been hunted and farmed for their fur to make items such as coats and hats. Dyestuffs including carmine (cochineal), shellac, and kermes have been made from the bodies of insects. Working animals including cattle and horses have been used for work and transport from the first days of agriculture.Animals such as the fruit fly Drosophila melanogaster serve a major role in science as experimental models. Animals have been used to create vaccines since their discovery in the 18th century. Some medicines such as the cancer drug trabectedin are based on toxins or other molecules of animal origin. People have used hunting dogs to help chase down and retrieve animals, and birds of prey to catch birds and mammals, while tethered cormorants have been used to catch fish. Poison dart frogs have been used to poison the tips of blowpipe darts. A wide variety of animals are kept as pets, from invertebrates such as tarantulas and octopuses, insects including praying mantises, reptiles such as snakes and chameleons, and birds including canaries, parakeets, and parrots all finding a place. However, the most kept pet species are mammals, namely dogs, cats, and rabbits. There is a tension between the role of animals as companions to humans, and their existence as individuals with rights of their own. A wide variety of terrestrial and aquatic animals are hunted for sport.  Symbolic uses  Animals have been the subjects of art from the earliest times, both historical, as in Ancient Egypt, and prehistoric, as in the cave paintings at Lascaux. Major animal paintings include Albrecht Dürer's 1515 The Rhinoceros, and George Stubbs's c. 1762 horse portrait Whistlejacket. Insects, birds and mammals play roles in literature and film, such as in giant bug movies.Animals including insects and mammals feature in mythology and religion. In both Japan and Europe, a butterfly was seen as the personification of a person's soul, while the scarab beetle was sacred in ancient Egypt. Among the mammals, cattle, deer, horses, lions, bats, bears, and wolves are the subjects of myths and worship. The signs of the Western and Chinese zodiacs are based on animals.  See also  Animal attacks Animal coloration Ethology Fauna List of animal names Lists of organisms by population  Notes   References   External links  Tree of Life Project Archived 12 June 2011 at the Wayback Machine Animal Diversity Web – University of Michigan's database of animals Wildscreen Arkive – multimedia database of endangered/protected species","Animals (or Metazoa) are living creatures with many cells. Animals get their energy from other living things. Usually they eat them or are parasites. Animals, plants, fungi, and some other living things have complex cells, so they are grouped together as eukaryotes. The study of animals is called zoology. The study of ancient life is called palaeontology. Most animals are mobile, meaning they can move around. Animals take in oxygen, and give out carbon dioxide. This cellular respiration is part of their metabolism (chemical working). In both these ways they are different from plants. Also, the cells of animals have different cell membranes to other eukaryotes like plants and fungi. Plants are also multicellular eukaryotic organisms, but live by using light, water and basic elements to make their tissues.  Grouping animals  There are many different types of animals. The common animals most people know are only about 3% of the animal kingdom. When biologists look at animals, they find things that certain animals have in common. They use this to group the animals in a biological classification. Several million species may exist, but biologists have only identified about one million. Animals can mainly be divided into two main groups: the invertebrates and the vertebrates. Vertebrates have a backbone, or spine; invertebrates do not. Vertebrates are the only group to have an adaptive immune system, which may be partly responsible for their size and success.Vertebrates are: Fish (or 'fishes': both ways are correct) Amphibia Reptiles Birds MammalsSome invertebrates are: Insects Spiders Crustacea Molluscs (like a snail or squid) worms jellyfish  Life styles  The animal mode of nutrition is called heterotrophic because they get their food from other living organisms. Some animals eat only plants; they are called herbivores. Other animals eat only meat and are called carnivores. Animals that eat both plants and meat are called omnivores. Some animals get their energy from photosynthetic protists that live inside them. The environments animals live in vary greatly. By the process of evolution, animals adapt to the habitats they live in. A fish is adapted to its life in water and a spider is adapted to a life catching and eating insects. A mammal living on the savannahs of East Africa lives quite a different life from a dolphin or porpoise catching fish in the sea. The fossil record of animals goes back about 600 million years to the Ediacaran period, or somewhat earlier. During the whole of this long time, animals have been constantly evolving, so that the animals alive on Earth today are very different from those on the edges of the sea-floor in the Ediacaran.  Everyday language  In scientific usage, humans are animals. But in everyday use, humans are often not regarded as animals.  Related pages  List of animal phyla Ethology, the study of animal behaviour  References "
"Deoxyribonucleic acid ( (listen); DNA) is a polymer composed of two polynucleotide chains that coil around each other to form a double helix. The polymer carries genetic instructions for the development, functioning, growth and reproduction of all known organisms and many viruses. DNA and ribonucleic acid (RNA) are nucleic acids. Alongside proteins, lipids and complex carbohydrates (polysaccharides), nucleic acids are one of the four major types of macromolecules that are essential for all known forms of life. The two DNA strands are known as polynucleotides as they are composed of simpler monomeric units called nucleotides. Each nucleotide is composed of one of four nitrogen-containing nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds (known as the phosphodiester linkage) between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound together, according to base pairing rules (A with T and C with G), with hydrogen bonds to make double-stranded DNA. The complementary nitrogenous bases are divided into two groups, pyrimidines and purines. In DNA, the pyrimidines are thymine and cytosine; the purines are adenine and guanine. Both strands of double-stranded DNA store the same biological information. This information is replicated when the two strands separate. A large part of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences. The two strands of DNA run in opposite directions to each other and are thus antiparallel. Attached to each sugar is one of four types of nucleobases (or bases). It is the sequence of these four nucleobases along the backbone that encodes genetic information. RNA strands are created using DNA strands as a template in a process called transcription, where DNA bases are exchanged for their corresponding bases except in the case of thymine (T), for which RNA substitutes uracil (U). Under the genetic code, these RNA strands specify the sequence of amino acids within proteins in a process called translation. Within eukaryotic cells, DNA is organized into long structures called chromosomes. Before typical cell division, these chromosomes are duplicated in the process of DNA replication, providing a complete set of chromosomes for each daughter cell. Eukaryotic organisms (animals, plants, fungi and protists) store most of their DNA inside the cell nucleus as nuclear DNA, and some in the mitochondria as mitochondrial DNA or in chloroplasts as chloroplast DNA. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm, in circular chromosomes. Within eukaryotic chromosomes, chromatin proteins, such as histones, compact and organize DNA. These compacting structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.  Properties  DNA is a long polymer made from repeating units called nucleotides. The structure of DNA is dynamic along its length, being capable of coiling into tight loops and other shapes. In all species it is composed of two helical chains, bound to each other by hydrogen bonds. Both chains are coiled around the same axis, and have the same pitch of 34 ångströms (3.4 nm). The pair of chains have a radius of 10 Å (1.0 nm). According to another study, when measured in a different solution, the DNA chain measured 22–26 Å (2.2–2.6 nm) wide, and one nucleotide unit measured 3.3 Å (0.33 nm) long.DNA does not usually exist as a single strand, but instead as a pair of strands that are held tightly together. These two long strands coil around each other, in the shape of a double helix. The nucleotide contains both a segment of the backbone of the molecule (which holds the chain together) and a nucleobase (which interacts with the other DNA strand in the helix). A nucleobase linked to a sugar is called a nucleoside, and a base linked to a sugar and to one or more phosphate groups is called a nucleotide. A biopolymer comprising multiple linked nucleotides (as in DNA) is called a polynucleotide.The backbone of the DNA strand is made from alternating phosphate and sugar groups. The sugar in DNA is 2-deoxyribose, which is a pentose (five-carbon) sugar. The sugars are joined by phosphate groups that form phosphodiester bonds between the third and fifth carbon atoms of adjacent sugar rings. These are known as the 3′-end (three prime end), and 5′-end (five prime end) carbons, the prime symbol being used to distinguish these carbon atoms from those of the base to which the deoxyribose forms a glycosidic bond.Therefore, any DNA strand normally has one end at which there is a phosphate group attached to the 5′ carbon of a ribose (the 5′ phosphoryl) and another end at which there is a free hydroxyl group attached to the 3′ carbon of a ribose (the 3′ hydroxyl). The orientation of the 3′ and 5′ carbons along the sugar-phosphate backbone confers directionality (sometimes called polarity) to each DNA strand. In a nucleic acid double helix, the direction of the nucleotides in one strand is opposite to their direction in the other strand: the strands are antiparallel. The asymmetric ends of DNA strands are said to have a directionality of five prime end (5′ ), and three prime end (3′), with the 5′ end having a terminal phosphate group and the 3′ end a terminal hydroxyl group. One major difference between DNA and RNA is the sugar, with the 2-deoxyribose in DNA being replaced by the related pentose sugar ribose in RNA. The DNA double helix is stabilized primarily by two forces: hydrogen bonds between nucleotides and base-stacking interactions among aromatic nucleobases. The four bases found in DNA are adenine (A), cytosine (C), guanine (G) and thymine (T). These four bases are attached to the sugar-phosphate to form the complete nucleotide, as shown for adenosine monophosphate. Adenine pairs with thymine and guanine pairs with cytosine, forming A-T and G-C base pairs.  Nucleobase classification  The nucleobases are classified into two types: the purines, A and G, which are fused five- and six-membered heterocyclic compounds, and the pyrimidines, the six-membered rings C and T. A fifth pyrimidine nucleobase, uracil (U), usually takes the place of thymine in RNA and differs from thymine by lacking a methyl group on its ring. In addition to RNA and DNA, many artificial nucleic acid analogues have been created to study the properties of nucleic acids, or for use in biotechnology.  Non-canonical bases  Modified bases occur in DNA. The first of these recognized was 5-methylcytosine, which was found in the genome of Mycobacterium tuberculosis in 1925. The reason for the presence of these noncanonical bases in bacterial viruses (bacteriophages) is to avoid the restriction enzymes present in bacteria. This enzyme system acts at least in part as a molecular immune system protecting bacteria from infection by viruses. Modifications of the bases cytosine and adenine, the more common and modified DNA bases, play vital roles in the epigenetic control of gene expression in plants and animals.A number of noncanonical bases are known to occur in DNA. Most of these are modifications of the canonical bases plus uracil. Modified Adenine N6-carbamoyl-methyladenine N6-methyadenine Modified Guanine 7-Deazaguanine 7-Methylguanine Modified Cytosine N4-Methylcytosine 5-Carboxylcytosine 5-Formylcytosine 5-Glycosylhydroxymethylcytosine 5-Hydroxycytosine 5-Methylcytosine Modified Thymidine α-Glutamythymidine α-Putrescinylthymine Uracil and modifications Base J Uracil 5-Dihydroxypentauracil 5-Hydroxymethyldeoxyuracil Others Deoxyarchaeosine 2,6-Diaminopurine (2-Aminoadenine)  Grooves  Twin helical strands form the DNA backbone. Another double helix may be found tracing the spaces, or grooves, between the strands. These voids are adjacent to the base pairs and may provide a binding site. As the strands are not symmetrically located with respect to each other, the grooves are unequally sized. The major groove is 22 ångströms (2.2 nm) wide, while the minor groove is 12 Å (1.2 nm) in width. Due to the larger width of the major groove, the edges of the bases are more accessible in the major groove than in the minor groove. As a result, proteins such as transcription factors that can bind to specific sequences in double-stranded DNA usually make contact with the sides of the bases exposed in the major groove. This situation varies in unusual conformations of DNA within the cell (see below), but the major and minor grooves are always named to reflect the differences in width that would be seen if the DNA was twisted back into the ordinary B form.  Base pairing  In a DNA double helix, each type of nucleobase on one strand bonds with just one type of nucleobase on the other strand. This is called complementary base pairing. Purines form hydrogen bonds to pyrimidines, with adenine bonding only to thymine in two hydrogen bonds, and cytosine bonding only to guanine in three hydrogen bonds. This arrangement of two nucleotides binding together across the double helix (from six-carbon ring to six-carbon ring) is called a Watson-Crick base pair. DNA with high GC-content is more stable than DNA with low GC-content. A Hoogsteen base pair (hydrogen bonding the 6-carbon ring to the 5-carbon ring) is a rare variation of base-pairing. As hydrogen bonds are not covalent, they can be broken and rejoined relatively easily. The two strands of DNA in a double helix can thus be pulled apart like a zipper, either by a mechanical force or high temperature. As a result of this base pair complementarity, all the information in the double-stranded sequence of a DNA helix is duplicated on each strand, which is vital in DNA replication. This reversible and specific interaction between complementary base pairs is critical for all the functions of DNA in organisms.  ssDNA vs. dsDNA  As noted above, most DNA molecules are actually two polymer strands, bound together in a helical fashion by noncovalent bonds; this double-stranded (dsDNA) structure is maintained largely by the intrastrand base stacking interactions, which are strongest for G,C stacks. The two strands can come apart—a process known as melting—to form two single-stranded DNA (ssDNA) molecules. Melting occurs at high temperatures, low salt and high pH (low pH also melts DNA, but since DNA is unstable due to acid depurination, low pH is rarely used). The stability of the dsDNA form depends not only on the GC-content (% G,C basepairs) but also on sequence (since stacking is sequence specific) and also length (longer molecules are more stable). The stability can be measured in various ways; a common way is the melting temperature (also called Tm value), which is the temperature at which 50% of the double-strand molecules are converted to single-strand molecules; melting temperature is dependent on ionic strength and the concentration of DNA. As a result, it is both the percentage of GC base pairs and the overall length of a DNA double helix that determines the strength of the association between the two strands of DNA. Long DNA helices with a high GC-content have more strongly interacting strands, while short helices with high AT content have more weakly interacting strands. In biology, parts of the DNA double helix that need to separate easily, such as the TATAAT Pribnow box in some promoters, tend to have a high AT content, making the strands easier to pull apart.In the laboratory, the strength of this interaction can be measured by finding the melting temperature Tm necessary to break half of the hydrogen bonds. When all the base pairs in a DNA double helix melt, the strands separate and exist in solution as two entirely independent molecules. These single-stranded DNA molecules have no single common shape, but some conformations are more stable than others.  Amount  In humans, the total female diploid nuclear genome per cell extends for 6.37 Gigabase pairs (Gbp), is 208.23 cm long and weighs 6.51 picograms (pg). Male values are 6.27 Gbp, 205.00 cm, 6.41 pg. Each DNA polymer can contain hundreds of millions of nucleotides, such as in chromosome 1. Chromosome 1 is the largest human chromosome with approximately 220 million base pairs, and would be 85 mm long if straightened.In eukaryotes, in addition to nuclear DNA, there is also mitochondrial DNA (mtDNA) which encodes certain proteins used by the mitochondria. The mtDNA is usually relatively small in comparison to the nuclear DNA. For example, the human mitochondrial DNA forms closed circular molecules, each of which contains 16,569 DNA base pairs, with each such molecule normally containing a full set of the mitochondrial genes. Each human mitochondrion contains, on average, approximately 5 such mtDNA molecules. Each human cell contains approximately 100 mitochondria, giving a total number of mtDNA molecules per human cell of approximately 500. However, the amount of mitochondria per cell also varies by cell type, and an egg cell can contain 100,000 mitochondria, corresponding to up to 1,500,000 copies of the mitochondrial genome (constituting up to 90% of the DNA of the cell).  Sense and antisense  A DNA sequence is called a ""sense"" sequence if it is the same as that of a messenger RNA copy that is translated into protein. The sequence on the opposite strand is called the ""antisense"" sequence. Both sense and antisense sequences can exist on different parts of the same strand of DNA (i.e. both strands can contain both sense and antisense sequences). In both prokaryotes and eukaryotes, antisense RNA sequences are produced, but the functions of these RNAs are not entirely clear. One proposal is that antisense RNAs are involved in regulating gene expression through RNA-RNA base pairing.A few DNA sequences in prokaryotes and eukaryotes, and more in plasmids and viruses, blur the distinction between sense and antisense strands by having overlapping genes. In these cases, some DNA sequences do double duty, encoding one protein when read along one strand, and a second protein when read in the opposite direction along the other strand. In bacteria, this overlap may be involved in the regulation of gene transcription, while in viruses, overlapping genes increase the amount of information that can be encoded within the small viral genome.  Supercoiling  DNA can be twisted like a rope in a process called DNA supercoiling. With DNA in its ""relaxed"" state, a strand usually circles the axis of the double helix once every 10.4 base pairs, but if the DNA is twisted the strands become more tightly or more loosely wound. If the DNA is twisted in the direction of the helix, this is positive supercoiling, and the bases are held more tightly together. If they are twisted in the opposite direction, this is negative supercoiling, and the bases come apart more easily. In nature, most DNA has slight negative supercoiling that is introduced by enzymes called topoisomerases. These enzymes are also needed to relieve the twisting stresses introduced into DNA strands during processes such as transcription and DNA replication.  Alternative DNA structures  DNA exists in many possible conformations that include A-DNA, B-DNA, and Z-DNA forms, although only B-DNA and Z-DNA have been directly observed in functional organisms. The conformation that DNA adopts depends on the hydration level, DNA sequence, the amount and direction of supercoiling, chemical modifications of the bases, the type and concentration of metal ions, and the presence of polyamines in solution.The first published reports of A-DNA X-ray diffraction patterns—and also B-DNA—used analyses based on Patterson functions that provided only a limited amount of structural information for oriented fibers of DNA. An alternative analysis was proposed by Wilkins et al. in 1953 for the in vivo B-DNA X-ray diffraction-scattering patterns of highly hydrated DNA fibers in terms of squares of Bessel functions. In the same journal, James Watson and Francis Crick presented their molecular modeling analysis of the DNA X-ray diffraction patterns to suggest that the structure was a double helix.Although the B-DNA form is most common under the conditions found in cells, it is not a well-defined conformation but a family of related DNA conformations that occur at the high hydration levels present in cells. Their corresponding X-ray diffraction and scattering patterns are characteristic of molecular paracrystals with a significant degree of disorder.Compared to B-DNA, the A-DNA form is a wider right-handed spiral, with a shallow, wide minor groove and a narrower, deeper major groove. The A form occurs under non-physiological conditions in partly dehydrated samples of DNA, while in the cell it may be produced in hybrid pairings of DNA and RNA strands, and in enzyme-DNA complexes. Segments of DNA where the bases have been chemically modified by methylation may undergo a larger change in conformation and adopt the Z form. Here, the strands turn about the helical axis in a left-handed spiral, the opposite of the more common B form. These unusual structures can be recognized by specific Z-DNA binding proteins and may be involved in the regulation of transcription.  Alternative DNA chemistry  For many years, exobiologists have proposed the existence of a shadow biosphere, a postulated microbial biosphere of Earth that uses radically different biochemical and molecular processes than currently known life. One of the proposals was the existence of lifeforms that use arsenic instead of phosphorus in DNA. A report in 2010 of the possibility in the bacterium GFAJ-1 was announced, though the research was disputed, and evidence suggests the bacterium actively prevents the incorporation of arsenic into the DNA backbone and other biomolecules.  Quadruplex structures  At the ends of the linear chromosomes are specialized regions of DNA called telomeres. The main function of these regions is to allow the cell to replicate chromosome ends using the enzyme telomerase, as the enzymes that normally replicate DNA cannot copy the extreme 3′ ends of chromosomes. These specialized chromosome caps also help protect the DNA ends, and stop the DNA repair systems in the cell from treating them as damage to be corrected. In human cells, telomeres are usually lengths of single-stranded DNA containing several thousand repeats of a simple TTAGGG sequence.These guanine-rich sequences may stabilize chromosome ends by forming structures of stacked sets of four-base units, rather than the usual base pairs found in other DNA molecules. Here, four guanine bases, known as a guanine tetrad, form a flat plate. These flat four-base units then stack on top of each other to form a stable G-quadruplex structure. These structures are stabilized by hydrogen bonding between the edges of the bases and chelation of a metal ion in the centre of each four-base unit. Other structures can also be formed, with the central set of four bases coming from either a single strand folded around the bases, or several different parallel strands, each contributing one base to the central structure. In addition to these stacked structures, telomeres also form large loop structures called telomere loops, or T-loops. Here, the single-stranded DNA curls around in a long circle stabilized by telomere-binding proteins. At the very end of the T-loop, the single-stranded telomere DNA is held onto a region of double-stranded DNA by the telomere strand disrupting the double-helical DNA and base pairing to one of the two strands. This triple-stranded structure is called a displacement loop or D-loop.  Branched DNA  In DNA, fraying occurs when non-complementary regions exist at the end of an otherwise complementary double-strand of DNA. However, branched DNA can occur if a third strand of DNA is introduced and contains adjoining regions able to hybridize with the frayed regions of the pre-existing double-strand. Although the simplest example of branched DNA involves only three strands of DNA, complexes involving additional strands and multiple branches are also possible. Branched DNA can be used in nanotechnology to construct geometric shapes, see the section on uses in technology below.  Artificial bases  Several artificial nucleobases have been synthesized, and successfully incorporated in the eight-base DNA analogue named Hachimoji DNA. Dubbed S, B, P, and Z, these artificial bases are capable of bonding with each other in a predictable way (S–B and P–Z), maintain the double helix structure of DNA, and be transcribed to RNA. Their existence could be seen as an indication that there is nothing special about the four natural nucleobases that evolved on Earth. On the other hand, DNA is tightly related to RNA which does not only act as a transcript of DNA but also performs as molecular machines many tasks in cells. For this purpose it has to fold into a structure. It has been shown that to allow to create all possible structures at least four bases are required for the corresponding RNA, while a higher number is also possible but this would be against the natural principle of least effort.  Acidity  The phosphate groups of DNA give it similar acidic properties to phosphoric acid and it can be considered as a strong acid. It will be fully ionized at a normal cellular pH, releasing protons which leave behind negative charges on the phosphate groups. These negative charges protect DNA from breakdown by hydrolysis by repelling nucleophiles which could hydrolyze it.  Macroscopic appearance  Pure DNA extracted from cells forms white, stringy clumps.  Chemical modifications and altered DNA packaging   Base modifications and DNA packaging  The expression of genes is influenced by how the DNA is packaged in chromosomes, in a structure called chromatin. Base modifications can be involved in packaging, with regions that have low or no gene expression usually containing high levels of methylation of cytosine bases. DNA packaging and its influence on gene expression can also occur by covalent modifications of the histone protein core around which DNA is wrapped in the chromatin structure or else by remodeling carried out by chromatin remodeling complexes (see Chromatin remodeling). There is, further, crosstalk between DNA methylation and histone modification, so they can coordinately affect chromatin and gene expression.For one example, cytosine methylation produces 5-methylcytosine, which is important for X-inactivation of chromosomes. The average level of methylation varies between organisms—the worm Caenorhabditis elegans lacks cytosine methylation, while vertebrates have higher levels, with up to 1% of their DNA containing 5-methylcytosine. Despite the importance of 5-methylcytosine, it can deaminate to leave a thymine base, so methylated cytosines are particularly prone to mutations. Other base modifications include adenine methylation in bacteria, the presence of 5-hydroxymethylcytosine in the brain, and the glycosylation of uracil to produce the ""J-base"" in kinetoplastids.  Damage  DNA can be damaged by many sorts of mutagens, which change the DNA sequence. Mutagens include oxidizing agents, alkylating agents and also high-energy electromagnetic radiation such as ultraviolet light and X-rays. The type of DNA damage produced depends on the type of mutagen. For example, UV light can damage DNA by producing thymine dimers, which are cross-links between pyrimidine bases. On the other hand, oxidants such as free radicals or hydrogen peroxide produce multiple forms of damage, including base modifications, particularly of guanosine, and double-strand breaks. A typical human cell contains about 150,000 bases that have suffered oxidative damage. Of these oxidative lesions, the most dangerous are double-strand breaks, as these are difficult to repair and can produce point mutations, insertions, deletions from the DNA sequence, and chromosomal translocations. These mutations can cause cancer. Because of inherent limits in the DNA repair mechanisms, if humans lived long enough, they would all eventually develop cancer. DNA damages that are naturally occurring, due to normal cellular processes that produce reactive oxygen species, the hydrolytic activities of cellular water, etc., also occur frequently. Although most of these damages are repaired, in any cell some DNA damage may remain despite the action of repair processes. These remaining DNA damages accumulate with age in mammalian postmitotic tissues. This accumulation appears to be an important underlying cause of aging.Many mutagens fit into the space between two adjacent base pairs, this is called intercalation. Most intercalators are aromatic and planar molecules; examples include ethidium bromide, acridines, daunomycin, and doxorubicin. For an intercalator to fit between base pairs, the bases must separate, distorting the DNA strands by unwinding of the double helix. This inhibits both transcription and DNA replication, causing toxicity and mutations. As a result, DNA intercalators may be carcinogens, and in the case of thalidomide, a teratogen. Others such as benzo[a]pyrene diol epoxide and aflatoxin form DNA adducts that induce errors in replication. Nevertheless, due to their ability to inhibit DNA transcription and replication, other similar toxins are also used in chemotherapy to inhibit rapidly growing cancer cells.  Biological functions  DNA usually occurs as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. The set of chromosomes in a cell makes up its genome; the human genome has approximately 3 billion base pairs of DNA arranged into 46 chromosomes. The information carried by DNA is held in the sequence of pieces of DNA called genes. Transmission of genetic information in genes is achieved via complementary base pairing. For example, in transcription, when a cell uses the information in a gene, the DNA sequence is copied into a complementary RNA sequence through the attraction between the DNA and the correct RNA nucleotides. Usually, this RNA copy is then used to make a matching protein sequence in a process called translation, which depends on the same interaction between RNA nucleotides. In an alternative fashion, a cell may copy its genetic information in a process called DNA replication. The details of these functions are covered in other articles; here the focus is on the interactions between DNA and other molecules that mediate the function of the genome.  Genes and genomes  Genomic DNA is tightly and orderly packed in the process called DNA condensation, to fit the small available volumes of the cell. In eukaryotes, DNA is located in the cell nucleus, with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid. The genetic information in a genome is held within genes, and the complete set of this information in an organism is called its genotype. A gene is a unit of heredity and is a region of DNA that influences a particular characteristic in an organism. Genes contain an open reading frame that can be transcribed, and regulatory sequences such as promoters and enhancers, which control transcription of the open reading frame. In many species, only a small fraction of the total sequence of the genome encodes protein. For example, only about 1.5% of the human genome consists of protein-coding exons, with over 50% of human DNA consisting of non-coding repetitive sequences. The reasons for the presence of so much noncoding DNA in eukaryotic genomes and the extraordinary differences in genome size, or C-value, among species, represent a long-standing puzzle known as the ""C-value enigma"". However, some DNA sequences that do not code protein may still encode functional non-coding RNA molecules, which are involved in the regulation of gene expression. Some noncoding DNA sequences play structural roles in chromosomes. Telomeres and centromeres typically contain few genes but are important for the function and stability of chromosomes. An abundant form of noncoding DNA in humans are pseudogenes, which are copies of genes that have been disabled by mutation. These sequences are usually just molecular fossils, although they can occasionally serve as raw genetic material for the creation of new genes through the process of gene duplication and divergence.  Transcription and translation  A gene is a sequence of DNA that contains genetic information and can influence the phenotype of an organism. Within a gene, the sequence of bases along a DNA strand defines a messenger RNA sequence, which then defines one or more protein sequences. The relationship between the nucleotide sequences of genes and the amino-acid sequences of proteins is determined by the rules of translation, known collectively as the genetic code. The genetic code consists of three-letter \'words\' called codons formed from a sequence of three nucleotides (e.g. ACT, CAG, TTT). In transcription, the codons of a gene are copied into messenger RNA by RNA polymerase. This RNA copy is then decoded by a ribosome that reads the RNA sequence by base-pairing the messenger RNA to transfer RNA, which carries amino acids. Since there are 4 bases in 3-letter combinations, there are 64 possible codons (43 combinations). These encode the twenty standard amino acids, giving most amino acids more than one possible codon. There are also three \'stop\' or \'nonsense\' codons signifying the end of the coding region; these are the TAG, TAA, and TGA codons, (UAG, UAA, and UGA on the mRNA).  Replication  Cell division is essential for an organism to grow, but, when a cell divides, it must replicate the DNA in its genome so that the two daughter cells have the same genetic information as their parent. The double-stranded structure of DNA provides a simple mechanism for DNA replication. Here, the two strands are separated and then each strand\'s complementary DNA sequence is recreated by an enzyme called DNA polymerase. This enzyme makes the complementary strand by finding the correct base through complementary base pairing and bonding it onto the original strand. As DNA polymerases can only extend a DNA strand in a 5′ to 3′ direction, different mechanisms are used to copy the antiparallel strands of the double helix. In this way, the base on the old strand dictates which base appears on the new strand, and the cell ends up with a perfect copy of its DNA.  Extracellular nucleic acids  Naked extracellular DNA (eDNA), most of it released by cell death, is nearly ubiquitous in the environment. Its concentration in soil may be as high as 2 μg/L, and its concentration in natural aquatic environments may be as high at 88 μg/L. Various possible functions have been proposed for eDNA: it may be involved in horizontal gene transfer; it may provide nutrients; and it may act as a buffer to recruit or titrate ions or antibiotics. Extracellular DNA acts as a functional extracellular matrix component in the biofilms of several bacterial species. It may act as a recognition factor to regulate the attachment and dispersal of specific cell types in the biofilm; it may contribute to biofilm formation; and it may contribute to the biofilm\'s physical strength and resistance to biological stress.Cell-free fetal DNA is found in the blood of the mother, and can be sequenced to determine a great deal of information about the developing fetus.Under the name of environmental DNA eDNA has seen increased use in the natural sciences as a survey tool for ecology, monitoring the movements and presence of species in water, air, or on land, and assessing an area\'s biodiversity.  Neutrophil extracellular traps  Neutrophil extracellular traps (NETs) are networks of extracellular fibers, primarily composed of DNA, which allow neutrophils, a type of white blood cell, to kill extracellular pathogens while minimizing damage to the host cells.  Interactions with proteins  All the functions of DNA depend on interactions with proteins. These protein interactions can be non-specific, or the protein can bind specifically to a single DNA sequence. Enzymes can also bind to DNA and of these, the polymerases that copy the DNA base sequence in transcription and DNA replication are particularly important.  DNA-binding proteins  Structural proteins that bind DNA are well-understood examples of non-specific DNA-protein interactions. Within chromosomes, DNA is held in complexes with structural proteins. These proteins organize the DNA into a compact structure called chromatin. In eukaryotes, this structure involves DNA binding to a complex of small basic proteins called histones, while in prokaryotes multiple types of proteins are involved. The histones form a disk-shaped complex called a nucleosome, which contains two complete turns of double-stranded DNA wrapped around its surface. These non-specific interactions are formed through basic residues in the histones, making ionic bonds to the acidic sugar-phosphate backbone of the DNA, and are thus largely independent of the base sequence. Chemical modifications of these basic amino acid residues include methylation, phosphorylation, and acetylation. These chemical changes alter the strength of the interaction between the DNA and the histones, making the DNA more or less accessible to transcription factors and changing the rate of transcription. Other non-specific DNA-binding proteins in chromatin include the high-mobility group proteins, which bind to bent or distorted DNA. These proteins are important in bending arrays of nucleosomes and arranging them into the larger structures that make up chromosomes.A distinct group of DNA-binding proteins is the DNA-binding proteins that specifically bind single-stranded DNA. In humans, replication protein A is the best-understood member of this family and is used in processes where the double helix is separated, including DNA replication, recombination, and DNA repair. These binding proteins seem to stabilize single-stranded DNA and protect it from forming stem-loops or being degraded by nucleases. In contrast, other proteins have evolved to bind to particular DNA sequences. The most intensively studied of these are the various transcription factors, which are proteins that regulate transcription. Each transcription factor binds to one particular set of DNA sequences and activates or inhibits the transcription of genes that have these sequences close to their promoters. The transcription factors do this in two ways. Firstly, they can bind the RNA polymerase responsible for transcription, either directly or through other mediator proteins; this locates the polymerase at the promoter and allows it to begin transcription. Alternatively, transcription factors can bind enzymes that modify the histones at the promoter. This changes the accessibility of the DNA template to the polymerase.As these DNA targets can occur throughout an organism\'s genome, changes in the activity of one type of transcription factor can affect thousands of genes. Consequently, these proteins are often the targets of the signal transduction processes that control responses to environmental changes or cellular differentiation and development. The specificity of these transcription factors\' interactions with DNA come from the proteins making multiple contacts to the edges of the DNA bases, allowing them to ""read"" the DNA sequence. Most of these base-interactions are made in the major groove, where the bases are most accessible.  DNA-modifying enzymes   Nucleases and ligases  Nucleases are enzymes that cut DNA strands by catalyzing the hydrolysis of the phosphodiester bonds. Nucleases that hydrolyse nucleotides from the ends of DNA strands are called exonucleases, while endonucleases cut within strands. The most frequently used nucleases in molecular biology are the restriction endonucleases, which cut DNA at specific sequences. For instance, the EcoRV enzyme shown to the left recognizes the 6-base sequence 5′-GATATC-3′ and makes a cut at the horizontal line. In nature, these enzymes protect bacteria against phage infection by digesting the phage DNA when it enters the bacterial cell, acting as part of the restriction modification system. In technology, these sequence-specific nucleases are used in molecular cloning and DNA fingerprinting. Enzymes called DNA ligases can rejoin cut or broken DNA strands. Ligases are particularly important in lagging strand DNA replication, as they join the short segments of DNA produced at the replication fork into a complete copy of the DNA template. They are also used in DNA repair and genetic recombination.  Topoisomerases and helicases  Topoisomerases are enzymes with both nuclease and ligase activity. These proteins change the amount of supercoiling in DNA. Some of these enzymes work by cutting the DNA helix and allowing one section to rotate, thereby reducing its level of supercoiling; the enzyme then seals the DNA break. Other types of these enzymes are capable of cutting one DNA helix and then passing a second strand of DNA through this break, before rejoining the helix. Topoisomerases are required for many processes involving DNA, such as DNA replication and transcription.Helicases are proteins that are a type of molecular motor. They use the chemical energy in nucleoside triphosphates, predominantly adenosine triphosphate (ATP), to break hydrogen bonds between bases and unwind the DNA double helix into single strands. These enzymes are essential for most processes where enzymes need to access the DNA bases.  Polymerases  Polymerases are enzymes that synthesize polynucleotide chains from nucleoside triphosphates. The sequence of their products is created based on existing polynucleotide chains—which are called templates. These enzymes function by repeatedly adding a nucleotide to the 3′ hydroxyl group at the end of the growing polynucleotide chain. As a consequence, all polymerases work in a 5′ to 3′ direction. In the active site of these enzymes, the incoming nucleoside triphosphate base-pairs to the template: this allows polymerases to accurately synthesize the complementary strand of their template. Polymerases are classified according to the type of template that they use. In DNA replication, DNA-dependent DNA polymerases make copies of DNA polynucleotide chains. To preserve biological information, it is essential that the sequence of bases in each copy are precisely complementary to the sequence of bases in the template strand. Many DNA polymerases have a proofreading activity. Here, the polymerase recognizes the occasional mistakes in the synthesis reaction by the lack of base pairing between the mismatched nucleotides. If a mismatch is detected, a 3′ to 5′ exonuclease activity is activated and the incorrect base removed. In most organisms, DNA polymerases function in a large complex called the replisome that contains multiple accessory subunits, such as the DNA clamp or helicases.RNA-dependent DNA polymerases are a specialized class of polymerases that copy the sequence of an RNA strand into DNA. They include reverse transcriptase, which is a viral enzyme involved in the infection of cells by retroviruses, and telomerase, which is required for the replication of telomeres. For example, HIV reverse transcriptase is an enzyme for AIDS virus replication. Telomerase is an unusual polymerase because it contains its own RNA template as part of its structure. It synthesizes telomeres at the ends of chromosomes. Telomeres prevent fusion of the ends of neighboring chromosomes and protect chromosome ends from damage.Transcription is carried out by a DNA-dependent RNA polymerase that copies the sequence of a DNA strand into RNA. To begin transcribing a gene, the RNA polymerase binds to a sequence of DNA called a promoter and separates the DNA strands. It then copies the gene sequence into a messenger RNA transcript until it reaches a region of DNA called the terminator, where it halts and detaches from the DNA. As with human DNA-dependent DNA polymerases, RNA polymerase II, the enzyme that transcribes most of the genes in the human genome, operates as part of a large protein complex with multiple regulatory and accessory subunits.  Genetic recombination  A DNA helix usually does not interact with other segments of DNA, and in human cells, the different chromosomes even occupy separate areas in the nucleus called ""chromosome territories"". This physical separation of different chromosomes is important for the ability of DNA to function as a stable repository for information, as one of the few times chromosomes interact is in chromosomal crossover which occurs during sexual reproduction, when genetic recombination occurs. Chromosomal crossover is when two DNA helices break, swap a section and then rejoin. Recombination allows chromosomes to exchange genetic information and produces new combinations of genes, which increases the efficiency of natural selection and can be important in the rapid evolution of new proteins. Genetic recombination can also be involved in DNA repair, particularly in the cell\'s response to double-strand breaks.The most common form of chromosomal crossover is homologous recombination, where the two chromosomes involved share very similar sequences. Non-homologous recombination can be damaging to cells, as it can produce chromosomal translocations and genetic abnormalities. The recombination reaction is catalyzed by enzymes known as recombinases, such as RAD51. The first step in recombination is a double-stranded break caused by either an endonuclease or damage to the DNA. A series of steps catalyzed in part by the recombinase then leads to joining of the two helices by at least one Holliday junction, in which a segment of a single strand in each helix is annealed to the complementary strand in the other helix. The Holliday junction is a tetrahedral junction structure that can be moved along the pair of chromosomes, swapping one strand for another. The recombination reaction is then halted by cleavage of the junction and re-ligation of the released DNA. Only strands of like polarity exchange DNA during recombination. There are two types of cleavage: east-west cleavage and north–south cleavage. The north–south cleavage nicks both strands of DNA, while the east–west cleavage has one strand of DNA intact. The formation of a Holliday junction during recombination makes it possible for genetic diversity, genes to exchange on chromosomes, and expression of wild-type viral genomes.  Evolution  DNA contains the genetic information that allows all forms of life to function, grow and reproduce. However, it is unclear how long in the 4-billion-year history of life DNA has performed this function, as it has been proposed that the earliest forms of life may have used RNA as their genetic material. RNA may have acted as the central part of early cell metabolism as it can both transmit genetic information and carry out catalysis as part of ribozymes. This ancient RNA world where nucleic acid would have been used for both catalysis and genetics may have influenced the evolution of the current genetic code based on four nucleotide bases. This would occur, since the number of different bases in such an organism is a trade-off between a small number of bases increasing replication accuracy and a large number of bases increasing the catalytic efficiency of ribozymes. However, there is no direct evidence of ancient genetic systems, as recovery of DNA from most fossils is impossible because DNA survives in the environment for less than one million years, and slowly degrades into short fragments in solution. Claims for older DNA have been made, most notably a report of the isolation of a viable bacterium from a salt crystal 250 million years old, but these claims are controversial.Building blocks of DNA (adenine, guanine, and related organic molecules) may have been formed extraterrestrially in outer space. Complex DNA and RNA organic compounds of life, including uracil, cytosine, and thymine, have also been formed in the laboratory under conditions mimicking those found in outer space, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar cosmic dust and gas clouds.In February 2021, scientists reported, for the first time, the sequencing of DNA from animal remains, a mammoth in this instance over a million years old, the oldest DNA sequenced to date.  Uses in technology   Genetic engineering  Methods have been developed to purify DNA from organisms, such as phenol-chloroform extraction, and to manipulate it in the laboratory, such as restriction digests and the polymerase chain reaction. Modern biology and biochemistry make intensive use of these techniques in recombinant DNA technology. Recombinant DNA is a man-made DNA sequence that has been assembled from other DNA sequences. They can be transformed into organisms in the form of plasmids or in the appropriate format, by using a viral vector. The genetically modified organisms produced can be used to produce products such as recombinant proteins, used in medical research, or be grown in agriculture.  DNA profiling  Forensic scientists can use DNA in blood, semen, skin, saliva or hair found at a crime scene to identify a matching DNA of an individual, such as a perpetrator. This process is formally termed DNA profiling, also called DNA fingerprinting. In DNA profiling, the lengths of variable sections of repetitive DNA, such as short tandem repeats and minisatellites, are compared between people. This method is usually an extremely reliable technique for identifying a matching DNA. However, identification can be complicated if the scene is contaminated with DNA from several people. DNA profiling was developed in 1984 by British geneticist Sir Alec Jeffreys, and first used in forensic science to convict Colin Pitchfork in the 1988 Enderby murders case.The development of forensic science and the ability to now obtain genetic matching on minute samples of blood, skin, saliva, or hair has led to re-examining many cases. Evidence can now be uncovered that was scientifically impossible at the time of the original examination. Combined with the removal of the double jeopardy law in some places, this can allow cases to be reopened where prior trials have failed to produce sufficient evidence to convince a jury. People charged with serious crimes may be required to provide a sample of DNA for matching purposes. The most obvious defense to DNA matches obtained forensically is to claim that cross-contamination of evidence has occurred. This has resulted in meticulous strict handling procedures with new cases of serious crime. DNA profiling is also used successfully to positively identify victims of mass casualty incidents, bodies or body parts in serious accidents, and individual victims in mass war graves, via matching to family members. DNA profiling is also used in DNA paternity testing to determine if someone is the biological parent or grandparent of a child with the probability of parentage is typically 99.99% when the alleged parent is biologically related to the child. Normal DNA sequencing methods happen after birth, but there are new methods to test paternity while a mother is still pregnant.  DNA enzymes or catalytic DNA  Deoxyribozymes, also called DNAzymes or catalytic DNA, were first discovered in 1994. They are mostly single stranded DNA sequences isolated from a large pool of random DNA sequences through a combinatorial approach called in vitro selection or systematic evolution of ligands by exponential enrichment (SELEX). DNAzymes catalyze variety of chemical reactions including RNA-DNA cleavage, RNA-DNA ligation, amino acids phosphorylation-dephosphorylation, carbon-carbon bond formation, etc. DNAzymes can enhance catalytic rate of chemical reactions up to 100,000,000,000-fold over the uncatalyzed reaction. The most extensively studied class of DNAzymes is RNA-cleaving types which have been used to detect different metal ions and designing therapeutic agents. Several metal-specific DNAzymes have been reported including the GR-5 DNAzyme (lead-specific), the CA1-3 DNAzymes (copper-specific), the 39E DNAzyme (uranyl-specific) and the NaA43 DNAzyme (sodium-specific).","DNA, short for deoxyribonucleic acid, is the molecule that contains the genetic code of organisms. This includes animals, plants, protists, archaea and bacteria. It is made up of two polynucleotide chains in a double helix.DNA is in each cell in the organism and tells cells what proteins to make. Mostly, these proteins are enzymes. DNA is inherited by children from their parents. This is why children share traits with their parents, such as skin, hair and eye color. The DNA in a person is a combination of the DNA from each of their parents. Part of an organism's DNA is ""non-coding DNA"" sequences. They do not code for protein sequences. Some noncoding DNA is transcribed into non-coding RNA molecules, such as transfer RNA, ribosomal RNA, and regulatory RNAs. Other sequences are not transcribed at all, or give rise to RNA of unknown function. The amount of non-coding DNA varies greatly among species. For example, over 98% of the human genome is non-coding DNA, while only about 2% of a typical bacterial genome is non-coding DNA. Viruses use either DNA or RNA to infect organisms. The genome replication of most DNA viruses takes place in the cell's nucleus, whereas RNA viruses usually replicate in the cytoplasm. Inside eukaryotic cells, DNA is organized into chromosomes. Before cell division, more chromosomes are made in the process of DNA replication. Eukaryotic organisms like animals, plants, fungi and protists store most of their DNA inside the cell nucleus. But prokaryotes, like bacteria and archaea store their DNA only in the cytoplasm, in circular chromosomes. Inside eukaryotic chromosomes, chromatin proteins, such as histones, help to compact and organize DNA.  Structure of DNA  DNA has a double helix shape, which is like a ladder twisted into a spiral. Each step of the ladder is a pair of nucleotides.  Nucleotides  A nucleotide is a molecule made up of: deoxyribose, a kind of sugar with 5 carbon atoms, a phosphate group made of phosphorus and oxygen, and nitrogenous baseDNA is made of four types of nucleotide: Adenine (A) Thymine (T) Cytosine (C) Guanine (G)The 'rungs' of the DNA ladder are each made of two bases, one base coming from each leg. The bases connect in the middle: 'A' only pairs with 'T', and 'C' only pairs with 'G'. The bases are held together by hydrogen bonds. Adenine (A) and thymine (T) can pair up because they make two hydrogen bonds, and cytosine (C) and guanine (G) pair up to make three hydrogen bonds. Although the bases are always in fixed pairs, the pairs can come in any order (A-T or T-A; similarly, C-G or G-C). This way, DNA can write 'codes' out of the 'letters' that are the bases. These codes contain the message that tells the cell what to do.  Chromatin  On chromosomes, the DNA is bound up with proteins called histones to form chromatin. This association takes part in epigenetics and gene regulation. Genes are switched on and off during development and cell activity, and this regulation is the basis of most of the activity which takes place in cells.  Copying DNA  When DNA is copied, this is called DNA replication. Briefly, the hydrogen bonds holding together paired bases are broken and the molecule is split in half: the legs of the ladder are separated. This gives two single strands. New strands are formed by matching the bases (A with T and G with C) to make the missing strands. First, an enzyme called DNA helicase splits the DNA down the middle by breaking the hydrogen bonds. Then after the DNA molecule is in two separate pieces, another molecule called DNA polymerase makes a new strand that matches each of the strands of the split DNA molecule. Each copy of a DNA molecule is made of half of the original (starting) molecule and half of new bases.  Mutations  When DNA is copied, mistakes are sometimes made – these are called mutations. There are four main types of mutations: Deletion, where one or more bases are left out. Substitution, where one or more bases are substituted for another base in the sequence. Insertion, where one or more extra base is put in. Duplication, where a sequence of bases pairs are repeated.Mutations may also be classified by their effect on the structure and function of proteins, or their effect on fitness. Mutations may be bad for the organism, or neutral, or of benefit. Sometimes mutations are fatal for the organism – the protein made by the new DNA does not work at all, and this causes the embryo to die. On the other hand, evolution is moved forward by mutations, when the new version of the protein works better for the organism.  Protein synthesis  A section of DNA that contains instructions to make a protein is called a gene. Each gene has the sequence for at least one polypeptide. Proteins form structures, and also form enzymes. The enzymes do most of the work in cells. Proteins are made out of smaller polypeptides, which are formed of amino acids. To make a protein to do a particular job, the correct amino acids need to be joined up in the correct order. Proteins are made by tiny machines in the cell called ribosomes. Ribosomes are in the main body of the cell, but DNA is only in the nucleus of the cell. The codon is part of the DNA, but DNA never leaves the nucleus. Because DNA cannot leave the nucleus, the cell nucleus makes a copy of the DNA sequence in RNA. This is smaller and can get through the holes – pores – in the membrane of the nucleus and out into the cell. Genes encoded in DNA are transcribed into messenger RNA (mRNA) by proteins such as RNA polymerase. Mature mRNA is then used as a template for protein synthesis by the ribosome. Ribosomes read codons, 'words' made of three base pairs that tell the ribosome which amino acid to add. The ribosome scans along an mRNA, reading the code while it makes protein. Another RNA called tRNA helps match the right amino acid to each codon.  History of DNA research  DNA was first isolated (extracted from cells) by Swiss physician Friedrich Miescher in 1869, when he was working on bacteria from the pus in surgical bandages. The molecule was found in the nucleus of the cells and so he called it nuclein.In 1928, Frederick Griffith discovered that traits of the ""smooth"" form of Pneumococcus could be transferred to the ""rough"" form of the same bacteria by mixing killed ""smooth"" bacteria with the live ""rough"" form. This system provided the first clear suggestion that DNA carries genetic information. The Avery–MacLeod–McCarty experiment identified DNA as the transforming principle in 1943.DNA's role in heredity was confirmed in 1952, when Alfred Hershey and Martha Chase in the Hershey–Chase experiment showed that DNA is the genetic material of the T2 bacteriophage.In the 1950s, Erwin Chargaff found that the amount of thymine (T) present in a molecule of DNA was about equal to the amount of adenine (A) present. He found that the same applies to guanine (G) and cytosine (C). Chargaff's rules summarises this finding. In 1953, James D. Watson and Francis Crick suggested what is now accepted as the first correct double-helix model of DNA structure in the journal Nature. Their double-helix, molecular model of DNA was then based on a single X-ray diffraction image ""Photo 51"", taken by Rosalind Franklin and Raymond Gosling in May 1952.Experimental evidence supporting the Watson and Crick model was published in a series of five articles in the same issue of Nature. Of these, Franklin and Gosling's paper was the first publication of their own X-ray diffraction data and original analysis method that partly supported the Watson and Crick model; this issue also contained an article on DNA structure by Maurice Wilkins and two of his colleagues, whose analysis and in vivo B-DNA X-ray patterns also supported the presence in vivo of the double-helical DNA configurations as proposed by Crick and Watson for their double-helix molecular model of DNA in the previous two pages of Nature. In 1962, after Franklin's death, Watson, Crick, and Wilkins jointly received the Nobel Prize in Physiology or Medicine. Nobel Prizes are awarded only to living recipients. A debate continues about who should receive credit for the discovery.In 1957, Crick explained the relationship between DNA, RNA, and proteins, in the central dogma of molecular biology.How DNA was copied (the replication mechanism) came in 1958 through the Meselson–Stahl experiment. More work by Crick and coworkers showed that the genetic code was based on non-overlapping triplets of bases, called codons. These findings represent the birth of molecular biology. How Watson and Crick got Franklin's results has been much debated. Crick, Watson and Maurice Wilkins were awarded the Nobel Prize in 1962 for their work on DNA – Rosalind Franklin had died in 1958.  What happens when DNA gets damaged  DNA gets damaged a lot of times in cells which is a problem has DNA provide instructions to making proteins. But, cells have ways to fix these problems most of the time. Cells make use of special enzymes. Different enzymes fix different types of damages to DNA. The problem comes in different types: One common error is base mismatch or where the bases are not matched correctly. This is where maybe for example, adenine is not matched with thymine or Guanine is not matched with cytosine. When a cell copies its own DNA a special enzyme called polymerase matches the bases together. But once in a while, there is an error. Usually, the enzyme notices it and fixes it, but just make sure, another set of proteins check what the enzyme has done. If the proteins find a base that was not matched with the right base, they remove it and replace it with a nucleotide with the right base. DNA can also be broken chemically by certain compounds. This can be toxic compounds like those found in tobacco or compounds the cell meets every day like hydrogen peroxide. Some chemical damages by compounds happens so much that there is a special enzyme to fix those types of problems. When a base gets damaged, it is usually fixed in a process called base excision repair. Here, an enzyme removes the base and another group of enzymes trim around the damage and replaces it with a new nucleotide. UV light damages DNA in such a way that it changes its shape. Fixing this type of damage takes a more complex process called nucleotide excision repair. Here, a team of proteins remove a long strand of 20 or more broken nucleotides and replaces them with fresh new ones. High energy waves like x-rays and gamma rays can actually cut one or both strands of DNA. This type of damage is called a double strand break. One double strand break can cause the cell to die. Two common ways the cell fixes this problem is homologous recombination and non homologous end joining. In homologous recombination, enzymes use a similar part of another gene as a template to fix the break. In non-homologous end joining enzymes trim around the place where the DNA strand broke and put them together. This way is much less accurate but works when there is no similar genes available.  DNA and privacy concerns  Police in the United States used DNA and family tree public databases to solve cold cases. The American Civil Liberties Union raised concerns over this practice.  Related pages  Bioinformatics Cell division Mitosis Meiosis DNA repair Chromosome Sequence analysis Epigenetics Junk DNA  References   Other websites  Human Genome Project: information"
"A microorganism, or microbe, is an organism of microscopic size, which may exist in its single-celled form or as a colony of cells. The possible existence of unseen microbial life was suspected from ancient times, such as in Jain scriptures from sixth century BC India. The scientific study of microorganisms began with their observation under the microscope in the 1670s by Anton van Leeuwenhoek. In the 1850s, Louis Pasteur found that microorganisms caused food spoilage, debunking the theory of spontaneous generation. In the 1880s, Robert Koch discovered that microorganisms caused the diseases tuberculosis, cholera, diphtheria, and anthrax. Because microorganisms include most unicellular organisms from all three domains of life they can be extremely diverse. Two of the three domains, Archaea and Bacteria, only contain microorganisms. The third domain Eukaryota includes all multicellular organisms as well as many unicellular protists and protozoans that are microbes. Some protists are related to animals and some to green plants. There are also many multicellular organisms that are microscopic, namely micro-animals, some fungi, and some algae, but these are generally not considered microorganisms.Microorganisms can have very different habitats, and live everywhere from the poles to the equator, deserts, geysers, rocks, and the deep sea. Some are adapted to extremes such as very hot or very cold conditions, others to high pressure, and a few, such as Deinococcus radiodurans, to high radiation environments. Microorganisms also make up the microbiota found in and on all multicellular organisms. There is evidence that 3.45-billion-year-old Australian rocks once contained microorganisms, the earliest direct evidence of life on Earth.Microbes are important in human culture and health in many ways, serving to ferment foods and treat sewage, and to produce fuel, enzymes, and other bioactive compounds. Microbes are essential tools in biology as model organisms and have been put to use in biological warfare and bioterrorism. Microbes are a vital component of fertile soil. In the human body, microorganisms make up the human microbiota, including the essential gut flora. The pathogens responsible for many infectious diseases are microbes and, as such, are the target of hygiene measures.  Discovery   Ancient precursors  The possible existence of microscopic organisms was discussed for many centuries before their discovery in the seventeenth century. By the 6th century BC, the Jains of present-day India postulated the existence of tiny organisms called nigodas. These nigodas are said to be born in clusters; they live everywhere, including the bodies of plants, animals, and people; and their life lasts only for a fraction of a second. According to Mahavira, the 24th preacher of Jainism, the humans destroy these nigodas on a massive scale, when they eat, breathe, sit, and move. Many modern Jains assert that Mahavira's teachings presage the existence of microorganisms as discovered by modern science. The earliest known idea to indicate the possibility of diseases spreading by yet unseen organisms was that of the Roman scholar Marcus Terentius Varro in a first-century BC book entitled On Agriculture in which he called the unseen creatures animalcules, and warns against locating a homestead near a swamp: … and because there are bred certain minute creatures that cannot be seen by the eyes, which float in the air and enter the body through the mouth and nose and they cause serious diseases. In The Canon of Medicine (1020), Avicenna suggested that tuberculosis and other diseases might be contagious.  Early modern  Akshamsaddin (Turkish scientist) mentioned the microbe in his work Maddat ul-Hayat (The Material of Life) about two centuries prior to Antonie van Leeuwenhoek's discovery through experimentation: It is incorrect to assume that diseases appear one by one in humans. Disease infects by spreading from one person to another. This infection occurs through seeds that are so small they cannot be seen but are alive. In 1546, Girolamo Fracastoro proposed that epidemic diseases were caused by transferable seedlike entities that could transmit infection by direct or indirect contact, or even without contact over long distances.Antonie van Leeuwenhoek is considered to be one of the fathers of microbiology. He was the first in 1673 to discover and conduct scientific experiments with microorganisms, using simple single-lensed microscopes of his own design. Robert Hooke, a contemporary of Leeuwenhoek, also used microscopy to observe microbial life in the form of the fruiting bodies of moulds. In his 1665 book Micrographia, he made drawings of studies, and he coined the term cell.  19th century  Louis Pasteur (1822–1895) exposed boiled broths to the air, in vessels that contained a filter to prevent particles from passing through to the growth medium, and also in vessels without a filter, but with air allowed in via a curved tube so dust particles would settle and not come in contact with the broth. By boiling the broth beforehand, Pasteur ensured that no microorganisms survived within the broths at the beginning of his experiment. Nothing grew in the broths in the course of Pasteur's experiment. This meant that the living organisms that grew in such broths came from outside, as spores on dust, rather than spontaneously generated within the broth. Thus, Pasteur refuted the theory of spontaneous generation and supported the germ theory of disease. In 1876, Robert Koch (1843–1910) established that microorganisms can cause disease. He found that the blood of cattle that were infected with anthrax always had large numbers of Bacillus anthracis. Koch found that he could transmit anthrax from one animal to another by taking a small sample of blood from the infected animal and injecting it into a healthy one, and this caused the healthy animal to become sick. He also found that he could grow the bacteria in a nutrient broth, then inject it into a healthy animal, and cause illness. Based on these experiments, he devised criteria for establishing a causal link between a microorganism and a disease and these are now known as Koch's postulates. Although these postulates cannot be applied in all cases, they do retain historical importance to the development of scientific thought and are still being used today.The discovery of microorganisms such as Euglena that did not fit into either the animal or plant kingdoms, since they were photosynthetic like plants, but motile like animals, led to the naming of a third kingdom in the 1860s. In 1860 John Hogg called this the Protoctista, and in 1866 Ernst Haeckel named it the Protista.The work of Pasteur and Koch did not accurately reflect the true diversity of the microbial world because of their exclusive focus on microorganisms having direct medical relevance. It was not until the work of Martinus Beijerinck and Sergei Winogradsky late in the nineteenth century that the true breadth of microbiology was revealed. Beijerinck made two major contributions to microbiology: the discovery of viruses and the development of enrichment culture techniques. While his work on the tobacco mosaic virus established the basic principles of virology, it was his development of enrichment culturing that had the most immediate impact on microbiology by allowing for the cultivation of a wide range of microbes with wildly different physiologies. Winogradsky was the first to develop the concept of chemolithotrophy and to thereby reveal the essential role played by microorganisms in geochemical processes. He was responsible for the first isolation and description of both nitrifying and nitrogen-fixing bacteria. French-Canadian microbiologist Felix d'Herelle co-discovered bacteriophages and was one of the earliest applied microbiologists.  Classification and structure  Microorganisms can be found almost anywhere on Earth. Bacteria and archaea are almost always microscopic, while a number of eukaryotes are also microscopic, including most protists, some fungi, as well as some micro-animals and plants. Viruses are generally regarded as not living and therefore not considered to be microorganisms, although a subfield of microbiology is virology, the study of viruses.  Evolution  Single-celled microorganisms were the first forms of life to develop on Earth, approximately 3.5 billion years ago. Further evolution was slow, and for about 3 billion years in the Precambrian eon, (much of the history of life on Earth), all organisms were microorganisms. Bacteria, algae and fungi have been identified in amber that is 220 million years old, which shows that the morphology of microorganisms has changed little since at least the Triassic period. The newly discovered biological role played by nickel, however – especially that brought about by volcanic eruptions from the Siberian Traps – may have accelerated the evolution of methanogens towards the end of the Permian–Triassic extinction event.Microorganisms tend to have a relatively fast rate of evolution. Most microorganisms can reproduce rapidly, and bacteria are also able to freely exchange genes through conjugation, transformation and transduction, even between widely divergent species. This horizontal gene transfer, coupled with a high mutation rate and other means of transformation, allows microorganisms to swiftly evolve (via natural selection) to survive in new environments and respond to environmental stresses. This rapid evolution is important in medicine, as it has led to the development of multidrug resistant pathogenic bacteria, superbugs, that are resistant to antibiotics.A possible transitional form of microorganism between a prokaryote and a eukaryote was discovered in 2012 by Japanese scientists. Parakaryon myojinensis is a unique microorganism larger than a typical prokaryote, but with nuclear material enclosed in a membrane as in a eukaryote, and the presence of endosymbionts. This is seen to be the first plausible evolutionary form of microorganism, showing a stage of development from the prokaryote to the eukaryote.  Archaea  Archaea are prokaryotic unicellular organisms, and form the first domain of life in Carl Woese's three-domain system. A prokaryote is defined as having no cell nucleus or other membrane bound-organelle. Archaea share this defining feature with the bacteria with which they were once grouped. In 1990 the microbiologist Woese proposed the three-domain system that divided living things into bacteria, archaea and eukaryotes, and thereby split the prokaryote domain. Archaea differ from bacteria in both their genetics and biochemistry. For example, while bacterial cell membranes are made from phosphoglycerides with ester bonds, archaean membranes are made of ether lipids. Archaea were originally described as extremophiles living in extreme environments, such as hot springs, but have since been found in all types of habitats. Only now are scientists beginning to realize how common archaea are in the environment, with Thermoproteota (formerly Crenarchaeota) being the most common form of life in the ocean, dominating ecosystems below 150 m in depth. These organisms are also common in soil and play a vital role in ammonia oxidation.The combined domains of archaea and bacteria make up the most diverse and abundant group of organisms on Earth and inhabit practically all environments where the temperature is below +140 °C. They are found in water, soil, air, as the microbiome of an organism, hot springs and even deep beneath the Earth's crust in rocks. The number of prokaryotes is estimated to be around five nonillion, or 5 × 1030, accounting for at least half the biomass on Earth.The biodiversity of the prokaryotes is unknown, but may be very large. A May 2016 estimate, based on laws of scaling from known numbers of species against the size of organism, gives an estimate of perhaps 1 trillion species on the planet, of which most would be microorganisms. Currently, only one-thousandth of one percent of that total have been described. Archael cells of some species aggregate and transfer DNA from one cell to another through direct contact, particularly under stressful environmental conditions that cause DNA damage.  Bacteria  Bacteria like archaea are prokaryotic – unicellular, and having no cell nucleus or other membrane-bound organelle. Bacteria are microscopic, with a few extremely rare exceptions, such as Thiomargarita namibiensis. Bacteria function and reproduce as individual cells, but they can often aggregate in multicellular colonies. Some species such as myxobacteria can aggregate into complex swarming structures, operating as multicellular groups as part of their life cycle, or form clusters in bacterial colonies such as E.coli. Their genome is usually a circular bacterial chromosome – a single loop of DNA, although they can also harbor small pieces of DNA called plasmids. These plasmids can be transferred between cells through bacterial conjugation. Bacteria have an enclosing cell wall, which provides strength and rigidity to their cells. They reproduce by binary fission or sometimes by budding, but do not undergo meiotic sexual reproduction. However, many bacterial species can transfer DNA between individual cells by a horizontal gene transfer process referred to as natural transformation. Some species form extraordinarily resilient spores, but for bacteria this is a mechanism for survival, not reproduction. Under optimal conditions bacteria can grow extremely rapidly and their numbers can double as quickly as every 20 minutes.  Eukaryotes  Most living things that are visible to the naked eye in their adult form are eukaryotes, including humans. However, many eukaryotes are also microorganisms. Unlike bacteria and archaea, eukaryotes contain organelles such as the cell nucleus, the Golgi apparatus and mitochondria in their cells. The nucleus is an organelle that houses the DNA that makes up a cell's genome. DNA (Deoxyribonucleic acid) itself is arranged in complex chromosomes. Mitochondria are organelles vital in metabolism as they are the site of the citric acid cycle and oxidative phosphorylation. They evolved from symbiotic bacteria and retain a remnant genome. Like bacteria, plant cells have cell walls, and contain organelles such as chloroplasts in addition to the organelles in other eukaryotes. Chloroplasts produce energy from light by photosynthesis, and were also originally symbiotic bacteria.Unicellular eukaryotes consist of a single cell throughout their life cycle. This qualification is significant since most multicellular eukaryotes consist of a single cell called a zygote only at the beginning of their life cycles. Microbial eukaryotes can be either haploid or diploid, and some organisms have multiple cell nuclei.Unicellular eukaryotes usually reproduce asexually by mitosis under favorable conditions. However, under stressful conditions such as nutrient limitations and other conditions associated with DNA damage, they tend to reproduce sexually by meiosis and syngamy.  Protists  Of eukaryotic groups, the protists are most commonly unicellular and microscopic. This is a highly diverse group of organisms that are not easy to classify. Several algae species are multicellular protists, and slime molds have unique life cycles that involve switching between unicellular, colonial, and multicellular forms. The number of species of protists is unknown since only a small proportion has been identified. Protist diversity is high in oceans, deep sea-vents, river sediment and an acidic river, suggesting that many eukaryotic microbial communities may yet be discovered.  Fungi  The fungi have several unicellular species, such as baker's yeast (Saccharomyces cerevisiae) and fission yeast (Schizosaccharomyces pombe). Some fungi, such as the pathogenic yeast Candida albicans, can undergo phenotypic switching and grow as single cells in some environments, and filamentous hyphae in others.  Plants  The green algae are a large group of photosynthetic eukaryotes that include many microscopic organisms. Although some green algae are classified as protists, others such as charophyta are classified with embryophyte plants, which are the most familiar group of land plants. Algae can grow as single cells, or in long chains of cells. The green algae include unicellular and colonial flagellates, usually but not always with two flagella per cell, as well as various colonial, coccoid, and filamentous forms. In the Charales, which are the algae most closely related to higher plants, cells differentiate into several distinct tissues within the organism. There are about 6000 species of green algae.  Ecology  Microorganisms are found in almost every habitat present in nature, including hostile environments such as the North and South poles, deserts, geysers, and rocks. They also include all the marine microorganisms of the oceans and deep sea. Some types of microorganisms have adapted to extreme environments and sustained colonies; these organisms are known as extremophiles. Extremophiles have been isolated from rocks as much as 7 kilometres below the Earth's surface, and it has been suggested that the amount of organisms living below the Earth's surface is comparable with the amount of life on or above the surface. Extremophiles have been known to survive for a prolonged time in a vacuum, and can be highly resistant to radiation, which may even allow them to survive in space. Many types of microorganisms have intimate symbiotic relationships with other larger organisms; some of which are mutually beneficial (mutualism), while others can be damaging to the host organism (parasitism). If microorganisms can cause disease in a host they are known as pathogens and then they are sometimes referred to as microbes. Microorganisms play critical roles in Earth's biogeochemical cycles as they are responsible for decomposition and nitrogen fixation.Bacteria use regulatory networks that allow them to adapt to almost every environmental niche on earth. A network of interactions among diverse types of molecules including DNA, RNA, proteins and metabolites, is utilised by the bacteria to achieve regulation of gene expression. In bacteria, the principal function of regulatory networks is to control the response to environmental changes, for example nutritional status and environmental stress. A complex organization of networks permits the microorganism to coordinate and integrate multiple environmental signals.  Extremophiles  Extremophiles are microorganisms that have adapted so that they can survive and even thrive in extreme environments that are normally fatal to most life-forms. Thermophiles and hyperthermophiles thrive in high temperatures. Psychrophiles thrive in extremely low temperatures. – Temperatures as high as 130 °C (266 °F), as low as −17 °C (1 °F) Halophiles such as Halobacterium salinarum (an archaean) thrive in high salt conditions, up to saturation. Alkaliphiles thrive in an alkaline pH of about 8.5–11. Acidophiles can thrive in a pH of 2.0 or less. Piezophiles thrive at very high pressures: up to 1,000–2,000 atm, down to 0 atm as in a vacuum of space. A few extremophiles such as Deinococcus radiodurans are radioresistant, resisting radiation exposure of up to 5k Gy. Extremophiles are significant in different ways. They extend terrestrial life into much of the Earth's hydrosphere, crust and atmosphere, their specific evolutionary adaptation mechanisms to their extreme environment can be exploited in biotechnology, and their very existence under such extreme conditions increases the potential for extraterrestrial life.  Plants and Soil  The nitrogen cycle in soils depends on the fixation of atmospheric nitrogen. This is achieved by a number of diazotrophs. One way this can occur is in the root nodules of legumes that contain symbiotic bacteria of the genera Rhizobium, Mesorhizobium, Sinorhizobium, Bradyrhizobium, and Azorhizobium.The roots of plants create a narrow region known as the rhizosphere that supports many microorganisms known as the root microbiome.These microorganisms in the root microbiome are able to interact with each other and surrounding plants through signals and cues. For example, mycorrhizal fungi are able to communicate with the root systems of many plants through chemical signals between both the plant and fungi. This results in a mutualistic symbiosis between the two. However, these signals can be eavesdropped by other microorganisms, such as the soil bacteria, Myxococcus xanthus, which preys on other bacteria. Eavesdropping, or the interception of signals from unintended receivers, such as plants and microorganisms, can lead to large-scale, evolutionary consequences. For example, signaler-receiver pairs, like plant-microorganism pairs, may lose the ability to communicate with neighboring populations because of variability in eavesdroppers. In adapting to avoid local eavesdroppers, signal divergence could occur and thus, lead to the isolation of plants and microorganisms from the inability to communicate with other populations.  Symbiosis  A lichen is a symbiosis of a macroscopic fungus with photosynthetic microbial algae or cyanobacteria.  Applications  Microorganisms are useful in producing foods, treating waste water, creating biofuels and a wide range of chemicals and enzymes. They are invaluable in research as model organisms. They have been weaponised and sometimes used in warfare and bioterrorism. They are vital to agriculture through their roles in maintaining soil fertility and in decomposing organic matter.  Food production  Microorganisms are used in a fermentation process to make yoghurt, cheese, curd, kefir, ayran, xynogala, and other types of food. Fermentation cultures provide flavour and aroma, and inhibit undesirable organisms. They are used to leaven bread, and to convert sugars to alcohol in wine and beer. Microorganisms are used in brewing, wine making, baking, pickling and other food-making processes.Some industrial uses of Microorganisms:  Water treatment  These depend for their ability to clean up water contaminated with organic material on microorganisms that can respire dissolved substances. Respiration may be aerobic, with a well-oxygenated filter bed such as a slow sand filter. Anaerobic digestion by methanogens generate useful methane gas as a by-product.  Energy  Microorganisms are used in fermentation to produce ethanol, and in biogas reactors to produce methane. Scientists are researching the use of algae to produce liquid fuels, and bacteria to convert various forms of agricultural and urban waste into usable fuels.  Chemicals, enzymes  Microorganisms are used to produce many commercial and industrial chemicals, enzymes and other bioactive molecules. Organic acids produced on a large industrial scale by microbial fermentation include acetic acid produced by acetic acid bacteria such as Acetobacter aceti, butyric acid made by the bacterium Clostridium butyricum, lactic acid made by Lactobacillus and other lactic acid bacteria, and citric acid produced by the mould fungus Aspergillus niger.Microorganisms are used to prepare bioactive molecules such as Streptokinase from the bacterium Streptococcus, Cyclosporin A from the ascomycete fungus Tolypocladium inflatum, and statins produced by the yeast Monascus purpureus.  Science  Microorganisms are essential tools in biotechnology, biochemistry, genetics, and molecular biology. The yeasts Saccharomyces cerevisiae and Schizosaccharomyces pombe are important model organisms in science, since they are simple eukaryotes that can be grown rapidly in large numbers and are easily manipulated. They are particularly valuable in genetics, genomics and proteomics. Microorganisms can be harnessed for uses such as creating steroids and treating skin diseases. Scientists are also considering using microorganisms for living fuel cells, and as a solution for pollution.  Warfare  In the Middle Ages, as an early example of biological warfare, diseased corpses were thrown into castles during sieges using catapults or other siege engines. Individuals near the corpses were exposed to the pathogen and were likely to spread that pathogen to others.In modern times, bioterrorism has included the 1984 Rajneeshee bioterror attack and the 1993 release of anthrax by Aum Shinrikyo in Tokyo.  Soil  Microbes can make nutrients and minerals in the soil available to plants, produce hormones that spur growth, stimulate the plant immune system and trigger or dampen stress responses. In general a more diverse set of soil microbes results in fewer plant diseases and higher yield.  Human health   Human gut flora  Microorganisms can form an endosymbiotic relationship with other, larger organisms. For example, microbial symbiosis plays a crucial role in the immune system. The microorganisms that make up the gut flora in the gastrointestinal tract contribute to gut immunity, synthesize vitamins such as folic acid and biotin, and ferment complex indigestible carbohydrates. Some microorganisms that are seen to be beneficial to health are termed probiotics and are available as dietary supplements, or food additives.  Disease  Microorganisms are the causative agents (pathogens) in many infectious diseases. The organisms involved include pathogenic bacteria, causing diseases such as plague, tuberculosis and anthrax; protozoan parasites, causing diseases such as malaria, sleeping sickness, dysentery and toxoplasmosis; and also fungi causing diseases such as ringworm, candidiasis or histoplasmosis. However, other diseases such as influenza, yellow fever or AIDS are caused by pathogenic viruses, which are not usually classified as living organisms and are not, therefore, microorganisms by the strict definition. No clear examples of archaean pathogens are known, although a relationship has been proposed between the presence of some archaean methanogens and human periodontal disease. Numerous microbial pathogens are capable of sexual processes that appear to facilitate their survival in their infected host.  Hygiene  Hygiene is a set of practices to avoid infection or food spoilage by eliminating microorganisms from the surroundings. As microorganisms, in particular bacteria, are found virtually everywhere, harmful microorganisms may be reduced to acceptable levels rather than actually eliminated. In food preparation, microorganisms are reduced by preservation methods such as cooking, cleanliness of utensils, short storage periods, or by low temperatures. If complete sterility is needed, as with surgical equipment, an autoclave is used to kill microorganisms with heat and pressure.  In fiction  Osmosis Jones, a 2001 film, and its show Ozzy & Drix, set in a stylized version of the human body, featured anthropomorphic microorganisms. War of the Worlds (2005 film), when Alien lifeforms attempt to conquer earth, they are ultimately defeated by a common Microbe to which Humans are immune.  See also   Notes   References   External links  Microbes.info is a microbiology information portal containing a vast collection of resources including articles, news, frequently asked questions, and links pertaining to the field of microbiology. Our Microbial Planet A free poster from the National Academy of Sciences about the positive roles of micro-organisms. ""Uncharted Microbial World: Microbes and Their Activities in the Environment"" Report from the American Academy of Microbiology Understanding Our Microbial Planet: The New Science of Metagenomics A 20-page educational booklet providing a basic overview of metagenomics and our microbial planet. Tree of Life Eukaryotes Microbe News from Genome News Network Medical Microbiology On-line textbook Through the microscope: A look at all things small On-line microbiology textbook by Timothy Paustian and Gary Roberts, University of Wisconsin–Madison Microorganisms in the pond water on YouTube Methane-spewing microbe blamed in worst mass extinction. CBCNews","A micro-organism or microbe is an organism which is microscopic, which means so small that people cannot see them with the naked eye. The study of microorganisms is called microbiology. Micro-organisms include bacteria, fungi, archaea, protists and viruses, and are among the earliest known life forms. The first of these four types of micro-organisms may either be free-living or parasitic. Viruses can only be parasitic, since they always reproduce inside other living things.Most micro-organisms are unicellular organisms with only one cell, but there are unicellular protists that are visible to the human eye, and some multicellular species are microscopic. Micro-organisms live almost everywhere on earth where there is liquid water, including hot springs on the ocean floor and deep inside rocks within the earth's crust. Such habitats are lived in by extremophiles. Micro-organisms are critical to nutrient recycling in ecosystems, because they act as decomposers. Because some micro-organisms can also take nitrogen out of the air, they are an important part of the nitrogen cycle. Pathogenic, or harmful, microbes can invade other organisms and cause disease.  Free-living micro-organisms  Free-living microbes get their energy in many different ways. Some use photosynthesis, like plants do. Some break down natural chemicals in their environment. Others feed on things that were once living, such as fallen leaves and dead animals, causing them to breakdown or decay. Some fungi and bacteria cause food to decay. Moldy bread or fruit, sour milk, and rotten meat are examples of decayed food. In nature, decayed materials mix with soil, providing essential nutrients for plants to use. Without this process, the nutrients in the soil would run out. These types of organisms are called decomposers. They are the natural recyclers of living things on our planet. Microbes also help us make some of our foods, such as bread, cheese, yogurt, beer, and wine. They feed on the sugar in grain, fruit, or milk, giving these foods a special texture and taste.  Parasitic microbes  Some microbes, often called germs, cause illness or disease. They are parasites which live by invading living things. Chickenpox, mumps, and measles are all caused by viruses. Some bacteria are also germs. They cause many infectious diseases including tuberculosis and tetanus. Certain bacteria cause tooth decay. It is possible to protect humans against some harmful microbes by storing and preparing food properly, cleaning the teeth, washing hands, and by avoiding close contact with ill people.  Comensalism  All animals seem to have bacteria and protozoa living in or on them without doing much harm. Sometimes, as with herbivores, the microorganisms are vital to the digestion of food. The human gut has more organisms living inside it than there are cells in the human body.  References   Other websites  Microbe News from Genome News Network BBC News, 28 September, 2001: The microbes that 'rule the world' Citat: ""... The Earth's climate may be dependent upon microbes that eat rock beneath the sea floor, according to new research....The number of the worm-like tracks in the rocks diminishes with depth; at 300 metres (985 feet) below the sea floor, they become much rarer..."" BBCNews: 16 January, 2002, Tough bugs point to life on Mars Citat: ""...This research demonstrates that certain microbes can thrive in the absence of sunlight by using hydrogen gas..."" BBCNews: 17 January, 2002, Alien life could be like Antarctic bugs Microbiology Archived 2009-09-20 at the Wayback Machine Microbe fixes nitrogen at a blistering 92 C Archived 2018-12-16 at the Wayback Machine"
"A fungus (PL: fungi or funguses) is any member of the group of eukaryotic organisms that includes microorganisms such as yeasts and molds, as well as the more familiar mushrooms. These organisms are classified as a kingdom, separately from the other eukaryotic kingdoms, which by one traditional classification include Plantae, Animalia, Protozoa, and Chromista. A characteristic that places fungi in a different kingdom from plants, bacteria, and some protists is chitin in their cell walls. Fungi, like animals, are heterotrophs; they acquire their food by absorbing dissolved molecules, typically by secreting digestive enzymes into their environment. Fungi do not photosynthesize. Growth is their means of mobility, except for spores (a few of which are flagellated), which may travel through the air or water. Fungi are the principal decomposers in ecological systems. These and other differences place fungi in a single group of related organisms, named the Eumycota (true fungi or Eumycetes), that share a common ancestor (i.e. they form a monophyletic group), an interpretation that is also strongly supported by molecular phylogenetics. This fungal group is distinct from the structurally similar myxomycetes (slime molds) and oomycetes (water molds). The discipline of biology devoted to the study of fungi is known as mycology (from the Greek μύκηςcode: ell promoted to code: el mykes, mushroom). In the past, mycology was regarded as a branch of botany, although it is now known fungi are genetically more closely related to animals than to plants. Abundant worldwide, most fungi are inconspicuous because of the small size of their structures, and their cryptic lifestyles in soil or on dead matter. Fungi include symbionts of plants, animals, or other fungi and also parasites. They may become noticeable when fruiting, either as mushrooms or as molds. Fungi perform an essential role in the decomposition of organic matter and have fundamental roles in nutrient cycling and exchange in the environment. They have long been used as a direct source of human food, in the form of mushrooms and truffles; as a leavening agent for bread; and in the fermentation of various food products, such as wine, beer, and soy sauce. Since the 1940s, fungi have been used for the production of antibiotics, and, more recently, various enzymes produced by fungi are used industrially and in detergents. Fungi are also used as biological pesticides to control weeds, plant diseases, and insect pests. Many species produce bioactive compounds called mycotoxins, such as alkaloids and polyketides, that are toxic to animals, including humans. The fruiting structures of a few species contain psychotropic compounds and are consumed recreationally or in traditional spiritual ceremonies. Fungi can break down manufactured materials and buildings, and become significant pathogens of humans and other animals. Losses of crops due to fungal diseases (e.g., rice blast disease) or food spoilage can have a large impact on human food supplies and local economies. The fungus kingdom encompasses an enormous diversity of taxa with varied ecologies, life cycle strategies, and morphologies ranging from unicellular aquatic chytrids to large mushrooms. However, little is known of the true biodiversity of the fungus kingdom, which has been estimated at 2.2 million to 3.8 million species. Of these, only about 148,000 have been described, with over 8,000 species known to be detrimental to plants and at least 300 that can be pathogenic to humans. Ever since the pioneering 18th and 19th century taxonomical works of Carl Linnaeus, Christiaan Hendrik Persoon, and Elias Magnus Fries, fungi have been classified according to their morphology (e.g., characteristics such as spore color or microscopic features) or physiology. Advances in molecular genetics have opened the way for DNA analysis to be incorporated into taxonomy, which has sometimes challenged the historical groupings based on morphology and other traits. Phylogenetic studies published in the first decade of the 21st century have helped reshape the classification within the fungi kingdom, which is divided into one subkingdom, seven phyla, and ten subphyla.  Etymology  The English word fungus is directly adopted from the Latin fungus (mushroom), used in the writings of Horace and Pliny. This in turn is derived from the Greek word sphongos (σφόγγος \'sponge\'), which refers to the macroscopic structures and morphology of mushrooms and molds; the root is also used in other languages, such as the German Schwamm (\'sponge\') and Schimmel (\'mold\').The word mycology is derived from the Greek mykes (μύκης \'mushroom\') and logos (λόγος \'discourse\'). It denotes the scientific study of fungi. The Latin adjectival form of ""mycology"" (mycologicæ) appeared as early as 1796 in a book on the subject by Christiaan Hendrik Persoon. The word appeared in English as early as 1824 in a book by Robert Kaye Greville. In 1836 the English naturalist Miles Joseph Berkeley\'s publication The English Flora of Sir James Edward Smith, Vol. 5. also refers to mycology as the study of fungi.A group of all the fungi present in a particular region is known as mycobiota (plural noun, no singular). The term mycota is often used for this purpose, but many authors use it as a synonym of Fungi. The word funga has been proposed as a less ambiguous term morphologically similar to fauna and flora. The Species Survival Commission (SSC) of the International Union for Conservation of Nature (IUCN) in August 2021 asked that the phrase fauna and flora be replaced by fauna, flora, and funga.  Characteristics  Before the introduction of molecular methods for phylogenetic analysis, taxonomists considered fungi to be members of the plant kingdom because of similarities in lifestyle: both fungi and plants are mainly immobile, and have similarities in general morphology and growth habitat. Although inaccurate, the common misconception that fungi are plants persists among the general public due to their historical classification, as well as several similarities. Like plants, fungi often grow in soil and, in the case of mushrooms, form conspicuous fruit bodies, which sometimes resemble plants such as mosses. The fungi are now considered a separate kingdom, distinct from both plants and animals, from which they appear to have diverged around one billion years ago (around the start of the Neoproterozoic Era). Some morphological, biochemical, and genetic features are shared with other organisms, while others are unique to the fungi, clearly separating them from the other kingdoms: Shared features: With other eukaryotes: Fungal cells contain membrane-bound nuclei with chromosomes that contain DNA with noncoding regions called introns and coding regions called exons. Fungi have membrane-bound cytoplasmic organelles such as mitochondria, sterol-containing membranes, and ribosomes of the 80S type. They have a characteristic range of soluble carbohydrates and storage compounds, including sugar alcohols (e.g., mannitol), disaccharides, (e.g., trehalose), and polysaccharides (e.g., glycogen, which is also found in animals). With animals: Fungi lack chloroplasts and are heterotrophic organisms and so require preformed organic compounds as energy sources. With plants: Fungi have a cell wall and vacuoles. They reproduce by both sexual and asexual means, and like basal plant groups (such as ferns and mosses) produce spores. Similar to mosses and algae, fungi typically have haploid nuclei. With euglenoids and bacteria: Higher fungi, euglenoids, and some bacteria produce the amino acid L-lysine in specific biosynthesis steps, called the α-aminoadipate pathway. The cells of most fungi grow as tubular, elongated, and thread-like (filamentous) structures called hyphae, which may contain multiple nuclei and extend by growing at their tips. Each tip contains a set of aggregated vesicles—cellular structures consisting of proteins, lipids, and other organic molecules—called the Spitzenkörper. Both fungi and oomycetes grow as filamentous hyphal cells. In contrast, similar-looking organisms, such as filamentous green algae, grow by repeated cell division within a chain of cells. There are also single-celled fungi (yeasts) that do not form hyphae, and some fungi have both hyphal and yeast forms. In common with some plant and animal species, more than one hundred fungal species display bioluminescence.Unique features: Some species grow as unicellular yeasts that reproduce by budding or fission. Dimorphic fungi can switch between a yeast phase and a hyphal phase in response to environmental conditions. The fungal cell wall is made of a chitin-glucan complex; while glucans are also found in plants and chitin in the exoskeleton of arthropods, fungi are the only organisms that combine these two structural molecules in their cell wall. Unlike those of plants and oomycetes, fungal cell walls do not contain cellulose. Most fungi lack an efficient system for the long-distance transport of water and nutrients, such as the xylem and phloem in many plants. To overcome this limitation, some fungi, such as Armillaria, form rhizomorphs, which resemble and perform functions similar to the roots of plants. As eukaryotes, fungi possess a biosynthetic pathway for producing terpenes that uses mevalonic acid and pyrophosphate as chemical building blocks. Plants and some other organisms have an additional terpene biosynthesis pathway in their chloroplasts, a structure that fungi and animals do not have. Fungi produce several secondary metabolites that are similar or identical in structure to those made by plants. Many of the plant and fungal enzymes that make these compounds differ from each other in sequence and other characteristics, which indicates separate origins and convergent evolution of these enzymes in the fungi and plants.  Diversity  Fungi have a worldwide distribution, and grow in a wide range of habitats, including extreme environments such as deserts or areas with high salt concentrations or ionizing radiation, as well as in deep sea sediments. Some can survive the intense UV and cosmic radiation encountered during space travel. Most grow in terrestrial environments, though several species live partly or solely in aquatic habitats, such as the chytrid fungi Batrachochytrium dendrobatidis and B. salamandrivorans, parasites that have been responsible for a worldwide decline in amphibian populations. These organisms spend part of their life cycle as a motile zoospore, enabling them to propel itself through water and enter their amphibian host. Other examples of aquatic fungi include those living in hydrothermal areas of the ocean. As of 2020, around 148,000 species of fungi have been described by taxonomists, but the global biodiversity of the fungus kingdom is not fully understood. A 2017 estimate suggests there may be between 2.2 and 3.8 million species. The number of new fungi species discovered yearly has increased from 1,000 to 1,500 per year about 10 years ago, to about 2000 with a peak of more than 2,500 species in 2016. In the year 2019, 1882 new species of fungi were described, and it was estimated that more than 90% of fungi remain unknown. The following year, 2905 new species were described—the highest annual record of new fungus names. In mycology, species have historically been distinguished by a variety of methods and concepts. Classification based on morphological characteristics, such as the size and shape of spores or fruiting structures, has traditionally dominated fungal taxonomy. Species may also be distinguished by their biochemical and physiological characteristics, such as their ability to metabolize certain biochemicals, or their reaction to chemical tests. The biological species concept discriminates species based on their ability to mate. The application of molecular tools, such as DNA sequencing and phylogenetic analysis, to study diversity has greatly enhanced the resolution and added robustness to estimates of genetic diversity within various taxonomic groups.  Mycology  Mycology is the branch of biology concerned with the systematic study of fungi, including their genetic and biochemical properties, their taxonomy, and their use to humans as a source of medicine, food, and psychotropic substances consumed for religious purposes, as well as their dangers, such as poisoning or infection. The field of phytopathology, the study of plant diseases, is closely related because many plant pathogens are fungi.The use of fungi by humans dates back to prehistory; Ötzi the Iceman, a well-preserved mummy of a 5,300-year-old Neolithic man found frozen in the Austrian Alps, carried two species of polypore mushrooms that may have been used as tinder (Fomes fomentarius), or for medicinal purposes (Piptoporus betulinus). Ancient peoples have used fungi as food sources—often unknowingly—for millennia, in the preparation of leavened bread and fermented juices. Some of the oldest written records contain references to the destruction of crops that were probably caused by pathogenic fungi.  History  Mycology became a systematic science after the development of the microscope in the 17th century. Although fungal spores were first observed by Giambattista della Porta in 1588, the seminal work in the development of mycology is considered to be the publication of Pier Antonio Micheli\'s 1729 work Nova plantarum genera. Micheli not only observed spores but also showed that, under the proper conditions, they could be induced into growing into the same species of fungi from which they originated. Extending the use of the binomial system of nomenclature introduced by Carl Linnaeus in his Species plantarum (1753), the Dutch Christiaan Hendrik Persoon (1761–1836) established the first classification of mushrooms with such skill as to be considered a founder of modern mycology. Later, Elias Magnus Fries (1794–1878) further elaborated the classification of fungi, using spore color and microscopic characteristics, methods still used by taxonomists today. Other notable early contributors to mycology in the 17th–19th and early 20th centuries include Miles Joseph Berkeley, August Carl Joseph Corda, Anton de Bary, the brothers Louis René and Charles Tulasne, Arthur H. R. Buller, Curtis G. Lloyd, and Pier Andrea Saccardo. In the 20th and 21st centuries, advances in biochemistry, genetics, molecular biology, biotechnology, DNA sequencing and phylogenetic analysis has provided new insights into fungal relationships and biodiversity, and has challenged traditional morphology-based groupings in fungal taxonomy.  Morphology   Microscopic structures  Most fungi grow as hyphae, which are cylindrical, thread-like structures 2–10 µm in diameter and up to several centimeters in length. Hyphae grow at their tips (apices); new hyphae are typically formed by emergence of new tips along existing hyphae by a process called branching, or occasionally growing hyphal tips fork, giving rise to two parallel-growing hyphae. Hyphae also sometimes fuse when they come into contact, a process called hyphal fusion (or anastomosis). These growth processes lead to the development of a mycelium, an interconnected network of hyphae. Hyphae can be either septate or coenocytic. Septate hyphae are divided into compartments separated by cross walls (internal cell walls, called septa, that are formed at right angles to the cell wall giving the hypha its shape), with each compartment containing one or more nuclei; coenocytic hyphae are not compartmentalized. Septa have pores that allow cytoplasm, organelles, and sometimes nuclei to pass through; an example is the dolipore septum in fungi of the phylum Basidiomycota. Coenocytic hyphae are in essence multinucleate supercells.Many species have developed specialized hyphal structures for nutrient uptake from living hosts; examples include haustoria in plant-parasitic species of most fungal phyla, and arbuscules of several mycorrhizal fungi, which penetrate into the host cells to consume nutrients.Although fungi are opisthokonts—a grouping of evolutionarily related organisms broadly characterized by a single posterior flagellum—all phyla except for the chytrids have lost their posterior flagella. Fungi are unusual among the eukaryotes in having a cell wall that, in addition to glucans (e.g., β-1,3-glucan) and other typical components, also contains the biopolymer chitin.  Macroscopic structures  Fungal mycelia can become visible to the naked eye, for example, on various surfaces and substrates, such as damp walls and spoiled food, where they are commonly called molds. Mycelia grown on solid agar media in laboratory petri dishes are usually referred to as colonies. These colonies can exhibit growth shapes and colors (due to spores or pigmentation) that can be used as diagnostic features in the identification of species or groups. Some individual fungal colonies can reach extraordinary dimensions and ages as in the case of a clonal colony of Armillaria solidipes, which extends over an area of more than 900 ha (3.5 square miles), with an estimated age of nearly 9,000 years.The apothecium—a specialized structure important in sexual reproduction in the ascomycetes—is a cup-shaped fruit body that is often macroscopic and holds the hymenium, a layer of tissue containing the spore-bearing cells. The fruit bodies of the basidiomycetes (basidiocarps) and some ascomycetes can sometimes grow very large, and many are well known as mushrooms.  Growth and physiology  The growth of fungi as hyphae on or in solid substrates or as single cells in aquatic environments is adapted for the efficient extraction of nutrients, because these growth forms have high surface area to volume ratios. Hyphae are specifically adapted for growth on solid surfaces, and to invade substrates and tissues. They can exert large penetrative mechanical forces; for example, many plant pathogens, including Magnaporthe grisea, form a structure called an appressorium that evolved to puncture plant tissues. The pressure generated by the appressorium, directed against the plant epidermis, can exceed 8 megapascals (1,200 psi). The filamentous fungus Paecilomyces lilacinus uses a similar structure to penetrate the eggs of nematodes.The mechanical pressure exerted by the appressorium is generated from physiological processes that increase intracellular turgor by producing osmolytes such as glycerol. Adaptations such as these are complemented by hydrolytic enzymes secreted into the environment to digest large organic molecules—such as polysaccharides, proteins, and lipids—into smaller molecules that may then be absorbed as nutrients. The vast majority of filamentous fungi grow in a polar fashion (extending in one direction) by elongation at the tip (apex) of the hypha. Other forms of fungal growth include intercalary extension (longitudinal expansion of hyphal compartments that are below the apex) as in the case of some endophytic fungi, or growth by volume expansion during the development of mushroom stipes and other large organs. Growth of fungi as multicellular structures consisting of somatic and reproductive cells—a feature independently evolved in animals and plants—has several functions, including the development of fruit bodies for dissemination of sexual spores (see above) and biofilms for substrate colonization and intercellular communication.The fungi are traditionally considered heterotrophs, organisms that rely solely on carbon fixed by other organisms for metabolism. Fungi have evolved a high degree of metabolic versatility that allows them to use a diverse range of organic substrates for growth, including simple compounds such as nitrate, ammonia, acetate, or ethanol. In some species the pigment melanin may play a role in extracting energy from ionizing radiation, such as gamma radiation. This form of ""radiotrophic"" growth has been described for only a few species, the effects on growth rates are small, and the underlying biophysical and biochemical processes are not well known. This process might bear similarity to CO2 fixation via visible light, but instead uses ionizing radiation as a source of energy.  Reproduction  Fungal reproduction is complex, reflecting the differences in lifestyles and genetic makeup within this diverse kingdom of organisms. It is estimated that a third of all fungi reproduce using more than one method of propagation; for example, reproduction may occur in two well-differentiated stages within the life cycle of a species, the teleomorph (sexual reproduction) and the anamorph (asexual reproduction). Environmental conditions trigger genetically determined developmental states that lead to the creation of specialized structures for sexual or asexual reproduction. These structures aid reproduction by efficiently dispersing spores or spore-containing propagules.  Asexual reproduction  Asexual reproduction occurs via vegetative spores (conidia) or through mycelial fragmentation. Mycelial fragmentation occurs when a fungal mycelium separates into pieces, and each component grows into a separate mycelium. Mycelial fragmentation and vegetative spores maintain clonal populations adapted to a specific niche, and allow more rapid dispersal than sexual reproduction. The ""Fungi imperfecti"" (fungi lacking the perfect or sexual stage) or Deuteromycota comprise all the species that lack an observable sexual cycle. Deuteromycota (alternatively known as Deuteromycetes, conidial fungi, or mitosporic fungi) is not an accepted taxonomic clade and is now taken to mean simply fungi that lack a known sexual stage.  Sexual reproduction  Sexual reproduction with meiosis has been directly observed in all fungal phyla except Glomeromycota (genetic analysis suggests meiosis in Glomeromycota as well). It differs in many aspects from sexual reproduction in animals or plants. Differences also exist between fungal groups and can be used to discriminate species by morphological differences in sexual structures and reproductive strategies. Mating experiments between fungal isolates may identify species on the basis of biological species concepts. The major fungal groupings have initially been delineated based on the morphology of their sexual structures and spores; for example, the spore-containing structures, asci and basidia, can be used in the identification of ascomycetes and basidiomycetes, respectively. Fungi employ two mating systems: heterothallic species allow mating only between individuals of the opposite mating type, whereas homothallic species can mate, and sexually reproduce, with any other individual or itself.Most fungi have both a haploid and a diploid stage in their life cycles. In sexually reproducing fungi, compatible individuals may combine by fusing their hyphae together into an interconnected network; this process, anastomosis, is required for the initiation of the sexual cycle. Many ascomycetes and basidiomycetes go through a dikaryotic stage, in which the nuclei inherited from the two parents do not combine immediately after cell fusion, but remain separate in the hyphal cells (see heterokaryosis). In ascomycetes, dikaryotic hyphae of the hymenium (the spore-bearing tissue layer) form a characteristic hook (crozier) at the hyphal septum. During cell division, the formation of the hook ensures proper distribution of the newly divided nuclei into the apical and basal hyphal compartments. An ascus (plural asci) is then formed, in which karyogamy (nuclear fusion) occurs. Asci are embedded in an ascocarp, or fruiting body. Karyogamy in the asci is followed immediately by meiosis and the production of ascospores. After dispersal, the ascospores may germinate and form a new haploid mycelium.Sexual reproduction in basidiomycetes is similar to that of the ascomycetes. Compatible haploid hyphae fuse to produce a dikaryotic mycelium. However, the dikaryotic phase is more extensive in the basidiomycetes, often also present in the vegetatively growing mycelium. A specialized anatomical structure, called a clamp connection, is formed at each hyphal septum. As with the structurally similar hook in the ascomycetes, the clamp connection in the basidiomycetes is required for controlled transfer of nuclei during cell division, to maintain the dikaryotic stage with two genetically different nuclei in each hyphal compartment. A basidiocarp is formed in which club-like structures known as basidia generate haploid basidiospores after karyogamy and meiosis. The most commonly known basidiocarps are mushrooms, but they may also take other forms (see Morphology section). In fungi formerly classified as Zygomycota, haploid hyphae of two individuals fuse, forming a gametangium, a specialized cell structure that becomes a fertile gamete-producing cell. The gametangium develops into a zygospore, a thick-walled spore formed by the union of gametes. When the zygospore germinates, it undergoes meiosis, generating new haploid hyphae, which may then form asexual sporangiospores. These sporangiospores allow the fungus to rapidly disperse and germinate into new genetically identical haploid fungal mycelia.  Spore dispersal  The spores of most of the researched species of fungi are transported by wind. Such species often produce dry or hydrophobic spores that do not absorb water and are readily scattered by raindrops, for example. In other species, both asexual and sexual spores or sporangiospores are often actively dispersed by forcible ejection from their reproductive structures. This ejection ensures exit of the spores from the reproductive structures as well as traveling through the air over long distances. Specialized mechanical and physiological mechanisms, as well as spore surface structures (such as hydrophobins), enable efficient spore ejection. For example, the structure of the spore-bearing cells in some ascomycete species is such that the buildup of substances affecting cell volume and fluid balance enables the explosive discharge of spores into the air. The forcible discharge of single spores termed ballistospores involves formation of a small drop of water (Buller\'s drop), which upon contact with the spore leads to its projectile release with an initial acceleration of more than 10,000 g; the net result is that the spore is ejected 0.01–0.02 cm, sufficient distance for it to fall through the gills or pores into the air below. Other fungi, like the puffballs, rely on alternative mechanisms for spore release, such as external mechanical forces. The hydnoid fungi (tooth fungi) produce spores on pendant, tooth-like or spine-like projections. The bird\'s nest fungi use the force of falling water drops to liberate the spores from cup-shaped fruiting bodies. Another strategy is seen in the stinkhorns, a group of fungi with lively colors and putrid odor that attract insects to disperse their spores.  Homothallism  In homothallic sexual reproduction, two haploid nuclei derived from the same individual fuse to form a zygote that can then undergo meiosis. Homothallic fungi include species with an Aspergillus-like asexual stage (anamorphs) occurring in numerous different genera, several species of the ascomycete genus Cochliobolus, and the ascomycete Pneumocystis jirovecii. The earliest mode of sexual reproduction among eukaryotes was likely homothallism, that is, self-fertile unisexual reproduction.  Other sexual processes  Besides regular sexual reproduction with meiosis, certain fungi, such as those in the genera Penicillium and Aspergillus, may exchange genetic material via parasexual processes, initiated by anastomosis between hyphae and plasmogamy of fungal cells. The frequency and relative importance of parasexual events is unclear and may be lower than other sexual processes. It is known to play a role in intraspecific hybridization and is likely required for hybridization between species, which has been associated with major events in fungal evolution.  Evolution  In contrast to plants and animals, the early fossil record of the fungi is meager. Factors that likely contribute to the under-representation of fungal species among fossils include the nature of fungal fruiting bodies, which are soft, fleshy, and easily degradable tissues and the microscopic dimensions of most fungal structures, which therefore are not readily evident. Fungal fossils are difficult to distinguish from those of other microbes, and are most easily identified when they resemble extant fungi. Often recovered from a permineralized plant or animal host, these samples are typically studied by making thin-section preparations that can be examined with light microscopy or transmission electron microscopy. Researchers study compression fossils by dissolving the surrounding matrix with acid and then using light or scanning electron microscopy to examine surface details. The earliest fossils possessing features typical of fungi date to the Paleoproterozoic era, some 2,400 million years ago (Ma); these multicellular benthic organisms had filamentous structures capable of anastomosis. Other studies (2009) estimate the arrival of fungal organisms at about 760–1060 Ma on the basis of comparisons of the rate of evolution in closely related groups. For much of the Paleozoic Era (542–251 Ma), the fungi appear to have been aquatic and consisted of organisms similar to the extant chytrids in having flagellum-bearing spores. The evolutionary adaptation from an aquatic to a terrestrial lifestyle necessitated a diversification of ecological strategies for obtaining nutrients, including parasitism, saprobism, and the development of mutualistic relationships such as mycorrhiza and lichenization. Studies suggest that the ancestral ecological state of the Ascomycota was saprobism, and that independent lichenization events have occurred multiple times.In May 2019, scientists reported the discovery of a fossilized fungus, named Ourasphaira giraldae, in the Canadian Arctic, that may have grown on land a billion years ago, well before plants were living on land. Pyritized fungus-like microfossils preserved in the basal Ediacaran Doushantuo Formation (~635 Ma) have been reported in South China. Earlier, it had been presumed that the fungi colonized the land during the Cambrian (542–488.3 Ma), also long before land plants. Fossilized hyphae and spores recovered from the Ordovician of Wisconsin (460 Ma) resemble modern-day Glomerales, and existed at a time when the land flora likely consisted of only non-vascular bryophyte-like plants. Prototaxites, which was probably a fungus or lichen, would have been the tallest organism of the late Silurian and early Devonian. Fungal fossils do not become common and uncontroversial until the early Devonian (416–359.2 Ma), when they occur abundantly in the Rhynie chert, mostly as Zygomycota and Chytridiomycota. At about this same time, approximately 400 Ma, the Ascomycota and Basidiomycota diverged, and all modern classes of fungi were present by the Late Carboniferous (Pennsylvanian, 318.1–299 Ma).Lichens formed a component of the early terrestrial ecosystems, and the estimated age of the oldest terrestrial lichen fossil is 415 Ma; this date roughly corresponds to the age of the oldest known sporocarp fossil, a Paleopyrenomycites species found in the Rhynie Chert. The oldest fossil with microscopic features resembling modern-day basidiomycetes is Palaeoancistrus, found permineralized with a fern from the Pennsylvanian. Rare in the fossil record are the Homobasidiomycetes (a taxon roughly equivalent to the mushroom-producing species of the Agaricomycetes). Two amber-preserved specimens provide evidence that the earliest known mushroom-forming fungi (the extinct species Archaeomarasmius leggetti) appeared during the late Cretaceous, 90 Ma.Some time after the Permian–Triassic extinction event (251.4 Ma), a fungal spike (originally thought to be an extraordinary abundance of fungal spores in sediments) formed, suggesting that fungi were the dominant life form at this time, representing nearly 100% of the available fossil record for this period. However, the relative proportion of fungal spores relative to spores formed by algal species is difficult to assess, the spike did not appear worldwide, and in many places it did not fall on the Permian–Triassic boundary.Sixty-five million years ago, immediately after the Cretaceous–Paleogene extinction event that famously killed off most dinosaurs, there was a dramatic increase in evidence of fungi; apparently the death of most plant and animal species led to a huge fungal bloom like ""a massive compost heap"".  Taxonomy  Although commonly included in botany curricula and textbooks, fungi are more closely related to animals than to plants and are placed with the animals in the monophyletic group of opisthokonts. Analyses using molecular phylogenetics support a monophyletic origin of fungi. The taxonomy of fungi is in a state of constant flux, especially due to research based on DNA comparisons. These current phylogenetic analyses often overturn classifications based on older and sometimes less discriminative methods based on morphological features and biological species concepts obtained from experimental matings.There is no unique generally accepted system at the higher taxonomic levels and there are frequent name changes at every level, from species upwards. Efforts among researchers are now underway to establish and encourage usage of a unified and more consistent nomenclature. Until relatively recent (2012) changes to the International Code of Nomenclature for algae, fungi and plants, fungal species could also have multiple scientific names depending on their life cycle and mode (sexual or asexual) of reproduction. Web sites such as Index Fungorum and MycoBank are officially recognized nomenclatural repositories and list current names of fungal species (with cross-references to older synonyms).The 2007 classification of Kingdom Fungi is the result of a large-scale collaborative research effort involving dozens of mycologists and other scientists working on fungal taxonomy. It recognizes seven phyla, two of which—the Ascomycota and the Basidiomycota—are contained within a branch representing subkingdom Dikarya, the most species rich and familiar group, including all the mushrooms, most food-spoilage molds, most plant pathogenic fungi, and the beer, wine, and bread yeasts. The accompanying cladogram depicts the major fungal taxa and their relationship to opisthokont and unikont organisms, based on the work of Philippe Silar, ""The Mycota: A Comprehensive Treatise on Fungi as Experimental Systems for Basic and Applied Research"" and Tedersoo et al. 2018. The lengths of the branches are not proportional to evolutionary distances.  Taxonomic groups  The major phyla (sometimes called divisions) of fungi have been classified mainly on the basis of characteristics of their sexual reproductive structures. As of 2019, nine major lineages have been identified: Opisthosporidia, Chytridiomycota, Neocallimastigomycota, Blastocladiomycota, Zoopagomycota, Mucoromycota, Glomeromycota, Ascomycota and Basidiomycota.Phylogenetic analysis has demonstrated that the Microsporidia, unicellular parasites of animals and protists, are fairly recent and highly derived endobiotic fungi (living within the tissue of another species). Previously considered to be ""primitive"" protozoa, they are now thought to be either a basal branch of the Fungi, or a sister group–each other\'s closest evolutionary relative.The Chytridiomycota are commonly known as chytrids. These fungi are distributed worldwide. Chytrids and their close relatives Neocallimastigomycota and Blastocladiomycota (below) are the only fungi with active motility, producing zoospores that are capable of active movement through aqueous phases with a single flagellum, leading early taxonomists to classify them as protists. Molecular phylogenies, inferred from rRNA sequences in ribosomes, suggest that the Chytrids are a basal group divergent from the other fungal phyla, consisting of four major clades with suggestive evidence for paraphyly or possibly polyphyly.The Blastocladiomycota were previously considered a taxonomic clade within the Chytridiomycota. Molecular data and ultrastructural characteristics, however, place the Blastocladiomycota as a sister clade to the Zygomycota, Glomeromycota, and Dikarya (Ascomycota and Basidiomycota). The blastocladiomycetes are saprotrophs, feeding on decomposing organic matter, and they are parasites of all eukaryotic groups. Unlike their close relatives, the chytrids, most of which exhibit zygotic meiosis, the blastocladiomycetes undergo sporic meiosis.The Neocallimastigomycota were earlier placed in the phylum Chytridiomycota. Members of this small phylum are anaerobic organisms, living in the digestive system of larger herbivorous mammals and in other terrestrial and aquatic environments enriched in cellulose (e.g., domestic waste landfill sites). They lack mitochondria but contain hydrogenosomes of mitochondrial origin. As in the related chrytrids, neocallimastigomycetes form zoospores that are posteriorly uniflagellate or polyflagellate. Members of the Glomeromycota form arbuscular mycorrhizae, a form of mutualist symbiosis wherein fungal hyphae invade plant root cells and both species benefit from the resulting increased supply of nutrients. All known Glomeromycota species reproduce asexually. The symbiotic association between the Glomeromycota and plants is ancient, with evidence dating to 400 million years ago. Formerly part of the Zygomycota (commonly known as \'sugar\' and \'pin\' molds), the Glomeromycota were elevated to phylum status in 2001 and now replace the older phylum Zygomycota. Fungi that were placed in the Zygomycota are now being reassigned to the Glomeromycota, or the subphyla incertae sedis Mucoromycotina, Kickxellomycotina, the Zoopagomycotina and the Entomophthoromycotina. Some well-known examples of fungi formerly in the Zygomycota include black bread mold (Rhizopus stolonifer), and Pilobolus species, capable of ejecting spores several meters through the air. Medically relevant genera include Mucor, Rhizomucor, and Rhizopus.The Ascomycota, commonly known as sac fungi or ascomycetes, constitute the largest taxonomic group within the Eumycota. These fungi form meiotic spores called ascospores, which are enclosed in a special sac-like structure called an ascus. This phylum includes morels, a few mushrooms and truffles, unicellular yeasts (e.g., of the genera Saccharomyces, Kluyveromyces, Pichia, and Candida), and many filamentous fungi living as saprotrophs, parasites, and mutualistic symbionts (e.g. lichens). Prominent and important genera of filamentous ascomycetes include Aspergillus, Penicillium, Fusarium, and Claviceps. Many ascomycete species have only been observed undergoing asexual reproduction (called anamorphic species), but analysis of molecular data has often been able to identify their closest teleomorphs in the Ascomycota. Because the products of meiosis are retained within the sac-like ascus, ascomycetes have been used for elucidating principles of genetics and heredity (e.g., Neurospora crassa).Members of the Basidiomycota, commonly known as the club fungi or basidiomycetes, produce meiospores called basidiospores on club-like stalks called basidia. Most common mushrooms belong to this group, as well as rust and smut fungi, which are major pathogens of grains. Other important basidiomycetes include the maize pathogen Ustilago maydis, human commensal species of the genus Malassezia, and the opportunistic human pathogen, Cryptococcus neoformans.  Fungus-like organisms  Because of similarities in morphology and lifestyle, the slime molds (mycetozoans, plasmodiophorids, acrasids, Fonticula and labyrinthulids, now in Amoebozoa, Rhizaria, Excavata, Opisthokonta and Stramenopiles, respectively), water molds (oomycetes) and hyphochytrids (both Stramenopiles) were formerly classified in the kingdom Fungi, in groups like Mastigomycotina, Gymnomycota and Phycomycetes. The slime molds were studied also as protozoans, leading to an ambiregnal, duplicated taxonomy.Unlike true fungi, the cell walls of oomycetes contain cellulose and lack chitin. Hyphochytrids have both chitin and cellulose. Slime molds lack a cell wall during the assimilative phase (except labyrinthulids, which have a wall of scales), and take in nutrients by ingestion (phagocytosis, except labyrinthulids) rather than absorption (osmotrophy, as fungi, labyrinthulids, oomycetes and hyphochytrids). Neither water molds nor slime molds are closely related to the true fungi, and, therefore, taxonomists no longer group them in the kingdom Fungi. Nonetheless, studies of the oomycetes and myxomycetes are still often included in mycology textbooks and primary research literature.The Eccrinales and Amoebidiales are opisthokont protists, previously thought to be zygomycete fungi. Other groups now in Opisthokonta (e.g., Corallochytrium, Ichthyosporea) were also at given time classified as fungi. The genus Blastocystis, now in Stramenopiles, was originally classified as a yeast. Ellobiopsis, now in Alveolata, was considered a chytrid. The bacteria were also included in fungi in some classifications, as the group Schizomycetes. The Rozellida clade, including the ""ex-chytrid"" Rozella, is a genetically disparate group known mostly from environmental DNA sequences that is a sister group to fungi. Members of the group that have been isolated lack the chitinous cell wall that is characteristic of fungi. Alternatively, Rozella can be classified as a basal fungal group.The nucleariids may be the next sister group to the eumycete clade, and as such could be included in an expanded fungal kingdom. Many Actinomycetales (Actinomycetota), a group with many filamentous bacteria, were also long believed to be fungi.  Ecology  Although often inconspicuous, fungi occur in every environment on Earth and play very important roles in most ecosystems. Along with bacteria, fungi are the major decomposers in most terrestrial (and some aquatic) ecosystems, and therefore play a critical role in biogeochemical cycles and in many food webs. As decomposers, they play an essential role in nutrient cycling, especially as saprotrophs and symbionts, degrading organic matter to inorganic molecules, which can then re-enter anabolic metabolic pathways in plants or other organisms.  Symbiosis  Many fungi have important symbiotic relationships with organisms from most if not all kingdoms. These interactions can be mutualistic or antagonistic in nature, or in the case of commensal fungi are of no apparent benefit or detriment to the host.  With plants  Mycorrhizal symbiosis between plants and fungi is one of the most well-known plant–fungus associations and is of significant importance for plant growth and persistence in many ecosystems; over 90% of all plant species engage in mycorrhizal relationships with fungi and are dependent upon this relationship for survival. The mycorrhizal symbiosis is ancient, dating back to at least 400 million years. It often increases the plant\'s uptake of inorganic compounds, such as nitrate and phosphate from soils having low concentrations of these key plant nutrients. The fungal partners may also mediate plant-to-plant transfer of carbohydrates and other nutrients. Such mycorrhizal communities are called ""common mycorrhizal networks"". A special case of mycorrhiza is myco-heterotrophy, whereby the plant parasitizes the fungus, obtaining all of its nutrients from its fungal symbiont. Some fungal species inhabit the tissues inside roots, stems, and leaves, in which case they are called endophytes. Similar to mycorrhiza, endophytic colonization by fungi may benefit both symbionts; for example, endophytes of grasses impart to their host increased resistance to herbivores and other environmental stresses and receive food and shelter from the plant in return.  With algae and cyanobacteria  Lichens are a symbiotic relationship between fungi and photosynthetic algae or cyanobacteria. The photosynthetic partner in the relationship is referred to in lichen terminology as a ""photobiont"". The fungal part of the relationship is composed mostly of various species of ascomycetes and a few basidiomycetes. Lichens occur in every ecosystem on all continents, play a key role in soil formation and the initiation of biological succession, and are prominent in some extreme environments, including polar, alpine, and semiarid desert regions. They are able to grow on inhospitable surfaces, including bare soil, rocks, tree bark, wood, shells, barnacles and leaves. As in mycorrhizas, the photobiont provides sugars and other carbohydrates via photosynthesis to the fungus, while the fungus provides minerals and water to the photobiont. The functions of both symbiotic organisms are so closely intertwined that they function almost as a single organism; in most cases the resulting organism differs greatly from the individual components. Lichenization is a common mode of nutrition for fungi; around 27% of known fungi—more than 19,400 species—are lichenized. Characteristics common to most lichens include obtaining organic carbon by photosynthesis, slow growth, small size, long life, long-lasting (seasonal) vegetative reproductive structures, mineral nutrition obtained largely from airborne sources, and greater tolerance of desiccation than most other photosynthetic organisms in the same habitat.  With insects  Many insects also engage in mutualistic relationships with fungi. Several groups of ants cultivate fungi in the order Chaetothyriales for several purposes: as a food source, as a structural component of their nests, and as a part of an ant/plant symbiosis in the domatia (tiny chambers in plants that house arthropods). Ambrosia beetles cultivate various species of fungi in the bark of trees that they infest. Likewise, females of several wood wasp species (genus Sirex) inject their eggs together with spores of the wood-rotting fungus Amylostereum areolatum into the sapwood of pine trees; the growth of the fungus provides ideal nutritional conditions for the development of the wasp larvae. At least one species of stingless bee has a relationship with a fungus in the genus Monascus, where the larvae consume and depend on fungus transferred from old to new nests. Termites on the African savannah are also known to cultivate fungi, and yeasts of the genera Candida and Lachancea inhabit the gut of a wide range of insects, including neuropterans, beetles, and cockroaches; it is not known whether these fungi benefit their hosts. Fungi growing in dead wood are essential for xylophagous insects (e.g. woodboring beetles). They deliver nutrients needed by xylophages to nutritionally scarce dead wood. Thanks to this nutritional enrichment the larvae of the woodboring insect is able to grow and develop to adulthood. The larvae of many families of fungicolous flies, particularly those within the superfamily Sciaroidea such as the Mycetophilidae and some Keroplatidae feed on fungal fruiting bodies and sterile mycorrhizae.  As pathogens and parasites  Many fungi are parasites on plants, animals (including humans), and other fungi. Serious pathogens of many cultivated plants causing extensive damage and losses to agriculture and forestry include the rice blast fungus Magnaporthe oryzae, tree pathogens such as Ophiostoma ulmi and Ophiostoma novo-ulmi causing Dutch elm disease, Cryphonectria parasitica responsible for chestnut blight, and Phymatotrichopsis omnivora causing Texas Root Rot, and plant pathogens in the genera Fusarium, Ustilago, Alternaria, and Cochliobolus. Some carnivorous fungi, like Paecilomyces lilacinus, are predators of nematodes, which they capture using an array of specialized structures such as constricting rings or adhesive nets. Many fungi that are plant pathogens, such as Magnaporthe oryzae, can switch from being biotrophic (parasitic on living plants) to being necrotrophic (feeding on the dead tissues of plants they have killed). This same principle is applied to fungi-feeding parasites, including Asterotremella albida, which feeds on the fruit bodies of other fungi both while they are living and after they are dead.Some fungi can cause serious diseases in humans, several of which may be fatal if untreated. These include aspergillosis, candidiasis, coccidioidomycosis, cryptococcosis, histoplasmosis, mycetomas, and paracoccidioidomycosis. Furthermore, persons with immuno-deficiencies are particularly susceptible to disease by genera such as Aspergillus, Candida, Cryptoccocus, Histoplasma, and Pneumocystis.","A fungus (plural: fungi) is a living organism that includes yeasts, moulds, mushrooms and others. Fungi have thin thread-like cells called hyphae that absorb nutrients and hold the fungus in place. Some, such as mushrooms, also have a body containing many cells. Fungi do not have chlorophyll to capture energy from sunlight as plants do. Instead, they are nourished by digesting dead organic matter around them and absorbing it. The study of fungi is called mycology. The fungi are a separate kingdom of living things, different from animals and plants.The cells of fungi have nuclei, unlike the cells of bacteria. Hyphae sometimes have many nuclei. Their cell walls contain chitin, unlike the cell walls of plants, which contain cellulose. These and other differences show that the fungi form a single group of related organisms. The group of fungi is called the Eumycota or Eumycetes. They share a common ancestor: they are a monophyletic group. Fungi are saprophytic: a fungus breaks down dead organic matter around it, and uses it as food. It absorbs the molecules of food through its cell wall.p107 Some fungi are parasitic or symbiotic. Fungi reproduce sexually and asexually in several different ways. Many fungi make spores that grow into new fungi. Fungi came into existence about 1000 million years ago. They are found in fossils from the Devonian period, and they are probably much older. They are hard to find in older fossils because they decay rapidly.  Structure   Reproduction  Fungi reproduce both sexually and asexually. Some fungi grow mushrooms: these are fruiting bodies. Under the cap there are gills; the gills bear spores that will disperse, and may develop into new fungi. Otherwise, fungi use a sporangium to bear asexual spores by mitosis, or sexual spores by meiosis. The spores are haploid. Fungi may be single celled or multicellular. Yeast is single-celled, and reproduces either sexually or asexually. Asexual reproduction occurs by simple budding (binary fission).  Mycelium  The mycelium is the vegetative (non-reproductive) part of a fungus. It is usually underground (or inside some other substance), and made of filaments called hyphae (singluar: hypha).  Hyphae  Hyphae look like threads or tiny roots. The mycelium is a mat of hyphae that may be very thickly woven. The fungus uses them to extract nutrients. Each hypha is a long cell inside a tube-shaped cell wall that grows from the end. Hyphae are usually syncytia. This means the cell walls (septa) are mostly not complete, and the cell nuclei are not separated from each other as in normal cells. Details differ between species.  Symbiosis  Symbiosis means living together. Lichens are a symbiosis between a fungus and an alga or bacterium. In this partnership the algal cells live inside the fungus tissue. The result is a new mat-like life-form which clings to rock and other surfaces. About 20% of all fungi live as part of a lichen. Another important kind of symbiosis is mycorrhiza. This is when a fungus lives inside plant roots; most trees have mycorrhizal roots, and so do many crop plants. Both the fungus and the plant benefit in this arrangement.  Pathogens  Some fungi cause crop diseases; others cause serious disease in humans. Some are highly poisonous: never eat a mushroom picked in the wild unless you know what you are doing.  Uses  Edible fungi are widely used as human food. Certain types of cheese need a fungal species to be added. Blue cheese and Camembert cheese are examples of those types of cheese. The fungi give a unique flavor and texture to the cheese. Some fungi produce psychotropic (mind-altering) substances. Some people take these fungi recreationally for their psychedelic properties. These psychedelic mushrooms are often called magic mushrooms because they can cause hallucinations. As with any drug, their effect ends after a certain amount of time. Most ""magic mushrooms"" last for 4 to 6 hours. Because of their mind-altering effects they are illegal in many countries around the world. However, scientists are also researching ways to use ""magic mushrooms"" as medicine. In modern times, some fungi (for example, penicillin) have been used as a source of antibiotics. The antibiotics are produced by many fungi as a natural defence against bacteria.  Related pages  Mycorrhiza Mould Lichen Candida  References "
"A biomolecule or biological molecule is a loosely used term for molecules present in organisms that are essential to one or more typically biological processes, such as cell division, morphogenesis, or development. Biomolecules include large macromolecules (or polyelectrolytes) such as proteins, carbohydrates, lipids, and nucleic acids, as well as small molecules such as primary metabolites, secondary metabolites and natural products. A more general name for this class of material is biological materials. Biomolecules are an important element of living organisms, those biomolecules are often endogenous, produced within the organism but organisms usually need exogenous biomolecules, for example certain nutrients, to survive. Biology and its subfields of biochemistry and molecular biology study biomolecules and their reactions. Most biomolecules are organic compounds, and just four elements—oxygen, carbon, hydrogen, and nitrogen—make up 96% of the human body's mass. But many other elements, such as the various biometals, are also present in small amounts. The uniformity of both specific types of molecules (the biomolecules) and of certain metabolic pathways are invariant features among the wide diversity of life forms; thus these biomolecules and metabolic pathways are referred to as ""biochemical universals"" or ""theory of material unity of the living beings"", a unifying concept in biology, along with cell theory and evolution theory.  Types of biomolecules  A diverse range of biomolecules exist, including: Small molecules: Lipids, fatty acids, glycolipids, sterols, monosaccharides Vitamins Hormones, neurotransmitters Metabolites Monomers, oligomers and polymers:  Nucleosides and nucleotides  Nucleosides are molecules formed by attaching a nucleobase to a ribose or deoxyribose ring. Examples of these include cytidine (C), uridine (U), adenosine (A), guanosine (G), and thymidine (T). Nucleosides can be phosphorylated by specific kinases in the cell, producing nucleotides. Both DNA and RNA are polymers, consisting of long, linear molecules assembled by polymerase enzymes from repeating structural units, or monomers, of mononucleotides. DNA uses the deoxynucleotides C, G, A, and T, while RNA uses the ribonucleotides (which have an extra hydroxyl(OH) group on the pentose ring) C, G, A, and U. Modified bases are fairly common (such as with methyl groups on the base ring), as found in ribosomal RNA or transfer RNAs or for discriminating the new from old strands of DNA after replication.Each nucleotide is made of an acyclic nitrogenous base, a pentose and one to three phosphate groups. They contain carbon, nitrogen, oxygen, hydrogen and phosphorus. They serve as sources of chemical energy (adenosine triphosphate and guanosine triphosphate), participate in cellular signaling (cyclic guanosine monophosphate and cyclic adenosine monophosphate), and are incorporated into important cofactors of enzymatic reactions (coenzyme A, flavin adenine dinucleotide, flavin mononucleotide, and nicotinamide adenine dinucleotide phosphate).  DNA and RNA structure  DNA structure is dominated by the well-known double helix formed by Watson-Crick base-pairing of C with G and A with T. This is known as B-form DNA, and is overwhelmingly the most favorable and common state of DNA; its highly specific and stable base-pairing is the basis of reliable genetic information storage. DNA can sometimes occur as single strands (often needing to be stabilized by single-strand binding proteins) or as A-form or Z-form helices, and occasionally in more complex 3D structures such as the crossover at Holliday junctions during DNA replication. RNA, in contrast, forms large and complex 3D tertiary structures reminiscent of proteins, as well as the loose single strands with locally folded regions that constitute messenger RNA molecules. Those RNA structures contain many stretches of A-form double helix, connected into definite 3D arrangements by single-stranded loops, bulges, and junctions. Examples are tRNA, ribosomes, ribozymes, and riboswitches. These complex structures are facilitated by the fact that RNA backbone has less local flexibility than DNA but a large set of distinct conformations, apparently because of both positive and negative interactions of the extra OH on the ribose. Structured RNA molecules can do highly specific binding of other molecules and can themselves be recognized specifically; in addition, they can perform enzymatic catalysis (when they are known as ""ribozymes"", as initially discovered by Tom Cech and colleagues).  Saccharides  Monosaccharides are the simplest form of carbohydrates with only one simple sugar. They essentially contain an aldehyde or ketone group in their structure. The presence of an aldehyde group in a monosaccharide is indicated by the prefix aldo-. Similarly, a ketone group is denoted by the prefix keto-. Examples of monosaccharides are the hexoses, glucose, fructose, Trioses, Tetroses, Heptoses, galactose, pentoses, ribose, and deoxyribose. Consumed fructose and glucose have different rates of gastric emptying, are differentially absorbed and have different metabolic fates, providing multiple opportunities for two different saccharides to differentially affect food intake. Most saccharides eventually provide fuel for cellular respiration. Disaccharides are formed when two monosaccharides, or two single simple sugars, form a bond with removal of water. They can be hydrolyzed to yield their saccharin building blocks by boiling with dilute acid or reacting them with appropriate enzymes. Examples of disaccharides include sucrose, maltose, and lactose. Polysaccharides are polymerized monosaccharides, or complex carbohydrates. They have multiple simple sugars. Examples are starch, cellulose, and glycogen. They are generally large and often have a complex branched connectivity. Because of their size, polysaccharides are not water-soluble, but their many hydroxy groups become hydrated individually when exposed to water, and some polysaccharides form thick colloidal dispersions when heated in water. Shorter polysaccharides, with 3 to 10 monomers, are called oligosaccharides. A fluorescent indicator-displacement molecular imprinting sensor was developed for discriminating saccharides. It successfully discriminated three brands of orange juice beverage. The change in fluorescence intensity of the sensing films resulting is directly related to the saccharide concentration.  Lignin  Lignin is a complex polyphenolic macromolecule composed mainly of beta-O4-aryl linkages. After cellulose, lignin is the second most abundant biopolymer and is one of the primary structural components of most plants. It contains subunits derived from p-coumaryl alcohol, coniferyl alcohol, and sinapyl alcohol and is unusual among biomolecules in that it is racemic. The lack of optical activity is due to the polymerization of lignin which occurs via free radical coupling reactions in which there is no preference for either configuration at a chiral center.  Lipid  Lipids (oleaginous) are chiefly fatty acid esters, and are the basic building blocks of biological membranes. Another biological role is energy storage (e.g., triglycerides). Most lipids consist of a polar or hydrophilic head (typically glycerol) and one to three non polar or hydrophobic fatty acid tails, and therefore they are amphiphilic. Fatty acids consist of unbranched chains of carbon atoms that are connected by single bonds alone (saturated fatty acids) or by both single and double bonds (unsaturated fatty acids). The chains are usually 14-24 carbon groups long, but it is always an even number. For lipids present in biological membranes, the hydrophilic head is from one of three classes: Glycolipids, whose heads contain an oligosaccharide with 1-15 saccharide residues. Phospholipids, whose heads contain a positively charged group that is linked to the tail by a negatively charged phosphate group. Sterols, whose heads contain a planar steroid ring, for example, cholesterol.Other lipids include prostaglandins and leukotrienes which are both 20-carbon fatty acyl units synthesized from arachidonic acid. They are also known as fatty acids  Amino acids  Amino acids contain both amino and carboxylic acid functional groups. (In biochemistry, the term amino acid is used when referring to those amino acids in which the amino and carboxylate functionalities are attached to the same carbon, plus proline which is not actually an amino acid). Modified amino acids are sometimes observed in proteins; this is usually the result of enzymatic modification after translation (protein synthesis). For example, phosphorylation of serine by kinases and dephosphorylation by phosphatases is an important control mechanism in the cell cycle. Only two amino acids other than the standard twenty are known to be incorporated into proteins during translation, in certain organisms: Selenocysteine is incorporated into some proteins at a UGA codon, which is normally a stop codon. Pyrrolysine is incorporated into some proteins at a UAG codon. For instance, in some methanogens in enzymes that are used to produce methane.Besides those used in protein synthesis, other biologically important amino acids include carnitine (used in lipid transport within a cell), ornithine, GABA and taurine.  Protein structure  The particular series of amino acids that form a protein is known as that protein's primary structure. This sequence is determined by the genetic makeup of the individual. It specifies the order of side-chain groups along the linear polypeptide ""backbone"". Proteins have two types of well-classified, frequently occurring elements of local structure defined by a particular pattern of hydrogen bonds along the backbone: alpha helix and beta sheet. Their number and arrangement is called the secondary structure of the protein. Alpha helices are regular spirals stabilized by hydrogen bonds between the backbone CO group (carbonyl) of one amino acid residue and the backbone NH group (amide) of the i+4 residue. The spiral has about 3.6 amino acids per turn, and the amino acid side chains stick out from the cylinder of the helix. Beta pleated sheets are formed by backbone hydrogen bonds between individual beta strands each of which is in an ""extended"", or fully stretched-out, conformation. The strands may lie parallel or antiparallel to each other, and the side-chain direction alternates above and below the sheet. Hemoglobin contains only helices, natural silk is formed of beta pleated sheets, and many enzymes have a pattern of alternating helices and beta-strands. The secondary-structure elements are connected by ""loop"" or ""coil"" regions of non-repetitive conformation, which are sometimes quite mobile or disordered but usually adopt a well-defined, stable arrangement.The overall, compact, 3D structure of a protein is termed its tertiary structure or its ""fold"". It is formed as result of various attractive forces like hydrogen bonding, disulfide bridges, hydrophobic interactions, hydrophilic interactions, van der Waals force etc. When two or more polypeptide chains (either of identical or of different sequence) cluster to form a protein, quaternary structure of protein is formed. Quaternary structure is an attribute of polymeric (same-sequence chains) or heteromeric (different-sequence chains) proteins like hemoglobin, which consists of two ""alpha"" and two ""beta"" polypeptide chains.  Apoenzymes  An apoenzyme (or, generally, an apoprotein) is the protein without any small-molecule cofactors, substrates, or inhibitors bound. It is often important as an inactive storage, transport, or secretory form of a protein. This is required, for instance, to protect the secretory cell from the activity of that protein. Apoenzymes become active enzymes on addition of a cofactor. Cofactors can be either inorganic (e.g., metal ions and iron-sulfur clusters) or organic compounds, (e.g., [Flavin group|flavin] and heme). Organic cofactors can be either prosthetic groups, which are tightly bound to an enzyme, or coenzymes, which are released from the enzyme's active site during the reaction.  Isoenzymes  Isoenzymes, or isozymes, are multiple forms of an enzyme, with slightly different protein sequence and closely similar but usually not identical functions. They are either products of different genes, or else different products of alternative splicing. They may either be produced in different organs or cell types to perform the same function, or several isoenzymes may be produced in the same cell type under differential regulation to suit the needs of changing development or environment. LDH (lactate dehydrogenase) has multiple isozymes, while fetal hemoglobin is an example of a developmentally regulated isoform of a non-enzymatic protein. The relative levels of isoenzymes in blood can be used to diagnose problems in the organ of secretion .  See also  Biomolecular engineering List of biomolecules Metabolism Multi-state modeling of biomolecules  References   External links  Society for Biomolecular Sciences provider of a forum for education and information exchange among professionals within drug discovery and related disciplines.","A biomolecule is any molecule produced by a living organism. That includes large macromolecules such as proteins, polysaccharides, lipids, and nucleic acids, as well as many smaller molecules. Biomolecules are used in biological processes such as cell division, morphogenesis, or development.Just four elements—oxygen, carbon, hydrogen, and nitrogen—make up 96% of the human body's mass. But many other elements, such as the various biometals, are also present in small (but vital) amounts.Biometals are at the heart of many biomolecules. One or two molecules of copper, zinc, iron or manganese are in the most important biological molecules. They act as cofactors, electron donors, at the heart of key biological molecules.  Types of biomolecules  A huge range of biomolecules exist, including: Small molecules: Lipids, polysaccharides, glycolipids, sterols, glycerolipids Vitamins Hormones, neurotransmitters Metabolites Monomers, oligomers and polymers:  References "
"Non-steroidal anti-inflammatory drugs (NSAID) are members of a therapeutic drug class which reduces pain, decreases inflammation, decreases fever, and prevents blood clots. Side effects depend on the specific drug, its dose and duration of use, but largely include an increased risk of gastrointestinal ulcers and bleeds, heart attack, and kidney disease.The term non-steroidal, common from around 1960, distinguishes these drugs from corticosteroids, which during the 1950s had acquired a bad reputation due to overuse and side-effect problems after their initial introduction in 1948.NSAIDs work by inhibiting the activity of cyclooxygenase enzymes (the COX-1 and COX-2 isoenzymes). In cells, these enzymes are involved in the synthesis of key biological mediators, namely prostaglandins, which are involved in inflammation, and thromboxanes, which are involved in blood clotting. There are two general types of NSAIDs available: non-selective, and COX-2 selective. Most NSAIDs are non-selective, and inhibit the activity of both COX-1 and COX-2. These NSAIDs, while reducing inflammation, also inhibit platelet aggregation and increase the risk of gastrointestinal ulcers and bleeds. COX-2 selective inhibitors have fewer gastrointestinal side effects, but promote thrombosis, and some of these agents substantially increase the risk of heart attack. As a result, certain older COX-2 selective inhibitors - such as celecoxib and rofecoxib - are no longer used due to the high risk of undiagnosed vascular disease. These differential effects are due to the different roles and tissue localisations of each COX isoenzyme. By inhibiting physiological COX activity, all NSAIDs increase the risk of kidney disease and, through a related mechanism, heart attack. In addition, NSAIDs can blunt the production of erythropoietin, resulting in anaemia, since haemoglobin needs this hormone to be produced. The most prominent NSAIDs are aspirin, ibuprofen, and naproxen; all available over the counter (OTC) in most countries. Paracetamol (acetaminophen) is generally not considered an NSAID because it has only minor anti-inflammatory activity. Paracetamol treats pain mainly by blocking COX-2 and inhibiting endocannabinoid reuptake almost exclusively within the brain, and only minimally in the rest of the body.  Medical uses  NSAIDs are often suggested for the treatment of acute or chronic conditions where pain and inflammation are present. NSAIDs are generally used for the symptomatic relief of the following conditions:  Chronic pain and cancer-related pain  The effectiveness of NSAIDs for treating non-cancer chronic pain and cancer-related pain in children and adolescents is not clear. There have not been sufficient numbers of high-quality randomised controlled trials conducted.  Inflammation  Differences in anti-inflammatory activity between the various individual NSAIDs are small, but there is considerable variation in individual patient response, and tolerance to these drugs. About 60% of patients will respond to any NSAID; of the others, those who do not respond to one may well respond to another. Pain relief starts soon after taking the first dose, and a full analgesic effect should normally be obtained within a week, whereas an anti-inflammatory effect may not be achieved (or may not be clinically assessable) for up to three weeks. If appropriate responses are not obtained within these times, another NSAID should be tried.  Surgical pain  Pain following surgery can be significant, and many people require strong pain medications such as opioids. There is some low-certainty evidence that starting NSAID painkiller medications in adults early, before surgery, may help reduce post-operative pain, and also reduce the dose or quantity of opioid medications required after surgery. Any increase risk of surgical bleeding, bleeding in the gastrointestinal system, myocardial infarctions, or injury to the kidneys has not been well studied. When used in combination with paracetamol, the analgesic effect on post-operative pain may be improved.  Aspirin  Aspirin, the only NSAID able to irreversibly inhibit COX-1, is also indicated for antithrombosis through inhibition of platelet aggregation. This is useful for the management of arterial thrombosis, and prevention of adverse cardiovascular events like heart attacks. Aspirin inhibits platelet aggregation by inhibiting the action of thromboxane A2.  Dentistry  NSAIDs are useful in the management of post-operative dental pain following invasive dental procedures such as dental extraction. When not contra-indicated, they are favoured over the use of paracetamol alone due to the anti-inflammatory effect they provide. There is weak evidence suggesting that taking pre-operative analgesia can reduce the length of post operative pain associated with placing orthodontic spacers under local anaesthetic.  Contraindications  NSAIDs may be used with caution by people with the following conditions: Persons who are over age 50, and who have a family history of gastrointestinal (GI) problems Persons who have had previous gastrointestinal problems from NSAID useNSAIDs should usually be avoided by people with the following conditions:  Adverse effects  The widespread use of NSAIDs has meant that the adverse effects of these drugs have become increasingly common. Use of NSAIDs increases risk of a range of gastrointestinal (GI) problems, kidney disease and adverse cardiovascular events. As commonly used for post-operative pain, there is evidence of increased risk of kidney complications. Their use following gastrointestinal surgery remains controversial, given mixed evidence of increased risk of leakage from any bowel anastomosis created.An estimated 10–20% of people taking NSAIDs experience indigestion. In the 1990s high doses of prescription NSAIDs were associated with serious upper gastrointestinal adverse events, including bleeding.NSAIDs, like all medications, may interact with other medications. For example, concurrent use of NSAIDs and quinolone antibiotics may increase the risk of quinolones' adverse central nervous system effects, including seizure.There is an argument over the benefits and risks of NSAIDs for treating chronic musculoskeletal pain. Each drug has a benefit-risk profile and balancing the risk of no treatment with the competing potential risks of various therapies should be considered. For people over the age of 65 years old, the balance between the benefits of pain-relief medications such as NSAIDS and the potential for adverse effects has not been well determined.There is some evidence suggesting that, for some people, use of NSAIDS (or other anti-inflammatories) may contribute to the initiation of chronic pain.In October 2020, the U.S. Food and Drug Administration (FDA) required the drug label to be updated for all nonsteroidal anti-inflammatory medications to describe the risk of kidney problems in unborn babies that result in low amniotic fluid. They are recommending avoiding NSAIDs in pregnant women at 20 weeks or later in pregnancy.  Combinational risk  If a COX-2 inhibitor is taken, a traditional NSAID (prescription or over-the-counter) should not be taken at the same time.Rofecoxib (Vioxx) was shown to produce significantly fewer gastrointestinal adverse drug reactions (ADRs) compared with naproxen. The study, the VIGOR trial, raised the issue of the cardiovascular safety of the coxibs (COX-2 inhibitors). A statistically significant increase in the incidence of myocardial infarctions was observed in patients on rofecoxib. Further data, from the APPROVe trial, showed a statistically significant relative risk of cardiovascular events of 1.97 versus placebo—which caused a worldwide withdrawal of rofecoxib in October 2004.Use of methotrexate together with NSAIDs in rheumatoid arthritis is safe, if adequate monitoring is done.  Cardiovascular  NSAIDs, aside from aspirin, increase the risk of myocardial infarction and stroke. This occurs at least within a week of use. They are not recommended in those who have had a previous heart attack as they increase the risk of death or recurrent MI. Evidence indicates that naproxen may be the least harmful out of these.NSAIDs aside from (low-dose) aspirin are associated with a doubled risk of heart failure in people without a history of cardiac disease. In people with such a history, use of NSAIDs (aside from low-dose aspirin) was associated with a more than 10-fold increase in heart failure. If this link is proven causal, researchers estimate that NSAIDs would be responsible for up to 20 percent of hospital admissions for congestive heart failure. In people with heart failure, NSAIDs increase mortality risk (hazard ratio) by approximately 1.2–1.3 for naproxen and ibuprofen, 1.7 for rofecoxib and celecoxib, and 2.1 for diclofenac.On 9 July 2015, the Food and Drug Administration (FDA) toughened warnings of increased heart attack and stroke risk associated with nonsteroidal anti-inflammatory drugs (NSAIDs) other than aspirin.  Possible erectile dysfunction risk  A 2005 Finnish survey study found an association between long term (over 3 months) use of NSAIDs and erectile dysfunction.A 2011 publication in The Journal of Urology received widespread publicity. According to the study, men who used NSAIDs regularly were at significantly increased risk of erectile dysfunction. A link between NSAID use and erectile dysfunction still existed after controlling for several conditions. However, the study was observational and not controlled, with low original participation rate, potential participation bias, and other uncontrolled factors. The authors warned against drawing any conclusion regarding cause.  Gastrointestinal  The main adverse drug reactions (ADRs) associated with NSAID use relate to direct and indirect irritation of the gastrointestinal (GI) tract. NSAIDs cause a dual assault on the GI tract: the acidic molecules directly irritate the gastric mucosa, and inhibition of COX-1 and COX-2 reduces the levels of protective prostaglandins. Inhibition of prostaglandin synthesis in the GI tract causes increased gastric acid secretion, diminished bicarbonate secretion, diminished mucus secretion and diminished trophic effects on the epithelial mucosa.Common gastrointestinal side effects include: Nausea or vomiting Indigestion Gastric ulceration or bleeding DiarrheaClinical NSAID ulcers are related to the systemic effects of NSAID administration. Such damage occurs irrespective of the route of administration of the NSAID (e.g., oral, rectal, or parenteral) and can occur even in people who have achlorhydria.Ulceration risk increases with therapy duration, and with higher doses. To minimize GI side effects, it is prudent to use the lowest effective dose for the shortest period of time—a practice that studies show is often not followed. Over 50% of patients who take NSAIDs have sustained some mucosal damage to their small intestine.The risk and rate of gastric adverse effects is different depending on the type of NSAID medication a person is taking. Indomethacin, ketoprofen, and piroxicam use appear to lead to the highest rate of gastric adverse effects, while ibuprofen (lower doses) and diclofenac appear to have lower rates.Certain NSAIDs, such as aspirin, have been marketed in enteric-coated formulations that manufacturers claim reduce the incidence of gastrointestinal ADRs. Similarly, some believe that rectal formulations may reduce gastrointestinal ADRs. However, consistent with the systemic mechanism of such ADRs, and in clinical practice, these formulations have not demonstrated a reduced risk of GI ulceration.Numerous ""gastro-protective"" drugs have been developed with the goal of preventing gastrointestinal toxicity in people who need to take NSAIDs on a regular basis. Gastric adverse effects may be reduced by taking medications that suppress acid production such as proton pump inhibitors (e.g.: omeprazole and esomeprazole), or by treatment with a drug that mimics prostaglandin in order to restore the lining of the GI tract (e.g.: a prostaglandin analog misoprostol). Diarrhea is a common side effect of misoprostol, however, higher doses of misoprostol have been shown to reduce the risk of a person having a complication related to a gastric ulcer while taking NSAIDs. While these techniques may be effective, they are expensive for maintenance therapy.Hydrogen sulfide NSAID hybrids prevent the gastric ulceration/bleeding associated with taking the NSAIDs alone. Hydrogen sulfide is known to have a protective effect on the cardiovascular and gastrointestinal system.  Inflammatory bowel disease  NSAIDs should be used with caution in individuals with inflammatory bowel disease (e.g., Crohn's disease or ulcerative colitis) due to their tendency to cause gastric bleeding and form ulceration in the gastric lining.  Renal  NSAIDs are also associated with a fairly high incidence of adverse drug reactions (ADRs) on the kidney and over time can lead to chronic kidney disease. The mechanism of these kidney ADRs is due to changes in kidney blood flow. Prostaglandins normally dilate the afferent arterioles of the glomeruli. This helps maintain normal glomerular perfusion and glomerular filtration rate (GFR), an indicator of kidney function. This is particularly important in kidney failure where the kidney is trying to maintain renal perfusion pressure by elevated angiotensin II levels. At these elevated levels, angiotensin II also constricts the afferent arteriole into the glomerulus in addition to the efferent arteriole it normally constricts. Since NSAIDs block this prostaglandin-mediated effect of afferent arteriole dilation, particularly in kidney failure, NSAIDs cause unopposed constriction of the afferent arteriole and decreased RPF (renal perfusion flow) and GFR.Common ADRs associated with altered kidney function include: Sodium and fluid retention Hypertension (high blood pressure)These agents may also cause kidney impairment, especially in combination with other nephrotoxic agents. Kidney failure is especially a risk if the patient is also concomitantly taking an ACE inhibitor (which removes angiotensin II's vasoconstriction of the efferent arteriole) and a diuretic (which drops plasma volume, and thereby RPF)—the so-called ""triple whammy"" effect.In rarer instances NSAIDs may also cause more severe kidney conditions: Interstitial nephritis Nephrotic syndrome Acute kidney injury Acute tubular necrosis Renal papillary necrosisNSAIDs in combination with excessive use of phenacetin or paracetamol (acetaminophen) may lead to analgesic nephropathy.  Photosensitivity  Photosensitivity is a commonly overlooked adverse effect of many of the NSAIDs. The 2-arylpropionic acids are the most likely to produce photosensitivity reactions, but other NSAIDs have also been implicated including piroxicam, diclofenac, and benzydamine.Benoxaprofen, since withdrawn due to its liver toxicity, was the most photoactive NSAID observed. The mechanism of photosensitivity, responsible for the high photoactivity of the 2-arylpropionic acids, is the ready decarboxylation of the carboxylic acid moiety. The specific absorbance characteristics of the different chromophoric 2-aryl substituents, affects the decarboxylation mechanism.  During pregnancy  While NSAIDs as a class are not direct teratogens, use of NSAIDs in late pregnancy can cause premature closure of the fetal ductus arteriosus and kidney ADRs in the fetus. Thus, NSAIDs are not recommended during the third trimester of pregnancy because of the increased risk of premature constriction of the ductus arteriosus. Additionally, they are linked with premature birth and miscarriage. Aspirin, however, is used together with heparin in pregnant women with antiphospholipid syndrome. Additionally, indomethacin can be used in pregnancy to treat polyhydramnios by reducing fetal urine production via inhibiting fetal renal blood flow.In contrast, paracetamol (acetaminophen) is regarded as being safe and well tolerated during pregnancy, but Leffers et al. released a study in 2010, indicating that there may be associated male infertility in the unborn. Doses should be taken as prescribed, due to risk of liver toxicity with overdoses.In France, the country's health agency contraindicates the use of NSAIDs, including aspirin, after the sixth month of pregnancy.In October 2020, the U.S. Food and Drug Administration (FDA) required the drug label to be updated for all nonsteroidal anti-inflammatory medications to describe the risk of kidney problems in unborn babies that result in low amniotic fluid. They are recommending avoiding NSAIDs in pregnant women at 20 weeks or later in pregnancy.  Allergy and allergy-like hypersensitivity reactions  A variety of allergic or allergic-like NSAID hypersensitivity reactions follow the ingestion of NSAIDs. These hypersensitivity reactions differ from the other adverse reactions listed here which are toxicity reactions, i.e. unwanted reactions that result from the pharmacological action of a drug, are dose-related, and can occur in any treated individual; hypersensitivity reactions are idiosyncratic reactions to a drug. Some NSAID hypersensitivity reactions are truly allergic in origin: 1) repetitive IgE-mediated urticarial skin eruptions, angioedema, and anaphylaxis following immediately to hours after ingesting one structural type of NSAID but not after ingesting structurally unrelated NSAIDs; and 2) Comparatively mild to moderately severe T cell-mediated delayed onset (usually more than 24 hour), skin reactions such as maculopapular rash, fixed drug eruptions, photosensitivity reactions, delayed urticaria, and contact dermatitis; or 3) far more severe and potentially life-threatening t-cell-mediated delayed systemic reactions such as the DRESS syndrome, acute generalized exanthematous pustulosis, the Stevens–Johnson syndrome, and toxic epidermal necrolysis. Other NSAID hypersensitivity reactions are allergy-like symptoms but do not involve true allergic mechanisms; rather, they appear due to the ability of NSAIDs to alter the metabolism of arachidonic acid in favor of forming metabolites that promote allergic symptoms. Affected individuals may be abnormally sensitive to these provocative metabolites or overproduce them and typically are susceptible to a wide range of structurally dissimilar NSAIDs, particularly those that inhibit COX1. Symptoms, which develop immediately to hours after ingesting any of various NSAIDs that inhibit COX-1, are: 1) exacerbations of asthmatic and rhinitis (see aspirin-exacerbated respiratory disease) symptoms in individuals with a history of asthma or rhinitis and 2) exacerbation or first-time development of wheals or angioedema in individuals with or without a history of chronic urticarial lesions or angioedema.  Possible effects on bone and soft tissue healing  It has been hypothesized that NSAIDs may delay healing from bone and soft-tissue injuries by inhibiting inflammation. On the other hand, it has also been hypothesized that NSAIDs might speed recovery from soft tissue injuries by preventing inflammatory processes from damaging adjacent, non-injured muscles.There is moderate evidence that they delay bone healing. Their overall effect on soft-tissue healing is unclear.  Ototoxicity  Long-term use of NSAID analgesics and paracetamol is associated with an increased risk of hearing loss.  Other  The use of NSAIDs for analgesia following gastrointestinal surgery remains controversial, given mixed evidence of an increased risk of leakage from any bowel anastomosis created. This risk may vary according to the class of NSAID prescribed.Common adverse drug reactions (ADR), other than listed above, include: raised liver enzymes, headache, dizziness. Uncommon ADRs include an abnormally high level of potassium in the blood, confusion, spasm of the airways, and rash. Ibuprofen may also rarely cause irritable bowel syndrome symptoms. NSAIDs are also implicated in some cases of Stevens–Johnson syndrome.Most NSAIDs penetrate poorly into the central nervous system (CNS). However, the COX enzymes are expressed constitutively in some areas of the CNS, meaning that even limited penetration may cause adverse effects such as somnolence and dizziness.NSAIDs may increase the risk of bleeding in patients with Dengue fever For this reason, NSAIDs are only available with a prescription in India.In very rare cases, ibuprofen can cause aseptic meningitis.As with other drugs, allergies to NSAIDs might exist. While many allergies are specific to one NSAID, up to 1 in 5 people may have unpredictable cross-reactive allergic responses to other NSAIDs as well.  Drug interactions  NSAIDs reduce kidney blood flow and thereby decrease the efficacy of diuretics, and inhibit the elimination of lithium and methotrexate.NSAIDs cause decreased ability to form blood clots, which can increase the risk of bleeding when combined with other drugs that also decrease blood clotting, such as warfarin.NSAIDs may aggravate hypertension (high blood pressure) and thereby antagonize the effect of antihypertensives, such as ACE inhibitors.NSAIDs may interfere and reduce effectiveness of SSRI antidepressants. NSAIDs, when used in combination with SSRIs, increases the risk of adverse gastrointestinal effects. NSAIDs, when used in combination with SSRIs, increases the risk of internal bleeding and brain hemorrhages.Various widely used nonsteroidal anti-inflammatory drugs (NSAIDs) enhance endocannabinoid signaling by blocking the anandamide-degrading membrane enzyme fatty acid amide hydrolase (FAAH).NSAIDs may reduce the effectiveness of antibiotics. Tests on cultured bacteria found that antibiotic effectiveness was reduced by 18-30% on average compared to tests which did not include NSAIDs.  Immune response  Although small doses generally have little to no effect on the immune system, large doses of NSAIDs significantly suppress the production of immune cells. As NSAIDs affect prostaglandins, they affect the production of most fast growing cells. This includes immune cells. Unlike corticosteroids, they do not directly suppress the immune system and so their effect on the immune system is not immediately obvious. They suppress the production of new immune cells, but leave existing immune cells functional. Large doses slowly reduce the immune response as the immune cells are renewed at a much lower rate. Causing a gradual reduction of the immune system, much slower and less noticeable than the immediate effect of Corticosteroids. The effect significantly increases with dosage, in a nearly exponential rate. Doubling of dose reduced cells by nearly four times. Increasing dose by five times reduced cell counts to only a few percent of normal levels. This is likely why the effect was not immediately obvious in low dose trials, as the effect is not apparent until much higher dosages are tested.  Mechanism of action  Most NSAIDs act as nonselective inhibitors of the cyclooxygenase (COX) enzymes, inhibiting both the cyclooxygenase-1 (COX-1) and cyclooxygenase-2 (COX-2) isoenzymes. This inhibition is competitively reversible (albeit at varying degrees of reversibility), as opposed to the mechanism of aspirin, which is irreversible inhibition. COX catalyzes the formation of prostaglandins and thromboxane from arachidonic acid (itself derived from the cellular phospholipid bilayer by phospholipase A2). Prostaglandins act (among other things) as messenger molecules in the process of inflammation. This mechanism of action was elucidated in 1970 by John Vane (1927–2004), who received a Nobel Prize for his work (see Mechanism of action of aspirin).COX-1 is a constitutively expressed enzyme with a ""house-keeping"" role in regulating many normal physiological processes. One of these is in the stomach lining, where prostaglandins serve a protective role, preventing the stomach mucosa from being eroded by its own acid. COX-2 is an enzyme facultatively expressed in inflammation, and it is inhibition of COX-2 that produces the desirable effects of NSAIDs.When nonselective COX-1/COX-2 inhibitors (such as aspirin, ibuprofen, and naproxen) lower stomach prostaglandin levels, ulcers of the stomach or duodenum and internal bleeding can result. The discovery of COX-2 led to research to the development of selective COX-2 inhibiting drugs that do not cause gastric problems characteristic of older NSAIDs.NSAIDs have been studied in various assays to understand how they affect each of these enzymes. While the assays reveal differences, unfortunately, different assays provide differing ratios.Paracetamol (acetaminophen) is not considered an NSAID because it has little anti-inflammatory activity. It treats pain mainly by blocking COX-2 mostly in the central nervous system, but not much in the rest of the body.However, many aspects of the mechanism of action of NSAIDs remain unexplained, and for this reason, further COX pathways are hypothesized. The COX-3 pathway was believed to fill some of this gap but recent findings make it appear unlikely that it plays any significant role in humans and alternative explanation models are proposed.NSAIDs interact with the endocannabinoid system and its endocannabinoids, as COX2 have been shown to utilize endocannabinoids as substrates, and may have a key role in both the therapeutic effects and adverse effects of NSAIDs, as well as in NSAID-induced placebo responses.NSAIDs are also used in the acute pain caused by gout because they inhibit urate crystal phagocytosis besides inhibition of prostaglandin synthase.  Antipyretic activity  NSAIDs have antipyretic activity and can be used to treat fever. Fever is caused by elevated levels of prostaglandin E2, which alters the firing rate of neurons within the hypothalamus that control thermoregulation. Antipyretics work by inhibiting the enzyme COX, which causes the general inhibition of prostanoid biosynthesis (PGE2) within the hypothalamus. PGE2 signals to the hypothalamus to increase the body's thermal setpoint. Ibuprofen has been shown more effective as an antipyretic than paracetamol (acetaminophen).Arachidonic acid is the precursor substrate for cyclooxygenase leading to the production of prostaglandins F, D, and E.  Classification  NSAIDs can be classified based on their chemical structure or mechanism of action. Older NSAIDs were known long before their mechanism of action was elucidated and were for this reason classified by chemical structure or origin. Newer substances are more often classified by mechanism of action.  Salicylates   Propionic acid derivatives   Acetic acid derivatives   Enolic acid (Oxicam) derivatives   Anthranilic acid derivatives (Fenamates)  The following NSAIDs are derived from fenamic acid. which is a derivative of anthranilic acid,: 235 which in turn is a nitrogen isostere of salicylic acid, which is the active metabolite of aspirin.: 235 : 17  Selective COX-2 inhibitors (Coxibs)   Sulfonanilides  Nimesulide (systemic preparations are banned by several countries for the potential risk of hepatotoxicity)  Others  Clonixin Licofelone acts by inhibiting LOX (lipooxygenase) and COX and hence known as 5-LOX/COX inhibitor H-harpagide in figwort or devil's claw  Chirality  Most NSAIDs are chiral molecules; diclofenac is a notable exception. However, the majority are prepared as racemic mixtures. Typically, only a single enantiomer is pharmacologically active. For some drugs (typically profens), an isomerase enzyme in vivo converts the inactive enantiomer into the active form, although its activity varies widely in individuals. This phenomenon is likely responsible for the poor correlation between NSAID efficacy and plasma concentration observed in older studies when specific analysis of the active enantiomer was not performed.Ibuprofen and ketoprofen are now available in single-enantiomer preparations (dexibuprofen and dexketoprofen), which purport to offer quicker onset and an improved side-effect profile. Naproxen has always been marketed as the single active enantiomer.  Main practical differences  NSAIDs within a group tend to have similar characteristics and tolerability. There is little difference in clinical efficacy among the NSAIDs when used at equivalent doses. Rather, differences among compounds usually relate to dosing regimens (related to the compound's elimination half-life), route of administration, and tolerability profile.Regarding adverse effects, selective COX-2 inhibitors have lower risk of gastrointestinal bleeding. With the exception of naproxen, nonselective NSAIDs increase the risk of having a heart attack. Some data also supports that the partially selective nabumetone is less likely to cause gastrointestinal events.A consumer report noted that ibuprofen, naproxen, and salsalate are less expensive than other NSAIDs, and essentially as effective and safe when used appropriately to treat osteoarthritis and pain.  Pharmacokinetics  Most nonsteroidal anti-inflammatory drugs are weak acids, with a pKa of 3–5. They are absorbed well from the stomach and intestinal mucosa. They are highly protein-bound in plasma (typically >95%), usually to albumin, so that their volume of distribution typically approximates to plasma volume. Most NSAIDs are metabolized in the liver by oxidation and conjugation to inactive metabolites that typically are excreted in the urine, though some drugs are partially excreted in bile. Metabolism may be abnormal in certain disease states, and accumulation may occur even with normal dosage.Ibuprofen and diclofenac have short half-lives (2–3 hours). Some NSAIDs (typically oxicams) have very long half-lives (e.g. 20–60 hours).  History  It is widely believed that naturally occurring salicin in willow trees and other plants was used by the ancients as a form of analgesic or anti-inflammatory drug, but this story, although compelling, is not entirely true. Hippocrates does not mention willow at all. Dioscorides's De materia medica was arguably the most influential herbal from Roman to Medieval times but, if he mentions willow at all (there is doubt about the identity of 'Itea'), then he used the ashes, steeped in vinegar, as a treatment for corns, which corresponds well with modern uses of salicylic acid. However, there is still some truth in this claim. Willow bark (from trees of the salix genus) was widely known to be used as a medicine by multiple First Nations communities. The bark would be chewed or steeped in water for its pain relieving and antipyretic effects. The effects are a result of the bark's salicin content. Meadowsweet, another plant to contain salicin, has strong roots in British folk medicine for the same maladies. These effects were first recorded in Western science by Reverend Edward Stone, who accidentally tried willow bark in 1757. He then went on to give it to 50 patients, where he reported a decrease in fever and pain. In the body, salicin is turned into salicylic acid, which produces the antipyretic and analgesic effects that the plants are known for. Salicin was first isolated by Johann Andreas Buchner in 1827. By 1829, French chemist Henri Leroux had improved the extraction process to obtain about 30g of purified salicin from 1.5 kg of willow bark. By hydrolysis, salicin releases glucose and salicyl alcohol which can be converted into salicylic acid, both in vivo and through chemical methods. In 1869, Hermann Kolbe synthesised salicylate, although it was too acidic for the gastric mucosa. The reaction used to synthesise aromatic acid from a phenol in the presence of CO2 is known as the Kolbe-Schmitt reaction. By 1897 the German chemist Felix Hoffmann and the Bayer company prompted a new age of pharmacology by converting salicylic acid into acetylsalicylic acid—named aspirin by Heinrich Dreser. Other NSAIDs like ibuprofen were developed from the 1950s forward. In 2001, NSAIDs accounted for 70,000,000 prescriptions and 30 billion over-the-counter doses sold annually in the United States.  Research  While studies have been conducted to see if various NSAIDs can improve behavior in transgenic mouse models of Alzheimer's disease and observational studies in humans have shown promise, there is no good evidence from randomized clinical trials that NSAIDs can treat or prevent Alzheimer's in humans; clinical trials of NSAIDs for treatment of Alzheimer's have found more harm than benefit. NSAIDs coordinate with metal ions affecting cellular function.  Veterinary use  Research supports the use of NSAIDs for the control of pain associated with veterinary procedures such as dehorning and castration of calves. The best effect is obtained by combining a short-term local anesthetic such as lidocaine with an NSAID acting as a longer term analgesic. However, as different species have varying reactions to different medications in the NSAID family, little of the existing research data can be extrapolated to animal species other than those specifically studied, and the relevant government agency in one area sometimes prohibits uses approved in other jurisdictions.In the United States, meloxicam is approved for use only in canines, whereas (due to concerns about liver damage) it carries warnings against its use in cats except for one-time use during surgery. In spite of these warnings, meloxicam is frequently prescribed ""off-label"" for non-canine animals including cats and livestock species. In other countries, for example The European Union (EU), there is a label claim for use in cats.  See also  Discovery and development of cyclooxygenase 2 inhibitors  References   External links  Media related to Non-steroidal anti-inflammatory drugs at Wikimedia Commons","Non-steroidal anti-inflammatory drugs (often shortened to NSAIDs) are drugs that have analgesic or fever-reducing properties, but that are not based on steroids. Higher doses of such drugs can also be used to fight inflammation. Such drugs are special as they are not narcotic, that is they don't induce sleep. Well-known examples of such drugs are aspirin, diclofenac and ibuprofen."
"A drug is any chemical substance that causes a change in an organism's physiology or psychology when consumed. Drugs are typically distinguished from food and substances that provide nutritional support. Consumption of drugs can be via inhalation, injection, smoking, ingestion, absorption via a patch on the skin, suppository, or dissolution under the tongue. In pharmacology, a drug is a chemical substance, typically of known structure, which, when administered to a living organism, produces a biological effect. A pharmaceutical drug, also called a medication or medicine, is a chemical substance used to treat, cure, prevent, or diagnose a disease or to promote well-being. Traditionally drugs were obtained through extraction from medicinal plants, but more recently also by organic synthesis. Pharmaceutical drugs may be used for a limited duration, or on a regular basis for chronic disorders.Pharmaceutical drugs are often classified into drug classes—groups of related drugs that have similar chemical structures, the same mechanism of action (binding to the same biological target), a related mode of action, and that are used to treat the same disease. The Anatomical Therapeutic Chemical Classification System (ATC), the most widely used drug classification system, assigns drugs a unique ATC code, which is an alphanumeric code that assigns it to specific drug classes within the ATC system. Another major classification system is the Biopharmaceutics Classification System. This classifies drugs according to their solubility and permeability or absorption properties.Psychoactive drugs are substances that affect the function of the central nervous system, altering perception, mood or consciousness. These drugs are divided into different groups like: stimulants, depressants, antidepressants, anxiolytics, antipsychotics, and hallucinogens. These psychoactive drugs have been proven useful in treating wide range of medical conditions including mental disorders around the world. The most widely used drugs in the world include caffeine, nicotine and alcohol, which are also considered recreational drugs, since they are used for pleasure rather than medicinal purposes. All drugs can have potential side effects. Abuse of several psychoactive drugs can cause addiction and/or physical dependence. Excessive use of stimulants can promote stimulant psychosis. Many recreational drugs are illicit and international treaties such as the Single Convention on Narcotic Drugs exist for the purpose of their prohibition.  Etymology  In English, the noun ""drug"" is thought to originate from Old French ""drogue"", possibly deriving from ""droge (vate)"" from Middle Dutch meaning ""dry (barrels)"", referring to medicinal plants preserved as dry matter in barrels.In the 1990s however, Spanish lexicographer Federico Corriente Córdoba documented the possible origin of the word in {ḥṭr} an early romanized form of Al-Andalus language from Northwestern part of the Iberian peninsula. The term could approximately be transcribed as حطروكة or hatruka.  Medication  A medication or medicine is a drug taken to cure or ameliorate any symptoms of an illness or medical condition. The use may also be as preventive medicine that has future benefits but does not treat any existing or pre-existing diseases or symptoms. Dispensing of medication is often regulated by governments into three categories—over-the-counter medications, which are available in pharmacies and supermarkets without special restrictions; behind-the-counter medicines, which are dispensed by a pharmacist without needing a doctor's prescription, and prescription only medicines, which must be prescribed by a licensed medical professional, usually a physician.In the United Kingdom, behind-the-counter medicines are called pharmacy medicines which can only be sold in registered pharmacies, by or under the supervision of a pharmacist. These medications are designated by the letter P on the label. The range of medicines available without a prescription varies from country to country. Medications are typically produced by pharmaceutical companies and are often patented to give the developer exclusive rights to produce them. Those that are not patented (or with expired patents) are called generic drugs since they can be produced by other companies without restrictions or licenses from the patent holder.Pharmaceutical drugs are usually categorised into drug classes. A group of drugs will share a similar chemical structure, or have the same mechanism of action, the same related mode of action or target the same illness or related illnesses. The Anatomical Therapeutic Chemical Classification System (ATC), the most widely used drug classification system, assigns drugs a unique ATC code, which is an alphanumeric code that assigns it to specific drug classes within the ATC system. Another major classification system is the Biopharmaceutics Classification System. This groups drugs according to their solubility and permeability or absorption properties.  Spiritual and religious use  Some religions, particularly ethnic religions, are based completely on the use of certain drugs, known as entheogens, which are mostly hallucinogens,—psychedelics, dissociatives, or deliriants. Some drugs used as entheogens include kava which can act as a stimulant, a sedative, a euphoriant and an anesthetic. The roots of the kava plant are used to produce a drink which is consumed throughout the cultures of the Pacific Ocean. Some shamans from different cultures use entheogens, defined as ""generating the divine within"" to achieve religious ecstasy. Amazonian shamans use ayahuasca (yagé) a hallucinogenic brew for this purpose. Mazatec shamans have a long and continuous tradition of religious use of Salvia divinorum a psychoactive plant. Its use is to facilitate visionary states of consciousness during spiritual healing sessions.Silene undulata is regarded by the Xhosa people as a sacred plant and used as an entheogen. Its roots are traditionally used to induce vivid (and according to the Xhosa, prophetic) lucid dreams during the initiation process of shamans, classifying it a naturally occurring oneirogen similar to the more well-known dream herb Calea ternifolia.Peyote, a small spineless cactus, has been a major source of psychedelic mescaline and has probably been used by Native Americans for at least five thousand years. Most mescaline is now obtained from a few species of columnar cacti in particular from San Pedro and not from the vulnerable peyote.The entheogenic use of cannabis has also been widely practised for centuries. Rastafari use marijuana (ganja) as a sacrament in their religious ceremonies. Psychedelic mushrooms (psilocybin mushrooms), commonly called magic mushrooms or shrooms have also long been used as entheogens.  Smart drugs and designer drugs  Nootropics, also commonly referred to as ""smart drugs"", are drugs that are claimed to improve human cognitive abilities. Nootropics are used to improve memory, concentration, thought, mood, and learning. An increasingly used nootropic among students, also known as a study drug, is methylphenidate branded commonly as Ritalin and used for the treatment of attention deficit hyperactivity disorder (ADHD) and narcolepsy. At high doses methylphenidate can become highly addictive. Serious addiction can lead to psychosis, anxiety and heart problems, and the use of this drug is related to a rise in suicides, and overdoses. Evidence for use outside of student settings is limited but suggests that it is commonplace. Intravenous use of methylphenidate can lead to emphysematous damage to the lungs, known as Ritalin lung.Other drugs known as designer drugs are produced. An early example of what today would be labelled a 'designer drug' was LSD, which was synthesised from ergot. Other examples include analogs of performance-enhancing drugs such as designer steroids taken to improve physical capabilities and these are sometimes used (legally or not) for this purpose, often by professional athletes. Other designer drugs mimic the effects of psychoactive drugs. Since the late 1990s there has been the identification of many of these synthesised drugs. In Japan and the United Kingdom this has spurred the addition of many designer drugs into a newer class of controlled substances known as a temporary class drug. Synthetic cannabinoids have been produced for a longer period of time and are used in the designer drug synthetic cannabis.  Recreational drug use  Recreational drug use is the use of a drug (legal, controlled, or illegal) with the primary intention of altering the state of consciousness through alteration of the central nervous system in order to create positive emotions and feelings. The hallucinogen LSD is a psychoactive drug commonly used as a recreational drug.Ketamine is a drug used for anesthesia, and is also used as a recreational drug, both in powder and liquid form, for its hallucinogenic and dissociative effects.Some national laws prohibit the use of different recreational drugs; and medicinal drugs that have the potential for recreational use are often heavily regulated. However, there are many recreational drugs that are legal in many jurisdictions and widely culturally accepted. Cannabis is the most commonly consumed controlled recreational drug in the world (as of 2012). Its use in many countries is illegal but is legally used in several countries usually with the proviso that it can only be used for personal use. It can be used in the leaf form of marijuana (grass), or in the resin form of hashish. Marijuana is a more mild form of cannabis than hashish. There may be an age restriction on the consumption and purchase of legal recreational drugs. Some recreational drugs that are legal and accepted in many places include alcohol, tobacco, betel nut, and caffeine products, and in some areas of the world the legal use of drugs such as khat is common.There are a number of legal intoxicants commonly called legal highs that are used recreationally. The most widely used of these is alcohol.  Administration of drugs  All drugs, can be administered via a number of routes, and many can be administered by more than one.  Control of drugs  Numerous governmental offices in many countries deal with the control and supervision of drug manufacture and use, and the implementation of various drug laws. The Single Convention on Narcotic Drugs is an international treaty brought about in 1961 to prohibit the use of narcotics save for those used in medical research and treatment. In 1971, a second treaty the Convention on Psychotropic Substances had to be introduced to deal with newer recreational psychoactive and psychedelic drugs. The legal status of Salvia divinorum varies in many countries and even in states within the United States. Where it is legislated against the degree of prohibition also varies. The Food and Drug Administration (FDA) in the United States is a federal agency responsible for protecting and promoting public health through the regulation and supervision of food safety, tobacco products, dietary supplements, prescription and over-the-counter medications, vaccines, biopharmaceuticals, blood transfusions, medical devices, electromagnetic radiation emitting devices, cosmetics, animal foods and veterinary drugs. In India, the Narcotics Control Bureau (abbr. NCB), an Indian federal law enforcement and intelligence agency under the Ministry of Home Affairs, Government of India is tasked with combating drug trafficking and assisting international use of illegal substances under the provisions of Narcotic Drugs and Psychotropic Substances Act.  See also   Lists of drugs  List of drugs List of pharmaceutical companies List of psychoactive plants List of Schedule I drugs (US)  References   Further reading  Richard J. Miller (2014). Drugged: the science and culture behind psychotropic drugs. Oxford University Press. ISBN 978-0-19-995797-2.  External links  DrugBank, a database of 13,400 drugs and 5,100 protein drug targets ""Drugs"", BBC Radio 4 discussion with Richard Davenport-Hines, Sadie Plant and Mike Jay (In Our Time, May 23, 2002)","According to the WHO, a drug is a substance that can change how a living organism works. Food is usually not seen as a drug, even though some foods may have such properties. Most of the time drugs are taken to treat a disease, or other medical condition. An example for such drugs may be Aspirin or Paracetamol. These are usually given to treat fever, as well as certain infections. If such drugs are taken over a longer time, they are usually prescribed by a doctor. Other drugs are taken for fun, because of the effect they have. Some of these drugs taken for fun are better accepted by society than others. Having or taking certain drugs may be illegal, in certain countries. Drugs that are taken to treat a disease or condition are usually called ""therapeutic"", drugs that are taken for fun are called ""recreational"" drugs. Drugs may have other effects than those wanted. Such effects are generally known as side-effects. Drugs act differently in different amounts. It is therefore important to take the right amount. The amount of the drug taken is called a dose. Aspirin is often prescribed against fever, or as an analgesic. One of the side-effects of Aspirin is that it makes the blood thinner. For this reason, it can also be used to prevent strokes, or heart attacks - in a much lower dose than the one used to treat fever, though. Taking too much of a drug (""too high a dose"") can cause sickness or even death. When a doctor says how much of a drug (the right dose) to take, only that amount should be taken. It is very important to keep taking the drug until the doctor says to stop because someone can feel better but still be sick. When a doctor says what drug to take, how much of it, and for how long, it is called a prescription. Drugs may cause addiction. Some drugs are illegal because they are very addictive. These drugs are really expensive, too. It can also be sold illegally from drug sellers which may cause serious results  Recreational drugs  Recreational drugs can sometimes be bad for someone's health even if they make them feel good. Alcohol can also be dangerous if the person drinking it drives a vehicle after drinking. This is called drunk driving. Many countries make this against the law. Common recreational drugs include: Alcohol - In beer, wine and hard liquor Nicotine - In cigarettes Caffeine - In Coffee and cacao (See figure) Cannabis - Smoked like cigarettes, or baked in something to eat, like a cake or brownie Methamphetamine (also known as Crystal Meth) - Can be smoked, eaten, injected, or inhaled Cocaine - can be snorted, injected or inhaled (freebasing) Heroin - can be snorted, injected or smoked in its freebase form.Certain recreational drugs also have uses as a therapeutic drug. Heroin can be used as an analgesic (a painkiller) and methamphetamine is used to treat narcolepsy or ADHD. Recreational drugs can be dangerous, certain countries have made it illegal to have or take them outside a medical context. Most of the time, this is because they can be addictive or that they are very dangerous when combined with other drugs. That way, Cannabis-based products are legal in the Netherlands, but illegal in many other countries. Alcohol and Nicotine are legal almost everywhere, but there are a lot of taxes on the sale of these. In other words, they are expensive to buy. Being expensive to buy because of taxes has two benefits; one is that the taxes collected from the sale of the drugs goes into helping to pay for assistance the drug user may experience later. A smoker, for example, may develop cancer later in life and need treatment at a place that is granted a certain amount of tax money from the government to keep it operating. Another benefit to the taxing of ""legal"" drugs, is that the high price may stop people from beginning the habit in the first place, which will help them avoid the negative medical or addictive side effects of the drug. In some cases, not everyone is allowed to buy these drugs unless they are a minimal age to do so. The age at which someone is allowed to buy a legal drug is most often decided by the government of a country, state or province, and is usually the age where a person is considered by the law to be an ""adult"". Some of the most common ages this happens is at 18, 19 or 21 years of age.  Therapeutic drugs  Therapeutic drugs are also called medicinal drugs, medicine, or medication. Doctors will give therapeutic drugs to someone who is ill to make you better. You can buy these drugs at a pharmacy. Some drugs need a prescription to be bought, other drugs do not. Drugs that do not require a prescription are called ""over the counter"" medications. There are lots of these drugs for different illnesses. These include: Aspirin - For pain Paracetamol - For pain Penicillin - For infections Prozac - For depression Diazepam - For anxiety Antibiotics - For killing bacteria (germs)  References "
"A chemical substance is a form of matter having constant chemical composition and characteristic properties. Some references add that chemical substance cannot be separated into its constituent elements by physical separation methods, i.e., without breaking chemical bonds. Chemical substances can be simple substances (substances consisting of a single chemical element), chemical compounds, or alloys. Chemical substances are often called 'pure' to set them apart from mixtures. A common example of a chemical substance is pure water; it has the same properties and the same ratio of hydrogen to oxygen whether it is isolated from a river or made in a laboratory. Other chemical substances commonly encountered in pure form are diamond (carbon), gold, table salt (sodium chloride) and refined sugar (sucrose). However, in practice, no substance is entirely pure, and chemical purity is specified according to the intended use of the chemical. Chemical substances exist as solids, liquids, gases, or plasma, and may change between these phases of matter with changes in temperature or pressure and time. Chemical substances may be combined or converted to others by means of chemical reactions.  Definition  A chemical substance may well be defined as ""any material with a definite chemical composition"" in an introductory general chemistry textbook. According to this definition a chemical substance can either be a pure chemical element or a pure chemical compound. But, there are exceptions to this definition; a pure substance can also be defined as a form of matter that has both definite composition and distinct properties. The chemical substance index published by CAS also includes several alloys of uncertain composition. Non-stoichiometric compounds are a special case (in inorganic chemistry) that violates the law of constant composition, and for them, it is sometimes difficult to draw the line between a mixture and a compound, as in the case of palladium hydride. Broader definitions of chemicals or chemical substances can be found, for example: ""the term 'chemical substance' means any organic or inorganic substance of a particular molecular identity, including – (i) any combination of such substances occurring in whole or in part as a result of a chemical reaction or occurring in nature"".In geology, substances of uniform composition are called minerals, while physical mixtures (aggregates) of several minerals (different substances) are defined as rocks. Many minerals, however, mutually dissolve into solid solutions, such that a single rock is a uniform substance despite being a mixture in stoichiometric terms. Feldspars are a common example: anorthoclase is an alkali aluminum silicate, where the alkali metal is interchangeably either sodium or potassium. In law, ""chemical substances"" may include both pure substances and mixtures with a defined composition or manufacturing process. For example, the EU regulation REACH defines ""monoconstituent substances"", ""multiconstituent substances"" and ""substances of unknown or variable composition"". The latter two consist of multiple chemical substances; however, their identity can be established either by direct chemical analysis or reference to a single manufacturing process. For example, charcoal is an extremely complex, partially polymeric mixture that can be defined by its manufacturing process. Therefore, although the exact chemical identity is unknown, identification can be made with a sufficient accuracy. The CAS index also includes mixtures. Polymers almost always appear as mixtures of molecules of multiple molar masses, each of which could be considered a separate chemical substance. However, the polymer may be defined by a known precursor or reaction(s) and the molar mass distribution. For example, polyethylene is a mixture of very long chains of -CH2- repeating units, and is generally sold in several molar mass distributions, LDPE, MDPE, HDPE and UHMWPE.  History  The concept of a ""chemical substance"" became firmly established in the late eighteenth century after work by the chemist Joseph Proust on the composition of some pure chemical compounds such as basic copper carbonate. He deduced that, ""All samples of a compound have the same composition; that is, all samples have the same proportions, by mass, of the elements present in the compound."" This is now known as the law of constant composition. Later with the advancement of methods for chemical synthesis particularly in the realm of organic chemistry; the discovery of many more chemical elements and new techniques in the realm of analytical chemistry used for isolation and purification of elements and compounds from chemicals that led to the establishment of modern chemistry, the concept was defined as is found in most chemistry textbooks. However, there are some controversies regarding this definition mainly because the large number of chemical substances reported in chemistry literature need to be indexed. Isomerism caused much consternation to early researchers, since isomers have exactly the same composition, but differ in configuration (arrangement) of the atoms. For example, there was much speculation about the chemical identity of benzene, until the correct structure was described by Friedrich August Kekulé. Likewise, the idea of stereoisomerism – that atoms have rigid three-dimensional structure and can thus form isomers that differ only in their three-dimensional arrangement – was another crucial step in understanding the concept of distinct chemical substances. For example, tartaric acid has three distinct isomers, a pair of diastereomers with one diastereomer forming two enantiomers.  Chemical elements  An element is a chemical substance made up of a particular kind of atom and hence cannot be broken down or transformed by a chemical reaction into a different element, though it can be transmuted into another element through a nuclear reaction. This is because all of the atoms in a sample of an element have the same number of protons, though they may be different isotopes, with differing numbers of neutrons. As of 2019, there are 118 known elements, about 80 of which are stable – that is, they do not change by radioactive decay into other elements. Some elements can occur as more than a single chemical substance (allotropes). For instance, oxygen exists as both diatomic oxygen (O2) and ozone (O3). The majority of elements are classified as metals. These are elements with a characteristic lustre such as iron, copper, and gold. Metals typically conduct electricity and heat well, and they are malleable and ductile. Around 14 to 21 elements, such as carbon, nitrogen, and oxygen, are classified as non-metals. Non-metals lack the metallic properties described above, they also have a high electronegativity and a tendency to form negative ions. Certain elements such as silicon sometimes resemble metals and sometimes resemble non-metals, and are known as metalloids.  Chemical compounds  A chemical compound is a chemical substance that is composed of a particular set of atoms or ions. Two or more elements combined into one substance through a chemical reaction form a chemical compound. All compounds are substances, but not all substances are compounds. A chemical compound can be either atoms bonded together in molecules or crystals in which atoms, molecules or ions form a crystalline lattice. Compounds based primarily on carbon and hydrogen atoms are called organic compounds, and all others are called inorganic compounds. Compounds containing bonds between carbon and a metal are called organometallic compounds. Compounds in which components share electrons are known as covalent compounds. Compounds consisting of oppositely charged ions are known as ionic compounds, or salts. Coordination complexes are compounds where a dative bond keeps the substance together without a covalent or ionic bond. Coordination complexes are distinct substances with distinct properties different from a simple mixture. Typically these have a metal, such as a copper ion, in the center and a nonmetals atom, such as the nitrogen in an ammonia molecule or oxygen in water in a water molecule, forms a dative bond to the metal center, e.g. tetraamminecopper(II) sulfate [Cu(NH3)4]SO4·H2O. The metal is known as a ""metal center"" and the substance that coordinates to the center is called a ""ligand"". However, the center does not need to be a metal, as exemplified by boron trifluoride etherate BF3OEt2, where the highly Lewis acidic, but nonmetallic boron center takes the role of the ""metal"". If the ligand bonds to the metal center with multiple atoms, the complex is called a chelate. In organic chemistry, there can be more than one chemical compound with the same composition and molecular weight. Generally, these are called isomers. Isomers usually have substantially different chemical properties, and often may be isolated without spontaneously interconverting. A common example is glucose vs. fructose. The former is an aldehyde, the latter is a ketone. Their interconversion requires either enzymatic or acid-base catalysis. However, tautomers are an exception: the isomerization occurs spontaneously in ordinary conditions, such that a pure substance cannot be isolated into its tautomers, even if these can be identified spectroscopically or even isolated in special conditions. A common example is glucose, which has open-chain and ring forms. One cannot manufacture pure open-chain glucose because glucose spontaneously cyclizes to the hemiacetal form.  Substances versus mixtures  All matter consists of various elements and chemical compounds, but these are often intimately mixed together. Mixtures contain more than one chemical substance, and they do not have a fixed composition. In principle, they can be separated into the component substances by purely mechanical processes. Butter, soil and wood are common examples of mixtures. Grey iron metal and yellow sulfur are both chemical elements, and they can be mixed together in any ratio to form a yellow-grey mixture. No chemical process occurs, and the material can be identified as a mixture by the fact that the sulfur and the iron can be separated by a mechanical process, such as using a magnet to attract the iron away from the sulfur. In contrast, if iron and sulfur are heated together in a certain ratio (1 atom of iron for each atom of sulfur, or by weight, 56 grams (1 mol) of iron to 32 grams (1 mol) of sulfur), a chemical reaction takes place and a new substance is formed, the compound iron(II) sulfide, with chemical formula FeS. The resulting compound has all the properties of a chemical substance and is not a mixture. Iron(II) sulfide has its own distinct properties such as melting point and solubility, and the two elements cannot be separated using normal mechanical processes; a magnet will be unable to recover the iron, since there is no metallic iron present in the compound.  Chemicals versus chemical substances  While the term chemical substance is a precise technical term that is synonymous with chemical for chemists, the word chemical is used in general usage to refer to both (pure) chemical substances and mixtures (often called compounds), and especially when produced or purified in a laboratory or an industrial process. In other words, the chemical substances of which fruits and vegetables, for example, are naturally composed even when growing wild are not called ""chemicals"" in general usage. In countries that require a list of ingredients in products, the ""chemicals"" listed are industrially produced ""chemical substances"". The word ""chemical"" is also often used to refer to addictive, narcotic, or mind-altering drugs.Within the chemical industry, manufactured ""chemicals"" are chemical substances, which can be classified by production volume into bulk chemicals, fine chemicals and chemicals found in research only: Bulk chemicals are produced in very large quantities, usually with highly optimized continuous processes and to a relatively low price. Fine chemicals are produced at a high cost in small quantities for special low-volume applications such as biocides, pharmaceuticals and speciality chemicals for technical applications. Research chemicals are produced individually for research, such as when searching for synthetic routes or screening substances for pharmaceutical activity. In effect, their price per gram is very high, although they are not sold.The cause of the difference in production volume is the complexity of the molecular structure of the chemical. Bulk chemicals are usually much less complex. While fine chemicals may be more complex, many of them are simple enough to be sold as ""building blocks"" in the synthesis of more complex molecules targeted for single use, as named above. The production of a chemical includes not only its synthesis but also its purification to eliminate by-products and impurities involved in the synthesis. The last step in production should be the analysis of batch lots of chemicals in order to identify and quantify the percentages of impurities for the buyer of the chemicals. The required purity and analysis depends on the application, but higher tolerance of impurities is usually expected in the production of bulk chemicals. Thus, the user of the chemical in the US might choose between the bulk or ""technical grade"" with higher amounts of impurities or a much purer ""pharmaceutical grade"" (labeled ""USP"", United States Pharmacopeia). ""Chemicals"" in the commercial and legal sense may also include mixtures of highly variable composition, as they are products made to a technical specification instead of particular chemical substances. For example, gasoline is not a single chemical compound or even a particular mixture: different gasolines can have very different chemical compositions, as ""gasoline"" is primarily defined through source, properties and octane rating.  Naming and indexing  Every chemical substance has one or more systematic names, usually named according to the IUPAC rules for naming. An alternative system is used by the Chemical Abstracts Service (CAS). Many compounds are also known by their more common, simpler names, many of which predate the systematic name. For example, the long-known sugar glucose is now systematically named 6-(hydroxymethyl)oxane-2,3,4,5-tetrol. Natural products and pharmaceuticals are also given simpler names, for example the mild pain-killer Naproxen is the more common name for the chemical compound (S)-6-methoxy-α-methyl-2-naphthaleneacetic acid. Chemists frequently refer to chemical compounds using chemical formulae or molecular structure of the compound. There has been a phenomenal growth in the number of chemical compounds being synthesized (or isolated), and then reported in the scientific literature by professional chemists around the world. An enormous number of chemical compounds are possible through the chemical combination of the known chemical elements. As of Feb 2021, about ""177 million organic and inorganic substances"" (including 68 million defined-sequence biopolymers) are in the scientific literature and registered in public databases. The names of many of these compounds are often nontrivial and hence not very easy to remember or cite accurately. Also it is difficult to keep the track of them in the literature. Several international organizations like IUPAC and CAS have initiated steps to make such tasks easier. CAS provides the abstracting services of the chemical literature, and provides a numerical identifier, known as CAS registry number to each chemical substance that has been reported in the chemical literature (such as chemistry journals and patents). This information is compiled as a database and is popularly known as the Chemical substances index. Other computer-friendly systems that have been developed for substance information, are: SMILES and the International Chemical Identifier or InChI.  Isolation, purification, characterization, and identification  Often a pure substance needs to be isolated from a mixture, for example from a natural source (where a sample often contains numerous chemical substances) or after a chemical reaction (which often gives mixtures of chemical substances).  See also  Hazard symbol Homogeneous and heterogeneous mixtures Prices of chemical elements Dedicated bio-based chemical Fire diamond Research chemical  References   External links  Media related to Chemical substances at Wikimedia Commons","A chemical substance is any material with a known chemical composition. For example, water has the same properties and the same ratio of hydrogen to oxygen whether it came from a river or was made in a laboratory. Typical chemical substances found in the home include water, salt (sodium chloride) and bleach. Generally, substances exist as a solid, a liquid, or a gas, and may change between these phases of matter when there are changes in temperature or pressure.  Gallery   References   Related pages  Chemical nomenclature"
"A chemical composition specifies the identity, arrangement, and ratio of the elements making up a compound. Chemical formulas can be used to describe the relative amounts of elements present in a compound. For example, the chemical formula for water is H2O: this means that each molecule of water is constituted by 2 atoms of hydrogen (H) and 1 atom of oxygen (O). The chemical composition of water may be interpreted as a 2:1 ratio of hydrogen atoms to oxygen atoms. Different types of chemical formulas are used to convey composition information, such as an empirical or molecular formula. Nomenclature can be used to express not only the elements present in a compound but their arrangement within the molecules of the compound. In this way, compounds will have unique names which can describe their elemental composition.  Composite mixture  The chemical composition of a mixture can be defined as the distribution of the individual substances that constitute the mixture, called ""components"". In other words, it is equivalent to quantifying the concentration of each component. Because there are different ways to define the concentration of a component, there are also different ways to define the composition of a mixture. It may be expressed as molar fraction, volume fraction, mass fraction, molality, molarity or normality or mixing ratio. Chemical composition of a mixture can be represented graphically in plots like ternary plot and quaternary plot.  References ","Chemical composition is the arrangement, type, and ratio of atoms in molecules of chemical substances. Chemical composition varies when chemicals are added or subtracted from a substance, when the ratio of substances changes, or when other chemical changes occur in chemicals. Chemical formulas show this information. The chemical composition of a substance determines the intramolecular forces and properties of the substance. This means that the way atoms are put together in something determines the color, density, strength, texture and other properties of the thing. Chemists can use tests to learn the chemical composition of a substance, including a pH test, flammability test, heavy metal test etc. A particular chemical has a particular ratio of its atoms, allowed by their valence (chemistry). An example is Hydrogen Fluoride, or HF, which has 1 Hydrogen atom in ratio to every 1 Fluorine atom. This substance has strong intramolecular forces of attraction because it is a hydrogen bond."
"In chemistry, a chemical formula is a way of presenting information about the chemical proportions of atoms that constitute a particular chemical compound or molecule, using chemical element symbols, numbers, and sometimes also other symbols, such as parentheses, dashes, brackets, commas and plus (+) and minus (−) signs. These are limited to a single typographic line of symbols, which may include subscripts and superscripts. A chemical formula is not a chemical name since it does not contain any words. Although a chemical formula may imply certain simple chemical structures, it is not the same as a full chemical structural formula. Chemical formulae can fully specify the structure of only the simplest of molecules and chemical substances, and are generally more limited in power than chemical names and structural formulae. The simplest types of chemical formulae are called empirical formulae, which use letters and numbers indicating the numerical proportions of atoms of each type. Molecular formulae indicate the simple numbers of each type of atom in a molecule, with no information on structure. For example, the empirical formula for glucose is CH2O (twice as many hydrogen atoms as carbon and oxygen), while its molecular formula is C6H12O6 (12 hydrogen atoms, six carbon and oxygen atoms). Sometimes a chemical formula is complicated by being written as a condensed formula (or condensed molecular formula, occasionally called a ""semi-structural formula""), which conveys additional information about the particular ways in which the atoms are chemically bonded together, either in covalent bonds, ionic bonds, or various combinations of these types. This is possible if the relevant bonding is easy to show in one dimension. An example is the condensed molecular/chemical formula for ethanol, which is CH3−CH2−OH or CH3CH2OH. However, even a condensed chemical formula is necessarily limited in its ability to show complex bonding relationships between atoms, especially atoms that have bonds to four or more different substituents. Since a chemical formula must be expressed as a single line of chemical element symbols, it often cannot be as informative as a true structural formula, which is a graphical representation of the spatial relationship between atoms in chemical compounds (see for example the figure for butane structural and chemical formulae, at right). For reasons of structural complexity, a single condensed chemical formula (or semi-structural formula) may correspond to different molecules, known as isomers. For example, glucose shares its molecular formula C6H12O6 with a number of other sugars, including fructose, galactose and mannose. Linear equivalent chemical names exist that can and do specify uniquely any complex structural formula (see chemical nomenclature), but such names must use many terms (words), rather than the simple element symbols, numbers, and simple typographical symbols that define a chemical formula. Chemical formulae may be used in chemical equations to describe chemical reactions and other chemical transformations, such as the dissolving of ionic compounds into solution. While, as noted, chemical formulae do not have the full power of structural formulae to show chemical relationships between atoms, they are sufficient to keep track of numbers of atoms and numbers of electrical charges in chemical reactions, thus balancing chemical equations so that these equations can be used in chemical problems involving conservation of atoms, and conservation of electric charge.  Overview  A chemical formula identifies each constituent element by its chemical symbol and indicates the proportionate number of atoms of each element. In empirical formulae, these proportions begin with a key element and then assign numbers of atoms of the other elements in the compound, by ratios to the key element. For molecular compounds, these ratio numbers can all be expressed as whole numbers. For example, the empirical formula of ethanol may be written C2H6O because the molecules of ethanol all contain two carbon atoms, six hydrogen atoms, and one oxygen atom. Some types of ionic compounds, however, cannot be written with entirely whole-number empirical formulae. An example is boron carbide, whose formula of CBn is a variable non-whole number ratio with n ranging from over 4 to more than 6.5. When the chemical compound of the formula consists of simple molecules, chemical formulae often employ ways to suggest the structure of the molecule. These types of formulae are variously known as molecular formulae and condensed formulae. A molecular formula enumerates the number of atoms to reflect those in the molecule, so that the molecular formula for glucose is C6H12O6 rather than the glucose empirical formula, which is CH2O. However, except for very simple substances, molecular chemical formulae lack needed structural information, and are ambiguous. For simple molecules, a condensed (or semi-structural) formula is a type of chemical formula that may fully imply a correct structural formula. For example, ethanol may be represented by the condensed chemical formula CH3CH2OH, and dimethyl ether by the condensed formula CH3OCH3. These two molecules have the same empirical and molecular formulae (C2H6O), but may be differentiated by the condensed formulae shown, which are sufficient to represent the full structure of these simple organic compounds. Condensed chemical formulae may also be used to represent ionic compounds that do not exist as discrete molecules, but nonetheless do contain covalently bound clusters within them. These polyatomic ions are groups of atoms that are covalently bound together and have an overall ionic charge, such as the sulfate [SO4]2− ion. Each polyatomic ion in a compound is written individually in order to illustrate the separate groupings. For example, the compound dichlorine hexoxide has an empirical formula ClO3, and molecular formula Cl2O6, but in liquid or solid forms, this compound is more correctly shown by an ionic condensed formula [ClO2]+[ClO4]−, which illustrates that this compound consists of [ClO2]+ ions and [ClO4]− ions. In such cases, the condensed formula only need be complex enough to show at least one of each ionic species. Chemical formulae as described here are distinct from the far more complex chemical systematic names that are used in various systems of chemical nomenclature. For example, one systematic name for glucose is (2R,3S,4R,5R)-2,3,4,5,6-pentahydroxyhexanal. This name, interpreted by the rules behind it, fully specifies glucose's structural formula, but the name is not a chemical formula as usually understood, and uses terms and words not used in chemical formulae. Such names, unlike basic formulae, may be able to represent full structural formulae without graphs.  Types   Empirical formula  In chemistry, the empirical formula of a chemical is a simple expression of the relative number of each type of atom or ratio of the elements in the compound. Empirical formulae are the standard for ionic compounds, such as CaCl2, and for macromolecules, such as SiO2. An empirical formula makes no reference to isomerism, structure, or absolute number of atoms. The term empirical refers to the process of elemental analysis, a technique of analytical chemistry used to determine the relative percent composition of a pure chemical substance by element. For example, hexane has a molecular formula of C6H14, and (for one of its isomers, n-hexane) a structural formula CH3CH2CH2CH2CH2CH3, implying that it has a chain structure of 6 carbon atoms, and 14 hydrogen atoms. However, the empirical formula for hexane is C3H7. Likewise the empirical formula for hydrogen peroxide, H2O2, is simply HO, expressing the 1:1 ratio of component elements. Formaldehyde and acetic acid have the same empirical formula, CH2O. This is the actual chemical formula for formaldehyde, but acetic acid has double the number of atoms.  Molecular formula  Molecular formulae simply indicate the numbers of each type of atom in a molecule of a molecular substance. They are the same as empirical formulae for molecules that only have one atom of a particular type, but otherwise may have larger numbers. An example of the difference is the empirical formula for glucose, which is CH2O (ratio 1:2:1), while its molecular formula is C6H12O6 (number of atoms 6:12:6). For water, both formulae are H2O. A molecular formula provides more information about a molecule than its empirical formula, but is more difficult to establish. A molecular formula shows the number of elements in a molecule, and determines whether it is a binary compound, ternary compound, quaternary compound, or has even more elements.  Structural formula  In addition to indicating the number of atoms of each elementa molecule, a structural formula indicates how the atoms are organized, and shows (or implies) the chemical bonds between the atoms. There are multiple types of structural formulas focused on different aspects of the molecular structure. The two diagrams show two molecules which are structural isomers of each other, since they both have the same molecular formula C4H10, but they have different structural formulas as shown.  Condensed formula  The connectivity of a molecule often has a strong influence on its physical and chemical properties and behavior. Two molecules composed of the same numbers of the same types of atoms (i.e. a pair of isomers) might have completely different chemical and/or physical properties if the atoms are connected differently or in different positions. In such cases, a structural formula is useful, as it illustrates which atoms are bonded to which other ones. From the connectivity, it is often possible to deduce the approximate shape of the molecule. A condensed (or semi-structural) formula may represent the types and spatial arrangement of bonds in a simple chemical substance, though it does not necessarily specify isomers or complex structures. For example, ethane consists of two carbon atoms single-bonded to each other, with each carbon atom having three hydrogen atoms bonded to it. Its chemical formula can be rendered as CH3CH3. In ethylene there is a double bond between the carbon atoms (and thus each carbon only has two hydrogens), therefore the chemical formula may be written: CH2CH2, and the fact that there is a double bond between the carbons is implicit because carbon has a valence of four. However, a more explicit method is to write H2CCH2 or less commonly H2C::CH2. The two lines (or two pairs of dots) indicate that a double bond connects the atoms on either side of them. A triple bond may be expressed with three lines (HC≡CH) or three pairs of dots (HC:::CH), and if there may be ambiguity, a single line or pair of dots may be used to indicate a single bond. Molecules with multiple functional groups that are the same may be expressed by enclosing the repeated group in round brackets. For example, isobutane may be written (CH3)3CH. This condensed structural formula implies a different connectivity from other molecules that can be formed using the same atoms in the same proportions (isomers). The formula (CH3)3CH implies a central carbon atom connected to one hydrogen atom and three methyl groups (CH3). The same number of atoms of each element (10 hydrogens and 4 carbons, or C4H10) may be used to make a straight chain molecule, n-butane: CH3CH2CH2CH3.  Law of composition  In any given chemical compound, the elements always combine in the same proportion with each other. This is the law of constant composition. The law of constant composition says that, in any particular chemical compound, all samples of that compound will be made up of the same elements in the same proportion or ratio. For example, any water molecule is always made up of two hydrogen atoms and one oxygen atom in a 2:1 ratio. If we look at the relative masses of oxygen and hydrogen in a water molecule, we see that 94% of the mass of a water molecule is accounted for by oxygen and the remaining 6% is the mass of hydrogen. This mass proportion will be the same for any water molecule.  Chemical names in answer to limitations of chemical formulae  The alkene called but-2-ene has two isomers, which the chemical formula CH3CHCHCH3 does not identify. The relative position of the two methyl groups must be indicated by additional notation denoting whether the methyl groups are on the same side of the double bond (cis or Z) or on the opposite sides from each other (trans or E).As noted above, in order to represent the full structural formulae of many complex organic and inorganic compounds, chemical nomenclature may be needed which goes well beyond the available resources used above in simple condensed formulae. See IUPAC nomenclature of organic chemistry and IUPAC nomenclature of inorganic chemistry 2005 for examples. In addition, linear naming systems such as International Chemical Identifier (InChI) allow a computer to construct a structural formula, and simplified molecular-input line-entry system (SMILES) allows a more human-readable ASCII input. However, all these nomenclature systems go beyond the standards of chemical formulae, and technically are chemical naming systems, not formula systems.  Polymers in condensed formulae  For polymers in condensed chemical formulae, parentheses are placed around the repeating unit. For example, a hydrocarbon molecule that is described as CH3(CH2)50CH3, is a molecule with fifty repeating units. If the number of repeating units is unknown or variable, the letter n may be used to indicate this formula: CH3(CH2)nCH3.  Ions in condensed formulae  For ions, the charge on a particular atom may be denoted with a right-hand superscript. For example, Na+, or Cu2+. The total charge on a charged molecule or a polyatomic ion may also be shown in this way, such as for hydronium, H3O+, or sulfate, SO2−4. Here + and - are used in place of +1 and -1, respectively. For more complex ions, brackets [ ] are often used to enclose the ionic formula, as in [B12H12]2−, which is found in compounds such as caesium dodecaborate, Cs2[B12H12]. Parentheses ( ) can be nested inside brackets to indicate a repeating unit, as in Hexamminecobalt(III) chloride, [Co(NH3)6]3+Cl−3. Here, (NH3)6 indicates that the ion contains six ammine groups (NH3) bonded to cobalt, and [ ] encloses the entire formula of the ion with charge +3.This is strictly optional; a chemical formula is valid with or without ionization information, and Hexamminecobalt(III) chloride may be written as [Co(NH3)6]3+Cl−3 or [Co(NH3)6]Cl3. Brackets, like parentheses, behave in chemistry as they do in mathematics, grouping terms together – they are not specifically employed only for ionization states. In the latter case here, the parentheses indicate 6 groups all of the same shape, bonded to another group of size 1 (the cobalt atom), and then the entire bundle, as a group, is bonded to 3 chlorine atoms. In the former case, it is clearer that the bond connecting the chlorines is ionic, rather than covalent.  Isotopes  Although isotopes are more relevant to nuclear chemistry or stable isotope chemistry than to conventional chemistry, different isotopes may be indicated with a prefixed superscript in a chemical formula. For example, the phosphate ion containing radioactive phosphorus-32 is [32PO4]3−. Also a study involving stable isotope ratios might include the molecule 18O16O. A left-hand subscript is sometimes used redundantly to indicate the atomic number. For example, 8O2 for dioxygen, and 168O2 for the most abundant isotopic species of dioxygen. This is convenient when writing equations for nuclear reactions, in order to show the balance of charge more clearly.  Trapped atoms  The @ symbol (at sign) indicates an atom or molecule trapped inside a cage but not chemically bound to it. For example, a buckminsterfullerene (C60) with an atom (M) would simply be represented as MC60 regardless of whether M was inside the fullerene without chemical bonding or outside, bound to one of the carbon atoms. Using the @ symbol, this would be denoted M@C60 if M was inside the carbon network. A non-fullerene example is [As@Ni12As20]3−, an ion in which one arsenic (As) atom is trapped in a cage formed by the other 32 atoms. This notation was proposed in 1991 with the discovery of fullerene cages (endohedral fullerenes), which can trap atoms such as La to form, for example, La@C60 or La@C82. The choice of the symbol has been explained by the authors as being concise, readily printed and transmitted electronically (the at sign is included in ASCII, which most modern character encoding schemes are based on), and the visual aspects suggesting the structure of an endohedral fullerene.  Non-stoichiometric chemical formulae  Chemical formulae most often use integers for each element. However, there is a class of compounds, called non-stoichiometric compounds, that cannot be represented by small integers. Such a formula might be written using decimal fractions, as in Fe0.95O, or it might include a variable part represented by a letter, as in Fe1−xO, where x is normally much less than 1.  General forms for organic compounds  A chemical formula used for a series of compounds that differ from each other by a constant unit is called a general formula. It generates a homologous series of chemical formulae. For example, alcohols may be represented by the formula CnH2n + 1OH (n ≥ 1), giving the homologs methanol, ethanol, propanol for 1 ≤ n ≤ 3.  Hill system  The Hill system (or Hill notation) is a system of writing empirical chemical formulae, molecular chemical formulae and components of a condensed formula such that the number of carbon atoms in a molecule is indicated first, the number of hydrogen atoms next, and then the number of all other chemical elements subsequently, in alphabetical order of the chemical symbols. When the formula contains no carbon, all the elements, including hydrogen, are listed alphabetically. By sorting formulae according to the number of atoms of each element present in the formula according to these rules, with differences in earlier elements or numbers being treated as more significant than differences in any later element or number—like sorting text strings into lexicographical order—it is possible to collate chemical formulae into what is known as Hill system order. The Hill system was first published by Edwin A. Hill of the United States Patent and Trademark Office in 1900. It is the most commonly used system in chemical databases and printed indexes to sort lists of compounds.A list of formulae in Hill system order is arranged alphabetically, as above, with single-letter elements coming before two-letter symbols when the symbols begin with the same letter (so ""B"" comes before ""Be"", which comes before ""Br"").The following example formulae are written using the Hill system, and listed in Hill order: BrI BrClH2Si CCl4 CH3I C2H5Br H2O4S  See also  Dictionary of chemical formulae Formula unit Nuclear notation Periodic table Skeletal formula Simplified molecular-input line-entry system  Notes   References  Petrucci, Ralph H.; Harwood, William S.; Herring, F. Geoffrey (2002). ""3"". General chemistry: principles and modern applications (8th ed.). Upper Saddle River, N.J: Prentice Hall. ISBN 978-0-13-014329-7. LCCN 2001032331. OCLC 46872308.  External links  Media related to Chemical formulas at Wikimedia Commons Hill notation example, from the University of Massachusetts Lowell libraries, including how to sort into Hill system order Molecular formula calculation applying Hill notation. The library calculating Hill notation is available on npm.","A chemical formula is a way that chemists describe a molecule. The formula says what atoms, and how many of each type, are in the molecule. Sometimes the formula shows how the atoms are linked, and sometimes the formula shows how the atoms are arranged in space. The letter shows what chemical element each atom is. These are called chemical symbols and they are one or two letters long. The subscript shows the number of each type of atom. For example, methane has one carbon (C) atom and four hydrogen atoms; the chemical formula is CH4. The sugar molecule glucose has six carbon atoms, twelve hydrogen atoms, and six oxygen atoms, so its chemical formula is C6H12O6. Chemical formulas are used in chemical equations to describe chemical reactions. The 19th-century Swedish chemist Jöns Jacob Berzelius worked out this system for writing chemical formulas.  Reading and writing formulas  Chemical formulas are another way to represent the number of atoms. Chemical formulas are used to represent kinds of atoms in a combination. Chemical formulas use subscripts to tell how many of each atom are present in a combination. Subscripts are small numbers to the lower right of a symbol. They represent the number of atoms of that element in the equation. Before writing Chemical formulas, write down the symbol of each atom present in your equation. Writing chemical formula is a way of informing the chemical figure. It is most easily found in the periodic table. The periodic table is a chart of all well-known parts. Use the periodic table to reference the figure that cannot be remembered.  Kinds of formulas  A molecular formula is the most common kind: it says the number of atoms in a molecule. An empirical formula instead shows the ratio between atoms of different elements. For example, the empirical formula of glucose is CH2O, because there are the same number of carbon and oxygen atoms, and twice that number of hydrogen atoms. The empirical formula is used for salts, which make large networks instead of separate molecules.  Related pages  Chemical equation  References "
"Genetics is the study of genes, genetic variation, and heredity in organisms. It is an important branch in biology because heredity is vital to organisms' evolution. Gregor Mendel, a Moravian Augustinian friar working in the 19th century in Brno, was the first to study genetics scientifically. Mendel studied ""trait inheritance"", patterns in the way traits are handed down from parents to offspring over time. He observed that organisms (pea plants) inherit traits by way of discrete ""units of inheritance"". This term, still used today, is a somewhat ambiguous definition of what is referred to as a gene. Trait inheritance and molecular inheritance mechanisms of genes are still primary principles of genetics in the 21st century, but modern genetics has expanded to study the function and behavior of genes. Gene structure and function, variation, and distribution are studied within the context of the cell, the organism (e.g. dominance), and within the context of a population. Genetics has given rise to a number of subfields, including molecular genetics, epigenetics and population genetics. Organisms studied within the broad field span the domains of life (archaea, bacteria, and eukarya). Genetic processes work in combination with an organism's environment and experiences to influence development and behavior, often referred to as nature versus nurture. The intracellular or extracellular environment of a living cell or organism may increase or decrease gene transcription. A classic example is two seeds of genetically identical corn, one placed in a temperate climate and one in an arid climate (lacking sufficient waterfall or rain). While the average height of the two corn stalks may be genetically determined to be equal, the one in the arid climate only grows to half the height of the one in the temperate climate due to lack of water and nutrients in its environment.  Etymology  The word genetics stems from the ancient Greek γενετικός genetikos meaning ""genitive""/""generative"", which in turn derives from γένεσις genesis meaning ""origin"".  History  The observation that living things inherit traits from their parents has been used since prehistoric times to improve crop plants and animals through selective breeding. The modern science of genetics, seeking to understand this process, began with the work of the Augustinian friar Gregor Mendel in the mid-19th century.Prior to Mendel, Imre Festetics, a Hungarian noble, who lived in Kőszeg before Mendel, was the first who used the word ""genetic"" in hereditarian context. He described several rules of biological inheritance in his works The genetic laws of the Nature (Die genetischen Gesetze der Natur, 1819). His second law is the same as what Mendel published. In his third law, he developed the basic principles of mutation (he can be considered a forerunner of Hugo de Vries). Festetics argued that changes observed in the generation of farm animals, plants, and humans are the result of scientific laws. Festetics empirically deduced that organisms inherit their characteristics, not acquire them. He recognized recessive traits and inherent variation by postulating that traits of past generations could reappear later, and organisms could produce progeny with different attributes. These observations represent an important prelude to Mendel’s theory of particulate inheritance insofar as it features a transition of heredity from its status as myth to that of a scientific discipline, by providing a fundamental theoretical basis for genetics in the twentieth century. Other theories of inheritance preceded Mendel's work. A popular theory during the 19th century, and implied by Charles Darwin's 1859 On the Origin of Species, was blending inheritance: the idea that individuals inherit a smooth blend of traits from their parents. Mendel's work provided examples where traits were definitely not blended after hybridization, showing that traits are produced by combinations of distinct genes rather than a continuous blend. Blending of traits in the progeny is now explained by the action of multiple genes with quantitative effects. Another theory that had some support at that time was the inheritance of acquired characteristics: the belief that individuals inherit traits strengthened by their parents. This theory (commonly associated with Jean-Baptiste Lamarck) is now known to be wrong—the experiences of individuals do not affect the genes they pass to their children. Other theories included Darwin's pangenesis (which had both acquired and inherited aspects) and Francis Galton's reformulation of pangenesis as both particulate and inherited.  Mendelian genetics  Modern genetics started with Mendel's studies of the nature of inheritance in plants. In his paper ""Versuche über Pflanzenhybriden"" (""Experiments on Plant Hybridization""), presented in 1865 to the Naturforschender Verein (Society for Research in Nature) in Brünn, Mendel traced the inheritance patterns of certain traits in pea plants and described them mathematically. Although this pattern of inheritance could only be observed for a few traits, Mendel's work suggested that heredity was particulate, not acquired, and that the inheritance patterns of many traits could be explained through simple rules and ratios.The importance of Mendel's work did not gain wide understanding until 1900, after his death, when Hugo de Vries and other scientists rediscovered his research. William Bateson, a proponent of Mendel's work, coined the word genetics in 1905. (The adjective genetic, derived from the Greek word genesis—γένεσις, ""origin"", predates the noun and was first used in a biological sense in 1860.) Bateson both acted as a mentor and was aided significantly by the work of other scientists from Newnham College at Cambridge, specifically the work of Becky Saunders, Nora Darwin Barlow, and Muriel Wheldale Onslow. Bateson popularized the usage of the word genetics to describe the study of inheritance in his inaugural address to the Third International Conference on Plant Hybridization in London in 1906.After the rediscovery of Mendel's work, scientists tried to determine which molecules in the cell were responsible for inheritance. In 1900, Nettie Stevens began studying the mealworm. Over the next 11 years, she discovered that females only had the X chromosome and males had both X and Y chromosomes. She was able to conclude that sex is a chromosomal factor and is determined by the male. In 1911, Thomas Hunt Morgan argued that genes are on chromosomes, based on observations of a sex-linked white eye mutation in fruit flies. In 1913, his student Alfred Sturtevant used the phenomenon of genetic linkage to show that genes are arranged linearly on the chromosome.  Molecular genetics  Although genes were known to exist on chromosomes, chromosomes are composed of both protein and DNA, and scientists did not know which of the two is responsible for inheritance. In 1928, Frederick Griffith discovered the phenomenon of transformation: dead bacteria could transfer genetic material to ""transform"" other still-living bacteria. Sixteen years later, in 1944, the Avery–MacLeod–McCarty experiment identified DNA as the molecule responsible for transformation. The role of the nucleus as the repository of genetic information in eukaryotes had been established by Hämmerling in 1943 in his work on the single celled alga Acetabularia. The Hershey–Chase experiment in 1952 confirmed that DNA (rather than protein) is the genetic material of the viruses that infect bacteria, providing further evidence that DNA is the molecule responsible for inheritance.James Watson and Francis Crick determined the structure of DNA in 1953, using the X-ray crystallography work of Rosalind Franklin and Maurice Wilkins that indicated DNA has a helical structure (i.e., shaped like a corkscrew). Their double-helix model had two strands of DNA with the nucleotides pointing inward, each matching a complementary nucleotide on the other strand to form what look like rungs on a twisted ladder. This structure showed that genetic information exists in the sequence of nucleotides on each strand of DNA. The structure also suggested a simple method for replication: if the strands are separated, new partner strands can be reconstructed for each based on the sequence of the old strand. This property is what gives DNA its semi-conservative nature where one strand of new DNA is from an original parent strand.Although the structure of DNA showed how inheritance works, it was still not known how DNA influences the behavior of cells. In the following years, scientists tried to understand how DNA controls the process of protein production. It was discovered that the cell uses DNA as a template to create matching messenger RNA, molecules with nucleotides very similar to DNA. The nucleotide sequence of a messenger RNA is used to create an amino acid sequence in protein; this translation between nucleotide sequences and amino acid sequences is known as the genetic code.With the newfound molecular understanding of inheritance came an explosion of research. A notable theory arose from Tomoko Ohta in 1973 with her amendment to the neutral theory of molecular evolution through publishing the nearly neutral theory of molecular evolution. In this theory, Ohta stressed the importance of natural selection and the environment to the rate at which genetic evolution occurs. One important development was chain-termination DNA sequencing in 1977 by Frederick Sanger. This technology allows scientists to read the nucleotide sequence of a DNA molecule. In 1983, Kary Banks Mullis developed the polymerase chain reaction, providing a quick way to isolate and amplify a specific section of DNA from a mixture. The efforts of the Human Genome Project, Department of Energy, NIH, and parallel private efforts by Celera Genomics led to the sequencing of the human genome in 2003.  Features of inheritance   Discrete inheritance and Mendel's laws  At its most fundamental level, inheritance in organisms occurs by passing discrete heritable units, called genes, from parents to offspring. This property was first observed by Gregor Mendel, who studied the segregation of heritable traits in pea plants, showing for example that flowers on a single plant were either purple or white—but never an intermediate between the two colors. The discrete versions of the same gene controlling the inherited appearance (phenotypes) are called alleles.In the case of the pea, which is a diploid species, each individual plant has two copies of each gene, one copy inherited from each parent. Many species, including humans, have this pattern of inheritance. Diploid organisms with two copies of the same allele of a given gene are called homozygous at that gene locus, while organisms with two different alleles of a given gene are called heterozygous. The set of alleles for a given organism is called its genotype, while the observable traits of the organism are called its phenotype. When organisms are heterozygous at a gene, often one allele is called dominant as its qualities dominate the phenotype of the organism, while the other allele is called recessive as its qualities recede and are not observed. Some alleles do not have complete dominance and instead have incomplete dominance by expressing an intermediate phenotype, or codominance by expressing both alleles at once.When a pair of organisms reproduce sexually, their offspring randomly inherit one of the two alleles from each parent. These observations of discrete inheritance and the segregation of alleles are collectively known as Mendel's first law or the Law of Segregation. However, the probability of getting one gene over the other can change due to dominant, recessive, homozygous, or heterozygous genes. For example, Mendel found that if you cross homozygous dominate trait and homozygous recessive trait your odds of getting the dominant trait is 3:1. Real geneticist study and calculate probabilities by using theoretical probabilities, empirical probabilities, the product rule, the sum rule, and more.  Notation and diagrams  Geneticists use diagrams and symbols to describe inheritance. A gene is represented by one or a few letters. Often a ""+"" symbol is used to mark the usual, non-mutant allele for a gene.In fertilization and breeding experiments (and especially when discussing Mendel's laws) the parents are referred to as the ""P"" generation and the offspring as the ""F1"" (first filial) generation. When the F1 offspring mate with each other, the offspring are called the ""F2"" (second filial) generation. One of the common diagrams used to predict the result of cross-breeding is the Punnett square.When studying human genetic diseases, geneticists often use pedigree charts to represent the inheritance of traits. These charts map the inheritance of a trait in a family tree.  Multiple gene interactions  Organisms have thousands of genes, and in sexually reproducing organisms these genes generally assort independently of each other. This means that the inheritance of an allele for yellow or green pea color is unrelated to the inheritance of alleles for white or purple flowers. This phenomenon, known as ""Mendel's second law"" or the ""law of independent assortment,"" means that the alleles of different genes get shuffled between parents to form offspring with many different combinations. Different genes often interact to influence the same trait. In the Blue-eyed Mary (Omphalodes verna), for example, there exists a gene with alleles that determine the color of flowers: blue or magenta. Another gene, however, controls whether the flowers have color at all or are white. When a plant has two copies of this white allele, its flowers are white—regardless of whether the first gene has blue or magenta alleles. This interaction between genes is called epistasis, with the second gene epistatic to the first.Many traits are not discrete features (e.g. purple or white flowers) but are instead continuous features (e.g. human height and skin color). These complex traits are products of many genes. The influence of these genes is mediated, to varying degrees, by the environment an organism has experienced. The degree to which an organism's genes contribute to a complex trait is called heritability. Measurement of the heritability of a trait is relative—in a more variable environment, the environment has a bigger influence on the total variation of the trait. For example, human height is a trait with complex causes. It has a heritability of 89% in the United States. In Nigeria, however, where people experience a more variable access to good nutrition and health care, height has a heritability of only 62%.  Molecular basis for inheritance   DNA and chromosomes  The molecular basis for genes is deoxyribonucleic acid (DNA). DNA is composed of deoxyribose (sugar molecule), a phosphate group, and a base (amine group). There are four types of bases: adenine (A), cytosine (C), guanine (G), and thymine (T). The phosphates make hydrogen bonds with the sugars to make long phosphate-sugar backbones. Bases specifically pair together (T&A, C&G) between two backbones and make like rungs on a ladder. The bases, phosphates, and sugars together make a nucleotide that connects to make long chains of DNA. Genetic information exists in the sequence of these nucleotides, and genes exist as stretches of sequence along the DNA chain. These chains coil into a double a-helix structure and wrap around proteins called Histones which provide the structural support. DNA wrapped around these histones are called chromosomes. Viruses sometimes use the similar molecule RNA instead of DNA as their genetic material.DNA normally exists as a double-stranded molecule, coiled into the shape of a double helix. Each nucleotide in DNA preferentially pairs with its partner nucleotide on the opposite strand: A pairs with T, and C pairs with G. Thus, in its two-stranded form, each strand effectively contains all necessary information, redundant with its partner strand. This structure of DNA is the physical basis for inheritance: DNA replication duplicates the genetic information by splitting the strands and using each strand as a template for synthesis of a new partner strand. Genes are arranged linearly along long chains of DNA base-pair sequences. In bacteria, each cell usually contains a single circular genophore, while eukaryotic organisms (such as plants and animals) have their DNA arranged in multiple linear chromosomes. These DNA strands are often extremely long; the largest human chromosome, for example, is about 247 million base pairs in length. The DNA of a chromosome is associated with structural proteins that organize, compact, and control access to the DNA, forming a material called chromatin; in eukaryotes, chromatin is usually composed of nucleosomes, segments of DNA wound around cores of histone proteins. The full set of hereditary material in an organism (usually the combined DNA sequences of all chromosomes) is called the genome. DNA is most often found in the nucleus of cells, but Ruth Sager helped in the discovery of nonchromosomal genes found outside of the nucleus. In plants, these are often found in the chloroplasts and in other organisms, in the mitochondria. These nonchromosomal genes can still be passed on by either partner in sexual reproduction and they control a variety of hereditary characteristics that replicate and remain active throughout generations.While haploid organisms have only one copy of each chromosome, most animals and many plants are diploid, containing two of each chromosome and thus two copies of every gene. The two alleles for a gene are located on identical loci of the two homologous chromosomes, each allele inherited from a different parent. Many species have so-called sex chromosomes that determine the sex of each organism. In humans and many other animals, the Y chromosome contains the gene that triggers the development of the specifically male characteristics. In evolution, this chromosome has lost most of its content and also most of its genes, while the X chromosome is similar to the other chromosomes and contains many genes. This being said, Mary Frances Lyon discovered that there is X-chromosome inactivation during reproduction to avoid passing on twice as many genes to the offspring. Lyon's discovery led to the discovery of X-linked diseases.  Reproduction  When cells divide, their full genome is copied and each daughter cell inherits one copy. This process, called mitosis, is the simplest form of reproduction and is the basis for asexual reproduction. Asexual reproduction can also occur in multicellular organisms, producing offspring that inherit their genome from a single parent. Offspring that are genetically identical to their parents are called clones.Eukaryotic organisms often use sexual reproduction to generate offspring that contain a mixture of genetic material inherited from two different parents. The process of sexual reproduction alternates between forms that contain single copies of the genome (haploid) and double copies (diploid). Haploid cells fuse and combine genetic material to create a diploid cell with paired chromosomes. Diploid organisms form haploids by dividing, without replicating their DNA, to create daughter cells that randomly inherit one of each pair of chromosomes. Most animals and many plants are diploid for most of their lifespan, with the haploid form reduced to single cell gametes such as sperm or eggs.Although they do not use the haploid/diploid method of sexual reproduction, bacteria have many methods of acquiring new genetic information. Some bacteria can undergo conjugation, transferring a small circular piece of DNA to another bacterium. Bacteria can also take up raw DNA fragments found in the environment and integrate them into their genomes, a phenomenon known as transformation. These processes result in horizontal gene transfer, transmitting fragments of genetic information between organisms that would be otherwise unrelated. Natural bacterial transformation occurs in many bacterial species, and can be regarded as a sexual process for transferring DNA from one cell to another cell (usually of the same species). Transformation requires the action of numerous bacterial gene products, and its primary adaptive function appears to be repair of DNA damages in the recipient cell.  Recombination and genetic linkage  The diploid nature of chromosomes allows for genes on different chromosomes to assort independently or be separated from their homologous pair during sexual reproduction wherein haploid gametes are formed. In this way new combinations of genes can occur in the offspring of a mating pair. Genes on the same chromosome would theoretically never recombine. However, they do, via the cellular process of chromosomal crossover. During crossover, chromosomes exchange stretches of DNA, effectively shuffling the gene alleles between the chromosomes. This process of chromosomal crossover generally occurs during meiosis, a series of cell divisions that creates haploid cells. Meiotic recombination, particularly in microbial eukaryotes, appears to serve the adaptive function of repair of DNA damages.The first cytological demonstration of crossing over was performed by Harriet Creighton and Barbara McClintock in 1931. Their research and experiments on corn provided cytological evidence for the genetic theory that linked genes on paired chromosomes do in fact exchange places from one homolog to the other.The probability of chromosomal crossover occurring between two given points on the chromosome is related to the distance between the points. For an arbitrarily long distance, the probability of crossover is high enough that the inheritance of the genes is effectively uncorrelated. For genes that are closer together, however, the lower probability of crossover means that the genes demonstrate genetic linkage; alleles for the two genes tend to be inherited together. The amounts of linkage between a series of genes can be combined to form a linear linkage map that roughly describes the arrangement of the genes along the chromosome.  Gene expression   Genetic code  Genes generally express their functional effect through the production of proteins, molecules responsible for most functions in the cell. Proteins are made up of one or more polypeptide chains, each composed of a sequence of amino acids. The DNA sequence of a gene is used to produce a specific amino acid sequence. This process begins with the production of an RNA molecule with a sequence matching the gene's DNA sequence, a process called transcription. This messenger RNA molecule then serves to produce a corresponding amino acid sequence through a process called translation. Each group of three nucleotides in the sequence, called a codon, corresponds either to one of the twenty possible amino acids in a protein or an instruction to end the amino acid sequence; this correspondence is called the genetic code. The flow of information is unidirectional: information is transferred from nucleotide sequences into the amino acid sequence of proteins, but it never transfers from protein back into the sequence of DNA—a phenomenon Francis Crick called the central dogma of molecular biology.The specific sequence of amino acids results in a unique three-dimensional structure for that protein, and the three-dimensional structures of proteins are related to their functions. Some are simple structural molecules, like the fibers formed by the protein collagen. Proteins can bind to other proteins and simple molecules, sometimes acting as enzymes by facilitating chemical reactions within the bound molecules (without changing the structure of the protein itself). Protein structure is dynamic; the protein hemoglobin bends into slightly different forms as it facilitates the capture, transport, and release of oxygen molecules within mammalian blood.A single nucleotide difference within DNA can cause a change in the amino acid sequence of a protein. Because protein structures are the result of their amino acid sequences, some changes can dramatically change the properties of a protein by destabilizing the structure or changing the surface of the protein in a way that changes its interaction with other proteins and molecules. For example, sickle-cell anemia is a human genetic disease that results from a single base difference within the coding region for the β-globin section of hemoglobin, causing a single amino acid change that changes hemoglobin's physical properties. Sickle-cell versions of hemoglobin stick to themselves, stacking to form fibers that distort the shape of red blood cells carrying the protein. These sickle-shaped cells no longer flow smoothly through blood vessels, having a tendency to clog or degrade, causing the medical problems associated with this disease.Some DNA sequences are transcribed into RNA but are not translated into protein products—such RNA molecules are called non-coding RNA. In some cases, these products fold into structures which are involved in critical cell functions (e.g. ribosomal RNA and transfer RNA). RNA can also have regulatory effects through hybridization interactions with other RNA molecules (such as microRNA).The genetic code is a dictionary that matches together the amino acid and nucleotide sequences called add-ons. 64 genetic codons are there in which every codon has 3 bases. In 64 codons,20 amino acids are coded by 61 codons which are found in proteins and 3 codons don’t code for any amino acid. There are different types of codons. The codons that code for amino acids are called Sense codons and the codons that code for protein synthesis are called Signal codons. Signal codons are of two types which are Terminating codons and Initiating codons. UAA UAG UGA is termed as termination codons or also called nonsense codons. AUG is called an initiation codon used to code for the first amino acids in every protein. During the translation process the t-RNA base sequence pairs with the codon of m RNA which is known as an Anticodon. The difference between codon and anticodon is that codon is present not only in DNA but in RNA, whereas anticodon is present only in RNA but not in DNA. Codons will be directed from 5’ end to 3’ end in the same way anticodons are directed in the opposite way i.e., 3’ end to 5’ end. In some t RNA molecules, anticodons must pair with more than one codon. The arrangement of codons is sequence manner based while an arrangement of anticodons is discretely present in cells with amino acids.  Nature and nurture  Although genes contain all the information an organism uses to function, the environment plays an important role in determining the ultimate phenotypes an organism displays. The phrase ""nature and nurture"" refers to this complementary relationship. The phenotype of an organism depends on the interaction of genes and the environment. An interesting example is the coat coloration of the Siamese cat. In this case, the body temperature of the cat plays the role of the environment. The cat's genes code for dark hair, thus the hair-producing cells in the cat make cellular proteins resulting in dark hair. But these dark hair-producing proteins are sensitive to temperature (i.e. have a mutation causing temperature-sensitivity) and denature in higher-temperature environments, failing to produce dark-hair pigment in areas where the cat has a higher body temperature. In a low-temperature environment, however, the protein's structure is stable and produces dark-hair pigment normally. The protein remains functional in areas of skin that are colder—such as its legs, ears, tail, and face—so the cat has dark hair at its extremities.Environment plays a major role in effects of the human genetic disease phenylketonuria. The mutation that causes phenylketonuria disrupts the ability of the body to break down the amino acid phenylalanine, causing a toxic build-up of an intermediate molecule that, in turn, causes severe symptoms of progressive intellectual disability and seizures. However, if someone with the phenylketonuria mutation follows a strict diet that avoids this amino acid, they remain normal and healthy.A common method for determining how genes and environment (""nature and nurture"") contribute to a phenotype involves studying identical and fraternal twins, or other siblings of multiple births. Identical siblings are genetically the same since they come from the same zygote. Meanwhile, fraternal twins are as genetically different from one another as normal siblings. By comparing how often a certain disorder occurs in a pair of identical twins to how often it occurs in a pair of fraternal twins, scientists can determine whether that disorder is caused by genetic or postnatal environmental factors. One famous example involved the study of the Genain quadruplets, who were identical quadruplets all diagnosed with schizophrenia.  Gene regulation  The genome of a given organism contains thousands of genes, but not all these genes need to be active at any given moment. A gene is expressed when it is being transcribed into mRNA and there exist many cellular methods of controlling the expression of genes such that proteins are produced only when needed by the cell. Transcription factors are regulatory proteins that bind to DNA, either promoting or inhibiting the transcription of a gene. Within the genome of Escherichia coli bacteria, for example, there exists a series of genes necessary for the synthesis of the amino acid tryptophan. However, when tryptophan is already available to the cell, these genes for tryptophan synthesis are no longer needed. The presence of tryptophan directly affects the activity of the genes—tryptophan molecules bind to the tryptophan repressor (a transcription factor), changing the repressor's structure such that the repressor binds to the genes. The tryptophan repressor blocks the transcription and expression of the genes, thereby creating negative feedback regulation of the tryptophan synthesis process. Differences in gene expression are especially clear within multicellular organisms, where cells all contain the same genome but have very different structures and behaviors due to the expression of different sets of genes. All the cells in a multicellular organism derive from a single cell, differentiating into variant cell types in response to external and intercellular signals and gradually establishing different patterns of gene expression to create different behaviors. As no single gene is responsible for the development of structures within multicellular organisms, these patterns arise from the complex interactions between many cells.Within eukaryotes, there exist structural features of chromatin that influence the transcription of genes, often in the form of modifications to DNA and chromatin that are stably inherited by daughter cells. These features are called ""epigenetic"" because they exist ""on top"" of the DNA sequence and retain inheritance from one cell generation to the next. Because of epigenetic features, different cell types grown within the same medium can retain very different properties. Although epigenetic features are generally dynamic over the course of development, some, like the phenomenon of paramutation, have multigenerational inheritance and exist as rare exceptions to the general rule of DNA as the basis for inheritance.  Genetic change   Mutations  During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, called mutations, can affect the phenotype of an organism, especially if they occur within the protein coding sequence of a gene. Error rates are usually very low—1 error in every 10–100 million bases—due to the ""proofreading"" ability of DNA polymerases. Processes that increase the rate of changes in DNA are called mutagenic: mutagenic chemicals promote errors in DNA replication, often by interfering with the structure of base-pairing, while UV radiation induces mutations by causing damage to the DNA structure. Chemical damage to DNA occurs naturally as well and cells use DNA repair mechanisms to repair mismatches and breaks. The repair does not, however, always restore the original sequence. A particularly important source of DNA damages appears to be reactive oxygen species produced by cellular aerobic respiration, and these can lead to mutations.In organisms that use chromosomal crossover to exchange DNA and recombine genes, errors in alignment during meiosis can also cause mutations. Errors in crossover are especially likely when similar sequences cause partner chromosomes to adopt a mistaken alignment; this makes some regions in genomes more prone to mutating in this way. These errors create large structural changes in DNA sequence—duplications, inversions, deletions of entire regions—or the accidental exchange of whole parts of sequences between different chromosomes, chromosomal translocation.GENETIC MUTATION A highly pathogenic, more or less permanent alteration to the genetic code (genome) of a virus or a cell in a living creature that can be handed down to the progeny of the original cell or virus. A somatic mutation is a change in a multicellular organism's DNA that can progress to progeny by DNA replication. Alterations can happen as a result of subjection to electromagnetic spectrum with high intensity (such as X-rays, ultraviolet light), mishaps that can place during the normal chemical transactions of DNA, most frequently during replication. The bulk of variations are expected to be harmful because they are random changes, however, certain mutations might be helpful in certain circumstances. Types of mutations Mutations and perhaps other gene changes can be inherited or acquired. An inherited gene mutation is one that, as its name suggests, is passed down from one parent to the next. As a result, it can be found in the very first cell that develops into a human after the egg cell and sperm cell have mated. Because it began in the first cell, which gave rise to all the other cells in the body, this modification is present in every cell in the body and can be passed on to the next generation. Because the cells that give rise to eggs and sperm are known as germ cells, also known as a hereditary alteration. A gene mutation that is acquired does not come from the parent. As opposed to that, it emerges at some point in a person's life. Acquired mutations start in one cell and spread to any subsequent cells that develop from that cell. Because this mutation does not affect sperm or egg cells, it cannot be passed down to a person's offspring. Somatic mutation or spontaneous mutation are other names for this kind of mutation.  Natural selection and evolution  Mutations alter an organism's genotype and occasionally this causes different phenotypes to appear. Most mutations have little effect on an organism's phenotype, health, or reproductive fitness. Mutations that do have an effect are usually detrimental, but occasionally some can be beneficial. Studies in the fly Drosophila melanogaster suggest that if a mutation changes a protein produced by a gene, about 70 percent of these mutations are harmful with the remainder being either neutral or weakly beneficial. Population genetics studies the distribution of genetic differences within populations and how these distributions change over time. Changes in the frequency of an allele in a population are mainly influenced by natural selection, where a given allele provides a selective or reproductive advantage to the organism, as well as other factors such as mutation, genetic drift, genetic hitchhiking, artificial selection and migration.Over many generations, the genomes of organisms can change significantly, resulting in evolution. In the process called adaptation, selection for beneficial mutations can cause a species to evolve into forms better able to survive in their environment. New species are formed through the process of speciation, often caused by geographical separations that prevent populations from exchanging genes with each other.By comparing the homology between different species' genomes, it is possible to calculate the evolutionary distance between them and when they may have diverged. Genetic comparisons are generally considered a more accurate method of characterizing the relatedness between species than the comparison of phenotypic characteristics. The evolutionary distances between species can be used to form evolutionary trees; these trees represent the common descent and divergence of species over time, although they do not show the transfer of genetic material between unrelated species (known as horizontal gene transfer and most common in bacteria).  Model organisms  Although geneticists originally studied inheritance in a wide variety of organisms, the range of species studied has narrowed. One reason is that when significant research already exists for a given organism, new researchers are more likely to choose it for further study, and so eventually a few model organisms became the basis for most genetics research. Common research topics in model organism genetics include the study of gene regulation and the involvement of genes in development and cancer. Organisms were chosen, in part, for convenience—short generation times and easy genetic manipulation made some organisms popular genetics research tools. Widely used model organisms include the gut bacterium Escherichia coli, the plant Arabidopsis thaliana, baker's yeast (Saccharomyces cerevisiae), the nematode Caenorhabditis elegans, the common fruit fly (Drosophila melanogaster), the zebrafish (Danio rerio), and the common house mouse (Mus musculus).  Medicine  Medical genetics seeks to understand how genetic variation relates to human health and disease. When searching for an unknown gene that may be involved in a disease, researchers commonly use genetic linkage and genetic pedigree charts to find the location on the genome associated with the disease. At the population level, researchers take advantage of Mendelian randomization to look for locations in the genome that are associated with diseases, a method especially useful for multigenic traits not clearly defined by a single gene. Once a candidate gene is found, further research is often done on the corresponding (or homologous) genes of model organisms. In addition to studying genetic diseases, the increased availability of genotyping methods has led to the field of pharmacogenetics: the study of how genotype can affect drug responses.Individuals differ in their inherited tendency to develop cancer, and cancer is a genetic disease. The process of cancer development in the body is a combination of events. Mutations occasionally occur within cells in the body as they divide. Although these mutations will not be inherited by any offspring, they can affect the behavior of cells, sometimes causing them to grow and divide more frequently. There are biological mechanisms that attempt to stop this process; signals are given to inappropriately dividing cells that should trigger cell death, but sometimes additional mutations occur that cause cells to ignore these messages. An internal process of natural selection occurs within the body and eventually mutations accumulate within cells to promote their own growth, creating a cancerous tumor that grows and invades various tissues of the body. Normally, a cell divides only in response to signals called growth factors and stops growing once in contact with surrounding cells and in response to growth-inhibitory signals. It usually then divides a limited number of times and dies, staying within the epithelium where it is unable to migrate to other organs. To become a cancer cell, a cell has to accumulate mutations in a number of genes (three to seven). A cancer cell can divide without growth factor and ignores inhibitory signals. Also, it is immortal and can grow indefinitely, even after it makes contact with neighboring cells. It may escape from the epithelium and ultimately from the primary tumor. Then, the escaped cell can cross the endothelium of a blood vessel and get transported by the bloodstream to colonize a new organ, forming deadly metastasis. Although there are some genetic predispositions in a small fraction of cancers, the major fraction is due to a set of new genetic mutations that originally appear and accumulate in one or a small number of cells that will divide to form the tumor and are not transmitted to the progeny (somatic mutations). The most frequent mutations are a loss of function of p53 protein, a tumor suppressor, or in the p53 pathway, and gain of function mutations in the Ras proteins, or in other oncogenes.  Research methods  DNA can be manipulated in the laboratory. Restriction enzymes are commonly used enzymes that cut DNA at specific sequences, producing predictable fragments of DNA. DNA fragments can be visualized through use of gel electrophoresis, which separates fragments according to their length.The use of ligation enzymes allows DNA fragments to be connected. By binding (""ligating"") fragments of DNA together from different sources, researchers can create recombinant DNA, the DNA often associated with genetically modified organisms. Recombinant DNA is commonly used in the context of plasmids: short circular DNA molecules with a few genes on them. In the process known as molecular cloning, researchers can amplify the DNA fragments by inserting plasmids into bacteria and then culturing them on plates of agar (to isolate clones of bacteria cells). ""Cloning"" can also refer to the various means of creating cloned (""clonal"") organisms.DNA can also be amplified using a procedure called the polymerase chain reaction (PCR). By using specific short sequences of DNA, PCR can isolate and exponentially amplify a targeted region of DNA. Because it can amplify from extremely small amounts of DNA, PCR is also often used to detect the presence of specific DNA sequences.  DNA sequencing and genomics  DNA sequencing, one of the most fundamental technologies developed to study genetics, allows researchers to determine the sequence of nucleotides in DNA fragments. The technique of chain-termination sequencing, developed in 1977 by a team led by Frederick Sanger, is still routinely used to sequence DNA fragments. Using this technology, researchers have been able to study the molecular sequences associated with many human diseases.As sequencing has become less expensive, researchers have sequenced the genomes of many organisms using a process called genome assembly, which uses computational tools to stitch together sequences from many different fragments. These technologies were used to sequence the human genome in the Human Genome Project completed in 2003. New high-throughput sequencing technologies are dramatically lowering the cost of DNA sequencing, with many researchers hoping to bring the cost of resequencing a human genome down to a thousand dollars.Next-generation sequencing (or high-throughput sequencing) came about due to the ever-increasing demand for low-cost sequencing. These sequencing technologies allow the production of potentially millions of sequences concurrently. The large amount of sequence data available has created the subfield of genomics, research that uses computational tools to search for and analyze patterns in the full genomes of organisms. Genomics can also be considered a subfield of bioinformatics, which uses computational approaches to analyze large sets of biological data. A common problem to these fields of research is how to manage and share data that deals with human subject and personally identifiable information.  Society and culture  On 19 March 2015, a group of leading biologists urged a worldwide ban on clinical use of methods, particularly the use of CRISPR and zinc finger, to edit the human genome in a way that can be inherited. In April 2015, Chinese researchers reported results of basic research to edit the DNA of non-viable human embryos using CRISPR.  See also   References   Further reading   External links  Quotations related to Genetics at Wikiquote Genetics at Wikibooks Library resources in your library and in other libraries about Genetics Genetics on In Our Time at the BBC Genetics at Curlie","Genetics is a discipline of biology. It is the science of heredity. This includes the study of genes, and the inheritance of variation and traits of living organisms. In the laboratory, genetics proceeds by mating carefully selected organisms, and analysing their offspring. More informally, genetics is the study of how parents pass some of their characteristics to their children. It is an important part of biology, and gives the basic rules on which evolution acts. The fact that living things inherit traits from their parents has been known since prehistoric times, and used to improve crop plants and animals through selective breeding. However, the modern science of genetics seeks to understand the process of inheritance. This began with the work of Gregor Mendel in the mid-nineteenth century. Although he did not know the physical basis for heredity, Mendel observed that organisms inherit traits via discrete units of inheritance, now called genes. Modern genetics has expanded beyond inheritance. It studies the way genes work.  DNA  Living things are made of millions of tiny self-contained components called cells. Inside each cell are long and complex molecules called deoxyribonucleic acid, known for short as DNA. Some DNA stores information for making proteins. The bits of DNA which do this are known as genes. People look different from each other mainly because they have different versions of the human set of genes. However, a large part of DNA (more than 98% for humans) is non-coding DNA. These sections do not serve as patterns for protein sequences. What it does is code for important non-protein information. Examples are various important RNA molecules, and ""scaffolding"" bits and pieces like centromeres and telomeres.Every cell in the same living thing has the same DNA, but only some of it is used in each cell. For instance, some genes that tell how to make parts of the liver are switched off in the brain. What genes are used can also change over time. For instance, a lot of genes are used by a child early in pregnancy that are not used later. A person has two copies of each gene, one from their mother, and one from their father. There can be several types of a single gene, which give different instructions: one version might cause a person to have blue eyes, another might cause them to have brown. These different versions are known as alleles of the gene. Since a living thing has two copies of each gene, it can have two different alleles of it at the same time. Often, one allele will be dominant, meaning that the living thing looks and acts as if it had only that one allele. The unexpressed allele is called recessive. In other cases, you end up with something in between the two possibilities. In that case, the two alleles are called co-dominant. Most of the characteristics that you can see in a living thing have more than one gene which influences them. And many genes have multiple effects on the body, because their function will not have the same effect in each tissue. The multiple effects of a single gene is called pleiotropism. The whole set of genes is called the genotype, and the total effect of genes on the body is called the phenotype. These are key terms in genetics.  History of genetics   Pre-Mendelian ideas  We know that man started breeding domestic animals from early times, probably before the invention of agriculture. We do not know when heredity was first appreciated as a scientific problem. The Greeks, and most obviously Aristotle, studied living things, and proposed ideas about reproduction and heredity.Imre Festetics, who published work in German in the first part of the 19th century, was totally forgotten until recently. He described several rules of genetic inheritance in his work Die genetische Gesätze der Natur, 1819 (The genetic law of nature). His second law is the same as Mendel. In his third law, he developed the basic principles of mutation. None of the histories of genetics published in the 20th century mentions him. Probably the most publicized idea before Mendel was that of Charles Darwin, whose idea of pangenesis had two parts. The first, that persistent hereditary units were passed on from one generation to another, was quite right. The second was his idea that they were replenished by 'gemmules' from the somatic (body) tissues. This was entirely wrong, and plays no part in science today. Darwin was right about one thing: whatever happens in evolution must happen by means of heredity, and so an accurate science of genetics is fundamental to the theory of evolution. This 'mating' between genetics and evolution took many years to organise. It resulted in the modern evolutionary synthesis.  Mendelian genetics  The basic rules of genetics were discovered by Imre Festetics, a landowner (1764–1847), and a monk named Gregor Mendel around 1865. For thousands of years people had noticed how some traits in parents are passed to their children. However, Mendel's work was different because he designed his experiments very carefully. In his experiments, Mendel studied how traits were passed on in pea plants. He started his crosses with plants that bred true, and counted characters that were either/or in nature (either tall or short). He bred large numbers of plants, and expressed his results numerically. He used test crosses to reveal the presence and proportion of recessive characters.Mendel explained the results of his experiment using two scientific laws: 1. Factors, later called genes, normally occur in pairs in ordinary body cells, yet separate during the formation of sex cells. These factors determine the organism's traits, and are inherited from its parents. When gametes are produced by meiosis, the two factors separate. A gamete only receives one or the other. This Mendel called the Law of segregation. 2. Alleles of different genes separate independently of one another when gametes are formed. This he called the Law of Independent Assortment. So Mendel thought that different traits are inherited independently of one another. We now know this is only true if the genes are not on the same chromosome, in which case they are not linked to each other.Mendel's laws helped explain the results he observed in his pea plants. Later, geneticists discovered that his laws were also true for other living things, even humans. Mendel's findings from his work on the garden pea plants helped to establish the field of genetics. His contributions were not limited to the basic rules that he discovered. Mendel's care towards controlling experiment conditions along with his attention to his numerical results set a standard for future experiments. Over the years, scientists have changed and improved Mendel's ideas. However, the science of genetics would not be possible today without the early work of Gregor Mendel.  Between Mendel and modern genetics  Between Mendel's work and 1900 the foundations of cytology, the study of cells, was developed. The facts discovered about the nucleus and cell division were essential for Mendel's work to be properly understood. 1832: Barthélémy Dumortier, the first to observe cell division in a multicellular organism. 1841, 1852: Robert Remak (1815–1865), a Jewish Polish–German physiologist, was the first person to state the foundation of cell biology: that cells only derive from other cells. This was later popularized by the German doctor Rudolf Virchow (1821–1902), who used the famous phrase omnis cellula e cellula, meaning, all cells from other cells. 1865: Gregor Mendel's paper, Experiments on plant hybridization was published. 1876: Meiosis was discovered and described for the first time in sea urchin eggs, by German biologist Oscar Hertwig (1849–1922). 1878–1888: Walther Flemming and Eduard Strasburger describe chromosome behaviour during mitosis. 1883: Meiosis was described at the level of chromosomes, by Belgian zoologist Edouard van Beneden (1846–1910), in Ascaris (roundworm) eggs. 1883: German zoologist Wilhelm Roux (1850–1924) realised the significance of the linear structure of chromosomes. Their splitting into two equal longitudinal halves meant each daughter cell got the same chromosome complement. Therefore, chromosomes were the bearers of heredity. 1889: Dutch botanist Hugo de Vries suggests that ""inheritance of specific traits in organisms comes in particles"", naming such particles (pan)genes. 1890: The significance of meiosis for reproduction and inheritance was described in 1890 by German biologist August Weismann (1834–1914). He noted that two cell divisions were necessary to turn one diploid cell into four haploid cells if the number of chromosomes was to be maintained. 1902–1904: Theodor Boveri (1862–1915), a German biologist, in a series of papers, drew attention to the correspondence between the behaviour of chromosomes and the results obtained by Mendel. He said that chromosomes were ""independent entities which keep their independence even in the resting nucleus... What comes out of the nucleus is what goes into it"". 1903: Walter Sutton suggested that chromosomes, which segregate in a Mendelian fashion, are hereditary units. Edmund B. Wilson (1856–1939), Sutton's teacher, was the author of one of the most famous text-books in biology. Wilson called this idea the Sutton–Boveri hypothesis.At this point, discoveries in cytology merged with the rediscovered ideas of Mendel to make a fusion called cytogenetics, (cyto  cell; genetics  heredity) which has continued to the present day.  Rediscovery of Mendel's work  During the 1890s several biologists began doing experiments on breeding. and soon Mendel's results were duplicated, even before his papers were read. Carl Correns and Hugo de Vries were the main rediscoverers of Mendel's writings and laws. Both acknowledged Mendel's priority, although it is probable that de Vries did not understand his own results until after reading Mendel. Though Erich von Tschermak was originally also credited with rediscovery, this is no longer accepted because he did not understand Mendel's laws. Though de Vries later lost interest in Mendelism, other biologists built genetics into a science.Mendel's results were replicated, and genetic linkage soon worked out. William Bateson perhaps did the most in the early days to publicise Mendel's theory. The word genetics, and other terminology, originated with Bateson.Mendel's experimental results were later the object of some debate. Fisher analysed the results of the F2 (second filial) ratio and found them to be implausibly close to the exact ratio of 3 to 1. It is sometimes suggested that Mendel may have censored his results, and that his seven traits each occur on a separate chromosome pair, an extremely unlikely occurrence if they were chosen at random. In fact, the genes Mendel studied occurred in only four linkage groups, and only one gene pair (out of 21 possible) is close enough to show deviation from independent assortment; this is not a pair that Mendel studied.  Tools of genetics   Mutations  During the process of DNA replication, errors sometimes occur. These errors, called mutations, can have an effect on the phenotype of an organism. In turn, that usually has an effect on the organism's fitness, its ability to live and reproduce successfully. Error rates are usually very low—1 error in every 10–100 million bases—due to the ""proofreading"" ability of DNA polymerases. Error rates are a thousandfold higher in many viruses. Because they rely on DNA and RNA polymerases which lack proofreading ability, they get higher mutation rates. Processes that increase the rate of changes in DNA are called mutagenic. Mutagenic chemicals increase errors in DNA replication, often by interfering with the structure of base-pairing, while UV radiation induces mutations by causing damage to the DNA structure. Chemical damage to DNA occurs naturally as well, and cells use DNA repair mechanisms to repair mismatches and breaks in DNA—nevertheless, the repair sometimes fails to return the DNA to its original sequence. In organisms which use chromosomal crossovers to exchange DNA and recombine genes, errors in alignment during meiosis can also cause mutations. Errors in crossover are especially likely when similar sequences cause partner chromosomes to adopt a mistaken alignment; this makes some regions in genomes more prone to mutating in this way. These errors create large structural changes in DNA sequence—duplications, inversions or deletions of entire regions, or the accidental exchanging of whole parts between different chromosomes (called translocation).  Punnett squares  Developed by Reginald Punnett, Punnett squares are used by biologists to determine the probability of offspring having a particular genotype. If B represents the allele for having black hair and b represents the allele for having white hair, the offspring of two Bb parents would have a 25% probability of having two white hair alleles (bb), 50% of having one of each (Bb), and 25% of having only black hair alleles (BB).  Pedigree chart  Geneticists (biologists who study genetics) use pedigree charts to record traits of people in a family. Using these charts, geneticists can study how a trait is inherited from person to person. Geneticists can also use pedigree charts to predict how traits will be passed to future children in a family. For instance, genetic counselors are professionals who work with families who might be affected by genetic diseases. As part of their job, they create pedigree charts for the family, which can be used to study how the disease might be inherited.  Twin studies  Since human beings are not bred experimentally, human genetics must be studied by other means. One recent way is by studying the human genome. Another way, older by many years, is to study twins. Identical twins are natural clones. They carry the same genes, they may be used to investigate how much heredity contributes to individual people. Studies with twins have been quite interesting. If we make a list of characteristic traits, we find that they vary in how much they owe to heredity. For example: Eye colour: entirely inherited Weight, height: partly inherited, partly environmental Which language a person speaks: entirely environmental.The way the studies are done is like this. Take a group of identical twins and a group of fraternal twins. Measure them for various traits. Do a statistical analysis (such as analysis of variance). This tells you to what extent the trait is inherited. Those traits which are partly inherited will be significantly more similar in identical twins. Studies like this may be carried further, by comparing identical twins brought up together with identical twins brought up in different circumstances. That gives a handle on how much circumstances can alter the outcomes of genetically identical people. The person who first did twin studies was Francis Galton, Darwin's half-cousin, who was a founder of statistics. His method was to trace twins through their life-history, making many kinds of measurement. Unfortunately, though he knew about mono and dizygotic twins, he did not appreciate the real genetic difference. Twin studies of the modern kind did not appear until the 1920s.  Genetics of prokaryotes and viruses  The genetics of bacteria, archaea and viruses is a major field of research. Bacteria mostly divide by asexual cell division, but do have a kind of sex by horizontal gene transfer. Bacterial conjugation, transduction and transformation are their methods. In addition, the complete DNA sequence of many bacteria, archaea and viruses is now known. Although many bacteria were given generic and specific names, like Staphylococcus aureus, the whole idea of a species is rather meaningless for an organism which does not have sexes and crossing-over of chromosomes. Instead, these organisms have strains, and that is how they are identified in the laboratory.  Genes and development   Gene expression  Gene expression is how the heritable information in a gene, the sequence of DNA base pairs, is made into a functional gene product, such as protein or RNA. The basic idea is that DNA is transcribed into RNA, which is then translated into proteins. Proteins make many of the structures and all the enzymes in a cell or organism. Several steps in the gene expression process may be modulated (tuned). This includes both the transcription and translation stages, and the final folded state of a protein. Gene regulation switches genes on and off, and so controls cell differentiation, and morphogenesis. Gene regulation may also serve as a basis for evolutionary change: control of the timing, location, and amount of gene expression can have a profound effect on the development of the organism. The expression of a gene may vary a lot in different tissues. This is called pleiotropism, a widespread phenomenon in genetics. Alternative splicing is a modern discovery of great importance. It is a process where from a single gene a large number of variant proteins can be assembled. One particular Drosophila gene (DSCAM) can be alternatively spliced into 38,000 different mRNA molecules.  Epigenetics & control of development  Epigenetics is the study of changes in gene activity which are not caused by changes in the DNA sequence. It is the study of gene expression, the way genes bring about their phenotypic effects.These changes in gene activity may stay for the remainder of the cell's life and may also last for many generations of cells, through cell divisions. However, there is no change in the underlying DNA sequence of the organism. Instead, non-hereditary factors cause the organism's genes to behave (express themselves) differently.Hox genes are a complex of genes whose proteins bind to the regulatory regions of target genes. The target genes then activate or repress cell processes to direct the final development of the organism.  Extranuclear inheritance  There are some kinds of heredity which happen outside the cell nucleus. Normal inheritance is from both parents via the chromosomes in the nucleus of a fertilised egg cell. There are some kinds of inheritance other than this.  Organelle heredity  Mitochondria and chloroplasts carry some DNA of their own. Their make-up is decided by genes in the chromosomes and genes in the organelle. Carl Correns discovered an example in 1908. The four o'clock plant, Mirabilis jalapa, has leaves which may be white, green or variegated. Correns discovered the pollen had no influence on this inheritance. The colour is decided by genes in the chloroplasts.  Infectious heredity  This is caused by a symbiotic or parasitic relationship with a microorganism.  Maternal effect  In this case nuclear genes in the female gamete are transcribed. The products accumulate in the egg cytoplasm, and have an effect on the early development of the fertilised egg. The coiling of a snail, Limnaea peregra, is determined like this. Right-handed shells are genotypes Dd or dd, while left-handed shells are dd. The most important example of maternal effect is in Drosophila melanogaster. The protein product maternal-effect genes activate other genes, which in turn activate still more genes. This work won the Nobel Prize in Physiology or Medicine for 1995.  Aspects of modern genetics  Much modern research uses a mixture of genetics, cell biology and molecular biology. Topics which have been the subject of Nobel Prizes in either chemistry or physiology include: Alternative splicing, where one gene codes for a variety of related protein products. Genomics, the sequence and analysis the function and structure of genomes. Genetic engineering, the changing of an organism's genome using biotechnology. Mobile genetic elements, types of DNA which can change position in the genome. Horizontal gene transfer, where an organism gets genetic material from another organism without being the offspring of that organism. Epigenetics, the study of changes in gene activity which are not caused by changes in the DNA sequence. CRISPR: In 2012, Jennifer Doudna and Emmanuelle Charpentier suggested that CRISPR-Cas9 (enzymes from bacteria which control microbial immunity) could be used to edit genomes. This has been called one of the most significant discoveries in the history of biology. The two scientists shared the 2020 Nobel Prize in Chemistry.  Genetics of human behaviour  Many well-known disorders of human behaviour have a genetic component. This means that their inheritance partly causes the behaviour, or makes it more likely the problem would occur. Examples include: Autism ADHD (attention deficit disorder) Drug use and abuse Risk taking SchizophreniaAlso, normal behaviour is also heavily influenced by heredity: Learning and cognitive ability Personality.  Related pages  ENCODE: the complete analysis of the human genome Gene therapy Epigenetics  References   Standard works  Alberts B, Bray D, Hopkin K, Johnson A, Lewis J, Raff M, Roberts K, Walter P. 2013. Essential cell biology, 4th Edition. Garland Science. ISBN 978-1-317-80627-1. Griffiths A.J.H. & others 2000. An introduction to genetic analysis. 7th ed, Freeman, New York. ISBN 0-7167-3520-2 [7] Hartl D. & Jones E. 2005. Genetics: analysis of genes and genomes. 6th ed, Jones & Bartlett. ISBN 0-7637-1511-5. King R.C; Mulligan P.K. & Stansfield W.D. 2013. A dictionary of genetics. 8th ed, Oxford University Press. ISBN 978-0-19-976644-4 Klug, William S. et al 2012. Concepts of genetics. 10th ed, Pearson. ISBN 0-321-79578-4. Lodish H, Berk A, Zipursky LS, Matsudaira P, Baltimore D, Darnell J(2000. Molecular Cell Biology. 4th ed, New York: Scientific American Books. ISBN 978-0-7167-3136-8  Works on genetic manipulation  Jennifer A. Doudna and Samuel H. Sternberg. 2017. A Crack in Creation: gene editing and the unthinkable power to control evolution. Houghton Mifflin Harcourt. Carey, Nessa 2019. Hacking the code of life: how gene editing will write our futures. London: Icon Books. ISBN 978-1-78578-625-9."
"In biology, the word gene (from Greek: γένος, génos; meaning generation or birth or gender) can have several different meanings. The Mendelian gene is a basic unit of heredity and the molecular gene is a sequence of nucleotides in DNA that is transcribed to produce a functional RNA. There are two types of molecular genes: protein-coding genes and noncoding genes.During gene expression, the DNA is first copied into RNA. The RNA can be directly functional or be the intermediate template for a protein that performs a function. (Some viruses have an RNA genome so the genes are made of RNA that may function directly without being copied into RNA. This is an exception to the strict definition of a gene described above.) The transmission of genes to an organism's offspring is the basis of the inheritance of phenotypic traits. These genes make up different DNA sequences called genotypes. Genotypes along with environmental and developmental factors determine what the phenotypes will be. Most biological traits are under the influence of polygenes (many different genes) as well as gene–environment interactions. Some genetic traits are instantly visible, such as eye color or the number of limbs, and some are not, such as blood type, the risk for specific diseases, or the thousands of basic biochemical processes that constitute life. A gene can acquire mutations in their sequence, leading to different variants, known as alleles, in the population. These alleles encode slightly different versions of a gene, which may cause different phenotypical traits. Usage of the term ""having a gene"" (e.g., ""good genes,"" ""hair color gene"") typically refers to containing a different allele of the same, shared gene. Genes evolve due to natural selection / survival of the fittest and genetic drift of the alleles. The term gene was introduced by Danish botanist, plant physiologist and geneticist Wilhelm Johannsen in 1909. It is inspired by the Ancient Greek: γόνος, gonos, that means offspring and procreation.  Definitions  There are many different ways to use the term ""gene"" based on different aspects of their inheritance, selection, biological function, or molecular structure but most of these definitions fall into two categories, the Mendelian gene or the molecular gene.The Mendelian gene is the classical gene of genetics and it refers to any heritable trait. This is the gene described in ""The Selfish Gene."" More thorough discussions of this version of a gene can be found in the articles on Genetics and Gene-centered view of evolution. The molecular gene definition is more commonly used across biochemistry, molecular biology, and most of genetics — the gene that's described in terms of DNA sequence. There are many different definitions of this gene — some of which are misleading or incorrect.Very early work in the field that became molecular genetics suggested the concept that one gene makes one protein (originally 'one gene - one enzyme'). However, genes that produce repressor RNAs were proposed in the 1950s and by the 1960s, textbooks were using molecular gene definitions that included those that specified functional RNA molecules such as ribosomal RNA and tRNA (noncoding genes) as well as protein-coding genes.This idea of two kinds of genes is still part of the definition of a gene in most textbooks. For example, ""The primary function of the genome is to produce RNA molecules. Selected portions of the DNA nucleotide sequence are copied into a corresponding RNA nucleotide sequence, which either encodes a protein (if it is an mRNA) or forms a 'structural' RNA, such as a transfer RNA (tRNA) or ribosomal RNA (rRNA) molecule. Each region of the DNA helix that produces a functional RNA molecule constitutes a gene.""""We define a gene as a DNA sequence that is transcribed. This definition includes genes that do not encode proteins (not all transcripts are messenger RNA). The definition normally excludes regions of the genome that control transcription but are not themselves transcribed. We will encounter some exceptions to our definition of a gene - surprisingly, there is no definition that is entirely satisfactory.""""A gene is a DNA sequence that codes for a diffusible product. This product may be protein (as is the case in the majority of genes) or may be RNA (as is the case of genes that code for tRNA and rRNA). The crucial feature is that the product diffuses away from its site of synthesis to act elsewhere.""The important parts of such definitions are: (1) that a gene corresponds to a transcription unit; (2) that genes produce both mRNA and noncoding RNAs; and (3) regulatory sequences control gene expression but are not part of the gene itself. However, there's one other important part of the definition and it is emphasized in Kostas Kampourakis' book ""Making Sense of Genes."" ""Therefore in this book I will consider genes as DNA sequences encoding information for functional products, be it proteins or RNA molecules. With 'encoding information,' I mean that the DNA sequence is used as a template for the production of an RNA molecule or a protein that performs some function.'The emphasis on function is essential because there are stretches of DNA that produce non-functional transcripts and they don't qualify as genes. These include obvious examples such as transcribed pseudogenes as well as less obvious examples such as junk RNA produced as noise due to transcription errors. In order to qualify as a true gene, by this definition, one has to prove that the transcript has a biological function.Early speculations on the size of a typical gene were based on high resolution genetic mapping and on the size of proteins and RNA molecules. A length of 1500 base pairs seemed reasonable at the time (1965). This was based on the idea that the gene was the DNA that was directly responsible for production of the functional product. The discovery of introns in the 1970s meant that many eukaryotic genes were much larger than the size of the functional product would imply. Typical mammalian protein-coding genes, for example, are about 62,000 base pairs in length (transcribed region) and since there are about 20,000 of them they occupy about 35-40% of the mammalian genome (including the human genome).In spite of the fact that both protein-coding genes and noncoding genes have been known for more than 50 years, there are still a number of textbooks, websites, and scientific publications that define a gene as a DNA sequence that specifies a protein. In other words, the definition is restricted to protein-coding genes. Here's an example from a recent article in American Scientist. ... to truly assess the potential significance of de novo genes, we relied on a strict definition of the word ""gene"" with which nearly every expert can agree. First, in order for a nucleotide sequence to be considered a true gene, an open reading frame (ORF) must be present. The ORF can be thought of as the ""gene itself""; it begins with a starting mark common for every gene and ends with one of three possible finish line signals. One of the key enzymes in this process, the RNA polymerase, zips along the strand of DNA like a train on a monorail, transcribing it into its messenger RNA form. This point brings us to our second important criterion: A true gene is one that is both transcribed and translated. That is, a true gene is first used as a template to make transient messenger RNA, which is then translated into a protein.This restricted definition is so common that it has spawned many recent articles that criticize this ""standard definition"" and call for a new expanded definition that includes noncoding genes. However, this so-called ""new"" definition has been around for more than half a century and it's not clear why some modern writers are ignoring noncoding genes.Although some definitions can be more broadly applicable than others, the fundamental complexity of biology means that no definition of a gene can capture all aspects perfectly. Not all genomes are DNA (e.g. RNA viruses), bacterial operons are multiple protein-coding regions transcribed into single large mRNAs, alternative splicing enables a single genomic region to encode multiple district products and trans-splicing concatenates mRNAs from shorter coding sequence across the genome. Since molecular definitions exclude elements such as introns, promotors and other regulatory regions, these are instead thought of as 'associated' with the gene and affect its function. An even broader operational definition is sometimes used to encompass the complexity of these diverse phenomena, where a gene is defined as a union of genomic sequences encoding a coherent set of potentially overlapping functional products. This definition categorizes genes by their functional products (proteins or RNA) rather than their specific DNA loci, with regulatory elements classified as gene-associated regions.  History   Discovery of discrete inherited units  The existence of discrete inheritable units was first suggested by Gregor Mendel (1822–1884). From 1857 to 1864, in Brno, Austrian Empire (today's Czech Republic), he studied inheritance patterns in 8000 common edible pea plants, tracking distinct traits from parent to offspring. He described these mathematically as 2n combinations where n is the number of differing characteristics in the original peas. Although he did not use the term gene, he explained his results in terms of discrete inherited units that give rise to observable physical characteristics. This description prefigured Wilhelm Johannsen's distinction between genotype (the genetic material of an organism) and phenotype (the observable traits of that organism). Mendel was also the first to demonstrate independent assortment, the distinction between dominant and recessive traits, the distinction between a heterozygote and homozygote, and the phenomenon of discontinuous inheritance. Prior to Mendel's work, the dominant theory of heredity was one of blending inheritance, which suggested that each parent contributed fluids to the fertilization process and that the traits of the parents blended and mixed to produce the offspring. Charles Darwin developed a theory of inheritance he termed pangenesis, from Greek pan (""all, whole"") and genesis (""birth"") / genos (""origin""). Darwin used the term gemmule to describe hypothetical particles that would mix during reproduction. Mendel's work went largely unnoticed after its first publication in 1866, but was rediscovered in the late 19th century by Hugo de Vries, Carl Correns, and Erich von Tschermak, who (claimed to have) reached similar conclusions in their own research. Specifically, in 1889, Hugo de Vries published his book Intracellular Pangenesis, in which he postulated that different characters have individual hereditary carriers and that inheritance of specific traits in organisms comes in particles. De Vries called these units ""pangenes"" (Pangens in German), after Darwin's 1868 pangenesis theory. Twenty years later, in 1909, Wilhelm Johannsen introduced the term 'gene' and in 1906, William Bateson, that of 'genetics' while Eduard Strasburger, amongst others, still used the term 'pangene' for the fundamental physical and functional unit of heredity.: Translator's preface, viii  Discovery of DNA  Advances in understanding genes and inheritance continued throughout the 20th century. Deoxyribonucleic acid (DNA) was shown to be the molecular repository of genetic information by experiments in the 1940s to 1950s. The structure of DNA was studied by Rosalind Franklin and Maurice Wilkins using X-ray crystallography, which led James D. Watson and Francis Crick to publish a model of the double-stranded DNA molecule whose paired nucleotide bases indicated a compelling hypothesis for the mechanism of genetic replication.In the early 1950s the prevailing view was that the genes in a chromosome acted like discrete entities arranged like beads on a string. The experiments of Benzer using mutants defective in the rII region of bacteriophage T4 (1955–1959) showed that individual genes have a simple linear structure and are likely to be equivalent to a linear section of DNA.Collectively, this body of research established the central dogma of molecular biology, which states that proteins are translated from RNA, which is transcribed from DNA. This dogma has since been shown to have exceptions, such as reverse transcription in retroviruses. The modern study of genetics at the level of DNA is known as molecular genetics. In 1972, Walter Fiers and his team were the first to determine the sequence of a gene: that of Bacteriophage MS2 coat protein. The subsequent development of chain-termination DNA sequencing in 1977 by Frederick Sanger improved the efficiency of sequencing and turned it into a routine laboratory tool. An automated version of the Sanger method was used in early phases of the Human Genome Project.  Modern synthesis and its successors  The theories developed in the early 20th century to integrate Mendelian genetics with Darwinian evolution are called the modern synthesis, a term introduced by Julian Huxley.This view of evolution was emphasized by George C. Williams' gene-centric view of evolution. He proposed that the Mendelian gene is a unit of natural selection with the definition: ""that which segregates and recombines with appreciable frequency."": 24 Related ideas emphasizing the centrality of Mendelian genes and the importance of natural selection in evolution were popularized by Richard Dawkins.The development of the neutral theory of evolution in the late 1960s led to the recognition that random genetic drift is a major player in evolution and that neutral theory should be the null hypothesis of molecular evolution. This led to the construction of phylogenetic trees and the development of the molecular clock, which is the basis of all dating techniques using DNA sequences. These techniques are not confined to molecular gene sequences but can be used on all DNA segments in the genome.  Molecular basis   DNA  The vast majority of organisms encode their genes in long strands of DNA (deoxyribonucleic acid). DNA consists of a chain made from four types of nucleotide subunits, each composed of: a five-carbon sugar (2-deoxyribose), a phosphate group, and one of the four bases adenine, cytosine, guanine, and thymine.: 2.1 Two chains of DNA twist around each other to form a DNA double helix with the phosphate-sugar backbone spiraling around the outside, and the bases pointing inwards with adenine base pairing to thymine and guanine to cytosine. The specificity of base pairing occurs because adenine and thymine align to form two hydrogen bonds, whereas cytosine and guanine form three hydrogen bonds. The two strands in a double helix must, therefore, be complementary, with their sequence of bases matching such that the adenines of one strand are paired with the thymines of the other strand, and so on.: 4.1 Due to the chemical composition of the pentose residues of the bases, DNA strands have directionality. One end of a DNA polymer contains an exposed hydroxyl group on the deoxyribose; this is known as the 3' end of the molecule. The other end contains an exposed phosphate group; this is the 5' end. The two strands of a double-helix run in opposite directions. Nucleic acid synthesis, including DNA replication and transcription occurs in the 5'→3' direction, because new nucleotides are added via a dehydration reaction that uses the exposed 3' hydroxyl as a nucleophile.: 27.2 The expression of genes encoded in DNA begins by transcribing the gene into RNA, a second type of nucleic acid that is very similar to DNA, but whose monomers contain the sugar ribose rather than deoxyribose. RNA also contains the base uracil in place of thymine. RNA molecules are less stable than DNA and are typically single-stranded. Genes that encode proteins are composed of a series of three-nucleotide sequences called codons, which serve as the ""words"" in the genetic ""language"". The genetic code specifies the correspondence during protein translation between codons and amino acids. The genetic code is nearly the same for all known organisms.: 4.1  Chromosomes  The total complement of genes in an organism or cell is known as its genome, which may be stored on one or more chromosomes. A chromosome consists of a single, very long DNA helix on which thousands of genes are encoded.: 4.2 The region of the chromosome at which a particular gene is located is called its locus. Each locus contains one allele of a gene; however, members of a population may have different alleles at the locus, each with a slightly different gene sequence. The majority of eukaryotic genes are stored on a set of large, linear chromosomes. The chromosomes are packed within the nucleus in complex with storage proteins called histones to form a unit called a nucleosome. DNA packaged and condensed in this way is called chromatin.: 4.2 The manner in which DNA is stored on the histones, as well as chemical modifications of the histone itself, regulate whether a particular region of DNA is accessible for gene expression. In addition to genes, eukaryotic chromosomes contain sequences involved in ensuring that the DNA is copied without degradation of end regions and sorted into daughter cells during cell division: replication origins, telomeres and the centromere.: 4.2 Replication origins are the sequence regions where DNA replication is initiated to make two copies of the chromosome. Telomeres are long stretches of repetitive sequences that cap the ends of the linear chromosomes and prevent degradation of coding and regulatory regions during DNA replication. The length of the telomeres decreases each time the genome is replicated and has been implicated in the aging process. The centromere is required for binding spindle fibres to separate sister chromatids into daughter cells during cell division.: 18.2 Prokaryotes (bacteria and archaea) typically store their genomes on a single large, circular chromosome. Similarly, some eukaryotic organelles contain a remnant circular chromosome with a small number of genes.: 14.4 Prokaryotes sometimes supplement their chromosome with additional small circles of DNA called plasmids, which usually encode only a few genes and are transferable between individuals. For example, the genes for antibiotic resistance are usually encoded on bacterial plasmids and can be passed between individual cells, even those of different species, via horizontal gene transfer.Whereas the chromosomes of prokaryotes are relatively gene-dense, those of eukaryotes often contain regions of DNA that serve no obvious function. Simple single-celled eukaryotes have relatively small amounts of such DNA, whereas the genomes of complex multicellular organisms, including humans, contain an absolute majority of DNA without an identified function. This DNA has often been referred to as ""junk DNA"". However, more recent analyses suggest that, although protein-coding DNA makes up barely 2% of the human genome, about 80% of the bases in the genome may be expressed, so the term ""junk DNA"" may be a misnomer.  Structure and function   Structure  The structure of a protein-coding gene consists of many elements of which the actual protein coding sequence is often only a small part. These include introns and untranslated regions of the mature mRNA. Noncoding genes can also contain introns that are removed during processing to produce the mature functional RNA. All genes are associated with regulatory sequences that are required for their expression. First, genes require a promoter sequence. The promoter is recognized and bound by transcription factors that recruit and help RNA polymerase bind to the region to initiate transcription.: 7.1 The recognition typically occurs as a consensus sequence like the TATA box. A gene can have more than one promoter, resulting in messenger RNAs (mRNA) that differ in how far they extend in the 5' end. Highly transcribed genes have ""strong"" promoter sequences that form strong associations with transcription factors, thereby initiating transcription at a high rate. Others genes have ""weak"" promoters that form weak associations with transcription factors and initiate transcription less frequently.: 7.2 Eukaryotic promoter regions are much more complex and difficult to identify than prokaryotic promoters.: 7.3 Additionally, genes can have regulatory regions many kilobases upstream or downstream of the gene that alter expression. These act by binding to transcription factors which then cause the DNA to loop so that the regulatory sequence (and bound transcription factor) become close to the RNA polymerase binding site. For example, enhancers increase transcription by binding an activator protein which then helps to recruit the RNA polymerase to the promoter; conversely silencers bind repressor proteins and make the DNA less available for RNA polymerase.The mature messenger RNA produced from protein-coding genes contains untranslated regions at both ends which contain binding sites for ribosomes, RNA-binding proteins, miRNA, as well as terminator, and start and stop codons. In addition, most eukaryotic open reading frames contain untranslated introns, which are removed and exons, which are connected together in a process known as RNA splicing. Finally, the ends of gene transcripts are defined by cleavage and polyadenylation (CPA) sites, where newly produced pre-mRNA gets cleaved and a string of ~200 adenosine monophosphates is added at the 3' end. The poly(A) tail protects mature mRNA from degradation and has other functions, affecting translation, localization, and transport of the transcript from the nucleus. Splicing, followed by CPA, generate the final mature mRNA, which encodes the protein or RNA product. Although the general mechanisms defining locations of human genes are known, identification of the exact factors regulating these cellular processes is an area of active research. For example, known sequence features in the 3'-UTR can only explain half of all human gene ends.Many noncoding genes in eukaryotes have different transcription termination mechanisms and they do not have pol(A) tails. Many prokaryotic genes are organized into operons, with multiple protein-coding sequences that are transcribed as a unit. The genes in an operon are transcribed as a continuous messenger RNA, referred to as a polycistronic mRNA. The term cistron in this context is equivalent to gene. The transcription of an operon's mRNA is often controlled by a repressor that can occur in an active or inactive state depending on the presence of specific metabolites. When active, the repressor binds to a DNA sequence at the beginning of the operon, called the operator region, and represses transcription of the operon; when the repressor is inactive transcription of the operon can occur (see e.g. Lac operon). The products of operon genes typically have related functions and are involved in the same regulatory network.: 7.3  Complexity  Though many genes have simple structures, as with much of biology, others can be quite complex or represent unusual edge-cases. Eukaryotic genes often have introns are often much larger than their exons, and those introns can even have other genes nested inside them. Associated enhancers may be many kilobase away, or even on entirely different chromosomes operating via physical contact between two chromosomes. A single gene can encode multiple different functional products by alternative splicing, and conversely gene may be split across chromosomes but those transcripts are concatenated back together into a functional sequence by trans-splicing. It is also possible for overlapping genes to share some of their DNA sequence, either on opposite strands or the same strand (in a different reading frame, or even the same reading frame).  Gene expression  In all organisms, two steps are required to read the information encoded in a gene's DNA and produce the protein it specifies. First, the gene's DNA is transcribed to messenger RNA (mRNA).: 6.1 Second, that mRNA is translated to protein.: 6.2 RNA-coding genes must still go through the first step, but are not translated into protein. The process of producing a biologically functional molecule of either RNA or protein is called gene expression, and the resulting molecule is called a gene product.  Genetic code  The nucleotide sequence of a gene's DNA specifies the amino acid sequence of a protein through the genetic code. Sets of three nucleotides, known as codons, each correspond to a specific amino acid.: 6 The principle that three sequential bases of DNA code for each amino acid was demonstrated in 1961 using frameshift mutations in the rIIB gene of bacteriophage T4 (see Crick, Brenner et al. experiment). Additionally, a ""start codon"", and three ""stop codons"" indicate the beginning and end of the protein coding region. There are 64 possible codons (four possible nucleotides at each of three positions, hence 43 possible codons) and only 20 standard amino acids; hence the code is redundant and multiple codons can specify the same amino acid. The correspondence between codons and amino acids is nearly universal among all known living organisms.  Transcription  Transcription produces a single-stranded RNA molecule known as messenger RNA, whose nucleotide sequence is complementary to the DNA from which it was transcribed.: 6.1 The mRNA acts as an intermediate between the DNA gene and its final protein product. The gene's DNA is used as a template to generate a complementary mRNA. The mRNA matches the sequence of the gene's DNA coding strand because it is synthesised as the complement of the template strand. Transcription is performed by an enzyme called an RNA polymerase, which reads the template strand in the 3' to 5' direction and synthesizes the RNA from 5' to 3'. To initiate transcription, the polymerase first recognizes and binds a promoter region of the gene. Thus, a major mechanism of gene regulation is the blocking or sequestering the promoter region, either by tight binding by repressor molecules that physically block the polymerase or by organizing the DNA so that the promoter region is not accessible.: 7 In prokaryotes, transcription occurs in the cytoplasm; for very long transcripts, translation may begin at the 5' end of the RNA while the 3' end is still being transcribed. In eukaryotes, transcription occurs in the nucleus, where the cell's DNA is stored. The RNA molecule produced by the polymerase is known as the primary transcript and undergoes post-transcriptional modifications before being exported to the cytoplasm for translation. One of the modifications performed is the splicing of introns which are sequences in the transcribed region that do not encode a protein. Alternative splicing mechanisms can result in mature transcripts from the same gene having different sequences and thus coding for different proteins. This is a major form of regulation in eukaryotic cells and also occurs in some prokaryotes.: 7.5  Translation  Translation is the process by which a mature mRNA molecule is used as a template for synthesizing a new protein.: 6.2 Translation is carried out by ribosomes, large complexes of RNA and protein responsible for carrying out the chemical reactions to add new amino acids to a growing polypeptide chain by the formation of peptide bonds. The genetic code is read three nucleotides at a time, in units called codons, via interactions with specialized RNA molecules called transfer RNA (tRNA). Each tRNA has three unpaired bases known as the anticodon that are complementary to the codon it reads on the mRNA. The tRNA is also covalently attached to the amino acid specified by the complementary codon. When the tRNA binds to its complementary codon in an mRNA strand, the ribosome attaches its amino acid cargo to the new polypeptide chain, which is synthesized from amino terminus to carboxyl terminus. During and after synthesis, most new proteins must fold to their active three-dimensional structure before they can carry out their cellular functions.: 3  Regulation  Genes are regulated so that they are expressed only when the product is needed, since expression draws on limited resources.: 7 A cell regulates its gene expression depending on its external environment (e.g. available nutrients, temperature and other stresses), its internal environment (e.g. cell division cycle, metabolism, infection status), and its specific role if in a multicellular organism. Gene expression can be regulated at any step: from transcriptional initiation, to RNA processing, to post-translational modification of the protein. The regulation of lactose metabolism genes in E. coli (lac operon) was the first such mechanism to be described in 1961.  RNA genes  A typical protein-coding gene is first copied into RNA as an intermediate in the manufacture of the final protein product.: 6.1 In other cases, the RNA molecules are the actual functional products, as in the synthesis of ribosomal RNA and transfer RNA. Some RNAs known as ribozymes are capable of enzymatic function, while others such as microRNAs and riboswitches have regulatory roles. The DNA sequences from which such RNAs are transcribed are known as non-coding RNA genes.Some viruses store their entire genomes in the form of RNA, and contain no DNA at all. Because they use RNA to store genes, their cellular hosts may synthesize their proteins as soon as they are infected and without the delay in waiting for transcription. On the other hand, RNA retroviruses, such as HIV, require the reverse transcription of their genome from RNA into DNA before their proteins can be synthesized.  Inheritance  Organisms inherit their genes from their parents. Asexual organisms simply inherit a complete copy of their parent's genome. Sexual organisms have two copies of each chromosome because they inherit one complete set from each parent.: 1  Mendelian inheritance  According to Mendelian inheritance, variations in an organism's phenotype (observable physical and behavioral characteristics) are due in part to variations in its genotype (particular set of genes). Each gene specifies a particular trait with a different sequence of a gene (alleles) giving rise to different phenotypes. Most eukaryotic organisms (such as the pea plants Mendel worked on) have two alleles for each trait, one inherited from each parent.: 20 Alleles at a locus may be dominant or recessive; dominant alleles give rise to their corresponding phenotypes when paired with any other allele for the same trait, whereas recessive alleles give rise to their corresponding phenotype only when paired with another copy of the same allele. If you know the genotypes of the organisms, you can determine which alleles are dominant and which are recessive. For example, if the allele specifying tall stems in pea plants is dominant over the allele specifying short stems, then pea plants that inherit one tall allele from one parent and one short allele from the other parent will also have tall stems. Mendel's work demonstrated that alleles assort independently in the production of gametes, or germ cells, ensuring variation in the next generation. Although Mendelian inheritance remains a good model for many traits determined by single genes (including a number of well-known genetic disorders) it does not include the physical processes of DNA replication and cell division.  DNA replication and cell division  The growth, development, and reproduction of organisms relies on cell division; the process by which a single cell divides into two usually identical daughter cells. This requires first making a duplicate copy of every gene in the genome in a process called DNA replication.: 5.2 The copies are made by specialized enzymes known as DNA polymerases, which ""reads"" one strand of the double-helical DNA, known as the template strand, and synthesize a new complementary strand. Because the DNA double helix is held together by base pairing, the sequence of one strand completely specifies the sequence of its complement; hence only one strand needs to be read by the enzyme to produce a faithful copy. The process of DNA replication is semiconservative; that is, the copy of the genome inherited by each daughter cell contains one original and one newly synthesized strand of DNA.: 5.2 The rate of DNA replication in living cells was first measured as the rate of phage T4 DNA elongation in phage-infected E. coli and found to be impressively rapid. During the period of exponential DNA increase at 37 °C, the rate of elongation was 749 nucleotides per second. After DNA replication is complete, the cell must physically separate the two copies of the genome and divide into two distinct membrane-bound cells.: 18.2 In prokaryotes (bacteria and archaea) this usually occurs via a relatively simple process called binary fission, in which each circular genome attaches to the cell membrane and is separated into the daughter cells as the membrane invaginates to split the cytoplasm into two membrane-bound portions. Binary fission is extremely fast compared to the rates of cell division in eukaryotes. Eukaryotic cell division is a more complex process known as the cell cycle; DNA replication occurs during a phase of this cycle known as S phase, whereas the process of segregating chromosomes and splitting the cytoplasm occurs during M phase.: 18.1  Molecular inheritance  The duplication and transmission of genetic material from one generation of cells to the next is the basis for molecular inheritance and the link between the classical and molecular pictures of genes. Organisms inherit the characteristics of their parents because the cells of the offspring contain copies of the genes in their parents' cells. In asexually reproducing organisms, the offspring will be a genetic copy or clone of the parent organism. In sexually reproducing organisms, a specialized form of cell division called meiosis produces cells called gametes or germ cells that are haploid, or contain only one copy of each gene.: 20.2 The gametes produced by females are called eggs or ova, and those produced by males are called sperm. Two gametes fuse to form a diploid fertilized egg, a single cell that has two sets of genes, with one copy of each gene from the mother and one from the father.: 20 During the process of meiotic cell division, an event called genetic recombination or crossing-over can sometimes occur, in which a length of DNA on one chromatid is swapped with a length of DNA on the corresponding homologous non-sister chromatid. This can result in reassortment of otherwise linked alleles.: 5.5 The Mendelian principle of independent assortment asserts that each of a parent's two genes for each trait will sort independently into gametes; which allele an organism inherits for one trait is unrelated to which allele it inherits for another trait. This is in fact only true for genes that do not reside on the same chromosome or are located very far from one another on the same chromosome. The closer two genes lie on the same chromosome, the more closely they will be associated in gametes and the more often they will appear together (known as genetic linkage). Genes that are very close are essentially never separated because it is extremely unlikely that a crossover point will occur between them.  Molecular evolution   Mutation  DNA replication is for the most part extremely accurate, however errors (mutations) do occur.: 7.6 The error rate in eukaryotic cells can be as low as 10−8 per nucleotide per replication, whereas for some RNA viruses it can be as high as 10−3. This means that each generation, each human genome accumulates 1–2 new mutations. Small mutations can be caused by DNA replication and the aftermath of DNA damage and include point mutations in which a single base is altered and frameshift mutations in which a single base is inserted or deleted. Either of these mutations can change the gene by missense (change a codon to encode a different amino acid) or nonsense (a premature stop codon). Larger mutations can be caused by errors in recombination to cause chromosomal abnormalities including the duplication, deletion, rearrangement or inversion of large sections of a chromosome. Additionally, DNA repair mechanisms can introduce mutational errors when repairing physical damage to the molecule. The repair, even with mutation, is more important to survival than restoring an exact copy, for example when repairing double-strand breaks.: 5.4 When multiple different alleles for a gene are present in a species's population it is called polymorphic. Most different alleles are functionally equivalent, however some alleles can give rise to different phenotypic traits. A gene's most common allele is called the wild type, and rare alleles are called mutants. The genetic variation in relative frequencies of different alleles in a population is due to both natural selection and genetic drift. The wild-type allele is not necessarily the ancestor of less common alleles, nor is it necessarily fitter. Most mutations within genes are neutral, having no effect on the organism's phenotype (silent mutations). Some mutations do not change the amino acid sequence because multiple codons encode the same amino acid (synonymous mutations). Other mutations can be neutral if they lead to amino acid sequence changes, but the protein still functions similarly with the new amino acid (e.g. conservative mutations). Many mutations, however, are deleterious or even lethal, and are removed from populations by natural selection. Genetic disorders are the result of deleterious mutations and can be due to spontaneous mutation in the affected individual, or can be inherited. Finally, a small fraction of mutations are beneficial, improving the organism's fitness and are extremely important for evolution, since their directional selection leads to adaptive evolution.: 7.6  Sequence homology  The relationship between genes can be measured by comparing the sequences of their DNA. If the level of similarity exceeds a minimum value, one can conclude that the genes descend from a common ancestor; they are homologous. Genes that are related by direct descent from a common ancestor are orthologous genes - they are usually found at the same locus in different species. Genes that are related as a result of a gene duplication event are parologous genes.It is often assumed that the functions of orthologous genes are more similar than those of paralogous genes, although the difference is minimal.  Origins of new genes  The most common source of new genes in eukaryotic lineages is gene duplication, which creates copy number variation of an existing gene in the genome. The resulting genes (paralogs) may then diverge in sequence and in function. Sets of genes formed in this way compose a gene family. Gene duplications and losses within a family are common and represent a major source of evolutionary biodiversity. Sometimes, gene duplication may result in a nonfunctional copy of a gene, or a functional copy may be subject to mutations that result in loss of function; such nonfunctional genes are called pseudogenes.: 7.6 ""Orphan"" genes, whose sequence shows no similarity to existing genes, are less common than gene duplicates. The human genome contains an estimate 18 to 60 genes with no identifiable homologs outside humans. Orphan genes arise primarily from either de novo emergence from previously non-coding sequence, or gene duplication followed by such rapid sequence change that the original relationship becomes undetectable. De novo genes are typically shorter and simpler in structure than most eukaryotic genes, with few if any introns. Over long evolutionary time periods, de novo gene birth may be responsible for a significant fraction of taxonomically restricted gene families.Horizontal gene transfer refers to the transfer of genetic material through a mechanism other than reproduction. This mechanism is a common source of new genes in prokaryotes, sometimes thought to contribute more to genetic variation than gene duplication. It is a common means of spreading antibiotic resistance, virulence, and adaptive metabolic functions. Although horizontal gene transfer is rare in eukaryotes, likely examples have been identified of protist and alga genomes containing genes of bacterial origin.  Genome  The genome is the total genetic material of an organism and includes both the genes and non-coding sequences. Eukaryotic genes can be annotated using FINDER.  Number of genes  The genome size, and the number of genes it encodes varies widely between organisms. The smallest genomes occur in viruses, and viroids (which act as a single non-coding RNA gene). Conversely, plants can have extremely large genomes, with rice containing >46,000 protein-coding genes. The total number of protein-coding genes (the Earth's proteome) is estimated to be 5 million sequences.Although the number of base-pairs of DNA in the human genome has been known since the 1950s, the estimated number of genes has changed over time as definitions of genes, and methods of detecting them have been refined. Initial theoretical predictions of the number of human genes in the 1960s and 1970s were based on mutation load estimates and the numbers of mRNAs and these estimates tended to be about 30,000 protein-coding genes. During the 1990s there were guesstimates of up to 100,000 genes and early data on detection of mRNAs (expressed sequence tags) suggested more than the traditional value of 30,000 genes that had been reported in the textbooks during the 1980s.The initial draft sequences of the human genome confirmed the earlier predictions of about 30,000 protein-coding genes however that estimate has fallen to about 19,000 with the ongoing GENCODE annotation project . The number of noncoding genes is not known with certainty but the latest estimates from Ensembl suggest 26,000 noncoding genes.  Essential genes  Essential genes are the set of genes thought to be critical for an organism's survival. This definition assumes the abundant availability of all relevant nutrients and the absence of environmental stress. Only a small portion of an organism's genes are essential. In bacteria, an estimated 250–400 genes are essential for Escherichia coli and Bacillus subtilis, which is less than 10% of their genes. Half of these genes are orthologs in both organisms and are largely involved in protein synthesis. In the budding yeast Saccharomyces cerevisiae the number of essential genes is slightly higher, at 1000 genes (~20% of their genes). Although the number is more difficult to measure in higher eukaryotes, mice and humans are estimated to have around 2000 essential genes (~10% of their genes). The synthetic organism, Syn 3, has a minimal genome of 473 essential genes and quasi-essential genes (necessary for fast growth), although 149 have unknown function.Essential genes include housekeeping genes (critical for basic cell functions) as well as genes that are expressed at different times in the organisms development or life cycle. Housekeeping genes are used as experimental controls when analysing gene expression, since they are constitutively expressed at a relatively constant level.  Genetic and genomic nomenclature  Gene nomenclature has been established by the HUGO Gene Nomenclature Committee (HGNC), a committee of the Human Genome Organisation, for each known human gene in the form of an approved gene name and symbol (short-form abbreviation), which can be accessed through a database maintained by HGNC. Symbols are chosen to be unique, and each gene has only one symbol (although approved symbols sometimes change). Symbols are preferably kept consistent with other members of a gene family and with homologs in other species, particularly the mouse due to its role as a common model organism.  Genetic engineering  Genetic engineering is the modification of an organism's genome through biotechnology. Since the 1970s, a variety of techniques have been developed to specifically add, remove and edit genes in an organism. Recently developed genome engineering techniques use engineered nuclease enzymes to create targeted DNA repair in a chromosome to either disrupt or edit a gene when the break is repaired. The related term synthetic biology is sometimes used to refer to extensive genetic engineering of an organism.Genetic engineering is now a routine research tool with model organisms. For example, genes are easily added to bacteria and lineages of knockout mice with a specific gene's function disrupted are used to investigate that gene's function. Many organisms have been genetically modified for applications in agriculture, industrial biotechnology, and medicine. For multicellular organisms, typically the embryo is engineered which grows into the adult genetically modified organism. However, the genomes of cells in an adult organism can be edited using gene therapy techniques to treat genetic diseases.  See also   References   Citations   Sources  Main textbookAlberts B, Johnson A, Lewis J, Raff M, Roberts K, Walter P (2002). Molecular Biology of the Cell (Fourth ed.). New York: Garland Science. ISBN 978-0-8153-3218-3. – A molecular biology textbook available free online through NCBI Bookshelf.  Further reading   External links ","Genes are parts of DNA. DNA is a molecule inside a cell that carries the instructions for making the proteins the cell will need. Each gene contains a single set of instructions. These instructions usually code for a particular protein. Humans have about 20,000 genes that code proteins and many more that are non-coding. Half of a person's genes come from the mother. The other half come from the father.  The definition  Originally: a hereditary unit which occupies a specific position (locus) on a chromosome. Other definitions are ways the gene showed itself: 1. A unit which has one or more specific effects on the phenotype of an organism; 2. A unit that can mutate to various alleles; 3. A unit which recombines with other such units.Modern definitions must take note of later discoveries. There are now two classes of genes:p173 1. genes that are transcribed into RNAs and are translated into polypeptide chains. 2. genes whose transcripts (tRNAs, rRNAs, snRNAs) are used directly. These are operators which serve as 'regulatory sequences' during transcription and translation of the DNA.""The building blocks of life.""  What genes do?  Genes are passed on from parent to child and are an important part of what decides how children look and act (their biological properties). Genes affect the way our bodies work, including how we look. Our eye, hair and skin color are decided by genes. It is said that genes cause genetic effects in our bodies. A gene may be dominant or recessive. These terms refer to the effect a gene has on the offspring who carry it in their genome. For example, let's say a mother only has genes for brown hair and a father only has genes for red hair. The child will inherit – receive – genes for red hair (from her father) and brown hair (from her mother). The brown hair gene is 'dominant' to the red hair gene. This means the child will have brown hair even though she has genes for both red and brown hair. This means only one dominant gene is needed for the child to receive that particular trait, while two recessive genes are needed for one. A recessive trait might stay hidden for many generations. Let us use the child from the last example. We will call her ""Mary"". Mary has brown hair but has genes for both red and brown hair. Let us say Mary grew up and married Tom. Tom also has brown hair, but like Mary one of his parents had red hair. This means Tom has genes for both red and brown hair. Mary and Tom would each have a chance of passing either brown or red hair genes to their children. This means that the children of Mary and Tom could have either red or brown hair. This explains why a person might look different from their parents, but look like their grandparents or great-grandparents.  Structure and function  The structure of a gene has many elements: the actual protein coding sequence is only a small part. There are DNA regions that are not transcribed as well as untranslated regions of the RNA.  Related pages  Allele#Dominance Sequence analysis Genetics ENCODE, the complete analysis of the human genome Gene therapy  References "
"A biopsy is a medical test commonly performed by a surgeon, interventional radiologist, or an interventional cardiologist. The process involves extraction of sample cells or tissues for examination to determine the presence or extent of a disease. The tissue is then fixed, dehydrated, embedded, sectioned, stained and mounted before it is generally examined under a microscope by a pathologist; it may also be analyzed chemically. When an entire lump or suspicious area is removed, the procedure is called an excisional biopsy. An incisional biopsy or core biopsy samples a portion of the abnormal tissue without attempting to remove the entire lesion or tumor. When a sample of tissue or fluid is removed with a needle in such a way that cells are removed without preserving the histological architecture of the tissue cells, the procedure is called a needle aspiration biopsy. Biopsies are most commonly performed for insight into possible cancerous or inflammatory conditions.  History  The Arab physician Abulcasis (1013–1107) developed one of the earliest diagnostic biopsies. He used a needle to puncture a goiter and then characterized the material.  Etymology  The term biopsy reflects the Greek words βίος bios, ""life,"" and ὄψις opsis, ""a sight.""The French dermatologist Ernest Besnier introduced the word biopsie to the medical community in 1879.  Medical use   Cancer  When cancer is suspected, a variety of biopsy techniques can be applied. An excisional biopsy is an attempt to remove an entire lesion. When the specimen is evaluated, in addition to diagnosis, the amount of uninvolved tissue around the lesion, the surgical margin of the specimen is examined to see if the disease has spread beyond the area biopsied. ""Clear margins"" or ""negative margins"" means that no disease was found at the edges of the biopsy specimen. ""Positive margins"" means that disease was found, and a wider excision may be needed, depending on the diagnosis.When intact removal is not indicated for a variety of reasons, a wedge of tissue may be taken in an incisional biopsy. In some cases, a sample can be collected by devices that ""bite"" a sample. A variety of sizes of needle can collect tissue in the lumen (core biopsy). Smaller diameter needles collect cells and cell clusters, fine needle aspiration biopsy.Pathologic examination of a biopsy can determine whether a lesion is benign or malignant, and can help differentiate between different types of cancer. In contrast to a biopsy that merely samples a lesion, a larger excisional specimen called a resection may come to a pathologist, typically from a surgeon attempting to eradicate a known lesion from a patient. For example, a pathologist would examine a mastectomy specimen, even if a previous nonexcisional breast biopsy had already established the diagnosis of breast cancer. Examination of the full mastectomy specimen would confirm the exact nature of the cancer (subclassification of tumor and histologic ""grading"") and reveal the extent of its spread (pathologic ""staging"").  Liquid biopsy  There are two types of liquid biopsy (which is not really a biopsy as they are blood tests that do not require a biopsy of tissue): circulating tumor cell assays or cell-free circulating tumor DNA tests. These methods provide a non-invasive alternative to repeat invasive biopsies to monitor cancer treatment, test available drugs against the circulating tumor cells, evaluate the mutations in cancer and plan individualized treatments. In addition, because cancer is a heterogeneous genetic disease, and excisional biopsies provide only a snapshot in time of some of the rapid, dynamic genetic changes occurring in tumors, liquid biopsies provide some advantages over tissue biopsy-based genomic testing. In addition, excisional biopsies are invasive, can't be used repeatedly, and are ineffective in understanding the dynamics of tumor progression and metastasis. By detecting, quantifying and characterisation of vital circulating tumor cells or genomic alterations in CTCs and cell-free DNA in blood, liquid biopsy can provide real-time information on the stage of tumor progression, treatment effectiveness, and cancer metastasis risk. This technological development could make it possible to diagnose and manage cancer from repeated blood tests rather than from a traditional biopsy.Circulating tumor cell tests are already available but not covered by insurance yet at maintrac and under development by many pharmaceutical companies. Those tests analyze circulating tumor cells (CTCs) Analysis of individual CTCs demonstrated a high level of heterogeneity seen at the single cell level for both protein expression and protein localization and the CTCs reflected both the primary biopsy and the changes seen in the metastatic sites.Analysis of cell-free circulating tumor DNA (cfDNA) has an advantage over circulating tumor cells assays in that there is approximately 100 times more cell-free DNA than there is DNA in circulating tumor cells. These tests analyze fragments of tumor-cell DNA that are continuously shed by tumors into the bloodstream. Companies offering cfDNA next generation sequencing testing include Personal Genome Diagnostics and Guardant Health. These tests are moving into widespread use when a tissue biopsy has insufficient material for DNA testing or when it is not safe to do an invasive biopsy procedure, according to a recent report of results on over 15,000 advanced cancer patients sequenced with the Guardant Health test.A 2014 study of the blood of 846 patients with 15 different types of cancer in 24 institutions was able to detect the presence of cancer DNA in the body. They found tumor DNA in the blood of more than 80 percent of patients with metastatic cancers and about 47 percent of those with localized tumors. The test does not indicate the tumor site(s) or other information about the tumor. The test did not produce false positives.Such tests may also be useful to assess whether malignant cells remain in patients whose tumors have been surgically removed. Up to 30 percent are expected to relapse because some tumor cells remain. Initial studies identified about half the patients who later relapsed, again without false positives.Another potential use is to track the specific DNA mutations driving a tumor. Many new cancer medications block specific molecular processes. Such tests could allow easier targeting of therapy to tumor.  Precancerous conditions  For easily detected and accessed sites, any suspicious lesions may be assessed. Originally, this was skin or superficial masses. X-ray, then later CT, MRI, and ultrasound along with endoscopy extended the range.  Inflammatory conditions  A biopsy of the temporal arteries is often performed for suspected vasculitis. In inflammatory bowel disease (Crohn's disease and ulcerative colitis), frequent biopsies are taken to assess the activity of disease and to assess changes that precede malignancy.Biopsy specimens are often taken from part of a lesion when the cause of a disease is uncertain or its extent or exact character is in doubt. Vasculitis, for instance, is usually diagnosed on biopsy. Kidney disease: Biopsy and fluorescence microscopy are key in the diagnosis of alterations of renal function. The immunofluorescence plays vital role in the diagnosis of Crescentic glomerulonephritis. Infectious disease: Lymph node enlargement may be due to a variety of infectious or autoimmune diseases. Metabolic disease: Some conditions affect the whole body, but certain sites are selectively biopsied because they are easily accessed. Amyloidosis is a condition where degraded proteins accumulate in body tissues. In order to make the diagnosis, the gingival. Transplantation: Biopsies of transplanted organs are performed in order to determine that they are not being rejected or that the disease that necessitated transplant has not recurred. Fertility: A testicular biopsy is used for evaluating the fertility of men and find out the cause of a possible infertility, e.g. when sperm quality is low, but hormone levels still are within normal ranges.  Biopsied sites   Analysis of biopsied material  After the biopsy is performed, the sample of tissue that was removed from the patient is sent to the pathology laboratory. A pathologist specializes in diagnosing diseases (such as cancer) by examining tissue under a microscope. When the laboratory (see Histology) receives the biopsy sample, the tissue is processed and an extremely thin slice of tissue is removed from the sample and attached to a glass slide. Any remaining tissue is saved for use in later studies, if required.The slide with the tissue attached is treated with dyes that stain the tissue, which allows the individual cells in the tissue to be seen more clearly. The slide is then given to the pathologist, who examines the tissue under a microscope, looking for any abnormal findings. The pathologist then prepares a report that lists any abnormal or important findings from the biopsy. This report is sent to the surgeon who originally performed the biopsy on the patient.  References   External links  Mybiopsyinfo.com - What is a biopsy? How is a biopsy examination performed? This website gives you answers to these and many other questions. MyBiopsy.org - Links to a video. Information about biopsy results for patients. This site is created by pathologists, the physicians who diagnose cancer and other diseases by looking at biopsies under a microscope. RadiologyInfo - The radiology information resource for patients: Biopsy Biopsia de prostata - Prostate biopsy","A biopsy is a test in medicine where doctors remove cells and look at them closely under a microscope or do chemical analysis to see whether there is an illness.  Etymology  Biopsy is a Greek word, from the Greek words bio meaning ""life"" and opsia meaning see.  References "
"A molecule is a group of two or more atoms held together by attractive forces known as chemical bonds; depending on context, the term may or may not include ions which satisfy this criterion. In quantum physics, organic chemistry, and biochemistry, the distinction from ions is dropped and molecule is often used when referring to polyatomic ions. A molecule may be homonuclear, that is, it consists of atoms of one chemical element, e.g. two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, e.g. water (two hydrogen atoms and one oxygen atom; H2O). In the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. This relaxes the requirement that a molecule contains two or more atoms, since the noble gases are individual atoms. Atoms and complexes connected by non-covalent interactions, such as hydrogen bonds or ionic bonds, are typically not considered single molecules.Concepts similar to molecules have been discussed since ancient times, but modern investigation into the nature of molecules and their bonds began in the 17th century. Refined over time by scientists such as Robert Boyle, Amedeo Avogadro, Jean Perrin, and Linus Pauling, the study of molecules is today known as molecular physics or molecular chemistry.  Etymology  According to Merriam-Webster and the Online Etymology Dictionary, the word ""molecule"" derives from the Latin ""moles"" or small unit of mass. The word is derived from French molécule (1678), from Neo-Latin molecula, diminutive of Latin moles ""mass, barrier"". The word, which until the late 18th century was used only in Latin form, became popular after being used in works of philosophy by Descartes.  History  The definition of the molecule has evolved as knowledge of the structure of molecules has increased. Earlier definitions were less precise, defining molecules as the smallest particles of pure chemical substances that still retain their composition and chemical properties. This definition often breaks down since many substances in ordinary experience, such as rocks, salts, and metals, are composed of large crystalline networks of chemically bonded atoms or ions, but are not made of discrete molecules. The modern concept of molecules can be traced back towards pre-scientific and Greek philosophers such as Leucippus and Democritus who argued that all the universe is composed of atoms and voids. Circa 450 BC Empedocles imagined fundamental elements (fire (), earth (), air (), and water ()) and ""forces"" of attraction and repulsion allowing the elements to interact. A fifth element, the incorruptible quintessence aether, was considered to be the fundamental building block of the heavenly bodies. The viewpoint of Leucippus and Empedocles, along with the aether, was accepted by Aristotle and passed to medieval and renaissance Europe. In a more concrete manner, however, the concept of aggregates or units of bonded atoms, i.e. ""molecules"", traces its origins to Robert Boyle's 1661 hypothesis, in his famous treatise The Sceptical Chymist, that matter is composed of clusters of particles and that chemical change results from the rearrangement of the clusters. Boyle argued that matter's basic elements consisted of various sorts and sizes of particles, called ""corpuscles"", which were capable of arranging themselves into groups. In 1789, William Higgins published views on what he called combinations of ""ultimate"" particles, which foreshadowed the concept of valency bonds. If, for example, according to Higgins, the force between the ultimate particle of oxygen and the ultimate particle of nitrogen were 6, then the strength of the force would be divided accordingly, and similarly for the other combinations of ultimate particles. Amedeo Avogadro created the word ""molecule"". His 1811 paper ""Essay on Determining the Relative Masses of the Elementary Molecules of Bodies"", he essentially states, i.e. according to Partington's A Short History of Chemistry, that:The smallest particles of gases are not necessarily simple atoms, but are made up of a certain number of these atoms united by attraction to form a single molecule.In coordination with these concepts, in 1833 the French chemist Marc Antoine Auguste Gaudin presented a clear account of Avogadro's hypothesis, regarding atomic weights, by making use of ""volume diagrams"", which clearly show both semi-correct molecular geometries, such as a linear water molecule, and correct molecular formulas, such as H2O: In 1917, an unknown American undergraduate chemical engineer named Linus Pauling was learning the Dalton hook-and-eye bonding method, which was the mainstream description of bonds between atoms at the time. Pauling, however, wasn't satisfied with this method and looked to the newly emerging field of quantum physics for a new method. In 1926, French physicist Jean Perrin received the Nobel Prize in physics for proving, conclusively, the existence of molecules. He did this by calculating the Avogadro constant using three different methods, all involving liquid phase systems. First, he used a gamboge soap-like emulsion, second by doing experimental work on Brownian motion, and third by confirming Einstein's theory of particle rotation in the liquid phase.In 1927, the physicists Fritz London and Walter Heitler applied the new quantum mechanics to the deal with the saturable, nondynamic forces of attraction and repulsion, i.e., exchange forces, of the hydrogen molecule. Their valence bond treatment of this problem, in their joint paper, was a landmark in that it brought chemistry under quantum mechanics. Their work was an influence on Pauling, who had just received his doctorate and visited Heitler and London in Zürich on a Guggenheim Fellowship. Subsequently, in 1931, building on the work of Heitler and London and on theories found in Lewis' famous article, Pauling published his ground-breaking article ""The Nature of the Chemical Bond"" in which he used quantum mechanics to calculate properties and structures of molecules, such as angles between bonds and rotation about bonds. On these concepts, Pauling developed hybridization theory to account for bonds in molecules such as CH4, in which four sp³ hybridised orbitals are overlapped by hydrogen's 1s orbital, yielding four sigma (σ) bonds. The four bonds are of the same length and strength, which yields a molecular structure as shown below:  Molecular science  The science of molecules is called molecular chemistry or molecular physics, depending on whether the focus is on chemistry or physics. Molecular chemistry deals with the laws governing the interaction between molecules that results in the formation and breakage of chemical bonds, while molecular physics deals with the laws governing their structure and properties. In practice, however, this distinction is vague. In molecular sciences, a molecule consists of a stable system (bound state) composed of two or more atoms. Polyatomic ions may sometimes be usefully thought of as electrically charged molecules. The term unstable molecule is used for very reactive species, i.e., short-lived assemblies (resonances) of electrons and nuclei, such as radicals, molecular ions, Rydberg molecules, transition states, van der Waals complexes, or systems of colliding atoms as in Bose–Einstein condensate.  Prevalence  Molecules as components of matter are common. They also make up most of the oceans and atmosphere. Most organic substances are molecules. The substances of life are molecules, e.g. proteins, the amino acids of which they are composed, the nucleic acids (DNA and RNA), sugars, carbohydrates, fats, and vitamins. The nutrient minerals are generally ionic compounds, thus they are not molecules, e.g. iron sulfate. However, the majority of familiar solid substances on Earth are made partly or completely of crystals or ionic compounds, which are not made of molecules. These include all of the minerals that make up the substance of the Earth, sand, clay, pebbles, rocks, boulders, bedrock, the molten interior, and the core of the Earth. All of these contain many chemical bonds, but are not made of identifiable molecules. No typical molecule can be defined for salts nor for covalent crystals, although these are often composed of repeating unit cells that extend either in a plane, e.g. graphene; or three-dimensionally e.g. diamond, quartz, sodium chloride. The theme of repeated unit-cellular-structure also holds for most metals which are condensed phases with metallic bonding. Thus solid metals are not made of molecules. In glasses, which are solids that exist in a vitreous disordered state, the atoms are held together by chemical bonds with no presence of any definable molecule, nor any of the regularity of repeating unit-cellular-structure that characterizes salts, covalent crystals, and metals.  Bonding  Molecules are generally held together by covalent bonding. Several non-metallic elements exist only as molecules in the environment either in compounds or as homonuclear molecules, not as free atoms: for example, hydrogen. While some people say a metallic crystal can be considered a single giant molecule held together by metallic bonding, others point out that metals behave very differently than molecules.  Covalent  A covalent bond is a chemical bond that involves the sharing of electron pairs between atoms. These electron pairs are termed shared pairs or bonding pairs, and the stable balance of attractive and repulsive forces between atoms, when they share electrons, is termed covalent bonding.  Ionic  Ionic bonding is a type of chemical bond that involves the electrostatic attraction between oppositely charged ions, and is the primary interaction occurring in ionic compounds. The ions are atoms that have lost one or more electrons (termed cations) and atoms that have gained one or more electrons (termed anions). This transfer of electrons is termed electrovalence in contrast to covalence. In the simplest case, the cation is a metal atom and the anion is a nonmetal atom, but these ions can be of a more complicated nature, e.g. molecular ions like NH4+ or SO42−. At normal temperatures and pressures, ionic bonding mostly creates solids (or occasionally liquids) without separate identifiable molecules, but the vaporization/sublimation of such materials does produce separate molecules where electrons are still transferred fully enough for the bonds to be considered ionic rather than covalent.  Molecular size  Most molecules are far too small to be seen with the naked eye, although molecules of many polymers can reach macroscopic sizes, including biopolymers such as DNA. Molecules commonly used as building blocks for organic synthesis have a dimension of a few angstroms (Å) to several dozen Å, or around one billionth of a meter. Single molecules cannot usually be observed by light (as noted above), but small molecules and even the outlines of individual atoms may be traced in some circumstances by use of an atomic force microscope. Some of the largest molecules are macromolecules or supermolecules. The smallest molecule is the diatomic hydrogen (H2), with a bond length of 0.74 Å.Effective molecular radius is the size a molecule displays in solution. The table of permselectivity for different substances contains examples.  Molecular formulas   Chemical formula types  The chemical formula for a molecule uses one line of chemical element symbols, numbers, and sometimes also other symbols, such as parentheses, dashes, brackets, and plus (+) and minus (−) signs. These are limited to one typographic line of symbols, which may include subscripts and superscripts. A compound's empirical formula is a very simple type of chemical formula. It is the simplest integer ratio of the chemical elements that constitute it. For example, water is always composed of a 2:1 ratio of hydrogen to oxygen atoms, and ethanol (ethyl alcohol) is always composed of carbon, hydrogen, and oxygen in a 2:6:1 ratio. However, this does not determine the kind of molecule uniquely – dimethyl ether has the same ratios as ethanol, for instance. Molecules with the same atoms in different arrangements are called isomers. Also carbohydrates, for example, have the same ratio (carbon:hydrogen:oxygen 1:2:1) (and thus the same empirical formula) but different total numbers of atoms in the molecule. The molecular formula reflects the exact number of atoms that compose the molecule and so characterizes different molecules. However different isomers can have the same atomic composition while being different molecules. The empirical formula is often the same as the molecular formula but not always. For example, the molecule acetylene has molecular formula C2H2, but the simplest integer ratio of elements is CH. The molecular mass can be calculated from the chemical formula and is expressed in conventional atomic mass units equal to 1/12 of the mass of a neutral carbon-12 (12C isotope) atom. For network solids, the term formula unit is used in stoichiometric calculations.  Structural formula  For molecules with a complicated 3-dimensional structure, especially involving atoms bonded to four different substituents, a simple molecular formula or even semi-structural chemical formula may not be enough to completely specify the molecule. In this case, a graphical type of formula called a structural formula may be needed. Structural formulas may in turn be represented with a one-dimensional chemical name, but such chemical nomenclature requires many words and terms which are not part of chemical formulas.  Molecular geometry  Molecules have fixed equilibrium geometries—bond lengths and angles— about which they continuously oscillate through vibrational and rotational motions. A pure substance is composed of molecules with the same average geometrical structure. The chemical formula and the structure of a molecule are the two important factors that determine its properties, particularly its reactivity. Isomers share a chemical formula but normally have very different properties because of their different structures. Stereoisomers, a particular type of isomer, may have very similar physico-chemical properties and at the same time different biochemical activities.  Molecular spectroscopy  Molecular spectroscopy deals with the response (spectrum) of molecules interacting with probing signals of known energy (or frequency, according to the Planck relation). Molecules have quantized energy levels that can be analyzed by detecting the molecule's energy exchange through absorbance or emission. Spectroscopy does not generally refer to diffraction studies where particles such as neutrons, electrons, or high energy X-rays interact with a regular arrangement of molecules (as in a crystal). Microwave spectroscopy commonly measures changes in the rotation of molecules, and can be used to identify molecules in outer space. Infrared spectroscopy measures the vibration of molecules, including stretching, bending or twisting motions. It is commonly used to identify the kinds of bonds or functional groups in molecules. Changes in the arrangements of electrons yield absorption or emission lines in ultraviolet, visible or near infrared light, and result in colour. Nuclear resonance spectroscopy measures the environment of particular nuclei in the molecule, and can be used to characterise the numbers of atoms in different positions in a molecule.  Theoretical aspects  The study of molecules by molecular physics and theoretical chemistry is largely based on quantum mechanics and is essential for the understanding of the chemical bond. The simplest of molecules is the hydrogen molecule-ion, H2+, and the simplest of all the chemical bonds is the one-electron bond. H2+ is composed of two positively charged protons and one negatively charged electron, which means that the Schrödinger equation for the system can be solved more easily due to the lack of electron–electron repulsion. With the development of fast digital computers, approximate solutions for more complicated molecules became possible and are one of the main aspects of computational chemistry. When trying to define rigorously whether an arrangement of atoms is sufficiently stable to be considered a molecule, IUPAC suggests that it ""must correspond to a depression on the potential energy surface that is deep enough to confine at least one vibrational state"". This definition does not depend on the nature of the interaction between the atoms, but only on the strength of the interaction. In fact, it includes weakly bound species that would not traditionally be considered molecules, such as the helium dimer, He2, which has one vibrational bound state and is so loosely bound that it is only likely to be observed at very low temperatures. Whether or not an arrangement of atoms is sufficiently stable to be considered a molecule is inherently an operational definition. Philosophically, therefore, a molecule is not a fundamental entity (in contrast, for instance, to an elementary particle); rather, the concept of a molecule is the chemist's way of making a useful statement about the strengths of atomic-scale interactions in the world that we observe.  See also   References   External links  Molecule of the Month – School of Chemistry, University of Bristol","A molecule is the smallest amount of a chemical substance that can exist. If a molecule were split into smaller pieces, it would be a different substance.Molecules are made up of atoms that are stuck together in a particular shape or form. Not all combinations of atoms are equally possible; atoms make certain shapes in preference to others. Also, they have different valency. For example, oxygen atoms always have two bonds with other atoms, carbon atoms always have four bonds with other atoms, and nitrogen atoms always have three bonds with other atoms.In the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. According to this definition, noble gas atoms are considered molecules as they are in fact monoatomic molecules.In gases like air, the molecules are just flying around. In liquids like water, the molecules are stuck together but they can still move. In solids like sugar, the molecules can only vibrate. In the fourth state of matter known as plasma, the atoms are ionized and cannot form molecules. With a molecular formula, you can write down the numbers of all atoms in a molecule. For example, the molecular formula of glucose is C6H12O6. That means that one molecule of glucose is made up of six carbon atoms, twelve hydrogen atoms and six oxygen atoms.  Bonding  For a molecule to exist, atoms have to stick together. This happens when two atoms share electrons. Instead of circling just one atom, the electron now circles around two. This is called a covalent bond. Sometimes, more than one electron is shared. The more electrons are shared, the stronger the bond gets and the stronger the atoms stick together.Bonds can also be broken apart. Since most bonds require energy to form, they also give off energy when they are broken. But before most bonds break, the molecule has to be heated. Then the atoms start to move, and when they move too much, the bond breaks. Molecules that require less energy to break than they give off when broken are called fuels. For example, a candle will just sit there and nothing happens. But when you use a match to light it, it will burn for a long time. The match brings the energy to break the first bonds, which release enough energy to break the bonds below them, until the candle has burned down. There are also ionic bonds.  References   Other websites  Molecule of the Month - School of Chemistry, University of Bristol Antibody Molecule - The National Health Museum Data Book of Molecules - Home Page for Learning Environmental Chemistry"
"The lungs are the primary organs of the respiratory system in humans and most other animals, including some snails and a small number of fish. In mammals and most other vertebrates, two lungs are located near the backbone on either side of the heart. Their function in the respiratory system is to extract oxygen from the air and transfer it into the bloodstream, and to release carbon dioxide from the bloodstream into the atmosphere, in a process of gas exchange. The pleurae, which are thin, smooth, and moist, serve to reduce friction between the lungs and chest wall during breathing, allowing for easy and effortless movements of the lungs. Respiration is driven by different muscular systems in different species. Mammals, reptiles and birds use their different muscles to support and foster breathing. In earlier tetrapods, air was driven into the lungs by the pharyngeal muscles via buccal pumping, a mechanism still seen in amphibians. In humans, the main muscle of respiration that drives breathing is the diaphragm. The lungs also provide airflow that makes vocal sounds including human speech possible. Humans have two lungs, one on the left and one on the right. They are situated within the thoracic cavity of the chest. The right lung is bigger and heavier than the left, which shares space in the chest with the heart. The lungs together weigh approximately 1.3 kilograms (2.9 pounds). The lungs are part of the lower respiratory tract that begins at the trachea and branches into the bronchi and bronchioles, and which receive air breathed in via the conducting zone. The conducting zone ends at the terminal bronchioles. These divide into the respiratory bronchioles of the respiratory zone which divide into alveolar ducts that give rise to the alveolar sacs that contain the alveoli, where gas exchange takes place. Alveoli are also sparsely present on the walls of the respiratory bronchioles and alveolar ducts. Together, the lungs contain approximately 2,400 kilometres (1,500 miles) of airways and 300 to 500 million alveoli. Each lung is enclosed within a pleural sac of two membranes called pleurae; the membranes are separated by a film of pleural fluid, which allows the inner and outer membranes to slide over each other whilst breathing takes place, without much friction. The inner pleura also divides each lung into sections called lobes. The right lung has three lobes and the left has two. The lobes are further divided into bronchopulmonary segments and pulmonary lobules. The lungs have a unique blood supply, receiving deoxygenated blood from the heart in the pulmonary circulation for the purposes of receiving oxygen and releasing carbon dioxide, and a separate supply of oxygenated blood to the tissue of the lungs, in the bronchial circulation. The tissue of the lungs can be affected by a number of respiratory diseases, including pneumonia and lung cancer. Chronic obstructive pulmonary disease includes chronic bronchitis and emphysema, and can be related to smoking or exposure to harmful substances. A number of occupational lung diseases can be caused by substances such as coal dust, asbestos fibres, and crystalline silica dust. Diseases such as bronchitis can also affect the respiratory tract. Medical terms related to the lung often begin with pulmo-, from the Latin pulmonarius (of the lungs) as in pulmonology, or with pneumo- (from Greek πνεύμων ""lung"") as in pneumonia. In embryonic development, the lungs begin to develop as an outpouching of the foregut, a tube which goes on to form the upper part of the digestive system. When the lungs are formed the fetus is held in the fluid-filled amniotic sac and so they do not function to breathe. Blood is also diverted from the lungs through the ductus arteriosus. At birth, however, air begins to pass through the lungs, and the diversionary duct closes, so that the lungs can begin to respire. The lungs only fully develop in early childhood.  Structure   Anatomy  The lungs are located in the chest on either side of the heart in the rib cage. They are conical in shape with a narrow rounded apex at the top, and a broad concave base that rests on the convex surface of the diaphragm. The apex of the lung extends into the root of the neck, reaching shortly above the level of the sternal end of the first rib. The lungs stretch from close to the backbone in the rib cage to the front of the chest and downwards from the lower part of the trachea to the diaphragm.The left lung shares space with the heart, and has an indentation in its border called the cardiac notch of the left lung to accommodate this. The front and outer sides of the lungs face the ribs, which make light indentations on their surfaces. The medial surfaces of the lungs face towards the centre of the chest, and lie against the heart, great vessels, and the carina where the trachea divides into the two main bronchi. The cardiac impression is an indentation formed on the surfaces of the lungs where they rest against the heart. Both lungs have a central recession called the hilum, where the blood vessels and airways pass into the lungs making up the root of the lung. There are also bronchopulmonary lymph nodes on the hilum.The lungs are surrounded by the pulmonary pleurae. The pleurae are two serous membranes; the outer parietal pleura lines the inner wall of the rib cage and the inner visceral pleura directly lines the surface of the lungs. Between the pleurae is a potential space called the pleural cavity containing a thin layer of lubricating pleural fluid.  Lobes  Each lung is divided into sections called lobes by the infoldings of the visceral pleura as fissures. Lobes are divided into segments, and segments have further divisions as lobules. There are three lobes in the right lung and two lobes in the left lung.  Fissures  The fissures are formed in early prenatal development by invaginations of the visceral pleura that divide the lobar bronchi, and section the lungs into lobes that helps in their expansion. The right lung is divided into three lobes by a horizontal fissure, and an oblique fissure. The left lung is divided into two lobes by an oblique fissure which is closely aligned with the oblique fissure in the right lung. In the right lung the upper horizontal fissure, separates the upper (superior) lobe from the middle lobe. The lower, oblique fissure separates the lower lobe from the middle and upper lobes.Variations in the fissures are fairly common being either incompletely formed or present as an extra fissure as in the azygos fissure, or absent. Incomplete fissures are responsible for interlobar collateral ventilation, airflow between lobes which is unwanted in some lung volume reduction procedures.  Segments  The main or primary bronchi enter the lungs at the hilum and initially branch into secondary bronchi also known as lobar bronchi that supply air to each lobe of the lung. The lobar bronchi branch into tertiary bronchi also known as segmental bronchi and these supply air to the further divisions of the lobes known as bronchopulmonary segments. Each bronchopulmonary segment has its own (segmental) bronchus and arterial supply. Segments for the left and right lung are shown in the table. The segmental anatomy is useful clinically for localising disease processes in the lungs. A segment is a discrete unit that can be surgically removed without seriously affecting surrounding tissue.  Right lung  The right lung has both more lobes and segments than the left. It is divided into three lobes, an upper, middle, and a lower lobe by two fissures, one oblique and one horizontal. The upper, horizontal fissure, separates the upper from the middle lobe. It begins in the lower oblique fissure near the posterior border of the lung, and, running horizontally forward, cuts the anterior border on a level with the sternal end of the fourth costal cartilage; on the mediastinal surface it may be traced back to the hilum. The lower, oblique fissure, separates the lower from the middle and upper lobes and is closely aligned with the oblique fissure in the left lung.The mediastinal surface of the right lung is indented by a number of nearby structures. The heart sits in an impression called the cardiac impression. Above the hilum of the lung is an arched groove for the azygos vein, and above this is a wide groove for the superior vena cava and right brachiocephalic vein; behind this, and close to the top of the lung is a groove for the brachiocephalic artery. There is a groove for the esophagus behind the hilum and the pulmonary ligament, and near the lower part of the esophageal groove is a deeper groove for the inferior vena cava before it enters the heart.The weight of the right lung varies between individuals, with a standard reference range in men of 155–720 g (0.342–1.587 lb) and in women of 100–590 g (0.22–1.30 lb).  Left lung  The left lung is divided into two lobes, an upper and a lower lobe, by the oblique fissure, which extends from the costal to the mediastinal surface of the lung both above and below the hilum. The left lung, unlike the right, does not have a middle lobe, though it does have a homologous feature, a projection of the upper lobe termed the lingula. Its name means ""little tongue"". The lingula on the left lung serves as an anatomic parallel to the middle lobe on the right lung, with both areas being predisposed to similar infections and anatomic complications. There are two bronchopulmonary segments of the lingula: superior and inferior.The mediastinal surface of the left lung has a large cardiac impression where the heart sits. This is deeper and larger than that on the right lung, at which level the heart projects to the left.On the same surface, immediately above the hilum, is a well-marked curved groove for the aortic arch, and a groove below it for the descending aorta. The left subclavian artery, a branch off the aortic arch, sits in a groove from the arch to near the apex of the lung. A shallower groove in front of the artery and near the edge of the lung, lodges the left brachiocephalic vein. The esophagus may sit in a wider shallow impression at the base of the lung.The weight of the left lung, by standard reference range, in men is 110–675 g (0.243–1.488 lb) in women 105–515 g (0.231–1.135 lb).  Illustrations   Microanatomy  The lungs are part of the lower respiratory tract, and accommodate the bronchial airways when they branch from the trachea. The bronchial airways terminate in alveoli which make up the functional tissue (parenchyma) of the lung, and veins, arteries, nerves, and lymphatic vessels. The trachea and bronchi have plexuses of lymph capillaries in their mucosa and submucosa. The smaller bronchi have a single layer of lymph capillaries, and they are absent in the alveoli. The lungs are supplied with the largest lymphatic drainage system of any other organ in the body. Each lung is surrounded by a serous membrane of visceral pleura, which has an underlying layer of loose connective tissue attached to the substance of the lung.  Connective tissue  The connective tissue of the lungs is made up of elastic and collagen fibres that are interspersed between the capillaries and the alveolar walls. Elastin is the key protein of the extracellular matrix and is the main component of the elastic fibres. Elastin gives the necessary elasticity and resilience required for the persistent stretching involved in breathing, known as lung compliance. It is also responsible for the elastic recoil needed. Elastin is more concentrated in areas of high stress such as the openings of the alveoli, and alveolar junctions. The connective tissue links all the alveoli to form the lung parenchyma which has a sponge-like appearance. The alveoli have interconnecting air passages in their walls known as the pores of Kohn.  Respiratory epithelium  All of the lower respiratory tract including the trachea, bronchi, and bronchioles is lined with respiratory epithelium. This is a ciliated epithelium interspersed with goblet cells which produce mucin the main component of mucus, ciliated cells, basal cells, and in the terminal bronchioles–club cells with actions similar to basal cells, and macrophages. The epithelial cells, and the submucosal glands throughout the respiratory tract secrete airway surface liquid (ASL), the composition of which is tightly regulated and determines how well mucociliary clearance works.Pulmonary neuroendocrine cells are found throughout the respiratory epithelium including the alveolar epithelium, though they only account for around 0.5 percent of the total epithelial population. PNECs are innervated airway epithelial cells that are particularly focused at airway junction points. These cells can produce serotonin, dopamine, and norepinephrine, as well as polypeptide products. Cytoplasmic processes from the pulmonary neuroendocrine cells extend into the airway lumen where they may sense the composition of inspired gas.  Bronchial airways  In the bronchi there are incomplete tracheal rings of cartilage and smaller plates of cartilage that keep them open.: 472 Bronchioles are too narrow to support cartilage and their walls are of smooth muscle, and this is largely absent in the narrower respiratory bronchioles which are mainly just of epithelium.: 472 The absence of cartilage in the terminal bronchioles gives them an alternative name of membranous bronchioles.  Respiratory zone  The conducting zone of the respiratory tract ends at the terminal bronchioles when they branch into the respiratory bronchioles. This marks the beginning of the terminal respiratory unit called the acinus which includes the respiratory bronchioles, the alveolar ducts, alveolar sacs, and alveoli. An acinus measures up to 10 mm in diameter. A primary pulmonary lobule is that part of the acinus that includes the alveolar ducts, sacs, and alveoli but does not include the respiratory bronchioles.The unit described as the secondary pulmonary lobule is the lobule most referred to as the pulmonary lobule or respiratory lobule.: 489 This lobule is a discrete unit that is the smallest component of the lung that can be seen without aid. The secondary pulmonary lobule is likely to be made up of between 30 and 50 primary lobules. The lobule is supplied by a terminal bronchiole that branches into respiratory bronchioles. The respiratory bronchioles supply the alveoli in each acinus and is accompanied by a pulmonary artery branch. Each lobule is enclosed by an interlobular septa. Each acinus is incompletely separated by an interlobular septa.The respiratory bronchiole gives rise to the alveolar ducts that lead to the alveolar sacs, which contain two or more alveoli. The walls of the alveoli are extremely thin allowing a fast rate of diffusion. The alveoli have interconnecting small air passages in their walls known as the pores of Kohn.  Alveoli  Alveoli consist of two types of alveolar cell and an alveolar macrophage. The two types of cell are known as type I and type II cells (also known as pneumocytes). Types I and II make up the walls and alveolar septa. Type I cells provide 95% of the surface area of each alveoli and are flat (""squamous""), and Type II cells generally cluster in the corners of the alveoli and have a cuboidal shape. Despite this, cells occur in a roughly equal ratio of 1:1 or 6:4.Type I are squamous epithelial cells that make up the alveolar wall structure. They have extremely thin walls that enable an easy gas exchange. These type I cells also make up the alveolar septa which separate each alveolus. The septa consist of an epithelial lining and associated basement membranes. Type I cells are not able to divide, and consequently rely on differentiation from Type II cells.Type II are larger and they line the alveoli and produce and secrete epithelial lining fluid, and lung surfactant. Type II cells are able to divide and differentiate to Type I cells.The alveolar macrophages have an important role in the immune system. They remove substances which deposit in the alveoli including loose red blood cells that have been forced out from blood vessels.  Microbiota  There is a large presence of microorganisms in the lungs known as the lung microbiota that interacts with the airway epithelial cells; an interaction of probable importance in maintaining homeostasis. The microbiota is complex and dynamic in healthy people, and altered in diseases such as asthma and COPD. For example significant changes can take place in COPD following infection with rhinovirus. Fungal genera that are commonly found as mycobiota in the microbiota include Candida, Malassezia, Saccharomyces, and Aspergillus.  Respiratory tract  The lower respiratory tract is part of the respiratory system, and consists of the trachea and the structures below this including the lungs. The trachea receives air from the pharynx and travels down to a place where it splits (the carina) into a right and left primary bronchus. These supply air to the right and left lungs, splitting progressively into the secondary and tertiary bronchi for the lobes of the lungs, and into smaller and smaller bronchioles until they become the respiratory bronchioles. These in turn supply air through alveolar ducts into the alveoli, where the exchange of gases take place. Oxygen breathed in, diffuses through the walls of the alveoli into the enveloping capillaries and into the circulation, and carbon dioxide diffuses from the blood into the lungs to be breathed out. Estimates of the total surface area of lungs vary from 50 to 75 square metres (540 to 810 sq ft); although this is often quoted in textbooks and the media being ""the size of a tennis court"", it is actually less than half the size of a singles court.The bronchi in the conducting zone are reinforced with hyaline cartilage in order to hold open the airways. The bronchioles have no cartilage and are surrounded instead by smooth muscle. Air is warmed to 37 °C (99 °F), humidified and cleansed by the conducting zone. Particles from the air being removed by the cilia on the respiratory epithelium lining the passageways, in a process called mucociliary clearance. Pulmonary stretch receptors in the smooth muscle of the airways initiate a reflex known as the Hering–Breuer reflex that prevents the lungs from over-inflation, during forceful inspiration.  Blood supply  The lungs have a dual blood supply provided by a bronchial and a pulmonary circulation. The bronchial circulation supplies oxygenated blood to the airways of the lungs, through the bronchial arteries that leave the aorta. There are usually three arteries, two to the left lung and one to the right, and they branch alongside the bronchi and bronchioles. The pulmonary circulation carries deoxygenated blood from the heart to the lungs and returns the oxygenated blood to the heart to supply the rest of the body.The blood volume of the lungs is about 450 millilitres on average, about 9% of the total blood volume of the entire circulatory system. This quantity can easily fluctuate from between one-half and twice the normal volume. Also, in the event of blood loss through hemorrhage, blood from the lungs can partially compensate by automatically transferring to the systemic circulation.  Nerve supply  The lungs are supplied by nerves of the autonomic nervous system. Input from the parasympathetic nervous system occurs via the vagus nerve. When stimulated by acetylcholine, this causes constriction of the smooth muscle lining the bronchus and bronchioles, and increases the secretions from glands. The lungs also have a sympathetic tone from norepinephrine acting on the beta 2 adrenoceptors in the respiratory tract, which causes bronchodilation.The action of breathing takes place because of nerve signals sent by the respiratory center in the brainstem, along the phrenic nerve from the cervical plexus to the diaphragm.  Variation  The lobes of the lung are subject to anatomical variations. A horizontal interlobar fissure was found to be incomplete in 25% of right lungs, or even absent in 11% of all cases. An accessory fissure was also found in 14% and 22% of left and right lungs, respectively. An oblique fissure was found to be incomplete in 21% to 47% of left lungs. In some cases a fissure is absent, or extra, resulting in a right lung with only two lobes, or a left lung with three lobes.A variation in the airway branching structure has been found specifically in the central airway branching. This variation is associated with the development of COPD in adulthood.  Development  The development of the human lungs arise from the laryngotracheal groove and develop to maturity over several weeks in the foetus and for several years following birth.The larynx, trachea, bronchi and lungs that make up the respiratory tract, begin to form during the fourth week of embryogenesis from the lung bud which appears ventrally to the caudal portion of the foregut. The respiratory tract has a branching structure, and is also known as the respiratory tree. In the embryo this structure is developed in the process of branching morphogenesis, and is generated by the repeated splitting of the tip of the branch. In the development of the lungs (as in some other organs) the epithelium forms branching tubes. The lung has a left-right symmetry and each bud known as a bronchial bud grows out as a tubular epithelium that becomes a bronchus. Each bronchus branches into bronchioles. The branching is a result of the tip of each tube bifurcating. The branching process forms the bronchi, bronchioles, and ultimately the alveoli. The four genes mostly associated with branching morphogenesis in the lung are the intercellular signalling protein – sonic hedgehog (SHH), fibroblast growth factors FGF10 and FGFR2b, and bone morphogenetic protein BMP4. FGF10 is seen to have the most prominent role. FGF10 is a paracrine signalling molecule needed for epithelial branching, and SHH inhibits FGF10. The development of the alveoli is influenced by a different mechanism whereby continued bifurcation is stopped and the distal tips become dilated to form the alveoli. At the end of the fourth week the lung bud divides into two, the right and left primary bronchial buds on each side of the trachea. During the fifth week the right bud branches into three secondary bronchial buds and the left branches into two secondary bronchial buds. These give rise to the lobes of the lungs, three on the right and two on the left. Over the following week, the secondary buds branch into tertiary buds, about ten on each side. From the sixth week to the sixteenth week, the major elements of the lungs appear except the alveoli. From week 16 to week 26, the bronchi enlarge and lung tissue becomes highly vascularised. Bronchioles and alveolar ducts also develop. By week 26 the terminal bronchioles have formed which branch into two respiratory bronchioles. During the period covering the 26th week until birth the important blood–air barrier is established. Specialised type I alveolar cells where gas exchange will take place, together with the type II alveolar cells that secrete pulmonary surfactant, appear. The surfactant reduces the surface tension at the air-alveolar surface which allows expansion of the alveolar sacs. The alveolar sacs contain the primitive alveoli that form at the end of the alveolar ducts, and their appearance around the seventh month marks the point at which limited respiration would be possible, and the premature baby could survive.  Vitamin A deficiency  The developing lung is particularly vulnerable to changes in the levels of vitamin A. Vitamin A deficiency has been linked to changes in the epithelial lining of the lung and in the lung parenchyma. This can disrupt the normal physiology of the lung and predispose to respiratory diseases. Severe nutritional deficiency in vitamin A results in a reduction in the formation of the alveolar walls (septa) and to notable changes in the respiratory epithelium; alterations are noted in the extracellular matrix and in the protein content of the basement membrane. The extracellular matrix maintains lung elasticity; the basement membrane is associated with alveolar epithelium and is important in the blood-air barrier. The deficiency is associated with functional defects and disease states. Vitamin A is crucial in the development of the alveoli which continues for several years after birth.  After birth  At birth, the baby's lungs are filled with fluid secreted by the lungs and are not inflated. After birth the infant's central nervous system reacts to the sudden change in temperature and environment. This triggers the first breath, within about 10 seconds after delivery. Before birth, the lungs are filled with fetal lung fluid. After the first breath, the fluid is quickly absorbed into the body or exhaled. The resistance in the lung's blood vessels decreases giving an increased surface area for gas exchange, and the lungs begin to breathe spontaneously. This accompanies other changes which result in an increased amount of blood entering the lung tissues.At birth the lungs are very undeveloped with only around one sixth of the alveoli of the adult lung present. The alveoli continue to form into early adulthood, and their ability to form when necessary is seen in the regeneration of the lung. Alveolar septa have a double capillary network instead of the single network of the developed lung. Only after the maturation of the capillary network can the lung enter a normal phase of growth. Following the early growth in numbers of alveoli there is another stage of the alveoli being enlarged.  Function   Gas exchange  The major function of the lungs is gas exchange between the lungs and the blood. The alveolar and pulmonary capillary gases equilibrate across the thin blood–air barrier. This thin membrane (about 0.5 –2 μm thick) is folded into about 300 million alveoli, providing an extremely large surface area (estimates varying between 70 and 145 m2) for gas exchange to occur. The lungs are not capable of expanding to breathe on their own, and will only do so when there is an increase in the volume of the thoracic cavity. This is achieved by the muscles of respiration, through the contraction of the diaphragm, and the intercostal muscles which pull the rib cage upwards as shown in the diagram. During breathing out the muscles relax, returning the lungs to their resting position. At this point the lungs contain the functional residual capacity (FRC) of air, which, in the adult human, has a volume of about 2.5–3.0 litres.During heavy breathing as in exertion, a large number of accessory muscles in the neck and abdomen are recruited, that during exhalation pull the ribcage down, decreasing the volume of the thoracic cavity. The FRC is now decreased, but since the lungs cannot be emptied completely there is still about a litre of residual air left. Lung function testing is carried out to evaluate lung volumes and capacities.  Protection  The lungs possess several characteristics which protect against infection. The respiratory tract is lined by respiratory epithelium or respiratory mucosa, with hair-like projections called cilia that beat rhythmically and carry mucus. This mucociliary clearance is an important defence system against air-borne infection. The dust particles and bacteria in the inhaled air are caught in the mucosal surface of the airways, and are moved up towards the pharynx by the rhythmic upward beating action of the cilia.: 661–730 The lining of the lung also secretes immunoglobulin A which protects against respiratory infections; goblet cells secrete mucus which also contains several antimicrobial compounds such as defensins, antiproteases, and antioxidants. A rare type of specialised cell called a pulmonary ionocyte that is suggested may regulate mucus viscosity has been described. In addition, the lining of the lung also contains macrophages, immune cells which engulf and destroy debris and microbes that enter the lung in a process known as phagocytosis; and dendritic cells which present antigens to activate components of the adaptive immune system such as T cells and B cells.The size of the respiratory tract and the flow of air also protect the lungs from larger particles. Smaller particles deposit in the mouth and behind the mouth in the oropharynx, and larger particles are trapped in nasal hair after inhalation.  Other  In addition to their function in respiration, the lungs have a number of other functions. They are involved in maintaining homeostasis, helping in the regulation of blood pressure as part of the renin–angiotensin system. The inner lining of the blood vessels secretes angiotensin-converting enzyme (ACE) an enzyme that catalyses the conversion of angiotensin I to angiotensin II. The lungs are involved in the blood's acid–base homeostasis by expelling carbon dioxide when breathing.The lungs also serve a protective role. Several blood-borne substances, such as a few types of prostaglandins, leukotrienes, serotonin and bradykinin, are excreted through the lungs. Drugs and other substances can be absorbed, modified or excreted in the lungs. The lungs filter out small blood clots from veins and prevent them from entering arteries and causing strokes.The lungs also play a pivotal role in speech by providing air and airflow for the creation of vocal sounds, and other paralanguage communications such as sighs and gasps. Research suggests a role of the lungs in the production of blood platelets.  Gene and protein expression  About 20,000 protein coding genes are expressed in human cells and almost 75% of these genes are expressed in the normal lung. A little less than 200 of these genes are more specifically expressed in the lung with less than 20 genes being highly lung specific. The highest expression of lung specific proteins are different surfactant proteins, such as SFTPA1, SFTPB and SFTPC, and napsin, expressed in type II pneumocytes. Other proteins with elevated expression in the lung are the dynein protein DNAH5 in ciliated cells, and the secreted SCGB1A1 protein in mucus-secreting goblet cells of the airway mucosa.  Clinical significance  Lungs can be affected by a number of diseases and disorders. Pulmonology is the medical speciality that deals with respiratory diseases involving the lungs and respiratory system. Cardiothoracic surgery deals with surgery of the lungs including lung volume reduction surgery, lobectomy, pneumectomy and lung transplantation.  Inflammation and infection  Inflammatory conditions of the lung tissue are pneumonia, of the respiratory tract are bronchitis and bronchiolitis, and of the pleurae surrounding the lungs pleurisy. Inflammation is usually caused by infections due to bacteria or viruses. When the lung tissue is inflamed due to other causes it is called pneumonitis. One major cause of bacterial pneumonia is tuberculosis. Chronic infections often occur in those with immunodeficiency and can include a fungal infection by Aspergillus fumigatus that can lead to an aspergilloma forming in the lung. In the US certain species of rat can transmit a hantavirus to humans that can cause untreatable hantavirus pulmonary syndrome with a similar presentation to that of acute respiratory distress syndrome (ARDS).Alcohol affects the lungs and can cause inflammatory alcoholic lung disease. Acute exposure to alcohol stimulates the beating of cilia in the respiratory epithelium. However, chronic exposure has the effect of desensitising the ciliary response which reduces mucociliary clearance (MCC). MCC is an innate defense system protecting against pollutants and pathogens, and when this is disrupted the numbers of alveolar macrophages are decreased. A subsequent inflammatory response is the release of cytokines. Another consequence is the susceptibility to infection.  Blood-supply changes  A pulmonary embolism is a blood clot that becomes lodged in the pulmonary arteries. The majority of emboli arise because of deep vein thrombosis in the legs. Pulmonary emboli may be investigated using a ventilation/perfusion scan, a CT scan of the arteries of the lung, or blood tests such as the D-dimer. Pulmonary hypertension describes an increased pressure at the beginning of the pulmonary artery that has a large number of differing causes. Other rarer conditions may also affect the blood supply of the lung, such as granulomatosis with polyangiitis, which causes inflammation of the small blood vessels of the lungs and kidneys.A lung contusion is a bruise caused by chest trauma. It results in hemorrhage of the alveoli causing a build-up of fluid which can impair breathing, and this can be either mild or severe. The function of the lungs can also be affected by compression from fluid in the pleural cavity pleural effusion, or other substances such as air (pneumothorax), blood (hemothorax), or rarer causes. These may be investigated using a chest X-ray or CT scan, and may require the insertion of a surgical drain until the underlying cause is identified and treated.  Obstructive lung diseases  Asthma, bronchiectasis, and chronic obstructive pulmonary disease (COPD) that includes chronic bronchitis, and emphysema, are all obstructive lung diseases characterised by airway obstruction. This limits the amount of air that is able to enter alveoli because of constriction of the bronchial tree, due to inflammation. Obstructive lung diseases are often identified because of symptoms and diagnosed with pulmonary function tests such as spirometry. Many obstructive lung diseases are managed by avoiding triggers (such as dust mites or smoking), with symptom control such as bronchodilators, and with suppression of inflammation (such as through corticosteroids) in severe cases. A common cause of chronic bronchitis, and emphysema, is smoking; and common causes of bronchiectasis include severe infections and cystic fibrosis. The definitive cause of asthma is not yet known.The breakdown of alveolar tissue, often as a result of tobacco-smoking leads to emphysema, which can become severe enough to develop into COPD. Elastase breaks down the elastin in the lung's connective tissue that can also result in emphysema. Elastase is inhibited by the acute-phase protein, alpha-1 antitrypsin, and when there is a deficiency in this, emphysema can develop. With persistent stress from smoking, the airway basal cells become disarranged and lose their regenerative ability needed to repair the epithelial barrier. The disorganised basal cells are seen to be responsible for the major airway changes that are characteristic of COPD, and with continued stress can undergo a malignant transformation. Studies have shown that the initial development of emphysema is centred on the early changes in the airway epithelium of the small airways. Basal cells become further deranged in a smoker's transition to clinically defined COPD.  Restrictive lung diseases  Some types of chronic lung diseases are classified as restrictive lung disease, because of a restriction in the amount of lung tissue involved in respiration. These include pulmonary fibrosis which can occur when the lung is inflamed for a long period of time. Fibrosis in the lung replaces functioning lung tissue with fibrous connective tissue. This can be due to a large variety of occupational lung diseases such as Coalworker's pneumoconiosis, autoimmune diseases or more rarely to a reaction to medication. Severe respiratory disorders, where spontaneous breathing is not enough to maintain life, may need the use of mechanical ventilation to ensure an adequate supply of air.  Cancers  Lung cancer can either arise directly from lung tissue or as a result of metastasis from another part of the body. There are two main types of primary tumour described as either small-cell or non-small-cell lung carcinomas. The major risk factor for cancer is smoking. Once a cancer is identified it is staged using scans such as a CT scan and a sample of tissue from a biopsy is taken. Cancers may be treated surgically by removing the tumour, the use of radiotherapy, chemotherapy or a combination, or with the aim of symptom control. Lung cancer screening is being recommended in the United States for high-risk populations.  Congenital disorders  Congenital disorders include cystic fibrosis, pulmonary hypoplasia (an incomplete development of the lungs)congenital diaphragmatic hernia, and infant respiratory distress syndrome caused by a deficiency in lung surfactant. An azygos lobe is a congenital anatomical variation which though usually without effect can cause problems in thoracoscopic procedures.  Pleural space pressure  A pneumothorax (collapsed lung) is an abnormal collection of air in the pleural space that causes an uncoupling of the lung from the chest wall. The lung cannot expand against the air pressure inside the pleural space. An easy to understand example is a traumatic pneumothorax, where air enters the pleural space from outside the body, as occurs with puncture to the chest wall. Similarly, scuba divers ascending while holding their breath with their lungs fully inflated can cause air sacs (alveoli) to burst and leak high pressure air into the pleural space.  Examination  As part of a physical examination in response to respiratory symptoms of shortness of breath, and cough, a lung examination may be carried out. This exam includes palpation and auscultation. The areas of the lungs that can be listened to using a stethoscope are called the lung fields, and these are the posterior, lateral, and anterior lung fields. The posterior fields can be listened to from the back and include: the lower lobes (taking up three quarters of the posterior fields); the anterior fields taking up the other quarter; and the lateral fields under the axillae, the left axilla for the lingual, the right axilla for the middle right lobe. The anterior fields can also be auscultated from the front. An area known as the triangle of auscultation is an area of thinner musculature on the back which allows improved listening. Abnormal breathing sounds heard during a lung exam can indicate the presence of a lung condition; wheezing for example is commonly associated with asthma and COPD.  Function testing  Lung function testing is carried out by evaluating a person's capacity to inhale and exhale in different circumstances. The volume of air inhaled and exhaled by a person at rest is the tidal volume (normally 500–750 mL); the inspiratory reserve volume and expiratory reserve volume are the additional amounts a person is able to forcibly inhale and exhale respectively. The summed total of forced inspiration and expiration is a person's vital capacity. Not all air is expelled from the lungs even after a forced breath out; the remainder of the air is called the residual volume. Together these terms are referred to as lung volumes.Pulmonary plethysmographs are used to measure functional residual capacity. Functional residual capacity cannot be measured by tests that rely on breathing out, as a person is only able to breathe a maximum of 80% of their total functional capacity. The total lung capacity depends on the person's age, height, weight, and sex, and normally ranges between 4 and 6 litres. Females tend to have a 20–25% lower capacity than males. Tall people tend to have a larger total lung capacity than shorter people. Smokers have a lower capacity than nonsmokers. Thinner persons tend to have a larger capacity. Lung capacity can be increased by physical training as much as 40% but the effect may be modified by exposure to air pollution.Other lung function tests include spirometry, measuring the amount (volume) and flow of air that can be inhaled and exhaled. The maximum volume of breath that can be exhaled is called the vital capacity. In particular, how much a person is able to exhale in one second (called forced expiratory volume (FEV1)) as a proportion of how much they are able to exhale in total (FEV). This ratio, the FEV1/FEV ratio, is important to distinguish whether a lung disease is restrictive or obstructive. Another test is that of the lung's diffusing capacity – this is a measure of the transfer of gas from air to the blood in the lung capillaries.  Other animals   Birds  The lungs of birds are relatively small, but are connected to 8 or 9 air sacs that extend through much of the body, and are in turn connected to air spaces within the bones. On inhalation, air travels through the trachea of a bird into the air sacs. Air then travels continuously from the air sacs at the back, through the lungs, which are relatively fixed in size, to the air sacs at the front. From here, the air is exhaled. These fixed size lungs are called ""circulatory lungs"", as distinct from the ""bellows-type lungs"" found in most other animals.The lungs of birds contain millions of tiny parallel passages called parabronchi. Small sacs called atria radiate from the walls of the tiny passages; these, like the alveoli in other lungs, are the site of gas exchange by simple diffusion. The blood flow around the parabronchi and their atria forms a cross-current process of gas exchange (see diagram on the right).The air sacs, which hold air, do not contribute much to gas exchange, despite being thin-walled, as they are poorly vascularised. The air sacs expand and contract due to changes in the volume in the thorax and abdomen. This volume change is caused by the movement of the sternum and ribs and this movement is often synchronised with movement of the flight muscles.Parabronchi in which the air flow is unidirectional are called paleopulmonic parabronchi and are found in all birds. Some birds, however, have, in addition, a lung structure where the air flow in the parabronchi is bidirectional. These are termed neopulmonic parabronchi.  Reptiles  The lungs of most reptiles have a single bronchus running down the centre, from which numerous branches reach out to individual pockets throughout the lungs. These pockets are similar to alveoli in mammals, but much larger and fewer in number. These give the lung a sponge-like texture. In tuataras, snakes, and some lizards, the lungs are simpler in structure, similar to that of typical amphibians.Snakes and limbless lizards typically possess only the right lung as a major respiratory organ; the left lung is greatly reduced, or even absent. Amphisbaenians, however, have the opposite arrangement, with a major left lung, and a reduced or absent right lung.Both crocodilians and monitor lizards have lungs similar to those of birds, providing a unidirectional airflow and even possessing air sacs. The now extinct pterosaurs have seemingly even further refined this type of lung, extending the airsacs into the wing membranes and, in the case of lonchodectids, tupuxuara, and azhdarchoids, the hindlimbs.Reptilian lungs typically receive air via expansion and contraction of the ribs driven by axial muscles and buccal pumping. Crocodilians also rely on the hepatic piston method, in which the liver is pulled back by a muscle anchored to the pubic bone (part of the pelvis) called the diaphragmaticus, which in turn creates negative pressure in the crocodile's thoracic cavity, allowing air to be moved into the lungs by Boyle's law. Turtles, which are unable to move their ribs, instead use their forelimbs and pectoral girdle to force air in and out of the lungs.  Amphibians  The lungs of most frogs and other amphibians are simple and balloon-like, with gas exchange limited to the outer surface of the lung. This is not very efficient, but amphibians have low metabolic demands and can also quickly dispose of carbon dioxide by diffusion across their skin in water, and supplement their oxygen supply by the same method. Amphibians employ a positive pressure system to get air to their lungs, forcing air down into the lungs by buccal pumping. This is distinct from most higher vertebrates, who use a breathing system driven by negative pressure where the lungs are inflated by expanding the rib cage. In buccal pumping, the floor of the mouth is lowered, filling the mouth cavity with air. The throat muscles then presses the throat against the underside of the skull, forcing the air into the lungs.Due to the possibility of respiration across the skin combined with small size, all known lungless tetrapods are amphibians. The majority of salamander species are lungless salamanders, which respirate through their skin and tissues lining their mouth. This necessarily restricts their size: all are small and rather thread-like in appearance, maximising skin surface relative to body volume. Other known lungless tetrapods are the Bornean flat-headed frog and Atretochoana eiselti, a caecilian.The lungs of amphibians typically have a few narrow internal walls (septa) of soft tissue around the outer walls, increasing the respiratory surface area and giving the lung a honeycomb appearance. In some salamanders even these are lacking, and the lung has a smooth wall. In caecilians, as in snakes, only the right lung attains any size or development.  Lungfish  The lungs of lungfish are similar to those of amphibians, with few, if any, internal septa. In the Australian lungfish, there is only a single lung, albeit divided into two lobes. Other lungfish and Polypterus, however, have two lungs, which are located in the upper part of the body, with the connecting duct curving around and above the esophagus. The blood supply also twists around the esophagus, suggesting that the lungs originally evolved in the ventral part of the body, as in other vertebrates.  Invertebrates  Some invertebrates have lung-like structures that serve a similar respiratory purpose as, but are not evolutionarily related to, vertebrate lungs. Some arachnids, such as spiders and scorpions, have structures called book lungs used for atmospheric gas exchange. Some species of spider have four pairs of book lungs but most have two pairs. Scorpions have spiracles on their body for the entrance of air to the book lungs.The coconut crab is terrestrial and uses structures called branchiostegal lungs to breathe air. They cannot swim and would drown in water, yet they possess a rudimentary set of gills. They can breathe on land and hold their breath underwater. The branchiostegal lungs are seen as a developmental adaptive stage from water-living to enable land-living, or from fish to amphibian.Pulmonates are mostly land snails and slugs that have developed a simple lung from the mantle cavity. An externally located opening called the pneumostome allows air to be taken into the mantle cavity lung.  Evolutionary origins  The lungs of today's terrestrial vertebrates and the gas bladders of today's fish are believed to have evolved from simple sacs, as outpocketings of the esophagus, that allowed early fish to gulp air under oxygen-poor conditions. These outpocketings first arose in the bony fish. In most of the ray-finned fish the sacs evolved into closed off gas bladders, while a number of carp, trout, herring, catfish, and eels have retained the physostome condition with the sac being open to the esophagus. In more basal bony fish, such as the gar, bichir, bowfin and the lobe-finned fish, the bladders have evolved to primarily function as lungs. The lobe-finned fish gave rise to the land-based tetrapods. Thus, the lungs of vertebrates are homologous to the gas bladders of fish (but not to their gills).  See also   References   Further reading   External links  Lung at the Human Protein Atlas","The lung is an organ in many vertebrates (animals having a spine, or backbone). It takes blood oxygen from the air, and expels carbon dioxide. Most vertebrates with lungs have two of them. In animals, the lungs are the area where gas exchange takes place. Without gas exchange, oxygen would not pass into the blood from the lungs so the body cells would not be able to receive the oxygen needed for respiration. The alveoli are moist to allow oxygen to move from the lung through the alveoli into blood vessels and red blood cells. Carbon dioxide passes from the blood into the alveoli. The oxygen-filled blood goes back to the heart and the carbon dioxide in the alveoli is pushed out of the lungs and into the air we breathe out.  Bird lung  Birds lungs are smaller than mammal lungs, and do not have alveoli, instead they have millions of para-bronchi. These para-bronchi end up in tiny capillaries or very small blood vessels and they pass close to the body's blood vessels, so diffusion can occur and the oxygen and carbon dioxide is exchanged. The oxygen and carbon dioxide in birds lungs are continuously diffused into and out of the blood, not like in mammals where diffusion can only happen in the alveoli. Air does not go into and back out of the lungs as in mammals. Instead, muscular air sacs push the air forward through bird lungs.  Reptile lung  Reptile lungs open and close because of the ribs surrounding them pressing down on them and then opening up with the help of muscles. The liver is also attached to the bottom of the lungs and when a muscle which is attached to the liver pulls, the liver moves away from the lungs and pulls them, making them bigger.  Amphibian lung  Frog lungs are very simple compared to most other lungs, they are simply balloons, with moist outsides allowing for diffusion. But frogs do not move around much and so do not need lots of oxygen, but they can also take in oxygen through their moist outer skin if a big demand of oxygen is needed (e.g. Fight or flight response)  Other websites  A revision site directed towards IGSCE students Archived 2002-11-08 at the Wayback Machine A to Z list of diseases of the Lung List of Lung Cancer information sites Archived 2008-11-10 at the Wayback Machine In depth articles on the lung In depth article on the anatomy of a lung"
"The heart is a muscular organ in most animals. This organ pumps blood through the blood vessels of the circulatory system. The pumped blood carries oxygen and nutrients to the body, while carrying metabolic waste such as carbon dioxide to the lungs. In humans, the heart is approximately the size of a closed fist and is located between the lungs, in the middle compartment of the chest, called the mediastinum.In humans, other mammals, and birds, the heart is divided into four chambers: upper left and right atria and lower left and right ventricles. Commonly the right atrium and ventricle are referred together as the right heart and their left counterparts as the left heart. Fish, in contrast, have two chambers, an atrium and a ventricle, while most reptiles have three chambers. In a healthy heart blood flows one way through the heart due to heart valves, which prevent backflow. The heart is enclosed in a protective sac, the pericardium, which also contains a small amount of fluid. The wall of the heart is made up of three layers: epicardium, myocardium, and endocardium.The heart pumps blood with a rhythm determined by a group of pacemaker cells in the sinoatrial node. These generate a current that causes the heart to contract, traveling through the atrioventricular node and along the conduction system of the heart. In humans, deoxygenated blood enters the heart through the right atrium from the superior and inferior venae cavae and passes it to the right ventricle. From here it is pumped into pulmonary circulation to the lungs, where it receives oxygen and gives off carbon dioxide. Oxygenated blood then returns to the left atrium, passes through the left ventricle and is pumped out through the aorta into systemic circulation, traveling through arteries, arterioles, and capillaries—where nutrients and other substances are exchanged between blood vessels and cells, losing oxygen and gaining carbon dioxide—before being returned to the heart through venules and veins. The heart beats at a resting rate close to 72 beats per minute. Exercise temporarily increases the rate, but lowers it in the long term, and is good for heart health.Cardiovascular diseases are the most common cause of death globally as of 2008, accounting for 30% of deaths. Of these more than three-quarters are a result of coronary artery disease and stroke. Risk factors include: smoking, being overweight, little exercise, high cholesterol, high blood pressure, and poorly controlled diabetes, among others. Cardiovascular diseases do not frequently have symptoms but may cause chest pain or shortness of breath. Diagnosis of heart disease is often done by the taking of a medical history, listening to the heart-sounds with a stethoscope, as well as with ECG, echocardiogram, and ultrasound. Specialists who focus on diseases of the heart are called cardiologists, although many specialties of medicine may be involved in treatment.  Structure   Location and shape  The human heart is situated in the mediastinum, at the level of thoracic vertebrae T5-T8. A double-membraned sac called the pericardium surrounds the heart and attaches to the mediastinum. The back surface of the heart lies near the vertebral column, and the front surface known as the sternocostal surface sits behind the sternum and rib cartilages. The upper part of the heart is the attachment point for several large blood vessels—the venae cavae, aorta and pulmonary trunk. The upper part of the heart is located at the level of the third costal cartilage. The lower tip of the heart, the apex, lies to the left of the sternum (8 to 9 cm from the midsternal line) between the junction of the fourth and fifth ribs near their articulation with the costal cartilages.The largest part of the heart is usually slightly offset to the left side of the chest (though occasionally it may be offset to the right) and is felt to be on the left because the left heart is stronger and larger, since it pumps to all body parts. Because the heart is between the lungs, the left lung is smaller than the right lung and has a cardiac notch in its border to accommodate the heart. The heart is cone-shaped, with its base positioned upwards and tapering down to the apex. An adult heart has a mass of 250–350 grams (9–12 oz). The heart is often described as the size of a fist: 12 cm (5 in) in length, 8 cm (3.5 in) wide, and 6 cm (2.5 in) in thickness, although this description is disputed, as the heart is likely to be slightly larger. Well-trained athletes can have much larger hearts due to the effects of exercise on the heart muscle, similar to the response of skeletal muscle.  Chambers  The heart has four chambers, two upper atria, the receiving chambers, and two lower ventricles, the discharging chambers. The atria open into the ventricles via the atrioventricular valves, present in the atrioventricular septum. This distinction is visible also on the surface of the heart as the coronary sulcus. There is an ear-shaped structure in the upper right atrium called the right atrial appendage, or auricle, and another in the upper left atrium, the left atrial appendage. The right atrium and the right ventricle together are sometimes referred to as the right heart. Similarly, the left atrium and the left ventricle together are sometimes referred to as the left heart. The ventricles are separated from each other by the interventricular septum, visible on the surface of the heart as the anterior longitudinal sulcus and the posterior interventricular sulcus.The fibrous cardiac skeleton gives structure to the heart. It forms the atrioventricular septum, which separates the atria from the ventricles, and the fibrous rings, which serve as bases for the four heart valves. The cardiac skeleton also provides an important boundary in the heart\'s electrical conduction system since collagen cannot conduct electricity. The interatrial septum separates the atria, and the interventricular septum separates the ventricles. The interventricular septum is much thicker than the interatrial septum since the ventricles need to generate greater pressure when they contract.  Valves  The heart has four valves, which separate its chambers. One valve lies between each atrium and ventricle, and one valve rests at the exit of each ventricle.The valves between the atria and ventricles are called the atrioventricular valves. Between the right atrium and the right ventricle is the tricuspid valve. The tricuspid valve has three cusps, which connect to chordae tendinae and three papillary muscles named the anterior, posterior, and septal muscles, after their relative positions. The mitral valve lies between the left atrium and left ventricle. It is also known as the bicuspid valve due to its having two cusps, an anterior and a posterior cusp. These cusps are also attached via chordae tendinae to two papillary muscles projecting from the ventricular wall.The papillary muscles extend from the walls of the heart to valves by cartilaginous connections called chordae tendinae. These muscles prevent the valves from falling too far back when they close. During the relaxation phase of the cardiac cycle, the papillary muscles are also relaxed and the tension on the chordae tendineae is slight. As the heart chambers contract, so do the papillary muscles. This creates tension on the chordae tendineae, helping to hold the cusps of the atrioventricular valves in place and preventing them from being blown back into the atria. Two additional semilunar valves sit at the exit of each of the ventricles. The pulmonary valve is located at the base of the pulmonary artery. This has three cusps which are not attached to any papillary muscles. When the ventricle relaxes blood flows back into the ventricle from the artery and this flow of blood fills the pocket-like valve, pressing against the cusps which close to seal the valve. The semilunar aortic valve is at the base of the aorta and also is not attached to papillary muscles. This too has three cusps which close with the pressure of the blood flowing back from the aorta.  Right heart  The right heart consists of two chambers, the right atrium and the right ventricle, separated by a valve, the tricuspid valve.The right atrium receives blood almost continuously from the body\'s two major veins, the superior and inferior venae cavae. A small amount of blood from the coronary circulation also drains into the right atrium via the coronary sinus, which is immediately above and to the middle of the opening of the inferior vena cava. In the wall of the right atrium is an oval-shaped depression known as the fossa ovalis, which is a remnant of an opening in the fetal heart known as the foramen ovale. Most of the internal surface of the right atrium is smooth, the depression of the fossa ovalis is medial, and the anterior surface has prominent ridges of pectinate muscles, which are also present in the right atrial appendage.The right atrium is connected to the right ventricle by the tricuspid valve. The walls of the right ventricle are lined with trabeculae carneae, ridges of cardiac muscle covered by endocardium. In addition to these muscular ridges, a band of cardiac muscle, also covered by endocardium, known as the moderator band reinforces the thin walls of the right ventricle and plays a crucial role in cardiac conduction. It arises from the lower part of the interventricular septum and crosses the interior space of the right ventricle to connect with the inferior papillary muscle. The right ventricle tapers into the pulmonary trunk, into which it ejects blood when contracting. The pulmonary trunk branches into the left and right pulmonary arteries that carry the blood to each lung. The pulmonary valve lies between the right heart and the pulmonary trunk.  Left heart  The left heart has two chambers: the left atrium and the left ventricle, separated by the mitral valve.The left atrium receives oxygenated blood back from the lungs via one of the four pulmonary veins. The left atrium has an outpouching called the left atrial appendage. Like the right atrium, the left atrium is lined by pectinate muscles. The left atrium is connected to the left ventricle by the mitral valve.The left ventricle is much thicker as compared with the right, due to the greater force needed to pump blood to the entire body. Like the right ventricle, the left also has trabeculae carneae, but there is no moderator band. The left ventricle pumps blood to the body through the aortic valve and into the aorta. Two small openings above the aortic valve carry blood to the heart muscle; the left coronary artery is above the left cusp of the valve, and the right coronary artery is above the right cusp.  Wall  The heart wall is made up of three layers: the inner endocardium, middle myocardium and outer epicardium. These are surrounded by a double-membraned sac called the pericardium. The innermost layer of the heart is called the endocardium. It is made up of a lining of simple squamous epithelium and covers heart chambers and valves. It is continuous with the endothelium of the veins and arteries of the heart, and is joined to the myocardium with a thin layer of connective tissue. The endocardium, by secreting endothelins, may also play a role in regulating the contraction of the myocardium. The middle layer of the heart wall is the myocardium, which is the cardiac muscle—a layer of involuntary striated muscle tissue surrounded by a framework of collagen. The cardiac muscle pattern is elegant and complex, as the muscle cells swirl and spiral around the chambers of the heart, with the outer muscles forming a figure 8 pattern around the atria and around the bases of the great vessels and the inner muscles, forming a figure 8 around the two ventricles and proceeding toward the apex. This complex swirling pattern allows the heart to pump blood more effectively.There are two types of cells in cardiac muscle: muscle cells which have the ability to contract easily, and pacemaker cells of the conducting system. The muscle cells make up the bulk (99%) of cells in the atria and ventricles. These contractile cells are connected by intercalated discs which allow a rapid response to impulses of action potential from the pacemaker cells. The intercalated discs allow the cells to act as a syncytium and enable the contractions that pump blood through the heart and into the major arteries. The pacemaker cells make up 1% of cells and form the conduction system of the heart. They are generally much smaller than the contractile cells and have few myofibrils which gives them limited contractibility. Their function is similar in many respects to neurons. Cardiac muscle tissue has autorhythmicity, the unique ability to initiate a cardiac action potential at a fixed rate—spreading the impulse rapidly from cell to cell to trigger the contraction of the entire heart.There are specific proteins expressed in cardiac muscle cells. These are mostly associated with muscle contraction, and bind with actin, myosin, tropomyosin, and troponin. They include MYH6, ACTC1, TNNI3, CDH2 and PKP2. Other proteins expressed are MYH7 and LDB3 that are also expressed in skeletal muscle.  Pericardium  The pericardium is the sac that surrounds the heart. The tough outer surface of the pericardium is called the fibrous membrane. This is lined by a double inner membrane called the serous membrane that produces pericardial fluid to lubricate the surface of the heart. The part of the serous membrane attached to the fibrous membrane is called the parietal pericardium, while the part of the serous membrane attached to the heart is known as the visceral pericardium. The pericardium is present in order to lubricate its movement against other structures within the chest, to keep the heart\'s position stabilised within the chest, and to protect the heart from infection.  Coronary circulation  Heart tissue, like all cells in the body, needs to be supplied with oxygen, nutrients and a way of removing metabolic wastes. This is achieved by the coronary circulation, which includes arteries, veins, and lymphatic vessels. Blood flow through the coronary vessels occurs in peaks and troughs relating to the heart muscle\'s relaxation or contraction.Heart tissue receives blood from two arteries which arise just above the aortic valve. These are the left main coronary artery and the right coronary artery. The left main coronary artery splits shortly after leaving the aorta into two vessels, the left anterior descending and the left circumflex artery. The left anterior descending artery supplies heart tissue and the front, outer side, and septum of the left ventricle. It does this by branching into smaller arteries—diagonal and septal branches. The left circumflex supplies the back and underneath of the left ventricle. The right coronary artery supplies the right atrium, right ventricle, and lower posterior sections of the left ventricle. The right coronary artery also supplies blood to the atrioventricular node (in about 90% of people) and the sinoatrial node (in about 60% of people). The right coronary artery runs in a groove at the back of the heart and the left anterior descending artery runs in a groove at the front. There is significant variation between people in the anatomy of the arteries that supply the heart The arteries divide at their furthest reaches into smaller branches that join at the edges of each arterial distribution.The coronary sinus is a large vein that drains into the right atrium, and receives most of the venous drainage of the heart. It receives blood from the great cardiac vein (receiving the left atrium and both ventricles), the posterior cardiac vein (draining the back of the left ventricle), the middle cardiac vein (draining the bottom of the left and right ventricles), and small cardiac veins. The anterior cardiac veins drain the front of the right ventricle and drain directly into the right atrium.Small lymphatic networks called plexuses exist beneath each of the three layers of the heart. These networks collect into a main left and a main right trunk, which travel up the groove between the ventricles that exists on the heart\'s surface, receiving smaller vessels as they travel up. These vessels then travel into the atrioventricular groove, and receive a third vessel which drains the section of the left ventricle sitting on the diaphragm. The left vessel joins with this third vessel, and travels along the pulmonary artery and left atrium, ending in the inferior tracheobronchial node. The right vessel travels along the right atrium and the part of the right ventricle sitting on the diaphragm. It usually then travels in front of the ascending aorta and then ends in a brachiocephalic node.  Nerve supply  The heart receives nerve signals from the vagus nerve and from nerves arising from the sympathetic trunk. These nerves act to influence, but not control, the heart rate. Sympathetic nerves also influence the force of heart contraction. Signals that travel along these nerves arise from two paired cardiovascular centres in the medulla oblongata. The vagus nerve of the parasympathetic nervous system acts to decrease the heart rate, and nerves from the sympathetic trunk act to increase the heart rate. These nerves form a network of nerves that lies over the heart called the cardiac plexus.The vagus nerve is a long, wandering nerve that emerges from the brainstem and provides parasympathetic stimulation to a large number of organs in the thorax and abdomen, including the heart. The nerves from the sympathetic trunk emerge through the T1-T4 thoracic ganglia and travel to both the sinoatrial and atrioventricular nodes, as well as to the atria and ventricles. The ventricles are more richly innervated by sympathetic fibers than parasympathetic fibers. Sympathetic stimulation causes the release of the neurotransmitter norepinephrine (also known as noradrenaline) at the neuromuscular junction of the cardiac nerves. This shortens the repolarization period, thus speeding the rate of depolarization and contraction, which results in an increased heart rate. It opens chemical or ligand-gated sodium and calcium ion channels, allowing an influx of positively charged ions. Norepinephrine binds to the beta–1 receptor.  Development  The heart is the first functional organ to develop and starts to beat and pump blood at about three weeks into embryogenesis. This early start is crucial for subsequent embryonic and prenatal development. The heart derives from splanchnopleuric mesenchyme in the neural plate which forms the cardiogenic region. Two endocardial tubes form here that fuse to form a primitive heart tube known as the tubular heart. Between the third and fourth week, the heart tube lengthens, and begins to fold to form an S-shape within the pericardium. This places the chambers and major vessels into the correct alignment for the developed heart. Further development will include the formation of the septa and the valves and the remodeling of the heart chambers. By the end of the fifth week, the septa are complete, and by the ninth week, the heart valves are complete.Before the fifth week, there is an opening in the fetal heart known as the foramen ovale. The foramen ovale allowed blood in the fetal heart to pass directly from the right atrium to the left atrium, allowing some blood to bypass the lungs. Within seconds after birth, a flap of tissue known as the septum primum that previously acted as a valve closes the foramen ovale and establishes the typical cardiac circulation pattern. A depression in the surface of the right atrium remains where the foramen ovale was, called the fossa ovalis. The embryonic heart begins beating at around 22 days after conception (5 weeks after the last normal menstrual period, LMP). It starts to beat at a rate near to the mother\'s which is about 75–80 beats per minute (bpm). The embryonic heart rate then accelerates and reaches a peak rate of 165–185 bpm early in the early 7th week (early 9th week after the LMP). After 9 weeks (start of the fetal stage) it starts to decelerate, slowing to around 145 (±25) bpm at birth. There is no difference in female and male heart rates before birth.  Physiology   Blood flow  The heart functions as a pump in the circulatory system to provide a continuous flow of blood throughout the body. This circulation consists of the systemic circulation to and from the body and the pulmonary circulation to and from the lungs. Blood in the pulmonary circulation exchanges carbon dioxide for oxygen in the lungs through the process of respiration. The systemic circulation then transports oxygen to the body and returns carbon dioxide and relatively deoxygenated blood to the heart for transfer to the lungs.The right heart collects deoxygenated blood from two large veins, the superior and inferior venae cavae. Blood collects in the right and left atrium continuously. The superior vena cava drains blood from above the diaphragm and empties into the upper back part of the right atrium. The inferior vena cava drains the blood from below the diaphragm and empties into the back part of the atrium below the opening for the superior vena cava. Immediately above and to the middle of the opening of the inferior vena cava is the opening of the thin-walled coronary sinus. Additionally, the coronary sinus returns deoxygenated blood from the myocardium to the right atrium. The blood collects in the right atrium. When the right atrium contracts, the blood is pumped through the tricuspid valve into the right ventricle. As the right ventricle contracts, the tricuspid valve closes and the blood is pumped into the pulmonary trunk through the pulmonary valve. The pulmonary trunk divides into pulmonary arteries and progressively smaller arteries throughout the lungs, until it reaches capillaries. As these pass by alveoli carbon dioxide is exchanged for oxygen. This happens through the passive process of diffusion. In the left heart, oxygenated blood is returned to the left atrium via the pulmonary veins. It is then pumped into the left ventricle through the mitral valve and into the aorta through the aortic valve for systemic circulation. The aorta is a large artery that branches into many smaller arteries, arterioles, and ultimately capillaries. In the capillaries, oxygen and nutrients from blood are supplied to body cells for metabolism, and exchanged for carbon dioxide and waste products. Capillary blood, now deoxygenated, travels into venules and veins that ultimately collect in the superior and inferior vena cavae, and into the right heart.  Cardiac cycle  The cardiac cycle is the sequence of events in which the heart contracts and relaxes with every heartbeat. The period of time during which the ventricles contract, forcing blood out into the aorta and main pulmonary artery, is known as systole, while the period during which the ventricles relax and refill with blood is known as diastole. The atria and ventricles work in concert, so in systole when the ventricles are contracting, the atria are relaxed and collecting blood. When the ventricles are relaxed in diastole, the atria contract to pump blood to the ventricles. This coordination ensures blood is pumped efficiently to the body.At the beginning of the cardiac cycle, the ventricles are relaxing. As they do so, they are filled by blood passing through the open mitral and tricuspid valves. After the ventricles have completed most of their filling, the atria contract, forcing further blood into the ventricles and priming the pump. Next, the ventricles start to contract. As the pressure rises within the cavities of the ventricles, the mitral and tricuspid valves are forced shut. As the pressure within the ventricles rises further, exceeding the pressure with the aorta and pulmonary arteries, the aortic and pulmonary valves open. Blood is ejected from the heart, causing the pressure within the ventricles to fall. Simultaneously, the atria refill as blood flows into the right atrium through the superior and inferior vena cavae, and into the left atrium through the pulmonary veins. Finally, when the pressure within the ventricles falls below the pressure within the aorta and pulmonary arteries, the aortic and pulmonary valves close. The ventricles start to relax, the mitral and tricuspid valves open, and the cycle begins again.  Cardiac output  Cardiac output (CO) is a measurement of the amount of blood pumped by each ventricle (stroke volume) in one minute. This is calculated by multiplying the stroke volume (SV) by the beats per minute of the heart rate (HR). So that: CO  SV x HR. The cardiac output is normalized to body size through body surface area and is called the cardiac index. The average cardiac output, using an average stroke volume of about 70mL, is 5.25 L/min, with a normal range of 4.0–8.0 L/min. The stroke volume is normally measured using an echocardiogram and can be influenced by the size of the heart, physical and mental condition of the individual, sex, contractility, duration of contraction, preload and afterload.Preload refers to the filling pressure of the atria at the end of diastole, when the ventricles are at their fullest. A main factor is how long it takes the ventricles to fill: if the ventricles contract more frequently, then there is less time to fill and the preload will be less. Preload can also be affected by a person\'s blood volume. The force of each contraction of the heart muscle is proportional to the preload, described as the Frank-Starling mechanism. This states that the force of contraction is directly proportional to the initial length of muscle fiber, meaning a ventricle will contract more forcefully, the more it is stretched.Afterload, or how much pressure the heart must generate to eject blood at systole, is influenced by vascular resistance. It can be influenced by narrowing of the heart valves (stenosis) or contraction or relaxation of the peripheral blood vessels.The strength of heart muscle contractions controls the stroke volume. This can be influenced positively or negatively by agents termed inotropes. These agents can be a result of changes within the body, or be given as drugs as part of treatment for a medical disorder, or as a form of life support, particularly in intensive care units. Inotropes that increase the force of contraction are ""positive"" inotropes, and include sympathetic agents such as adrenaline, noradrenaline and dopamine. ""Negative"" inotropes decrease the force of contraction and include calcium channel blockers.  Electrical conduction  The normal rhythmical heart beat, called sinus rhythm, is established by the heart\'s own pacemaker, the sinoatrial node (also known as the sinus node or the SA node). Here an electrical signal is created that travels through the heart, causing the heart muscle to contract. The sinoatrial node is found in the upper part of the right atrium near to the junction with the superior vena cava. The electrical signal generated by the sinoatrial node travels through the right atrium in a radial way that is not completely understood. It travels to the left atrium via Bachmann\'s bundle, such that the muscles of the left and right atria contract together. The signal then travels to the atrioventricular node. This is found at the bottom of the right atrium in the atrioventricular septum, the boundary between the right atrium and the left ventricle. The septum is part of the cardiac skeleton, tissue within the heart that the electrical signal cannot pass through, which forces the signal to pass through the atrioventricular node only. The signal then travels along the bundle of His to left and right bundle branches through to the ventricles of the heart. In the ventricles the signal is carried by specialized tissue called the Purkinje fibers which then transmit the electric charge to the heart muscle.  Heart rate  The normal resting heart rate is called the sinus rhythm, created and sustained by the sinoatrial node, a group of pacemaking cells found in the wall of the right atrium. Cells in the sinoatrial node do this by creating an action potential. The cardiac action potential is created by the movement of specific electrolytes into and out of the pacemaker cells. The action potential then spreads to nearby cells.When the sinoatrial cells are resting, they have a negative charge on their membranes. A rapid influx of sodium ions causes the membrane\'s charge to become positive; this is called depolarisation and occurs spontaneously. Once the cell has a sufficiently high charge, the sodium channels close and calcium ions then begin to enter the cell, shortly after which potassium begins to leave it. All the ions travel through ion channels in the membrane of the sinoatrial cells. The potassium and calcium start to move out of and into the cell only once it has a sufficiently high charge, and so are called voltage-gated. Shortly after this, the calcium channels close and potassium channels open, allowing potassium to leave the cell. This causes the cell to have a negative resting charge and is called repolarization. When the membrane potential reaches approximately −60 mV, the potassium channels close and the process may begin again.The ions move from areas where they are concentrated to where they are not. For this reason sodium moves into the cell from outside, and potassium moves from within the cell to outside the cell. Calcium also plays a critical role. Their influx through slow channels means that the sinoatrial cells have a prolonged ""plateau"" phase when they have a positive charge. A part of this is called the absolute refractory period. Calcium ions also combine with the regulatory protein troponin C in the troponin complex to enable contraction of the cardiac muscle, and separate from the protein to allow relaxation.The adult resting heart rate ranges from 60 to 100 bpm. The resting heart rate of a newborn can be 129 beats per minute (bpm) and this gradually decreases until maturity. An athlete\'s heart rate can be lower than 60 bpm. During exercise the rate can be 150 bpm with maximum rates reaching from 200 to 220 bpm.  Influences  The normal sinus rhythm of the heart, giving the resting heart rate, is influenced by a number of factors. The cardiovascular centres in the brainstem control the sympathetic and parasympathetic influences to the heart through the vagus nerve and sympathetic trunk. These cardiovascular centres receive input from a series of receptors including baroreceptors, sensing the stretching of blood vessels and chemoreceptors, sensing the amount of oxygen and carbon dioxide in the blood and its pH. Through a series of reflexes these help regulate and sustain blood flow.Baroreceptors are stretch receptors located in the aortic sinus, carotid bodies, the venae cavae, and other locations, including pulmonary vessels and the right side of the heart itself. Baroreceptors fire at a rate determined by how much they are stretched, which is influenced by blood pressure, level of physical activity, and the relative distribution of blood. With increased pressure and stretch, the rate of baroreceptor firing increases, and the cardiac centers decrease sympathetic stimulation and increase parasympathetic stimulation. As pressure and stretch decrease, the rate of baroreceptor firing decreases, and the cardiac centers increase sympathetic stimulation and decrease parasympathetic stimulation. There is a similar reflex, called the atrial reflex or Bainbridge reflex, associated with varying rates of blood flow to the atria. Increased venous return stretches the walls of the atria where specialized baroreceptors are located. However, as the atrial baroreceptors increase their rate of firing and as they stretch due to the increased blood pressure, the cardiac center responds by increasing sympathetic stimulation and inhibiting parasympathetic stimulation to increase heart rate. The opposite is also true. Chemoreceptors present in the carotid body or adjacent to the aorta in an aortic body respond to the blood\'s oxygen, carbon dioxide levels. Low oxygen or high carbon dioxide will stimulate firing of the receptors.Exercise and fitness levels, age, body temperature, basal metabolic rate, and even a person\'s emotional state can all affect the heart rate. High levels of the hormones epinephrine, norepinephrine, and thyroid hormones can increase the heart rate. The levels of electrolytes including calcium, potassium, and sodium can also influence the speed and regularity of the heart rate; low blood oxygen, low blood pressure and dehydration may increase it.  Clinical significance   Diseases  Cardiovascular diseases, which include diseases of the heart, are the leading cause of death worldwide. The majority of cardiovascular disease is noncommunicable and related to lifestyle and other factors, becoming more prevalent with ageing. Heart disease is a major cause of death, accounting for an average of 30% of all deaths in 2008, globally. This rate varies from a lower 28% to a high 40% in high-income countries. Doctors that specialise in the heart are called cardiologists. Many other medical professionals are involved in treating diseases of the heart, including doctors, cardiothoracic surgeons, intensivists, and allied health practitioners including physiotherapists and dieticians.  Ischemic heart disease  Coronary artery disease, also known as ischemic heart disease, is caused by atherosclerosis—a build-up of fatty material along the inner walls of the arteries. These fatty deposits known as atherosclerotic plaques narrow the coronary arteries, and if severe may reduce blood flow to the heart. If a narrowing (or stenosis) is relatively minor then the patient may not experience any symptoms. Severe narrowings may cause chest pain (angina) or breathlessness during exercise or even at rest. The thin covering of an atherosclerotic plaque can rupture, exposing the fatty centre to the circulating blood. In this case a clot or thrombus can form, blocking the artery, and restricting blood flow to an area of heart muscle causing a myocardial infarction (a heart attack) or unstable angina. In the worst case this may cause cardiac arrest, a sudden and utter loss of output from the heart. Obesity, high blood pressure, uncontrolled diabetes, smoking and high cholesterol can all increase the risk of developing atherosclerosis and coronary artery disease.  Heart failure  Heart failure is defined as a condition in which the heart is unable to pump enough blood to meet the demands of the body. Patients with heart failure may experience breathlessness especially when lying flat, as well as ankle swelling, known as peripheral oedema. Heart failure is the result of many diseases affecting the heart, but is most commonly associated with ischemic heart disease, valvular heart disease, or high blood pressure. Less common causes include various cardiomyopathies. Heart failure is frequently associated with weakness of the heart muscle in the ventricles (systolic heart failure), but can also be seen in patients with heart muscle that is strong but stiff (diastolic heart failure). The condition may affect the left ventricle (causing predominantly breathlessness), the right ventricle (causing predominantly swelling of the legs and an elevated jugular venous pressure), or both ventricles. Patients with heart failure are at higher risk of developing dangerous heart rhythm disturbances or arrhythmias.  Cardiomyopathies  Cardiomyopathies are diseases affecting the muscle of the heart. Some cause abnormal thickening of the heart muscle (hypertrophic cardiomyopathy), some cause the heart to abnormally expand and weaken (dilated cardiomyopathy), some cause the heart muscle to become stiff and unable to fully relax between contractions (restrictive cardiomyopathy) and some make the heart prone to abnormal heart rhythms (arrhythmogenic cardiomyopathy). These conditions are often genetic and can be inherited, but some such as dilated cardiomyopathy may be caused by damage from toxins such as alcohol. Some cardiomyopathies such as hypertrophic cardiomopathy are linked to a higher risk of sudden cardiac death, particularly in athletes. Many cardiomyopathies can lead to heart failure in the later stages of the disease.  Valvular heart disease  Healthy heart valves allow blood to flow easily in one direction, but prevent it from flowing in the other direction. Diseased heart valves may have a narrow opening and therefore restrict the flow of blood in the forward direction (referred to as a stenotic valve), or may allow blood to leak in the reverse direction (referred to as valvular regurgitation). Valvular heart disease may cause breathlessness, blackouts, or chest pain, but may be asymptomatic and only detected on a routine examination by hearing abnormal heart sounds or a heart murmur. In the developed world, valvular heart disease is most commonly caused by degeneration secondary to old age, but may also be caused by infection of the heart valves (endocarditis). In some parts of the world rheumatic heart disease is a major cause of valvular heart disease, typically leading to mitral or aortic stenosis and caused by the body\'s immune system reacting to a streptococcal throat infection.  Cardiac arrhythmias  While in the healthy heart, waves of electrical impulses originate in the sinus node before spreading to the rest of the atria, the atrioventricular node, and finally the ventricles (referred to as a normal sinus rhythm), this normal rhythm can be disrupted. Abnormal heart rhythms or arrhythmias may be asymptomatic or may cause palpitations, blackouts, or breathlessness. Some types of arrhythmia such as atrial fibrillation increase the long term risk of stroke.Some arrhythmias cause the heart to beat abnormally slowly, referred to as a bradycardia or bradyarrhythmia. This may be caused by an abnormally slow sinus node or damage within the cardiac conduction system (heart block). In other arrhythmias the heart may beat abnormally rapidly, referred to as a tachycardia or tachyarrhythmia. These arrhythmias can take many forms and can originate from different structures within the heart—some arise from the atria (e.g. atrial flutter), some from the atrioventricular node (e.g. AV nodal re-entrant tachycardia) whilst others arise from the ventricles (e.g. ventricular tachycardia). Some tachyarrhythmias are caused by scarring within the heart (e.g. some forms of ventricular tachycardia), others by an irritable focus (e.g. focal atrial tachycardia), while others are caused by additional abnormal conduction tissue that has been present since birth (e.g. Wolff-Parkinson-White syndrome). The most dangerous form of heart racing is ventricular fibrillation, in which the ventricles quiver rather than contract, and which if untreated is rapidly fatal.  Pericardial disease  The sac which surrounds the heart, called the pericardium, can become inflamed in a condition known as pericarditis. This condition typically causes chest pain that may spread to the back, and is often caused by a viral infection (glandular fever, cytomegalovirus, or coxsackievirus). Fluid can build up within the pericardial sac, referred to as a pericardial effusion. Pericardial effusions often occur secondary to pericarditis, kidney failure, or tumours, and frequently do not cause any symptoms. However, large effusions or effusions which accumulate rapidly can compress the heart in a condition known as cardiac tamponade, causing breathlessness and potentially fatal low blood pressure. Fluid can be removed from the pericardial space for diagnosis or to relieve tamponade using a syringe in a procedure called pericardiocentesis.  Congenital heart disease  Some people are born with hearts that are abnormal and these abnormalities are known as congenital heart defects. They may range from the relatively minor (e.g. patent foramen ovale, arguably a variant of normal) to serious life-threatening abnormalities (e.g. hypoplastic left heart syndrome). Common abnormalities include those that affect the heart muscle that separates the two side of the heart (a ""hole in the heart"", e.g. ventricular septal defect). Other defects include those affecting the heart valves (e.g. congenital aortic stenosis), or the main blood vessels that lead from the heart (e.g. coarctation of the aorta). More complex syndromes are seen that affect more than one part of the heart (e.g. Tetralogy of Fallot). Some congenital heart defects allow blood that is low in oxygen that would normally be returned to the lungs to instead be pumped back to the rest of the body. These are known as cyanotic congenital heart defects and are often more serious. Major congenital heart defects are often picked up in childhood, shortly after birth, or even before a child is born (e.g. transposition of the great arteries), causing breathlessness and a lower rate of growth. More minor forms of congenital heart disease may remain undetected for many years and only reveal themselves in adult life (e.g., atrial septal defect).  Channelopathies  Channelopathies can be categorized based on the organ system they affect. In the cardiovascular system, the electrical impulse required for each heart beat is provided by the electrochemical gradient of each heart cell. Because the beating of the heart depends on the proper movement of ions across the surface membrane, cardiac ion channelopathies form a major group of heart diseases. Cardiac ion channelopathies may explain some of the cases of sudden death syndrome and sudden arrhythmic death syndrome. Long QT syndrome is the most common form of cardiac channelopathy. Long QT Syndrome (LQTS) - Mostly hereditary. On EKG can be observed as longer corrected QT interval (QTc). Characterized by fainting, sudden, life-threatening heart rhythm disturbances - Torsades de pointes type ventricular tachycardia, ventricular fibrillation and risk of sudden cardiac death. Short QT syndrome. Catecholaminergic polymorphic ventricular tachycardia (CPVT). Progressive cardiac conduction defect (PCCD). Early repolarization syndrome - common in younger and active people, especially men, because it is affected by higher testosterone levels, which cause increased potassium currents, which further causes an elevation of the J-point on the EKG. In very rare cases, it can cause ventricular fibrillation and death. Brugada syndrome - a genetic disorder characterized by an abnormal EKG and is one of the most common causes of sudden cardiac death in young men.  Diagnosis  Heart disease is diagnosed by the taking of a medical history, a cardiac examination, and further investigations, including blood tests, echocardiograms, electrocardiograms, and imaging. Other invasive procedures such as cardiac catheterisation can also play a role.  Examination  The cardiac examination includes inspection, feeling the chest with the hands (palpation) and listening with a stethoscope (auscultation). It involves assessment of signs that may be visible on a person\'s hands (such as splinter haemorrhages), joints and other areas. A person\'s pulse is taken, usually at the radial artery near the wrist, in order to assess for the rhythm and strength of the pulse. The blood pressure is taken, using either a manual or automatic sphygmomanometer or using a more invasive measurement from within the artery. Any elevation of the jugular venous pulse is noted. A person\'s chest is felt for any transmitted vibrations from the heart, and then listened to with a stethoscope.  Heart sounds  Typically, healthy hearts have only two audible heart sounds, called S1 and S2. The first heart sound S1, is the sound created by the closing of the atrioventricular valves during ventricular contraction and is normally described as ""lub"". The second heart sound, S2, is the sound of the semilunar valves closing during ventricular diastole and is described as ""dub"". Each sound consists of two components, reflecting the slight difference in time as the two valves close. S2 may split into two distinct sounds, either as a result of inspiration or different valvular or cardiac problems. Additional heart sounds may also be present and these give rise to gallop rhythms. A third heart sound, S3 usually indicates an increase in ventricular blood volume. A fourth heart sound S4 is referred to as an atrial gallop and is produced by the sound of blood being forced into a stiff ventricle. The combined presence of S3 and S4 give a quadruple gallop.Heart murmurs are abnormal heart sounds which can be either related to disease or benign, and there are several kinds. There are normally two heart sounds, and abnormal heart sounds can either be extra sounds, or ""murmurs"" related to the flow of blood between the sounds. Murmurs are graded by volume, from 1 (the quietest), to 6 (the loudest), and evaluated by their relationship to the heart sounds, position in the cardiac cycle, and additional features such as their radiation to other sites, changes with a person\'s position, the frequency of the sound as determined by the side of the stethoscope by which they are heard, and site at which they are heard loudest. Murmurs may be caused by damaged heart valves or congenital heart disease such as ventricular septal defects, or may be heard in normal hearts. A different type of sound, a pericardial friction rub can be heard in cases of pericarditis where the inflamed membranes can rub together.  Blood tests  Blood tests play an important role in the diagnosis and treatment of many cardiovascular conditions. Troponin is a sensitive biomarker for a heart with insufficient blood supply. It is released 4–6 hours after injury, and usually peaks at about 12–24 hours. Two tests of troponin are often taken—one at the time of initial presentation, and another within 3–6 hours, with either a high level or a significant rise being diagnostic. A test for brain natriuretic peptide (BNP) can be used to evaluate for the presence of heart failure, and rises when there is increased demand on the left ventricle. These tests are considered biomarkers because they are highly specific for cardiac disease. Testing for the MB form of creatine kinase provides information about the heart\'s blood supply, but is used less frequently because it is less specific and sensitive.Other blood tests are often taken to help understand a person\'s general health and risk factors that may contribute to heart disease. These often include a full blood count investigating for anaemia, and basic metabolic panel that may reveal any disturbances in electrolytes. A coagulation screen is often required to ensure that the right level of anticoagulation is given. Fasting lipids and fasting blood glucose (or an HbA1c level) are often ordered to evaluate a person\'s cholesterol and diabetes status, respectively.  Electrocardiogram  Using surface electrodes on the body, it is possible to record the electrical activity of the heart. This tracing of the electrical signal is the electrocardiogram (ECG) or (EKG). An ECG is a bedside test and involves the placement of ten leads on the body. This produces a ""12 lead"" ECG (three extra leads are calculated mathematically, and one lead is electrically ground, or earthed).There are five prominent features on the ECG: the P wave (atrial depolarisation), the QRS complex (ventricular depolarisation) and the T wave (ventricular repolarisation). As the heart cells contract, they create a current that travels through the heart. A downward deflection on the ECG implies cells are becoming more positive in charge (""depolarising"") in the direction of that lead, whereas an upward inflection implies cells are becoming more negative (""repolarising"") in the direction of the lead. This depends on the position of the lead, so if a wave of depolarising moved from left to right, a lead on the left would show a negative deflection, and a lead on the right would show a positive deflection. The ECG is a useful tool in detecting rhythm disturbances and in detecting insufficient blood supply to the heart. Sometimes abnormalities are suspected, but not immediately visible on the ECG. Testing when exercising can be used to provoke an abnormality, or an ECG can be worn for a longer period such as a 24-hour Holter monitor if a suspected rhythm abnormality is not present at the time of assessment.  Imaging  Several imaging methods can be used to assess the anatomy and function of the heart, including ultrasound (echocardiography), angiography, CT, MRI, and PET, scans. An echocardiogram is an ultrasound of the heart used to measure the heart\'s function, assess for valve disease, and look for any abnormalities. Echocardiography can be conducted by a probe on the chest (transthoracic), or by a probe in the esophagus (transesophageal). A typical echocardiography report will include information about the width of the valves noting any stenosis, whether there is any backflow of blood (regurgitation) and information about the blood volumes at the end of systole and diastole, including an ejection fraction, which describes how much blood is ejected from the left and right ventricles after systole. Ejection fraction can then be obtained by dividing the volume ejected by the heart (stroke volume) by the volume of the filled heart (end-diastolic volume). Echocardiograms can also be conducted under circumstances when the body is more stressed, in order to examine for signs of lack of blood supply. This cardiac stress test involves either direct exercise, or where this is not possible, injection of a drug such as dobutamine.CT scans, chest X-rays and other forms of imaging can help evaluate the heart\'s size, evaluate for signs of pulmonary oedema, and indicate whether there is fluid around the heart.","The heart is an organ found in every vertebrate. It is a very strong muscle. It is on the left side of the body in humans and is about the size of a fist. It pumps blood throughout the body. It has regular contractions, or when the heart squeezes the blood out into other parts of the body. Cardiac and cardio both mean ""about the heart"", so if something has the prefix cardio or cardiac, it has something to do with the heart. Myocardium means the heart muscle: 'myo' is from the Greek word for muscle - 'mys', cardium is from the Greek word for heart - 'kardia'.  Structure  The human heart has four chambers or closed spaces. Some animals have only two or three chambers. In humans, the four chambers are two atria and two ventricles. Atria is talking about two chambers; atrium is talking about one chamber. There is a right atrium and right ventricle. These get blood that comes to the heart. They pump this blood to the lungs. In the lungs blood picks up oxygen and drops carbon dioxide. Blood from the lungs goes to the left atrium and ventricle. The left atrium and ventricle send the blood out to the body. The left ventricle works six times harder than the right ventricle because it carries oxygenated blood.Blood is carried in blood vessels. These are arteries and veins. Blood going to the heart is carried in veins. Blood going away from the heart is carried in arteries. The main artery going out of the right ventricle is the pulmonary artery. (Pulmonary means about lungs.) The main artery going out of the left ventricle is the aorta. The veins going into the right atrium are the superior vena cava and inferior vena cava. These bring blood from the body to the right heart. The veins going into the left atrium are the pulmonary veins. These bring blood from the lungs to the left heart. When the blood goes from the atria to the ventricles it goes through heart valves. When blood goes out of the ventricles it goes through valves. The valves make sure that blood only goes one way in or out. The four valves of the heart are: Atria to ventricle valves Tricuspid valve – blood goes from right atrium to right ventricle Mitral valve – blood goes from left atrium to left ventricle Ventricles to arteries Pulmonic valve – blood goes out of the right ventricle to the lungs (through the pulmonic artery) Aortic valve – blood goes out of the left ventricle to the body (through the aorta)The heart has three layers. The outer covering is the pericardium. This is a tough sack that surrounds the heart. The middle layer is the myocardium. This is the heart muscle. The inner layer is the endocardium. This is the thin smooth lining of the chambers of the heart.  Cardiac cycle  A heart beat is when the heart muscle contracts. This means the heart pushes in and this makes the chambers smaller. This pushes blood out of the heart and into the blood vessels. After the heart contracts and pushes in, the muscle relaxes or stops pushing in. The chambers get bigger and blood coming back to the heart fills them. When the heart muscle contracts (pushes in) it is called systole. When the heart muscle relaxes (stops pushing in), this is called diastole. Both atria do systole together. Both ventricles do systole together. But the atria do systole before the ventricles. Even though the atrial systole comes before ventricular systole, all four chambers do diastole at the same time. This is called cardiac diastole The order is: atrial systole → ventricular systole → cardiac diastole. When this happens one time, it is called a cardiac cycle.  Heart's pacemaker  Systole (when the heart squeezes) happens because the muscle cells of the heart gets smaller in size. When they get smaller we also say they contract. Electricity going through the heart makes the cells contract. The electricity starts in the sino-atrial node (acronym SA Node) The SA Node is a group of cells called pacemaker cells in the right atria. These cells start an electrical impulse. This electrical impulse sets the rate and timing at which all cardiac muscle cells contract. This motion is called 'atrial systole'. Once electrical impulse goes through the atrio-ventricular node (AV Node). The AV Node makes the impulse slow down. Slowing down makes the electrical impulses get to the ventricles later. That is what makes the ventricular systole occur after atrial systole, and lets all the blood leave the atria before ventricle contracts (meaning squeeze). After the electrical impulse goes through the AV Node, the electrical impulse will go through the conduction system of the ventricle. Conduction means heat or electricity traveling through something. This brings the electrical impulse to the ventricles. The first part of the conduction system is the bundle of His. His is named for the doctor (Wilhelm His, Jr) who discovered it. Bundle means strings or wires grouped together in parallel. Once the bundle (meaning a group of strings or wires going in parallel directions) goes through the ventricle muscle, it divides into two bundle branches, the left bundle branch and the right bundle branch. The left bundle branch travels to the left ventricle and the right bundle branch travels to the right ventricle. At the end of the bundle branches, the electrical impulse goes into the ventricular muscle through the Purkinje Fibers. This is what makes ventricle contraction take place and makes ventricular systole. The order is: Sino-Atrial Node → Atria (systole) → Atrio-Ventricular Node → Bundle of His → Bundle branches → Purkinje Fibers → Ventricles (systole)  ECG  ECG is an acronym for ElectroCardioGram. It is also written EKG for ElectroKardioGram in German. The ECG shows what the electricity in the heart is doing. An ECG is done by putting electrodes on a person's skin. The electrodes see the electricity going through the heart. This is written on paper by a machine. This writing on the paper is the ECG. Doctors learn about the person's heart by looking at the ECG. The ECG shows some diseases of the heart like heart attacks or problems with the rhythm of the heart (how the electricity goes through the heart's conduction system.) The ECG shows atrial systole. This is called a P-wave. Then ventricular systole happens. This is called the QRS or QRS-complex. It is called a complex because there are three different waves in it. The Q-wave, R-wave, and S-wave. Then the ECG shows ventricular diastole. This is called the T-wave. Atrial diastole happens then too. But it is not seen separate from ventricular diastole. The PR-Interval is the space between atrial systole (P) and ventricular systole (QRS). The QT-Interval is from when the QRS starts to when the T ends. The ST-segment is the space between the QRS and T.  References   Other websites  Symptoms of heart disease What is the heart? - NIH The gross physiology of the cardiovascular system (2nd Ed., 2012) – Robert M. Anderson, M.D. (CC-BY-NC) Atlas of human cardiac anatomy "" healthy heart "" Blog"
"A hand is a prehensile, multi-fingered appendage located at the end of the forearm or forelimb of primates such as humans, chimpanzees, monkeys, and lemurs. A few other vertebrates such as the koala (which has two opposable thumbs on each ""hand"" and fingerprints extremely similar to human fingerprints) are often described as having ""hands"" instead of paws on their front limbs. The raccoon is usually described as having ""hands"" though opposable thumbs are lacking.Some evolutionary anatomists use the term hand to refer to the appendage of digits on the forelimb more generally—for example, in the context of whether the three digits of the bird hand involved the same homologous loss of two digits as in the dinosaur hand.The human hand usually has five digits: four fingers plus one thumb; these are often referred to collectively as five fingers, however, whereby the thumb is included as one of the fingers. It has 27 bones, not including the sesamoid bone, the number of which varies among people, 14 of which are the phalanges (proximal, intermediate and distal) of the fingers and thumb. The metacarpal bones connect the fingers and the carpal bones of the wrist. Each human hand has five metacarpals and eight carpal bones. Fingers contain some of the densest areas of nerve endings in the body, and are the richest source of tactile feedback. They also have the greatest positioning capability of the body; thus, the sense of touch is intimately associated with hands. Like other paired organs (eyes, feet, legs) each hand is dominantly controlled by the opposing brain hemisphere, so that handedness—the preferred hand choice for single-handed activities such as writing with a pencil, reflects individual brain functioning. Among humans, the hands play an important function in body language and sign language. Likewise, the ten digits of two hands and the twelve phalanges of four fingers (touchable by the thumb) have given rise to number systems and calculation techniques.  Structure  Many mammals and other animals have grasping appendages similar in form to a hand such as paws, claws, and talons, but these are not scientifically considered to be grasping hands. The scientific use of the term hand in this sense to distinguish the terminations of the front paws from the hind ones is an example of anthropomorphism. The only true grasping hands appear in the mammalian order of primates. Hands must also have opposable thumbs, as described later in the text. The hand is located at the distal end of each arm. Apes and monkeys are sometimes described as having four hands, because the toes are long and the hallux is opposable and looks more like a thumb, thus enabling the feet to be used as hands. The word ""hand"" is sometimes used by evolutionary anatomists to refer to the appendage of digits on the forelimb such as when researching the homology between the three digits of the bird hand and the dinosaur hand.An adult human male's hand weighs about a pound.  Areas  Areas of the human hand include: The palm (Volar), which is the central region of the anterior part of the hand, located superficially to the metacarpus. The skin in this area contains dermal papillae to increase friction, such as are also present on the fingers and used for fingerprints. The opisthenar area (dorsal) is the corresponding area on the posterior part of the hand. The heel of the hand is the area anteriorly to the bases of the metacarpal bones, located in the proximal part of the palm. It is the area that sustains most pressure when using the palm of the hand for support, such as in handstand.There are five digits attached to the hand, notably with a nail fixed to the end in place of the normal claw. The four fingers can be folded over the palm which allows the grasping of objects. Each finger, starting with the one closest to the thumb, has a colloquial name to distinguish it from the others: index finger, pointer finger, forefinger, or 2nd digit middle finger or long finger or 3rd digit ring finger or 4th digit little finger, pinky finger, small finger, baby finger, or 5th digitThe thumb (connected to the first metacarpal bone and trapezium) is located on one of the sides, parallel to the arm. A reliable way of identifying human hands is from the presence of opposable thumbs. Opposable thumbs are identified by the ability to be brought opposite to the fingers, a muscle action known as opposition.  Bones  The skeleton of the human hand consists of 27 bones: the eight short carpal bones of the wrist are organized into a proximal row (scaphoid, lunate, triquetral and pisiform) which articulates with the bones of the forearm, and a distal row (trapezium, trapezoid, capitate and hamate), which articulates with the bases of the five metacarpal bones of the hand. The heads of the metacarpals will each in turn articulate with the bases of the proximal phalanx of the fingers and thumb. These articulations with the fingers are the metacarpophalangeal joints known as the knuckles. At the palmar aspect of the first metacarpophalangeal joints are small, almost spherical bones called the sesamoid bones. The fourteen phalanges make up the fingers and thumb, and are numbered I-V (thumb to little finger) when the hand is viewed from an anatomical position (palm up). The four fingers each consist of three phalanx bones: proximal, middle, and distal. The thumb only consists of a proximal and distal phalanx. Together with the phalanges of the fingers and thumb these metacarpal bones form five rays or poly-articulated chains. Because supination and pronation (rotation about the axis of the forearm) are added to the two axes of movements of the wrist, the ulna and radius are sometimes considered part of the skeleton of the hand. There are numerous sesamoid bones in the hand, small ossified nodes embedded in tendons; the exact number varies between people: whereas a pair of sesamoid bones are found at virtually all thumb metacarpophalangeal joints, sesamoid bones are also common at the interphalangeal joint of the thumb (72.9%) and at the metacarpophalangeal joints of the little finger (82.5%) and the index finger (48%). In rare cases, sesamoid bones have been found in all the metacarpophalangeal joints and all distal interphalangeal joints except that of the long finger. The articulations are: interphalangeal articulations of hand (the hinge joints between the bones of the digits) metacarpophalangeal joints (where the digits meet the palm) intercarpal articulations (where the palm meets the wrist) wrist (may also be viewed as belonging to the forearm).  Arches  The fixed and mobile parts of the hand adapt to various everyday tasks by forming bony arches: longitudinal arches (the rays formed by the finger bones and their associated metacarpal bones), transverse arches (formed by the carpal bones and distal ends of the metacarpal bones), and oblique arches (between the thumb and four fingers): Of the longitudinal arches or rays of the hand, that of the thumb is the most mobile (and the least longitudinal). While the ray formed by the little finger and its associated metacarpal bone still offers some mobility, the remaining rays are firmly rigid. The phalangeal joints of the index finger, however, offer some independence to its finger, due to the arrangement of its flexor and extension tendons.The carpal bones form two transversal rows, each forming an arch concave on the palmar side. Because the proximal arch simultaneously has to adapt to the articular surface of the radius and to the distal carpal row, it is by necessity flexible. In contrast, the capitate, the ""keystone"" of the distal arch, moves together with the metacarpal bones and the distal arch is therefore rigid. The stability of these arches is more dependent of the ligaments and capsules of the wrist than of the interlocking shapes of the carpal bones, and the wrist is therefore more stable in flexion than in extension. The distal carpal arch affects the function of the CMC joints and the hands, but not the function of the wrist or the proximal carpal arch. The ligaments that maintain the distal carpal arches are the transverse carpal ligament and the intercarpal ligaments (also oriented transversally). These ligaments also form the carpal tunnel and contribute to the deep and superficial palmar arches. Several muscle tendons attaching to the TCL and the distal carpals also contribute to maintaining the carpal arch.Compared to the carpal arches, the arch formed by the distal ends of the metacarpal bones is flexible due to the mobility of the peripheral metacarpals (thumb and little finger). As these two metacarpals approach each other, the palmar gutter deepens. The central-most metacarpal (middle finger) is the most rigid. It and its two neighbors are tied to the carpus by the interlocking shapes of the metacarpal bones. The thumb metacarpal only articulates with the trapezium and is therefore completely independent, while the fifth metacarpal (little finger) is semi-independent with the fourth metacarpal (ring finger) which forms a transitional element to the fifth metacarpal.Together with the thumb, the four fingers form four oblique arches, of which the arch of the index finger functionally is the most important, especially for precision grip, while the arch of the little finger contribute an important locking mechanism for power grip. The thumb is undoubtedly the ""master digit"" of the hand, giving value to all the other fingers. Together with the index and middle finger, it forms the dynamic tridactyl configuration responsible for most grips not requiring force. The ring and little fingers are more static, a reserve ready to interact with the palm when great force is needed.  Muscles  The muscles acting on the hand can be subdivided into two groups: the extrinsic and intrinsic muscle groups. The extrinsic muscle groups are the long flexors and extensors. They are called extrinsic because the muscle belly is located on the forearm.  Intrinsic  The intrinsic muscle groups are the thenar (thumb) and hypothenar (little finger) muscles; the interosseous muscles (four dorsally and three volarly) originating between the metacarpal bones; and the lumbrical muscles arising from the deep flexor (and are special because they have no bony origin) to insert on the dorsal extensor hood mechanism.  Extrinsic  The fingers have two long flexors, located on the underside of the forearm. They insert by tendons to the phalanges of the fingers. The deep flexor attaches to the distal phalanx, and the superficial flexor attaches to the middle phalanx. The flexors allow for the actual bending of the fingers. The thumb has one long flexor and a short flexor in the thenar muscle group. The human thumb also has other muscles in the thenar group (opponens and abductor brevis muscle), moving the thumb in opposition, making grasping possible. The extensors are located on the back of the forearm and are connected in a more complex way than the flexors to the dorsum of the fingers. The tendons unite with the interosseous and lumbrical muscles to form the extensorhood mechanism. The primary function of the extensors is to straighten out the digits. The thumb has two extensors in the forearm; the tendons of these form the anatomical snuff box. Also, the index finger and the little finger have an extra extensor used, for instance, for pointing. The extensors are situated within 6 separate compartments. The first four compartments are located in the grooves present on the dorsum of inferior side of radius while the 5th compartment is in between radius and ulna. The 6th compartment is in the groove on the dorsum of inferior side of ulna.  Nerve supply  The hand is innervated by the radial, median, and ulnar nerves. MotorThe radial nerve supplies the finger extensors and the thumb abductor, thus the muscles that extends at the wrist and metacarpophalangeal joints (knuckles); and that abducts and extends the thumb. The median nerve supplies the flexors of the wrist and digits, the abductors and opponens of the thumb, the first and second lumbrical. The ulnar nerve supplies the remaining intrinsic muscles of the hand.All muscles of the hand are innervated by the brachial plexus (C5–T1) and can be classified by innervation: SensoryThe radial nerve supplies the skin on the back of the hand from the thumb to the ring finger and the dorsal aspects of the index, middle, and half ring fingers as far as the proximal interphalangeal joints. The median nerve supplies the palmar side of the thumb, index, middle, and half ring fingers. Dorsal branches innervates the distal phalanges of the index, middle, and half ring fingers. The ulnar nerve supplies the ulnar third of the hand, both at the palm and the back of the hand, and the little and half ring fingers.There is a considerable variation to this general pattern, except for the little finger and volar surface of the index finger. For example, in some individuals, the ulnar nerve supplies the entire ring finger and the ulnar side of the middle finger, whilst, in others, the median nerve supplies the entire ring finger.  Blood supply  The hand is supplied with blood from two arteries, the ulnar artery and the radial artery. These arteries form three arches over the dorsal and palmar aspects of the hand, the dorsal carpal arch (across the back of the hand), the deep palmar arch, and the superficial palmar arch. Together these three arches and their anastomoses provide oxygenated blood to the palm, the fingers, and the thumb. The hand is drained by the dorsal venous network of the hand with deoxygenated blood leaving the hand via the cephalic vein and the basilic vein.  Skin  The glabrous (hairless) skin on the front of the hand, the palm, is relatively thick and can be bent along the hand's flexure lines where the skin is tightly bound to the underlying tissue and bones. Compared to the rest of the body's skin, the hands' palms (as well as the soles of the feet) are usually lighter—and even much lighter in dark-skinned individuals, compared to the other side of the hand. Indeed, genes specifically expressed in the dermis of palmoplantar skin inhibit melanin production and thus the ability to tan, and promote the thickening of the stratum lucidum and stratum corneum layers of the epidermis. All parts of the skin involved in grasping are covered by papillary ridges (fingerprints) acting as friction pads. In contrast, the hairy skin on the dorsal side is thin, soft, and pliable, so that the skin can recoil when the fingers are stretched. On the dorsal side, the skin can be moved across the hand up to 3 cm (1.2 in); an important input the cutaneous mechanoreceptors.The web of the hand is a ""fold of skin which connects the digits"". These webs, located between each set of digits, are known as skin folds (interdigital folds or plica interdigitalis). They are defined as ""one of the folds of skin, or rudimentary web, between the fingers and toes"".  Variation  The ratio of the length of the index finger to the length of the ring finger in adults is affected by the level of exposure to male sex hormones of the embryo in utero. This digit ratio is below 1 for both sexes but it is lower in males than in females on average.  Clinical significance  A number of genetic disorders affect the hand. Polydactyly is the presence of more than the usual number of fingers. One of the disorders that can cause this is Catel-Manzke syndrome. The fingers may be fused in a disorder known as syndactyly. Or there may be an absence of one or more central fingers—a condition known as ectrodactyly. Additionally, some people are born without one or both hands (amelia). Hereditary multiple exostoses of the forearm—also known as hereditary multiple osteochondromas—is another cause of hand and forearm deformity in children and adults.There are several cutaneous conditions that can affect the hand including the nails. The autoimmune disease rheumatoid arthritis can affect the hand, particularly the joints of the fingers. Some conditions can be treated by hand surgery. These include carpal tunnel syndrome, a painful condition of the hand and fingers caused by compression of the median nerve, and Dupuytren's contracture, a condition in which fingers bend towards the palm and cannot be straightened. Similarly, injury to the ulnar nerve may result in a condition in which some of the fingers cannot be flexed. A common fracture of the hand is a scaphoid fracture—a fracture of the scaphoid bone, one of the carpal bones. This is the commonest carpal bone fracture and can be slow to heal due to a limited blood flow to the bone. There are various types of fracture to the base of the thumb; these are known as Rolando fractures, Bennet's fracture, and Gamekeeper's thumb. Another common fracture, known as Boxer's fracture, is to the neck of a metacarpal. One can also have a broken finger.  Evolution  The prehensile hands and feet of primates evolved from the mobile hands of semi-arboreal tree shrews that lived about 60 million years ago. This development has been accompanied by important changes in the brain and the relocation of the eyes to the front of the face, together allowing the muscle control and stereoscopic vision necessary for controlled grasping. This grasping, also known as power grip, is supplemented by the precision grip between the thumb and the distal finger pads made possible by the opposable thumbs. Hominidae (great apes including humans) acquired an erect bipedal posture about 3.6 million years ago, which freed the hands from the task of locomotion and paved the way for the precision and range of motion in human hands. Functional analyses of the features unique to the hand of modern humans have shown that they are consistent with the stresses and requirements associated with the effective use of paleolithic stone tools. It is possible that the refinement of the bipedal posture in the earliest hominids evolved to facilitate the use of the trunk as leverage in accelerating the hand.While the human hand has unique anatomical features, including a longer thumb and fingers that can be controlled individually to a higher degree, the hands of other primates are anatomically similar and the dexterity of the human hand can not be explained solely on anatomical factors. The neural machinery underlying hand movements is a major contributing factor; primates have evolved direct connections between neurons in cortical motor areas and spinal motoneurons, giving the cerebral cortex monosynaptic control over the motoneurons of the hand muscles; placing the hands ""closer"" to the brain. The recent evolution of the human hand is thus a direct result of the development of the central nervous system, and the hand, therefore, is a direct tool of our consciousness—the main source of differentiated tactile sensations—and a precise working organ enabling gestures—the expressions of our personalities. There are nevertheless several primitive features left in the human hand, including pentadactyly (having five fingers), the hairless skin of the palm and fingers, and the os centrale found in human embryos, prosimians, and apes. Furthermore, the precursors of the intrinsic muscles of the hand are present in the earliest fishes, reflecting that the hand evolved from the pectoral fin and thus is much older than the arm in evolutionary terms.The proportions of the human hand are plesiomorphic (shared by both ancestors and extant primate species); the elongated thumbs and short hands more closely resemble the hand proportions of Miocene apes than those of extant primates. Humans did not evolve from knuckle-walking apes, and chimpanzees and gorillas independently acquired elongated metacarpals as part of their adaptation to their modes of locomotion. Several primitive hand features most likely present in the chimpanzee–human last common ancestor (CHLCA) and absent in modern humans are still present in the hands of Australopithecus, Paranthropus, and Homo floresiensis. This suggests that the derived changes in modern humans and Neanderthals did not evolve until 2.5 to 1.5 million years ago or after the appearance of the earliest Acheulian stone tools, and that these changes are associated with tool-related tasks beyond those observed in other hominins. The thumbs of Ardipithecus ramidus, an early hominin, are almost as robust as in humans, so this may be a primitive trait, while the palms of other extant higher primates are elongated to the extent that some of the thumb's original function has been lost (most notably in highly arboreal primates such as the spider monkey). In humans, the big toe is thus more derived than the thumb.There is a hypothesis suggesting the form of the modern human hand is especially conducive to the formation of a compact fist, presumably for fighting purposes. The fist is compact and thus effective as a weapon. It also provides protection for the fingers. However, this is not widely accepted to be one of the primary selective pressures acting on hand morphology throughout human evolution, with tool use and production being thought to be far more influential.  Additional images   See also   References   External links  Hand anatomy (eMedicine) Film Board of Canada documentary Faces of the Hand ""The Common Hand"" Archived 2016-07-13 at the Wayback Machine article in the May 2012 National Geographic","A hand is the part of the body at the end of an arm. Most humans have two hands. Each hand usually has four fingers and a thumb. On the inside of the hand is the palm. The five bones inside this part of the hand are called metacarpals. The wrist connects the hand to the arm. The hand has 27 bones including the wrist bones. When the fingers are all bent tightly, the hand forms a fist. The joints that are the hardest part of the fist are called knuckles. Many other animals, especially other primates, have hands that can hold things. Human hands can do things other hands cannot.  Related pages  Foot  Other websites  Hand anatomy (eMedicine)"
"A head is the part of an organism which usually includes the ears, brain, forehead, cheeks, chin, eyes, nose, and mouth, each of which aid in various sensory functions such as sight, hearing, smell, and taste. Some very simple animals may not have a head, but many bilaterally symmetric forms do, regardless of size. Heads develop in animals by an evolutionary trend known as cephalization. In bilaterally symmetrical animals, nervous tissue concentrate at the anterior region, forming structures responsible for information processing. Through biological evolution, sense organs and feeding structures also concentrate into the anterior region; these collectively form the head.  Human head  The human head is an anatomical unit that consists of the skull, hyoid bone and cervical vertebrae. The term ""skull"" collectively denotes the mandible (lower jaw bone) and the cranium (upper portion of the skull that houses the brain).Sculptures of human heads are generally based on a skeletal structure that consists of a cranium, jawbone, and cheekbone. Though the number of muscles making up the face is generally consistent between sculptures, the shape of the muscles varies widely based on the function, development, and expressions reflected on the faces of the subjects.Proponents of identism believe that the mind is identical to the brain. Philosopher John Searle asserts his identist beliefs, stating ""the brain is the only thing in the human head"". Similarly, Dr. Henry Bennet-Clark has stated that the head encloses billions of ""miniagents and microagents (with no single Boss)"".  Other animals  The evolution of a head is associated with the cephalization that occurred in Bilateria some 555 million years ago.  Arthropods  In some arthropods, especially trilobites (pictured at right), the cephalon, or cephalic region, is the region of the head which is a collective of ""fused segments"".  Insects  A typical insect head is composed of eyes, antennae, and components of mouth. As these components differ substantially from insect to insect, they form important identification links. Eyes in the head found, in several types of insects, are in the form of a pair of compound eyes with multiple faces. In many other types of insects, the compound eyes are seen in a ""single facet or group of single facets"". In some cases, the eyes may be seen as marks on the dorsal or located near or toward the head, two or three ocelli (single faceted organs).Antennae on the insect's head is found in the form of segmented attachments, in pairs, that are usually located between the eyes. These are in varying shapes and sizes, in the form of filaments or in different enlarged or clubbed form.Insects have mouth parts in various shapes depending on their feeding habits. Labrum is the ""upper lip"" which is in the front area of the head and is the most exterior part. A pair of mandibles is found on the backside of the labrum flanking the side of the mouth, succeeded by a pair of maxillae each of which is known as maxilliary palp. At the back side of the mouth is the labium or lower lip. There is also an extra mouth part in some insects which is termed as hypopharynx which is usually located between the maxillac.  Vertebrates and the ""new head hypothesis""  Though invertebrate chordates – such as the tunicate larvae or the lancelets – have heads, there has been a question of how the vertebrate head, characterized by a bony skull clearly separated from the main body, might have evolved from the head structures of these animals.According to Hyman (1979), the evolution of the head in the vertebrates has occurred by the fusion of a fixed number of anterior segments, in the same manner as in other ""heteronomously segmented animals"". In some cases, segments or a portion of the segments disappear. The head segments also lose most of their systems, except for the nervous system. With the progressive development of cephalization, ""the head incorporates more and more of the adjacent segments into its structure, so that in general it may be said that the higher the degree of cephalization the greater is the number of segments composing the head"".In the 1980s, the ""new head hypothesis"" was proposed, suggesting that the vertebrate head is an evolutionary novelty resulting from the emergence of neural crest and cranial placodes. In 2014, a transient larva tissue of the lancelet was found to be virtually indistinguishable from the neural crest-derived cartilage which forms the vertebrate skull, suggesting that persistence of this tissue and expansion into the entire headspace could be a viable evolutionary route to formation of the vertebrate head.  In society and culture   Heraldry  The heads of humans and other animals are commonly recurring charges in heraldry. Heads of humans are sometimes blazoned simply as a ""man's head"", but are far more frequently described in greater detail, either characteristic of a particular race or nationality (such as Moors' heads, Saxons' heads, Egyptians' heads or Turks' heads), or specifically identified (such as the head of Moses in the crest of Hilton, or the head of St. John the Baptist in the crest of the London Company of Tallowchandlers). Several varieties of women's heads also occur, including maidens' heads (often couped under the bust, with hair disheveled), ladies' heads, nuns' heads (often veiled), and occasionally queens' heads. The arms of Devaney of Norfolk include ""three nun's heads veiled couped at the shoulders proper,"" and the bust of a queen occurs in the arms of Queenborough, Kent. Infants' or children's heads are often couped at the shoulders with a snake wrapped around the neck (e.g. ""Argent, a boy's head proper, crined or, couped below the shoulders, vested gules, tarnished gold,"" in the arms of Boyman).  Art  One of the ways of drawing sketches of heads—as Jack Hamm advises—is to develop it in six well-defined steps, starting with the shape of the head in the shape of an egg. The female head, in particular, is sketched in a double circle design procedure with proportions considered as an ideal of a female head. In the first circle, the division is made of five sections on the diameter, each section of five eyes width. It is then developed over a series of ten defined steps, with the smaller circle imposed partially over the larger circle at the lower end at the fourth stage. Eyes and chins are fitted in various shapes to form the head.Leonardo da Vinci, considered one of the world's greatest artists, drew sketches of human anatomy using grid structures. His image of the face drawn on the grid structure principle is in perfect proportion. In this genre, using the technique of pen and ink, Leonardo created a sketch which is a ""Study on the proportions of head and eyes"" (pictured).  Idiomatic expressions  An idiom is a phrase or a fixed expression that has a figurative, or sometimes literal, meaning. ""To be big-headed"" - to be overly full of oneself ""To come to a head"" – to reach a critical stage and require immediate action ""To bite someone's head off"" – to criticize someone strongly ""Can't make head or tail of something"" – cannot understand something ""A head start"" – an early start that provides an advantage over others ""Head and shoulders above someone or something"" – better than someone or something in some way ""To want someone's head on a platter"" – to want someone severely punished ""To bang your head against a brick wall"" – to continually try to achieve something without success ""To have one's head in the clouds"" – to not pay attention to what is happening around one because one is so absorbed by one's own thoughts  Engineering and scientific fields  The head's function and appearance play an analogous role in the etymology of many technical terms. Cylinder head, pothead, and weatherhead are three such examples.  Gallery   See also  Cephalic disorder Cephalic flexure Cephalic index Cephalic phase Cephalic presentation Cephalic vein Circle of Animals/Zodiac Heads – an artwork by Chinese contemporary artist and political commentator Ai Weiwei Cynocephaly – a characteristic of having the head of a dog or of a jackal. It is a widely attested mythical phenomenon existing in many forms and contexts. Khutang – a type of harp often surmounted by a carven animal head, often a swan Theriocephaly – in some religious beliefs, the condition or quality of having the head of an animal, commonly used to refer the depiction in art of humans (or deities) with animal heads  References   Further reading  Lieberman, Daniel E. (3 May 2011). Evolution of the Human Head. Harvard University Press. ISBN 978-0-674-05944-3.","The head is the part of the body where the brain is. It is also where the face is. Different things may be worn on the head, for example a headband or a hat. Some people get pains in their head occasionally, known as headaches. Also, some people have worse pains in their head called migraines. A head in English can also mean a person in charge of something, such as the head of a company. Also, the word head can also mean the front of something. An example of this is the word ""Headline"", meaning large words on the front page of a newspaper."
"A brain is an organ that serves as the center of the nervous system in all vertebrate and most invertebrate animals. It is located in the head, usually close to the sensory organs for senses such as vision. It is the most complex organ in a vertebrate\'s body. In a human, the cerebral cortex contains approximately 14–16 billion neurons, and the estimated number of neurons in the cerebellum is 55–70 billion. Each neuron is connected by synapses to several thousand other neurons. These neurons typically communicate with one another by means of long fibers called axons, which carry trains of signal pulses called action potentials to distant parts of the brain or body targeting specific recipient cells. Physiologically, brains exert centralized control over a body\'s other organs. They act on the rest of the body both by generating patterns of muscle activity and by driving the secretion of chemicals called hormones. This centralized control allows rapid and coordinated responses to changes in the environment. Some basic types of responsiveness such as reflexes can be mediated by the spinal cord or peripheral ganglia, but sophisticated purposeful control of behavior based on complex sensory input requires the information integrating capabilities of a centralized brain. The operations of individual brain cells are now understood in considerable detail but the way they cooperate in ensembles of millions is yet to be solved. Recent models in modern neuroscience treat the brain as a biological computer, very different in mechanism from an electronic computer, but similar in the sense that it acquires information from the surrounding world, stores it, and processes it in a variety of ways. This article compares the properties of brains across the entire range of animal species, with the greatest attention to vertebrates. It deals with the human brain insofar as it shares the properties of other brains. The ways in which the human brain differs from other brains are covered in the human brain article. Several topics that might be covered here are instead covered there because much more can be said about them in a human context. The most important that are covered in the human brain article are brain disease and the effects of brain damage.  Anatomy  The shape and size of the brain varies greatly between species, and identifying common features is often difficult. Nevertheless, there are a number of principles of brain architecture that apply across a wide range of species. Some aspects of brain structure are common to almost the entire range of animal species; others distinguish ""advanced"" brains from more primitive ones, or distinguish vertebrates from invertebrates.The simplest way to gain information about brain anatomy is by visual inspection, but many more sophisticated techniques have been developed. Brain tissue in its natural state is too soft to work with, but it can be hardened by immersion in alcohol or other fixatives, and then sliced apart for examination of the interior. Visually, the interior of the brain consists of areas of so-called grey matter, with a dark color, separated by areas of white matter, with a lighter color. Further information can be gained by staining slices of brain tissue with a variety of chemicals that bring out areas where specific types of molecules are present in high concentrations. It is also possible to examine the microstructure of brain tissue using a microscope, and to trace the pattern of connections from one brain area to another.  Cellular structure  The brains of all species are composed primarily of two broad classes of cells: neurons and glial cells. Glial cells (also known as glia or neuroglia) come in several types, and perform a number of critical functions, including structural support, metabolic support, insulation, and guidance of development. Neurons, however, are usually considered the most important cells in the brain. The property that makes neurons unique is their ability to send signals to specific target cells over long distances. They send these signals by means of an axon, which is a thin protoplasmic fiber that extends from the cell body and projects, usually with numerous branches, to other areas, sometimes nearby, sometimes in distant parts of the brain or body. The length of an axon can be extraordinary: for example, if a pyramidal cell (an excitatory neuron) of the cerebral cortex were magnified so that its cell body became the size of a human body, its axon, equally magnified, would become a cable a few centimeters in diameter, extending more than a kilometer. These axons transmit signals in the form of electrochemical pulses called action potentials, which last less than a thousandth of a second and travel along the axon at speeds of 1–100 meters per second. Some neurons emit action potentials constantly, at rates of 10–100 per second, usually in irregular patterns; other neurons are quiet most of the time, but occasionally emit a burst of action potentials.Axons transmit signals to other neurons by means of specialized junctions called synapses. A single axon may make as many as several thousand synaptic connections with other cells. When an action potential, traveling along an axon, arrives at a synapse, it causes a chemical called a neurotransmitter to be released. The neurotransmitter binds to receptor molecules in the membrane of the target cell.Synapses are the key functional elements of the brain. The essential function of the brain is cell-to-cell communication, and synapses are the points at which communication occurs. The human brain has been estimated to contain approximately 100 trillion synapses; even the brain of a fruit fly contains several million. The functions of these synapses are very diverse: some are excitatory (exciting the target cell); others are inhibitory; others work by activating second messenger systems that change the internal chemistry of their target cells in complex ways. A large number of synapses are dynamically modifiable; that is, they are capable of changing strength in a way that is controlled by the patterns of signals that pass through them. It is widely believed that activity-dependent modification of synapses is the brain\'s primary mechanism for learning and memory.Most of the space in the brain is taken up by axons, which are often bundled together in what are called nerve fiber tracts. A myelinated axon is wrapped in a fatty insulating sheath of myelin, which serves to greatly increase the speed of signal propagation. (There are also unmyelinated axons). Myelin is white, making parts of the brain filled exclusively with nerve fibers appear as light-colored white matter, in contrast to the darker-colored grey matter that marks areas with high densities of neuron cell bodies.  Evolution   Generic bilaterian nervous system  Except for a few primitive organisms such as sponges (which have no nervous system) and cnidarians (which have a nervous system consisting of a diffuse nerve net), all living multicellular animals are bilaterians, meaning animals with a bilaterally symmetric body shape (that is, left and right sides that are approximate mirror images of each other). All bilaterians are thought to have descended from a common ancestor that appeared late in the Cryogenian period, 700–650 million years ago, and it has been hypothesized that this common ancestor had the shape of a simple tubeworm with a segmented body. At a schematic level, that basic worm-shape continues to be reflected in the body and nervous system architecture of all modern bilaterians, including vertebrates. The fundamental bilateral body form is a tube with a hollow gut cavity running from the mouth to the anus, and a nerve cord with an enlargement (a ganglion) for each body segment, with an especially large ganglion at the front, called the brain. The brain is small and simple in some species, such as nematode worms; in other species, including vertebrates, it is the most complex organ in the body. Some types of worms, such as leeches, also have an enlarged ganglion at the back end of the nerve cord, known as a ""tail brain"".There are a few types of existing bilaterians that lack a recognizable brain, including echinoderms and tunicates. It has not been definitively established whether the existence of these brainless species indicates that the earliest bilaterians lacked a brain, or whether their ancestors evolved in a way that led to the disappearance of a previously existing brain structure.  Invertebrates  This category includes tardigrades, arthropods, molluscs, and numerous types of worms. The diversity of invertebrate body plans is matched by an equal diversity in brain structures.Two groups of invertebrates have notably complex brains: arthropods (insects, crustaceans, arachnids, and others), and cephalopods (octopuses, squids, and similar molluscs). The brains of arthropods and cephalopods arise from twin parallel nerve cords that extend through the body of the animal. Arthropods have a central brain, the supraesophageal ganglion, with three divisions and large optical lobes behind each eye for visual processing. Cephalopods such as the octopus and squid have the largest brains of any invertebrates.There are several invertebrate species whose brains have been studied intensively because they have properties that make them convenient for experimental work: Fruit flies (Drosophila), because of the large array of techniques available for studying their genetics, have been a natural subject for studying the role of genes in brain development. In spite of the large evolutionary distance between insects and mammals, many aspects of Drosophila neurogenetics have been shown to be relevant to humans. The first biological clock genes, for example, were identified by examining Drosophila mutants that showed disrupted daily activity cycles. A search in the genomes of vertebrates revealed a set of analogous genes, which were found to play similar roles in the mouse biological clock—and therefore almost certainly in the human biological clock as well. Studies done on Drosophila, also show that most neuropil regions of the brain are continuously reorganized throughout life in response to specific living conditions. The nematode worm Caenorhabditis elegans, like Drosophila, has been studied largely because of its importance in genetics. In the early 1970s, Sydney Brenner chose it as a model organism for studying the way that genes control development. One of the advantages of working with this worm is that the body plan is very stereotyped: the nervous system of the hermaphrodite contains exactly 302 neurons, always in the same places, making identical synaptic connections in every worm. Brenner\'s team sliced worms into thousands of ultrathin sections and photographed each one under an electron microscope, then visually matched fibers from section to section, to map out every neuron and synapse in the entire body. The complete neuronal wiring diagram of C.elegans – its connectome was achieved. Nothing approaching this level of detail is available for any other organism, and the information gained has enabled a multitude of studies that would otherwise have not been possible. The sea slug Aplysia californica was chosen by Nobel Prize-winning neurophysiologist Eric Kandel as a model for studying the cellular basis of learning and memory, because of the simplicity and accessibility of its nervous system, and it has been examined in hundreds of experiments.  Vertebrates  The first vertebrates appeared over 500 million years ago (Mya), during the Cambrian period, and may have resembled the modern hagfish in form. Jawed fish appeared by 445 Mya, amphibians by 350 Mya, reptiles by 310 Mya and mammals by 200 Mya (approximately). Each species has an equally long evolutionary history, but the brains of modern hagfishes, lampreys, sharks, amphibians, reptiles, and mammals show a gradient of size and complexity that roughly follows the evolutionary sequence. All of these brains contain the same set of basic anatomical components, but many are rudimentary in the hagfish, whereas in mammals the foremost part (the telencephalon) is greatly elaborated and expanded.Brains are most commonly compared in terms of their size. The relationship between brain size, body size and other variables has been studied across a wide range of vertebrate species. As a rule, brain size increases with body size, but not in a simple linear proportion. In general, smaller animals tend to have larger brains, measured as a fraction of body size. For mammals, the relationship between brain volume and body mass essentially follows a power law with an exponent of about 0.75. This formula describes the central tendency, but every family of mammals departs from it to some degree, in a way that reflects in part the complexity of their behavior. For example, primates have brains 5 to 10 times larger than the formula predicts. Predators tend to have larger brains than their prey, relative to body size. All vertebrate brains share a common underlying form, which appears most clearly during early stages of embryonic development. In its earliest form, the brain appears as three swellings at the front end of the neural tube; these swellings eventually become the forebrain, midbrain, and hindbrain (the prosencephalon, mesencephalon, and rhombencephalon, respectively). At the earliest stages of brain development, the three areas are roughly equal in size. In many classes of vertebrates, such as fish and amphibians, the three parts remain similar in size in the adult, but in mammals the forebrain becomes much larger than the other parts, and the midbrain becomes very small.The brains of vertebrates are made of very soft tissue. Living brain tissue is pinkish on the outside and mostly white on the inside, with subtle variations in color. Vertebrate brains are surrounded by a system of connective tissue membranes called meninges that separate the skull from the brain. Blood vessels enter the central nervous system through holes in the meningeal layers. The cells in the blood vessel walls are joined tightly to one another, forming the blood–brain barrier, which blocks the passage of many toxins and pathogens (though at the same time blocking antibodies and some drugs, thereby presenting special challenges in treatment of diseases of the brain).Neuroanatomists usually divide the vertebrate brain into six main regions: the telencephalon (cerebral hemispheres), diencephalon (thalamus and hypothalamus), mesencephalon (midbrain), cerebellum, pons, and medulla oblongata. Each of these areas has a complex internal structure. Some parts, such as the cerebral cortex and the cerebellar cortex, consist of layers that are folded or convoluted to fit within the available space. Other parts, such as the thalamus and hypothalamus, consist of clusters of many small nuclei. Thousands of distinguishable areas can be identified within the vertebrate brain based on fine distinctions of neural structure, chemistry, and connectivity. Although the same basic components are present in all vertebrate brains, some branches of vertebrate evolution have led to substantial distortions of brain geometry, especially in the forebrain area. The brain of a shark shows the basic components in a straightforward way, but in teleost fishes (the great majority of existing fish species), the forebrain has become ""everted"", like a sock turned inside out. In birds, there are also major changes in forebrain structure. These distortions can make it difficult to match brain components from one species with those of another species.Here is a list of some of the most important vertebrate brain components, along with a brief description of their functions as currently understood: The medulla, along with the spinal cord, contains many small nuclei involved in a wide variety of sensory and involuntary motor functions such as vomiting, heart rate and digestive processes. The pons lies in the brainstem directly above the medulla. Among other things, it contains nuclei that control often voluntary but simple acts such as sleep, respiration, swallowing, bladder function, equilibrium, eye movement, facial expressions, and posture. The hypothalamus is a small region at the base of the forebrain, whose complexity and importance belies its size. It is composed of numerous small nuclei, each with distinct connections and neurochemistry. The hypothalamus is engaged in additional involuntary or partially voluntary acts such as sleep and wake cycles, eating and drinking, and the release of some hormones. The thalamus is a collection of nuclei with diverse functions: some are involved in relaying information to and from the cerebral hemispheres, while others are involved in motivation. The subthalamic area (zona incerta) seems to contain action-generating systems for several types of ""consummatory"" behaviors such as eating, drinking, defecation, and copulation. The cerebellum modulates the outputs of other brain systems, whether motor-related or thought related, to make them certain and precise. Removal of the cerebellum does not prevent an animal from doing anything in particular, but it makes actions hesitant and clumsy. This precision is not built-in but learned by trial and error. The muscle coordination learned while riding a bicycle is an example of a type of neural plasticity that may take place largely within the cerebellum. 10% of the brain\'s total volume consists of the cerebellum and 50% of all neurons are held within its structure. The optic tectum allows actions to be directed toward points in space, most commonly in response to visual input. In mammals, it is usually referred to as the superior colliculus, and its best-studied function is to direct eye movements. It also directs reaching movements and other object-directed actions. It receives strong visual inputs, but also inputs from other senses that are useful in directing actions, such as auditory input in owls and input from the thermosensitive pit organs in snakes. In some primitive fishes, such as lampreys, this region is the largest part of the brain. The superior colliculus is part of the midbrain. The pallium is a layer of grey matter that lies on the surface of the forebrain and is the most complex and most recent evolutionary development of the brain as an organ. In reptiles and mammals, it is called the cerebral cortex. Multiple functions involve the pallium, including smell and spatial memory. In mammals, where it becomes so large as to dominate the brain, it takes over functions from many other brain areas. In many mammals, the cerebral cortex consists of folded bulges called gyri that create deep furrows or fissures called sulci. The folds increase the surface area of the cortex and therefore increase the amount of gray matter and the amount of information that can be stored and processed. The hippocampus, strictly speaking, is found only in mammals. However, the area it derives from, the medial pallium, has counterparts in all vertebrates. There is evidence that this part of the brain is involved in complex events such as spatial memory and navigation in fishes, birds, reptiles, and mammals. The basal ganglia are a group of interconnected structures in the forebrain. The primary function of the basal ganglia appears to be action selection: they send inhibitory signals to all parts of the brain that can generate motor behaviors, and in the right circumstances can release the inhibition, so that the action-generating systems are able to execute their actions. Reward and punishment exert their most important neural effects by altering connections within the basal ganglia. The olfactory bulb is a special structure that processes olfactory sensory signals and sends its output to the olfactory part of the pallium. It is a major brain component in many vertebrates, but is greatly reduced in humans and other primates (whose senses are dominated by information acquired by sight rather than smell).  Reptiles   Birds   Mammals  The most obvious difference between the brains of mammals and other vertebrates is in terms of size. On average, a mammal has a brain roughly twice as large as that of a bird of the same body size, and ten times as large as that of a reptile of the same body size.Size, however, is not the only difference: there are also substantial differences in shape. The hindbrain and midbrain of mammals are generally similar to those of other vertebrates, but dramatic differences appear in the forebrain, which is greatly enlarged and also altered in structure. The cerebral cortex is the part of the brain that most strongly distinguishes mammals. In non-mammalian vertebrates, the surface of the cerebrum is lined with a comparatively simple three-layered structure called the pallium. In mammals, the pallium evolves into a complex six-layered structure called neocortex or isocortex. Several areas at the edge of the neocortex, including the hippocampus and amygdala, are also much more extensively developed in mammals than in other vertebrates.The elaboration of the cerebral cortex carries with it changes to other brain areas. The superior colliculus, which plays a major role in visual control of behavior in most vertebrates, shrinks to a small size in mammals, and many of its functions are taken over by visual areas of the cerebral cortex. The cerebellum of mammals contains a large portion (the neocerebellum) dedicated to supporting the cerebral cortex, which has no counterpart in other vertebrates.  Primates  The brains of humans and other primates contain the same structures as the brains of other mammals, but are generally larger in proportion to body size. The encephalization quotient (EQ) is used to compare brain sizes across species. It takes into account the nonlinearity of the brain-to-body relationship. Humans have an average EQ in the 7-to-8 range, while most other primates have an EQ in the 2-to-3 range. Dolphins have values higher than those of primates other than humans, but nearly all other mammals have EQ values that are substantially lower. Most of the enlargement of the primate brain comes from a massive expansion of the cerebral cortex, especially the prefrontal cortex and the parts of the cortex involved in vision. The visual processing network of primates includes at least 30 distinguishable brain areas, with a complex web of interconnections. It has been estimated that visual processing areas occupy more than half of the total surface of the primate neocortex. The prefrontal cortex carries out functions that include planning, working memory, motivation, attention, and executive control. It takes up a much larger proportion of the brain for primates than for other species, and an especially large fraction of the human brain.  Development  The brain develops in an intricately orchestrated sequence of stages. It changes in shape from a simple swelling at the front of the nerve cord in the earliest embryonic stages, to a complex array of areas and connections. Neurons are created in special zones that contain stem cells, and then migrate through the tissue to reach their ultimate locations. Once neurons have positioned themselves, their axons sprout and navigate through the brain, branching and extending as they go, until the tips reach their targets and form synaptic connections. In a number of parts of the nervous system, neurons and synapses are produced in excessive numbers during the early stages, and then the unneeded ones are pruned away.For vertebrates, the early stages of neural development are similar across all species. As the embryo transforms from a round blob of cells into a wormlike structure, a narrow strip of ectoderm running along the midline of the back is induced to become the neural plate, the precursor of the nervous system. The neural plate folds inward to form the neural groove, and then the lips that line the groove merge to enclose the neural tube, a hollow cord of cells with a fluid-filled ventricle at the center. At the front end, the ventricles and cord swell to form three vesicles that are the precursors of the prosencephalon (forebrain), mesencephalon (midbrain), and rhombencephalon (hindbrain). At the next stage, the forebrain splits into two vesicles called the telencephalon (which will contain the cerebral cortex, basal ganglia, and related structures) and the diencephalon (which will contain the thalamus and hypothalamus). At about the same time, the hindbrain splits into the metencephalon (which will contain the cerebellum and pons) and the myelencephalon (which will contain the medulla oblongata). Each of these areas contains proliferative zones where neurons and glial cells are generated; the resulting cells then migrate, sometimes for long distances, to their final positions.Once a neuron is in place, it extends dendrites and an axon into the area around it. Axons, because they commonly extend a great distance from the cell body and need to reach specific targets, grow in a particularly complex way. The tip of a growing axon consists of a blob of protoplasm called a growth cone, studded with chemical receptors. These receptors sense the local environment, causing the growth cone to be attracted or repelled by various cellular elements, and thus to be pulled in a particular direction at each point along its path. The result of this pathfinding process is that the growth cone navigates through the brain until it reaches its destination area, where other chemical cues cause it to begin generating synapses. Considering the entire brain, thousands of genes create products that influence axonal pathfinding.The synaptic network that finally emerges is only partly determined by genes, though. In many parts of the brain, axons initially ""overgrow"", and then are ""pruned"" by mechanisms that depend on neural activity. In the projection from the eye to the midbrain, for example, the structure in the adult contains a very precise mapping, connecting each point on the surface of the retina to a corresponding point in a midbrain layer. In the first stages of development, each axon from the retina is guided to the right general vicinity in the midbrain by chemical cues, but then branches very profusely and makes initial contact with a wide swath of midbrain neurons. The retina, before birth, contains special mechanisms that cause it to generate waves of activity that originate spontaneously at a random point and then propagate slowly across the retinal layer. These waves are useful because they cause neighboring neurons to be active at the same time; that is, they produce a neural activity pattern that contains information about the spatial arrangement of the neurons. This information is exploited in the midbrain by a mechanism that causes synapses to weaken, and eventually vanish, if activity in an axon is not followed by activity of the target cell. The result of this sophisticated process is a gradual tuning and tightening of the map, leaving it finally in its precise adult form.Similar things happen in other brain areas: an initial synaptic matrix is generated as a result of genetically determined chemical guidance, but then gradually refined by activity-dependent mechanisms, partly driven by internal dynamics, partly by external sensory inputs. In some cases, as with the retina-midbrain system, activity patterns depend on mechanisms that operate only in the developing brain, and apparently exist solely to guide development.In humans and many other mammals, new neurons are created mainly before birth, and the infant brain contains substantially more neurons than the adult brain. There are, however, a few areas where new neurons continue to be generated throughout life. The two areas for which adult neurogenesis is well established are the olfactory bulb, which is involved in the sense of smell, and the dentate gyrus of the hippocampus, where there is evidence that the new neurons play a role in storing newly acquired memories. With these exceptions, however, the set of neurons that is present in early childhood is the set that is present for life. Glial cells are different: as with most types of cells in the body, they are generated throughout the lifespan.There has long been debate about whether the qualities of mind, personality, and intelligence can be attributed to heredity or to upbringing—this is the nature and nurture controversy. Although many details remain to be settled, neuroscience research has clearly shown that both factors are important. Genes determine the general form of the brain, and genes determine how the brain reacts to experience. Experience, however, is required to refine the matrix of synaptic connections, which in its developed form contains far more information than the genome does. In some respects, all that matters is the presence or absence of experience during critical periods of development. In other respects, the quantity and quality of experience are important; for example, there is substantial evidence that animals raised in enriched environments have thicker cerebral cortices, indicating a higher density of synaptic connections, than animals whose levels of stimulation are restricted.  Physiology  The functions of the brain depend on the ability of neurons to transmit electrochemical signals to other cells, and their ability to respond appropriately to electrochemical signals received from other cells. The electrical properties of neurons are controlled by a wide variety of biochemical and metabolic processes, most notably the interactions between neurotransmitters and receptors that take place at synapses.  Neurotransmitters and receptors  Neurotransmitters are chemicals that are released at synapses when the local membrane is depolarised and Ca2+ enters into the cell, typically when an action potential arrives at the synapse – neurotransmitters attach themselves to receptor molecules on the membrane of the synapse\'s target cell (or cells), and thereby alter the electrical or chemical properties of the receptor molecules. With few exceptions, each neuron in the brain releases the same chemical neurotransmitter, or combination of neurotransmitters, at all the synaptic connections it makes with other neurons; this rule is known as Dale\'s principle. Thus, a neuron can be characterized by the neurotransmitters that it releases. The great majority of psychoactive drugs exert their effects by altering specific neurotransmitter systems. This applies to drugs such as cannabinoids, nicotine, heroin, cocaine, alcohol, fluoxetine, chlorpromazine, and many others.The two neurotransmitters that are most widely found in the vertebrate brain are glutamate, which almost always exerts excitatory effects on target neurons, and gamma-aminobutyric acid (GABA), which is almost always inhibitory. Neurons using these transmitters can be found in nearly every part of the brain. Because of their ubiquity, drugs that act on glutamate or GABA tend to have broad and powerful effects. Some general anesthetics act by reducing the effects of glutamate; most tranquilizers exert their sedative effects by enhancing the effects of GABA.There are dozens of other chemical neurotransmitters that are used in more limited areas of the brain, often areas dedicated to a particular function. Serotonin, for example—the primary target of many antidepressant drugs and many dietary aids—comes exclusively from a small brainstem area called the raphe nuclei. Norepinephrine, which is involved in arousal, comes exclusively from a nearby small area called the locus coeruleus. Other neurotransmitters such as acetylcholine and dopamine have multiple sources in the brain but are not as ubiquitously distributed as glutamate and GABA.  Electrical activity  As a side effect of the electrochemical processes used by neurons for signaling, brain tissue generates electric fields when it is active. When large numbers of neurons show synchronized activity, the electric fields that they generate can be large enough to detect outside the skull, using electroencephalography (EEG) or magnetoencephalography (MEG). EEG recordings, along with recordings made from electrodes implanted inside the brains of animals such as rats, show that the brain of a living animal is constantly active, even during sleep. Each part of the brain shows a mixture of rhythmic and nonrhythmic activity, which may vary according to behavioral state. In mammals, the cerebral cortex tends to show large slow delta waves during sleep, faster alpha waves when the animal is awake but inattentive, and chaotic-looking irregular activity when the animal is actively engaged in a task, called beta and gamma waves. During an epileptic seizure, the brain\'s inhibitory control mechanisms fail to function and electrical activity rises to pathological levels, producing EEG traces that show large wave and spike patterns not seen in a healthy brain. Relating these population-level patterns to the computational functions of individual neurons is a major focus of current research in neurophysiology.  Metabolism  All vertebrates have a blood–brain barrier that allows metabolism inside the brain to operate differently from metabolism in other parts of the body. Glial cells play a major role in brain metabolism by controlling the chemical composition of the fluid that surrounds neurons, including levels of ions and nutrients.Brain tissue consumes a large amount of energy in proportion to its volume, so large brains place severe metabolic demands on animals. The need to limit body weight in order, for example, to fly, has apparently led to selection for a reduction of brain size in some species, such as bats. Most of the brain\'s energy consumption goes into sustaining the electric charge (membrane potential) of neurons. Most vertebrate species devote between 2% and 8% of basal metabolism to the brain. In primates, however, the percentage is much higher—in humans it rises to 20–25%. The energy consumption of the brain does not vary greatly over time, but active regions of the cerebral cortex consume somewhat more energy than inactive regions; this forms the basis for the functional brain imaging methods of PET, fMRI, and NIRS. The brain typically gets most of its energy from oxygen-dependent metabolism of glucose (i.e., blood sugar), but ketones provide a major alternative source, together with contributions from medium chain fatty acids (caprylic and heptanoic acids), lactate, acetate, and possibly amino acids.  Function  Information from the sense organs is collected in the brain. There it is used to determine what actions the organism is to take. The brain processes the raw data to extract information about the structure of the environment. Next it combines the processed information with information about the current needs of the animal and with memory of past circumstances. Finally, on the basis of the results, it generates motor response patterns. These signal-processing tasks require intricate interplay between a variety of functional subsystems.The function of the brain is to provide coherent control over the actions of an animal. A centralized brain allows groups of muscles to be co-activated in complex patterns; it also allows stimuli impinging on one part of the body to evoke responses in other parts, and it can prevent different parts of the body from acting at cross-purposes to each other.  Perception  The human brain is provided with information about light, sound, the chemical composition of the atmosphere, temperature, the position of the body in space (proprioception), the chemical composition of the bloodstream, and more. In other animals additional senses are present, such as the infrared heat-sense of snakes, the magnetic field sense of some birds, or the electric field sense mainly seen in aquatic animals. Each sensory system begins with specialized receptor cells, such as photoreceptor cells in the retina of the eye, or vibration-sensitive hair cells in the cochlea of the ear. The axons of sensory receptor cells travel into the spinal cord or brain, where they transmit their signals to a first-order sensory nucleus dedicated to one specific sensory modality. This primary sensory nucleus sends information to higher-order sensory areas that are dedicated to the same modality. Eventually, via a way-station in the thalamus, the signals are sent to the cerebral cortex, where they are processed to extract the relevant features, and integrated with signals coming from other sensory systems.  Motor control  Motor systems are areas of the brain that are involved in initiating body movements, that is, in activating muscles. Except for the muscles that control the eye, which are driven by nuclei in the midbrain, all the voluntary muscles in the body are directly innervated by motor neurons in the spinal cord and hindbrain. Spinal motor neurons are controlled both by neural circuits intrinsic to the spinal cord, and by inputs that descend from the brain. The intrinsic spinal circuits implement many reflex responses, and contain pattern generators for rhythmic movements such as walking or swimming. The descending connections from the brain allow for more sophisticated control.The brain contains several motor areas that project directly to the spinal cord. At the lowest level are motor areas in the medulla and pons, which control stereotyped movements such as walking, breathing, or swallowing. At a higher level are areas in the midbrain, such as the red nucleus, which is responsible for coordinating movements of the arms and legs. At a higher level yet is the primary motor cortex, a strip of tissue located at the posterior edge of the frontal lobe. The primary motor cortex sends projections to the subcortical motor areas, but also sends a massive projection directly to the spinal cord, through the pyramidal tract. This direct corticospinal projection allows for precise voluntary control of the fine details of movements. Other motor-related brain areas exert secondary effects by projecting to the primary motor areas. Among the most important secondary areas are the premotor cortex, supplementary motor area, basal ganglia, and cerebellum. In addition to all of the above, the brain and spinal cord contain extensive circuitry to control the autonomic nervous system which controls the movement of the smooth muscle of the body.  Sleep  Many animals alternate between sleeping and waking in a daily cycle. Arousal and alertness are also modulated on a finer time scale by a network of brain areas. A key component of the sleep system is the suprachiasmatic nucleus (SCN), a tiny part of the hypothalamus located directly above the point at which the optic nerves from the two eyes cross. The SCN contains the body\'s central biological clock. Neurons there show activity levels that rise and fall with a period of about 24 hours, circadian rhythms: these activity fluctuations are driven by rhythmic changes in expression of a set of ""clock genes"". The SCN continues to keep time even if it is excised from the brain and placed in a dish of warm nutrient solution, but it ordinarily receives input from the optic nerves, through the retinohypothalamic tract (RHT), that allows daily light-dark cycles to calibrate the clock.The SCN projects to a set of areas in the hypothalamus, brainstem, and midbrain that are involved in implementing sleep-wake cycles. An important component of the system is the reticular formation, a group of neuron-clusters scattered diffusely through the core of the lower brain. Reticular neurons send signals to the thalamus, which in turn sends activity-level-controlling signals to every part of the cortex. Damage to the reticular formation can produce a permanent state of coma.Sleep involves great changes in brain activity. Until the 1950s it was generally believed that the brain essentially shuts off during sleep, but this is now known to be far from true; activity continues, but patterns become very different. There are two types of sleep: REM sleep (with dreaming) and NREM (non-REM, usually without dreaming) sleep, which repeat in slightly varying patterns throughout a sleep episode. Three broad types of distinct brain activity patterns can be measured: REM, light NREM and deep NREM. During deep NREM sleep, also called slow wave sleep, activity in the cortex takes the form of large synchronized waves, whereas in the waking state it is noisy and desynchronized. Levels of the neurotransmitters norepinephrine and serotonin drop during slow wave sleep, and fall almost to zero during REM sleep; levels of acetylcholine show the reverse pattern.  Homeostasis  For any animal, survival requires maintaining a variety of parameters of bodily state within a limited range of variation: these include temperature, water content, salt concentration in the bloodstream, blood glucose levels, blood oxygen level, and others. The ability of an animal to regulate the internal environment of its body—the milieu intérieur, as the pioneering physiologist Claude Bernard called it—is known as homeostasis (Greek for ""standing still""). Maintaining homeostasis is a crucial function of the brain. The basic principle that underlies homeostasis is negative feedback: any time a parameter diverges from its set-point, sensors generate an error signal that evokes a response that causes the parameter to shift back toward its optimum value. (This principle is widely used in engineering, for example in the control of temperature using a thermostat.) In vertebrates, the part of the brain that plays the greatest role is the hypothalamus, a small region at the base of the forebrain whose size does not reflect its complexity or the importance of its function. The hypothalamus is a collection of small nuclei, most of which are involved in basic biological functions. Some of these functions relate to arousal or to social interactions such as sexuality, aggression, or maternal behaviors; but many of them relate to homeostasis. Several hypothalamic nuclei receive input from sensors located in the lining of blood vessels, conveying information about temperature, sodium level, glucose level, blood oxygen level, and other parameters. These hypothalamic nuclei send output signals to motor areas that can generate actions to rectify deficiencies. Some of the outputs also go to the pituitary gland, a tiny gland attached to the brain directly underneath the hypothalamus. The pituitary gland secretes hormones into the bloodstream, where they circulate throughout the body and induce changes in cellular activity.  Motivation  The individual animals need to express survival-promoting behaviors, such as seeking food, water, shelter, and a mate. The motivational system in the brain monitors the current state of satisfaction of these goals, and activates behaviors to meet any needs that arise. The motivational system works largely by a reward–punishment mechanism. When a particular behavior is followed by favorable consequences, the reward mechanism in the brain is activated, which induces structural changes inside the brain that cause the same behavior to be repeated later, whenever a similar situation arises. Conversely, when a behavior is followed by unfavorable consequences, the brain\'s punishment mechanism is activated, inducing structural changes that cause the behavior to be suppressed when similar situations arise in the future.Most organisms studied to date use a reward–punishment mechanism: for instance, worms and insects can alter their behavior to seek food sources or to avoid dangers. In vertebrates, the reward-punishment system is implemented by a specific set of brain structures, at the heart of which lie the basal ganglia, a set of interconnected areas at the base of the forebrain. The basal ganglia are the central site at which decisions are made: the basal ganglia exert a sustained inhibitory control over most of the motor systems in the brain; when this inhibition is released, a motor system is permitted to execute the action it is programmed to carry out. Rewards and punishments function by altering the relationship between the inputs that the basal ganglia receive and the decision-signals that are emitted. The reward mechanism is better understood than the punishment mechanism, because its role in drug abuse has caused it to be studied very intensively. Research has shown that the neurotransmitter dopamine plays a central role: addictive drugs such as cocaine, amphetamine, and nicotine either cause dopamine levels to rise or cause the effects of dopamine inside the brain to be enhanced.  Learning and memory  Almost all animals are capable of modifying their behavior as a result of experience—even the most primitive types of worms. Because behavior is driven by brain activity, changes in behavior must somehow correspond to changes inside the brain. Already in the late 19th century theorists like Santiago Ramón y Cajal argued that the most plausible explanation is that learning and memory are expressed as changes in the synaptic connections between neurons. Until 1970, however, experimental evidence to support the synaptic plasticity hypothesis was lacking. In 1971 Tim Bliss and Terje Lømo published a paper on a phenomenon now called long-term potentiation: the paper showed clear evidence of activity-induced synaptic changes that lasted for at least several days. Since then technical advances have made these sorts of experiments much easier to carry out, and thousands of studies have been made that have clarified the mechanism of synaptic change, and uncovered other types of activity-driven synaptic change in a variety of brain areas, including the cerebral cortex, hippocampus, basal ganglia, and cerebellum. Brain-derived neurotrophic factor (BDNF) and physical activity appear to play a beneficial role in the process.Neuroscientists currently distinguish several types of learning and memory that are implemented by the brain in distinct ways: Working memory is the ability of the brain to maintain a temporary representation of information about the task that an animal is currently engaged in. This sort of dynamic memory is thought to be mediated by the formation of cell assemblies—groups of activated neurons that maintain their activity by constantly stimulating one another. Episodic memory is the ability to remember the details of specific events. This sort of memory can last for a lifetime. Much evidence implicates the hippocampus in playing a crucial role: people with severe damage to the hippocampus sometimes show amnesia, that is, inability to form new long-lasting episodic memories. Semantic memory is the ability to learn facts and relationships. This sort of memory is probably stored largely in the cerebral cortex, mediated by changes in connections between cells that represent specific types of information. Instrumental learning is the ability for rewards and punishments to modify behavior. It is implemented by a network of brain areas centered on the basal ganglia. Motor learning is the ability to refine patterns of body movement by practicing, or more generally by repetition. A number of brain areas are involved, including the premotor cortex, basal ganglia, and especially the cerebellum, which functions as a large memory bank for microadjustments of the parameters of movement.","The brain is the part of the body which lets animals and humans think, and perform bodily functions, such as telling the rest of the body what to do. It gets input from sense organs, and changes behavior in response to this information. In humans, the brain also controls our use of language, and is capable of abstract thought. The brain is the main control centre of the whole body. The brain is made up of special cells called nerves, which are connected with each other and with other nerves in our body. In all animals the brain is protected in some way. In ourselves, and all vertebrates, it is protected by the bones of the skull. In woodpeckers, the brain is protected by the tongue, which wraps around the brain.  Function  The brain does the thinking, learning, and feeling for the body. For humans, it is the source of consciousness. The brain also controls basic autonomic body actions, like breathing, digestion, heartbeat, that happen automatically. These activities, and much else, are governed by unconscious functions of the brain and nervous system. All the information about the world gathered by our senses is sent through nerves into the brain, allowing us to see, hear, smell, taste and feel things. The brain processes this information, and we experience it as pictures, sounds, and so on. The brain also uses nerves to tell the body what to do, for example by telling muscles to move or our heart to beat faster. This is generally true but some activity is caused by the spinal cord directly, for example, reflex actions do not involve the brain. In lower animals, a good deal is done without their brain being involved. All vertebrates have brains and, over time, their brains have evolved to become more complex. Some simple animals, however, like sponges, do not have anything like a brain. Segmented invertebrates have ganglions in each segment, and a ring of nervous tissue around the alimentary canal at the front. This acts to bring sense data from the front into play with the movement of the body.  Parts  In mammals, the brain is made of three main parts: the cerebrum, the cerebellum and the brainstem. The surface of the cerebrum is the cerebral cortex, which all vertebrates have. Mammals also have an extra layer, the neocortex. This is the key to the behaviour which is typical of mammals, especially humans.  Cerebral cortex  The cortex has sensory, motor, and association areas. The sensory areas are the areas that receive and process information from the senses. The motor areas control voluntary movements, especially fine movements performed by the hand. The right half of the motor area controls the left side of the body, and vice versa. Association areas produce a meaningful experience of the world, and supports abstract thinking and language. This enables us to interact effectively. Most connections are from one area of the cortex to another, rather than to subcortical areas; The figure may be as high as 99%.  Cerebellum  The cerebellum coordinates muscles so they work together. It is also the centre of keeping position and balance, and motor skills. It is one of the most ancient parts of the brain, and sits at the back underneath the cerebral cortex.  Thalamus  The thalamus puts together the input from most of the senses. It is the place in the brain which makes the ""picture"" we have of the world outside us. The thalamus sits centrally under the cerebral cortex.  Brain stem  The brain stem is at the back of the brain (actually underneath it in humans). It joins the rest of the brain with the spinal cord. It has lots of different parts that control different jobs in the body: for instance, the brain stem controls breathing, heartbeat, sneezing, eye blinking, and swallowing. Body temperature and hunger are also controlled by parts of the brain stem.  Size  The volume of the human brain (relative to the size of the whole body) is very large, compared to that of most other animals. The human brain also has a very large surface (called cortex) for its size, which is possible because it is very wrinkled. If the human cortex were flattened, it would be close to a square meter in area. Some other animals also have very wrinkled brains, such as dolphins and elephants. Here is a rule of thumb: the larger an animal is, the larger its brain will be.p15 Even allowing for that, the human brain, and in particular the neocortex, is very large. We know it increased in size four-fold over the last several million years of evolution.p79 There are ideas about why this happened, but no-one is quite sure. Most theories suggest complex social activity and the evolution of language would make a larger brain advantageous.p80 As an additional note, Einstein's brain weighed only 1,230 grams, which is less than the average adult male brain (about 1,400 grams). The detailed organisation of a brain obviously matters, but in ways which are not understood at present.  Number of cells  A human brain accounts for about 2% of the body's weight, but it uses about 20% of its energy. It has about 50–100 billion nerve cells (also called neurons), and roughly the same number of support cells, called glia. The job of neurons is to receive and send information to and from the rest of the body, while glia provide nutrients and guide blood flow to the neurons, allowing them to do their job. Each nerve cell has contact with as many as 10,000 other nerve cells through connections called synapses.  Related pages  Spinal cord Vertebrate brain Human Connectome Project  References   Other websites  Sylvius: 400+ structure neuroanatomical visual glossary; used by over half of U.S. medical schools High-resolution cytoarchitectural primate brain atlases Kolata, Gene 2013. The New York Times. In a first, experiment links brains of two rats February 28, 2013 Pais-Vieira, Miguel et al 2013. Nature Scientific Reports 3, #1319. A brain-to-brain interface for real-time sharing of sensorimotor information doi:10.1038/srep01319"
"Eyes are organs of the visual system. They provide living organisms with vision, the ability to receive and process visual detail, as well as enabling several photo response functions that are independent of vision. Eyes detect light and convert it into electro-chemical impulses in neurons (neurones). In higher organisms, the eye is a complex optical system which collects light from the surrounding environment, regulates its intensity through a diaphragm, focuses it through an adjustable assembly of lenses to form an image, converts this image into a set of electrical signals, and transmits these signals to the brain through complex neural pathways that connect the eye via the optic nerve to the visual cortex and other areas of the brain. Eyes with resolving power have come in ten fundamentally different forms, and 96% of animal species possess a complex optical system. Image-resolving eyes are present in molluscs, chordates and arthropods.The most simple eyes, pit eyes, are eye-spots which may be set into a pit to reduce the angle of light that enters and affects the eye-spot, to allow the organism to deduce the angle of incoming light. From more complex eyes, retinal photosensitive ganglion cells send signals along the retinohypothalamic tract to the suprachiasmatic nuclei to effect circadian adjustment and to the pretectal area to control the pupillary light reflex.  Overview  Complex eyes distinguish shapes and colours. The visual fields of many organisms, especially predators, involve large areas of binocular vision for depth perception. In other organisms, particularly prey animals, eyes are located to maximise the field of view, such as in rabbits and horses, which have monocular vision. The first proto-eyes evolved among animals 600 million years ago about the time of the Cambrian explosion. The last common ancestor of animals possessed the biochemical toolkit necessary for vision, and more advanced eyes have evolved in 96% of animal species in six of the ~35 main phyla. In most vertebrates and some molluscs, the eye allows light to enter and project onto a light-sensitive layer of cells known as the retina. The cone cells (for colour) and the rod cells (for low-light contrasts) in the retina detect and convert light into neural signals which are transmitted to the brain via the optic nerve to produce vision. Such eyes are typically spheroid, filled with the transparent gel-like vitreous humour, possess a focusing lens, and often an iris. Muscles around the iris change the size of the pupil, regulating the amount of light that enters the eye and reducing aberrations when there is enough light. The eyes of most cephalopods, fish, amphibians and snakes have fixed lens shapes, and focusing is achieved by telescoping the lens in a similar manner to that of a camera.The compound eyes of the arthropods are composed of many simple facets which, depending on anatomical detail, may give either a single pixelated image or multiple images per eye. Each sensor has its own lens and photosensitive cell(s). Some eyes have up to 28,000 such sensors arranged hexagonally, which can give a full 360° field of vision. Compound eyes are very sensitive to motion. Some arthropods, including many Strepsiptera, have compound eyes of only a few facets, each with a retina capable of creating an image. With each eye producing a different image, a fused, high-resolution image is produced in the brain. Possessing detailed hyperspectral colour vision, the mantis shrimp has the world's most complex colour vision system. Trilobites, now extinct, had unique compound eyes. Clear calcite crystals formed the lenses of their eyes. They differ in this from most other arthropods, which have soft eyes. The number of lenses in such an eye varied widely; some trilobites had only one while others had thousands of lenses per eye. In contrast to compound eyes, simple eyes have a single lens. Jumping spiders have one pair of large simple eyes with a narrow field of view, augmented by an array of smaller eyes for peripheral vision. Some insect larvae, like caterpillars, have a type of simple eye (stemmata) which usually provides only a rough image, but (as in sawfly larvae) can possess resolving powers of 4 degrees of arc, be polarization-sensitive, and capable of increasing its absolute sensitivity at night by a factor of 1,000 or more. Ocelli, some of the simplest eyes, are found in animals such as some of the snails. They have photosensitive cells but no lens or other means of projecting an image onto those cells. They can distinguish between light and dark but no more, enabling them to avoid direct sunlight. In organisms dwelling near deep-sea vents, compound eyes are adapted to see the infra-red light produced by the hot vents, allowing the creatures to avoid being boiled alive.  Types  There are ten different eye layouts—indeed every technological method of capturing an optical image commonly used by human beings, with the exceptions of zoom and Fresnel lenses, occur in nature. Eye types can be categorised into ""simple eyes"", with one concave photoreceptive surface, and ""compound eyes"", which comprise a number of individual lenses laid out on a convex surface. ""Simple"" does not imply a reduced level of complexity or acuity. Indeed, any eye type can be adapted for almost any behaviour or environment. The only limitations specific to eye types are that of resolution—the physics of compound eyes prevents them from achieving a resolution better than 1°. Also, superposition eyes can achieve greater sensitivity than apposition eyes, so are better suited to dark-dwelling creatures. Eyes also fall into two groups on the basis of their photoreceptor's cellular construction, with the photoreceptor cells either being cilliated (as in the vertebrates) or rhabdomeric. These two groups are not monophyletic; the cnidaria also possess cilliated cells, and some gastropods, as well as some annelids possess both.Some organisms have photosensitive cells that do nothing but detect whether the surroundings are light or dark, which is sufficient for the entrainment of circadian rhythms. These are not considered eyes because they lack enough structure to be considered an organ, and do not produce an image.  Non-compound eyes  Simple eyes are rather ubiquitous, and lens-bearing eyes have evolved at least seven times in vertebrates, cephalopods, annelids, crustaceans and cubozoa.  Pit eyes  Pit eyes, also known as stemma, are eye-spots which may be set into a pit to reduce the angles of light that enters and affects the eye-spot, to allow the organism to deduce the angle of incoming light. Found in about 85% of phyla, these basic forms were probably the precursors to more advanced types of ""simple eyes"". They are small, comprising up to about 100 cells covering about 100 µm. The directionality can be improved by reducing the size of the aperture, by incorporating a reflective layer behind the receptor cells, or by filling the pit with a refractile material.Pit vipers have developed pits that function as eyes by sensing thermal infra-red radiation, in addition to their optical wavelength eyes like those of other vertebrates (see infrared sensing in snakes). However, pit organs are fitted with receptors rather different from photoreceptors, namely a specific transient receptor potential channel (TRP channels) called TRPV1. The main difference is that photoreceptors are G-protein coupled receptors but TRP are ion channels.  Spherical lens eye  The resolution of pit eyes can be greatly improved by incorporating a material with a higher refractive index to form a lens, which may greatly reduce the blur radius encountered—hence increasing the resolution obtainable. The most basic form, seen in some gastropods and annelids, consists of a lens of one refractive index. A far sharper image can be obtained using materials with a high refractive index, decreasing to the edges; this decreases the focal length and thus allows a sharp image to form on the retina. This also allows a larger aperture for a given sharpness of image, allowing more light to enter the lens; and a flatter lens, reducing spherical aberration. Such a non-homogeneous lens is necessary for the focal length to drop from about 4 times the lens radius, to 2.5 radii.Heterogeneous eyes have evolved at least nine times: four or more times in gastropods, once in the copepods, once in the annelids, once in the cephalopods, and once in the chitons, which have aragonite lenses. No extant aquatic organisms possess homogeneous lenses; presumably the evolutionary pressure for a heterogeneous lens is great enough for this stage to be quickly ""outgrown"".This eye creates an image that is sharp enough that motion of the eye can cause significant blurring. To minimise the effect of eye motion while the animal moves, most such eyes have stabilising eye muscles.The ocelli of insects bear a simple lens, but their focal point usually lies behind the retina; consequently, those can't form a sharp image. Ocelli (pit-type eyes of arthropods) blur the image across the whole retina, and are consequently excellent at responding to rapid changes in light intensity across the whole visual field; this fast response is further accelerated by the large nerve bundles which rush the information to the brain. Focusing the image would also cause the sun's image to be focused on a few receptors, with the possibility of damage under the intense light; shielding the receptors would block out some light and thus reduce their sensitivity. This fast response has led to suggestions that the ocelli of insects are used mainly in flight, because they can be used to detect sudden changes in which way is up (because light, especially UV light which is absorbed by vegetation, usually comes from above).  Multiple lenses  Some marine organisms bear more than one lens; for instance the copepod Pontella has three. The outer has a parabolic surface, countering the effects of spherical aberration while allowing a sharp image to be formed. Another copepod, Copilia, has two lenses in each eye, arranged like those in a telescope. Such arrangements are rare and poorly understood, but represent an alternative construction. Multiple lenses are seen in some hunters such as eagles and jumping spiders, which have a refractive cornea: these have a negative lens, enlarging the observed image by up to 50% over the receptor cells, thus increasing their optical resolution.  Refractive cornea  In the eyes of most mammals, birds, reptiles, and most other terrestrial vertebrates (along with spiders and some insect larvae) the vitreous fluid has a higher refractive index than the air. In general, the lens is not spherical. Spherical lenses produce spherical aberration. In refractive corneas, the lens tissue is corrected with inhomogeneous lens material (see Luneburg lens), or with an aspheric shape. Flattening the lens has a disadvantage; the quality of vision is diminished away from the main line of focus. Thus, animals that have evolved with a wide field-of-view often have eyes that make use of an inhomogeneous lens.As mentioned above, a refractive cornea is only useful out of water. In water, there is little difference in refractive index between the vitreous fluid and the surrounding water. Hence creatures that have returned to the water—penguins and seals, for example—lose their highly curved cornea and return to lens-based vision. An alternative solution, borne by some divers, is to have a very strongly focusing cornea.  Reflector eyes  An alternative to a lens is to line the inside of the eye with ""mirrors"", and reflect the image to focus at a central point. The nature of these eyes means that if one were to peer into the pupil of an eye, one would see the same image that the organism would see, reflected back out.Many small organisms such as rotifers, copepods and flatworms use such organs, but these are too small to produce usable images. Some larger organisms, such as scallops, also use reflector eyes. The scallop Pecten has up to 100 millimetre-scale reflector eyes fringing the edge of its shell. It detects moving objects as they pass successive lenses.There is at least one vertebrate, the spookfish, whose eyes include reflective optics for focusing of light. Each of the two eyes of a spookfish collects light from both above and below; the light coming from above is focused by a lens, while that coming from below, by a curved mirror composed of many layers of small reflective plates made of guanine crystals.  Compound eyes  A compound eye may consist of thousands of individual photoreceptor units or ommatidia (ommatidium, singular). The image perceived is a combination of inputs from the numerous ommatidia (individual ""eye units""), which are located on a convex surface, thus pointing in slightly different directions. Compared with simple eyes, compound eyes possess a very large view angle, and can detect fast movement and, in some cases, the polarisation of light. Because the individual lenses are so small, the effects of diffraction impose a limit on the possible resolution that can be obtained (assuming that they do not function as phased arrays). This can only be countered by increasing lens size and number. To see with a resolution comparable to our simple eyes, humans would require very large compound eyes, around 11 metres (36 ft) in radius.Compound eyes fall into two groups: apposition eyes, which form multiple inverted images, and superposition eyes, which form a single erect image. Compound eyes are common in arthropods, annelids and some bivalved molluscs. Compound eyes in arthropods grow at their margins by the addition of new ommatidia.  Apposition eyes  Apposition eyes are the most common form of eyes and are presumably the ancestral form of compound eyes. They are found in all arthropod groups, although they may have evolved more than once within this phylum. Some annelids and bivalves also have apposition eyes. They are also possessed by Limulus, the horseshoe crab, and there are suggestions that other chelicerates developed their simple eyes by reduction from a compound starting point. (Some caterpillars appear to have evolved compound eyes from simple eyes in the opposite fashion.) Apposition eyes work by gathering a number of images, one from each eye, and combining them in the brain, with each eye typically contributing a single point of information. The typical apposition eye has a lens focusing light from one direction on the rhabdom, while light from other directions is absorbed by the dark wall of the ommatidium.  Superposition eyes  The second type is named the superposition eye. The superposition eye is divided into three types: refracting, reflecting and parabolic superpositionThe refracting superposition eye has a gap between the lens and the rhabdom, and no side wall. Each lens takes light at an angle to its axis and reflects it to the same angle on the other side. The result is an image at half the radius of the eye, which is where the tips of the rhabdoms are. This type of compound eye, for which a minimal size exists below which effective superposition cannot occur, is normally found in nocturnal insects, because it can create images up to 1000 times brighter than equivalent apposition eyes, though at the cost of reduced resolution. In the parabolic superposition compound eye type, seen in arthropods such as mayflies, the parabolic surfaces of the inside of each facet focus light from a reflector to a sensor array. Long-bodied decapod crustaceans such as shrimp, prawns, crayfish and lobsters are alone in having reflecting superposition eyes, which also have a transparent gap but use corner mirrors instead of lenses.  Parabolic superposition  This eye type functions by refracting light, then using a parabolic mirror to focus the image; it combines features of superposition and apposition eyes.  Other  Another kind of compound eye, found in males of Order Strepsiptera, employs a series of simple eyes—eyes having one opening that provides light for an entire image-forming retina. Several of these eyelets together form the strepsipteran compound eye, which is similar to the 'schizochroal' compound eyes of some trilobites. Because each eyelet is a simple eye, it produces an inverted image; those images are combined in the brain to form one unified image. Because the aperture of an eyelet is larger than the facets of a compound eye, this arrangement allows vision under low light levels.Good fliers such as flies or honey bees, or prey-catching insects such as praying mantis or dragonflies, have specialised zones of ommatidia organised into a fovea area which gives acute vision. In the acute zone, the eyes are flattened and the facets larger. The flattening allows more ommatidia to receive light from a spot and therefore higher resolution. The black spot that can be seen on the compound eyes of such insects, which always seems to look directly at the observer, is called a pseudopupil. This occurs because the ommatidia which one observes ""head-on"" (along their optical axes) absorb the incident light, while those to one side reflect it.There are some exceptions from the types mentioned above. Some insects have a so-called single lens compound eye, a transitional type which is something between a superposition type of the multi-lens compound eye and the single lens eye found in animals with simple eyes. Then there is the mysid shrimp, Dioptromysis paucispinosa. The shrimp has an eye of the refracting superposition type, in the rear behind this in each eye there is a single large facet that is three times in diameter the others in the eye and behind this is an enlarged crystalline cone. This projects an upright image on a specialised retina. The resulting eye is a mixture of a simple eye within a compound eye. Another version is a compound eye often referred to as ""pseudofaceted"", as seen in Scutigera. This type of eye consists of a cluster of numerous ommatidia on each side of the head, organised in a way that resembles a true compound eye. The body of Ophiocoma wendtii, a type of brittle star, is covered with ommatidia, turning its whole skin into a compound eye. The same is true of many chitons. The tube feet of sea urchins contain photoreceptor proteins, which together act as a compound eye; they lack screening pigments, but can detect the directionality of light by the shadow cast by its opaque body.  Nutrients  The ciliary body is triangular in horizontal section and is coated by a double layer, the ciliary epithelium. The inner layer is transparent and covers the vitreous body, and is continuous from the neural tissue of the retina. The outer layer is highly pigmented, continuous with the retinal pigment epithelium, and constitutes the cells of the dilator muscle. The vitreous is the transparent, colourless, gelatinous mass that fills the space between the lens of the eye and the retina lining the back of the eye. It is produced by certain retinal cells. It is of rather similar composition to the cornea, but contains very few cells (mostly phagocytes which remove unwanted cellular debris in the visual field, as well as the hyalocytes of Balazs of the surface of the vitreous, which reprocess the hyaluronic acid), no blood vessels, and 98–99% of its volume is water (as opposed to 75% in the cornea) with salts, sugars, vitrosin (a type of collagen), a network of collagen type II fibres with the mucopolysaccharide hyaluronic acid, and also a wide array of proteins in micro amounts. Amazingly, with so little solid matter, it tautly holds the eye.  Evolution  Photoreception is phylogenetically very old, with various theories of phylogenesis. The common origin (monophyly) of all animal eyes is now widely accepted as fact. This is based upon the shared genetic features of all eyes; that is, all modern eyes, varied as they are, have their origins in a proto-eye believed to have evolved some 650-600 million years ago, and the PAX6 gene is considered a key factor in this. The majority of the advancements in early eyes are believed to have taken only a few million years to develop, since the first predator to gain true imaging would have touched off an ""arms race"" among all species that did not flee the photopic environment. Prey animals and competing predators alike would be at a distinct disadvantage without such capabilities and would be less likely to survive and reproduce. Hence multiple eye types and subtypes developed in parallel (except those of groups, such as the vertebrates, that were only forced into the photopic environment at a late stage). Eyes in various animals show adaptation to their requirements. For example, the eye of a bird of prey has much greater visual acuity than a human eye, and in some cases can detect ultraviolet radiation. The different forms of eye in, for example, vertebrates and molluscs are examples of parallel evolution, despite their distant common ancestry. Phenotypic convergence of the geometry of cephalopod and most vertebrate eyes creates the impression that the vertebrate eye evolved from an imaging cephalopod eye, but this is not the case, as the reversed roles of their respective ciliary and rhabdomeric opsin classes and different lens crystallins show.The very earliest ""eyes"", called eye-spots, were simple patches of photoreceptor protein in unicellular animals. In multicellular beings, multicellular eyespots evolved, physically similar to the receptor patches for taste and smell. These eyespots could only sense ambient brightness: they could distinguish light and dark, but not the direction of the light source.Through gradual change, the eye-spots of species living in well-lit environments depressed into a shallow ""cup"" shape. The ability to slightly discriminate directional brightness was achieved by using the angle at which the light hit certain cells to identify the source. The pit deepened over time, the opening diminished in size, and the number of photoreceptor cells increased, forming an effective pinhole camera that was capable of dimly distinguishing shapes. However, the ancestors of modern hagfish, thought to be the protovertebrate, were evidently pushed to very deep, dark waters, where they were less vulnerable to sighted predators, and where it is advantageous to have a convex eye-spot, which gathers more light than a flat or concave one. This would have led to a somewhat different evolutionary trajectory for the vertebrate eye than for other animal eyes. The thin overgrowth of transparent cells over the eye's aperture, originally formed to prevent damage to the eyespot, allowed the segregated contents of the eye chamber to specialise into a transparent humour that optimised colour filtering, blocked harmful radiation, improved the eye's refractive index, and allowed functionality outside of water. The transparent protective cells eventually split into two layers, with circulatory fluid in between that allowed wider viewing angles and greater imaging resolution, and the thickness of the transparent layer gradually increased, in most species with the transparent crystallin protein.The gap between tissue layers naturally formed a biconvex shape, an optimally ideal structure for a normal refractive index. Independently, a transparent layer and a nontransparent layer split forward from the lens: the cornea and iris. Separation of the forward layer again formed a humour, the aqueous humour. This increased refractive power and again eased circulatory problems. Formation of a nontransparent ring allowed more blood vessels, more circulation, and larger eye sizes.  Relationship to life requirements  Eyes are generally adapted to the environment and life requirements of the organism which bears them. For instance, the distribution of photoreceptors tends to match the area in which the highest acuity is required, with horizon-scanning organisms, such as those that live on the African plains, having a horizontal line of high-density ganglia, while tree-dwelling creatures which require good all-round vision tend to have a symmetrical distribution of ganglia, with acuity decreasing outwards from the centre. Of course, for most eye types, it is impossible to diverge from a spherical form, so only the density of optical receptors can be altered. In organisms with compound eyes, it is the number of ommatidia rather than ganglia that reflects the region of highest data acquisition.: 23–24 Optical superposition eyes are constrained to a spherical shape, but other forms of compound eyes may deform to a shape where more ommatidia are aligned to, say, the horizon, without altering the size or density of individual ommatidia. Eyes of horizon-scanning organisms have stalks so they can be easily aligned to the horizon when this is inclined, for example, if the animal is on a slope.An extension of this concept is that the eyes of predators typically have a zone of very acute vision at their centre, to assist in the identification of prey. In deep water organisms, it may not be the centre of the eye that is enlarged. The hyperiid amphipods are deep water animals that feed on organisms above them. Their eyes are almost divided into two, with the upper region thought to be involved in detecting the silhouettes of potential prey—or predators—against the faint light of the sky above. Accordingly, deeper water hyperiids, where the light against which the silhouettes must be compared is dimmer, have larger ""upper-eyes"", and may lose the lower portion of their eyes altogether. In the giant Antarctic isopod Glyptonotus a small ventral compound eye is physically completely separated from the much larger dorsal compound eye. Depth perception can be enhanced by having eyes which are enlarged in one direction; distorting the eye slightly allows the distance to the object to be estimated with a high degree of accuracy.Acuity is higher among male organisms that mate in mid-air, as they need to be able to spot and assess potential mates against a very large backdrop. On the other hand, the eyes of organisms which operate in low light levels, such as around dawn and dusk or in deep water, tend to be larger to increase the amount of light that can be captured.It is not only the shape of the eye that may be affected by lifestyle. Eyes can be the most visible parts of organisms, and this can act as a pressure on organisms to have more transparent eyes at the cost of function.Eyes may be mounted on stalks to provide better all-round vision, by lifting them above an organism's carapace; this also allows them to track predators or prey without moving the head.  Physiology   Visual acuity  Visual acuity, or resolving power, is ""the ability to distinguish fine detail"" and is the property of cone cells. It is often measured in cycles per degree (CPD), which measures an angular resolution, or how much an eye can differentiate one object from another in terms of visual angles. Resolution in CPD can be measured by bar charts of different numbers of white/black stripe cycles. For example, if each pattern is 1.75 cm wide and is placed at 1 m distance from the eye, it will subtend an angle of 1 degree, so the number of white/black bar pairs on the pattern will be a measure of the cycles per degree of that pattern. The highest such number that the eye can resolve as stripes, or distinguish from a grey block, is then the measurement of visual acuity of the eye. For a human eye with excellent acuity, the maximum theoretical resolution is 50 CPD (1.2 arcminute per line pair, or a 0.35 mm line pair, at 1 m). A rat can resolve only about 1 to 2 CPD. A horse has higher acuity through most of the visual field of its eyes than a human has, but does not match the high acuity of the human eye's central fovea region.Spherical aberration limits the resolution of a 7 mm pupil to about 3 arcminutes per line pair. At a pupil diameter of 3 mm, the spherical aberration is greatly reduced, resulting in an improved resolution of approximately 1.7 arcminutes per line pair. A resolution of 2 arcminutes per line pair, equivalent to a 1 arcminute gap in an optotype, corresponds to 20/20 (normal vision) in humans. However, in the compound eye, the resolution is related to the size of individual ommatidia and the distance between neighbouring ommatidia. Physically these cannot be reduced in size to achieve the acuity seen with single lensed eyes as in mammals. Compound eyes have a much lower acuity than vertebrate eyes.  Colour perception  ""Colour vision is the faculty of the organism to distinguish lights of different spectral qualities."" All organisms are restricted to a small range of electromagnetic spectrum; this varies from creature to creature, but is mainly between wavelengths of 400 and 700 nm. This is a rather small section of the electromagnetic spectrum, probably reflecting the submarine evolution of the organ: water blocks out all but two small windows of the EM spectrum, and there has been no evolutionary pressure among land animals to broaden this range.The most sensitive pigment, rhodopsin, has a peak response at 500 nm. Small changes to the genes coding for this protein can tweak the peak response by a few nm; pigments in the lens can also filter incoming light, changing the peak response. Many organisms are unable to discriminate between colours, seeing instead in shades of grey; colour vision necessitates a range of pigment cells which are primarily sensitive to smaller ranges of the spectrum. In primates, geckos, and other organisms, these take the form of cone cells, from which the more sensitive rod cells evolved. Even if organisms are physically capable of discriminating different colours, this does not necessarily mean that they can perceive the different colours; only with behavioural tests can this be deduced.Most organisms with colour vision can detect ultraviolet light. This high energy light can be damaging to receptor cells. With a few exceptions (snakes, placental mammals), most organisms avoid these effects by having absorbent oil droplets around their cone cells. The alternative, developed by organisms that had lost these oil droplets in the course of evolution, is to make the lens impervious to UV light—this precludes the possibility of any UV light being detected, as it does not even reach the retina.  Rods and cones  The retina contains two major types of light-sensitive photoreceptor cells used for vision: the rods and the cones. Rods cannot distinguish colours, but are responsible for low-light (scotopic) monochrome (black-and-white) vision; they work well in dim light as they contain a pigment, rhodopsin (visual purple), which is sensitive at low light intensity, but saturates at higher (photopic) intensities. Rods are distributed throughout the retina but there are none at the fovea and none at the blind spot. Rod density is greater in the peripheral retina than in the central retina. Cones are responsible for colour vision. They require brighter light to function than rods require. In humans, there are three types of cones, maximally sensitive to long-wavelength, medium-wavelength, and short-wavelength light (often referred to as red, green, and blue, respectively, though the sensitivity peaks are not actually at these colours). The colour seen is the combined effect of stimuli to, and responses from, these three types of cone cells. Cones are mostly concentrated in and near the fovea. Only a few are present at the sides of the retina. Objects are seen most sharply in focus when their images fall on the fovea, as when one looks at an object directly. Cone cells and rods are connected through intermediate cells in the retina to nerve fibres of the optic nerve. When rods and cones are stimulated by light, they connect through adjoining cells within the retina to send an electrical signal to the optic nerve fibres. The optic nerves send off impulses through these fibres to the brain.  Pigmentation  The pigment molecules used in the eye are various, but can be used to define the evolutionary distance between different groups, and can also be an aid in determining which are closely related—although problems of convergence do exist.Opsins are the pigments involved in photoreception. Other pigments, such as melanin, are used to shield the photoreceptor cells from light leaking in from the sides. The opsin protein group evolved long before the last common ancestor of animals, and has continued to diversify since.There are two types of opsin involved in vision; c-opsins, which are associated with ciliary-type photoreceptor cells, and r-opsins, associated with rhabdomeric photoreceptor cells. The eyes of vertebrates usually contain ciliary cells with c-opsins, and (bilaterian) invertebrates have rhabdomeric cells in the eye with r-opsins. However, some ganglion cells of vertebrates express r-opsins, suggesting that their ancestors used this pigment in vision, and that remnants survive in the eyes. Likewise, c-opsins have been found to be expressed in the brain of some invertebrates. They may have been expressed in ciliary cells of larval eyes, which were subsequently resorbed into the brain on metamorphosis to the adult form. C-opsins are also found in some derived bilaterian-invertebrate eyes, such as the pallial eyes of the bivalve molluscs; however, the lateral eyes (which were presumably the ancestral type for this group, if eyes evolved once there) always use r-opsins. Cnidaria, which are an outgroup to the taxa mentioned above, express c-opsins—but r-opsins are yet to be found in this group. Incidentally, the melanin produced in the cnidaria is produced in the same fashion as that in vertebrates, suggesting the common descent of this pigment.  Additional images   See also  Accommodation (vertebrate eye)(focusing) Adaptation (eye) (night vision) Capsule of lens Cornea Emission theory (vision) Eye color Eye development Eye disease Eye injury Eye movement Eyelid Lens (vertebrate anatomy) Nictitating membrane Ophthalmology Orbit (anatomy) Simple eye in invertebrates Tapetum lucidum Tears  Notes   References   Citations   Bibliography  Ali, Mohamed Ather; Klyne, M.A. (1985). Vision in Vertebrates. New York: Plenum Press. ISBN 978-0-306-42065-8.  Further reading  Yong, Ed (14 January 2016). ""Inside the Eye: Nature's Most Exquisite Creation"". National Geographic.  External links  Evolution of the eye Anatomy of the eye – flash animated interactive. (Adobe Flash) Webvision. The organisation of the retina and visual system. An in-depth treatment of retinal function, open to all but geared most towards graduate students. Eye strips images of all but bare essentials before sending visual information to the brain, UC Berkeley research shows","The eye is a round organ for sensing light so organisms can see. It is the first part of the visual system. About 97 percent of animals have eyes. Image-resolving eyes are present in cnidaria, molluscs, vertebrates, annelids and arthropods.In mammals, two kinds of cells, rods and cones, allow sight by sending signals through the optic nerve to the brain. Some animals can see light that humans cannot see. They can see ultraviolet or infrared light. The lens on the front part of the eye acts like a camera lens. It can be pulled flatter by muscles inside the eye, or allowed to become rounder. As some people get older, they may not be as able to do this perfectly. Many people are born with other small problems or get them later in life, and they may need eyeglasses (or contact lenses) to fix the problem. Like different cameras, different eyes have different abilities. They may have higher or lower resolution, the ability to detect small details. They may have different performance in low light; nocturnal animals can see better at night than daytime animals. They may have different ability to distinguish colours.  Parts of the eye  The human eye is composed of several different parts. These parts may or may not be the same in other animals. They are: Cornea: The outermost, transparent layer that protects the iris and pupil. Pupil: The black circle in the middle of the eye, through which light passes. Iris: The colorful circle of the eye around the pupil. It can be brown, blue, green, etc. Its main function is to regulate the amount of light coming into the eye. Sclera: The large, white field around the iris that keeps the eyeball in shape. Lens: Behind the cornea there is a transparent bioconvex lens of very short focal length.This lens is held in the centre of eye ball with the help of ciliary muscles . Retina: Has the cells which turn light into nerve impulses. Optic nerve: The nerve that connects the eye to the brain. Optical information is taken to the rear of the brain for processing: see cerebral cortex.  Types of eye  Today, ten different types of eyes are known. Most ways of capturing an image have evolved at least once. One way to categorize eyes is to look at the number of ""chambers"". Simple eyes are made of only one concave chamber, perhaps with a lens. Compound eyes have many such chambers with their lenses on a convex surface.Eyes also can be grouped according to how the photoreceptor is made. Photoreceptors are either cillated, or rhabdomic. and some annelids possess both.  Simple eyes   Pit eyes  Pit eyes are set in a depression in the skin. This reduces the angles at which light can enter. It allows the organism to say where the light is coming from.Such eyes can be found in about 85% of phyla. They probably came before the development of more complex eyes. Pit eyes are small. They are made of up to about hundred cells, covering about 100 µm. The directionality can be improved by reducing the size of the opening, and by putting a reflective layer behind the receptor cells.  Pinhole eye  The pinhole eye is an advanced form of pit eye. It has several bits, most notably a small aperture and deep pit. Sometimes, the aperture can be changed. It is only found in the Nautilus. Without a lens to focus the image, it produces a blurry image. Consequently, nautiloids can not discriminate between objects with a separation of less than 11°. Shrinking the aperture would produce a sharper image, but let in less light.  Spherical lensed eye  The resolution of pit eyes can be improved a lot by adding a material to make a lens. This will reduce the radius of the blurring, and increase the resolution that can be achieved. The most basic form can still be seen in some gastropods and annelids. These eyes have a lens of one refractive index. It is possible to get a better image with materials that have a high refractive index which decreases towards the edges. This decreases the focal length and allows a sharp image to form on the retina.This eye creates an image that is sharp enough that motion of the eye can cause significant blurring. To minimize the effect of eye motion while the animal moves, most such eyes have stabilizing eye muscles.The ocelli of insects have a simple lens, but their focal point always lies behind the retina.They can never form a sharp image. This limits the function of the eye. Ocelli (pit-type eyes of arthropods) blur the image across the whole retina. They are very good at responding to rapid changes in light intensity across the whole visual field — this fast response is accelerated even more by the large nerve bundles which rush the information to the brain. Focusing the image would also cause the sun's image to be focused on a few receptors. These could possibly be damaged by the intense light; shielding the receptors would block out some light and reduce their sensitivity.This fast response has led to suggestions that the ocelli of insects are used mainly in flight, because they can be used to detect sudden changes in which way is up (because light, especially UV light which is absorbed by vegetation, usually comes from above).  Refractive cornea  The eyes of most land-living vertebrates (as well as those of some spiders, and insect larvae) contain a fluid that has a higher refractive index than the air. The cornea is sharply curved and refracts light towards the focus. The lens need not do all of the refracting. This lets the lens adjust the focus more easily, for much higher resolution.  Reflector eyes  Instead of using a lens it is also possible to have cells inside the eye that act like mirrors. The image can then be reflected to focus at a central point. This design also means that someone looking into such an eye will see the same image as the organism which has them.Many small organisms such as rotifers, copeopods and platyhelminthes use such this design, but their eyes are too small to produce usable images. Some larger organisms, such as scallops, also use reflector eyes. The scallop Pecten has up to 100 millimeter-scale reflector eyes fringing the edge of its shell. It detects moving objects as they pass successive lenses.  Compound eyes  Compound eyes are different from simple eyes. Instead of having one organ that can sense light, they put together many such organs. Some compound eyes have thousands of them. The resulting image is put together in the brain, based on the signals of the many eye units. Each such unit is called ommatidium, several are called ommatidia. The ommatidia are located on a convex surface, each of them points in a slighly different direction. Unlike simple eyes, compound eyes have a very large angle of view. They can detect fast movement, and sometimes the polarization of light.Compound eyes are common in arthropods, annelids, and some bivalved molluscs.  Evolution of the eye  The evolution of eyes started with simplest light-sensitive patches in unicellular organisms. These eye-spots do nothing but detect if the surroundings are light or dark. Most animals have a biochemical 'clock' inside. These simple eye-spots are used to adjust this daily clock, which is called circadian rhythm. Some snails, for example, see no image (picture) at all, but they sense light, which helps them stay out of bright sunlight.More complex eyes have not lost this function. A special type of cells in the eye senses light for a different purpose than seeing. These cells are called ganglion cells. They are located in the retina. They send their information about light to the brain along a different path (the retinohypothalamic tract). This information adjusts (synchronizes) the animal's circadian rhythm to nature's light/dark cycle of 24 hours. The system also works for some blind people who cannot see light at all. Eyes that are a little bit better are shaped like cups, which lets the animal know where the light is coming from. More complex eyes give the full sense of vision, including color, motion, and texture. These eyes have a round shape that makes light rays focus on the back part of the eye, called the retina.  Other  Good fliers like flies or honey bees, or prey-catching insects like praying mantis or dragonflies, have specialized zones of ommatidia organized into a fovea area which gives sharp vision. In this zone the eyes are flattened and the facets are larger. The flattening allows more ommatidia to receive light from a spot. This gives a higher resolution. The body of Ophiocoma wendtii, a type of brittle star, is covered with ommatidia, turning its whole skin into a compound eye. The same is true of many chitons.  References "
"An organism (from Ancient Greek ὄργανον (órganon) 'instrument, implement, tool', and -ισμός (-ismós)) is any biological living system that functions as an individual life form. All organisms are composed of cells (cell theory). The idea of organism is based on the concept of minimal functional unit of life. Three traits have been proposed to play the main role in qualification as an organism: noncompartmentability – structure that cannot be divided without its functionality loss, individuality – the entity has simultaneous holding of genetic uniqueness, genetic homogeneity and autonomy, distinctness – genetic information has to maintain open-system (a cell).Organisms include multicellular animals, plants, and fungi; or unicellular microorganisms such as protists, bacteria, and archaea. All types of organisms are capable of reproduction, growth and development, maintenance, and some degree of response to stimuli. Most multicellular organisms differentiate into specialized tissues and organs during their development. A unicellular organism may be either a prokaryote or a eukaryote. Prokaryotes are represented by two separate domains – bacteria and archaea. Eukaryotic organisms are characterized by the presence of a membrane-bound cell nucleus and contain additional membrane-bound compartments called organelles (such as mitochondria in animals and plants and plastids in plants and algae, all generally considered to be derived from endosymbiotic bacteria). Fungi, animals and plants are examples of kingdoms of organisms within the eukaryotes. Estimates on the number of Earth's current species range from 2 million to 1 trillion, of which over 1.7 million have been documented. More than 99% of all species, amounting to over five billion species, that ever lived are estimated to be extinct.In 2016, a set of 355 genes from the last universal common ancestor (LUCA) of all organisms from Earth was identified.  Etymology  The term ""organism"" (from Greek ὀργανισμός, organismos, from ὄργανον, organon, i.e. ""instrument, implement, tool, organ of sense or apprehension"") first appeared in the English language in 1703 and took on its current definition by 1834 (Oxford English Dictionary). It is directly related to the term ""organization"". There is a long tradition of defining organisms as self-organizing beings, going back at least to Immanuel Kant's 1790 Critique of Judgment.  Definitions  An organism may be defined as an assembly of molecules functioning as a more or less stable whole that exhibits the properties of life. Dictionary definitions can be broad, using phrases such as ""any living structure, such as a plant, animal, fungus or bacterium, capable of growth and reproduction"". Many definitions exclude viruses and possible man-made non-organic life forms, as viruses are dependent on the biochemical machinery of a host cell for reproduction. A superorganism is an organism consisting of many individuals working together as a single functional or social unit.There has been controversy about the best way to define the organism, and from a philosophical point of view, whether such a definition is necessary. Problematic cases include colonial organisms: for instance, a colony of eusocial insects fulfils criteria such as adaptive organisation and germ-soma specialisation. If so, the same argument would include some mutualistic and sexual partnerships as organisms. If group selection occurs, then a group could be viewed as a superorganism, optimised by group adaptation. Another view is that attributes like autonomy, genetic homogeneity and genetic uniqueness should be examined separately rather than demanding that an organism should have all of them; if so, there are multiple dimensions to biological individuality, resulting in several types of organism.Other views include the idea that an individual is distinguished by its immune response, separating self from foreign; that ""anti-entropy"", the ability to maintain order, is what distinguishes an organism; or that Shannon's information theory can be used to identify organisms as capable of self-maintaining their information content. Finally, it may be that the concept of the organism is inadequate in biology.  Viruses  Viruses are not typically considered to be organisms because they are incapable of autonomous reproduction, growth or metabolism. Although some organisms are also incapable of independent survival and live as obligatory intracellular parasites, they are capable of independent metabolism and procreation. Although viruses have a few enzymes and molecules characteristic of living organisms, they have no metabolism of their own; they cannot synthesize and organize the organic compounds from which they are formed. Naturally, this rules out autonomous reproduction: they can only be passively replicated by the machinery of the host cell. In this sense, they are similar to inanimate matter. Viruses have their own genes, and they evolve. Thus, an argument that viruses should be classed as living organisms is their ability to undergo evolution and replicate through self-assembly. However, some scientists argue that viruses neither evolve nor self-reproduce. Instead, viruses are evolved by their host cells, meaning that there was co-evolution of viruses and host cells. If host cells did not exist, viral evolution would be impossible. This is not true for cells. If viruses did not exist, the direction of cellular evolution could be different, but cells would nevertheless be able to evolve. As for reproduction, viruses rely on hosts' machinery to replicate. The discovery of viruses with genes coding for energy metabolism and protein synthesis fuelled the debate about whether viruses are living organisms. The presence of these genes suggested that viruses were once able to metabolize. However, it was found later that the genes coding for energy and protein metabolism have a cellular origin. Most likely, these genes were acquired through horizontal gene transfer from viral hosts.  Chemistry  Organisms are complex chemical systems, organized in ways that promote reproduction and some measure of sustainability or survival. The same laws that govern non-living chemistry govern the chemical processes of life. It is generally the phenomena of entire organisms that determine their fitness to an environment and therefore the survival of their DNA-based genes.Organisms clearly owe their origin, metabolism, and many other internal functions to chemical phenomena, especially the chemistry of large organic molecules. Organisms are complex systems of chemical compounds that, through interaction and environment, play a wide variety of roles.{[cn}} Organisms are semi-closed chemical systems. Although they are individual units of life (as the definition requires), they are not closed to the environment around them. To operate, they constantly take in and release energy. Autotrophs produce usable energy (in the form of organic compounds) using light from the Sun or inorganic compounds, while heterotrophs take in organic compounds from the environment. The primary chemical element in these compounds is carbon. The chemical properties of this element such as its great affinity for bonding with other small atoms, including other carbon atoms, and its small size making it capable of forming multiple bonds, make it ideal as the basis of organic life. It is able to form small three-atom compounds (such as carbon dioxide), as well as large chains of many thousands of atoms that can store data (nucleic acids), hold cells together, and transmit information (protein).  Macromolecules  Compounds that make up organisms may be divided into macromolecules and other, smaller molecules. The four groups of macromolecule are nucleic acids, proteins, carbohydrates and lipids. Nucleic acids (specifically deoxyribonucleic acid, or DNA) store genetic data as a sequence of nucleotides. The particular sequence of the four different types of nucleotides (adenine, cytosine, guanine, and thymine) dictate many characteristics that constitute the organism. The sequence is divided up into codons, each of which is a particular sequence of three nucleotides and corresponds to a particular amino acid. Thus, a sequence of DNA codes for a particular protein that, due to the chemical properties of the amino acids it is made from, folds in a particular manner and so performs a particular function.These protein functions have been recognized: Enzymes, which catalyze the reactions of metabolism Structural proteins, such as tubulin, or collagen Regulatory proteins, such as transcription factors or cyclins that regulate the cell cycle Signaling molecules or their receptors, such as some hormones and their receptors Defensive proteins, which can include everything from antibodies of the immune system, to toxins (e.g., dendrotoxins of snakes), to proteins that include unusual amino acids like canavanineA bilayer of phospholipids makes up the membrane of cells that constitutes a barrier, containing everything within a cell and preventing compounds from freely passing into, and out of, the cell. Due to the selective permeability of the phospholipid membrane, only specific compounds can pass through it.  Structure  All organisms consist of structural units called cells; some contain a single cell (unicellular) and others contain many units (multicellular). Multicellular organisms are able to specialize cells to perform specific functions. A group of such cells is a tissue, and in animals these occur as four basic types, namely epithelium, nervous tissue, muscle tissue, and connective tissue. Several types of tissue work together in the form of an organ to produce a particular function (such as the pumping of the blood by the heart, or as a barrier to the environment as the skin). This pattern continues to a higher level with several organs functioning as an organ system such as the reproductive system, and digestive system. Many multicellular organisms consist of several organ systems, which coordinate to allow for life.  Cell  The cell theory, first developed in 1839 by Schleiden and Schwann, states that all organisms are composed of one or more cells; all cells come from preexisting cells, and cells contain the hereditary information necessary for regulating cell functions and for transmitting information to the next generation of cells. There are two types of cells, eukaryotic and prokaryotic. Prokaryotic cells are usually singletons, while eukaryotic cells are usually found in multicellular organisms. Prokaryotic cells lack a nuclear membrane so DNA is unbound within the cell; eukaryotic cells have nuclear membranes. All cells, whether prokaryotic or eukaryotic, have a membrane, which envelops the cell, separates its interior from its environment, regulates what moves in and out, and maintains the electric potential of the cell. Inside the membrane, a salty cytoplasm takes up most of the cell volume. All cells possess DNA, the hereditary material of genes, and RNA, containing the information necessary to build various proteins such as enzymes, the cell's primary machinery. There are also other kinds of biomolecules in cells. All cells share several similar characteristics of: Reproduction by cell division (binary fission, mitosis or meiosis). Use of enzymes and other proteins coded by DNA genes and made via messenger RNA intermediates and ribosomes. Metabolism, including taking in raw materials, building cell components, converting energy, molecules and releasing by-products. The functioning of a cell depends upon its ability to extract and use chemical energy stored in organic molecules. This energy is derived from metabolic pathways. Response to external and internal stimuli such as changes in temperature, pH or nutrient levels. Cell contents are contained within a cell surface membrane that contains proteins and a lipid bilayer.  Evolutionary history   Last universal common ancestor  The last universal common ancestor (LUCA) is the most recent organism from which all organisms now living on Earth descend. Thus, it is the most recent common ancestor of all current life on Earth. The LUCA is estimated to have lived some 3.5 to 3.8 billion years ago (sometime in the Paleoarchean era). The earliest evidence for life on Earth is graphite found to be biogenic in 3.7 billion-year-old metasedimentary rocks discovered in Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone discovered in Western Australia. Although more than 99 percent of all species that ever lived on the planet are estimated to be extinct, it is likely that more than a billion species of life exist on Earth currently, with the highest estimates and projections reaching one trillion species.Information about the early development of life includes input from many different fields, including geology and planetary science. These sciences provide information about the history of the Earth and the changes produced by life. However, a great deal of information about the early Earth has been destroyed by geological processes over the course of time. All organisms are descended from a common ancestor or ancestral gene pool. Evidence for common descent may be found in traits shared between all living organisms. In Darwin's day, the evidence of shared traits was based solely on visible observation of morphologic similarities, such as the fact that all birds have wings, even those that do not fly. There is strong evidence from genetics that all organisms have a common ancestor. For example, every living cell makes use of nucleic acids as its genetic material, and uses the same twenty amino acids as the building blocks for proteins. All organisms use the same genetic code (with some extremely rare and minor deviations) to translate nucleic acid sequences into proteins. The universality of these traits strongly suggests common ancestry, because the selection of many of these traits seems arbitrary. Horizontal gene transfer makes it more difficult to study the last universal ancestor. However, the universal use of the same genetic code, same nucleotides, and same amino acids makes the existence of such an ancestor overwhelmingly likely. The first organisms were possibly anaerobic and thermophilic chemolithoautotrophis that evolved within inorganic compartments at geothermal environments.  Phylogeny   Location of the root  The most commonly accepted location of the root of the tree of life is between a monophyletic domain Bacteria and a clade formed by Archaea and Eukaryota of what is referred to as the ""traditional tree of life"" based on several molecular studies. A very small minority of studies have concluded differently, namely that the root is in the domain Bacteria, either in the phylum Bacillota or that the phylum Chloroflexota is basal to a clade with Archaea and Eukaryotes and the rest of Bacteria as proposed by Thomas Cavalier-Smith.Research published in 2016, by William F. Martin, by genetically analyzing 6.1 million protein-coding genes from sequenced prokaryotic genomes of various phylogenetic trees, identified 355 protein clusters from amongst 286,514 protein clusters that were probably common to the LUCA. The results ""depict LUCA as anaerobic, CO2-fixing, H2-dependent with a Wood–Ljungdahl pathway (the reductive acetyl-coenzyme A pathway), N2-fixing and thermophilic. LUCA's biochemistry was replete with FeS clusters and radical reaction mechanisms. Its cofactors reveal dependence upon transition metals, flavins, S-adenosyl methionine, coenzyme A, ferredoxin, molybdopterin, corrins and selenium. Its genetic code required nucleoside modifications and S-adenosylmethionine-dependent methylations."" The results depict methanogenic clostria as a basal clade in the 355 lineages examined, and suggest that the LUCA inhabited an anaerobic hydrothermal vent setting in a geochemically active environment rich in H2, CO2, and iron. However, the identification of these genes as being present in LUCA was criticized, suggesting that many of the proteins assumed to be present in LUCA represent later horizontal gene transfers between archaea and bacteria.  Reproduction  Sexual reproduction is widespread among current eukaryotes, and was likely present in the last common ancestor. This is suggested by the finding of a core set of genes for meiosis in the descendants of lineages that diverged early from the eukaryotic evolutionary tree. and Malik et al. It is further supported by evidence that eukaryotes previously regarded as ""ancient asexuals"", such as Amoeba, were likely sexual in the past, and that most present day asexual amoeboid lineages likely arose recently and independently.In prokaryotes, natural bacterial transformation involves the transfer of DNA from one bacterium to another and integration of the donor DNA into the recipient chromosome by recombination. Natural bacterial transformation is considered to be a primitive sexual process and occurs in both bacteria and archaea, although it has been studied mainly in bacteria. Transformation is clearly a bacterial adaptation and not an accidental occurrence, because it depends on numerous gene products that specifically interact with each other to enter a state of natural competence to perform this complex process. Transformation is a common mode of DNA transfer among prokaryotes.  Horizontal gene transfer  The ancestry of living organisms has traditionally been reconstructed from morphology, but is increasingly supplemented with phylogenetics – the reconstruction of phylogenies by the comparison of genetic (DNA) sequence. Sequence comparisons suggest recent horizontal transfer of many genes among diverse species including across the boundaries of phylogenetic ""domains"". Thus determining the phylogenetic history of a species can not be done conclusively by determining evolutionary trees for single genes. Biologist Peter Gogarten suggests ""the original metaphor of a tree no longer fits the data from recent genome research"", therefore ""biologists (should) use the metaphor of a mosaic to describe the different histories combined in individual genomes and use (the) metaphor of a net to visualize the rich exchange and cooperative effects of HGT among microbes.""  Future of life (cloning and synthetic organisms)  Modern biotechnology is challenging traditional concepts of organisms and species. Cloning is the process of creating a new multicellular organism, genetically identical to another, with the potential of creating entirely new species of organisms. Cloning is the subject of much ethical debate. In 2008, the J. Craig Venter Institute assembled a synthetic bacterial genome, Mycoplasma genitalium, by using recombination in yeast of 25 overlapping DNA fragments in a single step. The use of yeast recombination greatly simplifies the assembly of large DNA molecules from both synthetic and natural fragments. Other companies, such as Synthetic Genomics, have already been formed to take advantage of the many commercial uses of custom designed genomes.  See also  Earliest known life forms  References   Further reading   External links  ""The Tree of Life"". Tree of Life Web Project. ""Indexing the world's known species"". Species 2000. Species 2000 has the objective of enumerating all known species of plants, animals, fungi and microbes on Earth as the baseline dataset for studies of global biodiversity. It will also provide a simple access point enabling users to link from here to other data systems for all groups of organisms, using direct species-links.","An organism is an individual living thing. It is easy to recognize a living thing, but not so easy to define it. Animals and plants are organisms, obviously. Organisms are a biotic, or living, part of the environment. Rocks and sunshine are parts of the non-living environment. Organisms usually have six basic needs to continue their metabolism. They need air, water, nutrient (food), energy, a place to live, and homeostatsis (being able to maintain itself). However, not all living things need all these at the same time. Some organisms do not need access to air at all. The characteristics of living things are if they have cells, take and use energy, grow and develop, share similar chemicals, sense and resond to change (stimulus), and if they reproduce. A little thought is needed about viruses. There is no agreement as to whether they should be regarded as living. They are made of protein and nucleic acid, and they evolve, which is a really important fact. However, they exist in two quite different phases. One phase is dormant, not active. The other is inside a living cell of some other organism. Then the virus is very active reproducing itself. Consider the parallel with a computer program. When in use it is active; when it is not, it is completely inactive. It is still a program all the same. Another example from biology is the spore, which is a distribution phase of a bacteria, fungus or some plants. They are not active until they get to the right situation. They have all the working parts to build a complete organism, but for the moment it is switched off. Some organisms are made up of millions of cells. They are multicellular organisms. Many can be seen without using a microscope. Most organisms are so small that they cannot be seen with the naked eye. You need a microscope to see them. They are called microorganisms. Organisms can be made up of just one cell. They are called unicellular organisms or single celled organisms. Examples include bacteria, and protozoa such as the Amoeba and Paramecium.  Origin  The Tree of Life project works on the relationships between living things. Identifying a LUCA (last universal common ancestor) is one of its main aims. The LUCA is estimated to have lived some 3.8 billion years ago (sometime in the Palaeoarchaean era). A universal common ancestor is at least 102860 times more probable than having multiple ancestors. A model with a single common ancestor but allowing for some gene swapping among species was... 103489 times more probable than the best multi-ancestor model...The idea came from Charles Darwin's On the Origin of Species, ""Therefore... probably all the organic beings which have ever lived on this earth have descended from some one primordial form...""  Related pages  Earliest known life forms Origin of life Morphology (biology)  References   Other websites  Official website About the Tree of Life Web Project Maddison D.R. et al 2007. The Tree of Life Web Project. Pages 19-40 in: Zhang Z.-Q. & Shear W.A., eds. Linnaeus Tercentenary: progress in invertebrate taxonomy. Zootaxa 1668:1-766. Open Access PDF"
"Proteins are large biomolecules and macromolecules that comprise one or more long chains of amino acid residues. Proteins perform a vast array of functions within organisms, including catalysing metabolic reactions, DNA replication, responding to stimuli, providing structure to cells and organisms, and transporting molecules from one location to another. Proteins differ from one another primarily in their sequence of amino acids, which is dictated by the nucleotide sequence of their genes, and which usually results in protein folding into a specific 3D structure that determines its activity. A linear chain of amino acid residues is called a polypeptide. A protein contains at least one long polypeptide. Short polypeptides, containing less than 20–30 residues, are rarely considered to be proteins and are commonly called peptides. The individual amino acid residues are bonded together by peptide bonds and adjacent amino acid residues. The sequence of amino acid residues in a protein is defined by the sequence of a gene, which is encoded in the genetic code. In general, the genetic code specifies 20 standard amino acids; but in certain organisms the genetic code can include selenocysteine and—in certain archaea—pyrrolysine. Shortly after or even during synthesis, the residues in a protein are often chemically modified by post-translational modification, which alters the physical and chemical properties, folding, stability, activity, and ultimately, the function of the proteins. Some proteins have non-peptide groups attached, which can be called prosthetic groups or cofactors. Proteins can also work together to achieve a particular function, and they often associate to form stable protein complexes. Once formed, proteins only exist for a certain period and are then degraded and recycled by the cell's machinery through the process of protein turnover. A protein's lifespan is measured in terms of its half-life and covers a wide range. They can exist for minutes or years with an average lifespan of 1–2 days in mammalian cells. Abnormal or misfolded proteins are degraded more rapidly either due to being targeted for destruction or due to being unstable. Like other biological macromolecules such as polysaccharides and nucleic acids, proteins are essential parts of organisms and participate in virtually every process within cells. Many proteins are enzymes that catalyse biochemical reactions and are vital to metabolism. Proteins also have structural or mechanical functions, such as actin and myosin in muscle and the proteins in the cytoskeleton, which form a system of scaffolding that maintains cell shape. Other proteins are important in cell signaling, immune responses, cell adhesion, and the cell cycle. In animals, proteins are needed in the diet to provide the essential amino acids that cannot be synthesized. Digestion breaks the proteins down for metabolic use. Proteins may be purified from other cellular components using a variety of techniques such as ultracentrifugation, precipitation, electrophoresis, and chromatography; the advent of genetic engineering has made possible a number of methods to facilitate purification. Methods commonly used to study protein structure and function include immunohistochemistry, site-directed mutagenesis, X-ray crystallography, nuclear magnetic resonance and mass spectrometry.  History and etymology  Proteins were recognized as a distinct class of biological molecules in the eighteenth century by Antoine Fourcroy and others, distinguished by the molecules' ability to coagulate or flocculate under treatments with heat or acid. Noted examples at the time included albumin from egg whites, blood serum albumin, fibrin, and wheat gluten. Proteins were first described by the Dutch chemist Gerardus Johannes Mulder and named by the Swedish chemist Jöns Jacob Berzelius in 1838. Mulder carried out elemental analysis of common proteins and found that nearly all proteins had the same empirical formula, C400H620N100O120P1S1. He came to the erroneous conclusion that they might be composed of a single type of (very large) molecule. The term ""protein"" to describe these molecules was proposed by Mulder's associate Berzelius; protein is derived from the Greek word πρώτειος (proteios), meaning ""primary"", ""in the lead"", or ""standing in front"", + -in. Mulder went on to identify the products of protein degradation such as the amino acid leucine for which he found a (nearly correct) molecular weight of 131 Da. Prior to ""protein"", other names were used, like ""albumins"" or ""albuminous materials"" (Eiweisskörper, in German).Early nutritional scientists such as the German Carl von Voit believed that protein was the most important nutrient for maintaining the structure of the body, because it was generally believed that ""flesh makes flesh."" Karl Heinrich Ritthausen extended known protein forms with the identification of glutamic acid. At the Connecticut Agricultural Experiment Station a detailed review of the vegetable proteins was compiled by Thomas Burr Osborne. Working with Lafayette Mendel and applying Liebig's law of the minimum in feeding laboratory rats, the nutritionally essential amino acids were established. The work was continued and communicated by William Cumming Rose. The understanding of proteins as polypeptides came through the work of Franz Hofmeister and Hermann Emil Fischer in 1902. The central role of proteins as enzymes in living organisms was not fully appreciated until 1926, when James B. Sumner showed that the enzyme urease was in fact a protein.The difficulty in purifying proteins in large quantities made them very difficult for early protein biochemists to study. Hence, early studies focused on proteins that could be purified in large quantities, e.g., those of blood, egg white, various toxins, and digestive/metabolic enzymes obtained from slaughterhouses. In the 1950s, the Armour Hot Dog Co. purified 1 kg of pure bovine pancreatic ribonuclease A and made it freely available to scientists; this gesture helped ribonuclease A become a major target for biochemical study for the following decades.Linus Pauling is credited with the successful prediction of regular protein secondary structures based on hydrogen bonding, an idea first put forth by William Astbury in 1933. Later work by Walter Kauzmann on denaturation, based partly on previous studies by Kaj Linderstrøm-Lang, contributed an understanding of protein folding and structure mediated by hydrophobic interactions. The first protein to be sequenced was insulin, by Frederick Sanger, in 1949. Sanger correctly determined the amino acid sequence of insulin, thus conclusively demonstrating that proteins consisted of linear polymers of amino acids rather than branched chains, colloids, or cyclols. He won the Nobel Prize for this achievement in 1958. With the development of X-ray crystallography, it became possible to sequence protein structures. The first protein structures to be solved were hemoglobin by Max Perutz and myoglobin by John Kendrew, in 1958. The use of computers and increasing computing power also supported the sequencing of complex proteins. In 1999, Roger Kornberg succeeded in sequencing the highly complex structure of RNA polymerase using high intensity X-rays from synchrotrons.Since then, cryo-electron microscopy (cryo-EM) of large macromolecular assemblies has been developed. Cryo-EM uses protein samples that are frozen rather than crystals, and beams of electrons rather than x-rays. It causes less damage to the sample, allowing scientists to obtain more information and analyze larger structures. Computational protein structure prediction of small protein domains has also helped researchers to approach atomic-level resolution of protein structures. As of 2017, the Protein Data Bank has over 126,060 atomic-resolution structures of proteins.  Number of proteins encoded in genomes  The number of proteins encoded in a genome roughly corresponds to the number of genes (although there may be a significant number of genes that encode RNA of protein, e.g. ribosomal RNAs). Viruses typically encode a few to a few hundred proteins, archaea and bacteria a few hundred to a few thousand, while eukaryotes typically encode a few thousand up to tens of thousands of proteins (see genome size for a list of examples).  Biochemistry  Most proteins consist of linear polymers built from series of up to 20 different L-α- amino acids. All proteinogenic amino acids possess common structural features, including an α-carbon to which an amino group, a carboxyl group, and a variable side chain are bonded. Only proline differs from this basic structure as it contains an unusual ring to the N-end amine group, which forces the CO–NH amide moiety into a fixed conformation. The side chains of the standard amino acids, detailed in the list of standard amino acids, have a great variety of chemical structures and properties; it is the combined effect of all of the amino acid side chains in a protein that ultimately determines its three-dimensional structure and its chemical reactivity. The amino acids in a polypeptide chain are linked by peptide bonds. Once linked in the protein chain, an individual amino acid is called a residue, and the linked series of carbon, nitrogen, and oxygen atoms are known as the main chain or protein backbone.: 19 The peptide bond has two resonance forms that contribute some double-bond character and inhibit rotation around its axis, so that the alpha carbons are roughly coplanar. The other two dihedral angles in the peptide bond determine the local shape assumed by the protein backbone.: 31 The end with a free amino group is known as the N-terminus or amino terminus, whereas the end of the protein with a free carboxyl group is known as the C-terminus or carboxy terminus (the sequence of the protein is written from N-terminus to C-terminus, from left to right). The words protein, polypeptide, and peptide are a little ambiguous and can overlap in meaning. Protein is generally used to refer to the complete biological molecule in a stable conformation, whereas peptide is generally reserved for a short amino acid oligomers often lacking a stable 3D structure. But the boundary between the two is not well defined and usually lies near 20–30 residues. Polypeptide can refer to any single linear chain of amino acids, usually regardless of length, but often implies an absence of a defined conformation.  Interactions  Proteins can interact with many types of molecules, including with other proteins, with lipids, with carbohydrates, and with DNA.  Abundance in cells  It has been estimated that average-sized bacteria contain about 2 million proteins per cell (e.g. E. coli and Staphylococcus aureus). Smaller bacteria, such as Mycoplasma or spirochetes contain fewer molecules, on the order of 50,000 to 1 million. By contrast, eukaryotic cells are larger and thus contain much more protein. For instance, yeast cells have been estimated to contain about 50 million proteins and human cells on the order of 1 to 3 billion. The concentration of individual protein copies ranges from a few molecules per cell up to 20 million. Not all genes coding proteins are expressed in most cells and their number depends on, for example, cell type and external stimuli. For instance, of the 20,000 or so proteins encoded by the human genome, only 6,000 are detected in lymphoblastoid cells.  Synthesis   Biosynthesis  Proteins are assembled from amino acids using information encoded in genes. Each protein has its own unique amino acid sequence that is specified by the nucleotide sequence of the gene encoding this protein. The genetic code is a set of three-nucleotide sets called codons and each three-nucleotide combination designates an amino acid, for example AUG (adenine–uracil–guanine) is the code for methionine. Because DNA contains four nucleotides, the total number of possible codons is 64; hence, there is some redundancy in the genetic code, with some amino acids specified by more than one codon.: 1002–42 Genes encoded in DNA are first transcribed into pre-messenger RNA (mRNA) by proteins such as RNA polymerase. Most organisms then process the pre-mRNA (also known as a primary transcript) using various forms of Post-transcriptional modification to form the mature mRNA, which is then used as a template for protein synthesis by the ribosome. In prokaryotes the mRNA may either be used as soon as it is produced, or be bound by a ribosome after having moved away from the nucleoid. In contrast, eukaryotes make mRNA in the cell nucleus and then translocate it across the nuclear membrane into the cytoplasm, where protein synthesis then takes place. The rate of protein synthesis is higher in prokaryotes than eukaryotes and can reach up to 20 amino acids per second.The process of synthesizing a protein from an mRNA template is known as translation. The mRNA is loaded onto the ribosome and is read three nucleotides at a time by matching each codon to its base pairing anticodon located on a transfer RNA molecule, which carries the amino acid corresponding to the codon it recognizes. The enzyme aminoacyl tRNA synthetase ""charges"" the tRNA molecules with the correct amino acids. The growing polypeptide is often termed the nascent chain. Proteins are always biosynthesized from N-terminus to C-terminus.: 1002–42 The size of a synthesized protein can be measured by the number of amino acids it contains and by its total molecular mass, which is normally reported in units of daltons (synonymous with atomic mass units), or the derivative unit kilodalton (kDa). The average size of a protein increases from Archaea to Bacteria to Eukaryote (283, 311, 438 residues and 31, 34, 49 kDa respectively) due to a bigger number of protein domains constituting proteins in higher organisms. For instance, yeast proteins are on average 466 amino acids long and 53 kDa in mass. The largest known proteins are the titins, a component of the muscle sarcomere, with a molecular mass of almost 3,000 kDa and a total length of almost 27,000 amino acids.  Chemical synthesis  Short proteins can also be synthesized chemically by a family of methods known as peptide synthesis, which rely on organic synthesis techniques such as chemical ligation to produce peptides in high yield. Chemical synthesis allows for the introduction of non-natural amino acids into polypeptide chains, such as attachment of fluorescent probes to amino acid side chains. These methods are useful in laboratory biochemistry and cell biology, though generally not for commercial applications. Chemical synthesis is inefficient for polypeptides longer than about 300 amino acids, and the synthesized proteins may not readily assume their native tertiary structure. Most chemical synthesis methods proceed from C-terminus to N-terminus, opposite the biological reaction.  Structure  Most proteins fold into unique 3D structures. The shape into which a protein naturally folds is known as its native conformation.: 36 Although many proteins can fold unassisted, simply through the chemical properties of their amino acids, others require the aid of molecular chaperones to fold into their native states.: 37 Biochemists often refer to four distinct aspects of a protein's structure:: 30–34 Primary structure: the amino acid sequence. A protein is a polyamide. Secondary structure: regularly repeating local structures stabilized by hydrogen bonds. The most common examples are the α-helix, β-sheet and turns. Because secondary structures are local, many regions of different secondary structure can be present in the same protein molecule. Tertiary structure: the overall shape of a single protein molecule; the spatial relationship of the secondary structures to one another. Tertiary structure is generally stabilized by nonlocal interactions, most commonly the formation of a hydrophobic core, but also through salt bridges, hydrogen bonds, disulfide bonds, and even posttranslational modifications. The term ""tertiary structure"" is often used as synonymous with the term fold. The tertiary structure is what controls the basic function of the protein. Quaternary structure: the structure formed by several protein molecules (polypeptide chains), usually called protein subunits in this context, which function as a single protein complex. Quinary structure: the signatures of protein surface that organize the crowded cellular interior. Quinary structure is dependent on transient, yet essential, macromolecular interactions that occur inside living cells.Proteins are not entirely rigid molecules. In addition to these levels of structure, proteins may shift between several related structures while they perform their functions. In the context of these functional rearrangements, these tertiary or quaternary structures are usually referred to as ""conformations"", and transitions between them are called conformational changes. Such changes are often induced by the binding of a substrate molecule to an enzyme's active site, or the physical region of the protein that participates in chemical catalysis. In solution proteins also undergo variation in structure through thermal vibration and the collision with other molecules.: 368–75 Proteins can be informally divided into three main classes, which correlate with typical tertiary structures: globular proteins, fibrous proteins, and membrane proteins. Almost all globular proteins are soluble and many are enzymes. Fibrous proteins are often structural, such as collagen, the major component of connective tissue, or keratin, the protein component of hair and nails. Membrane proteins often serve as receptors or provide channels for polar or charged molecules to pass through the cell membrane.: 165–85 A special case of intramolecular hydrogen bonds within proteins, poorly shielded from water attack and hence promoting their own dehydration, are called dehydrons.  Protein domains  Many proteins are composed of several protein domains, i.e. segments of a protein that fold into distinct structural units. Domains usually also have specific functions, such as enzymatic activities (e.g. kinase) or they serve as binding modules (e.g. the SH3 domain binds to proline-rich sequences in other proteins).  Sequence motif  Short amino acid sequences within proteins often act as recognition sites for other proteins. For instance, SH3 domains typically bind to short PxxP motifs (i.e. 2 prolines [P], separated by two unspecified amino acids [x], although the surrounding amino acids may determine the exact binding specificity). Many such motifs has been collected in the Eukaryotic Linear Motif (ELM) database.  Protein topology  Topology of a protein describes the entanglement of the backbone and the arrangement of contacts within the folded chain. Two theoretical frameworks of knot theory and Circuit topology have been applied to characterise protein topology. Being able to describe protein topology opens up new pathways for protein engineering and pharmaceutical development, and adds to our understanding of protein misfolding diseases such as neuromuscular disorders and cancer.  Cellular functions  Proteins are the chief actors within the cell, said to be carrying out the duties specified by the information encoded in genes. With the exception of certain types of RNA, most other biological molecules are relatively inert elements upon which proteins act. Proteins make up half the dry weight of an Escherichia coli cell, whereas other macromolecules such as DNA and RNA make up only 3% and 20%, respectively. The set of proteins expressed in a particular cell or cell type is known as its proteome. The chief characteristic of proteins that also allows their diverse set of functions is their ability to bind other molecules specifically and tightly. The region of the protein responsible for binding another molecule is known as the binding site and is often a depression or ""pocket"" on the molecular surface. This binding ability is mediated by the tertiary structure of the protein, which defines the binding site pocket, and by the chemical properties of the surrounding amino acids' side chains. Protein binding can be extraordinarily tight and specific; for example, the ribonuclease inhibitor protein binds to human angiogenin with a sub-femtomolar dissociation constant (<10−15 M) but does not bind at all to its amphibian homolog onconase (>1 M). Extremely minor chemical changes such as the addition of a single methyl group to a binding partner can sometimes suffice to nearly eliminate binding; for example, the aminoacyl tRNA synthetase specific to the amino acid valine discriminates against the very similar side chain of the amino acid isoleucine.Proteins can bind to other proteins as well as to small-molecule substrates. When proteins bind specifically to other copies of the same molecule, they can oligomerize to form fibrils; this process occurs often in structural proteins that consist of globular monomers that self-associate to form rigid fibers. Protein–protein interactions also regulate enzymatic activity, control progression through the cell cycle, and allow the assembly of large protein complexes that carry out many closely related reactions with a common biological function. Proteins can also bind to, or even be integrated into, cell membranes. The ability of binding partners to induce conformational changes in proteins allows the construction of enormously complex signaling networks.: 830–49 As interactions between proteins are reversible, and depend heavily on the availability of different groups of partner proteins to form aggregates that are capable to carry out discrete sets of function, study of the interactions between specific proteins is a key to understand important aspects of cellular function, and ultimately the properties that distinguish particular cell types.  Enzymes  The best-known role of proteins in the cell is as enzymes, which catalyse chemical reactions. Enzymes are usually highly specific and accelerate only one or a few chemical reactions. Enzymes carry out most of the reactions involved in metabolism, as well as manipulating DNA in processes such as DNA replication, DNA repair, and transcription. Some enzymes act on other proteins to add or remove chemical groups in a process known as posttranslational modification. About 4,000 reactions are known to be catalysed by enzymes. The rate acceleration conferred by enzymatic catalysis is often enormous—as much as 1017-fold increase in rate over the uncatalysed reaction in the case of orotate decarboxylase (78 million years without the enzyme, 18 milliseconds with the enzyme).The molecules bound and acted upon by enzymes are called substrates. Although enzymes can consist of hundreds of amino acids, it is usually only a small fraction of the residues that come in contact with the substrate, and an even smaller fraction—three to four residues on average—that are directly involved in catalysis. The region of the enzyme that binds the substrate and contains the catalytic residues is known as the active site. Dirigent proteins are members of a class of proteins that dictate the stereochemistry of a compound synthesized by other enzymes.  Cell signaling and ligand binding  Many proteins are involved in the process of cell signaling and signal transduction. Some proteins, such as insulin, are extracellular proteins that transmit a signal from the cell in which they were synthesized to other cells in distant tissues. Others are membrane proteins that act as receptors whose main function is to bind a signaling molecule and induce a biochemical response in the cell. Many receptors have a binding site exposed on the cell surface and an effector domain within the cell, which may have enzymatic activity or may undergo a conformational change detected by other proteins within the cell.: 251–81 Antibodies are protein components of an adaptive immune system whose main function is to bind antigens, or foreign substances in the body, and target them for destruction. Antibodies can be secreted into the extracellular environment or anchored in the membranes of specialized B cells known as plasma cells. Whereas enzymes are limited in their binding affinity for their substrates by the necessity of conducting their reaction, antibodies have no such constraints. An antibody's binding affinity to its target is extraordinarily high.: 275–50 Many ligand transport proteins bind particular small biomolecules and transport them to other locations in the body of a multicellular organism. These proteins must have a high binding affinity when their ligand is present in high concentrations, but must also release the ligand when it is present at low concentrations in the target tissues. The canonical example of a ligand-binding protein is haemoglobin, which transports oxygen from the lungs to other organs and tissues in all vertebrates and has close homologs in every biological kingdom.: 222–29 Lectins are sugar-binding proteins which are highly specific for their sugar moieties. Lectins typically play a role in biological recognition phenomena involving cells and proteins. Receptors and hormones are highly specific binding proteins. Transmembrane proteins can also serve as ligand transport proteins that alter the permeability of the cell membrane to small molecules and ions. The membrane alone has a hydrophobic core through which polar or charged molecules cannot diffuse. Membrane proteins contain internal channels that allow such molecules to enter and exit the cell. Many ion channel proteins are specialized to select for only a particular ion; for example, potassium and sodium channels often discriminate for only one of the two ions.: 232–34  Structural proteins  Structural proteins confer stiffness and rigidity to otherwise-fluid biological components. Most structural proteins are fibrous proteins; for example, collagen and elastin are critical components of connective tissue such as cartilage, and keratin is found in hard or filamentous structures such as hair, nails, feathers, hooves, and some animal shells.: 178–81 Some globular proteins can also play structural functions, for example, actin and tubulin are globular and soluble as monomers, but polymerize to form long, stiff fibers that make up the cytoskeleton, which allows the cell to maintain its shape and size. Other proteins that serve structural functions are motor proteins such as myosin, kinesin, and dynein, which are capable of generating mechanical forces. These proteins are crucial for cellular motility of single celled organisms and the sperm of many multicellular organisms which reproduce sexually. They also generate the forces exerted by contracting muscles: 258–64, 272 and play essential roles in intracellular transport.  Protein evolution  A key question in molecular biology is how proteins evolve, i.e. how can mutations (or rather changes in amino acid sequence) lead to new structures and functions? Most amino acids in a protein can be changed without disrupting activity or function, as can be seen from numerous homologous proteins across species (as collected in specialized databases for protein families, e.g. PFAM). In order to prevent dramatic consequences of mutations, a gene may be duplicated before it can mutate freely. However, this can also lead to complete loss of gene function and thus pseudo-genes. More commonly, single amino acid changes have limited consequences although some can change protein function substantially, especially in enzymes. For instance, many enzymes can change their substrate specificity by one or a few mutations. Changes in substrate specificity are facilitated by substrate promiscuity, i.e. the ability of many enzymes to bind and process multiple substrates. When mutations occur, the specificity of an enzyme can increase (or decrease) and thus its enzymatic activity. Thus, bacteria (or other organisms) can adapt to different food sources, including unnatural substrates such as plastic.  Methods of study  The activities and structures of proteins may be examined in vitro, in vivo, and in silico. In vitro studies of purified proteins in controlled environments are useful for learning how a protein carries out its function: for example, enzyme kinetics studies explore the chemical mechanism of an enzyme's catalytic activity and its relative affinity for various possible substrate molecules. By contrast, in vivo experiments can provide information about the physiological role of a protein in the context of a cell or even a whole organism. In silico studies use computational methods to study proteins.  Protein purification  To perform in vitro analysis, a protein must be purified away from other cellular components. This process usually begins with cell lysis, in which a cell's membrane is disrupted and its internal contents released into a solution known as a crude lysate. The resulting mixture can be purified using ultracentrifugation, which fractionates the various cellular components into fractions containing soluble proteins; membrane lipids and proteins; cellular organelles, and nucleic acids. Precipitation by a method known as salting out can concentrate the proteins from this lysate. Various types of chromatography are then used to isolate the protein or proteins of interest based on properties such as molecular weight, net charge and binding affinity.: 21–24 The level of purification can be monitored using various types of gel electrophoresis if the desired protein's molecular weight and isoelectric point are known, by spectroscopy if the protein has distinguishable spectroscopic features, or by enzyme assays if the protein has enzymatic activity. Additionally, proteins can be isolated according to their charge using electrofocusing.For natural proteins, a series of purification steps may be necessary to obtain protein sufficiently pure for laboratory applications. To simplify this process, genetic engineering is often used to add chemical features to proteins that make them easier to purify without affecting their structure or activity. Here, a ""tag"" consisting of a specific amino acid sequence, often a series of histidine residues (a ""His-tag""), is attached to one terminus of the protein. As a result, when the lysate is passed over a chromatography column containing nickel, the histidine residues ligate the nickel and attach to the column while the untagged components of the lysate pass unimpeded. A number of different tags have been developed to help researchers purify specific proteins from complex mixtures.  Cellular localization  The study of proteins in vivo is often concerned with the synthesis and localization of the protein within the cell. Although many intracellular proteins are synthesized in the cytoplasm and membrane-bound or secreted proteins in the endoplasmic reticulum, the specifics of how proteins are targeted to specific organelles or cellular structures is often unclear. A useful technique for assessing cellular localization uses genetic engineering to express in a cell a fusion protein or chimera consisting of the natural protein of interest linked to a ""reporter"" such as green fluorescent protein (GFP). The fused protein's position within the cell can be cleanly and efficiently visualized using microscopy, as shown in the figure opposite. Other methods for elucidating the cellular location of proteins requires the use of known compartmental markers for regions such as the ER, the Golgi, lysosomes or vacuoles, mitochondria, chloroplasts, plasma membrane, etc. With the use of fluorescently tagged versions of these markers or of antibodies to known markers, it becomes much simpler to identify the localization of a protein of interest. For example, indirect immunofluorescence will allow for fluorescence colocalization and demonstration of location. Fluorescent dyes are used to label cellular compartments for a similar purpose.Other possibilities exist, as well. For example, immunohistochemistry usually uses an antibody to one or more proteins of interest that are conjugated to enzymes yielding either luminescent or chromogenic signals that can be compared between samples, allowing for localization information. Another applicable technique is cofractionation in sucrose (or other material) gradients using isopycnic centrifugation. While this technique does not prove colocalization of a compartment of known density and the protein of interest, it does increase the likelihood, and is more amenable to large-scale studies. Finally, the gold-standard method of cellular localization is immunoelectron microscopy. This technique also uses an antibody to the protein of interest, along with classical electron microscopy techniques. The sample is prepared for normal electron microscopic examination, and then treated with an antibody to the protein of interest that is conjugated to an extremely electro-dense material, usually gold. This allows for the localization of both ultrastructural details as well as the protein of interest.Through another genetic engineering application known as site-directed mutagenesis, researchers can alter the protein sequence and hence its structure, cellular localization, and susceptibility to regulation. This technique even allows the incorporation of unnatural amino acids into proteins, using modified tRNAs, and may allow the rational design of new proteins with novel properties.  Proteomics  The total complement of proteins present at a time in a cell or cell type is known as its proteome, and the study of such large-scale data sets defines the field of proteomics, named by analogy to the related field of genomics. Key experimental techniques in proteomics include 2D electrophoresis, which allows the separation of many proteins, mass spectrometry, which allows rapid high-throughput identification of proteins and sequencing of peptides (most often after in-gel digestion), protein microarrays, which allow the detection of the relative levels of the various proteins present in a cell, and two-hybrid screening, which allows the systematic exploration of protein–protein interactions. The total complement of biologically possible such interactions is known as the interactome. A systematic attempt to determine the structures of proteins representing every possible fold is known as structural genomics.  Structure determination  Discovering the tertiary structure of a protein, or the quaternary structure of its complexes, can provide important clues about how the protein performs its function and how it can be affected, i.e. in drug design. As proteins are too small to be seen under a light microscope, other methods have to be employed to determine their structure. Common experimental methods include X-ray crystallography and NMR spectroscopy, both of which can produce structural information at atomic resolution. However, NMR experiments are able to provide information from which a subset of distances between pairs of atoms can be estimated, and the final possible conformations for a protein are determined by solving a distance geometry problem. Dual polarisation interferometry is a quantitative analytical method for measuring the overall protein conformation and conformational changes due to interactions or other stimulus. Circular dichroism is another laboratory technique for determining internal β-sheet / α-helical composition of proteins. Cryoelectron microscopy is used to produce lower-resolution structural information about very large protein complexes, including assembled viruses;: 340–41 a variant known as electron crystallography can also produce high-resolution information in some cases, especially for two-dimensional crystals of membrane proteins. Solved structures are usually deposited in the Protein Data Bank (PDB), a freely available resource from which structural data about thousands of proteins can be obtained in the form of Cartesian coordinates for each atom in the protein.Many more gene sequences are known than protein structures. Further, the set of solved structures is biased toward proteins that can be easily subjected to the conditions required in X-ray crystallography, one of the major structure determination methods. In particular, globular proteins are comparatively easy to crystallize in preparation for X-ray crystallography. Membrane proteins and large protein complexes, by contrast, are difficult to crystallize and are underrepresented in the PDB. Structural genomics initiatives have attempted to remedy these deficiencies by systematically solving representative structures of major fold classes. Protein structure prediction methods attempt to provide a means of generating a plausible structure for proteins whose structures have not been experimentally determined.  Structure prediction  Complementary to the field of structural genomics, protein structure prediction develops efficient mathematical models of proteins to computationally predict the molecular formations in theory, instead of detecting structures with laboratory observation. The most successful type of structure prediction, known as homology modeling, relies on the existence of a ""template"" structure with sequence similarity to the protein being modeled; structural genomics' goal is to provide sufficient representation in solved structures to model most of those that remain. Although producing accurate models remains a challenge when only distantly related template structures are available, it has been suggested that sequence alignment is the bottleneck in this process, as quite accurate models can be produced if a ""perfect"" sequence alignment is known. Many structure prediction methods have served to inform the emerging field of protein engineering, in which novel protein folds have already been designed. Also proteins (in eukaryotes ~33%) contain large unstructured but biologically functional segments and can be classified as intrinsically disordered proteins. Predicting and analysing protein disorder is, therefore, an important part of protein structure characterisation.  Bioinformatics  A vast array of computational methods have been developed to analyze the structure, function and evolution of proteins. The development of such tools has been driven by the large amount of genomic and proteomic data available for a variety of organisms, including the human genome. It is simply impossible to study all proteins experimentally, hence only a few are subjected to laboratory experiments while computational tools are used to extrapolate to similar proteins. Such homologous proteins can be efficiently identified in distantly related organisms by sequence alignment. Genome and gene sequences can be searched by a variety of tools for certain properties. Sequence profiling tools can find restriction enzyme sites, open reading frames in nucleotide sequences, and predict secondary structures. Phylogenetic trees can be constructed and evolutionary hypotheses developed using special software like ClustalW regarding the ancestry of modern organisms and the genes they express. The field of bioinformatics is now indispensable for the analysis of genes and proteins.  In silico simulation of dynamical processes  A more complex computational problem is the prediction of intermolecular interactions, such as in molecular docking, protein folding, protein–protein interaction and chemical reactivity. Mathematical models to simulate these dynamical processes involve molecular mechanics, in particular, molecular dynamics. In this regard, in silico simulations discovered the folding of small α-helical protein domains such as the villin headpiece, the HIV accessory protein and hybrid methods combining standard molecular dynamics with quantum mechanical mathematics have explored the electronic states of rhodopsins.Beyond classical molecular dynamics, quantum dynamics methods allow the simulation of proteins in atomistic detail with an accurate description of quantum mechanical effects. Examples include the multi-layer multi-configuration time-dependent Hartree (MCTDH) method and the hierarchical equations of motion (HEOM) approach, which have been applied to plant cryptochromes and bacteria light-harvesting complexes, respectively. Both quantum and classical mechanical simulations of biological-scale systems are extremely computationally demanding, so distributed computing initiatives (for example, the Folding@home project) facilitate the molecular modeling by exploiting advances in GPU parallel processing and Monte Carlo techniques.  Chemical analysis  The total nitrogen content of organic matter is mainly formed by the amino groups in proteins. The Total Kjeldahl Nitrogen (TKN) is a measure of nitrogen widely used in the analysis of (waste) water, soil, food, feed and organic matter in general. As the name suggests, the Kjeldahl method is applied. More sensitive methods are available.  Nutrition  Most microorganisms and plants can biosynthesize all 20 standard amino acids, while animals (including humans) must obtain some of the amino acids from the diet. The amino acids that an organism cannot synthesize on its own are referred to as essential amino acids. Key enzymes that synthesize certain amino acids are not present in animals—such as aspartokinase, which catalyses the first step in the synthesis of lysine, methionine, and threonine from aspartate. If amino acids are present in the environment, microorganisms can conserve energy by taking up the amino acids from their surroundings and downregulating their biosynthetic pathways. In animals, amino acids are obtained through the consumption of foods containing protein. Ingested proteins are then broken down into amino acids through digestion, which typically involves denaturation of the protein through exposure to acid and hydrolysis by enzymes called proteases. Some ingested amino acids are used for protein biosynthesis, while others are converted to glucose through gluconeogenesis, or fed into the citric acid cycle. This use of protein as a fuel is particularly important under starvation conditions as it allows the body's own proteins to be used to support life, particularly those found in muscle.In animals such as dogs and cats, protein maintains the health and quality of the skin by promoting hair follicle growth and keratinization, and thus reducing the likelihood of skin problems producing malodours. Poor-quality proteins also have a role regarding gastrointestinal health, increasing the potential for flatulence and odorous compounds in dogs because when proteins reach the colon in an undigested state, they are fermented producing hydrogen sulfide gas, indole, and skatole. Dogs and cats digest animal proteins better than those from plants, but products of low-quality animal origin are poorly digested, including skin, feathers, and connective tissue.  See also   References   Further reading  Textbooks  External links   Databases and projects  NCBI Entrez Protein database NCBI Protein Structure database Human Protein Reference Database Human Proteinpedia Folding@Home (Stanford University) Archived 2012-09-08 at the Wayback Machine Protein Databank in Europe (see also PDBeQuips, short articles and tutorials on interesting PDB structures) Research Collaboratory for Structural Bioinformatics (see also Molecule of the Month Archived 2020-07-24 at the Wayback Machine, presenting short accounts on selected proteins from the PDB) Proteopedia – Life in 3D: rotatable, zoomable 3D model with wiki annotations for every known protein molecular structure. UniProt the Universal Protein Resource  Tutorials and educational websites  ""An Introduction to Proteins"" from HOPES (Huntington's Disease Outreach Project for Education at Stanford) Proteins: Biogenesis to Degradation – The Virtual Library of Biochemistry and Cell Biology","Proteins are long-chain molecules built from small units known as amino acids. They are joined with peptide bonds. They are biochemical compounds of one or more polypeptides folded into a round or fibrous shape.A polypeptide is a single linear polymer chain of amino acids. The sequence of amino acids in a polypeptide comes from the DNA sequence of a gene. The genetic code specifies 20 standard amino acids. Shortly after synthesis, some amino acids are chemically modified. This alters the folding, stability, activity, and function of the protein. Sometimes proteins have non-peptide groups attached, as cofactors. Proteins are essential to all cells. Like other biological macromolecules (polysaccharides and nucleic acids), proteins take part in virtually every process in cells: Many proteins are enzymes that catalyze (help to happen) biochemical reactions and are vital to metabolism. Other proteins have structural or mechanical functions, such as in muscle and in cells. The cytoskeleton is a system of scaffolding that keeps cell shape. Other proteins are important in cell signalling, immune responses, and cell division  Formation  Proteins are formed by a process called ""protein synthesis"". The cell reads the genetic information of the DNA and translates it into a protein. In eukaryotes, this process begins in the cell nucleus and ends in the ribosome. In prokaryotes all of it is done in the cytoplasm. Proteins have different functions depending on their shape and sequence. They can be found in meat or muscle. They are used for growth and repair, as well as for strengthening the bones. They help to make tissue and cells. They are in animals, plants, fungi, bacteria, and in the human body. Muscles are mostly made of protein. When protein is digested, it is broken down into amino acids. These amino acids can then be used to build new protein. Proteins form an important part in foods like milk, eggs, meat, fish, beans, spinach, and nuts. There are four factors that determine what a protein will do. The first is the order of the amino acids. There are 20 different types of amino acids. The second is the little twists in the chain. The third is how the entire structure is folded up. The fourth is whether it is made up of different sub-units. Haemoglobin molecules, for example, are made of four sub-units.  Damaging mutations  Most proteins are enzymes, and mutations may slow them or stop them working. 50% of human cancers are caused by mutations in the tumour suppressor p53. p53 is a protein which regulates cell division.  Lifespan  Once formed, proteins only exist for a certain period. Then they are and recycled by the cell's machinery. A protein's lifespan is measured by its half-life. This covers a wide range. They can exist for minutes or years with an average lifespan of 1–2 days in mammalian cells.  Essential amino acids  Proteins are necessary in an animal's diet, since they cannot make all the amino acids they need (they can make most of them). They must get certain amino acids from food. These are called the essential amino acids. Through digestion, animals break down ingested protein into free amino acids. The amino acids are then used in metabolism to make the enzymes and structures the body needs. There are nine essential amino acids for humans, which are obtained from food. The nine essential amino acids are: histidine, isoleucine, leucine, lysine, methionine, phenylalanine, threonine, tryptophan, and valine. Meat contains all the essential amino acids humans need; most plants do not. However, eating a mixture of plants, such as both wheat and peanut butter, or rice and beans, provides all the essential amino acids needed. Soy products like tofu provide all the essential amino acids—as does quinoa—but these are not the only way to get the protein humans need. Proteins were first described by the Dutch chemist Gerardus Johannes Mulder. Jöns Jacob Berzelius gave proteins their name. Hundreds of other scientists have studied proteins since him.  Related pages  Protein structure Protein folding Translation (genetics)  References   Other websites  Protein from the Harvard School of Public Health"
"Amino acids are organic compounds that contain both amino and carboxylic acid functional groups. Although over 500 amino acids exist in nature, by far the most important are the alpha-amino acids, from which proteins are composed. Only 22 alpha amino acids appear in the genetic code.Amino acids can be classified according to the locations of the core structural functional groups, as alpha- (α-), beta- (β-), gamma- (γ-) or delta- (δ-) amino acids; other categories relate to polarity, ionization, and side chain group type (aliphatic, acyclic, aromatic, containing hydroxyl or sulfur, etc.). In the form of proteins, amino acid residues form the second-largest component (water being the largest) of human muscles and other tissues. Beyond their role as residues in proteins, amino acids participate in a number of processes such as neurotransmitter transport and biosynthesis. It is thought that they played a key role in enabling life on Earth and its emergence. Amino acids are formally named by the IUPAC-IUBMB Joint Commission on Biochemical Nomenclature in terms of the fictitious ""neutral"" structure shown in the illustration. For example, the systematic name of alanine is 2-aminopropanoic acid, based on the formula CH3−CH(NH2)−COOH. The Commission justified this approach as follows: The systematic names and formulas given refer to hypothetical forms in which amino groups are unprotonated and carboxyl groups are undissociated. This convention is useful to avoid various nomenclatural problems but should not be taken to imply that these structures represent an appreciable fraction of the amino-acid molecules.  History  The first few amino acids were discovered in the early 1800s. In 1806, French chemists Louis-Nicolas Vauquelin and Pierre Jean Robiquet isolated a compound from asparagus that was subsequently named asparagine, the first amino acid to be discovered. Cystine was discovered in 1810, although its monomer, cysteine, remained undiscovered until 1884. Glycine and leucine were discovered in 1820. The last of the 20 common amino acids to be discovered was threonine in 1935 by William Cumming Rose, who also determined the essential amino acids and established the minimum daily requirements of all amino acids for optimal growth.The unity of the chemical category was recognized by Wurtz in 1865, but he gave no particular name to it. The first use of the term ""amino acid"" in the English language dates from 1898, while the German term, Aminosäure, was used earlier. Proteins were found to yield amino acids after enzymatic digestion or acid hydrolysis. In 1902, Emil Fischer and Franz Hofmeister independently proposed that proteins are formed from many amino acids, whereby bonds are formed between the amino group of one amino acid with the carboxyl group of another, resulting in a linear structure that Fischer termed ""peptide"".  General structure  In the structure shown at the top of the page, R represents a side chain specific to each amino acid. The carbon atom next to the carboxyl group is called the α–carbon. Amino acids containing an amino group bonded directly to the α-carbon are referred to as α-amino acids. These include proline and hydroxyproline, which are secondary amines. In the past they were often called imino acids, a misnomer because they do not contain an imine grouping HNC.  Isomerism  The common natural forms of amino acids have a zwitterionic structure, with −NH+3 (−NH+2− in the case of proline) and −CO−2 functional groups attached to the same C atom, and are thus α-amino acids. With the exception of achiral glycine, natural amino acids have the L configuration, and are the only ones found in proteins during translation in the ribosome. The L and D convention for amino acid configuration refers not to the optical activity of the amino acid itself but rather to the optical activity of the isomer of glyceraldehyde from which that amino acid can, in theory, be synthesized (D-glyceraldehyde is dextrorotatory; L-glyceraldehyde is levorotatory). An alternative convention is to use the (S) and (R) designators to specify the absolute configuration. Almost all of the amino acids in proteins are (S) at the α carbon, with cysteine being (R) and glycine non-chiral. Cysteine has its side chain in the same geometric location as the other amino acids, but the R/S terminology is reversed because sulfur has higher atomic number compared to the carboxyl oxygen which gives the side chain a higher priority by the Cahn-Ingold-Prelog sequence rules, whereas the atoms in most other side chains give them lower priority compared to the carboxyl group.Rarely, D-amino acid residues are found in proteins, and are converted from the l-amino acid as a post-translational modification.  Side chains  Amino acids are designated as α- when the amino nitrogen atom is attached to the α-carbon, the carbon atom adjacent to the carboxylate group. There are several ways to classify amino acids; however, they are often grouped by the polarity of their side chains, as depicted in the graphic at the head of this section.  Charged side chains  Five amino acids possess a charge at neutral pH. Often these side chains appear at the surfaces on proteins to enable their solubility in water, and side chains with opposite charges form important electrostatic contacts called salt bridges that maintain structures within a single protein or between interfacing proteins. Many proteins bind metal into their structures specifically, and these interactions are commonly mediated by charged side chains such as aspartate, glutamate and histidine. The two negatively charged amino acids at neutral pH are aspartate (Asp, D) and glutamate (Glu, E). The anionic carboxylate groups behave as Brønsted bases in most circumstances. Enzymes in very low pH environments, like the aspartic protease pepsin in mammalian stomachs, may have catalytic aspartate or glutamate residues that act as Brønsted acids. There are three amino acids with side chains that are cations at neutral pH: arginine (Arg, R), lysine (Lys, K) and histidine (His, H). Arginine has a charged guanidino group and lysine a charged alkyl amino group, and are fully protonated at pH 7. Histidine's imidazole group has a pKa of 6.0, and is only around 10 % protonated at neutral pH. Because histidine is easily found in its basic and conjugate acid forms it often participates in catalytic proton transfers in enzyme reactions.  Polar uncharged side chains  The polar, uncharged amino acids serine (Ser, S), threonine (Thr, T), asparagine (Asn, N) and glutamine (Gln, Q) readily form hydrogen bonds with water and other amino acids. They do not ionize in normal conditions, though a prominent exception being the catalytic serine in serine proteases. This is an example of severe perturbation, and is not characteristic of serine residues in general. Threonine has two chiral centers, not only the L (2S) chiral center at the α-carbon shared by all amino acids apart from achiral glycine, but also (3R) at the β-carbon. The full stereochemical specification is (2S,3R)-L-threonine.  Hydrophobic side chains  Nonpolar amino acid interactions are the primary driving force behind the processes that fold proteins into their functional three dimensional structures. None of these amino acids' side chains ionize easily, and therefore do not have pKas, with the exception of tyrosine (Tyr, Y). The hydroxyl of tyrosine can deprotonate at high pH forming the negatively charged phenolate. Because of this one could place tyrosine into the polar, uncharged amino acid category, but its very low solubility in water matches the characteristics of hydrophobic amino acids well.  Special case side chains  Several side chains are not described well by the charged, polar and hydrophobic categories. Glycine (Gly, G) could be considered a polar amino acid since its small size means that its solubility is largely determined by the amino and carboxylate groups. However, the lack of any side chain provides glycine with a unique flexibility among amino acids with large ramifications to protein folding. Cysteine (Cys, C) can also form hydrogen bonds readily, which would place it in the polar amino acid category, though it can often be found in protein structures forming covalent bonds with other cysteines called disulphide bonds. These bonds influence the folding and stability of proteins, and are essential in the formation of antibodies. Proline (Pro, P) has an alkyl side chain and could be considered hydrophobic, but because the side chain joins back onto the alpha amino group it becomes particularly inflexible when incorporated into proteins. Similar to glycine this influences protein structure in a way unique among amino acids. Selenocysteine (Sec, U) is a rare amino acid not directly encoded by DNA, but is incorporated into proteins via the ribosome. Selenocysteine has a lower redox potential compared to the similar cysteine, and participates in several unique enzymatic reactions. Pyrrolysine (Pyl, O) is another amino acid not encoded in DNA, but synthesized into protein by ribosomes. It is found in archaeal species where it participates in the catalytic activity of several methyltransferases.  β- and γ-amino acids  Amino acids with the structure NH+3−CXY−CXY−CO−2, such as β-alanine, a component of carnosine and a few other peptides, are β-amino acids. Ones with the structure NH+3−CXY−CXY−CXY−CO−2 are γ-amino acids, and so on, where X and Y are two substituents (one of which is normally H).  Zwitterions  In aqueous solution at pH close to neutrality, amino acids exist as zwitterions, i.e. as dipolar ions with both NH+3 and CO−2 in charged states, so the overall structure is NH+3−CHR−CO−2. At physiological pH the so-called ""neutral forms"" −NH2−CHR−CO2H are not present to any measurable degree. Although the two charges in the zwitterion structure add up to zero it is misleading to call a species with a net charge of zero ""uncharged"". In strongly acidic conditions (pH below 3), the carboxylate group becomes protonated and the structure becomes an ammonio carboxylic acid, NH+3−CHR−CO2H. This is relevant for enzymes like pepsin that are active in acidic environments such as the mammalian stomach and lysosomes, but does not significantly apply to intracellular enzymes. In highly basic conditions (pH greater than 10, not normally seen in physiological conditions), the ammonio group is deprotonated to give NH2−CHR−CO−2. Although various definitions of acids and bases are used in chemistry, the only one that is useful for chemistry in aqueous solution is that of Brønsted: an acid is a species that can donate a proton to another species, and a base is one that can accept a proton. This criterion is used to label the groups in the above illustration. The carboxylate side chains of aspartate and glutamate residues are the principal Brønsted bases in proteins. Likewise, lysine, tyrosine and cysteine will typically act as a Brønsted acid. Histidine under these conditions can act both as a Brønsted acid and a base.  Isoelectric point  For amino acids with uncharged side-chains the zwitterion predominates at pH values between the two pKa values, but coexists in equilibrium with small amounts of net negative and net positive ions. At the midpoint between the two pKa values, the trace amount of net negative and trace of net positive ions balance, so that average net charge of all forms present is zero. This pH is known as the isoelectric point pI, so pI  1/2(pKa1 + pKa2). For amino acids with charged side chains, the pKa of the side chain is involved. Thus for aspartate or glutamate with negative side chains, the terminal amino group is essentially entirely in the charged form −NH+3, but this positive charge needs to be balanced by the state with just one C-terminal carboxylate group is negatively charged. This occurs halfway between the two carboxylate pKa values: pI  1/2(pKa1 + pKa(R)), where pKa(R) is the side chain pKa.Similar considerations apply to other amino acids with ionizable side-chains, including not only glutamate (similar to aspartate), but also cysteine, histidine, lysine, tyrosine and arginine with positive side chains. Amino acids have zero mobility in electrophoresis at their isoelectric point, although this behaviour is more usually exploited for peptides and proteins than single amino acids. Zwitterions have minimum solubility at their isoelectric point, and some amino acids (in particular, with nonpolar side chains) can be isolated by precipitation from water by adjusting the pH to the required isoelectric point.  Physicochemical properties  The 20 canonical amino acids can be classified according to their properties. Important factors are charge, hydrophilicity or hydrophobicity, size, and functional groups. These properties influence protein structure and protein–protein interactions. The water-soluble proteins tend to have their hydrophobic residues (Leu, Ile, Val, Phe, and Trp) buried in the middle of the protein, whereas hydrophilic side chains are exposed to the aqueous solvent. (In biochemistry, a residue refers to a specific monomer within the polymeric chain of a polysaccharide, protein or nucleic acid.) The integral membrane proteins tend to have outer rings of exposed hydrophobic amino acids that anchor them in the lipid bilayer. Some peripheral membrane proteins have a patch of hydrophobic amino acids on their surface that sticks to the membrane. In a similar fashion, proteins that have to bind to positively charged molecules have surfaces rich in negatively charged amino acids such as glutamate and aspartate, while proteins binding to negatively charged molecules have surfaces rich in positively charged amino acids like lysine and arginine. For example, lysine and arginine are present in large amounts in the low-complexity regions of nucleic-acid binding proteins. There are various hydrophobicity scales of amino acid residues.Some amino acids have special properties. Cysteine can form covalent disulfide bonds to other cysteine residues. Proline forms a cycle to the polypeptide backbone, and glycine is more flexible than other amino acids. Glycine and proline are strongly present within low complexity regions of both eukaryotic and prokaryotic proteins, whereas the opposite is the case with cysteine, phenylalanine, tryptophan, methionine, valine, leucine, isoleucine, which are highly reactive, or complex, or hydrophobic.Many proteins undergo a range of posttranslational modifications, whereby additional chemical groups are attached to the amino acid residue side chains sometimes producing lipoproteins (that are hydrophobic), or glycoproteins (that are hydrophilic) allowing the protein to attach temporarily to a membrane. For example, a signaling protein can attach and then detach from a cell membrane, because it contains cysteine residues that can have the fatty acid palmitic acid added to them and subsequently removed.  Table of standard amino acid abbreviations and properties  Although one-letter symbols are included in the table, IUPAC–IUBMB recommend that ""Use of the one-letter symbols should be restricted to the comparison of long sequences"". Two additional amino acids are in some species coded for by codons that are usually interpreted as stop codons: In addition to the specific amino acid codes, placeholders are used in cases where chemical or crystallographic analysis of a peptide or protein cannot conclusively determine the identity of a residue. They are also used to summarise conserved protein sequence motifs. The use of single letters to indicate sets of similar residues is similar to the use of abbreviation codes for degenerate bases. Unk is sometimes used instead of Xaa, but is less standard. Ter or  (from termination) is used in notation for mutations in proteins when a stop codon occurs. It correspond to no amino acid at all.In addition, many nonstandard amino acids have a specific code. For example, several peptide drugs, such as Bortezomib and MG132, are artificially synthesized and retain their protecting groups, which have specific codes. Bortezomib is Pyz–Phe–boroLeu, and MG132 is Z–Leu–Leu–Leu–al. To aid in the analysis of protein structure, photo-reactive amino acid analogs are available. These include photoleucine (pLeu) and photomethionine (pMet).  Occurrence and functions in biochemistry  Amino acids which have the amine group attached to the (alpha-) carbon atom next to the carboxyl group have primary importance in living organisms since they participate in protein synthesis. They are known as 2-, alpha-, or α-amino acids (generic formula H2NCHRCOOH in most cases, where R is an organic substituent known as a ""side chain""); often the term ""amino acid"" is used to refer specifically to these. They include the 22 proteinogenic (""protein-building"") amino acids, which combine into peptide chains (""polypeptides"") to form the building blocks of a vast array of proteins. These are all L-stereoisomers (""left-handed"" enantiomers), although a few D-amino acids (""right-handed"") occur in bacterial envelopes, as a neuromodulator (D-serine), and in some antibiotics.Many proteinogenic and non-proteinogenic amino acids have biological functions. For example, in the human brain, glutamate (standard glutamic acid) and gamma-aminobutyric acid (""GABA"", nonstandard gamma-amino acid) are, respectively, the main excitatory and inhibitory neurotransmitters. Hydroxyproline, a major component of the connective tissue collagen, is synthesised from proline. Glycine is a biosynthetic precursor to porphyrins used in red blood cells. Carnitine is used in lipid transport. Nine proteinogenic amino acids are called ""essential"" for humans because they cannot be produced from other compounds by the human body and so must be taken in as food. Others may be conditionally essential for certain ages or medical conditions. Essential amino acids may also vary from species to species. Because of their biological significance, amino acids are important in nutrition and are commonly used in nutritional supplements, fertilizers, feed, and food technology. Industrial uses include the production of drugs, biodegradable plastics, and chiral catalysts.  Proteinogenic amino acids  Amino acids are the precursors to proteins. They join by condensation reactions to form short polymer chains called peptides or longer chains called either polypeptides or proteins. These chains are linear and unbranched, with each amino acid residue within the chain attached to two neighboring amino acids. In Nature, the process of making proteins encoded by DNA/RNA genetic material is called translation and involves the step-by-step addition of amino acids to a growing protein chain by a ribozyme that is called a ribosome. The order in which the amino acids are added is read through the genetic code from an mRNA template, which is an RNA copy of one of the organism's genes. Twenty-two amino acids are naturally incorporated into polypeptides and are called proteinogenic or natural amino acids. Of these, 20 are encoded by the universal genetic code. The remaining 2, selenocysteine and pyrrolysine, are incorporated into proteins by unique synthetic mechanisms. Selenocysteine is incorporated when the mRNA being translated includes a SECIS element, which causes the UGA codon to encode selenocysteine instead of a stop codon. Pyrrolysine is used by some methanogenic archaea in enzymes that they use to produce methane. It is coded for with the codon UAG, which is normally a stop codon in other organisms. This UAG codon is followed by a PYLIS downstream sequence.Several independent evolutionary studies have suggested that Gly, Ala, Asp, Val, Ser, Pro, Glu, Leu, Thr may belong to a group of amino acids that constituted the early genetic code, whereas Cys, Met, Tyr, Trp, His, Phe may belong to a group of amino acids that constituted later additions of the genetic code.  Standard vs nonstandard amino acids  The 20 amino acids that are encoded directly by the codons of the universal genetic code are called standard or canonical amino acids. A modified form of methionine (N-formylmethionine) is often incorporated in place of methionine as the initial amino acid of proteins in bacteria, mitochondria and chloroplasts. Other amino acids are called nonstandard or non-canonical. Most of the nonstandard amino acids are also non-proteinogenic (i.e. they cannot be incorporated into proteins during translation), but two of them are proteinogenic, as they can be incorporated translationally into proteins by exploiting information not encoded in the universal genetic code. The two nonstandard proteinogenic amino acids are selenocysteine (present in many non-eukaryotes as well as most eukaryotes, but not coded directly by DNA) and pyrrolysine (found only in some archaea and at least one bacterium). The incorporation of these nonstandard amino acids is rare. For example, 25 human proteins include selenocysteine in their primary structure, and the structurally characterized enzymes (selenoenzymes) employ selenocysteine as the catalytic moiety in their active sites. Pyrrolysine and selenocysteine are encoded via variant codons. For example, selenocysteine is encoded by stop codon and SECIS element.N-formylmethionine (which is often the initial amino acid of proteins in bacteria, mitochondria, and chloroplasts) is generally considered as a form of methionine rather than as a separate proteinogenic amino acid. Codon–tRNA combinations not found in nature can also be used to ""expand"" the genetic code and form novel proteins known as alloproteins incorporating non-proteinogenic amino acids.  Non-proteinogenic amino acids  Aside from the 22 proteinogenic amino acids, many non-proteinogenic amino acids are known. Those either are not found in proteins (for example carnitine, GABA, levothyroxine) or are not produced directly and in isolation by standard cellular machinery (for example, hydroxyproline and selenomethionine). Non-proteinogenic amino acids that are found in proteins are formed by post-translational modification, which is modification after translation during protein synthesis. These modifications are often essential for the function or regulation of a protein. For example, the carboxylation of glutamate allows for better binding of calcium cations, and collagen contains hydroxyproline, generated by hydroxylation of proline. Another example is the formation of hypusine in the translation initiation factor EIF5A, through modification of a lysine residue. Such modifications can also determine the localization of the protein, e.g., the addition of long hydrophobic groups can cause a protein to bind to a phospholipid membrane.Some non-proteinogenic amino acids are not found in proteins. Examples include 2-aminoisobutyric acid and the neurotransmitter gamma-aminobutyric acid. Non-proteinogenic amino acids often occur as intermediates in the metabolic pathways for standard amino acids – for example, ornithine and citrulline occur in the urea cycle, part of amino acid catabolism (see below). A rare exception to the dominance of α-amino acids in biology is the β-amino acid beta alanine (3-aminopropanoic acid), which is used in plants and microorganisms in the synthesis of pantothenic acid (vitamin B5), a component of coenzyme A.  In human nutrition  When taken up into the human body from the diet, the 20 standard amino acids either are used to synthesize proteins, other biomolecules, or are oxidized to urea and carbon dioxide as a source of energy. The oxidation pathway starts with the removal of the amino group by a transaminase; the amino group is then fed into the urea cycle. The other product of transamidation is a keto acid that enters the citric acid cycle. Glucogenic amino acids can also be converted into glucose, through gluconeogenesis. Of the 20 standard amino acids, nine (His, Ile, Leu, Lys, Met, Phe, Thr, Trp and Val) are called essential amino acids because the human body cannot synthesize them from other compounds at the level needed for normal growth, so they must be obtained from food. In addition, cysteine, tyrosine, and arginine are considered semiessential amino acids, and taurine a semiessential aminosulfonic acid in children. The metabolic pathways that synthesize these monomers are not fully developed. The amounts required also depend on the age and health of the individual, so it is hard to make general statements about the dietary requirement for some amino acids. Dietary exposure to the nonstandard amino acid BMAA has been linked to human neurodegenerative diseases, including ALS.  Non-protein functions  In humans, non-protein amino acids also have important roles as metabolic intermediates, such as in the biosynthesis of the neurotransmitter gamma-aminobutyric acid (GABA). Many amino acids are used to synthesize other molecules, for example: Tryptophan is a precursor of the neurotransmitter serotonin. Tyrosine (and its precursor phenylalanine) are precursors of the catecholamine neurotransmitters dopamine, epinephrine and norepinephrine and various trace amines. Phenylalanine is a precursor of phenethylamine and tyrosine in humans. In plants, it is a precursor of various phenylpropanoids, which are important in plant metabolism. Glycine is a precursor of porphyrins such as heme. Arginine is a precursor of nitric oxide. Ornithine and S-adenosylmethionine are precursors of polyamines. Aspartate, glycine, and glutamine are precursors of nucleotides. However, not all of the functions of other abundant nonstandard amino acids are known.Some nonstandard amino acids are used as defenses against herbivores in plants. For example, canavanine is an analogue of arginine that is found in many legumes, and in particularly large amounts in Canavalia gladiata (sword bean). This amino acid protects the plants from predators such as insects and can cause illness in people if some types of legumes are eaten without processing. The non-protein amino acid mimosine is found in other species of legume, in particular Leucaena leucocephala. This compound is an analogue of tyrosine and can poison animals that graze on these plants.  Uses in industry   Fertilizer  The chelating ability of amino acids is sometimes used in fertilizers to facilitate the delivery of minerals to plants in order to correct mineral deficiencies, such as iron chlorosis. These fertilizers are also used to prevent deficiencies from occurring and to improve the overall health of the plants.  Animal feed  Amino acids are sometimes added to animal feed because some of the components of these feeds, such as soybeans, have low levels of some of the essential amino acids, especially of lysine, methionine, threonine, and tryptophan. Likewise amino acids are used to chelate metal cations in order to improve the absorption of minerals from feed supplements.  Food  The food industry is a major consumer of amino acids, especially glutamic acid, which is used as a flavor enhancer, and aspartame (aspartylphenylalanine 1-methyl ester), which is used as an artificial sweetener. Amino acids are sometimes added to food by manufacturers to alleviate symptoms of mineral deficiencies, such as anemia, by improving mineral absorption and reducing negative side effects from inorganic mineral supplementation.  Pharmaceuticals and cosmetics  Similarly, some amino acids derivatives are used in pharmaceutical industry. They include 5-HTP (5-hydroxytryptophan) used for experimental treatment of depression, L-DOPA (L-dihydroxyphenylalanine) for Parkinson's treatment, and eflornithine drug that inhibits ornithine decarboxylase and used in the treatment of sleeping sickness. Amino acids are used in the synthesis of some cosmetics.  Expanded genetic code  Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.  Nullomers  Nullomers are codons that in theory code for an amino acid, however, in nature there is a selective bias against using this codon in favor of another, for example bacteria prefer to use CGA instead of AGA to code for arginine. This creates some sequences that do not appear in the genome. This characteristic can be taken advantage of and used to create new selective cancer-fighting drugs and to prevent cross-contamination of DNA samples from crime-scene investigations.  Chemical building blocks  Amino acids are important as low-cost feedstocks. These compounds are used in chiral pool synthesis as enantiomerically pure building blocks.Amino acids have been investigated as precursors chiral catalysts, such as for asymmetric hydrogenation reactions, although no commercial applications exist.  Biodegradable plastics  Amino acids have been considered as components of biodegradable polymers, which have applications as environmentally friendly packaging and in medicine in drug delivery and the construction of prosthetic implants. An interesting example of such materials is polyaspartate, a water-soluble biodegradable polymer that may have applications in disposable diapers and agriculture. Due to its solubility and ability to chelate metal ions, polyaspartate is also being used as a biodegradable antiscaling agent and a corrosion inhibitor. In addition, the aromatic amino acid tyrosine has been considered as a possible replacement for phenols such as bisphenol A in the manufacture of polycarbonates.  Synthesis   Chemical synthesis  The commercial production of amino acids usually relies on mutant bacteria that overproduce individual amino acids using glucose as a carbon source. Some amino acids are produced by enzymatic conversions of synthetic intermediates. 2-Aminothiazoline-4-carboxylic acid is an intermediate in one industrial synthesis of L-cysteine for example. Aspartic acid is produced by the addition of ammonia to fumarate using a lyase.  Biosynthesis  In plants, nitrogen is first assimilated into organic compounds in the form of glutamate, formed from alpha-ketoglutarate and ammonia in the mitochondrion. For other amino acids, plants use transaminases to move the amino group from glutamate to another alpha-keto acid. For example, aspartate aminotransferase converts glutamate and oxaloacetate to alpha-ketoglutarate and aspartate. Other organisms use transaminases for amino acid synthesis, too. Nonstandard amino acids are usually formed through modifications to standard amino acids. For example, homocysteine is formed through the transsulfuration pathway or by the demethylation of methionine via the intermediate metabolite S-adenosylmethionine, while hydroxyproline is made by a post translational modification of proline.Microorganisms and plants synthesize many uncommon amino acids. For example, some microbes make 2-aminoisobutyric acid and lanthionine, which is a sulfide-bridged derivative of alanine. Both of these amino acids are found in peptidic lantibiotics such as alamethicin. However, in plants, 1-aminocyclopropane-1-carboxylic acid is a small disubstituted cyclic amino acid that is an intermediate in the production of the plant hormone ethylene.  Primordial synthesis  The formation of amino acids and peptides are assumed to precede and perhaps induce the emergence of life on earth. Amino acids can form from simple precursors under various conditions. Surface-based chemical metabolism of amino acids and very small compounds may have led to the build-up of amino acids, coenzymes and phosphate-based small carbon molecules. Amino acids and similar building blocks could have been elaborated into proto-peptides, with peptides being considered key players in the origin of life.In the famous Urey-Miller experiment, the passage of an electric arc through a mixture of methane, hydrogen, and ammonia produces a large number of amino acids. Since then, scientists have discovered a range of ways and components by which the potentially prebiotic formation and chemical evolution of peptides may have occurred, such as condensing agents, the design of self-replicating peptides and a number of non-enzymatic mechanisms by which amino acids could have emerged and elaborated into peptides. Several hypotheses invoke the Strecker synthesis whereby hydrogen cyanide, simple aldehydes, ammonia, and water produce amino acids.According to a review, amino acids, and even peptides, ""turn up fairly regularly in the various experimental broths that have been allowed to be cooked from simple chemicals. This is because nucleotides are far more difficult to synthesize chemically than amino acids."" For a chronological order, it suggests that there must have been a 'protein world' or at least a 'polypeptide world', possibly later followed by the 'RNA world' and the 'DNA world'. Codon–amino acids mappings may be the biological information system at the primordial origin of life on Earth. While amino acids and consequently simple peptides must have formed under different experimentally probed geochemical scenarios, the transition from an abiotic world to the first life forms is to a large extent still unresolved.  Reactions  Amino acids undergo the reactions expected of the constituent functional groups.  Peptide bond formation  As both the amine and carboxylic acid groups of amino acids can react to form amide bonds, one amino acid molecule can react with another and become joined through an amide linkage. This polymerization of amino acids is what creates proteins. This condensation reaction yields the newly formed peptide bond and a molecule of water. In cells, this reaction does not occur directly; instead, the amino acid is first activated by attachment to a transfer RNA molecule through an ester bond. This aminoacyl-tRNA is produced in an ATP-dependent reaction carried out by an aminoacyl tRNA synthetase. This aminoacyl-tRNA is then a substrate for the ribosome, which catalyzes the attack of the amino group of the elongating protein chain on the ester bond. As a result of this mechanism, all proteins made by ribosomes are synthesized starting at their N-terminus and moving toward their C-terminus. However, not all peptide bonds are formed in this way. In a few cases, peptides are synthesized by specific enzymes. For example, the tripeptide glutathione is an essential part of the defenses of cells against oxidative stress. This peptide is synthesized in two steps from free amino acids. In the first step, gamma-glutamylcysteine synthetase condenses cysteine and glutamate through a peptide bond formed between the side chain carboxyl of the glutamate (the gamma carbon of this side chain) and the amino group of the cysteine. This dipeptide is then condensed with glycine by glutathione synthetase to form glutathione.In chemistry, peptides are synthesized by a variety of reactions. One of the most-used in solid-phase peptide synthesis uses the aromatic oxime derivatives of amino acids as activated units. These are added in sequence onto the growing peptide chain, which is attached to a solid resin support. Libraries of peptides are used in drug discovery through high-throughput screening.The combination of functional groups allow amino acids to be effective polydentate ligands for metal–amino acid chelates. The multiple side chains of amino acids can also undergo chemical reactions.  Catabolism  Degradation of an amino acid often involves deamination by moving its amino group to alpha-ketoglutarate, forming glutamate. This process involves transaminases, often the same as those used in amination during synthesis. In many vertebrates, the amino group is then removed through the urea cycle and is excreted in the form of urea. However, amino acid degradation can produce uric acid or ammonia instead. For example, serine dehydratase converts serine to pyruvate and ammonia. After removal of one or more amino groups, the remainder of the molecule can sometimes be used to synthesize new amino acids, or it can be used for energy by entering glycolysis or the citric acid cycle, as detailed in image at right.  Complexation  Amino acids are bidentate ligands, forming transition metal amino acid complexes.  Chemical analysis  The total nitrogen content of organic matter is mainly formed by the amino groups in proteins. The Total Kjeldahl Nitrogen (TKN) is a measure of nitrogen widely used in the analysis of (waste) water, soil, food, feed and organic matter in general. As the name suggests, the Kjeldahl method is applied. More sensitive methods are available.  See also   Notes   References   Further reading   External links  Media related to Amino acid at Wikimedia Commons","Amino acids are the building blocks of proteins. In eukaryotes, there are 20 ""standard"" amino acids out of which almost all proteins are made. In biochemistry, an amino acid is any molecule that has both amine (NH2+R) and carboxyl (CO) functional groups. In biochemistry, this term refers to alpha-amino acids with the general formula H2NCHRCOOH, where R is one of many side groups (see diagram).  There are hundreds  Across all forms of life, about 500 amino acids are known. The most important thing that amino acids do is to be part of proteins, which are long chains of amino acids. Every protein has its own sequence of amino acids, and that sequence makes the protein take different shapes, and have different functions. Amino acids are like the alphabet for proteins; even though you only have a few letters, if you connect them, you can make many different sentences. Nine of the 20 standard amino acids are ""essential"" amino acids for humans. They cannot be built (synthesised) from other compounds by the human body. They must be taken in as food. Others may be essential for some ages or medical conditions. Essential amino acids may also differ between species. Herbivores have to get their essential amino acids from their diet, which for some is almost entirely grass. Ruminants such as cows get some amino acids via microbes in the first two stomach chambers.  Structure  An amino acid is an organic chemical. It consists of an α-carbon atom that is covalently bonded to four groups. a hydrogen atom an amino group (-NH2) a carboxyl group (-COOH) a variable R groupEvery amino acid has at least one amino group (-NH2) and one carboxyl group (-COOH), except proline.  Gene expression and biochemistry  These are the proteinogenic amino acids, which are the building blocks for proteins. They are produced by cellular machinery coded for in the genetic code of any organism.  UAG is normally the amber stop codon, but encodes pyrrolysine if a PYLIS element is present. UGA is normally the opal (or umber) stop codon, but encodes selenocysteine if a SECIS element is present.† The stop codon is not an amino acid, but is included for completeness.†† UAG and UGA do not always act as stop codons (see above).‡ An essential amino acid cannot be synthesized in humans. It must be supplied in the diet. Conditionally essential amino acids are not normally required in the diet, but must be supplied to populations which do not make enough of it. To these α-amino acids further in biosynthesis processes appearing non-essential ones are structurally (here by using SMILES notation) related: OC(O)C(N)– ├ H .. 🅖 Glycine ├ C .. 🅐 Alanine │├ C .. 2-Aminobutanoic acid ││├ C .. Norvaline │││├ –2H .. 🅟 Proline (Dehydronorvaline) │││├ C .. Norleucine ││││└ N .. 🅚 Lysine ││││ └ C(O)C1NCCC1C .. 🅞 Pyrrolysine │││└ NC(N)N .. 🅡 Arginine ││├ C(O)N .. 🅠 Glutamine ││├ C(O)O .. 🅔 Glutamic acid ││├ O .. Homoserine ││└ S .. Homocysteine ││ └ C .. 🅜 Methionine │├ C(C)C .. 🅛 Leucine │├ C(O)N .. 🅝 Asparagine │├ C(O)O .. 🅓 Aspartic acid │├ C1CNCN1 .. 🅗 Histidine │├ c1ccccc1 .. 🅕 Phenylalanine │├ c1ccc(O)cc1 .. 🅨 Tyrosine │├ C1CNc2ccccc12 .. 🅦 Tryptophan │├ C1CNc2ccc(O)cc12 .. Oxitriptan │├ c(cc1I)cc(I)c1-O-c2cc(I)c(O)c(I)c2 .. Thyroxine │├ O .. 🅢 Serine │├ S .. 🅒 Cysteine │└ [SeH] .. 🅤 Selenocysteine ├ C(C)C .. 🅥 Valine ├ C(C)O .. 🅣 Threonine └ C(C)CC .. 🅘 Isoleucine  References "
"Organic chemistry is a subdiscipline within chemistry involving the scientific study of the structure, properties, and reactions of organic compounds and organic materials, i.e., matter in its various forms that contain carbon atoms. Study of structure determines their structural formula. Study of properties includes physical and chemical properties, and evaluation of chemical reactivity to understand their behavior. The study of organic reactions includes the chemical synthesis of natural products, drugs, and polymers, and study of individual organic molecules in the laboratory and via theoretical (in silico) study. The range of chemicals studied in organic chemistry includes hydrocarbons (compounds containing only carbon and hydrogen) as well as compounds based on carbon, but also containing other elements, especially oxygen, nitrogen, sulfur, phosphorus (included in many biochemicals) and the halogens. Organometallic chemistry is the study of compounds containing carbon–metal bonds. In addition, contemporary research focuses on organic chemistry involving other organometallics including the lanthanides, but especially the transition metals zinc, copper, palladium, nickel, cobalt, titanium and chromium. Organic compounds form the basis of all earthly life and constitute the majority of known chemicals. The bonding patterns of carbon, with its valence of four—formal single, double, and triple bonds, plus structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They form the basis of, or are constituents of, many commercial products including pharmaceuticals; petrochemicals and agrichemicals, and products made from them including lubricants, solvents; plastics; fuels and explosives. The study of organic chemistry overlaps organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, and materials science.  History  Before the 18th century, chemists generally believed that compounds obtained from living organisms were endowed with a vital force that distinguished them from inorganic compounds. According to the concept of vitalism (vital force theory), organic matter was endowed with a ""vital force"". During the first half of the nineteenth century, some of the first systematic studies of organic compounds were reported. Around 1816 Michel Chevreul started a study of soaps made from various fats and alkalis. He separated the acids that, in combination with the alkali, produced the soap. Since these were all individual compounds, he demonstrated that it was possible to make a chemical change in various fats (which traditionally come from organic sources), producing new compounds, without ""vital force"". In 1828 Friedrich Wöhler produced the organic chemical urea (carbamide), a constituent of urine, from inorganic starting materials (the salts potassium cyanate and ammonium sulfate), in what is now called the Wöhler synthesis. Although Wöhler himself was cautious about claiming he had disproved vitalism, this was the first time a substance thought to be organic was synthesized in the laboratory without biological (organic) starting materials. The event is now generally accepted as indeed disproving the doctrine of vitalism.In 1856 William Henry Perkin, while trying to manufacture quinine accidentally produced the organic dye now known as Perkin's mauve. His discovery, made widely known through its financial success, greatly increased interest in organic chemistry.A crucial breakthrough for organic chemistry was the concept of chemical structure, developed independently in 1858 by both Friedrich August Kekulé and Archibald Scott Couper. Both researchers suggested that tetravalent carbon atoms could link to each other to form a carbon lattice, and that the detailed patterns of atomic bonding could be discerned by skillful interpretations of appropriate chemical reactions.The era of the pharmaceutical industry began in the last decade of the 19th century when the German company, Bayer, first manufactured acetylsalicylic acid—more commonly known as aspirin. By 1910 Paul Ehrlich and his laboratory group began developing arsenic-based arsphenamine, (Salvarsan), as the first effective medicinal treatment of syphilis, and thereby initiated the medical practice of chemotherapy. Ehrlich popularized the concepts of ""magic bullet"" drugs and of systematically improving drug therapies. His laboratory made decisive contributions to developing antiserum for diphtheria and standardizing therapeutic serums. Early examples of organic reactions and applications were often found because of a combination of luck and preparation for unexpected observations. The latter half of the 19th century however witnessed systematic studies of organic compounds. The development of synthetic indigo is illustrative. The production of indigo from plant sources dropped from 19,000 tons in 1897 to 1,000 tons by 1914 thanks to the synthetic methods developed by Adolf von Baeyer. In 2002, 17,000 tons of synthetic indigo were produced from petrochemicals.In the early part of the 20th century, polymers and enzymes were shown to be large organic molecules, and petroleum was shown to be of biological origin. The multiple-step synthesis of complex organic compounds is called total synthesis. Total synthesis of complex natural compounds increased in complexity to glucose and terpineol. For example, cholesterol-related compounds have opened ways to synthesize complex human hormones and their modified derivatives. Since the start of the 20th century, complexity of total syntheses has been increased to include molecules of high complexity such as lysergic acid and vitamin B12. The discovery of petroleum and the development of the petrochemical industry spurred the development of organic chemistry. Converting individual petroleum compounds into types of compounds by various chemical processes led to organic reactions enabling a broad range of industrial and commercial products including, among (many) others: plastics, synthetic rubber, organic adhesives, and various property-modifying petroleum additives and catalysts. The majority of chemical compounds occurring in biological organisms are carbon compounds, so the association between organic chemistry and biochemistry is so close that biochemistry might be regarded as in essence a branch of organic chemistry. Although the history of biochemistry might be taken to span some four centuries, fundamental understanding of the field only began to develop in the late 19th century and the actual term biochemistry was coined around the start of 20th century. Research in the field increased throughout the twentieth century, without any indication of slackening in the rate of increase, as may be verified by inspection of abstraction and indexing services such as BIOSIS Previews and Biological Abstracts, which began in the 1920s as a single annual volume, but has grown so drastically that by the end of the 20th century it was only available to the everyday user as an online electronic database.  Characterization  Since organic compounds often exist as mixtures, a variety of techniques have also been developed to assess purity; chromatography techniques are especially important for this application, and include HPLC and gas chromatography. Traditional methods of separation include distillation, crystallization, evaporation, magnetic separation and solvent extraction. Organic compounds were traditionally characterized by a variety of chemical tests, called ""wet methods"", but such tests have been largely displaced by spectroscopic or other computer-intensive methods of analysis. Listed in approximate order of utility, the chief analytical methods are: Nuclear magnetic resonance (NMR) spectroscopy is the most commonly used technique, often permitting the complete assignment of atom connectivity and even stereochemistry using correlation spectroscopy. The principal constituent atoms of organic chemistry – hydrogen and carbon – exist naturally with NMR-responsive isotopes, respectively 1H and 13C. Elemental analysis: A destructive method used to determine the elemental composition of a molecule. See also mass spectrometry, below. Mass spectrometry indicates the molecular weight of a compound and, from the fragmentation patterns, its structure. High-resolution mass spectrometry can usually identify the exact formula of a compound and is used in place of elemental analysis. In former times, mass spectrometry was restricted to neutral molecules exhibiting some volatility, but advanced ionization techniques allow one to obtain the ""mass spec"" of virtually any organic compound. Crystallography can be useful for determining molecular geometry when a single crystal of the material is available. Highly efficient hardware and software allows a structure to be determined within hours of obtaining a suitable crystal.Traditional spectroscopic methods such as infrared spectroscopy, optical rotation, and UV/VIS spectroscopy provide relatively nonspecific structural information but remain in use for specific applications. Refractive index and density can also be important for substance identification.  Properties  The physical properties of organic compounds typically of interest include both quantitative and qualitative features. Quantitative information includes a melting point, boiling point, solubility, and index of refraction. Qualitative properties include odor, consistency, and color.  Melting and boiling properties  Organic compounds typically melt and many boil. In contrast, while inorganic materials generally can be melted, many do not boil, and instead tend to degrade. In earlier times, the melting point (m.p.) and boiling point (b.p.) provided crucial information on the purity and identity of organic compounds. The melting and boiling points correlate with the polarity of the molecules and their molecular weight. Some organic compounds, especially symmetrical ones, sublime. A well-known example of a sublimable organic compound is para-dichlorobenzene, the odiferous constituent of modern mothballs. Organic compounds are usually not very stable at temperatures above 300 °C, although some exceptions exist.  Solubility  Neutral organic compounds tend to be hydrophobic; that is, they are less soluble in water than in organic solvents. Exceptions include organic compounds that contain ionizable groups as well as low molecular weight alcohols, amines, and carboxylic acids where hydrogen bonding occurs. Otherwise, organic compounds tend to dissolve in organic solvents. Solubility varies widely with the organic solute and with the organic solvent.  Solid state properties  Various specialized properties of molecular crystals and organic polymers with conjugated systems are of interest depending on applications, e.g. thermo-mechanical and electro-mechanical such as piezoelectricity, electrical conductivity (see conductive polymers and organic semiconductors), and electro-optical (e.g. non-linear optics) properties. For historical reasons, such properties are mainly the subjects of the areas of polymer science and materials science.  Nomenclature  The names of organic compounds are either systematic, following logically from a set of rules, or nonsystematic, following various traditions. Systematic nomenclature is stipulated by specifications from IUPAC. Systematic nomenclature starts with the name for a parent structure within the molecule of interest. This parent name is then modified by prefixes, suffixes, and numbers to unambiguously convey the structure. Given that millions of organic compounds are known, rigorous use of systematic names can be cumbersome. Thus, IUPAC recommendations are more closely followed for simple compounds, but not complex molecules. To use the systematic naming, one must know the structures and names of the parent structures. Parent structures include unsubstituted hydrocarbons, heterocycles, and mono functionalized derivatives thereof. Nonsystematic nomenclature is simpler and unambiguous, at least to organic chemists. Nonsystematic names do not indicate the structure of the compound. They are common for complex molecules, which include most natural products. Thus, the informally named lysergic acid diethylamide is systematically named (6aR,9R)-N,N-diethyl-7-methyl-4,6,6a,7,8,9-hexahydroindolo-[4,3-fg] quinoline-9-carboxamide. With the increased use of computing, other naming methods have evolved that are intended to be interpreted by machines. Two popular formats are SMILES and InChI.  Structural drawings  Organic molecules are described more commonly by drawings or structural formulas, combinations of drawings and chemical symbols. The line-angle formula is simple and unambiguous. In this system, the endpoints and intersections of each line represent one carbon, and hydrogen atoms can either be notated explicitly or assumed to be present as implied by tetravalent carbon.  History  By 1880 an explosion in the number of chemical compounds being discovered occurred assisted by new synthetic and analytical techniques. Grignard described the situation as ""chaos le plus complet"" (complete chaos) due to the lack of convention it was possible to have multiple names for the same compound. This led to the creation of the Geneva rules in 1892.  Classification of organic compounds   Functional groups  The concept of functional groups is central in organic chemistry, both as a means to classify structures and for predicting properties. A functional group is a molecular module, and the reactivity of that functional group is assumed, within limits, to be the same in a variety of molecules. Functional groups can have a decisive influence on the chemical and physical properties of organic compounds. Molecules are classified based on their functional groups. Alcohols, for example, all have the subunit C-O-H. All alcohols tend to be somewhat hydrophilic, usually form esters, and usually can be converted to the corresponding halides. Most functional groups feature heteroatoms (atoms other than C and H). Organic compounds are classified according to functional groups, alcohols, carboxylic acids, amines, etc. Functional groups make the molecule more acidic or basic due to their electronic influence on surrounding parts of the molecule. As the pKa (aka basicity) of the molecular addition/functional group increases, there is a corresponding dipole, when measured, increases in strength. A dipole directed towards the functional group (higher pKa therefore basic nature of group) points towards it and decreases in strength with increasing distance. Dipole distance (measured in Angstroms) and steric hindrance towards the functional group have an intermolecular and intramolecular effect on the surrounding environment and pH level. Different functional groups have different pKa values and bond strengths (single, double, triple) leading to increased electrophilicity with lower pKa and increased nucleophile strength with higher pKa. More basic/nucleophilic functional groups desire to attack an electrophilic functional group with a lower pKa on another molecule (intermolecular) or within the same molecule (intramolecular). Any group with a net acidic pKa that gets within range, such as an acyl or carbonyl group is fair game. Since the likelihood of being attacked decreases with an increase in pKa, acyl chloride components with the lowest measured pKa values are most likely to be attacked, followed by carboxylic acids (pKa 4), thiols (13), malonates (13), alcohols (17), aldehydes (20), nitriles (25), esters (25), then amines (35). Amines are very basic, and are great nucleophiles/attackers.  Aliphatic compounds  The aliphatic hydrocarbons are subdivided into three groups of homologous series according to their state of saturation: alkanes (paraffins): aliphatic hydrocarbons without any double or triple bonds, i.e. just C-C, C-H single bonds alkenes (olefins): aliphatic hydrocarbons that contain one or more double bonds, i.e. di-olefins (dienes) or poly-olefins. alkynes (acetylenes): aliphatic hydrocarbons which have one or more triple bonds.The rest of the group is classified according to the functional groups present. Such compounds can be ""straight-chain"", branched-chain or cyclic. The degree of branching affects characteristics, such as the octane number or cetane number in petroleum chemistry. Both saturated (alicyclic) compounds and unsaturated compounds exist as cyclic derivatives. The most stable rings contain five or six carbon atoms, but large rings (macrocycles) and smaller rings are common. The smallest cycloalkane family is the three-membered cyclopropane ((CH2)3). Saturated cyclic compounds contain single bonds only, whereas aromatic rings have an alternating (or conjugated) double bond. Cycloalkanes do not contain multiple bonds, whereas the cycloalkenes and the cycloalkynes do.  Aromatic compounds  Aromatic hydrocarbons contain conjugated double bonds. This means that every carbon atom in the ring is sp2 hybridized, allowing for added stability. The most important example is benzene, the structure of which was formulated by Kekulé who first proposed the delocalization or resonance principle for explaining its structure. For ""conventional"" cyclic compounds, aromaticity is conferred by the presence of 4n + 2 delocalized pi electrons, where n is an integer. Particular instability (antiaromaticity) is conferred by the presence of 4n conjugated pi electrons.  Heterocyclic compounds  The characteristics of the cyclic hydrocarbons are again altered if heteroatoms are present, which can exist as either substituents attached externally to the ring (exocyclic) or as a member of the ring itself (endocyclic). In the case of the latter, the ring is termed a heterocycle. Pyridine and furan are examples of aromatic heterocycles while piperidine and tetrahydrofuran are the corresponding alicyclic heterocycles. The heteroatom of heterocyclic molecules is generally oxygen, sulfur, or nitrogen, with the latter being particularly common in biochemical systems. Heterocycles are commonly found in a wide range of products including aniline dyes and medicines. Additionally, they are prevalent in a wide range of biochemical compounds such as alkaloids, vitamins, steroids, and nucleic acids (e.g. DNA, RNA). Rings can fuse with other rings on an edge to give polycyclic compounds. The purine nucleoside bases are notable polycyclic aromatic heterocycles. Rings can also fuse on a ""corner"" such that one atom (almost always carbon) has two bonds going to one ring and two to another. Such compounds are termed spiro and are important in several natural products.  Polymers  One important property of carbon is that it readily forms chains, or networks, that are linked by carbon-carbon (carbon-to-carbon) bonds. The linking process is called polymerization, while the chains, or networks, are called polymers. The source compound is called a monomer. Two main groups of polymers exist synthetic polymers and biopolymers. Synthetic polymers are artificially manufactured, and are commonly referred to as industrial polymers. Biopolymers occur within a respectfully natural environment, or without human intervention.  Biomolecules  Biomolecular chemistry is a major category within organic chemistry which is frequently studied by biochemists. Many complex multi-functional group molecules are important in living organisms. Some are long-chain biopolymers, and these include peptides, DNA, RNA and the polysaccharides such as starches in animals and celluloses in plants. The other main classes are amino acids (monomer building blocks of peptides and proteins), carbohydrates (which includes the polysaccharides), the nucleic acids (which include DNA and RNA as polymers), and the lipids. Besides, animal biochemistry contains many small molecule intermediates which assist in energy production through the Krebs cycle, and produces isoprene, the most common hydrocarbon in animals. Isoprenes in animals form the important steroid structural (cholesterol) and steroid hormone compounds; and in plants form terpenes, terpenoids, some alkaloids, and a class of hydrocarbons called biopolymer polyisoprenoids present in the latex of various species of plants, which is the basis for making rubber. See also: peptide synthesis, oligonucleotide synthesis and carbohydrate synthesis.  Small molecules  In pharmacology, an important group of organic compounds is small molecules, also referred to as 'small organic compounds'. In this context, a small molecule is a small organic compound that is biologically active but is not a polymer. In practice, small molecules have a molar mass less than approximately 1000 g/mol.  Fullerenes  Fullerenes and carbon nanotubes, carbon compounds with spheroidal and tubular structures, have stimulated much research into the related field of materials science. The first fullerene was discovered in 1985 by Sir Harold W. Kroto of the United Kingdom and by Richard E. Smalley and Robert F. Curl, Jr., of the United States. Using a laser to vaporize graphite rods in an atmosphere of helium gas, these chemists and their assistants obtained cagelike molecules composed of 60 carbon atoms (C60) joined by single and double bonds to form a hollow sphere with 12 pentagonal and 20 hexagonal faces—a design that resembles a football, or soccer ball. In 1996 the trio was awarded the Nobel Prize for their pioneering efforts. The C60 molecule was named buckminsterfullerene (or, more simply, the buckyball) after the American architect R. Buckminster Fuller, whose geodesic dome is constructed on the same structural principles.  Others  Organic compounds containing bonds of carbon to nitrogen, oxygen and the halogens are not normally grouped separately. Others are sometimes put into major groups within organic chemistry and discussed under titles such as organosulfur chemistry, organometallic chemistry, organophosphorus chemistry and organosilicon chemistry.  Organic reactions  Organic reactions are chemical reactions involving organic compounds. Many of these reactions are associated with functional groups. The general theory of these reactions involves careful analysis of such properties as the electron affinity of key atoms, bond strengths and steric hindrance. These factors can determine the relative stability of short-lived reactive intermediates, which usually directly determine the path of the reaction. The basic reaction types are: addition reactions, elimination reactions, substitution reactions, pericyclic reactions, rearrangement reactions and redox reactions. An example of a common reaction is a substitution reaction written as: Nu − + C − X ⟶ C − Nu + X − {displaystyle {ce {Nu- + C-X -> C-Nu + X-}}} where X is some functional group and Nu is a nucleophile. The number of possible organic reactions is infinite. However, certain general patterns are observed that can be used to describe many common or useful reactions. Each reaction has a stepwise reaction mechanism that explains how it happens in sequence—although the detailed description of steps is not always clear from a list of reactants alone. The stepwise course of any given reaction mechanism can be represented using arrow pushing techniques in which curved arrows are used to track the movement of electrons as starting materials transition through intermediates to final products.  Organic synthesis  Synthetic organic chemistry is an applied science as it borders engineering, the ""design, analysis, and/or construction of works for practical purposes"". Organic synthesis of a novel compound is a problem-solving task, where a synthesis is designed for a target molecule by selecting optimal reactions from optimal starting materials. Complex compounds can have tens of reaction steps that sequentially build the desired molecule. The synthesis proceeds by utilizing the reactivity of the functional groups in the molecule. For example, a carbonyl compound can be used as a nucleophile by converting it into an enolate, or as an electrophile; the combination of the two is called the aldol reaction. Designing practically useful syntheses always requires conducting the actual synthesis in the laboratory. The scientific practice of creating novel synthetic routes for complex molecules is called total synthesis. Strategies to design a synthesis include retrosynthesis, popularized by E.J. Corey, which starts with the target molecule and splices it to pieces according to known reactions. The pieces, or the proposed precursors, receive the same treatment, until available and ideally inexpensive starting materials are reached. Then, the retrosynthesis is written in the opposite direction to give the synthesis. A ""synthetic tree"" can be constructed because each compound and also each precursor has multiple syntheses.  See also  Important publications in organic chemistry List of organic reactions Molecular modelling  References   External links  MIT.edu, OpenCourseWare: Organic Chemistry I HaverFord.edu, Organic Chemistry Lectures, Videos and Text Organic-Chemistry.org, Organic Chemistry Portal – Recent Abstracts and (Name)Reactions Orgsyn.org, Organic Chemistry synthesis journal Clutchprep.com, Organic Chemistry Video Lectures and Practice Problems Khanacademy.org, Khan Academy - Organic Chemistry","Organic chemistry is the study of chemical compounds that contain carbon. Carbon has the ability to form a chemical bond with a wide variety of chemical elements and other carbon atoms. This allows a nearly unlimited number of combinations, called organic compounds. The subject of carbon compounds is called organic chemistry because all known organisms, or living things, are made up of water and carbon compounds. Organic chemistry largely involves the synthesis, or formation, of organic products by chemical reaction using different reactants and reagents, the substances used up during a reaction. Several different areas of chemistry expand on the concepts and principles of organic chemistry, including biochemistry, microbiology, and medicine.  History  The term organic originates from Jons Jacob Berzelius, a 19th century Swedish scientist, who used the term to refer to substances present in living things. During Berzelius’ time, the vital force theory was popular. This theory stated that a life force was needed to produce the organic compounds found only in living things. The vital force theory began losing support after an 1828 experiment conducted by Friedrich Wöhler. His work showed that urea, an organic compound, could be created from ammonium cyanate, an inorganic compound.  Hydrocarbons  The study of hydrocarbons is a very large part of organic chemistry. Hydrocarbons are molecules containing only the elements carbon and hydrogen in the form of chains. Hydrocarbons can be classified into two categories based on the presence of a benzene ring, a circular type of hydrocarbon. Aliphatic hydrocarbons do not contain a benzene ring and aromatic hydrocarbons do.  Reactions  Organic chemistry reactions happen because electrons are not shared evenly in a chemical bond. Some atoms or molecules, like oxygen, nitrogen, and negatively charged anions, are nucleophilic because they have extra electrons and want to be around positive charges. Others, such as H+ and other positively charged cations, are electrophilic and want to be around negative charges. When an organic molecule has a positive charge, it is called a carbocation. It is also an electrophile. When nucleophiles and electrophiles mix, a reaction can occur.  Common reaction mechanisms  A reaction mechanism is a series of smaller reactions that form an overall reaction. Two basic mechanism types are substitution and elimination reactions. They are very important in the study of organic chemistry mechanisms because many more complicated mechanisms use them.  Substitution Reactions (SN1 & SN2)  Nucleophilic substitution occurs when an atom or group of atoms detaches from an organic molecule and is replaced by another. If the leaving and adding happens at the same time, it is called a SN2 reaction. If the leaving group breaks away from the organic molecule and forms a carbocation before substitution occurs, it is called an SN1 reaction.  Elimination Reactions (E1 & E2)  Elimination occurs when two groups are broken off of an organic molecule by a strong acid and the resulting charges form a double bond. Usually one of the groups is a nucleophile and the other is a hydrogen atom. If both groups are pulled off at the same time, it is called an E2 reaction. If one group is pulled off first and forms a carbocation before the second group is removed, it is called an E1 reaction.  Stereochemistry  Stereochemistry is the study of molecules in space. It looks into the arrangement of atoms inside of molecules in space relative to one another and how they will interact. Molecules that have the same chemical make up but are arranged differently are called isomers. Famous chemist Louis Pasteur was an early researcher of stereochemistry. A central part of the study of sterochemistry is chirality. Put simply, chirality looks at the symmetry in chemical molecules. If an object cannot be superimposed onto its mirror image, then it is a chiral object. If it can, it is called achiral.  Spectroscopy  Spectroscopy is the study of the interactions between light energy and matter. We are able to see colors because of energy absorption by organic and inorganic compounds. When a plant undergoes photosynthesis, it traps energy from the sun, and this is an example of an interaction between energy and organic compounds. Spectroscopy is used to identify organic molecules in unknown compounds. There are many types of spectroscopy, but most important to organic chemistry are infrared spectroscopy and nuclear magnetic resonance spectroscopy.  References   Other websites  Portal site on Organic Chemistry Archived 2015-03-16 at the Wayback Machine Organic Chemistry Help! Organic Chemistry: An Introduction MIT.edu, OpenCourseWare: Organic Chemistry I HaverFord.edu, Organic Chemistry Lectures, Videos and Text Journal of Organic Chemistry (subscription required) (Table of Contents) Organic Letters (Pubs.ACS.org, Table of Contents) Thime-Connect.com Archived 2008-01-24 at the Wayback Machine, Synlett Thieme-Connect.com Archived 2009-01-19 at the Wayback Machine, Synthesis Organic-Chemistry.org, Organic Chemistry Portal - Recent Abstracts and (Name)Reactions Orgsyn.org, Organic Chemistry synthesis journal Ochem4free.info, Home of a full, online, peer-reviewed organic chemistry text CEM.MSU.edu Archived 2007-10-29 at the Wayback Machine, Virtual Textbook of Organic Chemistry Organic Chemistry Resources WorldWide - A collection of Links Archived 2015-03-16 at the Wayback Machine Organic.RogerFrost.com, Roger Frost's Organic Chemistry - mechanisms and animation for teaching and learning, typically for ages 15–19 ChemHelper.com, Organic chemistry help Organic-Chemistry-Tutor.com, Organic Chemistry Tutor ACDlabs.com Archived 2010-07-22 at the Wayback Machine, Chemical Freeware Chemaxon.com Archived 2010-01-20 at the Wayback Machine, Chemical Freeware from ChemAxon. AceOrganicChem.com Archived 2010-01-23 at the Wayback Machine, OrgChemInfo.8k.com Archived 2010-06-16 at the Wayback Machine, A collection of Organic chemistry Resources Benzylene.com Archived 2009-10-16 at the Wayback Machine, Organic Chemistry Reactions, Mechanisms, and Problems Beilstein-Journals.org, Beilstein Journal of Organic Chemistry (Open Access) Study-Organic-Chemistry.com, Resources for Success in Organic Chemistry"
"A physician (American English), medical practitioner (Commonwealth English), medical doctor, or simply doctor, is a health professional who practices medicine, which is concerned with promoting, maintaining or restoring health through the study, diagnosis, prognosis and treatment of disease, injury, and other physical and mental impairments. Physicians may focus their practice on certain disease categories, types of patients, and methods of treatment—known as specialities—or they may assume responsibility for the provision of continuing and comprehensive medical care to individuals, families, and communities—known as general practice. Medical practice properly requires both a detailed knowledge of the academic disciplines, such as anatomy and physiology, underlying diseases and their treatment—the science of medicine—and also a decent competence in its applied practice—the art or craft of medicine. Both the role of the physician and the meaning of the word itself vary around the world. Degrees and other qualifications vary widely, but there are some common elements, such as medical ethics requiring that physicians show consideration, compassion, and benevolence for their patients.  Modern meanings   Specialist in internal medicine  Around the world the term physician refers to a specialist in internal medicine or one of its many sub-specialties (especially as opposed to a specialist in surgery). This meaning of physician conveys a sense of expertise in treatment by drugs or medications, rather than by the procedures of surgeons.This term is at least nine hundred years old in English: physicians and surgeons were once members of separate professions, and traditionally were rivals. The Shorter Oxford English Dictionary, third edition, gives a Middle English quotation making this contrast, from as early as 1400: ""O Lord, whi is it so greet difference betwixe a cirugian and a physician.""Henry VIII granted a charter to the London Royal College of Physicians in 1518. It was not until 1540 that he granted the Company of Barber-Surgeons (ancestor of the Royal College of Surgeons) its separate charter. In the same year, the English monarch established the Regius Professorship of Physic at the University of Cambridge. Newer universities would probably describe such an academic as a professor of internal medicine. Hence, in the 16th century, physic meant roughly what internal medicine does now. Currently, a specialist physician in the United States may be described as an internist. Another term, hospitalist, was introduced in 1996, to describe US specialists in internal medicine who work largely or exclusively in hospitals. Such 'hospitalists' now make up about 19% of all US general internists, who are often called general physicians in Commonwealth countries. This original use, as distinct from surgeon, is common in most of the world including the United Kingdom and other Commonwealth countries (such as Australia, Bangladesh, India, New Zealand, Pakistan, South Africa, Sri Lanka, and Zimbabwe), as well as in places as diverse as Brazil, Hong Kong, Indonesia, Japan, Ireland, and Taiwan. In such places, the more general English terms doctor or medical practitioner are prevalent, describing any practitioner of medicine (whom an American would likely call a physician, in the broad sense). In Commonwealth countries, specialist pediatricians and geriatricians are also described as specialist physicians who have sub-specialized by age of patient rather than by organ system.  Physician and surgeon  Around the world, the combined term ""physician and surgeon"" is used to describe either a general practitioner or any medical practitioner irrespective of specialty. This usage still shows the original meaning of physician and preserves the old difference between a physician, as a practitioner of physic, and a surgeon. The term may be used by state medical boards in the United States, and by equivalent bodies in Canadian provinces, to describe any medical practitioner.  North America  In modern English, the term physician is used in two main ways, with relatively broad and narrow meanings respectively. This is the result of history and is often confusing. These meanings and variations are explained below. In the United States and Canada, the term physician describes all medical practitioners holding a professional medical degree. The American Medical Association, established in 1847, as well as the American Osteopathic Association, founded in 1897, both currently use the term physician to describe members. However, the American College of Physicians, established in 1915, does not: its title uses physician in its original sense.  American physicians  The vast majority of physicians trained in the United States have a Doctor of Medicine degree, and use the initials M.D. A smaller number attend osteopathic medical schools and have a Doctor of Osteopathic Medicine degree and use the initials D.O. The World Directory of Medical Schools lists both MD and DO granting schools as medical schools located in the United States. After completion of medical school, physicians complete a residency in the specialty in which they will practice. Subspecialties require the completion of a fellowship after residency. Both MD and DO physicians participate in the National Resident Matching Program (NRMP) and attend ACGME-accredited residencies and fellowships across all medical specialties to obtain licensure. All boards of certification now require that physicians demonstrate, by examination, continuing mastery of the core knowledge and skills for a chosen specialty. Recertification varies by particular specialty between every seven and every ten years.  Primary care  Primary care physicians guide patients in preventing disease and detecting health problems early while they are still treatable. They are divided into two types: family medicine doctors and internal medicine doctors. Family doctors, or family physicians, are trained to care for patients of any age, while internists are trained to care for adults. Family doctors receive training in a variety of care and are therefore also referred to as general practitioners. Family medicine grew out of the general practitioner movement of the 1960s in response to the growing specialization in medicine that was seen as threatening to the doctor-patient relationship and continuity of care.  Podiatrists  In the United States, the American Podiatric Medical Association (APMA) defines podiatrists as physicians and surgeons who treat the foot, ankle, and associated structures of the leg. Podiatrists undergo training with the Doctor of Podiatric Medicine (DPM) degree. The American Medical Association (AMA), however, advocates for the definition of a physician as ""an individual possessing degree of either a Doctor of Medicine or Doctor of Osteopathic Medicine."" In the US, podiatrists are required to complete three to four years of podiatry residency upon graduating with a DPM degree. After residency, one to two years of fellowship programs are available in plastic surgery, foot and ankle reconstructive surgery, sports medicine, and wound care.Podiatry residencies and/ or fellowships are not accredited by the ACGME. The overall scope of podiatric practice varies from state to state and is not similar to that of physicians holding an MD or DO degree. DPM is also available at one Canadian university, namely the Université du Québec à Trois-Rivières; students are typically required to complete an internship in New York prior to the obtention of their professional degree. The World Directory of Medical Schools does not list US or Canadian schools of podiatric medicine as medical schools and only lists US-granted MD, DO, and Canadian MD programs as medical schools for the respective regions.  Shortage  Many countries in the developing world have the problem of too few physicians. In 2015, the Association of American Medical Colleges warned that the US will face a doctor shortage of as many as 90,000 by 2025.  Social role and world view   Biomedicine  Within Western culture and over recent centuries, medicine has become increasingly based on scientific reductionism and materialism. This style of medicine is now dominant throughout the industrialized world, and is often termed biomedicine by medical anthropologists. Biomedicine ""formulates the human body and disease in a culturally distinctive pattern"", and is a world view learnt by medical students. Within this tradition, the medical model is a term for the complete ""set of procedures in which all doctors are trained"", including mental attitudes. A particularly clear expression of this world view, currently dominant among conventional physicians, is evidence-based medicine. Within conventional medicine, most physicians still pay heed to their ancient traditions: The critical sense and sceptical attitude of the citation of medicine from the shackles of priestcraft and of caste; secondly, the conception of medicine as an art based on accurate observation, and as a science, an integral part of the science of man and of nature; thirdly, the high moral ideals, expressed in that most ""memorable of human documents"" (Gomperz), the Hippocratic oath; and fourthly, the conception and realization of medicine as the profession of a cultivated gentleman. — Sir William Osler, Chauvanism in Medicine (1902) In this Western tradition, physicians are considered to be members of a learned profession, and enjoy high social status, often combined with expectations of a high and stable income and job security. However, medical practitioners often work long and inflexible hours, with shifts at unsociable times. Their high status is partly from their extensive training requirements, and also because of their occupation's special ethical and legal duties. The term traditionally used by physicians to describe a person seeking their help is the word patient (although one who visits a physician for a routine check-up may also be so described). This word patient is an ancient reminder of medical duty, as it originally meant 'one who suffers'. The English noun comes from the Latin word patiens, the present participle of the deponent verb, patior, meaning 'I am suffering', and akin to the Greek verb πάσχειν (romanized: paschein, lit. to suffer) and its cognate noun πάθος (pathos, suffering).Physicians in the original, narrow sense (specialist physicians or internists, see above) are commonly members or fellows of professional organizations, such as the American College of Physicians or the Royal College of Physicians in the United Kingdom, and such hard-won membership is itself a mark of status.  Alternative medicine  While contemporary biomedicine has distanced itself from its ancient roots in religion and magic, many forms of traditional medicine and alternative medicine continue to espouse vitalism in various guises: ""As long as life had its own secret properties, it was possible to have sciences and medicines based on those properties"". The US National Center for Complementary and Alternative Medicine (NCCAM) classifies complementary and alternative medicine therapies into five categories or domains, including: alternative medical systems, or complete systems of therapy and practice; mind-body interventions, or techniques designed to facilitate the mind's effect on bodily functions and symptoms; biologically based systems including herbalism; and manipulative and body-based methods such as chiropractic and massage therapy. In considering these alternate traditions that differ from biomedicine (see above), medical anthropologists emphasize that all ways of thinking about health and disease have a significant cultural content, including conventional western medicine.Ayurveda, Unani medicine, and homeopathy are popular types of alternative medicine.  Physicians' own health  Some commentators have argued that physicians have duties to serve as role models for the general public in matters of health, for example by not smoking cigarettes. Indeed, in most western nations relatively few physicians smoke, and their professional knowledge does appear to have a beneficial effect on their health and lifestyle. According to a study of male physicians, life expectancy is slightly higher for physicians (73 years for white and 69 years for black) than lawyers or many other highly educated professionals. Causes of death which are less likely to occur in physicians than the general population include respiratory disease (including pneumonia, pneumoconioses, COPD, but excluding emphysema and other chronic airway obstruction), alcohol-related deaths, rectosigmoid and anal cancers, and bacterial diseases.Physicians do experience exposure to occupational hazards, and there is a well-known aphorism that ""doctors make the worst patients"". Causes of death that are shown to be higher in the physician population include suicide among doctors and self-inflicted injury, drug-related causes, traffic accidents, and cerebrovascular and ischaemic heart disease. Physicians are also prone to occupational burnout. This manifests as a long-term stress reaction characterized by poorer quality of care towards patients, emotional exhaustion, a feeling of decreased personal achievement, and others. A study by the Agency for Healthcare Research and Quality reported that time pressure was the greatest cause of burnout; a survey from the American Medical Association reported that more than half of all respondents chose ""too many bureaucratic tasks"" as the leading cause of burnout.  Education and training  Medical education and career pathways for doctors vary considerably across the world.  All medical practitioners  In all developed countries, entry-level medical education programs are tertiary-level courses, undertaken at a medical school attached to a university. Depending on jurisdiction and university, entry may follow directly from secondary school or require pre-requisite undergraduate education. The former commonly takes five or six years to complete. Programs that require previous undergraduate education (typically a three- or four-year degree, often in science) are usually four or five years in length. Hence, gaining a basic medical degree may typically take from five to eight years, depending on jurisdiction and university. Following the completion of entry-level training, newly graduated medical practitioners are often required to undertake a period of supervised practice before full registration is granted, typically one or two years. This may be referred to as an ""internship"", as the ""foundation"" years in the UK, or as ""conditional registration"". Some jurisdictions, including the United States, require residencies for practice. Medical practitioners hold a medical degree specific to the university from which they graduated. This degree qualifies the medical practitioner to become licensed or registered under the laws of that particular country, and sometimes of several countries, subject to requirements for an internship or conditional registration.  Specialists in internal medicine  Specialty training is begun immediately following completion of entry-level training, or even before. In other jurisdictions, junior medical doctors must undertake generalist (un-streamed) training for one or more years before commencing specialization. Hence, depending on the jurisdiction, a specialist physician (internist) often does not achieve recognition as a specialist until twelve or more years after commencing basic medical training—five to eight years at university to obtain a basic medical qualification, and up to another nine years to become a specialist.  Regulation  In most jurisdictions, physicians (in either sense of the word) need government permission to practice. Such permission is intended to promote public safety, and often to protect government spending, as medical care is commonly subsidized by national governments. In some jurisdictions such as in Singapore, it is common for physicians to inflate their qualifications with the title ""Dr"" in correspondence or namecards, even if their qualifications are limited to a basic (e.g., bachelor level) degree. In other countries such as Germany, only physicians holding an academic doctorate may call themselves doctor – on the other hand, the European Research Council has decided that the German medical doctorate does not meet the international standards of a PhD research degree.  All medical practitioners  Among the English-speaking countries, this process is known either as licensure as in the United States, or as registration in the United Kingdom, other Commonwealth countries, and Ireland. Synonyms in use elsewhere include colegiación in Spain, ishi menkyo in Japan, autorisasjon in Norway, Approbation in Germany, and άδεια εργασίας in Greece. In France, Italy and Portugal, civilian physicians must be members of the Order of Physicians to practice medicine. In some countries, including the United Kingdom and Ireland, the profession largely regulates itself, with the government affirming the regulating body's authority. The best-known example of this is probably the General Medical Council of Britain. In all countries, the regulating authorities will revoke permission to practice in cases of malpractice or serious misconduct. In the large English-speaking federations (United States, Canada, Australia), the licensing or registration of medical practitioners is done at a state or provincial level, or nationally as in New Zealand. Australian states usually have a ""Medical Board"", which has now been replaced by the Australian Health Practitioner Regulation Agency (AHPRA) in most states, while Canadian provinces usually have a ""College of Physicians and Surgeons"". All American states have an agency that is usually called the ""Medical Board"", although there are alternate names such as ""Board of Medicine"", ""Board of Medical Examiners"", ""Board of Medical Licensure"", ""Board of Healing Arts"" or some other variation. After graduating from a first-professional school, physicians who wish to practice in the US usually take standardized exams, such as the USMLE for a Doctor in Medicine.  Specialists in internal medicine  Most countries have some method of officially recognizing specialist qualifications in all branches of medicine, including internal medicine. Sometimes, this aims to promote public safety by restricting the use of hazardous treatments. Other reasons for regulating specialists may include standardization of recognition for hospital employment and restriction on which practitioners are entitled to receive higher insurance payments for specialist services.  Performance and professionalism supervision  The issue of medical errors, drug abuse, and other issues in physician professional behavior received significant attention across the world, in particular following a critical 2000 report which ""arguably launched"" the patient-safety movement. In the US, as of 2006 there were few organizations that systematically monitored performance. In the US, only the Department of Veterans Affairs randomly drug tests physicians, in contrast to drug testing practices for other professions that have a major impact on public welfare. Licensing boards at the US state-level depend upon continuing education to maintain competence. Through the utilization of the National Practitioner Data Bank, Federation of State Medical Boards' disciplinary report, and American Medical Association Physician Profile Service, the 67 State Medical Boards continually self-report any adverse/disciplinary actions taken against a licensed physician in order that the other Medical Boards in which the physician holds or is applying for a medical license will be properly notified so that corrective, reciprocal action can be taken against the offending physician. In Europe, as of 2009 the health systems are governed according to various national laws, and can also vary according to regional differences similar to the United States.  See also   References   Further reading  Bell, Whitfield J. ""Medical practice in colonial America"". Bulletin of the History of Medicine 31.5 (1957): 442–453. JSTOR 44449174. Hamilton, Bernice. ""The Medical Professions in the Eighteenth Century"". Economic History Review 4#2 1951, pp. 141–169. JSTOR 2599120. In Britain Holloway, Sydney WF. ""Medical education in England, 1830–1858: A sociological analysis"". History 49.167 (1964): 299–324. JSTOR 24404427. Keevil, John Joyce. Medicine and the Navy, 1200–1900 (4 vol.; E. & S. Livingstone, 1957) on Royal Navy Porter, Roy. Disease, Medicine and Society in England, 1550–1860 (Cambridge University Press, 1995).  External links  Media related to Physicians at Wikimedia Commons The dictionary definition of physician at Wiktionary","A physician or medical doctor is a person who uses medicine to treat illness and injuries to improve a patient's health. In most countries, the basic medical degree qualifies a person to treat patients and prescribe appropriate treatment, including drugs. A physician may also do the simplest kinds of surgery.  Training and qualifications  Doctors are trained in medical schools which are usually part of a university. They hold a degree awarded by a medical school. Doctors work in hospitals, medical clinics, from their own offices, or may even visit people in their homes. They may also work for schools, companies, sports teams, or the military. Medical doctors are often assisted in their work by nurses.The basic degree is awarded on the successful completion of medical school education and practice. It is given different names in different countries. It is M.D. (Doctor of Medicine) in the USA, Scotland and some other countries. In England, different universities use different terms. The University of London qualification is M.B. Ch.B. (that is, Bachelor of Medicine and Bachelor of Surgery). Most countries have higher qualifications, based on experience, supervised work, more exams, and theses. Because of its history, in England a general practitioner eventually becomes an MRCP (member of the Royal College of Physicians), but a surgeon works towards becoming an MRCS (Member of the Royal College of Surgeons). A similar system is used in Edinburgh, Ireland and Canada.  What they do  Medical doctors treat patients by finding out what is wrong with them, known as a diagnosis. They ask questions about the patient's symptoms. These might include fever or pain. They may ask about past illnesses or family members who have been sick. They will then examine the patient. They look at different parts of the body, listen to the heart and lungs with a stethoscope. Sometimes they may need to collect a sample of blood, use an x-ray machine, or use other tools. When they have gathered enough information, a doctor can make a diagnosis and then plan a treatment. Often they prescribe drugs.  Specialists  Some physicians only work on certain diseases or injuries, or may only work on one part of the human body. These doctors are called specialists. For example, there are doctors who specialize in diseases of the stomach or intestines. Other medical doctors are ""general practitioners"" or ""family practitioners"". This means that they do a little bit of everything. The general practitioner the first doctor a patient will see, and this doctor may decide to send them to a specialist doctor if needed. Some types of specialists are: Anesthesiologist, a doctor who gives anesthesia to patients Dentist, also known in the US as a dental surgeon, is a surgeon who specializes in dentistry—the diagnosis, prevention, and treatment of diseases and conditions of the oral cavity. Ophthalmologist, a doctor who specialises in treating eyes Podiatrist, a doctor who specialises in treating feet Psychiatrist, a doctor who specializes in psychiatry, and treats people with mental illness. Psychiatrists can prescribe psychiatric medication. Surgeon, a doctor who performs surgery Pediatrician, a child specialist who also knew about everything such as elderly health, mental illness, eye problems etc.,  Related pages  Doctor of Medicine Doctor-patient relationship Category: Physicians  References "
"Pharmacology is a branch of medicine, biology, and pharmaceutical sciences concerned with drug or medication action, where a drug may be defined as any artificial, natural, or endogenous (from within the body) molecule which exerts a biochemical or physiological effect on the cell, tissue, organ, or organism (sometimes the word pharmacon is used as a term to encompass these endogenous and exogenous bioactive species). It is the science of drugs including their origin, composition, pharmacokinetics, therapeutic use, and toxicology. More specifically, it is the study of the interactions that occur between a living organism and chemicals that affect normal or abnormal biochemical function. If substances have medicinal properties, they are considered pharmaceuticals. The field encompasses drug composition and properties, functions, sources, synthesis and drug design, molecular and cellular mechanisms, organ/systems mechanisms, signal transduction/cellular communication, molecular diagnostics, interactions, chemical biology, therapy, and medical applications and antipathogenic capabilities. The two main areas of pharmacology are pharmacodynamics and pharmacokinetics. Pharmacodynamics studies the effects of a drug on biological systems, and pharmacokinetics studies the effects of biological systems on a drug. In broad terms, pharmacodynamics discusses the chemicals with biological receptors, and pharmacokinetics discusses the absorption, distribution, metabolism, and excretion (ADME) of chemicals from the biological systems. Pharmacology is not synonymous with pharmacy and the two terms are frequently confused. Pharmacology, a biomedical science, deals with the research, discovery, and characterization of chemicals which show biological effects and the elucidation of cellular and organismal function in relation to these chemicals. In contrast, pharmacy, a health services profession, is concerned with the application of the principles learned from pharmacology in its clinical settings; whether it be in a dispensing or clinical care role. In either field, the primary contrast between the two is their distinctions between direct-patient care, pharmacy practice, and the science-oriented research field, driven by pharmacology.  Etymology  The word pharmacology is derived from Greek φάρμακον, pharmakon, ""drug, poison"" and -λογία, -logia ""study of"", ""knowledge of"" (cf. the etymology of pharmacy). Pharmakon is related to pharmakos, the ritualistic sacrifice or exile of a human scapegoat or victim in Ancient Greek religion. The modern term pharmacon is used more broadly than the term drug because it includes endogenous substances, and biologically active substances which are not used as drugs. Typically it includes pharmacological agonists and antagonists, but also enzyme inhibitors (such as monoamine oxidase inhibitors).  History  The origins of clinical pharmacology date back to the Middle Ages, with pharmacognosy and Avicenna's The Canon of Medicine, Peter of Spain's Commentary on Isaac, and John of St Amand's Commentary on the Antedotary of Nicholas. Early pharmacology focused on herbalism and natural substances, mainly plant extracts. Medicines were compiled in books called pharmacopoeias. Crude drugs have been used since prehistory as a preparation of substances from natural sources. However, the active ingredient of crude drugs are not purified and the substance is adulterated with other substances. Traditional medicine varies between cultures and may be specific to a particular culture, such as in traditional Chinese, Mongolian, Tibetan and Korean medicine. However much of this has since been regarded as pseudoscience. Pharmacological substances known as entheogens may have spiritual and religious use and historical context. In the 17th century, the English physician Nicholas Culpeper translated and used pharmacological texts. Culpeper detailed plants and the conditions they could treat. In the 18th century, much of clinical pharmacology was established by the work of William Withering. Pharmacology as a scientific discipline did not further advance until the mid-19th century amid the great biomedical resurgence of that period. Before the second half of the nineteenth century, the remarkable potency and specificity of the actions of drugs such as morphine, quinine and digitalis were explained vaguely and with reference to extraordinary chemical powers and affinities to certain organs or tissues. The first pharmacology department was set up by Rudolf Buchheim in 1847, at University of Tartu, in recognition of the need to understand how therapeutic drugs and poisons produced their effects. Subsequently, the first pharmacology department in England was set up in 1905 at University College London. Pharmacology developed in the 19th century as a biomedical science that applied the principles of scientific experimentation to therapeutic contexts. The advancement of research techniques propelled pharmacological research and understanding. The development of the organ bath preparation, where tissue samples are connected to recording devices, such as a myograph, and physiological responses are recorded after drug application, allowed analysis of drugs' effects on tissues. The development of the ligand binding assay in 1945 allowed quantification of the binding affinity of drugs at chemical targets. Modern pharmacologists use techniques from genetics, molecular biology, biochemistry, and other advanced tools to transform information about molecular mechanisms and targets into therapies directed against disease, defects or pathogens, and create methods for preventive care, diagnostics, and ultimately personalized medicine.  Divisions  The discipline of pharmacology can be divided into many sub disciplines each with a specific focus.  Systems of the body  Pharmacology can also focus on specific systems comprising the body. Divisions related to bodily systems study the effects of drugs in different systems of the body. These include neuropharmacology, in the central and peripheral nervous systems; immunopharmacology in the immune system. Other divisions include cardiovascular, renal and endocrine pharmacology. Psychopharmacology is the study of the use of drugs that affect the psyche, mind and behavior (e.g. antidepressants) in treating mental disorders (e.g. depression). It incorporates approaches and techniques from neuropharmacology, animal behavior and behavioral neuroscience, and is interested in the behavioral and neurobiological mechanisms of action of psychoactive drugs. The related field of neuropsychopharmacology focuses on the effects of drugs at the overlap between the nervous system and the psyche. Pharmacometabolomics, also known as pharmacometabonomics, is a field which stems from metabolomics, the quantification and analysis of metabolites produced by the body. It refers to the direct measurement of metabolites in an individual's bodily fluids, in order to predict or evaluate the metabolism of pharmaceutical compounds, and to better understand the pharmacokinetic profile of a drug. Pharmacometabolomics can be applied to measure metabolite levels following the administration of a drug, in order to monitor the effects of the drug on metabolic pathways. Pharmacomicrobiomics studies the effect of microbiome variations on drug disposition, action, and toxicity. Pharmacomicrobiomics is concerned with the interaction between drugs and the gut microbiome. Pharmacogenomics is the application of genomic technologies to drug discovery and further characterization of drugs related to an organism's entire genome. For pharmacology regarding individual genes, pharmacogenetics studies how genetic variation gives rise to differing responses to drugs. Pharmacoepigenetics studies the underlying epigenetic marking patterns that lead to variation in an individual's response to medical treatment.  Clinical practice and drug discovery  Pharmacology can be applied within clinical sciences. Clinical pharmacology is the application of pharmacological methods and principles in the study of drugs in humans. An example of this is posology, which is the study of how medicines are dosed.Pharmacology is closely related to toxicology. Both pharmacology and toxicology are scientific disciplines that focus on understanding the properties and actions of chemicals. However, pharmacology emphasizes the therapeutic effects of chemicals, usually drugs or compounds that could become drugs, whereas toxicology is the study of chemical's adverse effects and risk assessment.Pharmacological knowledge is used to advise pharmacotherapy in medicine and pharmacy.  Drug discovery  Drug discovery is the field of study concerned with creating new drugs. It encompasses the subfields of drug design and development. Drug discovery starts with drug design, which is the inventive process of finding new drugs. In the most basic sense, this involves the design of molecules that are complementary in shape and charge to a given biomolecular target. After a lead compound has been identified through drug discovery, drug development involves bringing the drug to the market. Drug discovery is related to pharmacoeconomics, which is the sub-discipline of health economics that considers the value of drugs Pharmacoeconomics evaluates the cost and benefits of drugs in order to guide optimal healthcare resource allocation. The techniques used for the discovery, formulation, manufacturing and quality control of drugs discovery is studied by pharmaceutical engineering, a branch of engineering. Safety pharmacology specialises in detecting and investigating potential undesirable effects of drugs. Development of medication is a vital concern to medicine, but also has strong economical and political implications. To protect the consumer and prevent abuse, many governments regulate the manufacture, sale, and administration of medication. In the United States, the main body that regulates pharmaceuticals is the Food and Drug Administration; they enforce standards set by the United States Pharmacopoeia. In the European Union, the main body that regulates pharmaceuticals is the EMA, and they enforce standards set by the European Pharmacopoeia. The metabolic stability and the reactivity of a library of candidate drug compounds have to be assessed for drug metabolism and toxicological studies. Many methods have been proposed for quantitative predictions in drug metabolism; one example of a recent computational method is SPORCalc. A slight alteration to the chemical structure of a medicinal compound could alter its medicinal properties, depending on how the alteration relates to the structure of the substrate or receptor site on which it acts: this is called the structural activity relationship (SAR). When a useful activity has been identified, chemists will make many similar compounds called analogues, to try to maximize the desired medicinal effect(s). This can take anywhere from a few years to a decade or more, and is very expensive. One must also determine how safe the medicine is to consume, its stability in the human body and the best form for delivery to the desired organ system, such as tablet or aerosol. After extensive testing, which can take up to six years, the new medicine is ready for marketing and selling.Because of these long timescales, and because out of every 5000 potential new medicines typically only one will ever reach the open market, this is an expensive way of doing things, often costing over 1 billion dollars. To recoup this outlay pharmaceutical companies may do a number of things: Carefully research the demand for their potential new product before spending an outlay of company funds. Obtain a patent on the new medicine preventing other companies from producing that medicine for a certain allocation of time.The inverse benefit law describes the relationship between a drugs therapeutic benefits and its marketing. When designing drugs, the placebo effect must be considered to assess the drug's true therapeutic value. Drug development uses techniques from medicinal chemistry to chemically design drugs. This overlaps with the biological approach of finding targets and physiological effects.  Wider contexts  Pharmacology can be studied in relation to wider contexts than the physiology of individuals. For example, pharmacoepidemiology concerns the variations of the effects of drugs in or between populations, it is the bridge between clinical pharmacology and epidemiology. Pharmacoenvironmentology or environmental pharmacology is the study of the effects of used pharmaceuticals and personal care products (PPCPs) on the environment after their elimination from the body. Human health and ecology are intimately related so environmental pharmacology studies the environmental effect of drugs and pharmaceuticals and personal care products in the environment.Drugs may also have ethnocultural importance, so ethnopharmacology studies the ethnic and cultural aspects of pharmacology.  Emerging fields  Photopharmacology is an emerging approach in medicine in which drugs are activated and deactivated with light. The energy of light is used to change for shape and chemical properties of the drug, resulting in different biological activity. This is done to ultimately achieve control when and where drugs are active in a reversible manner, to prevent side effects and pollution of drugs into the environment.  Theory of pharmacology  The study of chemicals requires intimate knowledge of the biological system affected. With the knowledge of cell biology and biochemistry increasing, the field of pharmacology has also changed substantially. It has become possible, through molecular analysis of receptors, to design chemicals that act on specific cellular signaling or metabolic pathways by affecting sites directly on cell-surface receptors (which modulate and mediate cellular signaling pathways controlling cellular function). Chemicals can have pharmacologically relevant properties and effects. Pharmacokinetics describes the effect of the body on the chemical (e.g. half-life and volume of distribution), and pharmacodynamics describes the chemical's effect on the body (desired or toxic).  Systems, receptors and ligands  Pharmacology is typically studied with respect to particular systems, for example endogenous neurotransmitter systems. The major systems studied in pharmacology can be categorised by their ligands and include acetylcholine, adrenaline, glutamate, GABA, dopamine, histamine, serotonin, cannabinoid and opioid. Molecular targets in pharmacology include receptors, enzymes and membrane transport proteins. Enzymes can be targeted with enzyme inhibitors. Receptors are typically categorised based on structure and function. Major receptor types studied in pharmacology include G protein coupled receptors, ligand gated ion channels and receptor tyrosine kinases.  Pharmacodynamics  Pharmacodynamics is defined as how the body reacts to the drugs. Pharmacology models include the Hill equation, Cheng-Prusoff equation and Schild regression. Pharmacodynamics theory often investigates the binding affinity of ligands to their receptors. Medication is said to have a narrow or wide therapeutic index, certain safety factor or therapeutic window. This describes the ratio of desired effect to toxic effect. A compound with a narrow therapeutic index (close to one) exerts its desired effect at a dose close to its toxic dose. A compound with a wide therapeutic index (greater than five) exerts its desired effect at a dose substantially below its toxic dose. Those with a narrow margin are more difficult to dose and administer, and may require therapeutic drug monitoring (examples are warfarin, some antiepileptics, aminoglycoside antibiotics). Most anti-cancer drugs have a narrow therapeutic margin: toxic side-effects are almost always encountered at doses used to kill tumors. The effect of drugs can be described with Loewe additivity which is one of several common reference models.  Pharmacokinetics  Pharmacokinetics is the study of the bodily absorption, distribution, metabolism, and excretion of drugs.When describing the pharmacokinetic properties of the chemical that is the active ingredient or active pharmaceutical ingredient (API), pharmacologists are often interested in L-ADME: Liberation – How is the API disintegrated (for solid oral forms (breaking down into smaller particles), dispersed, or dissolved from the medication? Absorption – How is the API absorbed (through the skin, the intestine, the oral mucosa)? Distribution – How does the API spread through the organism? Metabolism – Is the API converted chemically inside the body, and into which substances. Are these active (as well)? Could they be toxic? Excretion – How is the API excreted (through the bile, urine, breath, skin)?Drug metabolism is assessed in pharmacokinetics and is important in drug research and prescribing.  Administration, drug policy and safety   Drug policy  In the United States, the Food and Drug Administration (FDA) is responsible for creating guidelines for the approval and use of drugs. The FDA requires that all approved drugs fulfill two requirements: The drug must be found to be effective against the disease for which it is seeking approval (where 'effective' means only that the drug performed better than placebo or competitors in at least two trials). The drug must meet safety criteria by being subject to animal and controlled human testing.Gaining FDA approval usually takes several years. Testing done on animals must be extensive and must include several species to help in the evaluation of both the effectiveness and toxicity of the drug. The dosage of any drug approved for use is intended to fall within a range in which the drug produces a therapeutic effect or desired outcome.The safety and effectiveness of prescription drugs in the U.S. are regulated by the federal Prescription Drug Marketing Act of 1987. The Medicines and Healthcare products Regulatory Agency (MHRA) has a similar role in the UK. Medicare Part D is a prescription drug plan in the U.S. The Prescription Drug Marketing Act (PDMA) is an act related to drug policy. Prescription drugs are drugs regulated by legislation.  Societies and education   Societies and administration  The International Union of Basic and Clinical Pharmacology, Federation of European Pharmacological Societies and European Association for Clinical Pharmacology and Therapeutics are organisations representing standardisation and regulation of clinical and scientific pharmacology. Systems for medical classification of drugs with pharmaceutical codes have been developed. These include the National Drug Code (NDC), administered by Food and Drug Administration.; Drug Identification Number (DIN), administered by Health Canada under the Food and Drugs Act; Hong Kong Drug Registration, administered by the Pharmaceutical Service of the Department of Health (Hong Kong) and National Pharmaceutical Product Index in South Africa. Hierarchical systems have also been developed, including the Anatomical Therapeutic Chemical Classification System (AT, or ATC/DDD), administered by World Health Organization; Generic Product Identifier (GPI), a hierarchical classification number published by MediSpan and SNOMED, C axis. Ingredients of drugs have been categorised by Unique Ingredient Identifier.  Education  The study of pharmacology overlaps with biomedical sciences and is the study of the effects of drugs on living organisms. Pharmacological research can lead to new drug discoveries, and promote a better understanding of human physiology. Students of pharmacology must have a detailed working knowledge of aspects in physiology, pathology, and chemistry. They may also require knowledge of plants as sources of pharmacologically-active compounds. Modern pharmacology is interdisciplinary and involves biophysical and computational sciences, and analytical chemistry. A pharmacist needs to be well-equipped with knowledge on pharmacology for application in pharmaceutical research or pharmacy practice in hospitals or commercial organisations selling to customers. Pharmacologists, however, usually work in a laboratory undertaking research or development of new products. Pharmacological research is important in academic research (medical and non-medical), private industrial positions, science writing, scientific patents and law, consultation, biotech and pharmaceutical employment, the alcohol industry, food industry, forensics/law enforcement, public health, and environmental/ecological sciences. Pharmacology is often taught to pharmacy and medicine students as part of a Medical School curriculum.  See also   References   External links  American Society for Pharmacology and Experimental Therapeutics British Pharmacological Society International Conference on Harmonisation US Pharmacopeia International Union of Basic and Clinical Pharmacology IUPHAR Committee on Receptor Nomenclature and Drug Classification IUPHAR/BPS Guide to Pharmacology  Further reading  Foreman JC, Johansen T, Gibb AJ (2009). Textbook of Receptor Pharmacology, Second Edition. CRC Press. ISBN 9781439887578. Brunton L (2011). Brunton LL, Chabner B, Knollmann BC (eds.). Goodman and Gilman's The Pharmacological Basis of Therapeutics (12 ed.). New York: McGraw-Hill. ISBN 978-0-07-162442-8. Whalen K (2014). Lippincott Illustrated Reviews: Pharmacology.","Pharmacology is the study of how medicine and other things have an effect on living organisms and change how they function. Pharmacology could also be defined as the study of how medicine actually works. Pharmacology is not exactly the same as pharmacy, and a pharmacologist is not exactly the same as a pharmacist. A pharmacologist is a scientist who studies how medicine actually works, and usually works in a science lab. A pharmacist is a health care provider who usually works at a pharmacy. However, there is quite a bit of overlap between these two fields. A pharmacist could be considered a type of pharmacologist. While in school, pharmacists do take many classes in pharmacology.  Origin of the word  If something can be used as a medicine, it is called a pharmaceutical. Pharmacology includes how drugs are made, how they interact with living organisms, what harmful effects they could have, how they can be used as medicines, and if they can be used to prevent illness. A person who works in the study of pharmacology is called a pharmacologist. Pharmacologists work in a team with biochemists, geneticists, microbiologists, toxicologists and pharmacists to run clinical tests on how drugs work.  Uses of pharmacology  The development of drugs is very important to medicine, but it also has strong economical and political uses. To protect people and prevent abuse, some countries try to control the way in which drugs are made, sold, and administered.  Scientific background  To study chemicals, a person needs to know a lot about what will be affected if it is ingested (taken into the body). As more people know about cell biology and biochemistry, the field of pharmacology has changed as well. It is now possible to design chemicals that do specific things. A chemical can have different properties. Pharmacokinetics describes the what effect the body will have on the chemical, and pharmacodynamics describes the chemical's effect on the body (desired or toxic). When a pharmacologist is talking about pharmacokinetic properties of a chemical, they are interested in four things: ADME. Absorption - How is the medication absorbed (through the skin, the intestine, the mouth)? Distribution - How does it spread through the organism? Metabolism - Is the medication converted chemically inside the body, and into what. Are these new substances active? Could they be toxic? Excretion - How does the organism get rid of the chemical (through the bile, urine, breath, skin)?Medication is said to have a narrow or wide therapeutic index. This describes the ratio of desired effect to toxic effect. A medicine with a narrow therapeutic index (close to one) only does what people want it to do when the amount given is enough to put the organism in danger. A medicine with a wide therapeutic index (greater than five) does what people want it to do and does not necessarily put the organism in danger. Medication with a narrow margin are more difficult to dose and give to a person, and may require therapeutic drug monitoring (examples are warfarin, some antiepileptics, aminoglycoside antibiotics). Most anti-cancer drugs have a narrow therapeutic margin; toxic side-effects are almost always encountered at doses needed to kill tumours.  Drugs as medicine  Drugs that are given to people to help cure them of a medical condition or help reduce the symptoms are often licensed. They can be divided into three groups: over-the-counter, where anybody can buy the drug from a shop; prescription-only medicine, where a doctor has to say that a person is allowed to take a drug; and in some countries, pharmacy medicines, where only a registered pharmacy can sell a drug. Most over-the-counter medication will not hurt a person if they take a bit more than they are meant to. Medications are often produced by pharmaceutical companies and are often patented. Drugs that are not patented are called generic drugs.  Related pages  Pharmacoepidemiology Pharmacokinetics Pharmacotheraphy"
"A medication (also called medicament, medicine, pharmaceutical drug, medicinal drug or simply drug) is a drug used to diagnose, cure, treat, or prevent disease. Drug therapy (pharmacotherapy) is an important part of the medical field and relies on the science of pharmacology for continual advancement and on pharmacy for appropriate management. Drugs are classified in multiple ways. One of the key divisions is by level of control, which distinguishes prescription drugs (those that a pharmacist dispenses only on the order of a physician, physician assistant, or qualified nurse) from over-the-counter drugs (those that consumers can order for themselves). Another key distinction is between traditional small molecule drugs, usually derived from chemical synthesis, and biopharmaceuticals, which include recombinant proteins, vaccines, blood products used therapeutically (such as IVIG), gene therapy, monoclonal antibodies and cell therapy (for instance, stem cell therapies). Other ways to classify medicines are by mode of action, route of administration, biological system affected, or therapeutic effects. An elaborate and widely used classification system is the Anatomical Therapeutic Chemical Classification System. The World Health Organization keeps a list of essential medicines. Drug discovery and drug development are complex and expensive endeavors undertaken by pharmaceutical companies, academic scientists, and governments. As a result of this complex path from discovery to commercialization, partnering has become a standard practice for advancing drug candidates through development pipelines. Governments generally regulate what drugs can be marketed, how drugs are marketed, and in some jurisdictions, drug pricing. Controversies have arisen over drug pricing and disposal of used drugs.  Definition  Medication is a medicine or a chemical compound used to treat or cure illness. According to Encyclopædia Britannica, medication is ""a substance used in treating a disease or relieving pain"".As defined by the National Cancer Institute, dosage forms of medication can include tablets, capsules, liquids, creams, and patches. Medications can be given in different ways, such as by mouth, by infusion into a vein, or by drops put into the ear or eye. A medication that does not contain an active ingredient and is used in research studies is called a placebo.In Europe, the term is ""medicinal product"", and it is defined by EU law as: ""Any substance or combination of substances presented as having properties for treating or preventing disease in human beings; or"" ""Any substance or combination of substances which may be used in or administered to human beings either with a view to restoring, correcting or modifying physiological functions by exerting a pharmacological, immunological or metabolic action or to making a medical diagnosis."": 36 In the US, a ""drug"" is: A substance (other than food) intended to affect the structure or any function of the body. A substance intended for use as a component of a medicine but not a device or a component, part, or accessory of a device. A substance intended for use in the diagnosis, cure, mitigation, treatment, or prevention of disease. A substance recognized by an official pharmacopeia or formulary. Biological products are included within this definition and are generally covered by the same laws and regulations, but differences exist regarding their manufacturing processes (chemical process versus biological process).  Usage  Drug use among elderly Americans has been studied; in a group of 2377 people with an average age of 71 surveyed between 2005 and 2006, 84% took at least one prescription drug, 44% took at least one over-the-counter (OTC) drug, and 52% took at least one dietary supplement; in a group of 2245 elderly Americans (average age of 71) surveyed over the period 2010 – 2011, those percentages were 88%, 38%, and 64%.  Classification  One of the key classifications is between traditional small molecule drugs; usually derived from chemical synthesis and biological medical products; which include recombinant proteins, vaccines, blood products used therapeutically (such as IVIG), gene therapy, and cell therapy (for instance, stem cell therapies). Pharmaceuticals or drugs or medicines are classified into various other groups besides their origin on the basis of pharmacological properties like mode of action and their pharmacological action or activity, such as by chemical properties, mode or route of administration, biological system affected, or therapeutic effects. An elaborate and widely used classification system is the Anatomical Therapeutic Chemical Classification System (ATC system). The World Health Organization keeps a list of essential medicines. A sampling of classes of medicine includes: Antipyretics: reducing fever (pyrexia/pyresis) Analgesics: reducing pain (painkillers) Antimalarial drugs: treating malaria Antibiotics: inhibiting germ growth Antiseptics: prevention of germ growth near burns, cuts,and wounds Mood stabilizers: lithium and valproate Hormone replacements: Premarin Oral contraceptives: Enovid, ""biphasic"" pill, and ""triphasic"" pill Stimulants: methylphenidate, amphetamine Tranquilizers: meprobamate, chlorpromazine, reserpine, chlordiazepoxide, diazepam, and alprazolam Statins: lovastatin, pravastatin, and simvastatinPharmaceuticals may also be described as ""specialty"", independent of other classifications, which is an ill-defined class of drugs that might be difficult to administer, require special handling during administration, require patient monitoring during and immediately after administration, have particular regulatory requirements restricting their use, and are generally expensive relative to other drugs.  Types of medicines   For the digestive system  Lower digestive tract: laxatives, antispasmodics, antidiarrhoeals, bile acid sequestrants, opioids. Upper digestive tract: antacids, reflux suppressants, antiflatulents, antidopaminergics, proton pump inhibitors (PPIs), H2-receptor antagonists, cytoprotectants, prostaglandin analogues.  For the cardiovascular system  Affecting blood pressure/(antihypertensive drugs): ACE inhibitors, angiotensin receptor blockers, beta-blockers, α blockers, calcium channel blockers, thiazide diuretics, loop diuretics, aldosterone inhibitors. Coagulation: anticoagulants, heparin, antiplatelet drugs, fibrinolytics, anti-hemophilic factors, haemostatic drugs. General: β-receptor blockers (""beta blockers""), calcium channel blockers, diuretics, cardiac glycosides, antiarrhythmics, nitrate, antianginals, vasoconstrictors, vasodilators. HMG-CoA reductase inhibitors (statins) for lowering LDL cholesterol inhibitors: hypolipidaemic agents.  For the central nervous system  Drugs affecting the central nervous system include psychedelics, hypnotics, anaesthetics, antipsychotics, eugeroics, antidepressants (including tricyclic antidepressants, monoamine oxidase inhibitors, lithium salts, and selective serotonin reuptake inhibitors (SSRIs)), antiemetics, anticonvulsants/antiepileptics, anxiolytics, barbiturates, movement disorder (e.g., Parkinson's disease) drugs, nootropics, stimulants (including amphetamines), benzodiazepines, cyclopyrrolones, dopamine antagonists, antihistamines, cholinergics, anticholinergics, emetics, cannabinoids, and 5-HT (serotonin) antagonists.  For pain  The main classes of painkillers are NSAIDs, opioids, and local anesthetics. For consciousness (anesthetic drugs) Some anesthetics include benzodiazepines and barbiturates.  For musculoskeletal disorders  The main categories of drugs for musculoskeletal disorders are: NSAIDs (including COX-2 selective inhibitors), muscle relaxants, neuromuscular drugs, and anticholinesterases.  For the eye  Anti-allergy: mast cell inhibitors. Anti-fungal: imidazoles, polyenes. Anti-glaucoma: adrenergic agonists, beta-blockers, carbonic anhydrase inhibitors/hyperosmotics, cholinergics, miotics, parasympathomimetics, prostaglandin agonists/prostaglandin inhibitors, nitroglycerin. Anti-inflammatory: NSAIDs, corticosteroids. Antibacterial: antibiotics, topical antibiotics, sulfa drugs, aminoglycosides, fluoroquinolones. Antiviral drugs. Diagnostic: topical anesthetics, sympathomimetics, parasympatholytics, mydriatics, cycloplegics. General: adrenergic neurone blocker, astringent.  For the ear, nose, and oropharynx  Antibiotics, sympathomimetics, antihistamines, anticholinergics, NSAIDs, corticosteroids, antiseptics, local anesthetics, antifungals, and cerumenolytics.  For the respiratory system  Bronchodilators, antitussives, mucolytics, decongestants, inhaled and systemic corticosteroids, beta2-adrenergic agonists, anticholinergics, mast cell stabilizers, leukotriene antagonists.  For endocrine problems  Androgens, antiandrogens, estrogens, gonadotropin, corticosteroids, human growth hormone, insulin, antidiabetics (sulfonylureas, biguanides/metformin, thiazolidinediones, insulin), thyroid hormones, antithyroid drugs, calcitonin, diphosphonate, vasopressin analogues.  For the reproductive system or urinary system  Antifungal, alkalinizing agents, quinolones, antibiotics, cholinergics, anticholinergics, antispasmodics, 5-alpha reductase inhibitor, selective alpha-1 blockers, sildenafils, fertility medications.  For contraception  Hormonal contraception. Ormeloxifene. Spermicide.  For obstetrics and gynecology  NSAIDs, anticholinergics, haemostatic drugs, antifibrinolytics, Hormone Replacement Therapy (HRT), bone regulators, beta-receptor agonists, follicle stimulating hormone, luteinising hormone, LHRH, gamolenic acid, gonadotropin release inhibitor, progestogen, dopamine agonists, oestrogen, prostaglandins, gonadorelin, clomiphene, tamoxifen, diethylstilbestrol.  For the skin  Emollients, anti-pruritics, antifungals, antiseptics, scabicides, pediculicides, tar products, vitamin A derivatives, vitamin D analogues, keratolytics, abrasives, systemic antibiotics, topical antibiotics, hormones, desloughing agents, exudate absorbents, fibrinolytics, proteolytics, sunscreens, antiperspirants, corticosteroids, immune modulators.  For infections and infestations  Antibiotics, antifungals, antileprotics, antituberculous drugs, antimalarials, anthelmintics, amoebicides, antivirals, antiprotozoals, probiotics, prebiotics, antitoxins, and antivenoms.  For the immune system  Vaccines, immunoglobulins, immunosuppressants, interferons, and monoclonal antibodies.  For allergic disorders  Anti-allergics, antihistamines, NSAIDs, corticosteroids.  For nutrition  Tonics, electrolytes and mineral preparations (including iron preparations and magnesium preparations), parenteral nutrition, vitamins, anti-obesity drugs, anabolic drugs, haematopoietic drugs, food product drugs.  For neoplastic disorders  Cytotoxic drugs, therapeutic antibodies, sex hormones, aromatase inhibitors, somatostatin inhibitors, recombinant interleukins, G-CSF, erythropoietin.  For diagnostics  Contrast media.  For euthanasia  A euthanaticum is used for euthanasia and physician-assisted suicide. Euthanasia is not permitted by law in many countries, and consequently, medicines will not be licensed for this use in those countries.  Administration  A single drug may contain single or multiple active ingredients. The administration is the process by which a patient takes medicine. There are three major categories of drug administration: enteral (via the human gastrointestinal tract), injection into the body, and by other routes (dermal, nasal, ophthalmic, otologic, and urogenital).Oral administration, the most common form of enteral administration, can be performed using various dosage forms including tablets or capsules and liquid such as syrup or suspension. Other ways to take the medication include buccally (placed inside the cheek), sublingually (placed underneath the tongue), eye and ear drops (dropped into the eye or ear), and transdermally (applied to the skin).They can be administered in one dose, as a bolus. Administration frequencies are often abbreviated from Latin, such as every 8 hours reading Q8H from Quaque VIII Hora. The drug frequencies are often expressed as the number of times a drug is used per day (e.g., four times a day). It may include event-related information (e.g., 1 hour before meals, in the morning, at bedtime), or complimentary to an interval, although equivalent expressions may have different implications (e.g., every 8 hours versus 3 times a day).  Drug discovery  In the fields of medicine, biotechnology, and pharmacology, drug discovery is the process by which new drugs are discovered. Historically, drugs were discovered by identifying the active ingredient from traditional remedies or by serendipitous discovery. Later chemical libraries of synthetic small molecules, natural products, or extracts were screened in intact cells or whole organisms to identify substances that have a desirable therapeutic effect in a process known as classical pharmacology. Since sequencing of the human genome which allowed rapid cloning and synthesis of large quantities of purified proteins, it has become common practice to use high throughput screening of large compound libraries against isolated biological targets which are hypothesized to be disease-modifying in a process known as reverse pharmacology. Hits from these screens are then tested in cells and then in animals for efficacy. Even more recently, scientists have been able to understand the shape of biological molecules at the atomic level and to use that knowledge to design (see drug design) drug candidates. Modern drug discovery involves the identification of screening hits, medicinal chemistry, and optimization of those hits to increase the affinity, selectivity (to reduce the potential of side effects), efficacy/potency, metabolic stability (to increase the half-life), and oral bioavailability. Once a compound that fulfills all of these requirements has been identified, it will begin the process of drug development prior to clinical trials. One or more of these steps may, but not necessarily, involve computer-aided drug design. Despite advances in technology and understanding of biological systems, drug discovery is still a lengthy, ""expensive, difficult, and inefficient process"" with a low rate of new therapeutic discovery. In 2010, the research and development cost of each new molecular entity (NME) was approximately US$1.8 billion. Drug discovery is done by pharmaceutical companies, sometimes with research assistance from universities. The ""final product"" of drug discovery is a patent on the potential drug. The drug requires very expensive Phase I, II, and III clinical trials, and most of them fail. Small companies have a critical role, often then selling the rights to larger companies that have the resources to run the clinical trials. Drug discovery is different from Drug Development. Drug Discovery is often considered the process of identifying new medicine. At the same time, Drug development is delivering a new drug molecule into clinical practice. In its broad definition, this encompasses all steps from the basic research process of finding a suitable molecular target to supporting the drug's commercial launch.  Development  Drug development is the process of bringing a new drug to the market once a lead compound has been identified through the process of drug discovery. It includes pre-clinical research (microorganisms/animals) and clinical trials (on humans) and may include the step of obtaining regulatory approval to market the drug.Drug Development Process Discovery: The Drug Development process starts with Discovery, a process of identifying a new medicine. Development: Chemicals extracted from natural products are used to make pills, capsules, or syrups for oral use. Injections for direct infusion into the blood drops for eyes or ears. Preclinical research: Drugs go under laboratory or animal testing, to ensure that they can be used on Humans. Clinical testing: The drug is used on people to confirm that it is safe to use. FDA Review: drug is sent to FDA before launching the drug into the market. FDA post-Market Review: The drug is reviewed and monitored by FDA for the safety once it is available to the public.  Regulation  The regulation of drugs varies by jurisdiction. In some countries, such as the United States, they are regulated at the national level by a single agency. In other jurisdictions, they are regulated at the state level, or at both state and national levels by various bodies, as is the case in Australia. The role of therapeutic goods regulation is designed mainly to protect the health and safety of the population. Regulation is aimed at ensuring the safety, quality, and efficacy of the therapeutic goods which are covered under the scope of the regulation. In most jurisdictions, therapeutic goods must be registered before they are allowed to be marketed. There is usually some degree of restriction on the availability of certain therapeutic goods depending on their risk to consumers. Depending upon the jurisdiction, drugs may be divided into over-the-counter drugs (OTC) which may be available without special restrictions, and prescription drugs, which must be prescribed by a licensed medical practitioner in accordance with medical guidelines due to the risk of adverse effects and contraindications. The precise distinction between OTC and prescription depends on the legal jurisdiction. A third category, ""behind-the-counter"" drugs, is implemented in some jurisdictions. These do not require a prescription, but must be kept in the dispensary, not visible to the public, and be sold only by a pharmacist or pharmacy technician. Doctors may also prescribe prescription drugs for off-label use – purposes which the drugs were not originally approved for by the regulatory agency. The Classification of Pharmaco-Therapeutic Referrals helps guide the referral process between pharmacists and doctors. The International Narcotics Control Board of the United Nations imposes a world law of prohibition of certain drugs. They publish a lengthy list of chemicals and plants whose trade and consumption (where applicable) are forbidden. OTC drugs are sold without restriction as they are considered safe enough that most people will not hurt themselves accidentally by taking it as instructed. Many countries, such as the United Kingdom have a third category of ""pharmacy medicines"", which can be sold only in registered pharmacies by or under the supervision of a pharmacist. Medical errors include over-prescription and polypharmacy, mis-prescription, contraindication and lack of detail in dosage and administration instructions. In 2000 the definition of a prescription error was studied using a Delphi method conference; the conference was motivated by ambiguity in what a prescription error is and a need to use a uniform definition in studies.  Drug pricing  In many jurisdictions, drug prices are regulated.  United Kingdom  In the UK, the Pharmaceutical Price Regulation Scheme is intended to ensure that the National Health Service is able to purchase drugs at reasonable prices. The prices are negotiated between the Department of Health, acting with the authority of Northern Ireland and the UK Government, and the representatives of the Pharmaceutical industry brands, the Association of the British Pharmaceutical Industry (ABPI). For 2017 this payment percentage set by the PPRS will be 4,75%.  Canada  In Canada, the Patented Medicine Prices Review Board examines drug pricing and determines if a price is excessive or not. In these circumstances, drug manufacturers must submit a proposed price to the appropriate regulatory agency. Furthermore, ""the International Therapeutic Class Comparison Test is responsible for comparing the National Average Transaction Price of the patented drug product under review"" different countries that the prices are being compared to are the following: France, Germany, Italy, Sweden, Switzerland, the United Kingdom, and the United States  Brazil  In Brazil, the prices are regulated through legislation under the name of Medicamento Genérico (generic drugs) since 1999.  India  In India, drug prices are regulated by the National Pharmaceutical Pricing Authority.  United States  In the United States, drug costs are partially unregulated, but instead are the result of negotiations between drug companies and insurance companies.High prices have been attributed to monopolies given to manufacturers by the government. New drug development costs continue to rise as well. Despite the enormous advances in science and technology, the number of new blockbuster drugs approved by the government per billion dollars spent has halved every 9 years since 1950.  Blockbuster drug  A blockbuster drug is a drug that generates more than $1 billion in revenue for a pharmaceutical company in a single year. Cimetidine was the first drug ever to reach more than $1 billion a year in sales, thus making it the first blockbuster drug. In the pharmaceutical industry, a blockbuster drug is one that achieves acceptance by prescribing physicians as a therapeutic standard for, most commonly, a highly prevalent chronic (rather than acute) condition. Patients often take the medicines for long periods.  History   Prescription drug history  Antibiotics first arrived on the medical scene in 1932 thanks to Gerhard Domagk; and were coined the ""wonder drugs"". The introduction of the sulfa drugs led to the mortality rate from pneumonia in the U.S. to drop from 0.2% each year to 0.05% by 1939. Antibiotics inhibit the growth or the metabolic activities of bacteria and other microorganisms by a chemical substance of microbial origin. Penicillin, introduced a few years later, provided a broader spectrum of activity compared to sulfa drugs and reduced side effects. Streptomycin, found in 1942, proved to be the first drug effective against the cause of tuberculosis and also came to be the best known of a long series of important antibiotics. A second generation of antibiotics was introduced in the 1940s: aureomycin and chloramphenicol. Aureomycin was the best known of the second generation. Lithium was discovered in the 19th century for nervous disorders and its possible mood-stabilizing or prophylactic effect; it was cheap and easily produced. As lithium fell out of favor in France, valpromide came into play. This antibiotic was the origin of the drug that eventually created the mood stabilizer category. Valpromide had distinct psychotrophic effects that were of benefit in both the treatment of acute manic states and in the maintenance treatment of manic depression illness. Psychotropics can either be sedative or stimulant; sedatives aim at damping down the extremes of behavior. Stimulants aim at restoring normality by increasing tone. Soon arose the notion of a tranquilizer which was quite different from any sedative or stimulant. The term tranquilizer took over the notions of sedatives and became the dominant term in the West through the 1980s. In Japan, during this time, the term tranquilizer produced the notion of a psyche-stabilizer and the term mood stabilizer vanished.Premarin (conjugated estrogens, introduced in 1942) and Prempro (a combination estrogen-progestin pill, introduced in 1995) dominated the hormone replacement therapy (HRT) during the 1990s. HRT is not a life-saving drug, nor does it cure any disease. HRT has been prescribed to improve one's quality of life. Doctors prescribe estrogen for their older female patients both to treat short-term menopausal symptoms and to prevent long-term diseases. In the 1960s and early 1970s, more and more physicians began to prescribe estrogen for their female patients. between 1991 and 1999, Premarin was listed as the most popular prescription and best-selling drug in America.The first oral contraceptive, Enovid, was approved by FDA in 1960. Oral contraceptives inhibit ovulation and so prevent conception. Enovid was known to be much more effective than alternatives including the condom and the diaphragm. As early as 1960, oral contraceptives were available in several different strengths by every manufacturer. In the 1980s and 1990s, an increasing number of options arose including, most recently, a new delivery system for the oral contraceptive via a transdermal patch. In 1982, a new version of the Pill was introduced, known as the ""biphasic"" pill. By 1985, a new triphasic pill was approved. Physicians began to think of the Pill as an excellent means of birth control for young women.Stimulants such as Ritalin (methylphenidate) came to be pervasive tools for behavior management and modification in young children. Ritalin was first marketed in 1955 for narcolepsy; its potential users were middle-aged and the elderly. It wasn't until some time in the 1980s along with hyperactivity in children that Ritalin came onto the market. Medical use of methlyphenidate is predominantly for symptoms of attention deficit/hyperactivity disorder (ADHD). Consumption of methylphenidate in the U.S. out-paced all other countries between 1991 and 1999. Significant growth in consumption was also evident in Canada, New Zealand, Australia, and Norway. Currently, 85% of the world's methylphenidate is consumed in America.The first minor tranquilizer was Meprobamate. Only fourteen months after it was made available, meprobamate had become the country's largest-selling prescription drug. By 1957, meprobamate had become the fastest-growing drug in history. The popularity of meprobamate paved the way for Librium and Valium, two minor tranquilizers that belonged to a new chemical class of drugs called the benzodiazepines. These were drugs that worked chiefly as anti-anxiety agents and muscle relaxants. The first benzodiazepine was Librium. Three months after it was approved, Librium had become the most prescribed tranquilizer in the nation. Three years later, Valium hit the shelves and was ten times more effective as a muscle relaxant and anti-convulsant. Valium was the most versatile of the minor tranquilizers. Later came the widespread adoption of major tranquilizers such as chlorpromazine and the drug reserpine. In 1970, sales began to decline for Valium and Librium, but sales of new and improved tranquilizers, such as Xanax, introduced in 1981 for the newly created diagnosis of panic disorder, soared.Mevacor (lovastatin) is the first and most influential statin in the American market. The 1991 launch of Pravachol (pravastatin), the second available in the United States, and the release of Zocor (simvastatin) made Mevacor no longer the only statin on the market. In 1998, Viagra was released as a treatment for erectile dysfunction.  Ancient pharmacology  Using plants and plant substances to treat all kinds of diseases and medical conditions is believed to date back to prehistoric medicine. The Kahun Gynaecological Papyrus, the oldest known medical text of any kind, dates to about 1800 BC and represents the first documented use of any kind of drug. It and other medical papyri describe Ancient Egyptian medical practices, such as using honey to treat infections and the legs of bee-eaters to treat neck pains. Ancient Babylonian medicine demonstrated the use of medication in the first half of the 2nd millennium BC. Medicinal creams and pills were employed as treatments.On the Indian subcontinent, the Atharvaveda, a sacred text of Hinduism whose core dates from the second millennium BC, although the hymns recorded in it are believed to be older, is the first Indic text dealing with medicine. It describes plant-based drugs to counter diseases. The earliest foundations of ayurveda were built on a synthesis of selected ancient herbal practices, together with a massive addition of theoretical conceptualizations, new nosologies and new therapies dating from about 400 BC onwards. The student of Āyurveda was expected to know ten arts that were indispensable in the preparation and application of his medicines: distillation, operative skills, cooking, horticulture, metallurgy, sugar manufacture, pharmacy, analysis and separation of minerals, compounding of metals, and preparation of alkalis. The Hippocratic Oath for physicians, attributed to fifth century BC Greece, refers to the existence of ""deadly drugs"", and ancient Greek physicians imported drugs from Egypt and elsewhere. The pharmacopoeia De materia medica, written between 50 and 70 CE by the Greek physician Pedanius Dioscorides, was widely read for more than 1,500 years.  Medieval pharmacology  Al-Kindi's ninth century AD book, De Gradibus and Ibn Sina (Avicenna)'s The Canon of Medicine, covers a range of drugs known to the practice of medicine in the medieval Islamic world. Medieval medicine of Western Europe saw advances in surgery compared to previously, but few truly effective drugs existed, beyond opium (found in such extremely popular drugs as the ""Great Rest"" of the Antidotarium Nicolai at the time) and quinine. Folklore cures and potentially poisonous metal-based compounds were popular treatments. Theodoric Borgognoni, (1205–1296), one of the most significant surgeons of the medieval period, responsible for introducing and promoting important surgical advances including basic antiseptic practice and the use of anaesthetics. Garcia de Orta described some herbal treatments that were used.  Modern pharmacology  For most of the 19th century, drugs were not highly effective, leading Oliver Wendell Holmes, Sr. to famously comment in 1842 that ""if all medicines in the world were thrown into the sea, it would be all the better for mankind and all the worse for the fishes"".: 21 During the First World War, Alexis Carrel and Henry Dakin developed the Carrel-Dakin method of treating wounds with an irrigation, Dakin's solution, a germicide which helped prevent gangrene. In the inter-war period, the first anti-bacterial agents such as the sulpha antibiotics were developed. The Second World War saw the introduction of widespread and effective antimicrobial therapy with the development and mass production of penicillin antibiotics, made possible by the pressures of the war and the collaboration of British scientists with the American pharmaceutical industry. Medicines commonly used by the late 1920s included aspirin, codeine, and morphine for pain; digitalis, nitroglycerin, and quinine for heart disorders, and insulin for diabetes. Other drugs included antitoxins, a few biological vaccines, and a few synthetic drugs. In the 1930s, antibiotics emerged: first sulfa drugs, then penicillin and other antibiotics. Drugs increasingly became ""the center of medical practice"".: 22 In the 1950s, other drugs emerged including corticosteroids for inflammation, rauvolfia alkaloids as tranquilizers and antihypertensives, antihistamines for nasal allergies, xanthines for asthma, and typical antipsychotics for psychosis.: 23–24 As of 2007, thousands of approved drugs have been developed. Increasingly, biotechnology is used to discover biopharmaceuticals. Recently, multi-disciplinary approaches have yielded a wealth of new data on the development of novel antibiotics and antibacterials and on the use of biological agents for antibacterial therapy.In the 1950s, new psychiatric drugs, notably the antipsychotic chlorpromazine, were designed in laboratories and slowly came into preferred use. Although often accepted as an advance in some ways, there was some opposition, due to serious adverse effects such as tardive dyskinesia. Patients often opposed psychiatry and refused or stopped taking the drugs when not subject to psychiatric control. Governments have been heavily involved in the regulation of drug development and drug sales. In the U.S., the Elixir Sulfanilamide disaster led to the establishment of the Food and Drug Administration, and the 1938 Federal Food, Drug, and Cosmetic Act required manufacturers to file new drugs with the FDA. The 1951 Humphrey-Durham Amendment required certain drugs to be sold by prescription. In 1962, a subsequent amendment required new drugs to be tested for efficacy and safety in clinical trials.: 24–26 Until the 1970s, drug prices were not a major concern for doctors and patients. As more drugs became prescribed for chronic illnesses, however, costs became burdensome, and by the 1970s nearly every U.S. state required or encouraged the substitution of generic drugs for higher-priced brand names. This also led to the 2006 U.S. law, Medicare Part D, which offers Medicare coverage for drugs.: 28–29 As of 2008, the United States is the leader in medical research, including pharmaceutical development. U.S. drug prices are among the highest in the world, and drug innovation is correspondingly high. In 2000, U.S.-based firms developed 29 of the 75 top-selling drugs; firms from the second-largest market, Japan, developed eight, and the United Kingdom contributed 10. France, which imposes price controls, developed three. Throughout the 1990s, outcomes were similar.: 30–31  Controversies  Controversies concerning pharmaceutical drugs include patient access to drugs under development and not yet approved, pricing, and environmental issues.  Access to unapproved drugs  Governments worldwide have created provisions for granting access to drugs prior to approval for patients who have exhausted all alternative treatment options and do not match clinical trial entry criteria. Often grouped under the labels of compassionate use, expanded access, or named patient supply, these programs are governed by rules which vary by country defining access criteria, data collection, promotion, and control of drug distribution.Within the United States, pre-approval demand is generally met through treatment IND (investigational new drug) applications (INDs), or single-patient INDs. These mechanisms, which fall under the label of expanded access programs, provide access to drugs for groups of patients or individuals residing in the US. Outside the US, Named Patient Programs provide controlled, pre-approval access to drugs in response to requests by physicians on behalf of specific, or ""named"", patients before those medicines are licensed in the patient's home country. Through these programs, patients are able to access drugs in late-stage clinical trials or approved in other countries for a genuine, unmet medical need, before those drugs have been licensed in the patient's home country. Patients who have not been able to get access to drugs in development have organized and advocated for greater access. In the United States, ACT UP formed in the 1980s, and eventually formed its Treatment Action Group in part to pressure the US government to put more resources into discovering treatments for AIDS and then to speed release of drugs that were under development.The Abigail Alliance was established in November 2001 by Frank Burroughs in memory of his daughter, Abigail. The Alliance seeks broader availability of investigational drugs on behalf of terminally ill patients. In 2013, BioMarin Pharmaceutical was at the center of a high-profile debate regarding expanded access of cancer patients to experimental drugs.  Access to medicines and drug pricing  Essential medicines, as defined by the World Health Organization (WHO), are ""those drugs that satisfy the health care needs of the majority of the population; they should therefore be available at all times in adequate amounts and in appropriate dosage forms, at a price the community can afford."" Recent studies have found that most of the medicines on the WHO essential medicines list, outside of the field of HIV drugs, are not patented in the developing world, and that lack of widespread access to these medicines arise from issues fundamental to economic development – lack of infrastructure and poverty. Médecins Sans Frontières also runs a Campaign for Access to Essential Medicines campaign, which includes advocacy for greater resources to be devoted to currently untreatable diseases that primarily occur in the developing world. The Access to Medicine Index tracks how well pharmaceutical companies make their products available in the developing world. World Trade Organization negotiations in the 1990s, including the TRIPS Agreement and the Doha Declaration, have centered on issues at the intersection of international trade in pharmaceuticals and intellectual property rights, with developed world nations seeking strong intellectual property rights to protect investments made to develop new drugs, and developing world nations seeking to promote their generic pharmaceuticals industries and their ability to make medicine available to their people via compulsory licenses. Some have raised ethical objections specifically with respect to pharmaceutical patents and the high prices for drugs that they enable their proprietors to charge, which poor people around the world, cannot afford. Critics also question the rationale that exclusive patent rights and the resulting high prices are required for pharmaceutical companies to recoup the large investments needed for research and development. One study concluded that marketing expenditures for new drugs often doubled the amount that was allocated for research and development. Other critics claim that patent settlements would be costly for consumers, the health care system, and state and federal governments because it would result in delaying access to lower cost generic medicines.Novartis fought a protracted battle with the government of India over the patenting of its drug, Gleevec, in India, which ended up in a Supreme Court in a case known as Novartis v. Union of India & Others. The Supreme Court ruled narrowly against Novartis, but opponents of patenting drugs claimed it as a major victory.  Environmental issues  The environmental impact of pharmaceuticals and personal care products is controversial. PPCPs are substances used by individuals for personal health or cosmetic reasons and the products used by agribusiness to boost growth or health of livestock. PPCPs comprise a diverse collection of thousands of chemical substances, including prescription and over-the-counter therapeutic drugs, veterinary drugs, fragrances, and cosmetics. PPCPs have been detected in water bodies throughout the world and ones that persist in the environment are called Environmental Persistent Pharmaceutical Pollutants. The effects of these chemicals on humans and the environment are not yet known, but to date there is no scientific evidence that they affect human health.  See also   References   External links  Drug Reference Site Directory | OpenMD Drugs & Medications Directory | Curlie European Medicines Agency NHS Medicines A-Z U.S. Food & Drug Administration: Drugs WHO Model List of Essential Medicines","Medication (also called medicine or pharmaceutical drugs) is the use of legal drugs to treat or cure an illness. Some drugs are freely sold. They are called over-the-counter (OTC) drugs. Other drugs are so powerful or dangerous that a doctor must give permission to use the drug. The note from the doctor is called a ""prescription."" These drugs are called prescription drugs, prescription medicines, or prescription only medicines (POM).  Terminology  There are many different words used to describe important things about medications.  Dosage  Dosage is how much medication needs to be taken to make the medication do what it is supposed to.Dosage is very important because all medicines can be poisons if they are taken in large amounts. If a person takes too much of a medication, they can get very sick or even die. This is called an overdose. For example, if a person takes too much acetaminophen (also called paracetamol, Tylenol, or Panadol), they can badly hurt their liver.Some dosages are based on age. For example, children often need less medication than adults. Others are based on body weight. Sometimes, normal dosages have to be changed if a person has certain medical problems, like kidney failure.  Action  Action is what the medication is supposed to do: the helpful effects that the medicine is supposed to have on the body. Many drugs have more than one action. For example, acetaminophen is an analgesic (it kills pain) and an antipyretic (it makes fevers go away).  Indication  An indication is a reason why a medication is given.Many drugs have more than one indication. For example, acetaminophen's indications include pain and fever.  Contraindication  A contraindication is a reason why a medication should not be given. Almost all medicines, even over-the-counter medications, have some contraindications. For example, acetaminophen should not be given to people who are allergic to acetaminophen. For these people, acetaminophen is ""contraindicated,"" and another medicine should be used instead. Acetaminophen is also contraindicated in people who have liver disease.  Side effects and adverse effects  A person takes a medication because they want it to do certain things. When the medication also does other things that the person did not want, these are called side effects. For example, acetaminophen can cause nausea. This is a side effect of acetaminophen. Adverse effects are side effects that are dangerous or harm the body. For example, in some people, acetaminophen can hurt the liver. This is an adverse effect of acetaminophen. Most medicines have many possible side effects. This does not mean that anyone who takes the medicine will have those side effects. For example, not everyone who takes acetaminophen gets nausea. A side effect is just a possible effect that a medicine can have on the body.  Medication names  All medications have a few different names.  Chemical name  When a medication is first discovered, it is given a chemical name. This name describes the atoms or molecules in the medication. Usually, only scientists use this name.For example, the chemical names for acetaminophen are N-acetyl-para-aminophenol and para-acetyl-amino-phenol.  Generic name  Every country has one generic (official) name for every medicine.In the United States, a medicine is given an official generic name after the Food and Drug Administration (FDA) says a it is safe to be sold. For example, acetaminophen is the official generic name used in the United States. (Paracetamol is the generic name used in the United Kingdom and some other countries.) Sometimes, generic names come from a medicine's chemical name. For example, acetaminophen is named after N-acetyl-para-amino-phenol, and paracetamol is named after para-acetyl-amino-phenol.  Brand name  Each company that makes a drug gives that drug a brand name. No other company is allowed to use this name.For example, in the United States, the most common brand name for acetaminophen is Tylenol. One of the companies that makes acetaminophen (Johnson & Johnson) chose the name ""Tylenol"" for its acetaminophen. Another company that makes acetaminophen (GlaxoSmithKline) chose ""Panadol"" as its brand name. Like with most medicines, there are many other brand names for acetaminophen.  Abbreviations  Some medicines have unofficial abbreviations. For example, acetaminophen is sometimes abbreviated APAP. This comes from the drug's chemical name: N-Acetyl-Para-Amino-Phenol.  All the same medicine  No matter which of these names is used, they all describe the same medicine. For example, there is no difference between N-acetyl-para-aminophenol, acetaminophen, paracetamol, Tylenol, Panadol, and APAP.  How medications are given  There are many ways that medications can be given. These are called ""routes of administration."" For most medications to work, they need to get into the bloodstream. The blood carries the medicine around the body and takes it where it is needed. The way a medication is given affects: The path that the medicine takes to get into the bloodstream and how long this takes How much of the medicine gets into the bloodstream How much of the medicine reaches the tissue where it is needed How long the medicine's effects will last  By mouth  The most common way of giving medicine is by mouth. The medicine comes in a pill or liquid that a person swallows.When taken by mouth, medication gets into the bloodstream through the digestive system. It takes a while, usually 15–20 minutes, for the medicine to get through parts of the digestive system and get taken up into the bloodstream. Also, a very small amount of the medicine actually gets into the bloodstream. This is because acid in the stomach kills most of the medicine before it can be taken up into the bloodstream.Medicines taken by mouth often last longer than medicines taken by other routes of administration.Not every medication can be given by mouth. With some medicines, like insulin, the acid in the stomach will change the medicine or break it down so much that it will not work.  Into a vein  Some medicines can be given through a needle placed into a vein. This way of giving medicine is called intravenous (IV).This is one of the fastest ways to get medicine into the bloodstream. Veins carry blood, so when a medication is given intravenously, it goes right into the bloodstream immediately. It takes less than a minute for blood to flow around the entire body. This means that when given intravenously, a medicine will reach the brain within a minute or less. All of the medicine (100%) gets into the bloodstream.However, IV medications will not last as long as medications given by mouth. This is because the body starts metabolizing medications (breaking them down so the body can get rid of them) as soon as the medicine gets into the bloodstream.Not every medicine can be given intravenously.  Into a muscle  Some medicines can be given through a needle placed into a big muscle, like the muscles in the upper arm, thigh, or buttocks. This way of giving medicine is called intramuscular (IM).When a medicine is given intramuscularly, the medicine gets into the bloodstream through smaller blood vessels in the muscles. This takes longer than an IV injection, because the medicine is not being injected directly into a blood vessel. However, the medicine still reaches the bloodstream faster than medicines given by mouth.Also, not all of the medicine gets into the bloodstream because some of it gets caught in the soft tissue in the muscle and never reaches the blood vessels.  Breathed in  Some special medicines can be breathed in. This way of giving medicines is called by inhalation (sometimes abbreviated INH). This can be especially helpful for lung problems like asthma. Since the medicine is breathed right into the lungs, it can start working on the lungs right away.  Other routes  There are many other routes of administration. For example: Into the bone (intraosseous (IO)). A needle is placed into a large bone, like the femur (thigh bone), and medicines are given into the bone marrow. Any medicine that can be given into a vein can also be given into a bone. Like with IV medicines, all of the medicine gets into the bloodstream, immediately. IO medicines can only be given by certain medical professionals, like doctors and paramedics. Into the rectum (per rectum (PR)). Some medicines can be given into the rectum. The medicine does not get into the bloodstream very quickly. This route is mostly used with people who cannot swallow medicines, like very young children or people who are vomiting (throwing up). Under the skin (subcutaneous (sub-q)). Some special medicines can be given through a needle placed under the skin. For example, insulin is often given this way. Into the nose (intranasal). Some special medicines can be sprayed into the nose. When a medicine is given intranasally, all of the medicine will go to the brain, immediately. For example, naloxone (which is used to treat opiate overdoses) can be given intranasally.There are many other routes of administration.Many medicines can be given more than one way. For example, acetaminophen can be given by mouth, into the rectum, or into a vein.  References "
"An intensive care unit (ICU), also known as an intensive therapy unit or intensive treatment unit (ITU) or critical care unit (CCU), is a special department of a hospital or health care facility that provides intensive care medicine. Intensive care units cater to patients with severe or life-threatening illnesses and injuries, which require constant care, close supervision from life support equipment and medication in order to ensure normal bodily functions. They are staffed by highly trained physicians, nurses and respiratory therapists who specialize in caring for critically ill patients. ICUs are also distinguished from general hospital wards by a higher staff-to-patient ratio and access to advanced medical resources and equipment that is not routinely available elsewhere. Common conditions that are treated within ICUs include respiratory and cardiovascular , as well as neurology . Patients may be referred directly from an emergency department or from a ward if they rapidly deteriorate, or immediately after surgery if the surgery is very invasive and the patient is at high risk of complications.  History  In 1854, Florence Nightingale left for the Crimean War, where triage was used to separate seriously wounded soldiers from those with non-life-threatening conditions. Until recently, it was reported that Nightingale’s method reduced mortality from 40% to 2% on the battlefield. Although this was not the case, her experiences during the war formed the foundation for her later discovery of the importance of sanitary conditions in hospitals, a critical component of intensive care. In 1950, anesthesiologist Peter Safar established the concept of advanced life support, keeping patients sedated and ventilated in an intensive care environment. Safar is considered to be the first practitioner of intensive care medicine as a speciality. In response to a polio epidemic (where many patients required constant ventilation and surveillance), Bjørn Aage Ibsen established the first intensive care unit globally in Copenhagen in 1953.The first application of this idea in the United States was in 1955 by William Mosenthal, a surgeon at the Dartmouth-Hitchcock Medical Center. In the 1960s, the importance of cardiac arrhythmias as a source of morbidity and mortality in myocardial infarctions (heart attacks) was recognized. This led to the routine use of cardiac monitoring in ICUs, especially after heart attacks.  Types  Hospitals may have various specialized ICUs that cater to a specific medical requirement or patient:  Equipment and systems  Common equipment in an ICU includes mechanical ventilators to assist breathing through an endotracheal tube or a tracheostomy tube; cardiac monitors for monitoring Cardiac condition; equipment for the constant monitoring of bodily functions; a web of intravenous lines, feeding tubes, nasogastric tubes, suction pumps, drains, and catheters, syringe pumps; and a wide array of drugs to treat the primary condition(s) of hospitalization. Medically induced comas, analgesics, and induced sedation are common ICU tools needed and used to reduce pain and prevent secondary infections.  Quality of care  The available data suggests a relation between ICU volume and quality of care for mechanically ventilated patients. After adjustment for severity of illnesses, demographic variables, and characteristics of different ICUs (including staffing by intensivists), higher ICU staffing was significantly associated with lower ICU and hospital mortality rates. A ratio of 2 patients to 1 nurse is recommended for a medical ICU, which contrasts to the ratio of 4:1 or 5:1 typically seen on medical floors. This varies from country to country, though; e.g., in Australia and the United Kingdom, most ICUs are staffed on a 2:1 basis (for high-dependency patients who require closer monitoring or more intensive treatment than a hospital ward can offer) or on a 1:1 basis for patients requiring extreme intensive support and monitoring; for example, a patient on a mechanical ventilator with associated anaesthetics or sedation such as propofol, midazolam and use of strong analgesics such as morphine, fentanyl and/or remifentanil. International guidelines recommend that every patient gets checked for delirium every day (usually twice or as much required) using a validated clinical tool. The two most widely used are the Confusion Assessment Method for the ICU (CAM-ICU) and the Intensive Care Delirium Screening Checklist (ICDSC). There are translations of these tools in over 20 languages and they are used globally in many ICU's.  Operational logistics  In the United States, up to 20% of hospital beds can be labelled as intensive-care beds; in the United Kingdom, intensive care usually will comprise only up to 2% of total beds. This high disparity is attributed to admission of patients in the UK only when considered the most severely ill.Intensive care is an expensive healthcare service. A recent study conducted in the United States found that hospital stays involving ICU services were 2.5 times more costly than other hospital stays.In the United Kingdom in 2003–04, the average cost of funding an intensive care unit was: £838 per bed per day for a neonatal intensive care unit £1,702 per bed per day for a pediatric intensive care unit £1,328 per bed per day for an adult intensive care unit  Remote collaboration systems  Some hospitals have installed teleconferencing systems that allow doctors and nurses at a central facility (either in the same building, at a central location serving several local hospitals, or in rural locations another more urban facility) to collaborate with on-site staff and speak with patients (a form of telemedicine). This is variously called an eICU, virtual ICU, or tele-ICU. Remote staff typically have access to vital signs from live monitoring systems, and telectronic health records so they may have access to a broader view of a patient's medical history. Often bedside and remote staff have met in person and may rotate responsibilities. Such systems are beneficial to intensive care units in order to ensure correct procedures are being followed for patients vulnerable to deterioration, to access vital signs remotely in order to keep patients that would have to be transferred to a larger facility if need be he/she may have demonstrated a significant decrease in stability.  See also  ICU quality and management tools Intensive Care Foundation, a charity in Australia and New Zealand Intensive Care Medicine (journal) Open-source ventilator  References   Further reading  Lois Reynolds; Tilli Tansey, eds. (2011). History of British Intensive Care, c. 1950–c. 2000. Wellcome Witnesses to Contemporary Medicine. History of Modern Biomedicine Research Group. ISBN 978-0-902238-75-6. Wikidata Q29581786.  External links  ""Intensive Care"". NHS choices. UK: National Health Service. 2017-10-18. ""Critical Care"". MedlinePlus. US: National Library of Medicine, National Institutes of Health. Society of Critical Care Medicine ICUsteps – Intensive care patient support charity Organisation for Critical Care Transportation Archived 2011-09-04 at the Wayback Machine Reynolds, H.N.; Rogove, H.; Bander, J.; McCambridge, M.; et al. (December 2011). ""A working lexicon for the tele-intensive care unit: We need to define tele-intensive care unit to grow and understand it"" (PDF). Telemedicine and E-Health. 17 (10): 773–783. doi:10.1089/tmj.2011.0045. hdl:2027.42/90470. PMID 22029748. Olson, Terrah J. Paul; Brasel, Karen J.; Redmann, Andrew J.; Alexander, G. Caleb; Schwarze, Margaret L. (January 2013). ""Surgeon-Reported Conflict With Intensivists About Postoperative Goals of Care"". JAMA Surgery. 148 (1): 29–35. doi:10.1001/jamasurgery.2013.403. PMC 3624604. PMID 23324837.","An intensive care unit (ICU), critical care unit (CCU), intensive therapy unit (ITU), or intensive treatment unit (ITU) is a special part of a hospital. Usually, people that are very sick are sent there. They need to be looked at by a nurse or doctor very closely in case they get more sick while at the hospital. Some ICUs may work with only one type of injuries.  History  In 1854, Florence Nightingale went to the Crimean War. There it was important to separate seriously wounded soldiers from less-seriously wounded. Nightingale reduced death rates from 40% to 2% by creating the concept of intensive care. Because of a polio epidemic, Bjørn Ibsen established the first intensive care unit in Copenhagen in 1953. Patients with polio require more ventilation than normal; this is why Ibsen set up a special unit for them. The first person to use this idea in the United States was Dr. William Mosenthal, a surgeon at the Dartmouth-Hitchcock Medical Center.  References "
"A hospital is a health care institution providing patient treatment with specialized health science and auxiliary healthcare staff and medical equipment. The best-known type of hospital is the general hospital, which typically has an emergency department to treat urgent health problems ranging from fire and accident victims to a sudden illness. A district hospital typically is the major health care facility in its region, with many beds for intensive care and additional beds for patients who need long-term care. Specialized hospitals include trauma centers, rehabilitation hospitals, children's hospitals, seniors' (geriatric) hospitals, and hospitals for dealing with specific medical needs such as psychiatric treatment (see psychiatric hospital) and certain disease categories. Specialized hospitals can help reduce health care costs compared to general hospitals. Hospitals are classified as general, specialty, or government depending on the sources of income received. A teaching hospital combines assistance to people with teaching to health science students and auxiliary healthcare students. A health science facility smaller than a hospital is generally called a clinic. Hospitals have a range of departments (e.g. surgery and urgent care) and specialist units such as cardiology. Some hospitals have outpatient departments and some have chronic treatment units. Common support units include a pharmacy, pathology, and radiology. Hospitals are typically funded by public funding, health organisations (for-profit or nonprofit), health insurance companies, or charities, including direct charitable donations. Historically, hospitals were often founded and funded by religious orders, or by charitable individuals and leaders.Currently, hospitals are largely staffed by professional physicians, surgeons, nurses, and allied health practitioners, whereas in the past, this work was usually performed by the members of founding religious orders or by volunteers. However, there are various Catholic religious orders, such as the Alexians and the Bon Secours Sisters that still focus on hospital ministry in the late 1990s, as well as several other Christian denominations, including the Methodists and Lutherans, which run hospitals. In accordance with the original meaning of the word, hospitals were original ""places of hospitality"", and this meaning is still preserved in the names of some institutions such as the Royal Hospital Chelsea, established in 1681 as a retirement and nursing home for veteran soldiers.  Etymology  During the Middle Ages, hospitals served different functions from modern institutions in that they were almshouses for the poor, hostels for pilgrims, or hospital schools. The word ""hospital"" comes from the Latin hospes, signifying a stranger or foreigner, hence a guest. Another noun derived from this, hospitium came to signify hospitality, that is the relation between guest and shelterer, hospitality, friendliness, and hospitable reception. By metonymy, the Latin word then came to mean a guest-chamber, guest's lodging, an inn. Hospes is thus the root for the English words host (where the p was dropped for convenience of pronunciation) hospitality, hospice, hostel, and hotel. The latter modern word derives from Latin via the Old French romance word hostel, which developed a silent s, which letter was eventually removed from the word, the loss of which is signified by a circumflex in the modern French word hôtel. The German word Spital shares similar roots.  Types  Some patients go to a hospital just for diagnosis, treatment, or therapy and then leave (""outpatients"") without staying overnight; while others are ""admitted"" and stay overnight or for several days or weeks or months (""inpatients""). Hospitals are usually distinguished from other types of medical facilities by their ability to admit and care for inpatients whilst the others, which are smaller, are often described as clinics.  General and acute care  The best-known type of hospital is the general hospital, also known as an acute-care hospital. These facilities handle many kinds of disease and injury, and normally have an emergency department (sometimes known as ""accident & emergency"") or trauma center to deal with immediate and urgent threats to health. Larger cities may have several hospitals of varying sizes and facilities. Some hospitals, especially in the United States and Canada, have their own ambulance service.  District  A district hospital typically is the major health care facility in its region, with large numbers of beds for intensive care, critical care, and long-term care. In California, ""district hospital"" refers specifically to a class of healthcare facility created shortly after World War II to address a shortage of hospital beds in many local communities. Even today, district hospitals are the sole public hospitals in 19 of California's counties, and are the sole locally accessible hospital within nine additional counties in which one or more other hospitals are present at a substantial distance from a local community. Twenty-eight of California's rural hospitals and 20 of its critical-access hospitals are district hospitals. They are formed by local municipalities, have boards that are individually elected by their local communities, and exist to serve local needs. They are a particularly important provider of healthcare to uninsured patients and patients with Medi-Cal (which is California's Medicaid program, serving low-income persons, some senior citizens, persons with disabilities, children in foster care, and pregnant women). In 2012, district hospitals provided $54 million in uncompensated care in California.  Specialized  A specialty hospital is primarily and exclusively dedicated to one or a few related medical specialties. Subtypes include rehabilitation hospitals, children's hospitals, seniors' (geriatric) hospitals, long-term acute care facilities, and hospitals for dealing with specific medical needs such as psychiatric problems (see psychiatric hospital), cancer treatment, certain disease categories such as cardiac, oncology, or orthopedic problems, and so forth. In Germany specialised hospitals are called Fachkrankenhaus; an example is Fachkrankenhaus Coswig (thoracic surgery). In India, specialty hospitals are known as super-specialty hospitals and are distinguished from multispecialty hospitals which are composed of several specialties.Specialised hospitals can help reduce health care costs compared to general hospitals. For example, Narayana Health's cardiac unit in Bangalore specialises in cardiac surgery and allows for a significantly greater number of patients. It has 3,000 beds and performs 3,000 in paediatric cardiac operations annually, the largest number in the world for such a facility. Surgeons are paid on a fixed salary instead of per operation, thus when the number of procedures increases, the hospital is able to take advantage of economies of scale and reduce its cost per procedure. Each specialist may also become more efficient by working on one procedure like a production line.  Teaching  A teaching hospital delivers healthcare to patients as well as training to prospective Medical Professionals such as medical students and student nurses. It may be linked to a medical school or nursing school, and may be involved in medical research. Students may also observe clinical work in the hospital.  Clinics  Clinics generally provide only outpatient services, but some may have a few inpatient beds and a limited range of services that may otherwise be found in typical hospitals.  Departments or wards  A hospital contains one or more wards that house hospital beds for inpatients. It may also have acute services such as an emergency department, operating theatre, and intensive care unit, as well as a range of medical specialty departments. A well-equipped hospital may be classified as a trauma center. They may also have other services such as a hospital pharmacy, radiology, pathology, and medical laboratories. Some hospitals have outpatient departments such as behavioral health services, dentistry, and rehabilitation services. A hospital may also have a department of nursing, headed by a chief nursing officer or director of nursing. This department is responsible for the administration of professional nursing practice, research, and policy for the hospital. Many units have both a nursing and a medical director that serve as administrators for their respective disciplines within that unit. For example, within an intensive care nursery, a medical director is responsible for physicians and medical care, while the nursing manager is responsible for all the nurses and nursing care. Support units may include a medical records department, release of information department, technical support, clinical engineering, facilities management, plant operations, dining services, and security departments.  Remote monitoring  The COVID-19 pandemic stimulated the development of virtual wards across the British NHS. Patients are managed at home, monitoring their own oxygen levels using an oxygen saturation probe if necessary and supported by telephone. West Hertfordshire Hospitals NHS Trust managed around 1200 patients at home between March and June 2020 and planned to continue the system after COVID-19, initially for respiratory patients. Mersey Care NHS Foundation Trust started a COVID Oximetry@Home service in April 2020. This enables them to monitor more than 5000 patients a day in their own homes. The technology allows nurses, carers, or patients to record and monitor vital signs such as blood oxygen levels.  History   Early examples  In early India, Fa Xian, a Chinese Buddhist monk who travelled across India c. AD 400, recorded examples of healing institutions. According to the Mahavamsa, the ancient chronicle of Sinhalese royalty, written in the sixth century AD, King Pandukabhaya of Sri Lanka (r. 437–367 BC) had lying-in-homes and hospitals (Sivikasotthi-Sala). A hospital and medical training centre also existed at Gundeshapur, a major city in southwest of the Sassanid Persian Empire founded in AD 271 by Shapur I. In ancient Greece, temples dedicated to the healer-god Asclepius, known as Asclepeion functioned as centres of medical advice, prognosis, and healing. The Asclepeia spread to the Roman Empire. While public healthcare was non-existent in the Roman Empire, military hospitals called valetudinaria did exist stationed in military barracks and would serve the soldiers and slaves within the fort. Evidence exists that some civilian hospitals, while unavailable to the Roman population, were occasionally privately built in extremely wealthy Roman households located in the countryside for that family, although this practice seems to have ended in 80 AD.  Middle Ages  The declaration of Christianity as an accepted religion in the Roman Empire drove an expansion of the provision of care. Following the First Council of Nicaea in AD 325 construction of a hospital in every cathedral town was begun, including among the earliest hospitals by Saint Sampson in Constantinople and by Basil, bishop of Caesarea in modern-day Turkey. By the twelfth century, Constantinople had two well-organised hospitals, staffed by doctors who were both male and female. Facilities included systematic treatment procedures and specialised wards for various diseases. The earliest general hospital in the Islamic world was built in 805 in Baghdad by Harun Al-Rashid. By the 10th century, Baghdad had five more hospitals, while Damascus had six hospitals by the 15th century, and Córdoba alone had 50 major hospitals, many exclusively for the military. The Islamic bimaristan served as a center of medical treatment, as well nursing home and lunatic asylum. It typically treated the poor, as the rich would have been treated in their own homes. Hospitals in this era were the first to require medical diplomas to license doctors, and compensation for negligence could be made. Hospitals were forbidden by law to turn away patients who were unable to pay. These hospitals were financially supported by waqfs, as well as state funds.  Early modern and Enlightenment Europe  In Europe the medieval concept of Christian care evolved during the sixteenth and seventeenth centuries into a secular one. In England, after the dissolution of the monasteries in 1540 by King Henry VIII, the church abruptly ceased to be the supporter of hospitals, and only by direct petition from the citizens of London, were the hospitals St Bartholomew's, St Thomas's and St Mary of Bethlehem's (Bedlam) endowed directly by the crown; this was the first instance of secular support being provided for medical institutions. The voluntary hospital movement began in the early 18th century, with hospitals being founded in London by the 1720s, including Westminster Hospital (1719) promoted by the private bank C. Hoare & Co and Guy's Hospital (1724) funded from the bequest of the wealthy merchant, Thomas Guy. Other hospitals sprang up in London and other British cities over the century, many paid for by private subscriptions. St Bartholomew's in London was rebuilt from 1730 to 1759, and the London Hospital, Whitechapel, opened in 1752. These hospitals represented a turning point in the function of the institution; they began to evolve from being basic places of care for the sick to becoming centres of medical innovation and discovery and the principal place for the education and training of prospective practitioners. Some of the era's greatest surgeons and doctors worked and passed on their knowledge at the hospitals. They also changed from being mere homes of refuge to being complex institutions for the provision of medicine and care for sick. The Charité was founded in Berlin in 1710 by King Frederick I of Prussia as a response to an outbreak of plague. The concept of voluntary hospitals also spread to Colonial America; the Bellevue Hospital opened in 1736 (as a workhouse, then later becoming a hospital); the Pennsylvania Hospital opened in 1752, New York Hospital (now Weill Cornell Medical Center) in 1771, and Massachusetts General Hospital in 1811. When the Vienna General Hospital opened in 1784 (instantly becoming the world's largest hospital), physicians acquired a new facility that gradually developed into one of the most important research centres.Another Enlightenment era charitable innovation was the dispensary; these would issue the poor with medicines free of charge. The London Dispensary opened its doors in 1696 as the first such clinic in the British Empire. The idea was slow to catch on until the 1770s, when many such organisations began to appear, including the Public Dispensary of Edinburgh (1776), the Metropolitan Dispensary and Charitable Fund (1779) and the Finsbury Dispensary (1780). Dispensaries were also opened in New York 1771, Philadelphia 1786, and Boston 1796.The Royal Naval Hospital, Stonehouse, Plymouth, was a pioneer of hospital design in having ""pavilions"" to minimize the spread of infection. John Wesley visited in 1785, and commented ""I never saw anything of the kind so complete; every part is so convenient, and so admirably neat. But there is nothing superfluous, and nothing purely ornamented, either within or without."" This revolutionary design was made more widely known by John Howard, the philanthropist. In 1787 the French government sent two scholar administrators, Coulomb and Tenon, who had visited most of the hospitals in Europe. They were impressed and the ""pavilion"" design was copied in France and throughout Europe.  19th century  English physician Thomas Percival (1740–1804) wrote a comprehensive system of medical conduct, Medical Ethics; or, a Code of Institutes and Precepts, Adapted to the Professional Conduct of Physicians and Surgeons (1803) that set the standard for many textbooks. In the mid-19th century, hospitals and the medical profession became more professionalised, with a reorganisation of hospital management along more bureaucratic and administrative lines. The Apothecaries Act 1815 made it compulsory for medical students to practise for at least half a year at a hospital as part of their training.Florence Nightingale pioneered the modern profession of nursing during the Crimean War when she set an example of compassion, commitment to patient care and diligent and thoughtful hospital administration. The first official nurses' training programme, the Nightingale School for Nurses, was opened in 1860, with the mission of training nurses to work in hospitals, to work with the poor and to teach. Nightingale was instrumental in reforming the nature of the hospital, by improving sanitation standards and changing the image of the hospital from a place the sick would go to die, to an institution devoted to recuperation and healing. She also emphasised the importance of statistical measurement for determining the success rate of a given intervention and pushed for administrative reform at hospitals.By the late 19th century, the modern hospital was beginning to take shape with a proliferation of a variety of public and private hospital systems. By the 1870s, hospitals had more than trebled their original average intake of 3,000 patients. In continental Europe the new hospitals generally were built and run from public funds. The National Health Service, the principal provider of health care in the United Kingdom, was founded in 1948. During the nineteenth century, the Second Viennese Medical School emerged with the contributions of physicians such as Carl Freiherr von Rokitansky, Josef Škoda, Ferdinand Ritter von Hebra, and Ignaz Philipp Semmelweis. Basic medical science expanded and specialisation advanced. Furthermore, the first dermatology, eye, as well as ear, nose, and throat clinics in the world were founded in Vienna, being considered as the birth of specialised medicine.  20th century and beyond  By the late 19th and early 20th centuries, medical advancements such as anesthesia and sterile techniques that could make surgery less risky, and the availability of more advanced diagnostic devices such as X-rays, continued to make hospitals a more attractive option for treatment.Modern hospitals measure various efficiency metrics such as occupancy rates, the average length of stay, time to service, patient satisfaction, physician performance, patient readmission rate, inpatient mortality rate, and case mix index.In the United States, the number of hospitalizations continued to grow and reached its peak in 1981 with 171 admissions per 1,000 Americans and 6,933 hospitals. This trend subsequently reversed, with the rate of hospitalization falling by more than 10% and the number of US hospitals shrinking from 6,933 in 1981 to 5,534 in 2016. Occupancy rates also dropped from 77% in 1980 to 60% in 2013. Among the reasons for this are the increasing availability of more complex care elsewhere such as at home or the physicians' offices and also the less therapeutic and more life-threatening image of the hospitals in the eyes of the public. In the US, a patient may sleep in a hospital bed, but be considered outpatient and ""under observation"" if not formally admitted. In the US, inpatient stays are covered under Medicare Part A, but a hospital might keep a patient under observation which is only covered under Medicare Part B, and subjects the patient to additional coinsurance costs. In 2013, the Center for Medicare and Medicaid Services (CMS) introduced a ""two-midnight"" rule for inpatient admissions, intended to reduce an increasing number of long-term ""observation"" stays being used for reimbursement. This rule was later dropped in 2018. In 2016 and 2017, healthcare reform and a continued decline in admissions resulted in US hospital-based healthcare systems performing poorly financially. Microhospitals, with bed capacities of between eight and fifty, are expanding in the United States. Similarly, freestanding emergency rooms, which transfer patients that require inpatient care to hospitals, were popularised in the 1970s and have since expanded rapidly across the United States.  Funding  Modern hospitals derive funding from a variety of sources. They may be funded by private payment and health insurance or public expenditure, charitable donations. In the United Kingdom, the National Health Service delivers health care to legal residents funded by the state ""free at the point of delivery"", and emergency care free to anyone regardless of nationality or status. Due to the need for hospitals to prioritise their limited resources, there is a tendency in countries with such systems for 'waiting lists' for non-crucial treatment, so those who can afford it may take out private health care to access treatment more quickly.In the United States, hospitals typically operate privately and in some cases on a for-profit basis, such as HCA Healthcare. The list of procedures and their prices are billed with a chargemaster; however, these prices may be lower for health care obtained within healthcare networks. Legislation requires hospitals to provide care to patients in life-threatening emergency situations regardless of the patient's ability to pay. Privately funded hospitals which admit uninsured patients in emergency situations incur direct financial losses, such as in the aftermath of Hurricane Katrina.  Quality and safety  As the quality of health care has increasingly become an issue around the world, hospitals have increasingly had to pay serious attention to this matter. Independent external assessment of quality is one of the most powerful ways to assess this aspect of health care, and hospital accreditation is one means by which this is achieved. In many parts of the world such accreditation is sourced from other countries, a phenomenon known as international healthcare accreditation, by groups such as Accreditation Canada from Canada, the Joint Commission from the US, the Trent Accreditation Scheme from Great Britain, and the Haute Autorité de santé (HAS) from France. In England hospitals are monitored by the Care Quality Commission. In 2020 they turned their attention to hospital food standards after seven patient deaths from listeria linked to pre-packaged sandwiches and salads in 2019, saying ""Nutrition and hydration is part of a patient's recovery.""The World Health Organization noted in 2011 that going into hospital was far riskier than flying. Globally the chance of a patient being subject to an error was about 10% and the chance of death resulting from an error was about 1 in 300 according to Liam Donaldson. 7% of hospitalised patients in developed countries, and 10% in developing countries, acquire at least one health care-associated infection. In the US 1.7 million infections are acquired in hospital each year, leading to 100,000 deaths, figures much worse than in Europe where there were 4.5 million infections and 37,000 deaths.  Architecture  Modern hospital buildings are designed to minimise the effort of medical personnel and the possibility of contamination while maximising the efficiency of the whole system. Travel time for personnel within the hospital and the transportation of patients between units is facilitated and minimised. The building also should be built to accommodate heavy departments such as radiology and operating rooms while space for special wiring, plumbing, and waste disposal must be allowed for in the design.However, many hospitals, even those considered ""modern"", are the product of continual and often badly managed growth over decades or even centuries, with utilitarian new sections added on as needs and finances dictate. As a result, Dutch architectural historian Cor Wagenaar has called many hospitals: ""... built catastrophes, anonymous institutional complexes run by vast bureaucracies, and totally unfit for the purpose they have been designed for ... They are hardly ever functional, and instead of making patients feel at home, they produce stress and anxiety."" Some newer hospitals now try to re-establish design that takes the patient's psychological needs into account, such as providing more fresh air, better views and more pleasant colour schemes. These ideas harken back to the late eighteenth century, when the concept of providing fresh air and access to the 'healing powers of nature' were first employed by hospital architects in improving their buildings.The research of British Medical Association is showing that good hospital design can reduce patient's recovery time. Exposure to daylight is effective in reducing depression. Single-sex accommodation help ensure that patients are treated in privacy and with dignity. Exposure to nature and hospital gardens is also important – looking out windows improves patients' moods and reduces blood pressure and stress level. Open windows in patient rooms have also demonstrated some evidence of beneficial outcomes by improving airflow and increased microbial diversity. Eliminating long corridors can reduce nurses' fatigue and stress.Another ongoing major development is the change from a ward-based system (where patients are accommodated in communal rooms, separated by movable partitions) to one in which they are accommodated in individual rooms. The ward-based system has been described as very efficient, especially for the medical staff, but is considered to be more stressful for patients and detrimental to their privacy. A major constraint on providing all patients with their own rooms is however found in the higher cost of building and operating such a hospital; this causes some hospitals to charge for private rooms.  See also  Burn center History of hospitals History of medicine Hospital network Lists of hospitals Hospital information system Trauma center The Waiting Room Hospice Walk-in clinic  Notes   References  ""Hospitals Database"". World Health Organization. ""Medicover Hospitals india"". Medicover Hospitals.  Bibliography   History of hospitals  Brockliss, Lawrence, and Colin Jones. ""The Hospital in the Enlightenment,"" in The Medical World of Early Modern France (Oxford UP, 1997), pp. 671–729; covers France 1650–1800 Chaney, Edward (2000),""'Philanthropy in Italy': English Observations on Italian Hospitals 1545–1789"", in: The Evolution of the Grand Tour: Anglo-Italian Cultural Relations since the Renaissance, 2nd ed. London, Routledge, 2000. https://books.google.com/books/about/The_evolution_of_the_grand_tour.html?idrYB_HYPsa8gC Connor, J.T.H. ""Hospital History in Canada and the United States,"" Canadian Bulletin of Medical History, 1990, Vol. 7 Issue 1, pp. 93–104 Crawford, D.S. Bibliography of Histories of Canadian hospitals and schools of nursing. Gorsky, Martin. ""The British National Health Service 1948–2008: A Review of the Historiography,"" Social History of Medicine, December 2008, Vol. 21 Issue 3, pp. 437–60 Harrison, Mar, et al. eds. From Western Medicine to Global Medicine: The Hospital Beyond the West (2008) Horden, Peregrine. Hospitals and Healing From Antiquity to the Later Middle Ages (2008) McGrew, Roderick E. Encyclopedia of Medical History (1985) Morelon, Régis; Rashed, Roshdi (1996), Encyclopedia of the History of Arabic Science, vol. 3, Routledge, ISBN 978-0-415-12410-2 Porter, Roy. The Hospital in History, with Lindsay Patricia Granshaw (1989) ISBN 978-0-415-00375-9 Risse, Guenter B. Mending Bodies, Saving Souls: A History of Hospitals (1999); world coverage Rosenberg, Charles E. The Care of Strangers: The Rise of America's Hospital System (1995); history to 1920 Scheutz, Martin et al. eds. Hospitals and Institutional Care in Medieval and Early Modern Europe (2009) Wall, Barbra Mann. American Catholic Hospitals: A Century of Changing Markets and Missions (Rutgers University Press, 2011). ISBN 978-0-8135-4940-8  External links  WHO Hospitals https://www.who.int/hospitals/en/ ""Global and Multilanguage Database of public and private hospitals"". hospitalsworldguide.com. ""Directory and Ranking of more than 17.000 Hospitals worldwide"". hospitals.webometrics.info. Archived from the original on 21 April 2010. Retrieved 7 November 2008.","A hospital is a place where a person goes to be healed when he or she is sick or injured. The difference between a hospital and other healthcare places like a clinic or a doctor's office is that a hospital will have beds where patients can stay overnight. These patients are called inpatients. The goal of inpatient treatment is to provide 24-7 medical stabilization, which is why this type of treatment has more of a hospital-like feel since patients are monitored by doctors, nurses, therapists, and social workers. Treatment is structured and has a schedule that can include individual therapy, group therapy, case management, and support groups.Hospitals also treat people who do not stay overnight, called outpatients. Doctors and nurses work at hospitals. Doctors make use of advanced medical technology to heal patients. Patients who are staying at the hospital will always be under the care of doctors and nurses who are always available for taking care of the injured or sick patients. Hospitals always have the tools and machines needed for treating the patients. The word hospital originally meant ""a place where people can stay"". There have been hospitals for sick people since ancient times. They were often created and run by religious groups. In the early modern period, hospitals began to be funded by donations from rich people and by governments. Today, hospitals might get money from the government, from charging patients for treatments and check-ups, from patients' health insurance, from people giving to charity or a mixture of those things.  Related pages  Intensive care unit  References   Other websites  Media related to Hospitals at Wikimedia Commons"
"The respiratory system (also respiratory apparatus, ventilatory system) is a biological system consisting of specific organs and structures used for gas exchange in animals and plants. The anatomy and physiology that make this happen varies greatly, depending on the size of the organism, the environment in which it lives and its evolutionary history. In land animals the respiratory surface is internalized as linings of the lungs. Gas exchange in the lungs occurs in millions of small air sacs; in mammals and reptiles these are called alveoli, and in birds they are known as atria. These microscopic air sacs have a very rich blood supply, thus bringing the air into close contact with the blood. These air sacs communicate with the external environment via a system of airways, or hollow tubes, of which the largest is the trachea, which branches in the middle of the chest into the two main bronchi. These enter the lungs where they branch into progressively narrower secondary and tertiary bronchi that branch into numerous smaller tubes, the bronchioles. In birds the bronchioles are termed parabronchi. It is the bronchioles, or parabronchi that generally open into the microscopic alveoli in mammals and atria in birds. Air has to be pumped from the environment into the alveoli or atria by the process of breathing which involves the muscles of respiration. In most fish, and a number of other aquatic animals (both vertebrates and invertebrates) the respiratory system consists of gills, which are either partially or completely external organs, bathed in the watery environment. This water flows over the gills by a variety of active or passive means. Gas exchange takes place in the gills which consist of thin or very flat filaments and lammelae which expose a very large surface area of highly vascularized tissue to the water. Other animals, such as insects, have respiratory systems with very simple anatomical features, and in amphibians even the skin plays a vital role in gas exchange. Plants also have respiratory systems but the directionality of gas exchange can be opposite to that in animals. The respiratory system in plants includes anatomical features such as stomata, that are found in various parts of the plant.  Mammals   Anatomy  In humans and other mammals, the anatomy of a typical respiratory system is the respiratory tract. The tract is divided into an upper and a lower respiratory tract. The upper tract includes the nose, nasal cavities, sinuses, pharynx and the part of the larynx above the vocal folds. The lower tract (Fig. 2.) includes the lower part of the larynx, the trachea, bronchi, bronchioles and the alveoli. The branching airways of the lower tract are often described as the respiratory tree or tracheobronchial tree (Fig. 2). The intervals between successive branch points along the various branches of ""tree"" are often referred to as branching ""generations"", of which there are, in the adult human about 23. The earlier generations (approximately generations 0–16), consisting of the trachea and the bronchi, as well as the larger bronchioles which simply act as air conduits, bringing air to the respiratory bronchioles, alveolar ducts and alveoli (approximately generations 17–23), where gas exchange takes place. Bronchioles are defined as the small airways lacking any cartilaginous support.The first bronchi to branch from the trachea are the right and left main bronchi. Second, only in diameter to the trachea (1.8 cm), these bronchi (1 -1.4 cm in diameter) enter the lungs at each hilum, where they branch into narrower secondary bronchi known as lobar bronchi, and these branch into narrower tertiary bronchi known as segmental bronchi. Further divisions of the segmental bronchi (1 to 6 mm in diameter) are known as 4th order, 5th order, and 6th order segmental bronchi, or grouped together as subsegmental bronchi.Compared to the 23 number (on average) of branchings of the respiratory tree in the adult human, the mouse has only about 13 such branchings. The alveoli are the dead end terminals of the ""tree"", meaning that any air that enters them has to exit via the same route. A system such as this creates dead space, a volume of air (about 150 ml in the adult human) that fills the airways after exhalation and is breathed back into the alveoli before environmental air reaches them. At the end of inhalation the airways are filled with environmental air, which is exhaled without coming in contact with the gas exchanger.  Ventilatory volumes  The lungs expand and contract during the breathing cycle, drawing air in and out of the lungs. The volume of air moved in or out of the lungs under normal resting circumstances (the resting tidal volume of about 500 ml), and volumes moved during maximally forced inhalation and maximally forced exhalation are measured in humans by spirometry. A typical adult human spirogram with the names given to the various excursions in volume the lungs can undergo is illustrated below (Fig. 3): Not all the air in the lungs can be expelled during maximally forced exhalation(ERV). This is the residual volume(volume of air remaining even after a forced exhalation) of about 1.0-1.5 liters which cannot be measured by spirometry. Volumes that include the residual volume (i.e. functional residual capacity of about 2.5-3.0 liters, and total lung capacity of about 6 liters) can therefore also not be measured by spirometry. Their measurement requires special techniques.The rates at which air is breathed in or out, either through the mouth or nose or into or out of the alveoli are tabulated below, together with how they are calculated. The number of breath cycles per minute is known as the respiratory rate. An average healthy human breathes 12-16 times a minute.  Mechanics of breathing  In mammals, inhalation at rest is primarily due to the contraction of the diaphragm. This is an upwardly domed sheet of muscle that separates the thoracic cavity from the abdominal cavity. When it contracts the sheet flattens, (i.e. moves downwards as shown in Fig. 7) increasing the volume of the thoracic cavity in the antero-posterior axis. The contracting diaphragm pushes the abdominal organs downwards. But because the pelvic floor prevents the lowermost abdominal organs from moving in that direction, the pliable abdominal contents cause the belly to bulge outwards to the front and sides, because the relaxed abdominal muscles do not resist this movement (Fig. 7). This entirely passive bulging (and shrinking during exhalation) of the abdomen during normal breathing is sometimes referred to as ""abdominal breathing"", although it is, in fact, ""diaphragmatic breathing"", which is not visible on the outside of the body. Mammals only use their abdominal muscles during forceful exhalation (see Fig. 8, and discussion below). Never during any form of inhalation. As the diaphragm contracts, the rib cage is simultaneously enlarged by the ribs being pulled upwards by the intercostal muscles as shown in Fig. 4. All the ribs slant downwards from the rear to the front (as shown in Fig. 4); but the lowermost ribs also slant downwards from the midline outwards (Fig. 5). Thus the rib cage\'s transverse diameter can be increased in the same way as the antero-posterior diameter is increased by the so-called pump handle movement shown in Fig. 4. The enlargement of the thoracic cavity\'s vertical dimension by the contraction of the diaphragm, and its two horizontal dimensions by the lifting of the front and sides of the ribs, causes the intrathoracic pressure to fall. The lungs interiors are open to the outside air and being elastic, therefore expand to fill the increased space, pleura fluid between double-layered pleura covering of lungs helps in reducing friction while lungs expansion and contraction. The inflow of air into the lungs occurs via the respiratory airways (Fig. 2). In a healthy person, these airways begin with the nose. (It is possible to begin with the mouth, which is the backup breathing system. However, chronic mouth breathing leads to, or is a sign of, illness.) It ends in the microscopic dead-end sacs called alveoli, which are always open, though the diameters of the various sections can be changed by the sympathetic and parasympathetic nervous systems. The alveolar air pressure is therefore always close to atmospheric air pressure (about 100 kPa at sea level) at rest, with the pressure gradients because of lungs contraction and expansion cause air to move in and out of the lungs during breathing rarely exceeding 2–3 kPa.During exhalation, the diaphragm and intercostal muscles relax. This returns the chest and abdomen to a position determined by their anatomical elasticity. This is the ""resting mid-position"" of the thorax and abdomen (Fig. 7) when the lungs contain their functional residual capacity of air (the light blue area in the right hand illustration of Fig. 7), which in the adult human has a volume of about 2.5–3.0 liters (Fig. 3). Resting exhalation lasts about twice as long as inhalation because the diaphragm relaxes passively more gently than it contracts actively during inhalation. The volume of air that moves in or out (at the nose or mouth) during a single breathing cycle is called the tidal volume. In a resting adult human it is about 500 ml per breath. At the end of exhalation, the airways contain about 150 ml of alveolar air which is the first air that is breathed back into the alveoli during inhalation. This volume air that is breathed out of the alveoli and back in again is known as dead space ventilation, which has the consequence that of the 500 ml breathed into the alveoli with each breath only 350 ml (500 ml - 150 ml  350 ml) is fresh warm and moistened air. Since this 350 ml of fresh air is thoroughly mixed and diluted by the air that remains in the alveoli after a normal exhalation (i.e. the functional residual capacity of about 2.5–3.0 liters), it is clear that the composition of the alveolar air changes very little during the breathing cycle (see Fig. 9). The oxygen tension (or partial pressure) remains close to 13-14 kPa (about 100 mm Hg), and that of carbon dioxide very close to 5.3 kPa (or 40 mm Hg). This contrasts with composition of the dry outside air at sea level, where the partial pressure of oxygen is 21 kPa (or 160 mm Hg) and that of carbon dioxide 0.04 kPa (or 0.3 mmHg).During heavy breathing (hyperpnea), as, for instance, during exercise, inhalation is brought about by a more powerful and greater excursion of the contracting diaphragm than at rest (Fig. 8). In addition, the ""accessory muscles of inhalation"" exaggerate the actions of the intercostal muscles (Fig. 8). These accessory muscles of inhalation are muscles that extend from the cervical vertebrae and base of the skull to the upper ribs and sternum, sometimes through an intermediary attachment to the clavicles. When they contract the rib cage\'s internal volume is increased to a far greater extent than can be achieved by contraction of the intercostal muscles alone. Seen from outside the body the lifting of the clavicles during strenuous or labored inhalation is sometimes called clavicular breathing, seen especially during asthma attacks and in people with chronic obstructive pulmonary disease. During heavy breathing, exhalation is caused by relaxation of all the muscles of inhalation. But now, the abdominal muscles, instead of remaining relaxed (as they do at rest), contract forcibly pulling the lower edges of the rib cage downwards (front and sides) (Fig. 8). This not only drastically decreases the size of the rib cage, but also pushes the abdominal organs upwards against the diaphragm which consequently bulges deeply into the thorax (Fig. 8). The end-exhalatory lung volume is now well below the resting mid-position and contains far less air than the resting ""functional residual capacity"". However, in a normal mammal, the lungs cannot be emptied completely. In an adult human, there is always still at least 1 liter of residual air left in the lungs after maximum exhalation.The automatic rhythmical breathing in and out, can be interrupted by coughing, sneezing (forms of very forceful exhalation), by the expression of a wide range of emotions (laughing, sighing, crying out in pain, exasperated intakes of breath) and by such voluntary acts as speech, singing, whistling and the playing of wind instruments. All of these actions rely on the muscles described above, and their effects on the movement of air in and out of the lungs. Although not a form of breathing, the Valsalva maneuver involves the respiratory muscles. It is, in fact, a very forceful exhalatory effort against a tightly closed glottis, so that no air can escape from the lungs. Instead abdominal contents are evacuated in the opposite direction, through orifices in the pelvic floor. The abdominal muscles contract very powerfully, causing the pressure inside the abdomen and thorax to rise to extremely high levels. The Valsalva maneuver can be carried out voluntarily but is more generally a reflex elicited when attempting to empty the abdomen during, for instance, difficult defecation, or during childbirth. Breathing ceases during this maneuver.  Gas exchange  The primary purpose of the respiratory system is the equalizing of the partial pressures of the respiratory gases in the alveolar air with those in the pulmonary capillary blood (Fig. 11). This process occurs by simple diffusion, across a very thin membrane (known as the blood–air barrier), which forms the walls of the pulmonary alveoli (Fig. 10). It consists of the alveolar epithelial cells, their basement membranes and the endothelial cells of the alveolar capillaries (Fig. 10). This blood gas barrier is extremely thin (in humans, on average, 2.2 μm thick). It is folded into about 300 million small air sacs called alveoli (each between 75 and 300 µm in diameter) branching off from the respiratory bronchioles in the lungs, thus providing an extremely large surface area (approximately 145 m2) for gas exchange to occur.The air contained within the alveoli has a semi-permanent volume of about 2.5-3.0 liters which completely surrounds the alveolar capillary blood (Fig. 12). This ensures that equilibration of the partial pressures of the gases in the two compartments is very efficient and occurs very quickly. The blood leaving the alveolar capillaries and is eventually distributed throughout the body therefore has a partial pressure of oxygen of 13-14 kPa (100 mmHg), and a partial pressure of carbon dioxide of 5.3 kPa (40 mmHg) (i.e. the same as the oxygen and carbon dioxide gas tensions as in the alveoli). As mentioned in the section above, the corresponding partial pressures of oxygen and carbon dioxide in the ambient (dry) air at sea level are 21 kPa (160 mmHg) and 0.04 kPa (0.3 mmHg) respectively.This marked difference between the composition of the alveolar air and that of the ambient air can be maintained because the functional residual capacity is contained in dead-end sacs connected to the outside air by fairly narrow and relatively long tubes (the airways: nose, pharynx, larynx, trachea, bronchi and their branches down to the bronchioles), through which the air has to be breathed both in and out (i.e. there is no unidirectional through-flow as there is in the bird lung). This typical mammalian anatomy combined with the fact that the lungs are not emptied and re-inflated with each breath (leaving a substantial volume of air, of about 2.5-3.0 liters, in the alveoli after exhalation), ensures that the composition of the alveolar air is only minimally disturbed when the 350 ml of fresh air is mixed into it with each inhalation. Thus the animal is provided with a very special ""portable atmosphere"", whose composition differs significantly from the present-day ambient air. It is this portable atmosphere (the functional residual capacity) to which the blood and therefore the body tissues are exposed – not to the outside air. The resulting arterial partial pressures of oxygen and carbon dioxide are homeostatically controlled. A rise in the arterial partial pressure of CO2 and, to a lesser extent, a fall in the arterial partial pressure of O2, will reflexly cause deeper and faster breathing until the blood gas tensions in the lungs, and therefore the arterial blood, return to normal. The converse happens when the carbon dioxide tension falls, or, again to a lesser extent, the oxygen tension rises: the rate and depth of breathing are reduced until blood gas normality is restored. Since the blood arriving in the alveolar capillaries has a partial pressure of O2 of, on average, 6 kPa (45 mmHg), while the pressure in the alveolar air is 13-14 kPa (100 mmHg), there will be a net diffusion of oxygen into the capillary blood, changing the composition of the 3 liters of alveolar air slightly. Similarly, since the blood arriving in the alveolar capillaries has a partial pressure of CO2 of also about 6 kPa (45 mmHg), whereas that of the alveolar air is 5.3 kPa (40 mmHg), there is a net movement of carbon dioxide out of the capillaries into the alveoli. The changes brought about by these net flows of individual gases into and out of the alveolar air necessitate the replacement of about 15% of the alveolar air with ambient air every 5 seconds or so. This is very tightly controlled by the monitoring of the arterial blood gases (which accurately reflect composition of the alveolar air) by the aortic and carotid bodies, as well as by the blood gas and pH sensor on the anterior surface of the medulla oblongata in the brain. There are also oxygen and carbon dioxide sensors in the lungs, but they primarily determine the diameters of the bronchioles and pulmonary capillaries, and are therefore responsible for directing the flow of air and blood to different parts of the lungs. It is only as a result of accurately maintaining the composition of the 3 liters of alveolar air that with each breath some carbon dioxide is discharged into the atmosphere and some oxygen is taken up from the outside air. If more carbon dioxide than usual has been lost by a short period of hyperventilation, respiration will be slowed down or halted until the alveolar partial pressure of carbon dioxide has returned to 5.3 kPa (40 mmHg). It is therefore strictly speaking untrue that the primary function of the respiratory system is to rid the body of carbon dioxide “waste”. The carbon dioxide that is breathed out with each breath could probably be more correctly be seen as a byproduct of the body\'s extracellular fluid carbon dioxide and pH homeostats If these homeostats are compromised, then a respiratory acidosis, or a respiratory alkalosis will occur. In the long run these can be compensated by renal adjustments to the H+ and HCO3− concentrations in the plasma; but since this takes time, the hyperventilation syndrome can, for instance, occur when agitation or anxiety cause a person to breathe fast and deeply thus causing a distressing respiratory alkalosis through the blowing off of too much CO2 from the blood into the outside air.Oxygen has a very low solubility in water, and is therefore carried in the blood loosely combined with hemoglobin. The oxygen is held on the hemoglobin by four ferrous iron-containing heme groups per hemoglobin molecule. When all the heme groups carry one O2 molecule each the blood is said to be “saturated” with oxygen, and no further increase in the partial pressure of oxygen will meaningfully increase the oxygen concentration of the blood. Most of the carbon dioxide in the blood is carried as bicarbonate ions (HCO3−) in the plasma. However the conversion of dissolved CO2 into HCO3− (through the addition of water) is too slow for the rate at which the blood circulates through the tissues on the one hand, and through alveolar capillaries on the other. The reaction is therefore catalyzed by carbonic anhydrase, an enzyme inside the red blood cells. The reaction can go in both directions depending on the prevailing partial pressure of CO2. A small amount of carbon dioxide is carried on the protein portion of the hemoglobin molecules as carbamino groups. The total concentration of carbon dioxide (in the form of bicarbonate ions, dissolved CO2, and carbamino groups) in arterial blood (i.e. after it has equilibrated with the alveolar air) is about 26 mM (or 58 ml/100 ml), compared to the concentration of oxygen in saturated arterial blood of about 9 mM (or 20 ml/100 ml blood).  Control of ventilation  Ventilation of the lungs in mammals occurs via the respiratory centers in the medulla oblongata and the pons of the brainstem. These areas form a series of neural pathways which receive information about the partial pressures of oxygen and carbon dioxide in the arterial blood. This information determines the average rate of ventilation of the alveoli of the lungs, to keep these pressures constant. The respiratory center does so via motor nerves which activate the diaphragm and other muscles of respiration. The breathing rate increases when the partial pressure of carbon dioxide in the blood increases. This is detected by central blood gas chemoreceptors on the anterior surface of the medulla oblongata. The aortic and carotid bodies, are the peripheral blood gas chemoreceptors which are particularly sensitive to the arterial partial pressure of O2 though they also respond, but less strongly, to the partial pressure of CO2. At sea level, under normal circumstances, the breathing rate and depth, is determined primarily by the arterial partial pressure of carbon dioxide rather than by the arterial partial pressure of oxygen, which is allowed to vary within a fairly wide range before the respiratory centers in the medulla oblongata and pons respond to it to change the rate and depth of breathing.Exercise increases the breathing rate due to the extra carbon dioxide produced by the enhanced metabolism of the exercising muscles. In addition passive movements of the limbs also reflexively produce an increase in the breathing rate.Information received from stretch receptors in the lungs limits tidal volume (the depth of inhalation and exhalation).  Responses to low atmospheric pressures  The alveoli are open (via the airways) to the atmosphere, with the result that alveolar air pressure is exactly the same as the ambient air pressure at sea level, at altitude, or in any artificial atmosphere (e.g. a diving chamber, or decompression chamber) in which the individual is breathing freely. With expansion of the lungs the alveolar air occupies a larger volume, and its pressure falls proportionally, causing air to flow in through the airways, until the pressure in the alveoli is again at the ambient air pressure. The reverse happens during exhalation. This process (of inhalation and exhalation) is exactly the same at sea level, as on top of Mt. Everest, or in a diving chamber or decompression chamber. However, as one rises above sea level the density of the air decreases exponentially (see Fig. 14), halving approximately with every 5500 m rise in altitude. Since the composition of the atmospheric air is almost constant below 80 km, as a result of the continuous mixing effect of the weather, the concentration of oxygen in the air (mmols O2 per liter of ambient air) decreases at the same rate as the fall in air pressure with altitude. Therefore, in order to breathe in the same amount of oxygen per minute, the person has to inhale a proportionately greater volume of air per minute at altitude than at sea level. This is achieved by breathing deeper and faster (i.e. hyperpnea) than at sea level (see below). There is, however, a complication that increases the volume of air that needs to be inhaled per minute (respiratory minute volume) to provide the same amount of oxygen to the lungs at altitude as at sea level. During inhalation the air is warmed and saturated with water vapor during its passage through the nose passages and pharynx. Saturated water vapor pressure is dependent only on temperature. At a body core temperature of 37 °C it is 6.3 kPa (47.0 mmHg), irrespective of any other influences, including altitude. Thus at sea level, where the ambient atmospheric pressure is about 100 kPa, the moistened air that flows into the lungs from the trachea consists of water vapor (6.3 kPa), nitrogen (74.0 kPa), oxygen (19.7 kPa) and trace amounts of carbon dioxide and other gases (a total of 100 kPa). In dry air the partial pressure of O2 at sea level is 21.0 kPa (i.e. 21% of 100 kPa), compared to the 19.7 kPa of oxygen entering the alveolar air. (The tracheal partial pressure of oxygen is 21% of [100 kPa – 6.3 kPa]  19.7 kPa). At the summit of Mt. Everest (at an altitude of 8,848 m or 29,029 ft) the total atmospheric pressure is 33.7 kPa, of which 7.1 kPa (or 21%) is oxygen. The air entering the lungs also has a total pressure of 33.7 kPa, of which 6.3 kPa is, unavoidably, water vapor (as it is at sea level). This reduces the partial pressure of oxygen entering the alveoli to 5.8 kPa (or 21% of [33.7 kPa – 6.3 kPa]  5.8 kPa). The reduction in the partial pressure of oxygen in the inhaled air is therefore substantially greater than the reduction of the total atmospheric pressure at altitude would suggest (on Mt Everest: 5.8 kPa vs. 7.1 kPa). A further minor complication exists at altitude. If the volume of the lungs were to be instantaneously doubled at the beginning of inhalation, the air pressure inside the lungs would be halved. This happens regardless of altitude. Thus, halving of the sea level air pressure (100 kPa) results in an intrapulmonary air pressure of 50 kPa. Doing the same at 5500 m, where the atmospheric pressure is only 50 kPa, the intrapulmonary air pressure falls to 25 kPa. Therefore, the same change in lung volume at sea level results in a 50 kPa difference in pressure between the ambient air and the intrapulmonary air, whereas it result in a difference of only 25 kPa at 5500 m. The driving pressure forcing air into the lungs during inhalation is therefore halved at this altitude. The rate of inflow of air into the lungs during inhalation at sea level is therefore twice that which occurs at 5500 m. However, in reality, inhalation and exhalation occur far more gently and less abruptly than in the example given. The differences between the atmospheric and intrapulmonary pressures, driving air in and out of the lungs during the breathing cycle, are in the region of only 2–3 kPa. A doubling or more of these small pressure differences could be achieved only by very major changes in the breathing effort at high altitudes. All of the above influences of low atmospheric pressures on breathing are accommodated primarily by breathing deeper and faster (hyperpnea). The exact degree of hyperpnea is determined by the blood gas homeostat, which regulates the partial pressures of oxygen and carbon dioxide in the arterial blood. This homeostat prioritizes the regulation of the arterial partial pressure of carbon dioxide over that of oxygen at sea level. That is to say, at sea level the arterial partial pressure of CO2 is maintained at very close to 5.3 kPa (or 40 mmHg) under a wide range of circumstances, at the expense of the arterial partial pressure of O2, which is allowed to vary within a very wide range of values, before eliciting a corrective ventilatory response. However, when the atmospheric pressure (and therefore the partial pressure of O2 in the ambient air) falls to below 50-75% of its value at sea level, oxygen homeostasis is given priority over carbon dioxide homeostasis. This switch-over occurs at an elevation of about 2500 m (or about 8000 ft). If this switch occurs relatively abruptly, the hyperpnea at high altitude will cause a severe fall in the arterial partial pressure of carbon dioxide, with a consequent rise in the pH of the arterial plasma. This is one contributor to high altitude sickness. On the other hand, if the switch to oxygen homeostasis is incomplete, then hypoxia may complicate the clinical picture with potentially fatal results. There are oxygen sensors in the smaller bronchi and bronchioles. In response to low partial pressures of oxygen in the inhaled air these sensors reflexively cause the pulmonary arterioles to constrict. (This is the exact opposite of the corresponding reflex in the tissues, where low arterial partial pressures of O2 cause arteriolar vasodilation.) At altitude this causes the pulmonary arterial pressure to rise resulting in a much more even distribution of blood flow to the lungs than occurs at sea level. At sea level the pulmonary arterial pressure is very low, with the result that the tops of the lungs receive far less blood than the bases, which are relatively over-perfused with blood. It is only in the middle of the lungs that the blood and air flow to the alveoli are ideally matched. At altitude this variation in the ventilation/perfusion ratio of alveoli from the tops of the lungs to the bottoms is eliminated, with all the alveoli perfused and ventilated in more or less the physiologically ideal manner. This is a further important contributor to the acclimatatization to high altitudes and low oxygen pressures. The kidneys measure the oxygen content (mmol O2/liter blood, rather than the partial pressure of O2) of the arterial blood. When the oxygen content of the blood is chronically low, as at high altitude, the oxygen-sensitive kidney cells secrete erythropoietin (EPO) into the blood. This hormone stimulates the red bone marrow to increase its rate of red cell production, which leads to an increase in the hematocrit of the blood, and a consequent increase in its oxygen carrying capacity (due to the now high hemoglobin content of the blood). In other words, at the same arterial partial pressure of O2, a person with a high hematocrit carries more oxygen per liter of blood than a person with a lower hematocrit does. High altitude dwellers therefore have higher hematocrits than sea-level residents.  Other functions of the lungs   Local defenses  Irritation of nerve endings within the nasal passages or airways, can induce a cough reflex and sneezing. These responses cause air to be expelled forcefully from the trachea or nose, respectively. In this manner, irritants caught in the mucus which lines the respiratory tract are expelled or moved to the mouth where they can be swallowed. During coughing, contraction of the smooth muscle in the airway walls narrows the trachea by pulling the ends of the cartilage plates together and by pushing soft tissue into the lumen. This increases the expired airflow rate to dislodge and remove any irritant particle or mucus. Respiratory epithelium can secrete a variety of molecules that aid in the defense of the lungs. These include secretory immunoglobulins (IgA), collectins, defensins and other peptides and proteases, reactive oxygen species, and reactive nitrogen species. These secretions can act directly as antimicrobials to help keep the airway free of infection. A variety of chemokines and cytokines are also secreted that recruit the traditional immune cells and others to the site of infections. Surfactant immune function is primarily attributed to two proteins: SP-A and SP-D. These proteins can bind to sugars on the surface of pathogens and thereby opsonize them for uptake by phagocytes. It also regulates inflammatory responses and interacts with the adaptive immune response. Surfactant degradation or inactivation may contribute to enhanced susceptibility to lung inflammation and infection.Most of the respiratory system is lined with mucous membranes that contain mucosa-associated lymphoid tissue, which produces white blood cells such as lymphocytes.  Prevention of alveolar collapse  The lungs make a surfactant, a surface-active lipoprotein complex (phospholipoprotein) formed by type II alveolar cells. It floats on the surface of the thin watery layer which lines the insides of the alveoli, reducing the water\'s surface tension. The surface tension of a watery surface (the water-air interface) tends to make that surface shrink. When that surface is curved as it is in the alveoli of the lungs, the shrinkage of the surface decreases the diameter of the alveoli. The more acute the curvature of the water-air interface the greater the tendency for the alveolus to collapse. This has three effects. Firstly the surface tension inside the alveoli resists expansion of the alveoli during inhalation (i.e. it makes the lung stiff, or non-compliant). Surfactant reduces the surface tension and therefore makes the lungs more compliant, or less stiff, than if it were not there. Secondly, the diameters of the alveoli increase and decrease during the breathing cycle. This means that the alveoli have a greater tendency to collapse (i.e. cause atelectasis) at the end of exhalation that at the end of inhalation. Since surfactant floats on the watery surface, its molecules are more tightly packed together when the alveoli shrink during exhalation. This causes them to have a greater surface tension-lowering effect when the alveoli are small than when they are large (as at the end of inhalation, when the surfactant molecules are more widely spaced). The tendency for the alveoli to collapse is therefore almost the same at the end of exhalation as at the end of inhalation. Thirdly, the surface tension of the curved watery layer lining the alveoli tends to draw water from the lung tissues into the alveoli. Surfactant reduces this danger to negligible levels, and keeps the alveoli dry.Pre-term babies who are unable to manufacture surfactant have lungs that tend to collapse each time they breathe out. Unless treated, this condition, called respiratory distress syndrome, is fatal. Basic scientific experiments, carried out using cells from chicken lungs, support the potential for using steroids as a means of furthering the development of type II alveolar cells. In fact, once a premature birth is threatened, every effort is made to delay the birth, and a series of steroid injections is frequently administered to the mother during this delay in an effort to promote lung maturation.  Contributions to whole body functions  The lung vessels contain a fibrinolytic system that dissolves clots that may have arrived in the pulmonary circulation by embolism, often from the deep veins in the legs. They also release a variety of substances that enter the systemic arterial blood, and they remove other substances from the systemic venous blood that reach them via the pulmonary artery. Some prostaglandins are removed from the circulation, while others are synthesized in the lungs and released into the blood when lung tissue is stretched. The lungs activate one hormone. The physiologically inactive decapeptide angiotensin I is converted to the aldosterone-releasing octapeptide, angiotensin II, in the pulmonary circulation. The reaction occurs in other tissues as well, but it is particularly prominent in the lungs. Angiotensin II also has a direct effect on arteriolar walls, causing arteriolar vasoconstriction, and consequently a rise in arterial blood pressure. Large amounts of the angiotensin-converting enzyme responsible for this activation are located on the surfaces of the endothelial cells of the alveolar capillaries. The converting enzyme also inactivates bradykinin. Circulation time through the alveolar capillaries is less than one second, yet 70% of the angiotensin I reaching the lungs is converted to angiotensin II in a single trip through the capillaries. Four other peptidases have been identified on the surface of the pulmonary endothelial cells.  Vocalization  The movement of gas through the larynx, pharynx and mouth allows humans to speak, or phonate. Vocalization, or singing, in birds occurs via the syrinx, an organ located at the base of the trachea. The vibration of air flowing across the larynx (vocal cords), in humans, and the syrinx, in birds, results in sound. Because of this, gas movement is vital for communication purposes.  Temperature control  Panting in dogs, cats, birds and some other animals provides a means of reducing body temperature, by evaporating saliva in the mouth (instead of evaporating sweat on the skin).  Clinical significance  Disorders of the respiratory system can be classified into several general groups: Airway obstructive conditions (e.g., emphysema, bronchitis, asthma) Pulmonary restrictive conditions (e.g., fibrosis, sarcoidosis, alveolar damage, pleural effusion) Vascular diseases (e.g., pulmonary edema, pulmonary embolism, pulmonary hypertension) Infectious, environmental and other ""diseases"" (e.g., pneumonia, tuberculosis, asbestosis, particulate pollutants) Primary cancers (e.g. bronchial carcinoma, mesothelioma) Secondary cancers (e.g. cancers that originated elsewhere in the body, but have seeded themselves in the lungs) Insufficient surfactant (e.g. respiratory distress syndrome in pre-term babies) .Disorders of the respiratory system are usually treated by a pulmonologist and respiratory therapist. Where there is an inability to breathe or insufficiency in breathing a medical ventilator may be used.  Exceptional mammals   Horses  Horses are obligate nasal breathers which means that they are different from many other mammals because they do not have the option of breathing through their mouths and must take in air through their noses.  Elephants  The elephant is the only mammal known to have no pleural space. Rather, the parietal and visceral pleura are both composed of dense connective tissue and joined to each other via loose connective tissue. This lack of a pleural space, along with an unusually thick diaphragm, are thought to be evolutionary adaptations allowing the elephant to remain underwater for long periods of time while breathing through its trunk which emerges as a snorkel.In the elephant the lungs are attached to the diaphragm and breathing relies mainly on the diaphragm rather than the expansion of the ribcage.  Birds  The respiratory system of birds differs significantly from that found in mammals. Firstly, they have rigid lungs which do not expand and contract during the breathing cycle. Instead an extensive system of air sacs (Fig. 15) distributed throughout their bodies act as the bellows drawing environmental air into the sacs, and expelling the spent air after it has passed through the lungs (Fig. 18). Birds also do not have diaphragms or pleural cavities. Bird lungs are smaller than those in mammals of comparable size, but the air sacs account for 15% of the total body volume, compared to the 7% devoted to the alveoli which act as the bellows in mammals.Inhalation and exhalation are brought about by alternately increasing and decreasing the volume of the entire thoraco-abdominal cavity (or coelom) using both their abdominal and costal muscles. During inhalation the muscles attached to the vertebral ribs (Fig. 17) contract angling them forwards and outwards. This pushes the sternal ribs, to which they are attached at almost right angles, downwards and forwards, taking the sternum (with its prominent keel) in the same direction (Fig. 17). This increases both the vertical and transverse diameters of thoracic portion of the trunk. The forward and downward movement of, particularly, the posterior end of the sternum pulls the abdominal wall downwards, increasing the volume of that region of the trunk as well. The increase in volume of the entire trunk cavity reduces the air pressure in all the thoraco-abdominal air sacs, causing them to fill with air as described below. During exhalation the external oblique muscle which is attached to the sternum and vertebral ribs anteriorly, and to the pelvis (pubis and ilium in Fig. 17) posteriorly (forming part of the abdominal wall) reverses the inhalatory movement, while compressing the abdominal contents, thus increasing the pressure in all the air sacs. Air is therefore expelled from the respiratory system in the act of exhalation. During inhalation air enters the trachea via the nostrils and mouth, and continues to just beyond the syrinx at which point the trachea branches into two primary bronchi, going to the two lungs (Fig. 16). The primary bronchi enter the lungs to become the intrapulmonary bronchi, which give off a set of parallel branches called ventrobronchi and, a little further on, an equivalent set of dorsobronchi (Fig. 16). The ends of the intrapulmonary bronchi discharge air into the posterior air sacs at the caudal end of the bird. Each pair of dorso-ventrobronchi is connected by a large number of parallel microscopic air capillaries (or parabronchi) where gas exchange occurs (Fig. 16). As the bird inhales, tracheal air flows through the intrapulmonary bronchi into the posterior air sacs, as well as into the dorsobronchi, but not into the ventrobronchi (Fig. 18). This is due to the bronchial architecture which directs the inhaled air away from the openings of the ventrobronchi, into the continuation of the intrapulmonary bronchus towards the dorsobronchi and posterior air sacs. From the dorsobronchi the inhaled air flows through the parabronchi (and therefore the gas exchanger) to the ventrobronchi from where the air can only escape into the expanding anterior air sacs. So, during inhalation, both the posterior and anterior air sacs expand, the posterior air sacs filling with fresh inhaled air, while the anterior air sacs fill with ""spent"" (oxygen-poor) air that has just passed through the lungs. During exhalation the pressure in the posterior air sacs (which were filled with fresh air during inhalation) increases due to the contraction of the oblique muscle described above. The aerodynamics of the interconnecting openings from the posterior air sacs to the dorsobronchi and intrapulmonary bronchi ensures that the air leaves these sacs in the direction of the lungs (via the dorsobronchi), rather than returning down the intrapulmonary bronchi (Fig. 18). From the dorsobronchi the fresh air from the posterior air sacs flows through the parabronchi (in the same direction as occurred during inhalation) into ventrobronchi. The air passages connecting the ventrobronchi and anterior air sacs to the intrapulmonary bronchi direct the ""spent"", oxygen poor air from these two organs to the trachea from where it escapes to the exterior. Oxygenated air therefore flows constantly (during the entire breathing cycle) in a single direction through the parabronchi.The blood flow through the bird lung is at right angles to the flow of air through the parabronchi, forming a cross-current flow exchange system (Fig. 19). The partial pressure of oxygen in the parabronchi declines along their lengths as O2 diffuses into the blood. The blood capillaries leaving the exchanger near the entrance of airflow take up more O2 than do the capillaries leaving near the exit end of the parabronchi. When the contents of all capillaries mix, the final partial pressure of oxygen of the mixed pulmonary venous blood is higher than that of the exhaled air, but is nevertheless less than half that of the inhaled air, thus achieving roughly the same systemic arterial blood partial pressure of oxygen as mammals do with their bellows-type lungs.The trachea is an area of dead space: the oxygen-poor air it contains at the end of exhalation is the first air to re-enter the posterior air sacs and lungs. In comparison to the mammalian respiratory tract, the dead space volume in a bird is, on average, 4.5 times greater than it is in mammals of the same size. Birds with long necks will inevitably have long tracheae, and must therefore take deeper breaths than mammals do to make allowances for their greater dead space volumes. In some birds (e.g. the whooper swan, Cygnus cygnus, the white spoonbill, Platalea leucorodia, the whooping crane, Grus americana, and the helmeted curassow, Pauxi pauxi) the trachea, which some cranes can be 1.5 m long, is coiled back and forth within the body, drastically increasing the dead space ventilation. The purpose of this extraordinary feature is unknown.  Reptiles  The anatomical structure of the lungs is less complex in reptiles than in mammals, with reptiles lacking the very extensive airway tree structure found in mammalian lungs. Gas exchange in reptiles still occurs in alveoli however. Reptiles do not possess a diaphragm. Thus, breathing occurs via a change in the volume of the body cavity which is controlled by contraction of intercostal muscles in all reptiles except turtles. In turtles, contraction of specific pairs of flank muscles governs inhalation and exhalation.  Amphibians  Both the lungs and the skin serve as respiratory organs in amphibians. The ventilation of the lungs in amphibians relies on positive pressure ventilation. Muscles lower the floor of the oral cavity, enlarging it and drawing in air through the nostrils into the oral cavity. With the nostrils and mouth closed, the floor of the oral cavity is then pushed up, which forces air down the trachea into the lungs. The skin of these animals is highly vascularized and moist, with moisture maintained via secretion of mucus from specialised cells, and is involved in cutaneous respiration. While the lungs are of primary organs for gas exchange between the blood and the environmental air (when out of the water), the skin\'s unique properties aid rapid gas exchange when amphibians are submerged in oxygen-rich water. Some amphibians have gills, either in the early stages of their development (e.g. tadpoles of frogs), while others retain them into adulthood (e.g. some salamanders).  Fish  Oxygen is poorly soluble in water. Fully aerated fresh water therefore contains only 8–10 ml O2/liter compared to the O2 concentration of 210 ml/liter in the air at sea level. Furthermore, the coefficient of diffusion (i.e. the rate at which a substances diffuses from a region of high concentration to one of low concentration, under standard conditions) of the respiratory gases is typically 10,000 faster in air than in water. Thus oxygen, for instance, has a diffusion coefficient of 17.6 mm2/s in air, but only 0.0021 mm2/s in water. The corresponding values for carbon dioxide are 16 mm2/s in air and 0.0016 mm2/s in water. This means that when oxygen is taken up from the water in contact with a gas exchanger, it is replaced considerably more slowly by the oxygen from the oxygen-rich regions small distances away from the exchanger than would have occurred in air. Fish have developed gills deal with these problems. Gills are specialized organs containing filaments, which further divide into lamellae. The lamellae contain a dense thin walled capillary network that exposes a large gas exchange surface area to the very large volumes of water passing over them.Gills use a countercurrent exchange system that increases the efficiency of oxygen-uptake from the water. Fresh oxygenated water taken in through the mouth is uninterruptedly ""pumped"" through the gills in one direction, while the blood in the lamellae flows in the opposite direction, creating the countercurrent blood and water flow (Fig. 22), on which the fish\'s survival depends.Water is drawn in through the mouth by closing the operculum (gill cover), and enlarging the mouth cavity (Fig. 23). Simultaneously the gill chambers enlarge, producing a lower pressure there than in the mouth causing water to flow over the gills. The mouth cavity then contracts, inducing the closure of the passive oral valves, thereby preventing the back-flow of water from the mouth (Fig. 23). The water in the mouth is, instead, forced over the gills, while the gill chambers contract emptying the water they contain through the opercular openings (Fig. 23). Back-flow into the gill chamber during the inhalatory phase is prevented by a membrane along the ventroposterior border of the operculum (diagram on the left in Fig. 23). Thus the mouth cavity and gill chambers act alternately as suction pump and pressure pump to maintain a steady flow of water over the gills in one direction.","For the biochemical process, see respiration The respiratory system, also called the gas exchange system, is the body getting rid of carbon dioxide and taking in oxygen. Carbon dioxide, a waste product, goes out of the body. Oxygen, which the body needs, comes in. The lungs are the main organ to do this. In other words, how oxidation of organic compounds happens in cells and energy is released is called the respiratory system.The first step is breathing in air, or inhaling. Inhalation means bringing air rich in oxygen into the body. Exhalation means giving out air rich in carbon dioxide from the body. The second step is gas exchange in the lungs where oxygen is diffused into the blood and the carbon dioxide diffuses out of the blood. The third step is cellular respiration, which makes the chemical energy that the cells in the body need, and carbon dioxide. Finally, the carbon dioxide from cellular respiration is breathed out of the body from the lungs.  Breathing  Breathing is the first step in respiration. For respiration to happen, the body needs a constant supply of oxygen, which is done by breathing. Inhalation is the breathing in of air. To inhale, the lungs expand, decreasing the air pressure in the lungs. This is caused by two actions. The diaphragm (a sheet of muscular tissue that separates the lungs from the abdomen) is pulled downward. Also the muscles between the ribs contract to expand the chest. Both of these actions expand the lungs. To fill the enlarged lungs, air from outside at higher pressure comes rushing into the area of low pressure in the lungs. Air first passes through the nose and mouth, then through the larynx (voice box), then down the trachea (windpipe), and into the lungs. The lungs are made of many tubes or branches. As air enters the lungs, it first goes through branches called the bronchi, then through smaller branches called bronchioles, and finally into the air sacs. Gas exchange occurs in the air sacs where oxygen is exchanged with carbon dioxide. The carbon dioxide in the air sacs now needs to be exhaled or breathed out. The diaphragm and the rib muscles relax, making the lungs smaller. As the air pressure in the lungs is greater when the lungs are smaller, the air is forced out. The air sacs are able to contract and expand because they are coated with a lubricant, surfactant, this lubricant helps the air sacs inflate while also preventing the collapse of the lungs during deflation. The exhaled air has a high concentration of carbon dioxide and a low concentration of oxygen. The maximum volume of air that can be breathed in and breathed out is called the vital capacity of the lungs and is up to five liters.  Gas exchange  The inhaled air goes down to the air sacs at the end of each bronchiole. The air sacs are called alveoli — they have a large surface area and are moist, thin, and close to a blood supply. The inhaled air has a much greater concentration of oxygen than carbon dioxide whilst the blood flowing to the lungs has more carbon dioxide than oxygen. This creates a concentration gradient between the air in the air sacs and the blood, meaning there is more oxygen in the air than the blood. As the membrane, oxygen can easily diffuse in and out. Oxygen at high concentration in the air sacs diffuses into the blood where oxygen concentration is low, and carbon dioxide at high concentration in the blood diffuses into the air sacs where carbon dioxide concentration is low. The oxygen in the blood enters the circulatory system and is used by the cells in the body. The carbon dioxide in the air sacs is exhaled out of the body.  Related pages  Respiration Respiratory tract  References "
"The trachea, also known as the windpipe, is a cartilaginous tube that connects the larynx to the bronchi of the lungs, allowing the passage of air, and so is present in almost all air-breathing animals with lungs. The trachea extends from the larynx and branches into the two primary bronchi. At the top of the trachea the cricoid cartilage attaches it to the larynx. The trachea is formed by a number of horseshoe-shaped rings, joined together vertically by overlying ligaments, and by the trachealis muscle at their ends. The epiglottis closes the opening to the larynx during swallowing. The trachea begins to form in the second month of embryo development, becoming longer and more fixed in its position over time. It is epithelium lined with column-shaped cells that have hair-like extensions called cilia, with scattered goblet cells that produce protective mucins. The trachea can be affected by inflammation or infection, usually as a result of a viral illness affecting other parts of the respiratory tract, such as the larynx and bronchi, called croup, that can result in a barking cough. Infection with bacteria usually affects the trachea only and can cause narrowing or even obstruction. As a major part of the respiratory tract, when obstructed the trachea prevents air entering the lungs and so a tracheostomy may be required if the trachea is obstructed. Additionally, during surgery if mechanical ventilation is required when a person is sedated, a tube is inserted into the trachea, called intubation. The word trachea is used to define a very different organ in invertebrates than in vertebrates. Insects have an open respiratory system made up of spiracles, tracheae, and tracheoles to transport metabolic gases to and from tissues  Structure  An adult's trachea has an inner diameter of about 1.5 to 2 centimetres (0.59 to 0.79 in) and a length of about 10 to 11 centimetres (3.9 to 4.3 in); wider in males than females. The trachea begins at the lower edge of the cricoid cartilage of the larynx at the level of sixth cervical vertebra (C6) and ends at the carina, the point where the trachea branches into left and right main bronchi., at the level of the fourth thoracic vertebra (T4), although its position may change with breathing. The trachea is surrounded by 16–20 rings of hyaline cartilage; these 'rings' are 4 millimetres high in the adult, incomplete and C-shaped. Ligaments connect the rings. The trachealis muscle connects the ends of the incomplete rings and runs along the back wall of the trachea. Also adventitia, which is the outermost layer of connective tissue that surrounds the hyaline cartilage, contributes to the trachea's ability to bend and stretch with movement.Although trachea is a midline structure, it can be displaced normally to the right by the aortic arch.  Nearby structures  The trachea passes by many structures of the neck and chest (thorax) along its course. In front of the upper trachea lies connective tissue and skin. Several other structures pass over or sit on the trachea; the jugular arch, which joins the two anterior jugular veins, sits in front of the upper part of the trachea. The sternohyoid and sternothyroid muscles stretch along its length. The thyroid gland also stretches across the upper trachea, with the isthmus overlying the second to fourth rings, and the lobes stretching to the level of the fifth or sixth cartilage. The blood vessels of the thyroid rest on the trachea next to the isthmus; superior thyroid arteries join just above it, and the inferior thyroid veins below it. In front of the lower trachea lies the manubrium of the sternum, the remnants of the thymus in adults. To the front left lie the large blood vessels the aortic arch and its branches the left common carotid artery and the brachiocephalic trunk; and the left brachiocephalic vein. The deep cardiac plexus and lymph nodes are also positioned in front of the lower trachea.Behind the trachea, along its length, sits the oesophagus, followed by connective tissue and the vertebral column. To its sides run the carotid arteries and inferior thyroid arteries; and to its sides on its back surface run the recurrent laryngeal nerves in the upper trachea, and the vagus nerves in the lower trachea.The trachealis muscle contracts during coughing, reducing the size of the lumen of the trachea.  Blood and lymphatic supply  The upper part of trachea receives and drains blood through the inferior thyroid arteries and veins; the lower trachea receives blood from bronchial arteries. Arteries that supply the trachea do so via small branches that supply the trachea from the sides. As the branches approach the wall of the trachea, they split into inferior and superior branches, which join with the branches of the arteries above and below; these then split into branches that supply the anterior and posterior parts of the trachea. The inferior thyroid arteries arise just below the isthmus of the thyroid, which sits atop the trachea. These arteries join (anastamoses) with ascending branches of the bronchial arteries, which are direct branches from the aorta, to supply blood to the trachea. The lymphatic vessels of the trachea drain into the pretracheal nodes that lie in front of the trachea, and paratracheal lymph nodes that lie beside it.  Development  In the fourth week of development of the human embryo as the respiratory bud grows, the trachea separates from the foregut through the formation of ridges which eventually separate the trachea from the oesophagus, the tracheoesophageal septum. This separates the future trachea from the oesophagus and divides the foregut tube into the laryngotracheal tube. By the start of the fifth week, the left and right main bronchi have begin to form, initially as buds at the terminal end of the trachea.The trachea is no more than 4mm diameter during the first year of life, expanding to its adult diameter of approximately 2cm by late childhood. The trachea is more circular and more vertical in children compared to adults, varies more in size, and also varies more in its position in relation to its surrounding structures.  Microanatomy  The trachea is lined with a layer of interspersed layers of column-shaped cells with cilia. The epithelium contains goblet cells, which are glandular, column-shaped cells that produce mucins, the main component of mucus. Mucus helps to moisten and protect the airways. Mucus lines the ciliated cells of the trachea to trap inhaled foreign particles that the cilia then waft upward toward the larynx and then the pharynx where it can be either swallowed into the stomach or expelled as phlegm. This self-clearing mechanism is termed mucociliary clearance.The trachea is surrounded by 16 to 20 rings of hyaline cartilage; these 'rings' are incomplete and C-shaped. Two or more of the cartilages often unite, partially or completely, and they are sometimes bifurcated at their extremities. The rings are generally highly elastic but they may calcify with age.  Function  The trachea is one part of the respiratory tree that is a conduit for air to pass through on its way to or from the alveoli of the lungs. This transmits oxygen to the body and removes carbon dioxide.  Clinical significance   Inflammation and infection  Inflammation of the trachea is known as tracheitis, usually due to an infection. It is usually caused by viral infections, with bacterial infections occurring almost entirely in children. Most commonly, infections occur with inflammation of other parts of the respiratory tract, such as the larynx and bronchi, known as croup, however bacterial infections may also affect the trachea alone, although they are often associated with a recent viral infection. Viruses that cause croup are generally the parainfluenza viruses 1–3, with influenza viruses A and B also causing croup, but usually causing more serious infections; bacteria may also cause croup and include Staphylococcus aureus, Haemophilus influenzae, Streptococcus pneumoniae and Moraxella catarrhalis. Causes of bacterial infection of the trachea are most commonly Staphylococcus aureus and Streptococcus pneumoniae. In patients who are in hospital, additional bacteria that may cause tracheitis include Escherichia coli, Klebsiella pneumoniae, and Pseudomonas aeruginosa.A person affected with tracheitis may start with symptoms that suggest an upper respiratory tract infection such as a cough, sore throat, or coryzal symptoms such as a runny nose. Fevers may develop and an affected child may develop difficulty breathing and sepsis. Swelling of the airway can cause narrowing of the airway, causing a hoarse breathing sound called stridor, or even cause complete blockage. Unfortunately, up to 80% of people affected by bacterial tracheitis require the use of mechanical ventilation, and treatment may include endoscopy for the purposes of acquiring microbiological specimens for culture and sensitivity, as well as removal of any dead tissue associated with the infection. Treatment in such situations usually includes antibiotics.  Narrowing  A trachea may be narrowed or compressed, usually a result of enlarged nearby lymph nodes; cancers of the trachea or nearby structures; large thyroid goitres; or rarely as a result of other processes such as unusually swollen blood vessels. Scarring from tracheobronchial injury or intubation; or inflammation associated with granulomatosis with polyangiitis may also cause a narrowing of the trachea (tracheal stenosis). Obstruction invariably causes a harsh breathing sound known as stridor. A camera inserted via the mouth down into the trachea, called bronchoscopy, may be performed to investigate the cause of an obstruction. Management of obstructions depends on the cause. Obstructions as a result of malignancy may be managed with surgery, chemotherapy or radiotherapy. A stent may be inserted over the obstruction. Benign lesions, such as narrowing resulting from scarring, are likely to be surgically excised.One cause of narrowing is tracheomalacia, which is the tendency for the trachea to collapse when there is increased external pressure, such as when airflow is increased during breathing in or out, due to decreased compliance. It can be due to congenital causes, or due to things that develop after birth, such as compression from nearby masses or swelling, or trauma. Congenital tracheomalacia can occur by itself or in association with other abnormalities such as bronchomalacia or laryngomalacia, and abnormal connections between the trachea and the oesophagus, amongst others. Congenital tracheomalacia often improves without specific intervention; when required, interventions may include beta agonists and muscarinic agonists, which enhance the tone of the smooth muscle surrounding the trachea; positive pressure ventilation, or surgery, which may include the placement of a stent, or the removal of the affected part of the trachea. In dogs, particularly miniature dogs and toy dogs, tracheomalacia, as well as bronchomalacia, can lead to tracheal collapse, which often presents with a honking goose-like cough.  Injury  The trachea may be injured by trauma such as in a vehicle accident, or intentionally by another wilfully inflicting damage for example as practiced in some martial arts.  Intubation  Tracheal intubation refers to the insertion of a tube down the trachea. This procedure is commonly performed during surgery, in order to ensure a person receives enough oxygen when sedated. The catheter is connected to a machine that monitors the airflow, oxygenation and several other metrics. This is often one of the responsibilities of an anaesthetist during surgery. In an emergency, or when tracheal intubation is deemed impossible, a tracheotomy is often performed to insert a tube for ventilation, usually when needed for particular types of surgery to be carried out so that the airway can be kept open. The provision of the opening via a tracheotomy is called a tracheostomy. Another method procedure can be carried, in an emergency situation, and this is a cricothyrotomy.  Congenital disorders  Tracheal agenesis is a rare birth defect in which the trachea fails to develop. The defect is usually fatal though sometimes surgical intervention has been successful. A tracheoesophageal fistula is a congenital defect in which the trachea and esophagus are abnormally connected (a fistula). This is because of abnormalities in the separation between the trachea and oesophagus during development. This occurs in approximately 1 in 3000 births, and the most common abnormalities is a separation of the upper and lower ends of the oesophagus, with the upper end finishing in a closed pouch. Other abnormalities may be associated with this, including cardiac abnormalities, or VACTERL syndrome. Such fistulas may be detected before a baby is born because of excess amniotic fluid; after birth, they are often associated with pneumonitis and pneumonia because of aspiration of food contents. Congenital fistulas are often treated by surgical repair. In adults, fistulas may occur because of erosion into the trachea from nearby malignant tumours, which erode into both the trachea and the oesophagus. Initially, these often result in coughing from swallowed contents of the oesophagus that are aspirated through the trachea, often progressing to fatal pneumonia; unfortunately, there is rarely a curative treatment. A tracheo-oesophageal puncture is a surgically created hole between the trachea and the esophagus in a person who has had their larynx removed. Air travels upwards from the surgical connection to the upper oesophagus and the pharynx, creating vibrations that create sound that can be used for speech. The purpose of the puncture is to restore a person's ability to speak after the vocal cords have been removed.Sometimes as an anatomical variation one or more of the tracheal rings are formed as complete rings, rather than horseshoe shaped rings. These O rings are smaller than the normal C-shaped rings and can cause narrowing (stenosis) of the trachea, resulting in breathing difficulties. An operation called a slide tracheoplasty can open up the rings and rejoin them as wider rings, shortening the length of the trachea. Slide tracheoplasty is said to be the best option in treating tracheal stenosis.Mounier-Kuhn syndrome is a rare congenital disorder of an abnormally enlarged trachea, characterised by absent elastic fibres, smooth muscle thinning, and a tendency to get recurrent respiratory tract infections.  Replacement  From 2008, operations have experimentally replaced tracheas, with those grown from stem cells, or with synthetic substitutes, however this is regarded as experimental and there is no standardised method. Difficulties with ensuring adequate blood supply to the replaced trachea is considered a major challenge to any replacement. Additionally, no evidence has been found to support the placement of stem cells taken from bone marrow on the trachea as a way of stimulating tissue regeneration, and such a method remains hypothetical.In January 2021, surgeons at Mount Sinai Hospital in New York performed the first complete trachea transplantation. The 18-hour procedure included harvesting a trachea from a donor and implanting it in the patient, connecting numerous veins and arteries to provide sufficient blood flow to the organ.  Other animals  Allowing for variations in the length of the neck, the trachea in other mammals is, in general, similar to that in humans. Generally, it is also similar to the reptilian trachea.  Vertebrates  In birds, the trachea runs from the pharynx to the syrinx, from which the primary bronchi diverge. Swans have an unusually elongated trachea, part of which is coiled beneath the sternum; this may act as a resonator to amplify sound. In some birds, the tracheal rings are complete, and may even be ossified.In amphibians, the trachea is normally extremely short, and leads directly into the lungs, without clear primary bronchi. A longer trachea is, however, found in some long-necked salamanders, and in caecilians. While there are irregular cartilagenous nodules on the amphibian trachea, these do not form the rings found in amniotes.The only vertebrates to have lungs, but no trachea, are the lungfish and the Polypterus, in which the lungs arise directly from the pharynx.  Invertebrates  The word trachea is used to define a very different organ in invertebrates than in vertebrates. Insects have an open respiratory system made up of spiracles, tracheae, and tracheoles to transport metabolic gases to and from tissues. The distribution of spiracles can vary greatly among the many orders of insects, but in general each segment of the body can have only one pair of spiracles, each of which connects to an atrium and has a relatively large tracheal tube behind it. The tracheae are invaginations of the cuticular exoskeleton that branch (anastomose) throughout the body with diameters from only a few micrometres up to 0.8 mm. Diffusion of oxygen and carbon dioxide takes place across the walls of the smallest tubes, called tracheoles, which penetrate tissues and even indent individual cells. Gas may be conducted through the respiratory system by means of active ventilation or passive diffusion. Unlike vertebrates, insects do not generally carry oxygen in their haemolymph. This is one of the factors that may limit their size. A tracheal tube may contain ridge-like circumferential rings of taenidia in various geometries such as loops or helices. Taenidia provide strength and flexibility to the trachea. In the head, thorax, or abdomen, tracheae may also be connected to air sacs. Many insects, such as grasshoppers and bees, which actively pump the air sacs in their abdomen, are able to control the flow of air through their body. In some aquatic insects, the tracheae exchange gas through the body wall directly, in the form of a gill, or function essentially as normal, via a plastron. Note that despite being internal, the tracheae of arthropods are lined with cuticular tissue and are shed during moulting (ecdysis).  Additional images   References ","The trachea, or windpipe, is the bony tube that connects the nose and mouth to the lungs, and is an important part of the vertebrate respiratory system. In mammals, the trachea begins at the lower part of the larynx and continues to the lungs, where it branches into the right and left bronchi. Inflammation of the trachea can lead to other conditions, such as tracheitis, which is the inflammation of the linings of the trachea.  Invertebrate trachea  The invertebrate trachea refers to the open respiratory system of terrestrial arthropods. It consists of spiracles, tracheae, and tracheoles that take metabolic gases to and from tissues. The distribution of spiracles varies, but in general each segment of the body has only one pair of spiracles, each of which connects to an atrium and has a relatively large tracheal tube behind it. The smallest tubes, tracheoles, penetrate cells and diffuse water, oxygen, and carbon dioxide. Gas may be moved actively or by passive diffusion. Unlike vertebrates, insects do not generally carry oxygen in their haemolymph. This is one of the factors that may limit their size. A tracheal tube may contain ridge-like circumferential rings of taenidia in various geometries such as loops or helices. In the head, thorax, or abdomen, tracheae may also be connected to air sacs. Many insects, such as grasshoppers and bees, which actively pump the air sacs in their abdomen, are able to control the flow of air through their body. In some aquatic insects, the tracheae exchange gas through the body wall directly, in the form of a gill, or function as normal, via a plastron. Despite being internal, the tracheae of arthropods are shed during moulting (ecdysis).  References "
"A ligament is the fibrous connective tissue that connects bones to other bones. It is also known as articular ligament, articular larua, fibrous ligament, or true ligament. Other ligaments in the body include the: Peritoneal ligament: a fold of peritoneum or other membranes. Fetal remnant ligament: the remnants of a fetal tubular structure. Periodontal ligament: a group of fibers that attach the cementum of teeth to the surrounding alveolar bone.Ligaments are similar to tendons and fasciae as they are all made of connective tissue. The differences among them are in the connections that they make: ligaments connect one bone to another bone, tendons connect muscle to bone, and fasciae connect muscles to other muscles. These are all found in the skeletal system of the human body. Ligaments cannot usually be regenerated naturally; however, there are periodontal ligament stem cells located near the periodontal ligament which are involved in the adult regeneration of periodontist ligament. The study of ligaments is known as desmology.  Articular ligaments  ""Ligament"" most commonly refers to a band of dense regular connective tissue bundles made of collagenous fibers, with bundles protected by dense irregular connective tissue sheaths. Ligaments connect bones to other bones to form joints, while tendons connect bone to muscle. Some ligaments limit the mobility of articulations or prevent certain movements altogether. Capsular ligaments are part of the articular capsule that surrounds synovial joints. They act as mechanical reinforcements. Extra-capsular ligaments join in harmony with the other ligaments and provide joint stability. Intra-capsular ligaments, which are much less common, also provide stability but permit a far larger range of motion. Cruciate ligaments are paired ligaments in the form of a cross.Ligaments are viscoelastic. They gradually strain when under tension and return to their original shape when the tension is removed. However, they cannot retain their original shape when extended past a certain point or for a prolonged period of time. This is one reason why dislocated joints must be set as quickly as possible: if the ligaments lengthen too much, then the joint will be weakened, becoming prone to future dislocations. Athletes, gymnasts, dancers, and martial artists perform stretching exercises to lengthen their ligaments, making their joints more supple. The term hypermobility refers to the characteristic of people with more-elastic ligaments, allowing their joints to stretch and contort further; this is sometimes still called double-jointedness. The consequence of a broken ligament can be instability of the joint. Not all broken ligaments need surgery, but, if surgery is needed to stabilise the joint, the broken ligament can be repaired. Scar tissue may prevent this. If it is not possible to fix the broken ligament, other procedures such as the Brunelli procedure can correct the instability. Instability of a joint can over time lead to wear of the cartilage and eventually to osteoarthritis.  Artificial ligaments  One of the most often torn ligaments in the body is the anterior cruciate ligament (ACL). The ACL is one of the ligaments crucial to knee stability and persons who tear their ACL often undergo reconstructive surgery, which can be done through a variety of techniques and materials. One of these techniques is the replacement of the ligament with an artificial material. Artificial ligaments are a synthetic material composed of a polymer, such as polyacrylonitrile fiber, polypropylene, PET (polyethylene terephthalate), or polyNaSS poly(sodium styrene sulfonate).  Examples   Peritoneal ligaments  Certain folds of peritoneum are referred to as ligaments. Examples include: The hepatoduodenal ligament, that surrounds the hepatic portal vein and other vessels as they travel from the duodenum to the liver. The broad ligament of the uterus, also a fold of peritoneum.  Fetal remnant ligaments  Certain tubular structures from the fetal period are referred to as ligaments after they close up and turn into cord-like structures:  See also  Ligamentous laxity Broström procedure  References ","In anatomy, the word ligament usually means the fibrous tissue that joins bones to other bones or cartilages.A ligament is a short band of tough fibrous connective tissue made of long, stringy collagen fibres. Ligaments join bones to other bones to form a joint. They do not connect muscles to bones; that is the function of tendons. Some ligaments limit the amount of movement in a joint, or stop certain movements altogether. Ligaments are only slightly elastic; when under tension, they gradually lengthen. This is one reason why dislocated joints must be set as quickly as possible: if the ligaments lengthen too much, then the joint will be weakened. Athletes, gymnasts, dancers, and martial artists perform stretching exercises to lengthen their ligaments, making their joints more supple. The result of a broken ligament can be instability of the joint. Not all broken ligaments need surgery, but if surgery is needed to stabilise the joint, the broken ligament can be joined.  References "
"A tooth (PL: teeth) is a hard, calcified structure found in the jaws (or mouths) of many vertebrates and used to break down food. Some animals, particularly carnivores and omnivores, also use teeth to help with capturing or wounding prey, tearing food, for defensive purposes, to intimidate other animals often including their own, or to carry prey or their young. The roots of teeth are covered by gums. Teeth are not made of bone, but rather of multiple tissues of varying density and hardness that originate from the outermost embryonic germ layer, the ectoderm. The general structure of teeth is similar across the vertebrates, although there is considerable variation in their form and position. The teeth of mammals have deep roots, and this pattern is also found in some fish, and in crocodilians. In most teleost fish, however, the teeth are attached to the outer surface of the bone, while in lizards they are attached to the inner surface of the jaw by one side. In cartilaginous fish, such as sharks, the teeth are attached by tough ligaments to the hoops of cartilage that form the jaw.Monophyodonts are animals that develop only one set of teeth, while diphyodonts grow an early set of deciduous teeth and a later set of permanent or ""adult"" teeth. Polyphyodonts grow many sets of teeth. For example, sharks, grow a new set of teeth every two weeks to replace worn teeth. Most extant mammals including humans are diphyodonts, but there are exceptions including elephants, kangaroos, and manatees, all of which are polyphyodonts. Rodent incisors grow and wear away continually through gnawing, which helps maintain relatively constant length. The industry of the beaver is due in part to this qualification. Many rodents such as voles and guinea pigs, but not mice, as well as leporidae like rabbits, have continuously growing molars in addition to incisors. Also, tusks (in tusked mammals) grow almost throughout life.Teeth are not always attached to the jaw, as they are in mammals. In many reptiles and fish, teeth are attached to the palate or to the floor of the mouth, forming additional rows inside those on the jaws proper. Some teleosts even have teeth in the pharynx. While not true teeth in the usual sense, the dermal denticles of sharks are almost identical in structure and are likely to have the same evolutionary origin. Indeed, teeth appear to have first evolved in sharks, and are not found in the more primitive jawless fish – while lampreys do have tooth-like structures on the tongue, these are in fact, composed of keratin, not of dentine or enamel, and bear no relationship to true teeth. Though ""modern"" teeth-like structures with dentine and enamel have been found in late conodonts, they are now supposed to have evolved independently of later vertebrates' teeth.Living amphibians typically have small teeth, or none at all, since they commonly feed only on soft foods. In reptiles, teeth are generally simple and conical in shape, although there is some variation between species, most notably the venom-injecting fangs of snakes. The pattern of incisors, canines, premolars and molars is found only in mammals, and to varying extents, in their evolutionary ancestors. The numbers of these types of teeth vary greatly between species; zoologists use a standardised dental formula to describe the precise pattern in any given group.  Etymology  The word tooth comes from Proto-Germanic tanþs derived from the Proto-Indo-European h₁dent-, which was composed of the root h₁ed- (""to eat"") plus the active participle suffix -nt, therefore literally meaning ""that which eats"".The irregular plural form teeth is the result of Germanic umlaut whereby vowels immediately preceding a high vocalic in the following syllable were raised. As the nominative plural ending of the Proto-Germanic consonant stems (to which tanþs belonged) was -iz, the root vowel in the plural form tanþiz (changed by this point to tą̄þi via unrelated phonological processes) was raised to /œː/, and later unrounded to /eː/, resulting in the tōþ/tēþ alternation attested from Old English. Cf. also Old English bōc/bēċ, ""book/books"" and mūs/mȳs, ""mouse/mice"", from Proto-Germanic bōks/bōkiz and mūs/mūsiz respectively. Cognate with Latin dēns, Greek ὀδούς odous, and Sanskrit dát.  Origin  Teeth are assumed to have evolved either from ectoderm denticles (scales, much like those on the skin of sharks) that folded and integrated into the mouth (called the ""outside–in"" theory), or from endoderm pharyngeal teeth (primarily formed in the pharynx of jawless vertebrates) (the ""inside–out"" theory). In addition, there is another theory stating that neural crest gene regulatory network, and neural crest-derived ectomesenchyme are the key to generate teeth (with any epithelium, either ectoderm or endoderm).The genes governing tooth development in mammals are homologous to those involved in the development of fish scales. Study of a tooth plate of a fossil of the extinct fish Romundina stellina showed that the teeth and scales were made of the same tissues, also found in mammal teeth, lending support to the theory that teeth evolved as a modification of scales.  Mammals  Teeth are among the most distinctive (and long-lasting) features of mammal species. Paleontologists use teeth to identify fossil species and determine their relationships. The shape of the animal's teeth are related to its diet. For example, plant matter is hard to digest, so herbivores have many molars for chewing and grinding. Carnivores, on the other hand, have canine teeth to kill prey and to tear meat. Mammals, in general, are diphyodont, meaning that they develop two sets of teeth. In humans, the first set (the ""baby"", ""milk"", ""primary"" or ""deciduous"" set) normally starts to appear at about six months of age, although some babies are born with one or more visible teeth, known as neonatal teeth. Normal tooth eruption at about six months is known as teething and can be painful. Kangaroos, elephants, and manatees are unusual among mammals because they are polyphyodonts.  Aardvark  In aardvarks, teeth lack enamel and have many pulp tubules, hence the name of the order Tubulidentata.  Canines  In dogs, the teeth are less likely than humans to form dental cavities because of the very high pH of dog saliva, which prevents enamel from demineralizing. Sometimes called cuspids, these teeth are shaped like points (cusps) and are used for tearing and grasping food.  Cetaceans  Like human teeth, whale teeth have polyp-like protrusions located on the root surface of the tooth. These polyps are made of cementum in both species, but in human teeth, the protrusions are located on the outside of the root, while in whales the nodule is located on the inside of the pulp chamber. While the roots of human teeth are made of cementum on the outer surface, whales have cementum on the entire surface of the tooth with a very small layer of enamel at the tip. This small enamel layer is only seen in older whales where the cementum has been worn away to show the underlying enamel.The toothed whale is a suborder of the cetaceans characterized by having teeth. The teeth differ considerably among the species. They may be numerous, with some dolphins bearing over 100 teeth in their jaws. On the other hand, the narwhals have a giant unicorn-like tusk, which is a tooth containing millions of sensory pathways and used for sensing during feeding, navigation, and mating. It is the most neurologically complex tooth known. Beaked whales are almost toothless, with only bizarre teeth found in males. These teeth may be used for feeding but also for demonstrating aggression and showmanship.  Primates  In humans (and most other primates) there are usually 20 primary (also ""baby"" or ""milk"") teeth, and later up to 32 permanent teeth. Four of these 32 may be third molars or wisdom teeth, although these are not present in all adults, and may be removed surgically later in life.Among primary teeth, 10 of them are usually found in the maxilla (i.e. upper jaw) and the other 10 in the mandible (i.e. lower jaw). Among permanent teeth, 16 are found in the maxilla and the other 16 in the mandible. Most of the teeth have uniquely distinguishing features.  Horse  An adult horse has between 36 and 44 teeth. The enamel and dentin layers of horse teeth are intertwined. All horses have 12 premolars, 12 molars, and 12 incisors. Generally, all male equines also have four canine teeth (called tushes) between the molars and incisors. However, few female horses (less than 28%) have canines, and those that do usually have only one or two, which many times are only partially erupted. A few horses have one to four wolf teeth, which are vestigial premolars, with most of those having only one or two. They are equally common in male and female horses and much more likely to be on the upper jaw. If present these can cause problems as they can interfere with the horse's bit contact. Therefore, wolf teeth are commonly removed.Horse teeth can be used to estimate the animal's age. Between birth and five years, age can be closely estimated by observing the eruption pattern on milk teeth and then permanent teeth. By age five, all permanent teeth have usually erupted. The horse is then said to have a ""full"" mouth. After the age of five, age can only be conjectured by studying the wear patterns on the incisors, shape, the angle at which the incisors meet, and other factors. The wear of teeth may also be affected by diet, natural abnormalities, and cribbing. Two horses of the same age may have different wear patterns. A horse's incisors, premolars, and molars, once fully developed, continue to erupt as the grinding surface is worn down through chewing. A young adult horse will have teeth which are 110–130 mm (4.5–5 inches) long, with the majority of the crown remaining below the gumline in the dental socket. The rest of the tooth will slowly emerge from the jaw, erupting about 3 mm (1⁄8 in) each year, as the horse ages. When the animal reaches old age, the crowns of the teeth are very short and the teeth are often lost altogether. Very old horses, if lacking molars, may need to have their fodder ground up and soaked in water to create a soft mush for them to eat in order to obtain adequate nutrition.  Proboscideans  Elephants' tusks are specialized incisors for digging food up and fighting. Some elephant teeth are similar to those in manatees, and it is notable that elephants are believed to have undergone an aquatic phase in their evolution. At birth, elephants have a total of 28 molar plate-like grinding teeth not including the tusks. These are organized into four sets of seven successively larger teeth which the elephant will slowly wear through during its lifetime of chewing rough plant material. Only four teeth are used for chewing at a given time, and as each tooth wears out, another tooth moves forward to take its place in a process similar to a conveyor belt. The last and largest of these teeth usually becomes exposed when the animal is around 40 years of age, and will often last for an additional 20 years. When the last of these teeth has fallen out, regardless of the elephant's age, the animal will no longer be able to chew food and will die of starvation.  Rabbit  Rabbits and other lagomorphs usually shed their deciduous teeth before (or very shortly after) their birth, and are usually born with their permanent teeth. The teeth of rabbits complement their diet, which consists of a wide range of vegetation. Since many of the foods are abrasive enough to cause attrition, rabbit teeth grow continuously throughout life. Rabbits have a total of 6 incisors, three upper premolars, three upper molars, two lower premolars, and two lower molars on each side. There are no canines. Three to four millimeters of the tooth is worn away by incisors every week, whereas the posterior teeth require a month to wear away the same amount. The incisors and cheek teeth of rabbits are called aradicular hypsodont teeth. This is sometimes referred to as an elodent dentition. These teeth grow or erupt continuously. The growth or eruption is held in balance by dental abrasion from chewing a diet high in fiber.  Rodents  Rodents have upper and lower hypselodont incisors that can continuously grow enamel throughout its life without having properly formed roots. These teeth are also known as aradicular teeth, and unlike humans whose ameloblasts die after tooth development, rodents continually produce enamel, they must wear down their teeth by gnawing on various materials. Enamel and dentin are produced by the enamel organ, and growth is dependent on the presence of stem cells, cellular amplification, and cellular maturation structures in the odontogenic region. Rodent incisors are used for cutting wood, biting through the skin of fruit, or for defense. This allows for the rate of wear and tooth growth to be at equilibrium. The microstructure of rodent incisor enamel has shown to be useful in studying the phylogeny and systematics of rodents because of its independent evolution from the other dental traits. The enamel on rodent incisors are composed of two layers: the inner portio interna (PI) with Hunter-Schreger bands (HSB) and an outer portio externa (PE) with radial enamel (RE). It usually involves the differential regulation of the epithelial stem cell niche in the tooth of two rodent species, such as guinea pigs. The teeth have enamel on the outside and exposed dentin on the inside, so they self-sharpen during gnawing. On the other hand, continually growing molars are found in some rodent species, such as the sibling vole and the guinea pig. There is variation in the dentition of the rodents, but generally, rodents lack canines and premolars, and have a space between their incisors and molars, called the diastema region.  Manatee  Manatees are polyphyodont with mandibular molars developing separately from the jaw and are encased in a bony shell separated by soft tissue.  Walrus  Walrus tusks are canine teeth that grow continuously throughout life.  Fish  Fish, such as sharks, may go through many teeth in their lifetime. The replacement of multiple teeth is known as polyphyodontia. A class of prehistoric shark are called cladodonts for their strange forked teeth. Unlike the continuous shedding of functional teeth seen in modern sharks, the majority of stem chondrichthyan lineages retained all tooth generations developed throughout the life of the animal. This replacement mechanism is exemplified by the tooth whorl-based dentitions of acanthodians, which include the oldest known toothed vertebrate, Qianodus duplicis.  Amphibians  All amphibians have pedicellate teeth which are modified to be flexible due to connective tissue and uncalcified dentine that separates the crown from the base of the tooth.Most amphibians exhibit teeth that have a slight attachment to the jaw or acrodont teeth. Acrodont teeth exhibit limited connection to the dentary and have little enervation. This is ideal for organisms who mostly use their teeth for grasping, but not for crushing and allows for rapid regeneration of teeth at a low energy cost. Teeth are usually lost in the course of feeding if the prey is struggling. Additionally, amphibians that undergo a metamorphosis develop bicuspid shaped teeth.  Reptiles  The teeth of reptiles are replaced constantly throughout their lives. Crocodilian juveniles replace teeth with larger ones at a rate as high as one new tooth per socket every month. Once mature, tooth replacement rates can slow to two years and even longer. Overall, crocodilians may use 3,000 teeth from birth to death. New teeth are created within old teeth.  Birds  A skull of Ichthyornis discovered in 2014 suggests that the beak of birds may have evolved from teeth to allow chicks to escape their shells earlier, and thus avoid predators and also to penetrate protective covers such as hard earth to access underlying food.  Invertebrates  True teeth are unique to vertebrates, although many invertebrates have analogous structures often referred to as teeth. The organisms with the simplest genome bearing such tooth-like structures are perhaps the parasitic worms of the family Ancylostomatidae. For example, the hookworm Necator americanus has two dorsal and two ventral cutting plates or teeth around the anterior margin of the buccal capsule. It also has a pair of subdorsal and a pair of subventral teeth located close to the rear.Historically the European medicinal leech, another invertebrate parasite, has been used in medicine to remove blood from patients. They have three jaws (tripartite) that resemble saws in both appearance and function, and on them are about 100 sharp teeth used to incise the host. The incision leaves a mark that is an inverted Y inside of a circle. After piercing the skin and injecting anticoagulants (hirudin) and anaesthetics, they suck out blood, consuming up to ten times their body weight in a single meal.In some species of Bryozoa, the first part of the stomach forms a muscular gizzard lined with chitinous teeth that crush armoured prey such as diatoms. Wave-like peristaltic contractions then move the food through the stomach for digestion. Molluscs have a structure called a radula which bears a ribbon of chitinous teeth. However, these teeth are histologically and developmentally different from vertebrate teeth and are unlikely to be homologous. For example, vertebrate teeth develop from a neural crest mesenchyme-derived dental papilla, and the neural crest is specific to vertebrates, as are tissues such as enamel.The radula is used by molluscs for feeding and is sometimes compared rather inaccurately to a tongue. It is a minutely toothed, chitinous ribbon, typically used for scraping or cutting food before the food enters the oesophagus. The radula is unique to molluscs, and is found in every class of mollusc apart from bivalves. Within the gastropods, the radula is used in feeding by both herbivorous and carnivorous snails and slugs. The arrangement of teeth (also known as denticles) on the radula ribbon varies considerably from one group to another as shown in the diagram on the left. Predatory marine snails such as the Naticidae use the radula plus an acidic secretion to bore through the shell of other molluscs. Other predatory marine snails, such as the Conidae, use a specialized radula tooth as a poisoned harpoon. Predatory pulmonate land slugs, such as the ghost slug, use elongated razor-sharp teeth on the radula to seize and devour earthworms. Predatory cephalopods, such as squid, use the radula for cutting prey. In most of the more ancient lineages of gastropods, the radula is used to graze by scraping diatoms and other microscopic algae off rock surfaces and other substrates. Limpets scrape algae from rocks using radula equipped with exceptionally hard rasping teeth. These teeth have the strongest known tensile strength of any biological material, outperforming spider silk. The mineral protein of the limpet teeth can withstand a tensile stress of 4.9 GPa, compared to 4 GPa of spider silk and 0.5 GPa of human teeth.  Fossilization and taphonomy  Because teeth are very resistant, often preserved when bones are not, and reflect the diet of the host organism, they are very valuable to archaeologists and palaeontologists. Early fish such as the thelodonts had scales composed of dentine and an enamel-like compound, suggesting that the origin of teeth was from scales which were retained in the mouth. Fish as early as the late Cambrian had dentine in their exoskeletons, which may have functioned in defense or for sensing their environments. Dentine can be as hard as the rest of teeth and is composed of collagen fibres, reinforced with hydroxyapatite.Though teeth are very resistant, they also can be brittle and highly susceptible to cracking. However, cracking of the tooth can be used as a diagnostic tool for predicting bite force. Additionally, enamel fractures can also give valuable insight into the diet and behaviour of archaeological and fossil samples. Decalcification removes the enamel from teeth and leaves only the organic interior intact, which comprises dentine and cementine. Enamel is quickly decalcified in acids, perhaps by dissolution by plant acids or via diagenetic solutions, or in the stomachs of vertebrate predators. Enamel can be lost by abrasion or spalling, and is lost before dentine or bone are destroyed by the fossilisation process. In such a case, the 'skeleton' of the teeth would consist of the dentine, with a hollow pulp cavity. The organic part of dentine, conversely, is destroyed by alkalis.  See also  Animal tooth development Dragon's teeth (mythology)  References   Sources  Shoshani, Jeheskel (2002). ""Tubulidentata"". In Robertson, Sarah (ed.). Encyclopedia of Life Sciences. Vol. 18: Svedberg, Theodor to Two-hybrid and Related Systems. London, UK: Nature Publishing Group. ISBN 978-1-56159-274-6.  External links  Beach, Chandler B., ed. (1914). ""Teeth"" . The New Student's Reference Work . Chicago: F. E. Compton and Co.","A tooth is one of the hard, white things in the mouth. Teeth (plural) are used to help the mastication process by chewing food. Chew means to break up and crush food so it can be swallowed (pushed down into the stomach). Most vertebrates have teeth. Birds are the biggest group that do not. Many invertebrates have mouthparts which, to some extent, act like teeth. Different animals have different kinds of teeth because they eat different foods. Some animals use teeth as a weapon. Human adults usually have 32 teeth. Human children usually have 20 teeth.  Natal teeth  Some human babies are born with teeth. Natal teeth are teeth that are present at birth. These are different from neonatal teeth which are teeth that emerge during the first month of life. Natal teeth are not common. They occur in about 1 out of every 2–3 thousand births. They are usually found on the lower jaw. Natal teeth are usually not well attached and may easily wobble.  Teeth eruption  Deciduous teeth or milk teeth or temporary teeth are the first set of teeth for most mammals. Humans have 20 of them. The first teeth (called ""primary teeth"") start to erupt (come through the gums of the jaw) when a baby is about 6 months old. When these teeth erupt it can really hurt. Babies chew on things to make the pain better. This is called teething (verb: to teethe). Most children have all 20 teeth by two or three years of age. At age 6–7 the permanent teeth start to erupt. By the age of 11–12 most children have 28 adult teeth. The last four teeth, called 'wisdom teeth' or third molars come in by age 17–21 in most people. Some people never grow wisdom teeth. Or they may have only two instead of four.  Teeth structure  The outside white part of teeth is called the enamel. The enamel is made of calcium phosphate and is very hard. Under the enamel is the dentine. The dentine is softer than the hard enamel. So it is hurt more by tooth decay (cavities). Under the dentine is the pulp which has the nerves and blood vessels that go to the tooth. This is the part that causes the pain of a toothache. Cementum is outside the dentine where there is no enamel. Cementum holds the tooth to the bone of the jaw.  Types of teeth  Incisor Canine tooth Premolar Molar  Healthy teeth  If they are protected and kept clean, teeth should stay for a person's whole life. Many people lose their teeth early because they do not do the right things to keep teeth healthy. Some things people can do to keep teeth healthy: Brush teeth after every meal and at bedtime with a soft-bristled brush. Floss after every meal (but at least once a day at bedtime). Flossing should be done before brushing! Drink water with fluoride before brushing. Or, use a fluoride mouthrinse (but not for children under age 6). See a dentist every 6 months for a tooth exam and tooth cleaning. Eat a healthy diet. Sugars like sucrose and glucose are bad for teeth. Milk and cheese are good for teeth because they have calcium.However, milk contains lactose which can cause cavities. Due to this, drinking a lot of milk can still cause cavities. Unsweetened (no sugar) chewing gum helps clean teeth, and makes salvia and removes food particles.Nothing with flavor in-between meals, give your saliva the two to three hours it needs to clean teeth. The saliva can not do that if there is a continuous food film being put on to the teeth. Dehydration leads to less saliva production. Drink plenty of water every day.  Disease of teeth  Plaque is the soft white substance that forms on teeth when they are not cleaned. It has bacteria in it that hurt enamel. If plaque is not cleaned off, after 2 days it can become tartar. Tartar is a hard substance that forms on teeth (mostly near the gums). Tartar makes gums unhealthy and makes more bacteria grow on the teeth. Plaque is cleaned off with a toothbrush. If tartar forms on teeth, a dentist must clean it off. The bacteria that are on teeth eat into the enamel. Cleaning and flossing teeth, eating good foods, and having a dentist take off plaque make less bacteria on teeth. If there is too much bacteria, they eat enamel faster than teeth make enamel. This makes holes in enamel called cavities. When a person gets cavities, he has the disease dental caries. Making cavities in enamel happens slowly. But once cavities go through enamel, the soft dentine is hurt much faster. Cavities may be fixed by dentists.  Related pages  Dental formula Dentition Dentures  References   Other websites  The New Student's Reference Work Wikisource Tooth Citizendium"
"The gums or gingiva (plural: gingivae) consist of the mucosal tissue that lies over the mandible and maxilla inside the mouth. Gum health and disease can have an effect on general health.  Structure  The gums are part of the soft tissue lining of the mouth. They surround the teeth and provide a seal around them. Unlike the soft tissue linings of the lips and cheeks, most of the gums are tightly bound to the underlying bone which helps resist the friction of food passing over them. Thus when healthy, it presents an effective barrier to the barrage of periodontal insults to deeper tissue. Healthy gums are usually coral pink in light skinned people, and may be naturally darker with melanin pigmentation. Changes in color, particularly increased redness, together with swelling and an increased tendency to bleed, suggest an inflammation that is possibly due to the accumulation of bacterial plaque. Overall, the clinical appearance of the tissue reflects the underlying histology, both in health and disease. When gum tissue is not healthy, it can provide a gateway for periodontal disease to advance into the deeper tissue of the periodontium, leading to a poorer prognosis for long-term retention of the teeth. Both the type of periodontal therapy and homecare instructions given to patients by dental professionals and restorative care are based on the clinical conditions of the tissue. The gums are divided anatomically into marginal, attached and interdental areas.  Marginal gums  The marginal gum is the edge of the gums surrounding the teeth in collar-like fashion. In about half of individuals, it is demarcated from the adjacent, attached gums by a shallow linear depression, the free gingival groove. This slight depression on the outer surface of the gum does not correspond to the depth of the gingival sulcus but instead to the apical border of the junctional epithelium. This outer groove varies in depth according to the area of the oral cavity. The groove is very prominent on mandibular anteriors and premolars. The marginal gum varies in width from 0.5 to 2.0 mm from the free gingival crest to the attached gingiva. The marginal gingiva follows the scalloped pattern established by the contour of the cementoenamel junction (CEJ) of the teeth. The marginal gingiva has a more translucent appearance than the attached gingiva, yet has a similar clinical appearance, including pinkness, dullness, and firmness. In contrast, the marginal gingiva lacks the presence of stippling, and the tissue is mobile or free from the underlying tooth surface, as can be demonstrated with a periodontal probe. The marginal gingiva is stabilized by the gingival fibers that have no bony support. The gingival margin, or free gingival crest, at the most superficial part of the marginal gingiva, is also easily seen clinically, and its location should be recorded on a patient's chart.  Attached gum  The attached gums are continuous with the marginal gum. It is firm, resilient, and tightly bound to the underlying periosteum of alveolar bone. The facial aspect of the attached gum extends to the relatively loose and movable alveolar mucosa, from which it is demarcated by the mucogingival junction. Attached gum may present with surface stippling. The tissue when dried is dull, firm, and immobile, with varying amounts of stippling. The width of the attached gum varies according to its location. The width of the attached gum on the facial aspect differs in different areas of the mouth. It is generally greatest in the incisor region (3.5 to 4.5 mm in the maxilla and 3.3 to 3.9 mm in the mandible) and less in the posterior segments, with the least width in the first premolar area (1.9 mm in the maxilla and 1.8 mm in the mandible). However, certain levels of attached gum may be necessary for the stability of the underlying root of the tooth.  Interdental gum  The interdental gum lies between the teeth. They occupy the gingival embrasure, which is the interproximal space beneath the area of tooth contact. The interdental papilla can be pyramidal or have a ""col"" shape. Attached gums are resistant to the forces of chewing and covered in keratin. The col varies in depth and width, depending on the expanse of the contacting tooth surfaces. The epithelium covering the col consists of the marginal gum of the adjacent teeth, except that it is nonkeratinized. It is mainly present in the broad interdental gingiva of the posterior teeth, and generally is not present with those interproximal tissue associated with anterior teeth because the latter tissue is narrower. In the absence of contact between adjacent teeth, the attached gum extends uninterrupted from the facial to the lingual aspect. The col may be important in the formation of periodontal disease but is visible clinically only when teeth are extracted.  Characteristics of healthy gums   Color  Healthy gums usually have a color that has been described as ""coral pink"". Other colours like red, white, and blue can signify inflammation (gingivitis) or pathology. Smoking or drug use can cause discoloring as well (such as ""meth mouth""). Although described as the colour coral pink, variation in colour is possible. This can be the result of factors such as: thickness and degree of keratinization of the epithelium, blood flow to the gums, natural pigmentation of the skin, disease, and medications.Since the colour of the gums can vary, uniformity of colour is more important than the underlying color itself. Excess deposits of melanin can cause dark spots or patches on the gums (melanin gingival hyperpigmentation), especially at the base of the interdental papillae. Gum depigmentation (aka gum bleaching) is a procedure used in cosmetic dentistry to remove these discolorations.  Contour  Healthy gums have a smooth curved or scalloped appearance around each tooth. Healthy gums fill and fit each space between the teeth, unlike the swollen gum papilla seen in gingivitis or the empty interdental embrasure seen in periodontal disease. Healthy gums hold tight to each tooth in that the gum surface narrows to ""knife-edge"" thin at the free gingival margin. On the other hand, inflamed gums have a ""puffy"" or ""rolled"" margin.  Texture  Healthy gums have a firm texture that is resistant to movement, and the surface texture often exhibits surface stippling. Unhealthy gums, on the other hand, are often swollen and less firm. Healthy gums have an orange-peel like texture to it due to the stippling.  Reaction to disturbance  Healthy gums usually have no reaction to normal disturbance such as brushing or periodontal probing. Unhealthy gums, conversely, will show bleeding on probing (BOP) and/or purulent exudate.  Clinical significance  The gingival cavity microecosystem, fueled by food residues and saliva, can support the growth of many microorganisms, of which some can be injurious to health. Improper or insufficient oral hygiene can thus lead to many gum and periodontal disorders, including gingivitis or periodontitis, which are major causes for tooth failure. Recent studies have also shown that anabolic steroids are also closely associated with gingival enlargement requiring a gingivectomy for many cases. Gingival recession is when there is an apical movement of the gum margin away from the biting (occlusal) surface. It may indicate an underlying inflammation such as periodontitis or pyorrhea, a pocket formation, dry mouth or displacement of the marginal gums away from the tooth by mechanical (such as brushing), chemical, or surgical means. Gingival retraction, in turn, may expose the dental neck and leave it vulnerable to the action of external stimuli, and may cause root sensitivity.  See also  Gum graft Head and neck anatomy Periodontitis  References ","The gums are the mucosal tissue that lies over the mandible and maxilla. They are also called gingiva. They surround the teeth and provide a seal around them.  About of healthy gums   Color  Healthy gums are usually ""coral pink."" Other colors like red, white, and blue can mean there is a problem. Red gums mean that the patient has gingivitis, or the inflammation of the gum.  Shape  Healthy gums fill and fit each space between teeth.  Texture  Healthy gums are firm and do not move very much.  Reaction to disturbance  Healthy gums usually have no reaction to normal disturbance such as brushing.  Additional images   Related pages  Gum graft Head and neck anatomy Periodontitis  Other websites  Periodontal disease Archived 2007-08-13 at the Wayback Machine"
"Inflammation (from Latin: inflammatio) is part of the complex biological response of body tissues to harmful stimuli, such as pathogens, damaged cells, or irritants, and is a protective response involving immune cells, blood vessels, and molecular mediators. The function of inflammation is to eliminate the initial cause of cell injury, clear out necrotic cells and tissues damaged from the original insult and the inflammatory process, and initiate tissue repair. The five cardinal signs are heat, pain, redness, swelling, and loss of function (Latin calor, dolor, rubor, tumor, and functio laesa). Inflammation is a generic response, and therefore it is considered as a mechanism of innate immunity, as compared to adaptive immunity, which is specific for each pathogen. Too little inflammation could lead to progressive tissue destruction by the harmful stimulus (e.g. bacteria) and compromise the survival of the organism. In contrast, too much inflammation, in the form of chronic inflammation, is associated with various diseases, such as hay fever, periodontal disease, atherosclerosis, and osteoarthritis. Inflammation can be classified as either acute or chronic. Acute inflammation is the initial response of the body to harmful stimuli, and is achieved by the increased movement of plasma and leukocytes (in particular granulocytes) from the blood into the injured tissues. A series of biochemical events propagates and matures the inflammatory response, involving the local vascular system, the immune system, and various cells within the injured tissue. Prolonged inflammation, known as chronic inflammation, leads to a progressive shift in the type of cells present at the site of inflammation, such as mononuclear cells, and is characterized by simultaneous destruction and healing of the tissue from the inflammatory process. Inflammation has also been classified as Type 1 and Type 2 based on the type of cytokines and helper T cells (Th1 and Th2) involved.Inflammation is not a synonym for infection. Infection describes the interaction between the action of microbial invasion and the reaction of the body's inflammatory response—the two components are considered together when discussing an infection, and the word is used to imply a microbial invasive cause for the observed inflammatory reaction. Inflammation, on the other hand, describes purely the body's immunovascular response—whatever the cause may be. But because of how often the two are correlated, words ending in the suffix -itis (which refers to inflammation) are sometimes informally described as referring to infection. For example, the word urethritis strictly means only ""urethral inflammation"", but clinical health care providers usually discuss urethritis as a urethral infection because urethral microbial invasion is the most common cause of urethritis. However, the inflammation–infection distinction becomes crucial for situations in pathology and medical diagnosis where inflammation is not driven by microbial invasion, such as the cases of atherosclerosis, trauma, ischemia, and autoimmune diseases (including type III hypersensitivity).  Causes   Types   Acute  Acute inflammation occurs immediately upon injury, lasting only a few days. Cytokines and chemokines promote the migration of neutrophils and macrophages to the site of inflammation. Pathogens, allergens, toxins, burns, and frostbite are some of the typical causes of acute inflammation. Toll-like receptors (TLRs) recognize microbial pathogens. Acute inflammation can be a defensive mechanism to protect tissues against injury. Inflammation lasting 2–6 weeks is designated subacute inflammation.  Cardinal signs  Acute inflammation is a short-term process, usually appearing within a few minutes or hours and begins to cease upon the removal of the injurious stimulus. It involves a coordinated and systemic mobilization response locally of various immune, endocrine and neurological mediators of acute inflammation. In a normal healthy response, it becomes activated, clears the pathogen and begins a repair process and then ceases. It is characterized by five cardinal signs:The traditional names for signs of inflammation come from Latin: Dolor (pain) Calor (heat) Rubor (redness) Tumor (swelling) Functio laesa (loss of function)The first four (classical signs) were described by Celsus (c. 30 BC–38 AD), while loss of function was probably added later by Galen. However, the addition of this fifth sign has also been ascribed to Thomas Sydenham and Virchow.Redness and heat are due to increased blood flow at body core temperature to the inflamed site; swelling is caused by accumulation of fluid; pain is due to the release of chemicals such as bradykinin and histamine that stimulate nerve endings. Loss of function has multiple causes.Acute inflammation of the lung (usually as in response to pneumonia) does not cause pain unless the inflammation involves the parietal pleura, which does have pain-sensitive nerve endings.  Acute process  The process of acute inflammation is initiated by resident immune cells already present in the involved tissue, mainly resident macrophages, dendritic cells, histiocytes, Kupffer cells and mast cells. These cells possess surface receptors known as pattern recognition receptors (PRRs), which recognize (i.e., bind) two subclasses of molecules: pathogen-associated molecular patterns (PAMPs) and damage-associated molecular patterns (DAMPs). PAMPs are compounds that are associated with various pathogens, but which are distinguishable from host molecules. DAMPs are compounds that are associated with host-related injury and cell damage. At the onset of an infection, burn, or other injuries, these cells undergo activation (one of the PRRs recognize a PAMP or DAMP) and release inflammatory mediators responsible for the clinical signs of inflammation. Vasodilation and its resulting increased blood flow causes the redness (rubor) and increased heat (calor). Increased permeability of the blood vessels results in an exudation (leakage) of plasma proteins and fluid into the tissue (edema), which manifests itself as swelling (tumor). Some of the released mediators such as bradykinin increase the sensitivity to pain (hyperalgesia, dolor). The mediator molecules also alter the blood vessels to permit the migration of leukocytes, mainly neutrophils and macrophages, to flow out of the blood vessels (extravasation) and into the tissue. The neutrophils migrate along a chemotactic gradient created by the local cells to reach the site of injury. The loss of function (functio laesa) is probably the result of a neurological reflex in response to pain. In addition to cell-derived mediators, several acellular biochemical cascade systems—consisting of preformed plasma proteins—act in parallel to initiate and propagate the inflammatory response. These include the complement system activated by bacteria and the coagulation and fibrinolysis systems activated by necrosis (e.g., burn, trauma).Acute inflammation may be regarded as the first line of defense against injury. Acute inflammatory response requires constant stimulation to be sustained. Inflammatory mediators are short-lived and are quickly degraded in the tissue. Hence, acute inflammation begins to cease once the stimulus has been removed.  Chronic  Chronic inflammation is inflammation that lasts for months or years. Macrophages, lymphocytes, and plasma cells predominate in chronic inflammation, in contrast to the neutrophils that predominate in acute inflammation. Diabetes, cardiovascular disease, allergies, and chronic obstructive pulmonary disease (COPD) are examples of diseases mediated by chronic inflammation. Obesity, smoking, stress and insufficient diet are some of the factors that promote chronic inflammation. A 2014 study reported that 60% of Americans had at least one chronic inflammatory condition, and 42% had more than one.  Cardinal signs  Common signs and symptoms that develop during chronic inflammation are: Body pain, arthralgia, myalgia Chronic fatigue and insomnia Depression, anxiety and mood disorders Gastrointestinal complications such as constipation, diarrhea, and acid reflux Weight gain or loss Frequent infections  Vascular component   Vasodilation and increased permeability  As defined, acute inflammation is an immunovascular response to inflammatory stimuli, which can include infection or trauma. This means acute inflammation can be broadly divided into a vascular phase that occurs first, followed by a cellular phase involving immune cells (more specifically myeloid granulocytes in the acute setting). The vascular component of acute inflammation involves the movement of plasma fluid, containing important proteins such as fibrin and immunoglobulins (antibodies), into inflamed tissue. Upon contact with PAMPs, tissue macrophages and mastocytes release vasoactive amines such as histamine and serotonin, as well as eicosanoids such as prostaglandin E2 and leukotriene B4 to remodel the local vasculature. Macrophages and endothelial cells release nitric oxide. These mediators vasodilate and permeabilize the blood vessels, which results in the net distribution of blood plasma from the vessel into the tissue space. The increased collection of fluid into the tissue causes it to swell (edema). This exuded tissue fluid contains various antimicrobial mediators from the plasma such as complement, lysozyme, antibodies, which can immediately deal damage to microbes, and opsonise the microbes in preparation for the cellular phase. If the inflammatory stimulus is a lacerating wound, exuded platelets, coagulants, plasmin and kinins can clot the wounded area using vitamin K-dependent mechanisms and provide haemostasis in the first instance. These clotting mediators also provide a structural staging framework at the inflammatory tissue site in the form of a fibrin lattice – as would construction scaffolding at a construction site – for the purpose of aiding phagocytic debridement and wound repair later on. Some of the exuded tissue fluid is also funneled by lymphatics to the regional lymph nodes, flushing bacteria along to start the recognition and attack phase of the adaptive immune system. Acute inflammation is characterized by marked vascular changes, including vasodilation, increased permeability and increased blood flow, which are induced by the actions of various inflammatory mediators. Vasodilation occurs first at the arteriole level, progressing to the capillary level, and brings about a net increase in the amount of blood present, causing the redness and heat of inflammation. Increased permeability of the vessels results in the movement of plasma into the tissues, with resultant stasis due to the increase in the concentration of the cells within blood – a condition characterized by enlarged vessels packed with cells. Stasis allows leukocytes to marginate (move) along the endothelium, a process critical to their recruitment into the tissues. Normal flowing blood prevents this, as the shearing force along the periphery of the vessels moves cells in the blood into the middle of the vessel.  Plasma cascade systems  The complement system, when activated, creates a cascade of chemical reactions that promotes opsonization, chemotaxis, and agglutination, and produces the MAC. The kinin system generates proteins capable of sustaining vasodilation and other physical inflammatory effects. The coagulation system or clotting cascade, which forms a protective protein mesh over sites of injury. The fibrinolysis system, which acts in opposition to the coagulation system, to counterbalance clotting and generate several other inflammatory mediators.  Plasma-derived mediators   non-exhaustive list  Cellular component  The cellular component involves leukocytes, which normally reside in blood and must move into the inflamed tissue via extravasation to aid in inflammation. Some act as phagocytes, ingesting bacteria, viruses, and cellular debris. Others release enzymatic granules that damage pathogenic invaders. Leukocytes also release inflammatory mediators that develop and maintain the inflammatory response. In general, acute inflammation is mediated by granulocytes, whereas chronic inflammation is mediated by mononuclear cells such as monocytes and lymphocytes.  Leukocyte extravasation  Various leukocytes, particularly neutrophils, are critically involved in the initiation and maintenance of inflammation. These cells must be able to move to the site of injury from their usual location in the blood, therefore mechanisms exist to recruit and direct leukocytes to the appropriate place. The process of leukocyte movement from the blood to the tissues through the blood vessels is known as extravasation and can be broadly divided up into a number of steps: Leukocyte margination and endothelial adhesion: The white blood cells within the vessels which are generally centrally located move peripherally towards the walls of the vessels. Activated macrophages in the tissue release cytokines such as IL-1 and TNFα, which in turn leads to production of chemokines that bind to proteoglycans forming gradient in the inflamed tissue and along the endothelial wall. Inflammatory cytokines induce the immediate expression of P-selectin on endothelial cell surfaces and P-selectin binds weakly to carbohydrate ligands on the surface of leukocytes and causes them to ""roll"" along the endothelial surface as bonds are made and broken. Cytokines released from injured cells induce the expression of E-selectin on endothelial cells, which functions similarly to P-selectin. Cytokines also induce the expression of integrin ligands such as ICAM-1 and VCAM-1 on endothelial cells, which mediate the adhesion and further slow leukocytes down. These weakly bound leukocytes are free to detach if not activated by chemokines produced in injured tissue after signal transduction via respective G protein-coupled receptors that activates integrins on the leukocyte surface for firm adhesion. Such activation increases the affinity of bound integrin receptors for ICAM-1 and VCAM-1 on the endothelial cell surface, firmly binding the leukocytes to the endothelium. Migration across the endothelium, known as transmigration, via the process of diapedesis: Chemokine gradients stimulate the adhered leukocytes to move between adjacent endothelial cells. The endothelial cells retract and the leukocytes pass through the basement membrane into the surrounding tissue using adhesion molecules such as ICAM-1. Movement of leukocytes within the tissue via chemotaxis: Leukocytes reaching the tissue interstitium bind to extracellular matrix proteins via expressed integrins and CD44 to prevent them from leaving the site. A variety of molecules behave as chemoattractants, for example, C3a or C5, and cause the leukocytes to move along a chemotactic gradient towards the source of inflammation.  Phagocytosis  Extravasated neutrophils in the cellular phase come into contact with microbes at the inflamed tissue. Phagocytes express cell-surface endocytic pattern recognition receptors (PRRs) that have affinity and efficacy against non-specific microbe-associated molecular patterns (PAMPs). Most PAMPs that bind to endocytic PRRs and initiate phagocytosis are cell wall components, including complex carbohydrates such as mannans and β-glucans, lipopolysaccharides (LPS), peptidoglycans, and surface proteins. Endocytic PRRs on phagocytes reflect these molecular patterns, with C-type lectin receptors binding to mannans and β-glucans, and scavenger receptors binding to LPS. Upon endocytic PRR binding, actin-myosin cytoskeletal rearrangement adjacent to the plasma membrane occurs in a way that endocytoses the plasma membrane containing the PRR-PAMP complex, and the microbe. Phosphatidylinositol and Vps34-Vps15-Beclin1 signalling pathways have been implicated to traffic the endocytosed phagosome to intracellular lysosomes, where fusion of the phagosome and the lysosome produces a phagolysosome. The reactive oxygen species, superoxides and hypochlorite bleach within the phagolysosomes then kill microbes inside the phagocyte. Phagocytic efficacy can be enhanced by opsonization. Plasma derived complement C3b and antibodies that exude into the inflamed tissue during the vascular phase bind to and coat the microbial antigens. As well as endocytic PRRs, phagocytes also express opsonin receptors Fc receptor and complement receptor 1 (CR1), which bind to antibodies and C3b, respectively. The co-stimulation of endocytic PRR and opsonin receptor increases the efficacy of the phagocytic process, enhancing the lysosomal elimination of the infective agent.  Cell-derived mediators   non-exhaustive list  Morphologic patterns  Specific patterns of acute and chronic inflammation are seen during particular situations that arise in the body, such as when inflammation occurs on an epithelial surface, or pyogenic bacteria are involved. Granulomatous inflammation: Characterised by the formation of granulomas, they are the result of a limited but diverse number of diseases, which include among others tuberculosis, leprosy, sarcoidosis, and syphilis. Fibrinous inflammation: Inflammation resulting in a large increase in vascular permeability allows fibrin to pass through the blood vessels. If an appropriate procoagulative stimulus is present, such as cancer cells, a fibrinous exudate is deposited. This is commonly seen in serous cavities, where the conversion of fibrinous exudate into a scar can occur between serous membranes, limiting their function. The deposit sometimes forms a pseudomembrane sheet. During inflammation of the intestine (pseudomembranous colitis), pseudomembranous tubes can be formed. Purulent inflammation: Inflammation resulting in large amount of pus, which consists of neutrophils, dead cells, and fluid. Infection by pyogenic bacteria such as staphylococci is characteristic of this kind of inflammation. Large, localised collections of pus enclosed by surrounding tissues are called abscesses. Serous inflammation: Characterised by the copious effusion of non-viscous serous fluid, commonly produced by mesothelial cells of serous membranes, but may be derived from blood plasma. Skin blisters exemplify this pattern of inflammation. Ulcerative inflammation: Inflammation occurring near an epithelium can result in the necrotic loss of tissue from the surface, exposing lower layers. The subsequent excavation in the epithelium is known as an ulcer.  Disorders  Inflammatory abnormalities are a large group of disorders that underlie a vast variety of human diseases. The immune system is often involved with inflammatory disorders, as demonstrated in both allergic reactions and some myopathies, with many immune system disorders resulting in abnormal inflammation. Non-immune diseases with causal origins in inflammatory processes include cancer, atherosclerosis, and ischemic heart disease.Examples of disorders associated with inflammation include:  Atherosclerosis  Atherosclerosis, formerly considered a bland lipid storage disease, actually involves an ongoing inflammatory response. Recent advances in basic science have established a fundamental role for inflammation in mediating all stages of atherosclerosis from initiation through progression and, ultimately, the thrombotic complications from it. These new findings provide important links between risk factors and the mechanisms of atherogenesis. Clinical studies have shown that this emerging biology of inflammation in atherosclerosis applies directly to human patients. Elevation in markers of inflammation predicts outcomes of patients with acute coronary syndromes, independently of myocardial damage. In addition, low-grade chronic inflammation, as indicated by levels of the inflammatory marker C-reactive protein, prospectively defines risk of atherosclerotic complications, thus adding to prognostic information provided by traditional risk factors. Moreover, certain treatments that reduce coronary risk also limit inflammation. In the case of lipid lowering with statins, the anti-inflammatory effect does not appear to correlate with reduction in low-density lipoprotein levels. These new insights on inflammation contribute to the etiology of atherosclerosis, and the practical clinical applications in risk stratification and the targeting of therapy for atherosclerosis.  Allergy  An allergic reaction, formally known as type 1 hypersensitivity, is the result of an inappropriate immune response triggering inflammation, vasodilation, and nerve irritation. A common example is hay fever, which is caused by a hypersensitive response by mast cells to allergens. Pre-sensitised mast cells respond by degranulating, releasing vasoactive chemicals such as histamine. These chemicals propagate an excessive inflammatory response characterised by blood vessel dilation, production of pro-inflammatory molecules, cytokine release, and recruitment of leukocytes. Severe inflammatory response may mature into a systemic response known as anaphylaxis.  Myopathies  Inflammatory myopathies are caused by the immune system inappropriately attacking components of muscle, leading to signs of muscle inflammation. They may occur in conjunction with other immune disorders, such as systemic sclerosis, and include dermatomyositis, polymyositis, and inclusion body myositis.  Leukocyte defects  Due to the central role of leukocytes in the development and propagation of inflammation, defects in leukocyte functionality often result in a decreased capacity for inflammatory defense with subsequent vulnerability to infection. Dysfunctional leukocytes may be unable to correctly bind to blood vessels due to surface receptor mutations, digest bacteria (Chédiak–Higashi syndrome), or produce microbicides (chronic granulomatous disease). In addition, diseases affecting the bone marrow may result in abnormal or few leukocytes.  Pharmacological  Certain drugs or exogenous chemical compounds are known to affect inflammation. Vitamin A deficiency, for example, causes an increase in inflammatory responses, and anti-inflammatory drugs work specifically by inhibiting the enzymes that produce inflammatory eicosanoids. Additionally, certain illicit drugs such as cocaine and ecstasy may exert some of their detrimental effects by activating transcription factors intimately involved with inflammation (e.g. NF-κB).  Cancer  Inflammation orchestrates the microenvironment around tumours, contributing to proliferation, survival and migration. Cancer cells use selectins, chemokines and their receptors for invasion, migration and metastasis. On the other hand, many cells of the immune system contribute to cancer immunology, suppressing cancer. Molecular intersection between receptors of steroid hormones, which have important effects on cellular development, and transcription factors that play key roles in inflammation, such as NF-κB, may mediate some of the most critical effects of inflammatory stimuli on cancer cells. This capacity of a mediator of inflammation to influence the effects of steroid hormones in cells is very likely to affect carcinogenesis. On the other hand, due to the modular nature of many steroid hormone receptors, this interaction may offer ways to interfere with cancer progression, through targeting of a specific protein domain in a specific cell type. Such an approach may limit side effects that are unrelated to the tumor of interest, and may help preserve vital homeostatic functions and developmental processes in the organism. According to a review of 2009, recent data suggests that cancer-related inflammation (CRI) may lead to accumulation of random genetic alterations in cancer cells.  Role in cancer  In 1863, Rudolf Virchow hypothesized that the origin of cancer was at sites of chronic inflammation. At present, chronic inflammation is estimated to contribute to approximately 15% to 25% of human cancers.  Mediators and DNA damage in cancer  An inflammatory mediator is a messenger that acts on blood vessels and/or cells to promote an inflammatory response. Inflammatory mediators that contribute to neoplasia include prostaglandins, inflammatory cytokines such as IL-1β, TNF-α, IL-6 and IL-15 and chemokines such as IL-8 and GRO-alpha. These inflammatory mediators, and others, orchestrate an environment that fosters proliferation and survival.Inflammation also causes DNA damages due to the induction of reactive oxygen species (ROS) by various intracellular inflammatory mediators. In addition, leukocytes and other phagocytic cells attracted to the site of inflammation induce DNA damages in proliferating cells through their generation of ROS and reactive nitrogen species (RNS). ROS and RNS are normally produced by these cells to fight infection. ROS, alone, cause more than 20 types of DNA damage. Oxidative DNA damages cause both mutations and epigenetic alterations. RNS also cause mutagenic DNA damages.A normal cell may undergo carcinogenesis to become a cancer cell if it is frequently subjected to DNA damage during long periods of chronic inflammation. DNA damages may cause genetic mutations due to inaccurate repair. In addition, mistakes in the DNA repair process may cause epigenetic alterations. Mutations and epigenetic alterations that are replicated and provide a selective advantage during somatic cell proliferation may be carcinogenic. Genome-wide analyses of human cancer tissues reveal that a single typical cancer cell may possess roughly 100 mutations in coding regions, 10-20 of which are ""driver mutations"" that contribute to cancer development. However, chronic inflammation also causes epigenetic changes such as DNA methylations, that are often more common than mutations. Typically, several hundreds to thousands of genes are methylated in a cancer cell (see DNA methylation in cancer). Sites of oxidative damage in chromatin can recruit complexes that contain DNA methyltransferases (DNMTs), a histone deacetylase (SIRT1), and a histone methyltransferase (EZH2), and thus induce DNA methylation. DNA methylation of a CpG island in a promoter region may cause silencing of its downstream gene (see CpG site and regulation of transcription in cancer). DNA repair genes, in particular, are frequently inactivated by methylation in various cancers (see hypermethylation of DNA repair genes in cancer). A 2018 report evaluated the relative importance of mutations and epigenetic alterations in progression to two different types of cancer. This report showed that epigenetic alterations were much more important than mutations in generating gastric cancers (associated with inflammation). However, mutations and epigenetic alterations were of roughly equal importance in generating esophageal squamous cell cancers (associated with tobacco chemicals and acetaldehyde, a product of alcohol metabolism).  HIV and AIDS  It has long been recognized that infection with HIV is characterized not only by development of profound immunodeficiency but also by sustained inflammation and immune activation. A substantial body of evidence implicates chronic inflammation as a critical driver of immune dysfunction, premature appearance of aging-related diseases, and immune deficiency. Many now regard HIV infection not only as an evolving virus-induced immunodeficiency, but also as chronic inflammatory disease. Even after the introduction of effective antiretroviral therapy (ART) and effective suppression of viremia in HIV-infected individuals, chronic inflammation persists. Animal studies also support the relationship between immune activation and progressive cellular immune deficiency: SIVsm infection of its natural nonhuman primate hosts, the sooty mangabey, causes high-level viral replication but limited evidence of disease. This lack of pathogenicity is accompanied by a lack of inflammation, immune activation and cellular proliferation. In sharp contrast, experimental SIVsm infection of rhesus macaque produces immune activation and AIDS-like disease with many parallels to human HIV infection.Delineating how CD4 T cells are depleted and how chronic inflammation and immune activation are induced lies at the heart of understanding HIV pathogenesis––one of the top priorities for HIV research by the Office of AIDS Research, National Institutes of Health. Recent studies demonstrated that caspase-1-mediated pyroptosis, a highly inflammatory form of programmed cell death, drives CD4 T-cell depletion and inflammation by HIV. These are the two signature events that propel HIV disease progression to AIDS. Pyroptosis appears to create a pathogenic vicious cycle in which dying CD4 T cells and other immune cells (including macrophages and neutrophils) release inflammatory signals that recruit more cells into the infected lymphoid tissues to die. The feed-forward nature of this inflammatory response produces chronic inflammation and tissue injury. Identifying pyroptosis as the predominant mechanism that causes CD4 T-cell depletion and chronic inflammation, provides novel therapeutic opportunities, namely caspase-1 which controls the pyroptotic pathway. In this regard, pyroptosis of CD4 T cells and secretion of pro-inflammatory cytokines such as IL-1β and IL-18 can be blocked in HIV-infected human lymphoid tissues by addition of the caspase-1 inhibitor VX-765, which has already proven to be safe and well tolerated in phase II human clinical trials. These findings could propel development of an entirely new class of ""anti-AIDS"" therapies that act by targeting the host rather than the virus. Such agents would almost certainly be used in combination with ART. By promoting ""tolerance"" of the virus instead of suppressing its replication, VX-765 or related drugs may mimic the evolutionary solutions occurring in multiple monkey hosts (e.g. the sooty mangabey) infected with species-specific lentiviruses that have led to a lack of disease, no decline in CD4 T-cell counts, and no chronic inflammation.  Resolution  The inflammatory response must be actively terminated when no longer needed to prevent unnecessary ""bystander"" damage to tissues. Failure to do so results in chronic inflammation, and cellular destruction. Resolution of inflammation occurs by different mechanisms in different tissues. Mechanisms that serve to terminate inflammation include: Acute inflammation normally resolves by mechanisms that have remained somewhat elusive. Emerging evidence now suggests that an active, coordinated program of resolution initiates in the first few hours after an inflammatory response begins. After entering tissues, granulocytes promote the switch of arachidonic acid–derived prostaglandins and leukotrienes to lipoxins, which initiate the termination sequence. Neutrophil recruitment thus ceases and programmed death by apoptosis is engaged. These events coincide with the biosynthesis, from omega-3 polyunsaturated fatty acids, of resolvins and protectins, which critically shorten the period of neutrophil infiltration by initiating apoptosis. As a consequence, apoptotic neutrophils undergo phagocytosis by macrophages, leading to neutrophil clearance and release of anti-inflammatory and reparative cytokines such as transforming growth factor-β1. The anti-inflammatory program ends with the departure of macrophages through the lymphatics.  Connection to depression  There is evidence for a link between inflammation and depression. Inflammatory processes can be triggered by negative cognitions or their consequences, such as stress, violence, or deprivation. Thus, negative cognitions can cause inflammation that can, in turn, lead to depression. In addition, there is increasing evidence that inflammation can cause depression because of the increase of cytokines, setting the brain into a ""sickness mode"". Classical symptoms of being physically sick, such as lethargy, show a large overlap in behaviors that characterize depression. Levels of cytokines tend to increase sharply during the depressive episodes of people with bipolar disorder and drop off during remission. Furthermore, it has been shown in clinical trials that anti-inflammatory medicines taken in addition to antidepressants not only significantly improves symptoms but also increases the proportion of subjects positively responding to treatment. Inflammations that lead to serious depression could be caused by common infections such as those caused by a virus, bacteria or even parasites.  Connection to delirium  There is evidence for a link between inflammation and delirium based on the results of a recent longitudinal study investigating CRP in COVID-19 patients.  Systemic effects  An infectious organism can escape the confines of the immediate tissue via the circulatory system or lymphatic system, where it may spread to other parts of the body. If an organism is not contained by the actions of acute inflammation, it may gain access to the lymphatic system via nearby lymph vessels. An infection of the lymph vessels is known as lymphangitis, and infection of a lymph node is known as lymphadenitis. When lymph nodes cannot destroy all pathogens, the infection spreads further. A pathogen can gain access to the bloodstream through lymphatic drainage into the circulatory system. When inflammation overwhelms the host, systemic inflammatory response syndrome is diagnosed. When it is due to infection, the term sepsis is applied, with the terms bacteremia being applied specifically for bacterial sepsis and viremia specifically to viral sepsis. Vasodilation and organ dysfunction are serious problems associated with widespread infection that may lead to septic shock and death.  Acute-phase proteins  Inflammation also is characterized by high systemic levels of acute-phase proteins. In acute inflammation, these proteins prove beneficial; however, in chronic inflammation, they can contribute to amyloidosis. These proteins include C-reactive protein, serum amyloid A, and serum amyloid P, which cause a range of systemic effects including:  Leukocyte numbers  Inflammation often affects the numbers of leukocytes present in the body: Leukocytosis is often seen during inflammation induced by infection, where it results in a large increase in the amount of leukocytes in the blood, especially immature cells. Leukocyte numbers usually increase to between 15 000 and 20 000 cells per microliter, but extreme cases can see it approach 100 000 cells per microliter. Bacterial infection usually results in an increase of neutrophils, creating neutrophilia, whereas diseases such as asthma, hay fever, and parasite infestation result in an increase in eosinophils, creating eosinophilia. Leukopenia can be induced by certain infections and diseases, including viral infection, Rickettsia infection, some protozoa, tuberculosis, and some cancers.  Interleukins and obesity  With the discovery of interleukins (IL), the concept of systemic inflammation developed. Although the processes involved are identical to tissue inflammation, systemic inflammation is not confined to a particular tissue but involves the endothelium and other organ systems. Chronic inflammation is widely observed in obesity. Obese people commonly have many elevated markers of inflammation, including: IL-6 (Interleukin-6) Low-grade chronic inflammation is characterized by a two- to threefold increase in the systemic concentrations of cytokines such as TNF-α, IL-6, and CRP. Waist circumference correlates significantly with systemic inflammatory response.Loss of white adipose tissue reduces levels of inflammation markers. As of 2017 the association of systemic inflammation with insulin resistance and type 2 diabetes, and with atherosclerosis was under preliminary research, although rigorous clinical trials had not been conducted to confirm such relationships.C-reactive protein (CRP) is generated at a higher level in obese people, and may increase the risk for cardiovascular diseases.  Outcomes  The outcome in a particular circumstance will be determined by the tissue in which the injury has occurred—and the injurious agent that is causing it. Here are the possible outcomes to inflammation: ResolutionThe complete restoration of the inflamed tissue back to a normal status. Inflammatory measures such as vasodilation, chemical production, and leukocyte infiltration cease, and damaged parenchymal cells regenerate. Such is usually the outcome when limited or short-lived inflammation has occurred. FibrosisLarge amounts of tissue destruction, or damage in tissues unable to regenerate, cannot be regenerated completely by the body. Fibrous scarring occurs in these areas of damage, forming a scar composed primarily of collagen. The scar will not contain any specialized structures, such as parenchymal cells, hence functional impairment may occur. Abscess formationA cavity is formed containing pus, an opaque liquid containing dead white blood cells and bacteria with general debris from destroyed cells. Chronic inflammationIn acute inflammation, if the injurious agent persists then chronic inflammation will ensue. This process, marked by inflammation lasting many days, months or even years, may lead to the formation of a chronic wound. Chronic inflammation is characterised by the dominating presence of macrophages in the injured tissue. These cells are powerful defensive agents of the body, but the toxins they release—including reactive oxygen species—are injurious to the organism's own tissues as well as invading agents. As a consequence, chronic inflammation is almost always accompanied by tissue destruction.  Examples  Inflammation is usually indicated by adding the suffix ""itis"", as shown below. However, some conditions, such as asthma and pneumonia, do not follow this convention. More examples are available at List of types of inflammation.  See also   Notes   References   External links  Inflammation at the U.S. National Library of Medicine Medical Subject Headings (MeSH)","Inflammation is the first reaction of the immune system to an infection or irritation. It is an attempt of the immune system to dispel invaders and repair the body. It can happen in many parts of the body and often involves the following five steps: The inflamed spot becomes red. The inflamed spot becomes hot. The inflamed spot begins to swell. The inflamed spot begins to feel uncomfortable. The inflamed spot might cause surrounding organs to dysfunction.The first four of these reactions have been known for a long time, since antiquity. Finding them is attributed to Celsus. The last one was added by Rudolf Virchow in 1858. There are two types of inflammation: acute and chronic. Acute inflammations are more intense but short-lived, while chronic inflammations are less intense but long-lived. Examples of acute inflammation include skin disorders (e.g., psoriasis, dandruff) and arthritis, while chronic inflammation can be responsible for diseases such as cancer, heart disease, type 2 diabetes and Alzheimer's disease. Adoption of healthy diet, physical exercise and rest are some of the ways to reduce Inflammations.  Related pages  Infection Injury  References   Other websites  Media related to Inflammation at Wikimedia Commons"
"Selective serotonin reuptake inhibitors (SSRIs) are a class of drugs that are typically used as antidepressants in the treatment of major depressive disorder, anxiety disorders, and other psychological conditions. SSRIs increase the extracellular level of the neurotransmitter serotonin by limiting its reabsorption (reuptake) into the presynaptic cell. They have varying degrees of selectivity for the other monoamine transporters, with pure SSRIs having strong affinity for the serotonin transporter and only weak affinity for the norepinephrine and dopamine transporters. SSRIs are the most widely prescribed antidepressants in many countries. The efficacy of SSRIs in mild or moderate cases of depression has been disputed and may or may not be outweighed by side effects, especially in adolescent populations.  Medical uses  The main indication for SSRIs is major depressive disorder; however, they are frequently prescribed for anxiety disorders, such as social anxiety disorder, generalized anxiety disorder, panic disorder, obsessive–compulsive disorder (OCD), eating disorders, chronic pain, and, in some cases, for posttraumatic stress disorder (PTSD). They are also frequently used to treat depersonalization disorder, although with varying results.  Depression  Antidepressants are recommended by the UK National Institute for Health and Care Excellence (NICE) as a first-line treatment of severe depression and for the treatment of mild-to-moderate depression that persists after conservative measures such as cognitive therapy. They recommend against their routine use by those who have chronic health problems and mild depression.There has been controversy regarding the efficacy of SSRIs in treating depression depending on its severity and duration. Two meta-analyses published in 2008 (Kirsch) and 2010 (Fournier) found that in mild and moderate depression, the effect of SSRIs is small or none compared to placebo, while in very severe depression the effect of SSRIs is between ""relatively small"" and ""substantial"". The 2008 meta-analysis combined 35 clinical trials submitted to the Food and Drug Administration (FDA) before licensing of four newer antidepressants (including the SSRIs paroxetine and fluoxetine, the non-SSRI antidepressant nefazodone, and the serotonin and norepinephrine reuptake inhibitor (SNRI) venlafaxine). The authors attributed the relationship between severity and efficacy to a reduction of the placebo effect in severely depressed patients, rather than an increase in the effect of the medication. Some researchers have questioned the statistical basis of this study suggesting that it underestimates the effect size of antidepressants. A 2012 meta-analysis of fluoxetine and venlafaxine concluded that statistically and clinically significant treatment effects were observed for each drug relative to placebo irrespective of baseline depression severity; some of the authors however disclosed substantial relationships with pharmaceutical industries. A 2017 systematic review stated that ""SSRIs versus placebo seem to have statistically significant effects on depressive symptoms, but the clinical significance of these effects seems questionable and all trials were at high risk of bias. Furthermore, SSRIs versus placebo significantly increase the risk of both serious and non-serious adverse events. Our results show that the harmful effects of SSRIs versus placebo for major depressive disorder seem to outweigh any potentially small beneficial effects"". Fredrik Hieronymus et al. criticized the review as inaccurate and misleading, but they also disclosed multiple ties to pharmaceutical industries and receipt of speaker's fees.In 2018, a systematic review and network meta-analysis comparing the efficacy and acceptability of 21 antidepressant drugs showed escitalopram to be one of the most effective.The use of SSRIs in children with depression remains controversial. A 2021 Cochrane review concluded that, for children and adolescents, SSRIs ""may reduce depression symptoms in a small and unimportant way compared with placebo."" However, it also noted significant methodological limitations that make drawing definitive conclusions about efficacy difficult. Fluoxetine is the only SSRI authorized for use in children and adolescents with moderate to severe depression in the United Kingdom.  Social anxiety disorder  Some SSRIs are effective for social anxiety disorder, although their effects on symptoms is not always robust and their use is sometimes rejected in favor of psychological therapies. Paroxetine was the first drug to be approved for social anxiety disorder and it is considered effective for this disorder, sertraline and fluvoxamine were later approved for it, too, escitalopram and citalopram are used off label with acceptable efficacy, while fluoxetine is not considered to be effective for this disorder.  Post-traumatic stress disorder  PTSD is relatively hard to treat and generally treatment is not highly effective; SSRIs are no exception. They are not very effective for this disorder and only two SSRI are FDA approved for this condition, paroxetine and sertraline. Paroxetine has slightly higher response and remission rates for PTSD than sertraline, but both are not fully effective for many patients. Fluoxetine is used off label, but with mixed results; venlafaxine, an SNRI, is considered somewhat effective, although used off label, too. Fluvoxamine, escitalopram and citalopram are not well tested in this disorder. Paroxetine remains the most suitable drug for PTSD as of now, but with limited benefits.  Generalized anxiety disorder  SSRIs are recommended by the National Institute for Health and Care Excellence (NICE) for the treatment of generalized anxiety disorder (GAD) that has failed to respond to conservative measures such as education and self-help activities. GAD is a common disorder of which the central feature is excessive worry about a number of different events. Key symptoms include excessive anxiety about multiple events and issues, and difficulty controlling worrisome thoughts that persists for at least 6 months. Antidepressants provide a modest-to-moderate reduction in anxiety in GAD, and are superior to placebo in treating GAD. The efficacy of different antidepressants is similar.  Obsessive–compulsive disorder  In Canada, SSRIs are a first-line treatment of adult obsessive–compulsive disorder (OCD). In the UK, they are first-line treatment only with moderate to severe functional impairment and as second line treatment for those with mild impairment, though, as of early 2019, this recommendation is being reviewed. In children, SSRIs can be considered a second line therapy in those with moderate-to-severe impairment, with close monitoring for psychiatric adverse effects. SSRIs, especially fluvoxamine, which is the first one to be FDA approved for OCD, are efficacious in its treatment; patients treated with SSRIs are about twice as likely to respond to treatment as those treated with placebo. Efficacy has been demonstrated both in short-term treatment trials of 6 to 24 weeks and in discontinuation trials of 28 to 52 weeks duration.  Panic disorder  Paroxetine CR was superior to placebo on the primary outcome measure. In a 10-wk randomized controlled, double-blind trial escitalopram was more effective than placebo. Fluvoxamine, another SSRI, has shown positive results. However, evidence for their effectiveness and acceptability is unclear.  Eating disorders  Antidepressants are recommended as an alternative or additional first step to self-help programs in the treatment of bulimia nervosa. SSRIs (fluoxetine in particular) are preferred over other anti-depressants due to their acceptability, tolerability, and superior reduction of symptoms in short-term trials. Long-term efficacy remains poorly characterized. Similar recommendations apply to binge eating disorder. SSRIs provide short-term reductions in binge eating behavior, but have not been associated with significant weight loss.Clinical trials have generated mostly negative results for the use of SSRIs in the treatment of anorexia nervosa. Treatment guidelines from the National Institute of Health and Clinical Excellence recommend against the use of SSRIs in this disorder. Those from the American Psychiatric Association note that SSRIs confer no advantage regarding weight gain, but that they may be used for the treatment of co-existing depressive, anxiety, or OCD.  Stroke recovery  SSRIs have been used off-label in the treatment of stroke patients, including those with and without symptoms of depression. A 2019 meta-analysis of randomized, controlled clinical trials found a statistically significant effect of SSRIs on dependence, neurological deficit, depression, and anxiety but the studies had a high risk of bias. No reliable evidence points to their routine use to promote recovery following stroke. Thrombosis risk is reduced because SSRIs limit serotonin availability to platelets, so benefits, such as stroke recovery, of reduced clotting go up, with SSRIs.  Premature ejaculation  SSRIs are effective for the treatment of premature ejaculation. Taking SSRIs on a chronic, daily basis is more effective than taking them prior to sexual activity. The increased efficacy of treatment when taking SSRIs on a daily basis is consistent with clinical observations that the therapeutic effects of SSRIs generally take several weeks to emerge. Sexual dysfunction ranging from decreased libido to anorgasmia is usually considered to be a significantly distressing side effect which may lead to noncompliance in patients receiving SSRIs. However, for those with premature ejaculation, this very same side effect becomes the desired effect.  Other uses  SSRIs such as sertraline have been found to be effective in decreasing anger.  Side effects  Side effects vary among the individual drugs of this class and may include: increased risk of bone fractures akathisia suicidal ideation (thoughts of suicide) and other risks (see below)  Sexual dysfunction  SSRIs can cause various types of sexual dysfunction such as anorgasmia, erectile dysfunction, diminished libido, genital numbness, and sexual anhedonia (pleasureless orgasm). Sexual problems are common with SSRIs. While initial trials showed side effects in 5-15% of users (based on spontaneous reporting by users), later studies (based on asking patients directly) have shown side effect rates from 36% to 98%. Poor sexual function is also one of the most common reasons people stop the medication.In some cases, symptoms of sexual dysfunction may persist after discontinuation of SSRIs.: 14 This combination of symptoms is sometimes referred to as Post-SSRI Sexual Dysfunction (PSSD). On the 11th of June 2019 the Pharmacovigilance Risk Assessment Committee of the European Medicines Agency concluded that a possible relationship exists between SSRI use and persistent sexual dysfunction after cessation of use. The committee concluded that a warning should be added to the label of SSRIs and SNRIs regarding this possible risk.The mechanism by which SSRIs may cause sexual side effects is not well understood as of 2021. The range of possible mechanisms includes (1) nonspecific neurological effects (e.g., sedation) that globally impair behavior including sexual function; (2) specific effects on brain systems mediating sexual function; (3) specific effects on peripheral tissues and organs, such as the penis, that mediate sexual function; and (4) direct or indirect effects on hormones mediating sexual function. Management strategies include: for erectile dysfunction the addition of a PDE5 inhibitor such as sildenafil; for decreased libido, possibly adding or switching to bupropion; and for overall sexual dysfunction, switching to nefazodone.A number of non-SSRI drugs are not associated with sexual side effects (such as bupropion, mirtazapine, tianeptine, agomelatine, tranylcypromine and moclobemide). Several studies have suggested that SSRIs may adversely affect semen quality.While trazodone (an antidepressant with alpha adrenergic receptor blockade) is a notorious cause of priapism, cases of priapism have also been reported with certain SSRIs (e.g. fluoxetine, citalopram).  Emotional blunting  Certain antidepressants may cause emotional blunting, characterized by reduced intensity of both positive and negative emotions as well as symptoms of apathy, indifference, and amotivation. It may be experienced as either beneficial or detrimental depending on the situation. This side effect has been particularly associated with serotonergic antidepressants like SSRIs and SNRIs, but may be less with atypical antidepressants like bupropion, agomelatine, and vortioxetine. Higher doses of antidepressants seem to be more likely to produce emotional blunting than lower doses. It can be decreased by reducing dosage, discontinuing the medication, or switching to a different antidepressant that may have less propensity for causing this side effect.  Vision  Acute narrow-angle glaucoma is the most common and important ocular side effect of SSRIs, and often goes misdiagnosed.  Cardiac  SSRIs do not appear to affect the risk of coronary heart disease (CHD) in those without a previous diagnosis of CHD. A large cohort study suggested no substantial increase in the risk of cardiac malformations attributable to SSRI usage during the first trimester of pregnancy. A number of large studies of people without known pre-existing heart disease have reported no EKG changes related to SSRI use. The recommended maximum daily dose of citalopram and escitalopram was reduced due to concerns with QT prolongation. In overdose, fluoxetine has been reported to cause sinus tachycardia, myocardial infarction, junctional rhythms and trigeminy. Some authors have suggested electrocardiographic monitoring in patients with severe pre-existing cardiovascular disease who are taking SSRIs.  Bleeding  SSRIs directly increase the risk of abnormal bleeding by lowering platelet serotonin levels, which are essential to platelet-driven hemostasis. SSRIs interact with anticoagulants, like warfarin, and antiplatelet drugs, like aspirin. This includes an increased risk of GI bleeding, and post operative bleeding. The relative risk of intracranial bleeding is increased, but the absolute risk is very low. SSRIs are known to cause platelet dysfunction. This risk is greater in those who are also on anticoagulants, antiplatelet agents and NSAIDs (nonsteroidal anti-inflammatory drugs), as well as with the co-existence of underlying diseases such as cirrhosis of the liver or liver failure.  Fracture risk  Evidence from longitudinal, cross-sectional, and prospective cohort studies suggests an association between SSRI usage at therapeutic doses and a decrease in bone mineral density, as well as increased fracture risk, a relationship that appears to persist even with adjuvant bisphosphonate therapy. However, because the relationship between SSRIs and fractures is based on observational data as opposed to prospective trials, the phenomenon is not definitively causal. There also appears to be an increase in fracture-inducing falls with SSRI use, suggesting the need for increased attention to fall risk in elderly patients using the medication. The loss of bone density does not appear to occur in younger patients taking SSRIs.  Bruxism  SSRI and SNRI antidepressants may cause jaw pain/jaw spasm reversible syndrome (although it is not common). Buspirone appears to be successful in treating bruxism on SSRI/SNRI induced jaw clenching.  Serotonin syndrome  Serotonin syndrome is typically caused by the use of two or more serotonergic drugs, including SSRIs. Serotonin syndrome is a condition that can range from mild (most common) to deadly. Mild symptoms may consist of increased heart rate, fever, shivering, sweating, dilated pupils, myoclonus (intermittent jerking or twitching), as well as hyperreflexia. Concomitant use of SSRIs or SNRIs for depression with a triptan for migraine does not appear to heighten the risk of the serotonin syndrome. Taking monoamine oxidase inhibitors (MAOIs) in combination with SSRIs can be fatal, since MAOIs disrupt monoamine oxidase, an enzyme which is needed to break down serotonin and other neurotransmitters. Without monoamine oxidase, the body is unable to eliminate excess neurotransmitters, allowing them to build up to dangerous levels. The prognosis for recovery in a hospital setting is generally good if serotonin syndrome is correctly identified. Treatment consists of discontinuing any serotonergic drugs and providing supportive care to manage agitation and hyperthermia, usually with benzodiazepines.  Suicide risk   Children and adolescents  Meta analyses of short duration randomized clinical trials have found that SSRI use is related to a higher risk of suicidal behavior in children and adolescents. For instance, a 2004 U.S. Food and Drug Administration (FDA) analysis of clinical trials on children with major depressive disorder found statistically significant increases of the risks of ""possible suicidal ideation and suicidal behavior"" by about 80%, and of agitation and hostility by about 130%. According to the FDA, the heightened risk of suicidality is within the first one to two months of treatment. The National Institute for Health and Care Excellence (NICE) places the excess risk in the ""early stages of treatment"". The European Psychiatric Association places the excess risk in the first two weeks of treatment and, based on a combination of epidemiological, prospective cohort, medical claims, and randomized clinical trial data, concludes that a protective effect dominates after this early period. A 2014 Cochrane review found that at six to nine months, suicidal ideation remained higher in children treated with antidepressants compared to those treated with psychological therapy.A recent comparison of aggression and hostility occurring during treatment with fluoxetine to placebo in children and adolescents found that no significant difference between the fluoxetine group and a placebo group. There is also evidence that higher rates of SSRI prescriptions are associated with lower rates of suicide in children, though since the evidence is correlational, the true nature of the relationship is unclear.In 2004, the Medicines and Healthcare products Regulatory Agency (MHRA) in the United Kingdom judged fluoxetine (Prozac) to be the only antidepressant that offered a favorable risk-benefit ratio in children with depression, though it was also associated with a slight increase in the risk of self-harm and suicidal ideation. Only two SSRIs are licensed for use with children in the UK, sertraline (Zoloft) and fluvoxamine (Luvox), and only for the treatment of obsessive–compulsive disorder. Fluoxetine is not licensed for this use.  Adults  It is unclear whether SSRIs affect the risk of suicidal behavior in adults. A 2005 meta-analysis of drug company data found no evidence that SSRIs increased the risk of suicide; however, important protective or hazardous effects could not be excluded. A 2005 review observed that suicide attempts are increased in those who use SSRIs as compared to placebo and compared to therapeutic interventions other than tricyclic antidepressants. No difference risk of suicide attempts was detected between SSRIs versus tricyclic antidepressants. On the other hand, a 2006 review suggests that the widespread use of antidepressants in the new ""SSRI-era"" appears to have led to a highly significant decline in suicide rates in most countries with traditionally high baseline suicide rates. The decline is particularly striking for women who, compared with men, seek more help for depression. Recent clinical data on large samples in the US too have revealed a protective effect of antidepressant against suicide. A 2006 meta-analysis of random controlled trials suggests that SSRIs increase suicide ideation compared with placebo. However, the observational studies suggest that SSRIs did not increase suicide risk more than older antidepressants. The researchers stated that if SSRIs increase suicide risk in some patients, the number of additional deaths is very small because ecological studies have generally found that suicide mortality has declined (or at least not increased) as SSRI use has increased. An additional meta-analysis by the FDA in 2006 found an age-related effect of SSRI's. Among adults younger than 25 years, results indicated that there was a higher risk for suicidal behavior. For adults between 25 and 64, the effect appears neutral on suicidal behavior but possibly protective for suicidal behavior for adults between the ages of 25 and 64. For adults older than 64, SSRI's seem to reduce the risk of both suicidal behavior. In 2016 a study criticized the effects of the FDA Black Box suicide warning inclusion in the prescription. The authors discussed the suicide rates might increase also as a consequence of the warning.  Risk of death  A 2017 meta-analysis found that antidepressants including SSRIs were associated with significantly increased risk of death (+33%) and new cardiovascular complications (+14%) in the general population. Conversely, risks were not greater in people with existing cardiovascular disease.  Pregnancy and breastfeeding  SSRI use in pregnancy has been associated with a variety of risks with varying degrees of proof of causation. As depression is independently associated with negative pregnancy outcomes, determining the extent to which observed associations between antidepressant use and specific adverse outcomes reflects a causative relationship has been difficult in some cases. In other cases, the attribution of adverse outcomes to antidepressant exposure seems fairly clear. SSRI use in pregnancy is associated with an increased risk of spontaneous abortion of about 1.7-fold. Use is also associated with preterm birth. According to some researches, decreased body weight of the child, intrauterine growth retardation, neonatal adaptive syndrome, and persistent pulmonary hypertension also was noted.A systematic review of the risk of major birth defects in antidepressant-exposed pregnancies found a small increase (3% to 24%) in the risk of major malformations and a risk of cardiovascular birth defects that did not differ from non-exposed pregnancies. Other studies have found an increased risk of cardiovascular birth defects among depressed mothers not undergoing SSRI treatment, suggesting the possibility of ascertainment bias, e.g. that worried mothers may pursue more aggressive testing of their infants. Another study found no increase in cardiovascular birth defects and a 27% increased risk of major malformations in SSRI exposed pregnancies.The FDA issued a statement on July 19, 2006, stating nursing mothers on SSRIs must discuss treatment with their physicians. However, the medical literature on the safety of SSRIs has determined that some SSRIs like Sertraline and Paroxetine are considered safe for breastfeeding.  Neonatal abstinence syndrome  Several studies have documented neonatal abstinence syndrome, a syndrome of neurological, gastrointestinal, autonomic, endocrine and/or respiratory symptoms among a large minority of infants with intrauterine exposure. These syndromes are short-lived, but insufficient long-term data is available to determine whether there are long-term effects.  Persistent pulmonary hypertension  Persistent pulmonary hypertension (PPHN) is a serious and life-threatening, but very rare, lung condition that occurs soon after birth of the newborn. Newborn babies with PPHN have high pressure in their lung blood vessels and are not able to get enough oxygen into their bloodstream. About 1 to 2 babies per 1000 babies born in the U.S. develop PPHN shortly after birth, and often they need intensive medical care. It is associated with about a 25% risk of significant long-term neurological deficits. A 2014 meta analysis found no increased risk of persistent pulmonary hypertension associated with exposure to SSRI's in early pregnancy and a slight increase in risk associates with exposure late in pregnancy; ""an estimated 286 to 351 women would need to be treated with an SSRI in late pregnancy to result in an average of one additional case of persistent pulmonary hypertension of the newborn"". A review published in 2012 reached conclusions very similar to those of the 2014 study.  Neuropsychiatric effects in offspring  According to a 2015 review available data found that ""some signal exists suggesting that antenatal exposure to SSRIs may increase the risk of ASDs (autism spectrum disorders)"" even though a large cohort study published in 2013 and a cohort study using data from Finland's national register between the years 1996 and 2010 and published in 2016 found no significant association between SSRI use and autism in offspring. The 2016 Finland study also found no association with ADHD, but did find an association with increased rates of depression diagnoses in early adolescence.  Bipolar switch  In adults and children with bipolar disorder, SSRIs may cause a bipolar switch from depression into hypomania/mania. When taken with mood stabilizers, the risk of switching is not increased, however when taking SSRI's as a monotherapy, the risk of switching may be twice or three times that of the average. The changes are not often easy to detect and require monitoring by family and mental health professionals. This switch might happen even with no prior (hypo)manic episodes and might therefore not be foreseen by the psychiatrist.  Interactions  The following drugs may precipitate serotonin syndrome in people on SSRIs: Linezolid Monoamine oxidase inhibitors (MAOIs) including moclobemide, phenelzine, tranylcypromine, selegiline and methylene blue Lithium Sibutramine MDMA (ecstasy) Dextromethorphan Tramadol 5-HTP Pethidine/meperidine St. John's wort Yohimbe Tricyclic antidepressants (TCAs) Serotonin-norepinephrine reuptake inhibitors (SNRIs) Buspirone Triptan Mirtazapine Methylene bluePainkillers of the NSAIDs drug family may interfere and reduce efficiency of SSRIs and may compound the increased risk of gastrointestinal bleeds caused by SSRI use. NSAIDs include: Aspirin Ibuprofen (Advil, Nurofen) Naproxen (Aleve)There are a number of potential pharmacokinetic interactions between the various individual SSRIs and other medications. Most of these arise from the fact that every SSRI has the ability to inhibit certain P450 cytochromes. Legend: 0 – no inhibition + – mild inhibition ++ – moderate inhibition +++ – strong inhibition The CYP2D6 enzyme is entirely responsible for the metabolism of hydrocodone, codeine and dihydrocodeine to their active metabolites (hydromorphone, morphine, and dihydromorphine, respectively), which in turn undergo phase 2 glucuronidation. These opioids (and to a lesser extent oxycodone, tramadol, and methadone) have interaction potential with selective serotonin reuptake inhibitors. The concomitant use of some SSRIs (paroxetine and fluoxetine) with codeine may decrease the plasma concentration of active metabolite morphine, which may result in reduced analgesic efficacy.Another important interaction of certain SSRIs involves paroxetine, a potent inhibitor of CYP2D6, and tamoxifen, an agent used commonly in the treatment and prevention of breast cancer. Tamoxifen is a prodrug that is metabolised by the hepatic cytochrome P450 enzyme system, especially CYP2D6, to its active metabolites. Concomitant use of paroxetine and tamoxifen in women with breast cancer is associated with a higher risk of death, as much as a 91 percent in women who used it the longest.  Overdose  SSRIs appear safer in overdose when compared with traditional antidepressants, such as the tricyclic antidepressants. This relative safety is supported both by case series and studies of deaths per numbers of prescriptions. However, case reports of SSRI poisoning have indicated that severe toxicity can occur and deaths have been reported following massive single ingestions, although this is exceedingly uncommon when compared to the tricyclic antidepressants.Because of the wide therapeutic index of the SSRIs, most patients will have mild or no symptoms following moderate overdoses. The most commonly reported severe effect following SSRI overdose is serotonin syndrome; serotonin toxicity is usually associated with very high overdoses or multiple drug ingestion. Other reported significant effects include coma, seizures, and cardiac toxicity.Poisoning is also known in animals, and some toxicity information is available for veterinary treatment.  Discontinuation syndrome  Serotonin reuptake inhibitors should not be abruptly discontinued after extended therapy, and whenever possible, should be tapered over several weeks to minimize discontinuation-related symptoms which may include nausea, headache, dizziness, chills, body aches, paresthesias, insomnia, and brain zaps. Paroxetine may produce discontinuation-related symptoms at a greater rate than other SSRIs, though qualitatively similar effects have been reported for all SSRIs. Discontinuation effects appear to be less for fluoxetine, perhaps owing to its long half-life and the natural tapering effect associated with its slow clearance from the body. One strategy for minimizing SSRI discontinuation symptoms is to switch the patient to fluoxetine and then taper and discontinue the fluoxetine.  Mechanism of action   Serotonin reuptake inhibition  In the brain, messages are passed from a nerve cell to another via a chemical synapse, a small gap between the cells. The presynaptic cell that sends the information releases neurotransmitters including serotonin into that gap. The neurotransmitters are then recognized by receptors on the surface of the recipient postsynaptic cell, which upon this stimulation, in turn, relays the signal. About 10% of the neurotransmitters are lost in this process; the other 90% are released from the receptors and taken up again by monoamine transporters into the sending presynaptic cell, a process called reuptake. SSRIs inhibit the reuptake of serotonin. As a result, the serotonin stays in the synaptic gap longer than it normally would, and may repeatedly stimulate the receptors of the recipient cell. In the short run, this leads to an increase in signaling across synapses in which serotonin serves as the primary neurotransmitter. On chronic dosing, the increased occupancy of post-synaptic serotonin receptors signals the pre-synaptic neuron to synthesize and release less serotonin. Serotonin levels within the synapse drop, then rise again, ultimately leading to downregulation of post-synaptic serotonin receptors. Other, indirect effects may include increased norepinephrine output, increased neuronal cyclic AMP levels, and increased levels of regulatory factors such as BDNF and CREB. Owing to the lack of a widely accepted comprehensive theory of the biology of mood disorders, there is no widely accepted theory of how these changes lead to the mood-elevating and anti-anxiety effects of SSRIs. Their effects on serotonin blood levels, which take weeks to take effect, appear to be largely responsible for their slow-to-appear psychiatric effects. SSRIs mediate their action largely with high occupancy in a total of all serotonin transporters within the brain and through this slow downstream changes of large brain regions at therapeutic concentrations, whereas MDMA leads to an excess serotonin release in a short run. This could explain the absence of a ""high"" by antidepressants and in addition the contrary ability of SSRIs in expressing neuroprotective actions to the neurotoxic abilities of MDMA.  Sigma receptor ligands  In addition to their actions as reuptake inhibitors of serotonin, some SSRIs are also, coincidentally, ligands of the sigma receptors. Fluvoxamine is an agonist of the σ1 receptor, while sertraline is an antagonist of the σ1 receptor, and paroxetine does not significantly interact with the σ1 receptor. None of the SSRIs have significant affinity for the σ2 receptor, and the SNRIs, unlike the SSRIs, do not interact with either of the sigma receptors. Fluvoxamine has by far the strongest activity of the SSRIs at the σ1 receptor. High occupancy of the σ1 receptor by clinical dosages of fluvoxamine has been observed in the human brain in positron emission tomography (PET) research. It is thought that agonism of the σ1 receptor by fluvoxamine may have beneficial effects on cognition. In contrast to fluvoxamine, the relevance of the σ1 receptor in the actions of the other SSRIs is uncertain and questionable due to their very low affinity for the receptor relative to the SERT.  Anti-inflammatory effects  The role of inflammation and the immune system in depression has been extensively studied. The evidence supporting this link has been shown in numerous studies over the past ten years. Nationwide studies and meta-analyses of smaller cohort studies have uncovered a correlation between pre-existing inflammatory conditions such as type 1 diabetes, rheumatoid arthritis (RA), or hepatitis, and an increased risk of depression. Data also shows that using pro-inflammatory agents in the treatment of diseases like melanoma can lead to depression. Several meta-analytical studies have found increased levels of proinflammatory cytokines and chemokines in depressed patients. This link has led scientists to investigate the effects of antidepressants on the immune system. SSRIs were originally invented with the goal of increasing levels of available serotonin in the extracellular spaces. However, the delayed response between when patients first begin SSRI treatment to when they see effects has led scientists to believe that other molecules are involved in the efficacy of these drugs. To investigate the apparent anti-inflammatory effects of SSRIs, both Kohler et al. and Więdłocha et al. conducted meta-analyses which have shown that after antidepressant treatment the levels of cytokines associated with inflammation are decreased. A large cohort study conducted by researchers in the Netherlands investigated the association between depressive disorders, symptoms, and antidepressants with inflammation. The study showed decreased levels of interleukin (IL)-6, a cytokine that has proinflammatory effects, in patients taking SSRIs compared to non-medicated patients.Treatment with SSRIs has shown reduced production of inflammatory cytokines such as IL-1β, tumor necrosis factor (TNF)-α, IL-6, and interferon (IFN)-γ, which leads to a decrease in inflammation levels and subsequently a decrease in the activation level of the immune response. These inflammatory cytokines have been shown to activate microglia which are specialized macrophages that reside in the brain. Macrophages are a subset of immune cells responsible for host defense in the innate immune system. Macrophages can release cytokines and other chemicals to cause an inflammatory response. Peripheral inflammation can induce an inflammatory response in microglia and can cause neuroinflammation. SSRIs inhibit proinflammatory cytokine production which leads to less activation of microglia and peripheral macrophages. SSRIs not only inhibit the production of these proinflammatory cytokines, they also have been shown to upregulate anti-inflammatory cytokines such as IL-10. Taken together, this reduces the overall inflammatory immune response.In addition to affecting cytokine production, there is evidence that treatment with SSRIs has effects on the proliferation and viability of immune system cells involved in both innate and adaptive immunity. Evidence shows that SSRIs can inhibit proliferation in T-cells, which are important cells for adaptive immunity and can induce inflammation. SSRIs can also induce apoptosis, programmed cell death, in T-cells. The full mechanism of action for the anti-inflammatory effects of SSRIs is not fully known. However, there is evidence for various pathways to have a hand in the mechanism. One such possible mechanism is the increased levels of cyclic adenosine monophosphate (cAMP) as a result of interference with activation of protein kinase A (PKA), a cAMP dependent protein. Other possible pathways include interference with calcium ion channels, or inducing cell death pathways like MAPK and Notch signaling pathway.The anti-inflammatory effects of SSRIs have prompted studies of the efficacy of SSRIs in the treatment of autoimmune diseases such as multiple sclerosis, RA, inflammatory bowel diseases, and septic shock. These studies have been performed in animal models but have shown consistent immune regulatory effects. Fluoxetine, an SSRI, has also shown efficacy in animal models of graft vs. host disease. SSRIs have also been used successfully as pain relievers in patients undergoing oncology treatment. The effectiveness of this has been hypothesized to be at least in part due to the anti-inflammatory effects of SSRIs.  Pharmacogenetics  Large bodies of research are devoted to using genetic markers to predict whether patients will respond to SSRIs or have side effects that will cause their discontinuation, although these tests are not yet ready for widespread clinical use.  Versus TCAs  SSRIs are described as 'selective' because they affect only the reuptake pumps responsible for serotonin, as opposed to earlier antidepressants, which affect other monoamine neurotransmitters as well, and as a result, SSRIs have fewer side effects. There appears to be no significant difference in effectiveness between SSRIs and tricyclic antidepressants, which were the most commonly used class of antidepressants before the development of SSRIs. However, SSRIs have the important advantage that their toxic dose is high, and, therefore, they are much more difficult to use as a means to commit suicide. Further, they have fewer and milder side effects. Tricyclic antidepressants also have a higher risk of serious cardiovascular side effects, which SSRIs lack. SSRIs act on signal pathways such as cyclic adenosine monophosphate (cAMP) on the postsynaptic neuronal cell, which leads to the release of brain-derived neurotrophic factor (BDNF). BDNF enhances the growth and survival of cortical neurons and synapses.  List of SSRIs   Marketed   Antidepressants  Citalopram (Celexa) Escitalopram (Lexapro) Fluoxetine (Prozac) Fluvoxamine (Luvox) Paroxetine (Paxil) Sertraline (Zoloft)  Others  Dapoxetine (Priligy)  Discontinued   Antidepressants  Indalpine (Upstène) Zimelidine (Zelmid)  Never marketed   Antidepressants  Alaproclate (GEA-654) Centpropazine Cericlamine (JO-1017) Femoxetine (Malexil; FG-4963) Ifoxetine (CGP-15210) Omiloxetine Panuramine (WY-26002) Pirandamine (AY-23713) Seproxetine ((S)-norfluoxetine)  Related drugs  Although described as SNRIs, duloxetine (Cymbalta), venlafaxine (Effexor), and desvenlafaxine (Pristiq) are in fact relatively selective as serotonin reuptake inhibitors (SRIs). They are about at least 10-fold selective for inhibition of serotonin reuptake over norepinephrine reuptake. The selectivity ratios are approximately 1:30 for venlafaxine, 1:10 for duloxetine, and 1:14 for desvenlafaxine. At low doses, these SNRIs act mostly as SSRIs; only at higher doses do they also prominently inhibit norepinephrine reuptake. Milnacipran (Ixel, Savella) and its stereoisomer levomilnacipran (Fetzima) are the only widely marketed SNRIs that inhibit serotonin and norepinephrine to similar degrees, both with ratios close to 1:1.Vilazodone (Viibryd) and vortioxetine (Trintellix) are SRIs that also act as modulators of serotonin receptors and are described as serotonin modulators and stimulators (SMS). Vilazodone is a 5-HT1A receptor partial agonist while vortioxetine is a 5-HT1A receptor agonist and 5-HT3 and 5-HT7 receptor antagonist. Litoxetine (SL 81–0385) and lubazodone (YM-992, YM-35995) are similar drugs that were never marketed. They are SRIs and litoxetine is also a 5-HT3 receptor antagonist while lubazodone is also a 5-HT2A receptor antagonist.  History  Fluoxetine was introduced in 1987 and was the first major SSRI to be marketed.  Controversy  A study examining publication of results from FDA-evaluated antidepressants concluded that those with favorable results were much more likely to be published than those with negative results. Furthermore, an investigation of 185 meta-analyses on antidepressants found that 79% of them had authors affiliated in some way to pharmaceutical companies and that they were reluctant to report caveats for antidepressants.David Healy has argued that warning signs were available for many years prior to regulatory authorities moving to put warnings on antidepressant labels that they might cause suicidal thoughts. At the time these warnings were added, others argued that the evidence for harm remained unpersuasive and others continued to do so after the warnings were added.  In other organisms  SSRIs are common environmental contaminant findings near human settlement.  Veterinary use  An SSRI (fluoxetine) has been approved for veterinary use in treatment of canine separation anxiety.  See also  List of antidepressants Serotonin releasing agent Serotonin–norepinephrine reuptake inhibitor  References   External links  WebMD – Selective Serotonin Reuptake Inhibitors","Selective serotonin reuptake inhibitors are a group of medications. They are usually called SSRIs. They are used to treat depression, anxiety disorders, and some other problems. In many countries, SSRIs are prescribed more often than any other type of antidepressant.Examples of common SSRIs are fluoxetine (Prozac), paroxetine (Paxil), citalopram (Celena), and escitalopram (Lexapro).  Medical uses  SSRIs are mainly used to treat: Major depressive disorder Anxiety disorders like obsessive-compulsive disorder (OCD); panic disorder; and generalized anxiety disorder Post-traumatic stress disorder (PTSD) Eating disorders Chronic pain  Depression  Antidepressants like SSRIs are a first-choice treatment for people with very bad depression. When a person's depression is not as bad, but counseling has not helped them, antidepressants can help.Scientists do not agree on whether SSRIs work for mild depression that does not last very long.  Anxiety disorders  SSRIs work well for generalized anxiety disorder. They help decrease people's anxiety. This can help them participate in counseling to learn how to deal with their anxiety.SSRIs also work well for obsessive-compulsive disorder (OCD). They are the first-choice treatment for people with very bad OCD. Like with depression and generalized anxiety disorder, SSRIs are not a cure; people need to participate in counseling and other treatments too. However, people with OCD who took an SSRI are about twice as likely to do well in treatment than people not taking an SSRI.Fluoxetine (Prozac) and paroxetine (Paxil) are the only medications the United States Food and Drug Administration has approved for treating post-traumatic stress disorder (PTSD). Medications alone usually will not cure PTSD; they need to be combined with counseling. Except for Prozac and Paxil, most other SSRIs do not seem to help PTSD.  Eating disorders  When a person starts to get treatment for bulimia nervosa or binge eating disorder, SSRIs can be a helpful first step. Over short periods of time, they can decrease some of the symptoms of these eating disorders. For example, for a short while, people taking SSRIs do less binge eating. However, SSRIs only seem to help for a short period of time.SSRIs do not seem to help anorexia nervosa. However, if a person with anorexia also has depression, anxiety, or OCD, SSRIs could help treat those problems.  Chronic pain  Research shows that two SSRIs can help treat chronic pain. These SSRIs are paroxetine (Paxil) and citalopram (Celexa). Other SSRIs, like fluoxetine (Prozac), do not help chronic pain.Another group of antidepressants, called tricyclic antidepressants, treat chronic pain better than SSRIs do. However, tricyclic antidepressants have many more side effects than SSRIs do. Because of this, some doctors prescribe paroxetine or citalopram for chronic pain, because the side effects are not as bad.  How they work  Serotonin is an important chemical in the human body. It exists in different parts of the body. In the brain, it helps control a person's mood, appetite, and sleep.Many researchers think low levels of serotonin in the brain can help cause depression. If a person's brain does not have enough serotonin, the serotonin cannot do its job of controlling their mood. This can make the person depressed. (It can also cause other symptoms of depression, like not having any appetite, not being able to sleep, or sleeping too much - because serotonin controls appetite and sleep too.)SSRIs increase the amount of serotonin that the brain can use. Researchers think that in depressed people, this brings the amounts of serotonin in their brains back to normal. However, depression is complicated. So are the other problems SSRIs treat, like anxiety disorders. There is no one cause for these disorders. They are usually caused by a mixture of things. This is why SSRIs are not a cure. Most people also need counseling to help treat the other causes of their depression, anxiety, or other problems.  Adverse effects  Each SSRI has its own possible adverse effects (side effects). It is important to remember that every medication has many possible side effects. This does not mean that everyone who takes the medication will have side effects. It only means that some people who take these medications have these symptoms. Here are some examples of adverse effects that SSRIs can cause.  Suicide risk  Taking SSRIs makes children and young adults more likely to think about suicide and try to kill themselves. This is true for young adults up to age 24.In 2004, the United States Food and Drug Administration (FDA) looked at clinical trials on children with major depressive disorder. They found that children taking SSRIs had: An 80% higher risk of ""possible suicidal ideation and suicidal behavior"" About a 130% greater risk of agitation (getting angry and upset easily) and hostility (acting angry towards other people)In both the United States and the United Kingdom, only three SSRIs are approved to treat children: Prozac, to treat children with depression Sertraline (Zoloft) and fluvoxamine (Luvox), for children with OCDScientists do not agree on whether SSRIs make adults more likely to think about suicide or try to kill themselves. The FDA says that people over age 24 are not more likely to think about suicide when they take SSRIs.  Sexual problems  SSRIs often cause sexual problems. These problems include erectile dysfunction, not being able to have an orgasm, not wanting to have sex, and not enjoying sex.Sexual problems are one of the most common reasons why people stop taking SSRIs.  Bleeding  When a person takes SSRIs along with anticoagulant (blood-thinning) medications, they are a little more likely to have bleeding problems. For example, the person is more likely to have bleeding in their gastrointestinal tract, or to bleed after they have surgery. Bleeding problems are most likely in people who: Are on blood-thinning medications, like warfarin (Coumadin); AND Are on medications that keep platelets from forming blood clots, like aspirin; AND Are taking nonsteroidal anti-inflammatory drugs (NSAIDS), like ibuprofen; AND Have liver disease or liver failure.  Other problems  Most SSRIs can also make a person: More likely to break a bone Feel very restless and unable to stand still (akathisia) Be very sensitive to bright lights  Stopping suddenly  If a person stops taking SSRIs suddenly, they can get serotonin discontinuation syndrome. This can cause: Nausea Headache Dizziness Pain in the whole body Strange feelings on the skin Trouble sleeping Feeling like the body is being shocked with electricityA person and their doctor should come up with a plan for how to stop taking an SSRI. If possible, the person should slowly decrease the amount of medication they are taking, bit by bit, over a few weeks.  Overdose  If a person overdoses on an SSRI, they can poison themselves or even die.SSRI overdoses can cause: Serotonin syndrome Coma Seizures Poisoning of the heart  Drug interactions  It is not safe to take some drugs with SSRIs. Taking these drugs with SSRIs can cause serotonin syndrome. Here are some examples of drugs that cannot be taken with SSRIs: Some other medicines for depression and anxiety: Monoamine oxidase inhibitors (MAOIs) Tricyclic antidepressants Serotonin-norepinephrine reuptake inhibitors (SNRIs) Lithium Buspirone (Buspar) Mirtazapine (Remeron) Some pain medications Pethidine/meperidine (Demerol) Tramadol (Ultram) Other things Dextromethorphan, an over-the-counter cough medicine St. John's Wort, an herb that some people use to treat depression MDMA (Ecstasy), an illegal drug  Related pages  Serotonin Depression Anxiety disorders  References "
"Hypertension (HTN or HT), also known as high blood pressure (HBP), is a long-term medical condition in which the blood pressure in the arteries is persistently elevated. High blood pressure usually does not cause symptoms. High blood pressure, however, is a major risk factor for stroke, coronary artery disease, heart failure, atrial fibrillation, peripheral arterial disease, vision loss, chronic kidney disease, and dementia. Hypertension is a major cause of premature death worldwide.High blood pressure is classified as primary (essential) hypertension or secondary hypertension. About 90–95% of cases are primary, defined as high blood pressure due to nonspecific lifestyle and genetic factors. Lifestyle factors that increase the risk include excess salt in the diet, excess body weight, smoking, physical inactivity and alcohol use. The remaining 5–10% of cases are categorized as secondary high blood pressure, defined as high blood pressure due to an identifiable cause, such as chronic kidney disease, narrowing of the kidney arteries, an endocrine disorder, or the use of birth control pills.Blood pressure is classified by two measurements, the systolic and diastolic pressures, which are the maximum and minimum pressures, respectively. For most adults, normal blood pressure at rest is within the range of 100–130 millimeters mercury (mmHg) systolic and 60–80 mmHg diastolic. For most adults, high blood pressure is present if the resting blood pressure is persistently at or above 130/80 or 140/90 mmHg. Different numbers apply to children. Ambulatory blood pressure monitoring over a 24-hour period appears more accurate than office-based blood pressure measurement.Lifestyle changes and medications can lower blood pressure and decrease the risk of health complications. Lifestyle changes include weight loss, physical exercise, decreased salt intake, reducing alcohol intake, and a healthy diet. If lifestyle changes are not sufficient, then blood pressure medications are used. Up to three medications taken concurrently can control blood pressure in 90% of people. The treatment of moderately high arterial blood pressure (defined as >160/100 mmHg) with medications is associated with an improved life expectancy. The effect of treatment of blood pressure between 130/80 mmHg and 160/100 mmHg is less clear, with some reviews finding benefit and others finding unclear benefit. High blood pressure affects between 16 and 37% of the population globally. In 2010 hypertension was believed to have been a factor in 18% of all deaths (9.4 million globally).  Signs and symptoms  Hypertension is rarely accompanied by symptoms, and its identification is usually through health screening, or when seeking healthcare for an unrelated problem. Some people with high blood pressure report headaches (particularly at the back of the head and in the morning), as well as lightheadedness, vertigo, tinnitus (buzzing or hissing in the ears), altered vision or fainting episodes. These symptoms, however, might be related to associated anxiety rather than the high blood pressure itself.On physical examination, hypertension may be associated with the presence of changes in the optic fundus seen by ophthalmoscopy. The severity of the changes typical of hypertensive retinopathy is graded from I to IV; grades I and II may be difficult to differentiate. The severity of the retinopathy correlates roughly with the duration or the severity of the hypertension.  Secondary hypertension  Secondary hypertension is hypertension due to an identifiable cause, and may result in certain specific additional signs and symptoms. For example, as well as causing high blood pressure, Cushing's syndrome frequently causes truncal obesity, glucose intolerance, moon face, a hump of fat behind the neck and shoulders (referred to as a buffalo hump), and purple abdominal stretch marks. Hyperthyroidism frequently causes weight loss with increased appetite, fast heart rate, bulging eyes, and tremor. Renal artery stenosis (RAS) may be associated with a localized abdominal bruit to the left or right of the midline (unilateral RAS), or in both locations (bilateral RAS). Coarctation of the aorta frequently causes a decreased blood pressure in the lower extremities relative to the arms, or delayed or absent femoral arterial pulses. Pheochromocytoma may cause abrupt episodes of hypertension accompanied by headache, palpitations, pale appearance, and excessive sweating.  Hypertensive crisis  Severely elevated blood pressure (equal to or greater than a systolic 180 or diastolic of 120) is referred to as a hypertensive crisis. Hypertensive crisis is categorized as either hypertensive urgency or hypertensive emergency, according to the absence or presence of end organ damage, respectively.In hypertensive urgency, there is no evidence of end organ damage resulting from the elevated blood pressure. In these cases, oral medications are used to lower the BP gradually over 24 to 48 hours.In hypertensive emergency, there is evidence of direct damage to one or more organs. The most affected organs include the brain, kidney, heart and lungs, producing symptoms which may include confusion, drowsiness, chest pain and breathlessness. In hypertensive emergency, the blood pressure must be reduced more rapidly to stop ongoing organ damage, however, there is a lack of randomized controlled trial evidence for this approach.  Pregnancy  Hypertension occurs in approximately 8–10% of pregnancies. Two blood pressure measurements six hours apart of greater than 140/90 mm Hg are diagnostic of hypertension in pregnancy. High blood pressure in pregnancy can be classified as pre-existing hypertension, gestational hypertension, or pre-eclampsia.Pre-eclampsia is a serious condition of the second half of pregnancy and following delivery characterised by increased blood pressure and the presence of protein in the urine. It occurs in about 5% of pregnancies and is responsible for approximately 16% of all maternal deaths globally. Pre-eclampsia also doubles the risk of death of the baby around the time of birth. Usually there are no symptoms in pre-eclampsia and it is detected by routine screening. When symptoms of pre-eclampsia occur the most common are headache, visual disturbance (often ""flashing lights""), vomiting, pain over the stomach, and swelling. Pre-eclampsia can occasionally progress to a life-threatening condition called eclampsia, which is a hypertensive emergency and has several serious complications including vision loss, brain swelling, seizures, kidney failure, pulmonary edema, and disseminated intravascular coagulation (a blood clotting disorder).In contrast, gestational hypertension is defined as new-onset hypertension during pregnancy without protein in the urine.  Children  Failure to thrive, seizures, irritability, lack of energy, and difficulty in breathing can be associated with hypertension in newborns and young infants. In older infants and children, hypertension can cause headache, unexplained irritability, fatigue, failure to thrive, blurred vision, nosebleeds, and facial paralysis.  Causes   Primary hypertension  Hypertension results from a complex interaction of genes and environmental factors. Numerous common genetic variants with small effects on blood pressure have been identified as well as some rare genetic variants with large effects on blood pressure. Also, genome-wide association studies (GWAS) have identified 35 genetic loci related to blood pressure; 12 of these genetic loci influencing blood pressure were newly found. Sentinel SNP for each new genetic locus identified has shown an association with DNA methylation at multiple nearby CpG sites. These sentinel SNP are located within genes related to vascular smooth muscle and renal function. DNA methylation might affect in some way linking common genetic variation to multiple phenotypes even though mechanisms underlying these associations are not understood. Single variant test performed in this study for the 35 sentinel SNP (known and new) showed that genetic variants singly or in aggregate contribute to risk of clinical phenotypes related to high blood pressure.Blood pressure rises with aging when associated with a western diet and lifestyle and the risk of becoming hypertensive in later life is significant. Several environmental factors influence blood pressure. High salt intake raises the blood pressure in salt sensitive individuals; lack of exercise and central obesity can play a role in individual cases. The possible roles of other factors such as caffeine consumption, and vitamin D deficiency are less clear. Insulin resistance, which is common in obesity and is a component of syndrome X (or the metabolic syndrome), also contributes to hypertension.Events in early life, such as low birth weight, maternal smoking, and lack of breastfeeding may be risk factors for adult essential hypertension, although the mechanisms linking these exposures to adult hypertension remain unclear. An increased rate of high blood uric acid has been found in untreated people with hypertension in comparison with people with normal blood pressure, although it is uncertain whether the former plays a causal role or is subsidiary to poor kidney function. Average blood pressure may be higher in the winter than in the summer. Periodontal disease is also associated with high blood pressure.  Secondary hypertension  Secondary hypertension results from an identifiable cause. Kidney disease is the most common secondary cause of hypertension. Hypertension can also be caused by endocrine conditions, such as Cushing's syndrome, hyperthyroidism, hypothyroidism, acromegaly, Conn's syndrome or hyperaldosteronism, renal artery stenosis (from atherosclerosis or fibromuscular dysplasia), hyperparathyroidism, and pheochromocytoma. Other causes of secondary hypertension include obesity, sleep apnea, pregnancy, coarctation of the aorta, excessive eating of liquorice, excessive drinking of alcohol, certain prescription medicines, herbal remedies, and stimulants such as coffee, cocaine and methamphetamine. Arsenic exposure through drinking water has been shown to correlate with elevated blood pressure. Depression was also linked to hypertension. Loneliness is also a risk factor.A 2018 review found that any alcohol increased blood pressure in males while over one or two drinks increased the risk in females.  Pathophysiology  In most people with established essential hypertension, increased resistance to blood flow (total peripheral resistance) accounts for the high pressure while cardiac output remains normal. There is evidence that some younger people with prehypertension or 'borderline hypertension' have high cardiac output, an elevated heart rate and normal peripheral resistance, termed hyperkinetic borderline hypertension. These individuals develop the typical features of established essential hypertension in later life as their cardiac output falls and peripheral resistance rises with age. Whether this pattern is typical of all people who ultimately develop hypertension is disputed. The increased peripheral resistance in established hypertension is mainly attributable to structural narrowing of small arteries and arterioles, although a reduction in the number or density of capillaries may also contribute.It is not clear whether or not vasoconstriction of arteriolar blood vessels plays a role in hypertension. Hypertension is also associated with decreased peripheral venous compliance which may increase venous return, increase cardiac preload and, ultimately, cause diastolic dysfunction. Pulse pressure (the difference between systolic and diastolic blood pressure) is frequently increased in older people with hypertension. This can mean that systolic pressure is abnormally high, but diastolic pressure may be normal or low, a condition termed isolated systolic hypertension. The high pulse pressure in elderly people with hypertension or isolated systolic hypertension is explained by increased arterial stiffness, which typically accompanies aging and may be exacerbated by high blood pressure.Many mechanisms have been proposed to account for the rise in peripheral resistance in hypertension. Most evidence implicates either disturbances in the kidneys' salt and water handling (particularly abnormalities in the intrarenal renin–angiotensin system) or abnormalities of the sympathetic nervous system. These mechanisms are not mutually exclusive and it is likely that both contribute to some extent in most cases of essential hypertension. It has also been suggested that endothelial dysfunction and vascular inflammation may also contribute to increased peripheral resistance and vascular damage in hypertension. Interleukin 17 has garnered interest for its role in increasing the production of several other immune system chemical signals thought to be involved in hypertension such as tumor necrosis factor alpha, interleukin 1, interleukin 6, and interleukin 8.Excessive sodium or insufficient potassium in the diet leads to excessive intracellular sodium, which contracts vascular smooth muscle, restricting blood flow and so increases blood pressure.  Diagnosis  Hypertension is diagnosed on the basis of a persistently high resting blood pressure. The American Heart Association (AHA) recommends at least three resting measurements on at least two separate health care visits. The UK National Institute for Health and Care Excellence recommends ambulatory blood pressure monitoring to confirm the diagnosis of hypertension if a clinic blood pressure is 140/90 mmHg or higher.  Measurement technique  For an accurate diagnosis of hypertension to be made, it is essential for proper blood pressure measurement technique to be used. Improper measurement of blood pressure is common and can change the blood pressure reading by up to 10 mmHg, which can lead to misdiagnosis and misclassification of hypertension. Correct blood pressure measurement technique involves several steps. Proper blood pressure measurement requires the person whose blood pressure is being measured to sit quietly for at least five minutes which is then followed by application of a properly fitted blood pressure cuff to a bare upper arm. The person should be seated with their back supported, feet flat on the floor, and with their legs uncrossed. The person whose blood pressure is being measured should avoid talking or moving during this process. The arm being measured should be supported on a flat surface at the level of the heart. Blood pressure measurement should be done in a quiet room so the medical professional checking the blood pressure can hear the Korotkoff sounds while listening to the brachial artery with a stethoscope for accurate blood pressure measurements. The blood pressure cuff should be deflated slowly (2–3 mmHg per second) while listening for the Korotkoff sounds. The bladder should be emptied before a person's blood pressure is measured since this can increase blood pressure by up to 15/10 mmHg. Multiple blood pressure readings (at least two) spaced 1–2 minutes apart should be obtained to ensure accuracy. Ambulatory blood pressure monitoring over 12 to 24 hours is the most accurate method to confirm the diagnosis. An exception to this is those with very high blood pressure readings especially when there is poor organ function.With the availability of 24-hour ambulatory blood pressure monitors and home blood pressure machines, the importance of not wrongly diagnosing those who have white coat hypertension has led to a change in protocols. In the United Kingdom, current best practice is to follow up a single raised clinic reading with ambulatory measurement, or less ideally with home blood pressure monitoring over the course of 7 days. The United States Preventive Services Task Force also recommends getting measurements outside of the healthcare environment. Pseudohypertension in the elderly or noncompressibility artery syndrome may also require consideration. This condition is believed to be due to calcification of the arteries resulting in abnormally high blood pressure readings with a blood pressure cuff while intra arterial measurements of blood pressure are normal. Orthostatic hypertension is when blood pressure increases upon standing.  Other investigations  Once the diagnosis of hypertension has been made, healthcare providers should attempt to identify the underlying cause based on risk factors and other symptoms, if present. Secondary hypertension is more common in preadolescent children, with most cases caused by kidney disease. Primary or essential hypertension is more common in adolescents and adults and has multiple risk factors, including obesity and a family history of hypertension. Laboratory tests can also be performed to identify possible causes of secondary hypertension, and to determine whether hypertension has caused damage to the heart, eyes, and kidneys. Additional tests for diabetes and high cholesterol levels are usually performed because these conditions are additional risk factors for the development of heart disease and may require treatment.Initial assessment of the hypertensive people should include a complete history and physical examination. Serum creatinine is measured to assess for the presence of kidney disease, which can be either the cause or the result of hypertension. Serum creatinine alone may overestimate glomerular filtration rate and the 2003 JNC7 guidelines advocate the use of predictive equations such as the Modification of Diet in Renal Disease (MDRD) formula to estimate glomerular filtration rate (eGFR). eGFR can also provide a baseline measurement of kidney function that can be used to monitor for side effects of certain anti-hypertensive drugs on kidney function. Additionally, testing of urine samples for protein is used as a secondary indicator of kidney disease. Electrocardiogram (EKG/ECG) testing is done to check for evidence that the heart is under strain from high blood pressure. It may also show whether there is thickening of the heart muscle (left ventricular hypertrophy) or whether the heart has experienced a prior minor disturbance such as a silent heart attack. A chest X-ray or an echocardiogram may also be performed to look for signs of heart enlargement or damage to the heart.  Classification in adults  In people aged 18 years or older, hypertension is defined as either a systolic or a diastolic blood pressure measurement consistently higher than an accepted normal value (this is above 129 or 139 mmHg systolic, 89 mmHg diastolic depending on the guideline). Other thresholds are used (135 mmHg systolic or 85 mmHg diastolic) if measurements are derived from 24-hour ambulatory or home monitoring. International hypertension guidelines have also created categories below the hypertensive range to indicate a continuum of risk with higher blood pressures in the normal range. The Seventh Report of the Joint National Committee on Prevention, Detection, Evaluation and Treatment of High Blood Pressure (JNC7) published in 2003 uses the term prehypertension for blood pressure in the range 120–139 mmHg systolic or 80–89 mmHg diastolic, while European Society of Hypertension Guidelines (2007) and British Hypertension Society (BHS) IV (2004) use optimal, normal and high normal categories to subdivide pressures below 140 mmHg systolic and 90 mmHg diastolic. Hypertension is also sub-classified: JNC7 distinguishes hypertension stage I, hypertension stage II, and isolated systolic hypertension. Isolated systolic hypertension refers to elevated systolic pressure with normal diastolic pressure and is common in the elderly. The ESH-ESC Guidelines (2007) and BHS IV (2004) additionally define a third stage (stage III hypertension) for people with systolic blood pressure exceeding 179 mmHg or a diastolic pressure over 109 mmHg. Hypertension is classified as ""resistant"" if medications do not reduce blood pressure to normal levels. In November 2017, the American Heart Association and American College of Cardiology published a joint guideline which updates the recommendations of the JNC7 report. The 2020 International Society of Hypertension guidelines define hypertension based on office blood pressure ≥140/90 mmHg or home monitoring blood pressure ≥135/85 mmHg, or 24-hour ambulatory blood pressure average ≥130/80 mmHg (daytime average ≥135/85 mmHg or nighttime average BP ≥120/70 mmHg).  Children  Hypertension occurs in around 0.2 to 3% of newborns; however, blood pressure is not measured routinely in healthy newborns. Hypertension is more common in high risk newborns. A variety of factors, such as gestational age, postconceptional age and birth weight needs to be taken into account when deciding if a blood pressure is normal in a newborn.Hypertension defined as elevated blood pressure over several visits affects 1% to 5% of children and adolescents and is associated with long-term risks of ill-health. Blood pressure rises with age in childhood and, in children, hypertension is defined as an average systolic or diastolic blood pressure on three or more occasions equal or higher than the 95th percentile appropriate for the sex, age and height of the child. High blood pressure must be confirmed on repeated visits however before characterizing a child as having hypertension. Prehypertension in children has been defined as average systolic or diastolic blood pressure that is greater than or equal to the 90th percentile, but less than the 95th percentile. In adolescents, it has been proposed that hypertension and pre-hypertension are diagnosed and classified using the same criteria as in adults.  Prevention  Much of the disease burden of high blood pressure is experienced by people who are not labeled as hypertensive. Consequently, population strategies are required to reduce the consequences of high blood pressure and reduce the need for antihypertensive medications. Lifestyle changes are recommended to lower blood pressure, before starting medications. The 2004 British Hypertension Society guidelines proposed lifestyle changes consistent with those outlined by the US National High BP Education Program in 2002 for the primary prevention of hypertension: maintain normal body weight for adults (e.g. body mass index 20–25 kg/m2) reduce dietary sodium intake to <100 mmol/ day (<6 g of sodium chloride or <2.4 g of sodium per day) engage in regular aerobic physical activity such as brisk walking (≥30 min per day, most days of the week) limit alcohol consumption to no more than 3 units/day in men and no more than 2 units/day in women consume a diet rich in fruit and vegetables (e.g. at least five portions per day); Stress reductionAvoiding or learning to manage stress can help a person control blood pressure. A few relaxation techniques that can help relieve stress are: meditation warm baths yoga going on long walksEffective lifestyle modification may lower blood pressure as much as an individual antihypertensive medication. Combinations of two or more lifestyle modifications can achieve even better results. There is considerable evidence that reducing dietary salt intake lowers blood pressure, but whether this translates into a reduction in mortality and cardiovascular disease remains uncertain. Estimated sodium intake ≥6g/day and <3g/day are both associated with high risk of death or major cardiovascular disease, but the association between high sodium intake and adverse outcomes is only observed in people with hypertension. Consequently, in the absence of results from randomized controlled trials, the wisdom of reducing levels of dietary salt intake below 3g/day has been questioned. ESC guidelines mention periodontitis is associated with poor cardiovascular health status.The value of routine screening for hypertension is debated. In 2004, the National High Blood Pressure Education Program recommended that children aged 3 years and older have blood pressure measurement at least once at every health care visit and the National Heart, Lung, and Blood Institute and American Academy of Pediatrics made a similar recommendation. However, the American Academy of Family Physicians supports the view of the U.S. Preventive Services Task Force that the available evidence is insufficient to determine the balance of benefits and harms of screening for hypertension in children and adolescents who do not have symptoms. The US Preventive Services Task Force recommends screening adults 18 years or older for hypertension with office blood pressure measurement.  Management  According to one review published in 2003, reduction of the blood pressure by 5 mmHg can decrease the risk of stroke by 34%, of ischemic heart disease by 21%, and reduce the likelihood of dementia, heart failure, and mortality from cardiovascular disease.  Target blood pressure  Various expert groups have produced guidelines regarding how low the blood pressure target should be when a person is treated for hypertension. These groups recommend a target below the range 140–160 / 90–100 mmHg for the general population. Cochrane reviews recommend similar targets for subgroups such as people with diabetes and people with prior cardiovascular disease. Additionally, Cochrane reviews have found that for older individuals with moderate to high cardiovascular risk, the benefits of trying to achieve a lower than standard blood pressure target (at or below 140/90 mmHg) are outweighed by the risk associated with the intervention. These findings may not be applicable to other populations.Many expert groups recommend a slightly higher target of 150/90 mmHg for those over somewhere between 60 and 80 years of age. The JNC-8 and American College of Physicians recommend the target of 150/90 mmHg for those over 60 years of age, but some experts within these groups disagree with this recommendation. Some expert groups have also recommended slightly lower targets in those with diabetes or chronic kidney disease with protein loss in the urine, but others recommend the same target as for the general population. The issue of what is the best target and whether targets should differ for high risk individuals is unresolved, although some experts propose more intensive blood pressure lowering than advocated in some guidelines.For people who have never experienced cardiovascular disease who are at a 10-year risk of cardiovascular disease of less than 10%, the 2017 American Heart Association guidelines recommend medications if the systolic blood pressure is >140 mmHg or if the diastolic BP is >90 mmHg. For people who have experienced cardiovascular disease or those who are at a 10-year risk of cardiovascular disease of greater than 10%, it recommends medications if the systolic blood pressure is >130 mmHg or if the diastolic BP is >80 mmHg.  Lifestyle modifications  The first line of treatment for hypertension is lifestyle changes, including dietary changes, physical exercise, and weight loss. Though these have all been recommended in scientific advisories, a Cochrane systematic review found no evidence (due to lack of data) for effects of weight loss diets on death, long-term complications or adverse events in persons with hypertension. The review did find a decrease in body weight and blood pressure. Their potential effectiveness is similar to and at times exceeds a single medication. If hypertension is high enough to justify immediate use of medications, lifestyle changes are still recommended in conjunction with medication. Dietary changes shown to reduce blood pressure include diets with low sodium, the DASH diet (Dietary Approaches to Stop Hypertension), which was the best against 11 other diet in an umbrella review, and plant-based diets. There is some evidence green tea consumption may help lower blood pressure, but this is insufficient for it to be recommended as a treatment. There is evidence from randomized, double-blind, placebo-controlled clinical trials that Hibiscus tea consumption significantly reduces systolic blood pressure (-4.71 mmHg, 95% CI [-7.87, -1.55]) and diastolic blood pressure (−4.08 mmHg, 95% CI [-6.48, −1.67]). Beetroot juice consumption also significantly lowers the blood pressure of people with high blood pressure.Increasing dietary potassium has a potential benefit for lowering the risk of hypertension. The 2015 Dietary Guidelines Advisory Committee (DGAC) stated that potassium is one of the shortfall nutrients which is under-consumed in the United States. However, people who take certain antihypertensive medications (such as ACE-inhibitors or ARBs) should not take potassium supplements or potassium-enriched salts due to the risk of high levels of potassium.Physical exercise regimens which are shown to reduce blood pressure include isometric resistance exercise, aerobic exercise, resistance exercise, and device-guided breathing.Stress reduction techniques such as biofeedback or transcendental meditation may be considered as an add-on to other treatments to reduce hypertension, but do not have evidence for preventing cardiovascular disease on their own. Self-monitoring and appointment reminders might support the use of other strategies to improve blood pressure control, but need further evaluation.  Medications  Several classes of medications, collectively referred to as antihypertensive medications, are available for treating hypertension. First-line medications for hypertension include thiazide-diuretics, calcium channel blockers, angiotensin converting enzyme inhibitors (ACE inhibitors), and angiotensin receptor blockers (ARBs). These medications may be used alone or in combination (ACE inhibitors and ARBs are not recommended for use together); the latter option may serve to minimize counter-regulatory mechanisms that act to restore blood pressure values to pre-treatment levels, although the evidence for first-line combination therapy is not strong enough. Most people require more than one medication to control their hypertension. Medications for blood pressure control should be implemented by a stepped care approach when target levels are not reached. Withdrawal such medications in elderly can be considered by healthcare professional because there is no strong evidence for effect on mortality, myocardial infarction, and stroke.Previously, beta-blockers such as atenolol were thought to have similar beneficial effects when used as first-line therapy for hypertension. However, a Cochrane review that included 13 trials found that the effects of beta-blockers are inferior to that of other antihypertensive medications in preventing cardiovascular disease.The prescription of antihypertensive medication for children with hypertension has limited evidence. There is limited evidence which compare it with placebo and shows modest effect to blood pressure in short term. Administration of higher dose did not make the reduction of blood pressure greater.  Resistant hypertension  Resistant hypertension is defined as high blood pressure that remains above a target level, in spite of being prescribed three or more antihypertensive drugs simultaneously with different mechanisms of action. Failing to take prescribed medications as directed is an important cause of resistant hypertension. Resistant hypertension may also result from chronically high activity of the autonomic nervous system, an effect known as neurogenic hypertension. Electrical therapies that stimulate the baroreflex are being studied as an option for lowering blood pressure in people in this situation.Some common secondary causes of resistant hypertension include obstructive sleep apnea, pheochromocytoma, renal artery stenosis, coarctation of the aorta, and primary aldosteronism. As many as one in five people with resistant hypertension have primary aldosteronism, which is a treatable and sometimes curable condition.  Refractory hypertension  Refractory hypertension is characterized by uncontrolled elevated blood pressure unmitigated by five or more antihypertensive agents of different classes, including a long-acting thiazide-like diuretic, a calcium channel blocker, and a blocker of the renin-angiotensin system. People with refractory hypertension typically have increased sympathetic nervous system activity, and are at high risk for more severe cardiovascular diseases and all-cause mortality.  Non-modulating  Non-modulating essential hypertension is a form of salt-sensitive hypertension, where sodium intake does not modulate either adrenal or renal vascular responses to angiotensin II. Individuals with this subset have been termed non-modulators. They make up 25–30% of the hypertensive population.  Epidemiology   Adults  As of 2014, approximately one billion adults or ~22% of the population of the world have hypertension. It is slightly more frequent in men, in those of low socioeconomic status, and it becomes more common with age. It is common in high, medium, and low income countries. In 2004, rates of high blood pressure were highest in Africa, (30% for both sexes) and lowest in the Americas (18% for both sexes). Rates also vary markedly within regions with rates as low as 3.4% (men) and 6.8% (women) in rural India and as high as 68.9% (men) and 72.5% (women) in Poland. Rates in Africa were about 45% in 2016.In Europe hypertension occurs in about 30–45% of people as of 2013. In 1995 it was estimated that 43 million people (24% of the population) in the United States had hypertension or were taking antihypertensive medication. By 2004 this had increased to 29% and further to 32% (76 million US adults) by 2017. In 2017, with the change in definitions for hypertension, 46% of people in the United States are affected. African-American adults in the United States have among the highest rates of hypertension in the world at 44%. It is also more common in Filipino Americans and less common in US whites and Mexican Americans. Differences in hypertension rates are multifactorial and under study.  Children  Rates of high blood pressure in children and adolescents have increased in the last 20 years in the United States. Childhood hypertension, particularly in pre-adolescents, is more often secondary to an underlying disorder than in adults. Kidney disease is the most common secondary cause of hypertension in children and adolescents. Nevertheless, primary or essential hypertension accounts for most cases.  Prognosis  Hypertension is the most important preventable risk factor for premature death worldwide. It increases the risk of ischemic heart disease, strokes, peripheral vascular disease, and other cardiovascular diseases, including heart failure, aortic aneurysms, diffuse atherosclerosis, chronic kidney disease, atrial fibrillation, cancers, leukemia and pulmonary embolism. Hypertension is also a risk factor for cognitive impairment and dementia. Other complications include hypertensive retinopathy and hypertensive nephropathy.  History   Measurement  Modern understanding of the cardiovascular system began with the work of physician William Harvey (1578–1657), who described the circulation of blood in his book ""De motu cordis"". The English clergyman Stephen Hales made the first published measurement of blood pressure in 1733. However, hypertension as a clinical entity came into its own with the invention of the cuff-based sphygmomanometer by Scipione Riva-Rocci in 1896. This allowed easy measurement of systolic pressure in the clinic. In 1905, Nikolai Korotkoff improved the technique by describing the Korotkoff sounds that are heard when the artery is ausculted with a stethoscope while the sphygmomanometer cuff is deflated. This permitted systolic and diastolic pressure to be measured.  Identification  The symptoms similar to symptoms of patients with hypertensive crisis are discussed in medieval Persian medical texts in the chapter of ""fullness disease"". The symptoms include headache, heaviness in the head, sluggish movements, general redness and warm to touch feel of the body, prominent, distended and tense vessels, fullness of the pulse, distension of the skin, coloured and dense urine, loss of appetite, weak eyesight, impairment of thinking, yawning, drowsiness, vascular rupture, and hemorrhagic stroke. Fullness disease was presumed to be due to an excessive amount of blood within the blood vessels. Descriptions of hypertension as a disease came among others from Thomas Young in 1808 and especially Richard Bright in 1836. The first report of elevated blood pressure in a person without evidence of kidney disease was made by Frederick Akbar Mahomed (1849–1884).  Treatment  Historically the treatment for what was called the ""hard pulse disease"" consisted in reducing the quantity of blood by bloodletting or the application of leeches. This was advocated by The Yellow Emperor of China, Cornelius Celsus, Galen, and Hippocrates. The therapeutic approach for the treatment of hard pulse disease included changes in lifestyle (staying away from anger and sexual intercourse) and dietary program for patients (avoiding the consumption of wine, meat, and pastries, reducing the volume of food in a meal, maintaining a low-energy diet and the dietary usage of spinach and vinegar). In the 19th and 20th centuries, before effective pharmacological treatment for hypertension became possible, three treatment modalities were used, all with numerous side-effects: strict sodium restriction (for example the rice diet), sympathectomy (surgical ablation of parts of the sympathetic nervous system), and pyrogen therapy (injection of substances that caused a fever, indirectly reducing blood pressure).The first chemical for hypertension, sodium thiocyanate, was used in 1900 but had many side effects and was unpopular. Several other agents were developed after the Second World War, the most popular and reasonably effective of which were tetramethylammonium chloride, hexamethonium, hydralazine, and reserpine (derived from the medicinal plant Rauvolfia serpentina). None of these were well tolerated. A major breakthrough was achieved with the discovery of the first well-tolerated orally available agents. The first was chlorothiazide, the first thiazide diuretic and developed from the antibiotic sulfanilamide, which became available in 1958. Subsequently, beta blockers, calcium channel blockers, angiotensin converting enzyme (ACE) inhibitors, angiotensin receptor blockers, and renin inhibitors were developed as antihypertensive agents.  Society and culture   Awareness  The World Health Organization has identified hypertension, or high blood pressure, as the leading cause of cardiovascular mortality. The World Hypertension League (WHL), an umbrella organization of 85 national hypertension societies and leagues, recognized that more than 50% of the hypertensive population worldwide are unaware of their condition. To address this problem, the WHL initiated a global awareness campaign on hypertension in 2005 and dedicated 17 May of each year as World Hypertension Day (WHD). Over the past three years, more national societies have been engaging in WHD and have been innovative in their activities to get the message to the public. In 2007, there was record participation from 47 member countries of the WHL. During the week of WHD, all these countries – in partnership with their local governments, professional societies, nongovernmental organizations and private industries – promoted hypertension awareness among the public through several media and public rallies. Using mass media such as Internet and television, the message reached more than 250 million people. As the momentum picks up year after year, the WHL is confident that almost all the estimated 1.5 billion people affected by elevated blood pressure can be reached.  Economics  High blood pressure is the most common chronic medical problem prompting visits to primary health care providers in US. The American Heart Association estimated the direct and indirect costs of high blood pressure in 2010 as $76.6 billion. In the US 80% of people with hypertension are aware of their condition, 71% take some antihypertensive medication, but only 48% of people aware that they have hypertension adequately control it. Adequate management of hypertension can be hampered by inadequacies in the diagnosis, treatment, or control of high blood pressure. Health care providers face many obstacles to achieving blood pressure control, including resistance to taking multiple medications to reach blood pressure goals. People also face the challenges of adhering to medicine schedules and making lifestyle changes. Nonetheless, the achievement of blood pressure goals is possible, and most importantly, lowering blood pressure significantly reduces the risk of death due to heart disease and stroke, the development of other debilitating conditions, and the cost associated with advanced medical care.  Other animals  Hypertension in cats is indicated with a systolic blood pressure greater than 150 mmHg, with amlodipine the usual first-line treatment. A cat with a systolic blood pressure above 170 mmHg is considered hypertensive. If a cat has other problems such as any kidney disease or retina detachment then a blood pressure below 160 mm HG may also need to be monitored.Normal blood pressure in dogs can differ substantially between breeds but hypertension is often diagnosed if systolic blood pressure is above 160 mmHg particularly if this is associated with target organ damage. Inhibitors of the renin-angiotensin system and calcium channel blockers are often used to treat hypertension in dogs, although other drugs may be indicated for specific conditions causing high blood pressure.  References   Further reading   External links ","Hypertension or high blood pressure is a chronic medical condition in which the blood pressure in the arteries is higher than it should be. This involves the heart working harder than normal to circulate blood through the blood vessels.  Blood pressure  The pressure in the arteries changes depending on what the heart is doing. When the heart squeezes, pumping blood into the arteries, the pressure increases. When the heart relaxes, the pressure decreases. When blood pressure is measured, the highest pressure (when the heart is squeezing) is called the systolic blood pressure. The lowest pressure (when the heart is relaxing) is called the diastolic blood pressure. Blood pressure is written as two numbers. For example, in the picture at the right, the person's systolic blood pressure was 158. Their diastolic blood pressure was 99. This blood pressure is written as 158/99. It is said ""158 over 99.""  Types  There are two types of hypertension, called “primary” and “secondary.” Primary hypertension means that the hypertension is not caused by any other disease or condition and it gradually develops over time with age. Secondary hypertension means that the hypertension is caused by another disease or conditions. Secondary hypertension tend to result in higher blood pressure than primary hypertension. In most cases (90-95%), hypertension is primary. Only a small amount of hypertension (5-10%) is secondary. There are various health conditions that leads to secondary hypertension which includes: Obstructive sleep apnea, Kidney problems, Adrenal gland tumors, Thyroid problems, Certain defects you're born with (congenital) in blood vessels, Certain medications (birth control pills, cold remedies, decongestants, over-the-counter pain relievers and some prescription drugs), Illegal drugs (cocaine and amphetamines).  Complications  Hypertension can cause many problems, including heart attack, stroke, Aneurysm, congestive heart failure, kidney failure, vision loss, Metabolic syndrome, Dementia, etc.. To stay healthy, most people should try to keep their blood pressure below 140/90 mmHg.  Risk Factors  The risk factors includes age, Race, Family history or genes, obesity, lack of physical activity, chewing or smoking tobacco, too much salt in diet, not enough potassium in diet, alcohol, stress, kidney disease, diabetes and sleep apnea.  Treatment   Lifestyle changes  Hypertension can often be fixed with changes in diet or lifestyle. The 2004 British Hypertension Society suggests that people with high blood pressure: Lose weight if they are overweight or obese Exercise regularly Decrease the amount of salt they eat Limit the amount of alcohol they drink Eat a lot of fruits and vegetables  Medicine  If lifestyle changes do not decrease a person's blood pressure, then the person may need medications. A doctor will choose which medications to use, based on what other medical problems the person has. Examples of medications that decrease blood pressure include: Diuretics, which increase urination to get rid of extra fluid Beta blockers, which slow down the heart rate ACE inhibitors, which relax the arteries  Effectiveness  Even small decreases in blood pressure can have a large effect on a person's health. For example, decreasing blood pressure by 5 mmHg (for example, from 150/100 to 145/95 mmHg) can decrease the risk of stroke by 34%. It can also decrease the risk of heart disease by 21%.  Related pages  Blood pressure Heart Arteries Circulatory system Hypotension (low blood pressure)  References  What is Blood Pressure Or Hypertension ? Archived 2020-04-12 at the Wayback Machine"
"Histamine is an organic nitrogenous compound involved in local immune responses, as well as regulating physiological functions in the gut and acting as a neurotransmitter for the brain, spinal cord, and uterus. Since histamine was discovered in 1910, it has been considered a local hormone (autocoid) because it lacks the classic endocrine glands to secrete it; however, in recent years, histamine has been recognized as a central neurotransmitter. Histamine is involved in the inflammatory response and has a central role as a mediator of itching. As part of an immune response to foreign pathogens, histamine is produced by basophils and by mast cells found in nearby connective tissues. Histamine increases the permeability of the capillaries to white blood cells and some proteins, to allow them to engage pathogens in the infected tissues. It consists of an imidazole ring attached to an ethylamine chain; under physiological conditions, the amino group of the side-chain is protonated.  Properties  Histamine base, obtained as a mineral oil mull, melts at 83–84 °C. Hydrochloride and phosphorus salts form white hygroscopic crystals and are easily dissolved in water or ethanol, but not in ether. In aqueous solution, the imidazole ring of histamine exists in two tautomeric forms, identified by which of the two nitrogen atoms is protonated. The nitrogen farther away from the side chain is the 'tele' nitrogen and is denoted by a lowercase tau sign and the nitrogen closer to the side chain is the 'pros' nitrogen and is denoted by the pi sign. The tele tautomer, Nτ-H-histamine, is preferred in solution as compared to the pros tautomer, Nπ-H-histamine. Histamine has two basic centres, namely the aliphatic amino group and whichever nitrogen atom of the imidazole ring does not already have a proton. Under physiological conditions, the aliphatic amino group (having a pKa around 9.4) will be protonated, whereas the second nitrogen of the imidazole ring (pKa ≈ 5.8) will not be protonated. Thus, histamine is normally protonated to a singly charged cation. Since human blood is slightly basic (with a normal pH range of 7.35 to 7.45) therefore the predominant form of histamine present in human blood is monoprotic at the aliphatic nitrogen. Histamine is a monoamine neurotransmitter.  Synthesis and metabolism  Histamine is derived from the decarboxylation of the amino acid histidine, a reaction catalyzed by the enzyme L-histidine decarboxylase. It is a hydrophilic vasoactive amine. Once formed, histamine is either stored or rapidly inactivated by its primary degradative enzymes, histamine-N-methyltransferase or diamine oxidase. In the central nervous system, histamine released into the synapses is primarily broken down by histamine-N-methyltransferase, while in other tissues both enzymes may play a role. Several other enzymes, including MAO-B and ALDH2, further process the immediate metabolites of histamine for excretion or recycling. Bacteria also are capable of producing histamine using histidine decarboxylase enzymes unrelated to those found in animals. A non-infectious form of foodborne disease, scombroid poisoning, is due to histamine production by bacteria in spoiled food, particularly fish. Fermented foods and beverages naturally contain small quantities of histamine due to a similar conversion performed by fermenting bacteria or yeasts. Sake contains histamine in the 20–40 mg/L range; wines contain it in the 2–10 mg/L range.  Storage and release  Most histamine in the body is generated in granules in mast cells and in white blood cells (leukocytes) called basophils. Mast cells are especially numerous at sites of potential injury – the nose, mouth, and feet, internal body surfaces, and blood vessels. Non-mast cell histamine is found in several tissues, including the hypothalamus region of the brain, where it functions as a neurotransmitter. Another important site of histamine storage and release is the enterochromaffin-like (ECL) cell of the stomach. The most important pathophysiologic mechanism of mast cell and basophil histamine release is immunologic. These cells, if sensitized by IgE antibodies attached to their membranes, degranulate when exposed to the appropriate antigen. Certain amines and alkaloids, including such drugs as morphine, and curare alkaloids, can displace histamine in granules and cause its release. Antibiotics like polymyxin are also found to stimulate histamine release. Histamine release occurs when allergens bind to mast-cell-bound IgE antibodies. Reduction of IgE overproduction may lower the likelihood of allergens finding sufficient free IgE to trigger a mast-cell-release of histamine.  Degradation  Histamine is released by mast cells as an immune response and is later degraded primarily by two enzymes: diamine oxidase (DAO), coded by AOC1 genes, and histamine-N-methyltransferase (HNMT), coded by the HNMT gene. The presence of single nucleotide polymorphisms (SNPs) at these genes are associated with a wide variety of disorders caused by an overactive immune system, from ulcerative colitis to autism spectrum disorder (ASD). Histamine degradation is crucial to the prevention of allergic reactions to otherwise harmless substances. DAO is typically expressed in epithelial cells at the tip of the villus of the small intestine mucosa. Reduced DAO activity is associated with gastrointestinal disorders and widespread food intolerances. This is due to an increase in histamine absorption through enterocytes, which increases histamine concentration in the bloodstream. One study found that migraine patients with gluten sensitivity were positively correlated with having lower DAO serum levels. Low DAO activity can have more severe consequences as mutations in the ABP1 alleles of the AOC1 gene have been associated with ulcerative colitis. Heterozygous or homozygous recessive genotypes at the rs2052129, rs2268999, rs10156191 and rs1049742 alleles increased the risk for reduced DAO activity. People with genotypes for reduced DAO activity can avoid foods high in histamine, such as alcohol, fermented foods, and aged foods, to attenuate any allergic reactions. Additionally, they should be aware whether any probiotics they are taking contain any histamine-producing strains and consult with their doctor to receive proper support. HNMT is expressed in the central nervous system, where deficiencies have been shown to lead to aggressive behavior and abnormal sleep-wake cycles in mice. Since brain histamine as a neurotransmitter regulates a number of neurophysiological functions, emphasis has been placed on the development of drugs to target histamine regulation. Yoshikawa et al. explores how the C314T, A939G, G179A, and T632C polymorphisms all impact HNMT enzymatic activity and the pathogenesis of various neurological disorders. These mutations can have either a positive or negative impact. Some patients with ADHD have been shown to exhibit exacerbated symptoms in response to food additives and preservatives, due in part to histamine release. In a double-blind placebo-controlled crossover trial, children with ADHD who responded with aggravated symptoms after consuming a challenge beverage were more likely to have HNMT polymorphisms at T939C and Thr105Ile. Histamine’s role in neuroinflammation and cognition has made it a target of study for many neurological disorders, including autism spectrum disorder (ASD). De novo deletions in the HNMT gene have also been associated with ASD.Mast cells serve an important immunological role by defending the body from antigens and maintaining homeostasis in the gut microbiome. They act as an alarm to trigger inflammatory responses by the immune system. Their presence in the digestive system enables them to serve as an early barrier to pathogens entering the body. People who suffer from widespread sensitivities and allergic reactions may have mast cell activation syndrome (MCAS), in which excessive amounts of histamine are released from mast cells, and cannot be properly degraded. The abnormal release of histamine can be caused by either dysfunctional internal signals from defective mast cells or by the development of clonal mast cell populations through mutations occurring in the tyrosine kinase Kit. In such cases, the body may not be able to produce sufficient degradative enzymes to properly eliminate the excess histamine. Since MCAS is symptomatically characterized as such a broad disorder, it is difficult to diagnose and can be mislabeled as a variety of diseases, including irritable bowel syndrome and fibromyalgia.Histamine is often explored as a potential cause for diseases related to hyper-responsiveness of the immune system. In patients with asthma, abnormal histamine receptor activation in the lungs is associated with bronchospasm, airway obstruction, and production of excess mucus. Mutations in histamine degradation are more common in patients with a combination of asthma and allergen hypersensitivity than in those with just asthma. The HNMT-464 TT and HNMT-1639 TT are significantly more common among children with allergic asthma, the latter of which is overrepresented in African-American children.  Mechanism of action  In humans, histamine exerts its effects primarily by binding to G protein-coupled histamine receptors, designated H1 through H4. As of 2015, histamine is believed to activate ligand-gated chloride channels in the brain and intestinal epithelium.  Roles in the body  Although histamine is small compared to other biological molecules (containing only 17 atoms), it plays an important role in the body. It is known to be involved in 23 different physiological functions. Histamine is known to be involved in many physiological functions because of its chemical properties that allow it to be versatile in binding. It is Coulombic (able to carry a charge), conformational, and flexible. This allows it to interact and bind more easily.  Vasodilation and fall in blood pressure  It has been known for more than one hundred years that an intravenous injection of histamine causes a fall in the blood pressure. The underlying mechanism concerns both vascular hyperpermeability and vasodilation. Histamine binding to endothelial cells causes them to contract, thus increasing vascular leak. It also stimulates synthesis and release of various vascular smooth muscle cell relaxants, such as nitric oxide, endothelium-derived hyperpolarizing factors and other compounds, resulting in blood vessel dilation. These two mechanisms play a key role in the pathophysiology of anaphylaxis.  Effects on nasal mucous membrane  Increased vascular permeability causes fluid to escape from capillaries into the tissues, which leads to the classic symptoms of an allergic reaction: a runny nose and watery eyes. Allergens can bind to IgE-loaded mast cells in the nasal cavity's mucous membranes. This can lead to three clinical responses: sneezing due to histamine-associated sensory neural stimulation hyper-secretion from glandular tissue nasal congestion due to vascular engorgement associated with vasodilation and increased capillary permeability  Sleep-wake regulation  Histamine is a neurotransmitter that is released from histaminergic neurons which project out of the mammalian hypothalamus. The cell bodies of these neurons are located in a portion of the posterior hypothalamus known as the tuberomammillary nucleus (TMN). The histamine neurons in this region comprise the brain's histamine system, which projects widely throughout the brain and includes axonal projections to the cortex, medial forebrain bundle, other hypothalamic nuclei, medial septum, the nucleus of the diagonal band, ventral tegmental area, amygdala, striatum, substantia nigra, hippocampus, thalamus and elsewhere. The histamine neurons in the TMN are involved in regulating the sleep-wake cycle and promote arousal when activated. The neural firing rate of histamine neurons in the TMN is strongly positively correlated with an individual's state of arousal. These neurons fire rapidly during periods of wakefulness, fire more slowly during periods of relaxation/tiredness, and stop firing altogether during REM and NREM (non-REM) sleep. First-generation H1 antihistamines (i.e., antagonists of histamine receptor H1) are capable of crossing the blood–brain barrier and produce drowsiness by antagonizing histamine H1 receptors in the tuberomammillary nucleus. The newer class of second-generation H1 antihistamines do not readily permeate the blood–brain barrier and thus are less likely to cause sedation, although individual reactions, concomitant medications and dosage may increase the likelihood of a sedating effect. In contrast, histamine H3 receptor antagonists increase wakefulness. Similar to the sedative effect of first-generation H1 antihistamines, an inability to maintain vigilance can occur from the inhibition of histamine biosynthesis or the loss (i.e., degeneration or destruction) of histamine-releasing neurons in the TMN.  Gastric acid release  Enterochromaffin-like cells, located within the gastric glands of the stomach, release histamine that stimulates nearby parietal cells by binding to the apical H2 receptor. Stimulation of the parietal cell induces the uptake of carbon dioxide and water from the blood, which is then converted to carbonic acid by the enzyme carbonic anhydrase. Inside the cytoplasm of the parietal cell, the carbonic acid readily dissociates into hydrogen and bicarbonate ions. The bicarbonate ions diffuse back through the basilar membrane and into the bloodstream, while the hydrogen ions are pumped into the lumen of the stomach via a K+/H+ ATPase pump. Histamine release is halted when the pH of the stomach starts to decrease. Antagonist molecules, like ranitidine, block the H2 receptor and prevent histamine from binding, causing decreased hydrogen ion secretion.  Protective effects  While histamine has stimulatory effects upon neurons, it also has suppressive ones that protect against the susceptibility to convulsion, drug sensitization, denervation supersensitivity, ischemic lesions and stress. It has also been suggested that histamine controls the mechanisms by which memories and learning are forgotten.  Erection and sexual function  Libido loss and erectile failure can occur during treatment with histamine H2 receptor antagonists such as cimetidine, ranitidine, and risperidone. The injection of histamine into the corpus cavernosum in men with psychogenic impotence produces full or partial erections in 74% of them. It has been suggested that H2 antagonists may cause sexual difficulties by reducing the functional binding of testosterone to its endogenous receptors.  Schizophrenia  Metabolites of histamine are increased in the cerebrospinal fluid of people with schizophrenia, while the efficiency of H1 receptor binding sites is decreased. Many atypical antipsychotic medications have the effect of increasing histamine production, because histamine levels seem to be imbalanced in people with that disorder.  Multiple sclerosis  Histamine therapy for treatment of multiple sclerosis is currently being studied. The different H receptors have been known to have different effects on the treatment of this disease. The H1 and H4 receptors, in one study, have been shown to be counterproductive in the treatment of MS. The H1 and H4 receptors are thought to increase permeability in the blood-brain barrier, thus increasing infiltration of unwanted cells in the central nervous system. This can cause inflammation, and MS symptom worsening. The H2 and H3 receptors are thought to be helpful when treating MS patients. Histamine has been shown to help with T-cell differentiation. This is important because in MS, the body's immune system attacks its own myelin sheaths on nerve cells (which causes loss of signaling function and eventual nerve degeneration). By helping T cells to differentiate, the T cells will be less likely to attack the body's own cells, and instead, attack invaders.  Disorders  As an integral part of the immune system, histamine may be involved in immune system disorders and allergies. Mastocytosis is a rare disease in which there is a proliferation of mast cells that produce excess histamine.Some people may accumulate excessive dietary histamine in their bodies as a result of histamine intolerance. This may lead to symptoms such as hives, itchy or flushed skin, red eyes, facial swelling, runny nose and congestion, headaches, or asthma attacks.  History  The properties of histamine, then called β-imidazolylethylamine, were first described in 1910 by the British scientists Henry H. Dale and P.P. Laidlaw. By 1913 the name histamine was in use, using combining forms of histo- + amine, yielding ""tissue amine"". ""H substance"" or ""substance H"" are occasionally used in medical literature for histamine or a hypothetical histamine-like diffusible substance released in allergic reactions of skin and in the responses of tissue to inflammation.  See also  Anaphylaxis Diamine oxidase Hay fever (allergic rhinitis) Histamine intolerance Histamine receptor antagonist Scombroid food poisoning Photic sneeze reflex  References   External links  Histamine MS Spectrum Histamine bound to proteins in the PDB","Histamine is an organic nitrogenous compound involved in local immune responses. It also regulates physiological function in the gut, and acts as a neurotransmitter. Histamine is involved in the inflammatory response, where tissues get red, swollen and painful. As part of an immune response to foreign pathogens, histamine is produced by basophils and by mast cells found in nearby connective tissues. Histamine increases the permeability of the capillaries to white blood cells and some proteins. The cells get through the walls of the tiny blood vessels to get at pathogens in the infected tissues.Histamine in water exists as two tautomers in equilibrium, differing by the position of the hydrogen atom:  References "
"The blood circulatory system is a system of organs that includes the heart, blood vessels, and blood which is circulated throughout the entire body of a human or other vertebrate. It includes the cardiovascular system, or vascular system, that consists of the heart and blood vessels (from Greek kardia meaning heart, and from Latin vascula meaning vessels). The circulatory system has two divisions, a systemic circulation or circuit, and a pulmonary circulation or circuit. Some sources use the terms cardiovascular system and vascular system interchangeably with the circulatory system.The network of blood vessels are the great vessels of the heart including large elastic arteries, and large veins; other arteries, smaller arterioles, capillaries that join with venules (small veins), and other veins. The circulatory system is closed in vertebrates, which means that the blood never leaves the network of blood vessels. Some invertebrates such as arthropods have an open circulatory system. Diploblasts such as sponges, and comb jellies lack a circulatory system. Blood is a fluid consisting of plasma, red blood cells, white blood cells, and platelets that is circulated around the body carrying oxygen and nutrients to the tissues, and waste materials away. Circulated nutrients include proteins and minerals, other components transported are gases such as oxygen, and carbon dioxide, hormones, and hemoglobin; providing nourishment, help in the immune system to fight diseases, and in maintaining homeostasis by stabilizing temperature and natural pH. In vertebrates, complementary to the circulatory system is the lymphatic system. This system carries excess plasma filtered from the capillaries as interstitial fluid between cells, away from the body tissues in an accessory route to return the excess fluid back to the blood circulation as lymph. The passage of lymph takes much longer than that of blood. The lymphatic system is a subsystem that is essential for the functioning of the blood circulatory system; without it the blood would become depleted of fluid. The lymphatic system works together with the immune system. Unlike the closed circulatory system, the lymphatic system is an open system. Some sources describe it as a secondary circulatory system. The circulatory system can be affected by many cardiovascular diseases. Cardiologists are medical professionals which specialise in the heart, and cardiothoracic surgeons specialise in operating on the heart and its surrounding areas. Vascular surgeons focus on disorders of the blood vessels, and lymphatic vessels.  Structure  The circulatory system includes the heart, blood vessels, and blood. The cardiovascular system in all vertebrates, consists of the heart and blood vessels. The circulatory system is further divided into two major circuits – a pulmonary circulation, and a systemic circulation. The pulmonary circulation is a circuit loop from the right heart taking deoxygenated blood to the lungs where it is oxygenated and returned to the left heart. The systemic circulation is a circuit loop that delivers oxygenated blood from the left heart to the rest of the body, and returns deoxygenated blood back to the right heart via large veins known as the venae cavae. The systemic circulation can also be defined as two parts – a macrocirculation and a microcirculation. An average adult contains five to six quarts (roughly 4.7 to 5.7 liters) of blood, accounting for approximately 7% of their total body weight. Blood consists of plasma, red blood cells, white blood cells, and platelets. The digestive system also works with the circulatory system to provide the nutrients the system needs to keep the heart pumping.Further circulatory routes are associated, such as the coronary circulation to the heart itself, the cerebral circulation to the brain, renal circulation to the kidneys, and bronchial circulation to the bronchi in the lungs. The human circulatory system is closed, meaning that the blood is contained within the vascular network. Nutrients travel through tiny blood vessels of the microcirculation to reach organs. The lymphatic system is an essential subsystem of the circulatory system consisting of a network of lymphatic vessels, lymph nodes, organs, tissues and circulating lymph. This subsystem is an open system. A major function is to carry the lymph, draining and returning interstitial fluid into the lymphatic ducts back to the heart for return to the circulatory system. Another major function is working together with the immune system to provide defense against pathogens.  Heart  The heart pumps blood to all parts of the body providing nutrients and oxygen to every cell, and removing waste products. The left heart pumps oxygenated blood returned from the lungs to the rest of the body in the systemic circulation. The right heart pumps deoxygenated blood to the lungs in the pulmonary circulation. In the human heart there is one atrium and one ventricle for each circulation, and with both a systemic and a pulmonary circulation there are four chambers in total: left atrium, left ventricle, right atrium and right ventricle. The right atrium is the upper chamber of the right side of the heart. The blood that is returned to the right atrium is deoxygenated (poor in oxygen) and passed into the right ventricle to be pumped through the pulmonary artery to the lungs for re-oxygenation and removal of carbon dioxide. The left atrium receives newly oxygenated blood from the lungs as well as the pulmonary vein which is passed into the strong left ventricle to be pumped through the aorta to the different organs of the body.  Pulmonary circulation  The pulmonary circulation is the part of the circulatory system in which oxygen-depleted blood is pumped away from the heart, via the pulmonary artery, to the lungs and returned, oxygenated, to the heart via the pulmonary vein. Oxygen-deprived blood from the superior and inferior vena cava enters the right atrium of the heart and flows through the tricuspid valve (right atrioventricular valve) into the right ventricle, from which it is then pumped through the pulmonary semilunar valve into the pulmonary artery to the lungs. Gas exchange occurs in the lungs, whereby CO2 is released from the blood, and oxygen is absorbed. The pulmonary vein returns the now oxygen-rich blood to the left atrium.A separate circuit from the systemic circulation, the bronchial circulation supplies blood to the tissue of the larger airways of the lung.  Systemic circulation  The systemic circulation is a circuit loop that delivers oxygenated blood from the left heart to the rest of the body through the aorta. Deoxygenated blood is returned in the systemic circulation to the right heart via two large veins, the inferior vena cava and superior vena cava, where it is pumped from the right atrium into the pulmonary circulation for oxygenation. The systemic circulation can also be defined as having two parts – a macrocirculation and a microcirculation.  Blood vessels  The blood vessels of the circulatory system are the arteries, veins, and capillaries. The large arteries and veins that take blood to, and away from the heart are known as the great vessels.  Arteries  Oxygenated blood enters the systemic circulation when leaving the left ventricle, via the aortic semilunar valve. The first part of the systemic circulation is the aorta, a massive and thick-walled artery. The aorta arches and gives branches supplying the upper part of the body after passing through the aortic opening of the diaphragm at the level of thoracic ten vertebra, it enters the abdomen. Later, it descends down and supplies branches to abdomen, pelvis, perineum and the lower limbs.The walls of the aorta are elastic. This elasticity helps to maintain the blood pressure throughout the body. When the aorta receives almost five litres of blood from the heart, it recoils and is responsible for pulsating blood pressure. As the aorta branches into smaller arteries, their elasticity goes on decreasing and their compliance goes on increasing.  Capillaries  Arteries branch into small passages called arterioles and then into the capillaries. The capillaries merge to bring blood into the venous system.  Veins  Capillaries merge into venules, which merge into veins. The venous system feeds into the two major veins: the superior vena cava – which mainly drains tissues above the heart – and the inferior vena cava – which mainly drains tissues below the heart. These two large veins empty into the right atrium of the heart.  Portal veins  The general rule is that arteries from the heart branch out into capillaries, which collect into veins leading back to the heart. Portal veins are a slight exception to this. In humans the only significant example is the hepatic portal vein which combines from capillaries around the gastrointestinal tract where the blood absorbs the various products of digestion; rather than leading directly back to the heart, the hepatic portal vein branches into a second capillary system in the liver.  Coronary circulation  The heart itself is supplied with oxygen and nutrients through a small ""loop"" of the systemic circulation and derives very little from the blood contained within the four chambers. The coronary circulation system provides a blood supply to the heart muscle itself. The coronary circulation begins near the origin of the aorta by two coronary arteries: the right coronary artery and the left coronary artery. After nourishing the heart muscle, blood returns through the coronary veins into the coronary sinus and from this one into the right atrium. Backflow of blood through its opening during atrial systole is prevented by the Thebesian valve. The smallest cardiac veins drain directly into the heart chambers.  Cerebral circulation  The brain has a dual blood supply, an anterior and a posterior circulation from arteries at its front and back. The anterior circulation arises from the internal carotid arteries to supply the front of the brain. The posterior circulation arises from the vertebral arteries, to supply the back of the brain and brainstem. The circulation from the front and the back join (anastomise) at the circle of Willis.  Renal circulation  The renal circulation is the blood supply to the kidneys, contains many specialized blood vessels and receives around 20% of the cardiac output. It branches from the abdominal aorta and returns blood to the ascending inferior vena cava.  Development  The development of the circulatory system starts with vasculogenesis in the embryo. The human arterial and venous systems develop from different areas in the embryo. The arterial system develops mainly from the aortic arches, six pairs of arches that develop on the upper part of the embryo. The venous system arises from three bilateral veins during weeks 4 – 8 of embryogenesis. Fetal circulation begins within the 8th week of development. Fetal circulation does not include the lungs, which are bypassed via the truncus arteriosus. Before birth the fetus obtains oxygen (and nutrients) from the mother through the placenta and the umbilical cord.  Arteries  The human arterial system originates from the aortic arches and from the dorsal aortae starting from week 4 of embryonic life. The first and second aortic arches regress and form only the maxillary arteries and stapedial arteries respectively. The arterial system itself arises from aortic arches 3, 4 and 6 (aortic arch 5 completely regresses). The dorsal aortae, present on the dorsal side of the embryo, are initially present on both sides of the embryo. They later fuse to form the basis for the aorta itself. Approximately thirty smaller arteries branch from this at the back and sides. These branches form the intercostal arteries, arteries of the arms and legs, lumbar arteries and the lateral sacral arteries. Branches to the sides of the aorta will form the definitive renal, suprarenal and gonadal arteries. Finally, branches at the front of the aorta consist of the vitelline arteries and umbilical arteries. The vitelline arteries form the celiac, superior and inferior mesenteric arteries of the gastrointestinal tract. After birth, the umbilical arteries will form the internal iliac arteries.  Veins  The human venous system develops mainly from the vitelline veins, the umbilical veins and the cardinal veins, all of which empty into the sinus venosus.  Function  About 98.5% of the oxygen in a sample of arterial blood in a healthy human, breathing air at sea-level pressure, is chemically combined with hemoglobin molecules. About 1.5% is physically dissolved in the other blood liquids and not connected to hemoglobin. The hemoglobin molecule is the primary transporter of oxygen in vertebrates.  Clinical significance  Many diseases affect the circulatory system. These include a number of cardiovascular diseases, affecting the heart and blood vessels; hematologic diseases that affect the blood, such as anemia, and lymphatic diseases affecting the lymphatic system. Cardiologists are medical professionals which specialise in the heart, and cardiothoracic surgeons specialise in operating on the heart and its surrounding areas. Vascular surgeons focus on the blood vessels.  Cardiovascular disease  Diseases affecting the cardiovascular system are called cardiovascular disease. Many of these diseases are called ""lifestyle diseases"" because they develop over time and are related to a person's exercise habits, diet, whether they smoke, and other lifestyle choices a person makes. Atherosclerosis is the precursor to many of these diseases. It is where small atheromatous plaques build up in the walls of medium and large arteries. This may eventually grow or rupture to occlude the arteries. It is also a risk factor for acute coronary syndromes, which are diseases that are characterised by a sudden deficit of oxygenated blood to the heart tissue. Atherosclerosis is also associated with problems such as aneurysm formation or splitting (""dissection"") of arteries. Another major cardiovascular disease involves the creation of a clot, called a ""thrombus"". These can originate in veins or arteries. Deep venous thrombosis, which mostly occurs in the legs, is one cause of clots in the veins of the legs, particularly when a person has been stationary for a long time. These clots may embolise, meaning travel to another location in the body. The results of this may include pulmonary embolus, transient ischaemic attacks, or stroke. Cardiovascular diseases may also be congenital in nature, such as heart defects or persistent fetal circulation, where the circulatory changes that are supposed to happen after birth do not. Not all congenital changes to the circulatory system are associated with diseases, a large number are anatomical variations.  Investigations  The function and health of the circulatory system and its parts are measured in a variety of manual and automated ways. These include simple methods such as those that are part of the cardiovascular examination, including the taking of a person's pulse as an indicator of a person's heart rate, the taking of blood pressure through a sphygmomanometer or the use of a stethoscope to listen to the heart for murmurs which may indicate problems with the heart's valves. An electrocardiogram can also be used to evaluate the way in which electricity is conducted through the heart. Other more invasive means can also be used. A cannula or catheter inserted into an artery may be used to measure pulse pressure or pulmonary wedge pressures. Angiography, which involves injecting a dye into an artery to visualise an arterial tree, can be used in the heart (coronary angiography) or brain. At the same time as the arteries are visualised, blockages or narrowings may be fixed through the insertion of stents, and active bleeds may be managed by the insertion of coils. An MRI may be used to image arteries, called an MRI angiogram. For evaluation of the blood supply to the lungs a CT pulmonary angiogram may be used. Vascular ultrasonography may be used to investigate vascular diseases affecting the venous system and the arterial system including the diagnosis of stenosis, thrombosis or venous insufficiency. An intravascular ultrasound using a catheter is also an option.  Surgery  There are a number of surgical procedures performed on the circulatory system: Coronary artery bypass surgery Coronary stent used in angioplasty Vascular surgery Vein stripping Cosmetic proceduresCardiovascular procedures are more likely to be performed in an inpatient setting than in an ambulatory care setting; in the United States, only 28% of cardiovascular surgeries were performed in the ambulatory care setting.  Other animals  While humans, as well as other vertebrates, have a closed blood circulatory system (meaning that the blood never leaves the network of arteries, veins and capillaries), some invertebrate groups have an open circulatory system containing a heart but limited blood vessels. The most primitive, diploblastic animal phyla lack circulatory systems. An additional transport system, the lymphatic system, which is only found in animals with a closed blood circulation, is an open system providing an accessory route for excess interstitial fluid to be returned to the blood.The blood vascular system first appeared probably in an ancestor of the triploblasts over 600 million years ago, overcoming the time-distance constraints of diffusion, while endothelium evolved in an ancestral vertebrate some 540–510 million years ago.  Open circulatory system  In arthropods, the open circulatory system is a system in which a fluid in a cavity called the hemocoel bathes the organs directly with oxygen and nutrients, with there being no distinction between blood and interstitial fluid; this combined fluid is called hemolymph or haemolymph. Muscular movements by the animal during locomotion can facilitate hemolymph movement, but diverting flow from one area to another is limited. When the heart relaxes, blood is drawn back toward the heart through open-ended pores (ostia). Hemolymph fills all of the interior hemocoel of the body and surrounds all cells. Hemolymph is composed of water, inorganic salts (mostly sodium, chloride, potassium, magnesium, and calcium), and organic compounds (mostly carbohydrates, proteins, and lipids). The primary oxygen transporter molecule is hemocyanin. There are free-floating cells, the hemocytes, within the hemolymph. They play a role in the arthropod immune system.  Closed circulatory system  The circulatory systems of all vertebrates, as well as of annelids (for example, earthworms) and cephalopods (squids, octopuses and relatives) always keep their circulating blood enclosed within heart chambers or blood vessels and are classified as closed, just as in humans. Still, the systems of fish, amphibians, reptiles, and birds show various stages of the evolution of the circulatory system. Closed systems permit blood to be directed to the organs that require it. In fish, the system has only one circuit, with the blood being pumped through the capillaries of the gills and on to the capillaries of the body tissues. This is known as single cycle circulation. The heart of fish is, therefore, only a single pump (consisting of two chambers). In amphibians and most reptiles, a double circulatory system is used, but the heart is not always completely separated into two pumps. Amphibians have a three-chambered heart. In reptiles, the ventricular septum of the heart is incomplete and the pulmonary artery is equipped with a sphincter muscle. This allows a second possible route of blood flow. Instead of blood flowing through the pulmonary artery to the lungs, the sphincter may be contracted to divert this blood flow through the incomplete ventricular septum into the left ventricle and out through the aorta. This means the blood flows from the capillaries to the heart and back to the capillaries instead of to the lungs. This process is useful to ectothermic (cold-blooded) animals in the regulation of their body temperature. Mammals, birds and crocodilians show complete separation of the heart into two pumps, for a total of four heart chambers; it is thought that the four-chambered heart of birds and crocodilians evolved independently from that of mammals. Double circulatory systems permit blood to be repressurized after returning from the lungs, speeding up delivery of oxygen to tissues.  No circulatory system  Circulatory systems are absent in some animals, including flatworms. Their body cavity has no lining or enclosed fluid. Instead, a muscular pharynx leads to an extensively branched digestive system that facilitates direct diffusion of nutrients to all cells. The flatworm's dorso-ventrally flattened body shape also restricts the distance of any cell from the digestive system or the exterior of the organism. Oxygen can diffuse from the surrounding water into the cells, and carbon dioxide can diffuse out. Consequently, every cell is able to obtain nutrients, water and oxygen without the need of a transport system. Some animals, such as jellyfish, have more extensive branching from their gastrovascular cavity (which functions as both a place of digestion and a form of circulation), this branching allows for bodily fluids to reach the outer layers, since the digestion begins in the inner layers.  History  The earliest known writings on the circulatory system are found in the Ebers Papyrus (16th century BCE), an ancient Egyptian medical papyrus containing over 700 prescriptions and remedies, both physical and spiritual. In the papyrus, it acknowledges the connection of the heart to the arteries. The Egyptians thought air came in through the mouth and into the lungs and heart. From the heart, the air travelled to every member through the arteries. Although this concept of the circulatory system is only partially correct, it represents one of the earliest accounts of scientific thought. In the 6th century BCE, the knowledge of circulation of vital fluids through the body was known to the Ayurvedic physician Sushruta in ancient India. He also seems to have possessed knowledge of the arteries, described as 'channels' by Dwivedi & Dwivedi (2007). The valves of the heart were discovered by a physician of the Hippocratean school around the 4th century BCE. However, their function was not properly understood then. Because blood pools in the veins after death, arteries look empty. Ancient anatomists assumed they were filled with air and that they were for the transport of air. The Greek physician, Herophilus, distinguished veins from arteries but thought that the pulse was a property of arteries themselves. Greek anatomist Erasistratus observed that arteries that were cut during life bleed. He ascribed the fact to the phenomenon that air escaping from an artery is replaced with blood that enters between veins and arteries by very small vessels. Thus he apparently postulated capillaries but with reversed flow of blood.In 2nd-century AD Rome, the Greek physician Galen knew that blood vessels carried blood and identified venous (dark red) and arterial (brighter and thinner) blood, each with distinct and separate functions. Growth and energy were derived from venous blood created in the liver from chyle, while arterial blood gave vitality by containing pneuma (air) and originated in the heart. Blood flowed from both creating organs to all parts of the body where it was consumed and there was no return of blood to the heart or liver. The heart did not pump blood around, the heart's motion sucked blood in during diastole and the blood moved by the pulsation of the arteries themselves. Galen believed that the arterial blood was created by venous blood passing from the left ventricle to the right by passing through 'pores' in the interventricular septum, air passed from the lungs via the pulmonary artery to the left side of the heart. As the arterial blood was created 'sooty' vapors were created and passed to the lungs also via the pulmonary artery to be exhaled. In 1025, The Canon of Medicine by the Persian physician, Avicenna, ""erroneously accepted the Greek notion regarding the existence of a hole in the ventricular septum by which the blood traveled between the ventricles."" Despite this, Avicenna ""correctly wrote on the cardiac cycles and valvular function"", and ""had a vision of blood circulation"" in his Treatise on Pulse. While also refining Galen's erroneous theory of the pulse, Avicenna provided the first correct explanation of pulsation: ""Every beat of the pulse comprises two movements and two pauses. Thus, expansion : pause : contraction : pause. [...] The pulse is a movement in the heart and arteries ... which takes the form of alternate expansion and contraction.""In 1242, the Arabian physician, Ibn al-Nafis described the process of pulmonary circulation in greater, more accurate detail than his predecessors, though he believed, as they did, in the notion of vital spirit (pneuma), which he believed was formed in the left ventricle. Ibn al-Nafis stated in his Commentary on Anatomy in Avicenna's Canon: ...the blood from the right chamber of the heart must arrive at the left chamber but there is no direct pathway between them. The thick septum of the heart is not perforated and does not have visible pores as some people thought or invisible pores as Galen thought. The blood from the right chamber must flow through the vena arteriosa (pulmonary artery) to the lungs, spread through its substances, be mingled there with air, pass through the arteria venosa (pulmonary vein) to reach the left chamber of the heart and there form the vital spirit... In addition, Ibn al-Nafis had an insight into what would become a larger theory of the capillary circulation. He stated that ""there must be small communications or pores (manafidh in Arabic) between the pulmonary artery and vein,"" a prediction that preceded the discovery of the capillary system by more than 400 years. Ibn al-Nafis' theory, however, was confined to blood transit in the lungs and did not extend to the entire body. Michael Servetus was the first European to describe the function of pulmonary circulation, although his achievement was not widely recognized at the time, for a few reasons. He firstly described it in the ""Manuscript of Paris"" (near 1546), but this work was never published. And later he published this description, but in a theological treatise, Christianismi Restitutio, not in a book on medicine. Only three copies of the book survived but these remained hidden for decades, the rest were burned shortly after its publication in 1553 because of persecution of Servetus by religious authorities. A better known discovery of pulmonary circulation was by Vesalius's successor at Padua, Realdo Colombo, in 1559. Finally, the English physician William Harvey, a pupil of Hieronymus Fabricius (who had earlier described the valves of the veins without recognizing their function), performed a sequence of experiments and published his Exercitatio Anatomica de Motu Cordis et Sanguinis in Animalibus in 1628, which ""demonstrated that there had to be a direct connection between the venous and arterial systems throughout the body, and not just the lungs. Most importantly, he argued that the beat of the heart produced a continuous circulation of blood through minute connections at the extremities of the body. This is a conceptual leap that was quite different from Ibn al-Nafis' refinement of the anatomy and bloodflow in the heart and lungs."" This work, with its essentially correct exposition, slowly convinced the medical world. However, Harvey was not able to identify the capillary system connecting arteries and veins; these were later discovered by Marcello Malpighi in 1661. In 1956, André Frédéric Cournand, Werner Forssmann and Dickinson W. Richards were awarded the Nobel Prize in Medicine ""for their discoveries concerning heart catheterization and pathological changes in the circulatory system."" In his Nobel lecture, Forssmann credits Harvey as birthing cardiology with the publication of his book in 1628.In the 1970s, Diana McSherry developed computer-based systems to create images of the circulatory system and heart without the need for surgery.  See also   References   External links  Circulatory Pathways in Anatomy and Physiology by OpenStax The Circulatory System Michael Servetus Research Study on the Manuscript of Paris by Servetus (1546 description of the Pulmonary Circulation)","The circulatory system (also called the cardiovascular system) is the body system that moves blood around the body. It consists of the heart and blood vessels. The blood carries various materials that the body needs, and takes away waste and harmful substances. Blood vessels that take blood away from the heart are arteries. Arteries divide into smaller arteries as they go away from the heart. The smaller arteries that connect to the capillaries, are called arterioles. Blood vessels that take blood towards the heart are veins. Veins get bigger as they go towards the heart. The smallest veins are called venules. Pronounced (VEHN-yools) Capillaries go between arteries and veins. Capillaries are quite thin, hence the name which comes from the Latin capillus meaning ""hair."" So blood moves: heart→artery→arteriole→capillary→venule→vein→heart. This is called circulation. There are two different circulations in the circulatory system. The systemic circulation is how blood goes to most of the body. The pulmonary circulation is how blood goes through the lungs. (Pulmonary means ¨about the lungs¨). This is how it works in mammals, including humans. Circulatory systems of other vertebrates differ somewhat.  Systemic circulation  Blood that comes from the left side of the heart is full of oxygen and nutrients. Nutrients are substances that your body needs to live, like protein, fat, carbohydrates, vitamins, and minerals. The blood brings the oxygen and nutrients to your body. This blood in systemic arteries that is full of oxygen and nutrients is systemic arterial blood. It is sometimes just called arterial blood. The biggest systemic artery in the body is the aorta. This is the large blood vessel that comes out of the heart. Smaller arteries branch off from the aorta. These arteries have smaller arteries that branch off from them. The smallest arteries turn into arterioles. The smallest blood vessels are capillaries. Systemic arterioles turn into capillaries. The blood from arterioles goes into the capillaries. There oxygen and nutrients go out of the blood into the tissue around the capillaries. The blood also picks up carbon dioxide and waste from the tissue. The network of capillaries that brings blood to an area is called a capillary bed. On the other end of the capillary, it turns into a venule. Venules are the smallest veins. Veins take blood back to the heart. As veins go back to the heart, they merge and get bigger. The biggest systemic veins in the body are the vena cava. There are two vena cava. The inferior vena cava takes blood from the lower part of the body to the right side of the heart. (In anatomy, inferior means below.) The superior vena cava takes blood from the upper part of the body to the heart. (Superior means above.)  Pulmonary circulation  This same movement of blood goes through the lungs in the pulmonary circulation. The blood that the vena cava vein takes to the heart is full of carbon dioxide. It has much less oxygen than (systemic) arterial blood. The right side of the heart pushes the venous blood into the pulmonary artery. The pulmonary artery takes blood to the lungs. In the lungs, the blood goes through the pulmonary capillary bed. (The capillaries that are in the lungs). Here it gets more oxygen. It also drops off carbon dioxide. (This is the opposite of what happens in capillary beds in the rest of the body. In the systemic circulation blood drops off oxygen and picks up carbon dioxide). After the pulmonary capillary bed, the blood goes to the pulmonary veins. This pulmonary venous blood now is full of oxygen. The pulmonary veins take blood to the left side of the heart. Then the blood goes to the systemic circulation again.  The shunt  Veins from the gut shunt to the liver before returning to the right atrium and ventricle. The shunt is called the hepatic portal vein. The meaning of this is as follows. The liver is the body's main chemical factory. It takes in the flow of nutrients from the gut, and adjusts them to suit what the body needs. It can store surplus nutrients, or release extra nutrients from store. It can change the chemical make-up of many nutrients. In this way it adapts to the many different kinds of food which the body digests.  References   Related pages  Lymphatic system  Other websites  American Medical Association Encyclopedia - The Circulatory System Archived 2005-04-18 at the Wayback Machine Ohio Heart and Vascular Center - pictures Circulatory system Citizendium"
"The blood vessels are the components of the circulatory system that transport blood throughout the human body. These vessels transport blood cells, nutrients, and oxygen to the tissues of the body. They also take waste and carbon dioxide away from the tissues. Blood vessels are needed to sustain life, because all of the body's tissues rely on their functionality.There are five types of blood vessels: the arteries, which carry the blood away from the heart; the arterioles; the capillaries, where the exchange of water and chemicals between the blood and the tissues occurs; the venules; and the veins, which carry blood from the capillaries back towards the heart. The word vascular, meaning relating to the blood vessels, is derived from the Latin vas, meaning vessel. Some structures – such as cartilage, the epithelium, and the lens and cornea of the eye – do not contain blood vessels and are labeled avascular.  Etymology  artery: late Middle English; from Latin arteria, from Greek artēria, probably from airein (""raise"") vein: Middle English; from Old French veine, from Latin vena. The earliest senses were ""blood vessel"" and ""small natural underground channel of water"". capillary: mid 17th century; from Latin capillaris, from capillus (""hair""), influenced by Old French capillaire.  Structure  The arteries and veins have three layers. The middle layer is thicker in the arteries than it is in the veins: The inner layer, tunica intima, is the thinnest layer. It is a single layer of flat cells (simple squamous epithelium) glued by a polysaccharide intercellular matrix, surrounded by a thin layer of subendothelial connective tissue interlaced with a number of circularly arranged elastic bands called the internal elastic lamina. A thin membrane of elastic fibers in the tunica intima run parallel to the vessel. The middle layer tunica media is the thickest layer in arteries. It consists of circularly arranged elastic fiber, connective tissue, polysaccharide substances, the second and third layer are separated by another thick elastic band called external elastic lamina. The tunica media may (especially in arteries) be rich in vascular smooth muscle, which controls the caliber of the vessel. Veins do not have the external elastic lamina, but only an internal one. The tunica media is thicker in the arteries rather than the veins. The outer layer is the tunica adventitia and the thickest layer in veins. It is entirely made of connective tissue. It also contains nerves that supply the vessel as well as nutrient capillaries (vasa vasorum) in the larger blood vessels.Capillaries consist of a single layer of endothelial cells with a supporting subendothelium consisting of a basement membrane and connective tissue. When blood vessels connect to form a region of diffuse vascular supply it is called an anastomosis. Anastomoses provide critical alternative routes for blood to flow in case of blockages. Leg veins have valves which prevent backflow of the blood being pumped against gravity by the surrounding muscles.  Types  There are various kinds of blood vessels: Arteries Elastic arteries Distributing arteries Arterioles Capillaries (smallest blood vessels) Venules Veins Large collecting vessels, such as the subclavian vein, the jugular vein, the renal vein and the iliac vein. Venae cavae (the two largest veins, carry blood into the heart). Sinusoids Extremely small vessels located within bone marrow, the spleen, and the liver.They are roughly grouped as ""arterial"" and ""venous"", determined by whether the blood in it is flowing away from (arterial) or toward (venous) the heart. The term ""arterial blood"" is nevertheless used to indicate blood high in oxygen, although the pulmonary artery carries ""venous blood"" and blood flowing in the pulmonary vein is rich in oxygen. This is because they are carrying the blood to and from the lungs, respectively, to be oxygenated.  Function  Blood vessels function to transport blood. In general, arteries and arterioles transport oxygenated blood from the lungs to the body and its organs, and veins and venules transport deoxygenated blood from the body to the lungs. Blood vessels also circulate blood throughout the circulatory system Oxygen (bound to hemoglobin in red blood cells) is the most critical nutrient carried by the blood. In all arteries apart from the pulmonary artery, hemoglobin is highly saturated (95–100%) with oxygen. In all veins apart from the pulmonary vein, the saturation of hemoglobin is about 75%. (The values are reversed in the pulmonary circulation.) In addition to carrying oxygen, blood also carries hormones, waste products and nutrients for cells of the body. Blood vessels do not actively engage in the transport of blood (they have no appreciable peristalsis). Blood is propelled through arteries and arterioles through pressure generated by the heartbeat. Blood vessels also transport red blood cells which contain the oxygen necessary for daily activities. The amount of red blood cells present in your vessels has an effect on your health. Hematocrit tests can be performed to calculate the proportion of red blood cells in your blood. Higher proportions result in conditions such as dehydration or heart disease while lower proportions could lead to anemia and long-term blood loss.Permeability of the endothelium is pivotal in the release of nutrients to the tissue. It is also increased in inflammation in response to histamine, prostaglandins and interleukins, which leads to most of the symptoms of inflammation (swelling, redness, warmth and pain).  Vessel size  Arteries—and veins to a degree—can regulate their inner diameter by contraction of the muscular layer. This changes the blood flow to downstream organs, and is determined by the autonomic nervous system. Vasodilation and vasoconstriction are also used antagonistically as methods of thermoregulation.The size of blood vessels is different for each of them. It ranges from a diameter of about 25 millimeters for the aorta to only 8 micrometers in the capillaries. This comes out to about a 3000-fold range. Vasoconstriction is the constriction of blood vessels (narrowing, becoming smaller in cross-sectional area) by contracting the vascular smooth muscle in the vessel walls. It is regulated by vasoconstrictors (agents that cause vasoconstriction). These include paracrine factors (e.g. prostaglandins), a number of hormones (e.g. vasopressin and angiotensin) and neurotransmitters (e.g. epinephrine) from the nervous system. Vasodilation is a similar process mediated by antagonistically acting mediators. The most prominent vasodilator is nitric oxide (termed endothelium-derived relaxing factor for this reason).  Blood flow  The circulatory system uses the channel of blood vessels to deliver blood to all parts of the body. This is a result of the left and right side of the heart working together to allow blood to flow continuously to the lungs and other parts of the body. Oxygen-poor blood enters the right side of the heart through two large veins. Oxygen-rich blood from the lungs enters through the pulmonary veins on the left side of the heart into the aorta and then reaches the rest of the body. The capillaries are responsible for allowing the blood to receive oxygen through tiny air sacs in the lungs. This is also the site where carbon dioxide exits the blood. This all occurs in the lungs where blood is oxygenated.The blood pressure in blood vessels is traditionally expressed in millimetres of mercury (1 mmHg  133 Pa). In the arterial system, this is usually around 120 mmHg systolic (high pressure wave due to contraction of the heart) and 80 mmHg diastolic (low pressure wave). In contrast, pressures in the venous system are constant and rarely exceed 10 mmHg. Vascular resistance occurs where the vessels away from the heart oppose the flow of blood. Resistance is an accumulation of three different factors: blood viscosity, blood vessel length, and vessel radius.Blood viscosity is the thickness of the blood and its resistance to flow as a result of the different components of the blood. Blood is 92% water by weight and the rest of blood is composed of protein, nutrients, electrolytes, wastes, and dissolved gases. Depending on the health of an individual, the blood viscosity can vary (i.e. anemia causing relatively lower concentrations of protein, high blood pressure an increase in dissolved salts or lipids, etc.).Vessel length is the total length of the vessel measured as the distance away from the heart. As the total length of the vessel increases, the total resistance as a result of friction will increase.Vessel radius also affects the total resistance as a result of contact with the vessel wall. As the radius of the wall gets smaller, the proportion of the blood making contact with the wall will increase. The greater amount of contact with the wall will increase the total resistance against the blood flow.  Disease  Blood vessels play a huge role in virtually every medical condition. Cancer, for example, cannot progress unless the tumor causes angiogenesis (formation of new blood vessels) to supply the malignant cells' metabolic demand. Atherosclerosis, the narrowing of the blood vessels due to the buildup of plaque, and the coronary artery disease that often follows can cause heart attacks or cardiac arrest and is the leading cause of death worldwide resulting in 8.9 million deaths or 16% of all deaths.Blood vessel permeability is increased in inflammation. Damage, due to trauma or spontaneously, may lead to hemorrhage due to mechanical damage to the vessel endothelium. In contrast, occlusion of the blood vessel by atherosclerotic plaque, by an embolised blood clot or a foreign body leads to downstream ischemia (insufficient blood supply) and possibly infarction (necrosis due to lack of blood supply). Vessel occlusion tends to be a positive feedback system; an occluded vessel creates eddies in the normally laminar flow or plug flow blood currents. These eddies create abnormal fluid velocity gradients which push blood elements such as cholesterol or chylomicron bodies to the endothelium. These deposit onto the arterial walls which are already partially occluded and build upon the blockage.The most common disease of the blood vessels is hypertension or high blood pressure. This is caused by an increase in the pressure of the blood flowing through the vessels. Hypertension can lead to more serious conditions such as heart failure and stroke. To prevent these diseases, the most common treatment option is medication as opposed to surgery. Aspirin helps prevent blood clots and can also help limit inflammation.Vasculitis is inflammation of the vessel wall, due to autoimmune disease or infection.  See also  Circulatory system Heart List of bones of the human skeleton List of skeletal muscles of the human body List of nerves of the human body  References ","A blood vessel is a tube that carries blood in the circulatory system. Blood vessels that take blood away from the heart are arteries. Blood vessels that take blood back to the heart are veins. Capillaries are between veins and arteries and they supply tissue with blood. The heart plus all of the blood vessels in the body together are called the circulatory system. Blood is moved by the pumping of the heart and carries oxygen to the tissues. The expansion of blood vessels is called vasodilation, it helps the body to get rid of heat energy (vas- in Latin means ""container"" or ""vessel""). The constriction of blood vessels is called vasoconstriction, it prevents the body from losing warmth. There are 100,000 km (60,000 miles) of blood vessels in an adult human body.Growing new blood vessels is called angiogenesis.  Structure  Different parts of the body have different kinds of blood vessels for different parts of their work. The vessel wall consists of three shells: inner - represented by the endothelium (single-layer squamous epithelium), which is built of elongated endothelial cells located on the basement membrane, and the subendothelial layer, which is based on loose fibrous connective tissue; middle - consists of circular bundles of smooth muscle cells with layers of elastic fibers; external - is represented by loose fibrous connective tissue, which contains a lot of blood vessels and nerve fibers.The structure of the vessel wall depends on hemodynamic conditions: blood flow velocity, volume and blood pressure. Arteries located close to the heart are characterized by a predominance of elastic elements that are able to counteract high hemodynamic parameters. As you move away from the heart, hemodynamic values decrease, the caliber of blood vessels decreases and the number of muscle elements in their walls increases, which are able to create additional force to push blood into the network of the smallest vessels.  References "
"Blood is a body fluid in the circulatory system of humans and other vertebrates that delivers necessary substances such as nutrients and oxygen to the cells, and transports metabolic waste products away from those same cells. Blood in the circulatory system is also known as peripheral blood, and the blood cells it carries, peripheral blood cells.Blood is composed of blood cells suspended in blood plasma. Plasma, which constitutes 55% of blood fluid, is mostly water (92% by volume), and contains proteins, glucose, mineral ions, hormones, carbon dioxide (plasma being the main medium for excretory product transportation), and blood cells themselves. Albumin is the main protein in plasma, and it functions to regulate the colloidal osmotic pressure of blood. The blood cells are mainly red blood cells (also called RBCs or erythrocytes), white blood cells (also called WBCs or leukocytes), and in mammals platelets (also called thrombocytes). The most abundant cells in vertebrate blood are red blood cells. These contain hemoglobin, an iron-containing protein, which facilitates oxygen transport by reversibly binding to this respiratory gas thereby increasing its solubility in blood. In contrast, carbon dioxide is mostly transported extracellularly as bicarbonate ion transported in plasma. Vertebrate blood is bright red when its hemoglobin is oxygenated and dark red when it is deoxygenated.Some animals, such as crustaceans and mollusks, use hemocyanin to carry oxygen, instead of hemoglobin. Insects and some mollusks use a fluid called hemolymph instead of blood, the difference being that hemolymph is not contained in a closed circulatory system. In most insects, this ""blood"" does not contain oxygen-carrying molecules such as hemoglobin because their bodies are small enough for their tracheal system to suffice for supplying oxygen. Jawed vertebrates have an adaptive immune system, based largely on white blood cells. White blood cells help to resist infections and parasites. Platelets are important in the clotting of blood. Arthropods, using hemolymph, have hemocytes as part of their immune system. Blood is circulated around the body through blood vessels by the pumping action of the heart. In animals with lungs, arterial blood carries oxygen from inhaled air to the tissues of the body, and venous blood carries carbon dioxide, a waste product of metabolism produced by cells, from the tissues to the lungs to be exhaled. Medical terms related to blood often begin with hemo-, hemato-, haemo- or haemato- from the Greek word αἷμα (haima) for ""blood"". In terms of anatomy and histology, blood is considered a specialized form of connective tissue, given its origin in the bones and the presence of potential molecular fibers in the form of fibrinogen.  Functions  Blood performs many important functions within the body, including: Supply of oxygen to tissues (bound to hemoglobin, which is carried in red cells) Supply of nutrients such as glucose, amino acids, and fatty acids (dissolved in the blood or bound to plasma proteins (e.g., blood lipids)) Removal of waste such as carbon dioxide, urea, and lactic acid Immunological functions, including circulation of white blood cells, and detection of foreign material by antibodies Coagulation, the response to a broken blood vessel, the conversion of blood from a liquid to a semisolid gel to stop bleeding Messenger functions, including the transport of hormones and the signaling of tissue damage Regulation of core body temperature Hydraulic functions  Constituents   In mammals  Blood accounts for 7% of the human body weight, with an average density around 1060 kg/m3, very close to pure water's density of 1000 kg/m3. The average adult has a blood volume of roughly 5 litres (11 US pt) or 1.3 gallons, which is composed of plasma and formed elements. The formed elements are the two types of blood cell or corpuscle – the red blood cells, (erythrocytes) and white blood cells (leukocytes), and the cell fragments called platelets that are involved in clotting. By volume, the red blood cells constitute about 45% of whole blood, the plasma about 54.3%, and white cells about 0.7%. Whole blood (plasma and cells) exhibits non-Newtonian fluid dynamics.  Cells  One microliter of blood contains: 4.7 to 6.1 million (male), 4.2 to 5.4 million (female) erythrocytes: Red blood cells contain the blood's hemoglobin and distribute oxygen. Mature red blood cells lack a nucleus and organelles in mammals. The red blood cells (together with endothelial vessel cells and other cells) are also marked by glycoproteins that define the different blood types. The proportion of blood occupied by red blood cells is referred to as the hematocrit, and is normally about 45%. The combined surface area of all red blood cells of the human body would be roughly 2,000 times as great as the body's exterior surface. 4,000–11,000 leukocytes: White blood cells are part of the body's immune system; they destroy and remove old or aberrant cells and cellular debris, as well as attack infectious agents (pathogens) and foreign substances. The cancer of leukocytes is called leukemia. 200,000–500,000 thrombocytes: Also called platelets, they take part in blood clotting (coagulation). Fibrin from the coagulation cascade creates a mesh over the platelet plug.  Plasma  About 55% of blood is blood plasma, a fluid that is the blood's liquid medium, which by itself is straw-yellow in color. The blood plasma volume totals of 2.7–3.0 liters (2.8–3.2 quarts) in an average human. It is essentially an aqueous solution containing 92% water, 8% blood plasma proteins, and trace amounts of other materials. Plasma circulates dissolved nutrients, such as glucose, amino acids, and fatty acids (dissolved in the blood or bound to plasma proteins), and removes waste products, such as carbon dioxide, urea, and lactic acid. Other important components include: Serum albumin Blood-clotting factors (to facilitate coagulation) Immunoglobulins (antibodies) lipoprotein particles Various other proteins Various electrolytes (mainly sodium and chloride)The term serum refers to plasma from which the clotting proteins have been removed. Most of the proteins remaining are albumin and immunoglobulins.  pH values  Blood pH is regulated to stay within the narrow range of 7.35 to 7.45, making it slightly basic (compensation). Extra-cellular fluid in blood that has a pH below 7.35 is too acidic, whereas blood pH above 7.45 is too basic. A pH below 6.9 or above 7.8 is usually lethal. Blood pH, partial pressure of oxygen (pO2), partial pressure of carbon dioxide (pCO2), and bicarbonate (HCO3−) are carefully regulated by a number of homeostatic mechanisms, which exert their influence principally through the respiratory system and the urinary system to control the acid–base balance and respiration, which is called compensation. An arterial blood gas test measures these. Plasma also circulates hormones transmitting their messages to various tissues. The list of normal reference ranges for various blood electrolytes is extensive.  In non-mammalian vertebrates  Human blood is typical of that of mammals, although the precise details concerning cell numbers, size, protein structure, and so on, vary somewhat between species. In non-mammalian vertebrates, however, there are some key differences: Red blood cells of non-mammalian vertebrates are flattened and ovoid in form, and retain their cell nuclei. There is considerable variation in the types and proportions of white blood cells; for example, acidophils are generally more common than in humans. Platelets are unique to mammals; in other vertebrates, small nucleated, spindle cells called thrombocytes are responsible for blood clotting instead.  Physiology   Circulatory system  Blood is circulated around the body through blood vessels by the pumping action of the heart. In humans, blood is pumped from the strong left ventricle of the heart through arteries to peripheral tissues and returns to the right atrium of the heart through veins. It then enters the right ventricle and is pumped through the pulmonary artery to the lungs and returns to the left atrium through the pulmonary veins. Blood then enters the left ventricle to be circulated again. Arterial blood carries oxygen from inhaled air to all of the cells of the body, and venous blood carries carbon dioxide, a waste product of metabolism by cells, to the lungs to be exhaled. However, one exception includes pulmonary arteries, which contain the most deoxygenated blood in the body, while the pulmonary veins contain oxygenated blood. Additional return flow may be generated by the movement of skeletal muscles, which can compress veins and push blood through the valves in veins toward the right atrium. The blood circulation was famously described by William Harvey in 1628.  Cell production and degradation  In vertebrates, the various cells of blood are made in the bone marrow in a process called hematopoiesis, which includes erythropoiesis, the production of red blood cells; and myelopoiesis, the production of white blood cells and platelets. During childhood, almost every human bone produces red blood cells; as adults, red blood cell production is limited to the larger bones: the bodies of the vertebrae, the breastbone (sternum), the ribcage, the pelvic bones, and the bones of the upper arms and legs. In addition, during childhood, the thymus gland, found in the mediastinum, is an important source of T lymphocytes. The proteinaceous component of blood (including clotting proteins) is produced predominantly by the liver, while hormones are produced by the endocrine glands and the watery fraction is regulated by the hypothalamus and maintained by the kidney. Healthy erythrocytes have a plasma life of about 120 days before they are degraded by the spleen, and the Kupffer cells in the liver. The liver also clears some proteins, lipids, and amino acids. The kidney actively secretes waste products into the urine.  Oxygen transport  About 98.5% of the oxygen in a sample of arterial blood in a healthy human breathing air at sea-level pressure is chemically combined with the hemoglobin. About 1.5% is physically dissolved in the other blood liquids and not connected to hemoglobin. The hemoglobin molecule is the primary transporter of oxygen in mammals and many other species (for exceptions, see below). Hemoglobin has an oxygen binding capacity between 1.36 and 1.40 ml O2 per gram hemoglobin, which increases the total blood oxygen capacity seventyfold, compared to if oxygen solely were carried by its solubility of 0.03 ml O2 per liter blood per mm Hg partial pressure of oxygen (about 100 mm Hg in arteries).With the exception of pulmonary and umbilical arteries and their corresponding veins, arteries carry oxygenated blood away from the heart and deliver it to the body via arterioles and capillaries, where the oxygen is consumed; afterwards, venules and veins carry deoxygenated blood back to the heart. Under normal conditions in adult humans at rest, hemoglobin in blood leaving the lungs is about 98–99% saturated with oxygen, achieving an oxygen delivery between 950 and 1150 ml/min to the body. In a healthy adult at rest, oxygen consumption is approximately 200–250 ml/min, and deoxygenated blood returning to the lungs is still roughly 75% (70 to 78%) saturated. Increased oxygen consumption during sustained exercise reduces the oxygen saturation of venous blood, which can reach less than 15% in a trained athlete; although breathing rate and blood flow increase to compensate, oxygen saturation in arterial blood can drop to 95% or less under these conditions. Oxygen saturation this low is considered dangerous in an individual at rest (for instance, during surgery under anesthesia). Sustained hypoxia (oxygenation less than 90%), is dangerous to health, and severe hypoxia (saturations less than 30%) may be rapidly fatal.A fetus, receiving oxygen via the placenta, is exposed to much lower oxygen pressures (about 21% of the level found in an adult's lungs), so fetuses produce another form of hemoglobin with a much higher affinity for oxygen (hemoglobin F) to function under these conditions.  Carbon dioxide transport  CO2 is carried in blood in three different ways. (The exact percentages vary depending whether it is arterial or venous blood). Most of it (about 70%) is converted to bicarbonate ions HCO−3 by the enzyme carbonic anhydrase in the red blood cells by the reaction CO2 + H2O → H2CO3 → H+ + HCO−3; about 7% is dissolved in the plasma; and about 23% is bound to hemoglobin as carbamino compounds.Hemoglobin, the main oxygen-carrying molecule in red blood cells, carries both oxygen and carbon dioxide. However, the CO2 bound to hemoglobin does not bind to the same site as oxygen. Instead, it combines with the N-terminal groups on the four globin chains. However, because of allosteric effects on the hemoglobin molecule, the binding of CO2 decreases the amount of oxygen that is bound for a given partial pressure of oxygen. The decreased binding to carbon dioxide in the blood due to increased oxygen levels is known as the Haldane effect, and is important in the transport of carbon dioxide from the tissues to the lungs. A rise in the partial pressure of CO2 or a lower pH will cause offloading of oxygen from hemoglobin, which is known as the Bohr effect.  Transport of hydrogen ions  Some oxyhemoglobin loses oxygen and becomes deoxyhemoglobin. Deoxyhemoglobin binds most of the hydrogen ions as it has a much greater affinity for more hydrogen than does oxyhemoglobin.  Lymphatic system  In mammals, blood is in equilibrium with lymph, which is continuously formed in tissues from blood by capillary ultrafiltration. Lymph is collected by a system of small lymphatic vessels and directed to the thoracic duct, which drains into the left subclavian vein, where lymph rejoins the systemic blood circulation.  Thermoregulation  Blood circulation transports heat throughout the body, and adjustments to this flow are an important part of thermoregulation. Increasing blood flow to the surface (e.g., during warm weather or strenuous exercise) causes warmer skin, resulting in faster heat loss. In contrast, when the external temperature is low, blood flow to the extremities and surface of the skin is reduced and to prevent heat loss and is circulated to the important organs of the body, preferentially.  Rate of flow  Rate of blood flow varies greatly between different organs. Liver has the most abundant blood supply with an approximate flow of 1350 ml/min. Kidney and brain are the second and the third most supplied organs, with 1100 ml/min and ~700 ml/min, respectively.Relative rates of blood flow per 100 g of tissue are different, with kidney, adrenal gland and thyroid being the first, second and third most supplied tissues, respectively.  Hydraulic functions  The restriction of blood flow can also be used in specialized tissues to cause engorgement, resulting in an erection of that tissue; examples are the erectile tissue in the penis and clitoris. Another example of a hydraulic function is the jumping spider, in which blood forced into the legs under pressure causes them to straighten for a powerful jump, without the need for bulky muscular legs.  Invertebrates  In insects, the blood (more properly called hemolymph) is not involved in the transport of oxygen. (Openings called tracheae allow oxygen from the air to diffuse directly to the tissues.) Insect blood moves nutrients to the tissues and removes waste products in an open system. Other invertebrates use respiratory proteins to increase the oxygen-carrying capacity. Hemoglobin is the most common respiratory protein found in nature. Hemocyanin (blue) contains copper and is found in crustaceans and mollusks. It is thought that tunicates (sea squirts) might use vanabins (proteins containing vanadium) for respiratory pigment (bright-green, blue, or orange). In many invertebrates, these oxygen-carrying proteins are freely soluble in the blood; in vertebrates they are contained in specialized red blood cells, allowing for a higher concentration of respiratory pigments without increasing viscosity or damaging blood filtering organs like the kidneys. Giant tube worms have unusual hemoglobins that allow them to live in extraordinary environments. These hemoglobins also carry sulfides normally fatal in other animals.  Color  The coloring matter of blood (hemochrome) is largely due to the protein in the blood responsible for oxygen transport. Different groups of organisms use different proteins.  Hemoglobin  Hemoglobin is the principal determinant of the color of blood in vertebrates. Each molecule has four heme groups, and their interaction with various molecules alters the exact color. In vertebrates and other hemoglobin-using creatures, arterial blood and capillary blood are bright red, as oxygen imparts a strong red color to the heme group. Deoxygenated blood is a darker shade of red; this is present in veins, and can be seen during blood donation and when venous blood samples are taken. This is because the spectrum of light absorbed by hemoglobin differs between the oxygenated and deoxygenated states.Blood in carbon monoxide poisoning is bright red, because carbon monoxide causes the formation of carboxyhemoglobin. In cyanide poisoning, the body cannot use oxygen, so the venous blood remains oxygenated, increasing the redness. There are some conditions affecting the heme groups present in hemoglobin that can make the skin appear blue – a symptom called cyanosis. If the heme is oxidized, methemoglobin, which is more brownish and cannot transport oxygen, is formed. In the rare condition sulfhemoglobinemia, arterial hemoglobin is partially oxygenated, and appears dark red with a bluish hue. Veins close to the surface of the skin appear blue for a variety of reasons. However, the factors that contribute to this alteration of color perception are related to the light-scattering properties of the skin and the processing of visual input by the visual cortex, rather than the actual color of the venous blood.Skinks in the genus Prasinohaema have green blood due to a buildup of the waste product biliverdin.  Hemocyanin  The blood of most mollusks – including cephalopods and gastropods – as well as some arthropods, such as horseshoe crabs, is blue, as it contains the copper-containing protein hemocyanin at concentrations of about 50 grams per liter. Hemocyanin is colorless when deoxygenated and dark blue when oxygenated. The blood in the circulation of these creatures, which generally live in cold environments with low oxygen tensions, is grey-white to pale yellow, and it turns dark blue when exposed to the oxygen in the air, as seen when they bleed. This is due to change in color of hemocyanin when it is oxidized. Hemocyanin carries oxygen in extracellular fluid, which is in contrast to the intracellular oxygen transport in mammals by hemoglobin in RBCs.  Chlorocruorin  The blood of most annelid worms and some marine polychaetes use chlorocruorin to transport oxygen. It is green in color in dilute solutions.  Hemerythrin  Hemerythrin is used for oxygen transport in the marine invertebrates sipunculids, priapulids, brachiopods, and the annelid worm, magelona. Hemerythrin is violet-pink when oxygenated.  Hemovanadin  The blood of some species of ascidians and tunicates, also known as sea squirts, contains proteins called vanadins. These proteins are based on vanadium, and give the creatures a concentration of vanadium in their bodies 100 times higher than the surrounding seawater. Unlike hemocyanin and hemoglobin, hemovanadin is not an oxygen carrier. When exposed to oxygen, however, vanadins turn a mustard yellow.  Disorders   General medical  Disorders of volume Injury can cause blood loss through bleeding. A healthy adult can lose almost 20% of blood volume (1 L) before the first symptom, restlessness, begins, and 40% of volume (2 L) before shock sets in. Thrombocytes are important for blood coagulation and the formation of blood clots, which can stop bleeding. Trauma to the internal organs or bones can cause internal bleeding, which can sometimes be severe. Dehydration can reduce the blood volume by reducing the water content of the blood. This would rarely result in shock (apart from the very severe cases) but may result in orthostatic hypotension and fainting. Disorders of circulation Shock is the ineffective perfusion of tissues, and can be caused by a variety of conditions including blood loss, infection, poor cardiac output. Atherosclerosis reduces the flow of blood through arteries, because atheroma lines arteries and narrows them. Atheroma tends to increase with age, and its progression can be compounded by many causes including smoking, high blood pressure, excess circulating lipids (hyperlipidemia), and diabetes mellitus. Coagulation can form a thrombosis, which can obstruct vessels. Problems with blood composition, the pumping action of the heart, or narrowing of blood vessels can have many consequences including hypoxia (lack of oxygen) of the tissues supplied. The term ischemia refers to tissue that is inadequately perfused with blood, and infarction refers to tissue death (necrosis), which can occur when the blood supply has been blocked (or is very inadequate).  Hematological  Anemia Insufficient red cell mass (anemia) can be the result of bleeding, blood disorders like thalassemia, or nutritional deficiencies, and may require one or more blood transfusions. Anemia can also be due to a genetic disorder in which the red blood cells do not function effectively. Anemia can be confirmed by a blood test if the hemoglobin value is less than 13.5 gm/dl in men or less than 12.0 gm/dl in women. Several countries have blood banks to fill the demand for transfusable blood. A person receiving a blood transfusion must have a blood type compatible with that of the donor. Sickle-cell anemia Disorders of cell proliferation Leukemia is a group of cancers of the blood-forming tissues and cells. Non-cancerous overproduction of red cells (polycythemia vera) or platelets (essential thrombocytosis) may be premalignant. Myelodysplastic syndromes involve ineffective production of one or more cell lines. Disorders of coagulation Hemophilia is a genetic illness that causes dysfunction in one of the blood's clotting mechanisms. This can allow otherwise inconsequential wounds to be life-threatening, but more commonly results in hemarthrosis, or bleeding into joint spaces, which can be crippling. Ineffective or insufficient platelets can also result in coagulopathy (bleeding disorders). Hypercoagulable state (thrombophilia) results from defects in regulation of platelet or clotting factor function, and can cause thrombosis. Infectious disorders of blood Blood is an important vector of infection. HIV, the virus that causes AIDS, is transmitted through contact with blood, semen or other body secretions of an infected person. Hepatitis B and C are transmitted primarily through blood contact. Owing to blood-borne infections, bloodstained objects are treated as a biohazard. Bacterial infection of the blood is bacteremia or sepsis. Viral Infection is viremia. Malaria and trypanosomiasis are blood-borne parasitic infections.  Carbon monoxide poisoning  Substances other than oxygen can bind to hemoglobin; in some cases, this can cause irreversible damage to the body. Carbon monoxide, for example, is extremely dangerous when carried to the blood via the lungs by inhalation, because carbon monoxide irreversibly binds to hemoglobin to form carboxyhemoglobin, so that less hemoglobin is free to bind oxygen, and fewer oxygen molecules can be transported throughout the blood. This can cause suffocation insidiously. A fire burning in an enclosed room with poor ventilation presents a very dangerous hazard, since it can create a build-up of carbon monoxide in the air. Some carbon monoxide binds to hemoglobin when smoking tobacco.  Treatments   Transfusion  Blood for transfusion is obtained from human donors by blood donation and stored in a blood bank. There are many different blood types in humans, the ABO blood group system, and the Rhesus blood group system being the most important. Transfusion of blood of an incompatible blood group may cause severe, often fatal, complications, so crossmatching is done to ensure that a compatible blood product is transfused. Other blood products administered intravenously are platelets, blood plasma, cryoprecipitate, and specific coagulation factor concentrates.  Intravenous administration  Many forms of medication (from antibiotics to chemotherapy) are administered intravenously, as they are not readily or adequately absorbed by the digestive tract. After severe acute blood loss, liquid preparations, generically known as plasma expanders, can be given intravenously, either solutions of salts (NaCl, KCl, CaCl2 etc.) at physiological concentrations, or colloidal solutions, such as dextrans, human serum albumin, or fresh frozen plasma. In these emergency situations, a plasma expander is a more effective life-saving procedure than a blood transfusion, because the metabolism of transfused red blood cells does not restart immediately after a transfusion.  Letting  In modern evidence-based medicine, bloodletting is used in management of a few rare diseases, including hemochromatosis and polycythemia. However, bloodletting and leeching were common unvalidated interventions used until the 19th century, as many diseases were incorrectly thought to be due to an excess of blood, according to Hippocratic medicine.  Etymology  English blood (Old English blod) derives from Germanic and has cognates with a similar range of meanings in all other Germanic languages (e.g. German Blut, Swedish blod, Gothic blōþ). There is no accepted Indo-European etymology.  History   Classical Greek medicine  Robin Fåhræus (a Swedish physician who devised the erythrocyte sedimentation rate) suggested that the Ancient Greek system of humorism, wherein the body was thought to contain four distinct bodily fluids (associated with different temperaments), were based upon the observation of blood clotting in a transparent container. When blood is drawn in a glass container and left undisturbed for about an hour, four different layers can be seen. A dark clot forms at the bottom (the ""black bile""). Above the clot is a layer of red blood cells (the ""blood""). Above this is a whitish layer of white blood cells (the ""phlegm""). The top layer is clear yellow serum (the ""yellow bile"").  Types  The ABO blood group system was discovered in the year 1900 by Karl Landsteiner. Jan Janský is credited with the first classification of blood into the four types (A, B, AB, and O) in 1907, which remains in use today. In 1907 the first blood transfusion was performed that used the ABO system to predict compatibility. The first non-direct transfusion was performed on 27 March 1914. The Rhesus factor was discovered in 1937.  Culture and religion  Due to its importance to life, blood is associated with a large number of beliefs. One of the most basic is the use of blood as a symbol for family relationships through birth/parentage; to be ""related by blood"" is to be related by ancestry or descendence, rather than marriage. This bears closely to bloodlines, and sayings such as ""blood is thicker than water"" and ""bad blood"", as well as ""Blood brother"". Blood is given particular emphasis in the Islamic, Jewish, and Christian religions, because Leviticus 17:11 says ""the life of a creature is in the blood."" This phrase is part of the Levitical law forbidding the drinking of blood or eating meat with the blood still intact instead of being poured off. Mythic references to blood can sometimes be connected to the life-giving nature of blood, seen in such events as childbirth, as contrasted with the blood of injury or death.  Indigenous Australians  In many indigenous Australian Aboriginal peoples' traditions, ochre (particularly red) and blood, both high in iron content and considered Maban, are applied to the bodies of dancers for ritual. As Lawlor states: In many Aboriginal rituals and ceremonies, red ochre is rubbed all over the naked bodies of the dancers. In secret, sacred male ceremonies, blood extracted from the veins of the participant's arms is exchanged and rubbed on their bodies. Red ochre is used in similar ways in less-secret ceremonies. Blood is also used to fasten the feathers of birds onto people's bodies. Bird feathers contain a protein that is highly magnetically sensitive. Lawlor comments that blood employed in this fashion is held by these peoples to attune the dancers to the invisible energetic realm of the Dreamtime. Lawlor then connects these invisible energetic realms and magnetic fields, because iron is magnetic.  European paganism  Among the Germanic tribes, blood was used during their sacrifices; the Blóts. The blood was considered to have the power of its originator, and, after the butchering, the blood was sprinkled on the walls, on the statues of the gods, and on the participants themselves. This act of sprinkling blood was called blóedsian in Old English, and the terminology was borrowed by the Roman Catholic Church becoming to bless and blessing. The Hittite word for blood, ishar was a cognate to words for ""oath"" and ""bond"", see Ishara. The Ancient Greeks believed that the blood of the gods, ichor, was a substance that was poisonous to mortals. As a relic of Germanic Law, the cruentation, an ordeal where the corpse of the victim was supposed to start bleeding in the presence of the murderer, was used until the early 17th century.  Christianity  In Genesis 9:4, God prohibited Noah and his sons from eating blood (see Noahide Law). This command continued to be observed by the Eastern Orthodox Church. It is also found in the Bible that when the Angel of Death came around to the Hebrew house that the first-born child would not die if the angel saw lamb's blood wiped across the doorway. At the Council of Jerusalem, the apostles prohibited certain Christians from consuming blood – this is documented in Acts 15:20 and 29. This chapter specifies a reason (especially in verses 19–21): It was to avoid offending Jews who had become Christians, because the Mosaic Law Code prohibited the practice. Christ's blood is the means for the atonement of sins. Also, ""... the blood of Jesus Christ his [God] Son cleanseth us from all sin."" (1 John 1:7), ""... Unto him [God] that loved us, and washed us from our sins in his own blood."" (Revelation 1:5), and ""And they overcame him (Satan) by the blood of the Lamb [Jesus the Christ], and by the word of their testimony ..."" (Revelation 12:11). Some Christian churches, including Roman Catholicism, Eastern Orthodoxy, Oriental Orthodoxy, and the Assyrian Church of the East teach that, when consecrated, the Eucharistic wine actually becomes the blood of Jesus for worshippers to drink. Thus in the consecrated wine, Jesus becomes spiritually and physically present. This teaching is rooted in the Last Supper, as written in the four gospels of the Bible, in which Jesus stated to his disciples that the bread that they ate was his body, and the wine was his blood. ""This cup is the new testament in my blood, which is shed for you."" (Luke 22:20). Most forms of Protestantism, especially those of a Methodist or Presbyterian lineage, teach that the wine is no more than a symbol of the blood of Christ, who is spiritually but not physically present. Lutheran theology teaches that the body and blood is present together ""in, with, and under"" the bread and wine of the Eucharistic feast.  Judaism  In Judaism, animal blood may not be consumed even in the smallest quantity (Leviticus 3:17 and elsewhere); this is reflected in Jewish dietary laws (Kashrut). Blood is purged from meat by rinsing and soaking in water (to loosen clots), salting and then rinsing with water again several times. Eggs must also be checked and any blood spots removed before consumption. Although blood from fish is biblically kosher, it is rabbinically forbidden to consume fish blood to avoid the appearance of breaking the Biblical prohibition.Another ritual involving blood involves the covering of the blood of fowl and game after slaughtering (Leviticus 17:13); the reason given by the Torah is: ""Because the life of the animal is [in] its blood"" (ibid 17:14). In relation to human beings, Kabbalah expounds on this verse that the animal soul of a person is in the blood, and that physical desires stem from it. Likewise, the mystical reason for salting temple sacrifices and slaughtered meat is to remove the blood of animal-like passions from the person. By removing the animal's blood, the animal energies and life-force contained in the blood are removed, making the meat fit for human consumption.  Islam  Consumption of food containing blood is forbidden by Islamic dietary laws. This is derived from the statement in the Qur'an, sura Al-Ma'ida (5:3): ""Forbidden to you (for food) are: dead meat, blood, the flesh of swine, and that on which has been invoked the name of other than Allah."" Blood is considered unclean, hence there are specific methods to obtain physical and ritual status of cleanliness once bleeding has occurred. Specific rules and prohibitions apply to menstruation, postnatal bleeding and irregular vaginal bleeding. When an animal has been slaughtered, the animal's neck is cut in a way to ensure that the spine is not severed, hence the brain may send commands to the heart to pump blood to it for oxygen. In this way, blood is removed from the body, and the meat is generally now safe to cook and eat. In modern times, blood transfusions are generally not considered against the rules.  Jehovah's Witnesses  Based on their interpretation of scriptures such as Acts 15:28, 29 (""Keep abstaining...from blood.""), many Jehovah's Witnesses neither consume blood nor accept transfusions of whole blood or its major components: red blood cells, white blood cells, platelets (thrombocytes), and plasma. Members may personally decide whether they will accept medical procedures that involve their own blood or substances that are further fractionated from the four major components.  Vampirism  Vampires are mythical creatures that drink blood directly for sustenance, usually with a preference for human blood. Cultures all over the world have myths of this kind; for example the 'Nosferatu' legend, a human who achieves damnation and immortality by drinking the blood of others, originates from Eastern European folklore. Ticks, leeches, female mosquitoes, vampire bats, and an assortment of other natural creatures do consume the blood of other animals, but only bats are associated with vampires. This has no relation to vampire bats, which are New World creatures discovered well after the origins of the European myths.  Other uses   Forensic and archaeological  Blood residue can help forensic investigators identify weapons, reconstruct a criminal action, and link suspects to the crime. Through bloodstain pattern analysis, forensic information can also be gained from the spatial distribution of bloodstains. Blood residue analysis is also a technique used in archeology.  Artistic  Blood is one of the body fluids that has been used in art. In particular, the performances of Viennese Actionist Hermann Nitsch, Istvan Kantor, Franko B, Lennie Lee, Ron Athey, Yang Zhichao, Lucas Abela and Kira O'Reilly, along with the photography of Andres Serrano, have incorporated blood as a prominent visual element. Marc Quinn has made sculptures using frozen blood, including a cast of his own head made using his own blood.  Genealogical  The term blood is used in genealogical circles to refer to one's ancestry, origins, and ethnic background as in the word bloodline. Other terms where blood is used in a family history sense are blue-blood, royal blood, mixed-blood and blood relative.  See also   References   External links  Blood Groups and Red Cell Antigens. Free online book at NCBI Bookshelf ID: NBK2261 Blood on In Our Time at the BBC Blood Photomicrographs","Blood is a liquid in humans and many animals. Blood is pushed through the organism by the heart. It brings nutrients and oxygen to the tissues of the body. It also takes away waste and carbon dioxide from tissues.Blood is made up of blood plasma and various cells. These include red blood cells, white blood cells and platelets. Platelets help blood to clot. Hemoglobin is in red blood cells. White blood cells help fight infections and heal wounds.  Plasma  Blood plasma is the yellow liquid in which blood cells float. Plasma is made up of nutrients, electrolytes (salts), gases, non-protein hormones, waste, lipids, and proteins. These proteins are albumin, antibodies (also called immunoglobulins), clotting factors, and protein hormones. Plasma that does not have the protein fibrinogen is called serum and cannot clot. Adults have about 3 liters of plasma. Plasma is a liquid, mostly water (90%). Plasma takes up 55% of blood volume.  Red blood cells  Another name for red blood cell is erythrocyte. 'Erythro' means red; 'cyte' means cell. RBC is an acronym for red blood cell. RBCs carry oxygen and carbon dioxide around the body. Cells in the body need oxygen to live. Cells also make carbon dioxide as a waste. RBCs are filled with hemoglobin. This is a protein. It is made to carry a large amount of oxygen. Hemoglobin has iron in it. The iron and oxygen gives hemoglobin its red color. Erythropoietin promotes the creation of RBCs. Blood type antigens are carried on the surface of red cells. RBCs also help the blood stay at a normal pH. The blood needs to be at a pH of 7.4. If it is much more or less than 7.4, a person can get very sick or die. RBCs stops changes in blood pH. The proteins and the carbon dioxide in the RBC do this.  White blood cells  White blood cells are a big part of the immune system. They attack things that do not belong in the body. They kill germs such as bacteria and viruses. They kill cancer cells. White blood cells also help to fight other toxic substances. White blood cells find where the germs are, and start to destroy them. WBCs arrive in the blood. They also go out of the blood in places where there is infection. WBCs do this to fight the germs that make the infection. If they go out of the blood to fight an infection, they may return in the lymphatic system. So WBCs are in lymph nodes. Another name for white blood cell is leukocyte. Leuko means white. -cyte means cell. WBC is an acronym for white blood cell. There are three main kinds of WBCs. They are lymphocytes, granulocytes and monocytes. Some of the WBCs mature into cells which do similar work in the tissues. The different WBCs work in different ways. Some WBCs kill and eat germs and cancer cells. Some WBCs make antibodies. These are proteins that stick to a cell and tell other WBCs to kill it. Some WBCs make chemicals. They release these chemicals to fight things that do not belong in the body. These chemicals cause inflammation in a part of the body. When a germ makes someone sick, the body shows it. If a bacteria gets under someone's skin and causes an infection, the skin gets red, hot, and painful. This redness, heat, and pain are signs of inflammation. This shows that WBCs are fighting the infection and killing the bacteria.  Platelets  Platelets help make blood clot. A clot is when the liquid blood becomes solid. The body makes blood clot when the skin is cut. This stops blood from going out of the skin too much. For blood to be able to clot is essential. But, rarely, some blood clots are bad. If a blood clot happens in a blood vessel going to the brain, it can cause a stroke. If it happens in a blood vessel going to the heart, it can cause a heart attack. This does not usually happen to young, healthy people with the exception of clotting conditions. Platelets are not the only things that make clots. There are proteins in the blood that help make clots. Both platelets and clotting proteins are needed to make good clots.  Where blood comes from  Blood cells are made in the bone marrow. The spleen (a smaller, vital organ situated inside the ribcage) manages the amount of white blood cells that flow throughout your blood, it also can manage many functions of the liver. The bone marrow is the soft material in the middle of bones. Special cells in the bone marrow make most of the blood cells in the body. Plasma proteins are made mostly by the liver. The water and electrolytes in plasma come from the food and water that a person eats. Although blood is a fluid, in some respects it is a kind of connective tissue. Its cells originate in bone marrow and the spleen, and in the blood there are potential molecular fibres in the form of fibrinogen. These are activated when a blood clot forms.  References "
"Carbon dioxide (chemical formula CO2) is a chemical compound made up of molecules that each have one carbon atom covalently double bonded to two oxygen atoms. It is found in the gas state at room temperature, and as the source of available carbon in the carbon cycle, atmospheric CO2 is the primary carbon source for life on Earth. In the air, carbon dioxide is transparent to visible light but absorbs infrared radiation, acting as a greenhouse gas. Carbon dioxide is soluble in water and is found in groundwater, lakes, ice caps, and seawater. When carbon dioxide dissolves in water, it forms carbonate and mainly bicarbonate (HCO−3), which causes ocean acidification as atmospheric CO2 levels increase.It is a trace gas in Earth's atmosphere at 421 parts per million (ppm), or about 0.04% by volume (as of May 2022), having risen from pre-industrial levels of 280 ppm. Burning fossil fuels is the primary cause of these increased CO2 concentrations and also the primary cause of climate change.Its concentration in Earth's pre-industrial atmosphere since late in the Precambrian has been regulated by organisms and geological phenomena. Plants, algae and cyanobacteria use energy from sunlight to synthesize carbohydrates from carbon dioxide and water in a process called photosynthesis, which produces oxygen as a waste product. In turn, oxygen is consumed and CO2 is released as waste by all aerobic organisms when they metabolize organic compounds to produce energy by respiration. CO2 is released from organic materials when they decay or combust, such as in forest fires. Since plants require CO2 for photosynthesis, and humans and animals depend on plants for food, CO2 is necessary for the survival of life on earth. Carbon dioxide is 53% more dense than dry air, but is long lived and thoroughly mixes in the atmosphere. About half of excess CO2 emissions to the atmosphere are absorbed by land and ocean carbon sinks. These sinks can become saturated and are volatile, as decay and wildfires result in the CO2 being released back into the atmosphere. CO2 is eventually sequestered (stored for the long term) in rocks and organic deposits like coal, petroleum and natural gas. Sequestered CO2 is released into the atmosphere through burning fossil fuels or naturally by volcanoes, hot springs, geysers, and when carbonate rocks dissolve in water or react with acids. CO2 is a versatile industrial material, used, for example, as an inert gas in welding and fire extinguishers, as a pressurizing gas in air guns and oil recovery, and as a supercritical fluid solvent in decaffeination of coffee and supercritical drying. It is a byproduct of fermentation of sugars in bread, beer and wine making, and is added to carbonated beverages like seltzer and beer for effervescence. It has a sharp and acidic odor and generates the taste of soda water in the mouth, but at normally encountered concentrations it is odorless.  Chemical and physical properties   Structure, bonding and molecular vibrations  The symmetry of a carbon dioxide molecule is linear and centrosymmetric at its equilibrium geometry. The length of the carbon-oxygen bond in carbon dioxide is 116.3 pm, noticeably shorter than the roughly 140-pm length of a typical single C–O bond, and shorter than most other C–O multiply bonded functional groups such as carbonyls. Since it is centrosymmetric, the molecule has no electric dipole moment. As a linear triatomic molecule, CO2 has four vibrational modes as shown in the diagram. In the symmetric and the antisymmetric stretching modes, the atoms move along the axis of the molecule. There are two bending modes, which are degenerate, meaning that they have the same frequency and same energy, because of the symmetry of the molecule. When a molecule touches a surface or touches another molecule, the two bending modes can differ in frequency because the interaction is different for the two modes. Some of the vibrational modes are observed in the infrared (IR) spectrum: the antisymmetric stretching mode at wavenumber 2349 cm−1 (wavelength 4.25 μm) and the degenerate pair of bending modes at 667 cm−1 (wavelength 15 μm). The symmetric stretching mode does not create an electric dipole so is not observed in IR spectroscopy, but it is detected in by Raman spectroscopy at 1388 cm−1 (wavelength 7.2 μm).In the gas phase, carbon dioxide molecules undergo significant vibrational motions and do not keep a fixed structure. However, in a Coulomb explosion imaging experiment, an instantaneous image of the molecular structure can be deduced. Such an experiment has been performed for carbon dioxide. The result of this experiment, and the conclusion of theoretical calculations based on an ab initio potential energy surface of the molecule, is that none of the molecules in the gas phase are ever exactly linear. This counter-intuitive result is trivially due to the fact that the nuclear motion volume element vanishes for linear geometries. This is so for all molecules (except diatomics!).  In aqueous solution  Carbon dioxide is soluble in water, in which it reversibly forms H2CO3 (carbonic acid), which is a weak acid since its ionization in water is incomplete. CO 2 + H 2 O ↽ − − ⇀ H 2 CO 3 {displaystyle {ce {CO2 + H2O <> H2CO3}}} The hydration equilibrium constant of carbonic acid is, at 25 °C: K h  [ H 2 CO 3 ] [ CO 2 ( aq ) ]  1.70 × 10 − 3 {displaystyle K_{mathrm {h} }{frac {{ce {[H2CO3]}}}{{ce {[CO2_{(aq)}]}}}}1.70times 10^{-3}} Hence, the majority of the carbon dioxide is not converted into carbonic acid, but remains as CO2 molecules, not affecting the pH. The relative concentrations of CO2, H2CO3, and the deprotonated forms HCO−3 (bicarbonate) and CO2−3(carbonate) depend on the pH. As shown in a Bjerrum plot, in neutral or slightly alkaline water (pH > 6.5), the bicarbonate form predominates (>50%) becoming the most prevalent (>95%) at the pH of seawater. In very alkaline water (pH > 10.4), the predominant (>50%) form is carbonate. The oceans, being mildly alkaline with typical pH  8.2–8.5, contain about 120 mg of bicarbonate per liter. Being diprotic, carbonic acid has two acid dissociation constants, the first one for the dissociation into the bicarbonate (also called hydrogen carbonate) ion (HCO−3): H 2 CO 3 ↽ − − ⇀ HCO 3 − + H + {displaystyle {ce {H2CO3 <> HCO3- + H+}}} Ka1  2.5×10−4 mol/L; pKa1  3.6 at 25 °C.This is the true first acid dissociation constant, defined as K a 1  [ HCO 3 − ] [ H + ] [ H 2 CO 3 ] {displaystyle K_{mathrm {a1} }{frac {{ce {[HCO3- ][H+]}}}{{ce {[H2CO3]}}}}} where the denominator includes only covalently bound H2CO3 and does not include hydrated CO2(aq). The much smaller and often-quoted value near 4.16×10−7 is an apparent value calculated on the (incorrect) assumption that all dissolved CO2 is present as carbonic acid, so that K a 1 ( a p p a r e n t )  [ HCO 3 − ] [ H + ] [ H 2 CO 3 ] + [ CO 2 ( aq ) ] {displaystyle K_{mathrm {a1} }{rm {(apparent)}}{frac {{ce {[HCO3- ][H+]}}}{{ce {[H2CO3] + [CO2_{(aq)}]}}}}} Since most of the dissolved CO2 remains as CO2 molecules, Ka1(apparent) has a much larger denominator and a much smaller value than the true Ka1.The bicarbonate ion is an amphoteric species that can act as an acid or as a base, depending on pH of the solution. At high pH, it dissociates significantly into the carbonate ion (CO2−3): HCO 3 − ↽ − − ⇀ CO 3 2 − + H + {displaystyle {ce {HCO3- <> CO3^2- + H+}}} Ka2  4.69×10−11 mol/L; pKa2  10.329In organisms, carbonic acid production is catalysed by the enzyme known as carbonic anhydrase.  Chemical reactions of CO2  CO2 is a potent electrophile having an electrophilic reactivity that is comparable to benzaldehyde or strong α,β-unsaturated carbonyl compounds. However, unlike electrophiles of similar reactivity, the reactions of nucleophiles with CO2 are thermodynamically less favored and are often found to be highly reversible. The reversible reaction of carbon dioxide with amines to make carbamates is used in CO2 scrubbers and has been suggested as a possible starting point for carbon capture and storage by amine gas treating. Only very strong nucleophiles, like the carbanions provided by Grignard reagents and organolithium compounds react with CO2 to give carboxylates: MR + CO 2 ⟶ RCO 2 M {displaystyle {ce {MR + CO2 -> RCO2M}}} where M  Li or Mg Br and R  alkyl or aryl.In metal carbon dioxide complexes, CO2 serves as a ligand, which can facilitate the conversion of CO2 to other chemicals.The reduction of CO2 to CO is ordinarily a difficult and slow reaction: CO 2 + 2 e − + 2 H + ⟶ CO + H 2 O {displaystyle {ce {CO2 + 2 e- + 2H+ -> CO + H2O}}} Photoautotrophs (i.e. plants and cyanobacteria) use the energy contained in sunlight to photosynthesize simple sugars from CO2 absorbed from the air and water: n CO 2 + n H 2 O ⟶ ( CH 2 O ) n + n O 2 {displaystyle {ce {{mathit {n}}CO2{}+{mathit {n}}H2O->(CH2O)_{mathit {n}}{}+{mathit {n}}O2}}} The redox potential for this reaction near pH 7 is about −0.53 V versus the standard hydrogen electrode. The nickel-containing enzyme carbon monoxide dehydrogenase catalyses this process.  Physical properties  Carbon dioxide is colorless. At low concentrations, the gas is odorless; however, at sufficiently high concentrations, it has a sharp, acidic odor. At standard temperature and pressure, the density of carbon dioxide is around 1.98 kg/m3, about 1.53 times that of air.Carbon dioxide has no liquid state at pressures below 0.51795(10) MPa (5.11177(99) atm). At a pressure of 1 atm (0.101325 MPa), the gas deposits directly to a solid at temperatures below 194.6855(30) K (−78.4645(30) °C) and the solid sublimes directly to a gas above this temperature. In its solid state, carbon dioxide is commonly called dry ice. Liquid carbon dioxide forms only at pressures above 0.51795(10) MPa (5.11177(99) atm); the triple point of carbon dioxide is 216.592(3) K (−56.558(3) °C) at 0.51795(10) MPa (5.11177(99) atm) (see phase diagram). The critical point is 304.128(15) K (30.978(15) °C) at 7.3773(30) MPa (72.808(30) atm). Another form of solid carbon dioxide observed at high pressure is an amorphous glass-like solid. This form of glass, called carbonia, is produced by supercooling heated CO2 at extreme pressures (40–48 GPa, or about 400,000 atmospheres) in a diamond anvil. This discovery confirmed the theory that carbon dioxide could exist in a glass state similar to other members of its elemental family, like silicon dioxide (silica glass) and germanium dioxide. Unlike silica and germania glasses, however, carbonia glass is not stable at normal pressures and reverts to gas when pressure is released. At temperatures and pressures above the critical point, carbon dioxide behaves as a supercritical fluid known as supercritical carbon dioxide. Table of thermal and physical properties of saturated liquid carbon dioxide: Table of thermal and physical properties of carbon dioxide (CO2) at atmospheric pressure:  Biological role  Carbon dioxide is an end product of cellular respiration in organisms that obtain energy by breaking down sugars, fats and amino acids with oxygen as part of their metabolism. This includes all plants, algae and animals and aerobic fungi and bacteria. In vertebrates, the carbon dioxide travels in the blood from the body's tissues to the skin (e.g., amphibians) or the gills (e.g., fish), from where it dissolves in the water, or to the lungs from where it is exhaled. During active photosynthesis, plants can absorb more carbon dioxide from the atmosphere than they release in respiration.  Photosynthesis and carbon fixation  Carbon fixation is a biochemical process by which atmospheric carbon dioxide is incorporated by plants, algae and (cyanobacteria) into energy-rich organic molecules such as glucose, thus creating their own food by photosynthesis. Photosynthesis uses carbon dioxide and water to produce sugars from which other organic compounds can be constructed, and oxygen is produced as a by-product. Ribulose-1,5-bisphosphate carboxylase oxygenase, commonly abbreviated to RuBisCO, is the enzyme involved in the first major step of carbon fixation, the production of two molecules of 3-phosphoglycerate from CO2 and ribulose bisphosphate, as shown in the diagram at left. RuBisCO is thought to be the single most abundant protein on Earth. Phototrophs use the products of their photosynthesis as internal food sources and as raw material for the biosynthesis of more complex organic molecules, such as polysaccharides, nucleic acids, and proteins. These are used for their own growth, and also as the basis of the food chains and webs that feed other organisms, including animals such as ourselves. Some important phototrophs, the coccolithophores synthesise hard calcium carbonate scales. A globally significant species of coccolithophore is Emiliania huxleyi whose calcite scales have formed the basis of many sedimentary rocks such as limestone, where what was previously atmospheric carbon can remain fixed for geological timescales. Plants can grow as much as 50% faster in concentrations of 1,000 ppm CO2 when compared with ambient conditions, though this assumes no change in climate and no limitation on other nutrients. Elevated CO2 levels cause increased growth reflected in the harvestable yield of crops, with wheat, rice and soybean all showing increases in yield of 12–14% under elevated CO2 in FACE experiments.Increased atmospheric CO2 concentrations result in fewer stomata developing on plants which leads to reduced water usage and increased water-use efficiency. Studies using FACE have shown that CO2 enrichment leads to decreased concentrations of micronutrients in crop plants. This may have knock-on effects on other parts of ecosystems as herbivores will need to eat more food to gain the same amount of protein.The concentration of secondary metabolites such as phenylpropanoids and flavonoids can also be altered in plants exposed to high concentrations of CO2.Plants also emit CO2 during respiration, and so the majority of plants and algae, which use C3 photosynthesis, are only net absorbers during the day. Though a growing forest will absorb many tons of CO2 each year, a mature forest will produce as much CO2 from respiration and decomposition of dead specimens (e.g., fallen branches) as is used in photosynthesis in growing plants. Contrary to the long-standing view that they are carbon neutral, mature forests can continue to accumulate carbon and remain valuable carbon sinks, helping to maintain the carbon balance of Earth's atmosphere. Additionally, and crucially to life on earth, photosynthesis by phytoplankton consumes dissolved CO2 in the upper ocean and thereby promotes the absorption of CO2 from the atmosphere.  Toxicity  Carbon dioxide content in fresh air (averaged between sea-level and 10 kPa level, i.e., about 30 km (19 mi) altitude) varies between 0.036% (360 ppm) and 0.041% (412 ppm), depending on the location.CO2 is an asphyxiant gas and not classified as toxic or harmful in accordance with Globally Harmonized System of Classification and Labelling of Chemicals standards of United Nations Economic Commission for Europe by using the OECD Guidelines for the Testing of Chemicals. In concentrations up to 1% (10,000 ppm), it will make some people feel drowsy and give the lungs a stuffy feeling. Concentrations of 7% to 10% (70,000 to 100,000 ppm) may cause suffocation, even in the presence of sufficient oxygen, manifesting as dizziness, headache, visual and hearing dysfunction, and unconsciousness within a few minutes to an hour. The physiological effects of acute carbon dioxide exposure are grouped together under the term hypercapnia, a subset of asphyxiation. Because it is heavier than air, in locations where the gas seeps from the ground (due to sub-surface volcanic or geothermal activity) in relatively high concentrations, without the dispersing effects of wind, it can collect in sheltered/pocketed locations below average ground level, causing animals located therein to be suffocated. Carrion feeders attracted to the carcasses are then also killed. Children have been killed in the same way near the city of Goma by CO2 emissions from the nearby volcano Mount Nyiragongo. The Swahili term for this phenomenon is mazuku. Adaptation to increased concentrations of CO2 occurs in humans, including modified breathing and kidney bicarbonate production, in order to balance the effects of blood acidification (acidosis). Several studies suggested that 2.0 percent inspired concentrations could be used for closed air spaces (e.g. a submarine) since the adaptation is physiological and reversible, as deterioration in performance or in normal physical activity does not happen at this level of exposure for five days. Yet, other studies show a decrease in cognitive function even at much lower levels. Also, with ongoing respiratory acidosis, adaptation or compensatory mechanisms will be unable to reverse such condition.  Below 1%  There are few studies of the health effects of long-term continuous CO2 exposure on humans and animals at levels below 1%. Occupational CO2 exposure limits have been set in the United States at 0.5% (5000 ppm) for an eight-hour period. At this CO2 concentration, International Space Station crew experienced headaches, lethargy, mental slowness, emotional irritation, and sleep disruption. Studies in animals at 0.5% CO2 have demonstrated kidney calcification and bone loss after eight weeks of exposure. A study of humans exposed in 2.5 hour sessions demonstrated significant negative effects on cognitive abilities at concentrations as low as 0.1% (1000 ppm) CO2 likely due to CO2 induced increases in cerebral blood flow. Another study observed a decline in basic activity level and information usage at 1000 ppm, when compared to 500 ppm. However a review of the literature found that most studies on the phenomenon of carbon dioxide induced cognitive impairment to have a small effect on high-level decision making and most of the studies were confounded by inadequate study designs, environmental comfort, uncertainties in exposure doses and differing cognitive assessments used. Similarly a study on the effects of the concentration of CO2 in motorcycle helmets has been criticized for having dubious methodology in not noting the self-reports of motorcycle riders and taking measurements using mannequins. Further when normal motorcycle conditions were achieved (such as highway or city speeds) or the visor was raised the concentration of CO2 declined to safe levels (0.2%).  Ventilation  Poor ventilation is one of the main causes of excessive CO2 concentrations in closed spaces, leading to poor indoor air quality. Carbon dioxide differential above outdoor concentrations at steady state conditions (when the occupancy and ventilation system operation are sufficiently long that CO2 concentration has stabilized) are sometimes used to estimate ventilation rates per person. Higher CO2 concentrations are associated with occupant health, comfort and performance degradation. ASHRAE Standard 62.1–2007 ventilation rates may result in indoor concentrations up to 2,100 ppm above ambient outdoor conditions. Thus if the outdoor concentration is 400 ppm, indoor concentrations may reach 2,500 ppm with ventilation rates that meet this industry consensus standard. Concentrations in poorly ventilated spaces can be found even higher than this (range of 3,000 or 4,000 ppm). Miners, who are particularly vulnerable to gas exposure due to insufficient ventilation, referred to mixtures of carbon dioxide and nitrogen as ""blackdamp"", ""choke damp"" or ""stythe"". Before more effective technologies were developed, miners would frequently monitor for dangerous levels of blackdamp and other gases in mine shafts by bringing a caged canary with them as they worked. The canary is more sensitive to asphyxiant gases than humans, and as it became unconscious would stop singing and fall off its perch. The Davy lamp could also detect high levels of blackdamp (which sinks, and collects near the floor) by burning less brightly, while methane, another suffocating gas and explosion risk, would make the lamp burn more brightly. In February 2020, three people died from suffocation at a party in Moscow when dry ice (frozen CO2) was added to a swimming pool to cool it down. A similar accident occurred in 2018 when a woman died from CO2 fumes emanating from the large amount of dry ice she was transporting in her car.  Outdoor areas with elevated concentrations  Local concentrations of carbon dioxide can reach high values near strong sources, especially those that are isolated by surrounding terrain. At the Bossoleto hot spring near Rapolano Terme in Tuscany, Italy, situated in a bowl-shaped depression about 100 m (330 ft) in diameter, concentrations of CO2 rise to above 75% overnight, sufficient to kill insects and small animals. After sunrise the gas is dispersed by convection. High concentrations of CO2 produced by disturbance of deep lake water saturated with CO2 are thought to have caused 37 fatalities at Lake Monoun, Cameroon in 1984 and 1700 casualties at Lake Nyos, Cameroon in 1986.  Human physiology   Content  The body produces approximately 2.3 pounds (1.0 kg) of carbon dioxide per day per person, containing 0.63 pounds (290 g) of carbon. In humans, this carbon dioxide is carried through the venous system and is breathed out through the lungs, resulting in lower concentrations in the arteries. The carbon dioxide content of the blood is often given as the partial pressure, which is the pressure which carbon dioxide would have had if it alone occupied the volume. In humans, the blood carbon dioxide contents is shown in the adjacent table.  Transport in the blood  CO2 is carried in blood in three different ways. (Exact percentages vary between arterial and venous blood). Majority (about 70% to 80%) is converted to bicarbonate ions HCO−3 by the enzyme carbonic anhydrase in the red blood cells, by the reaction CO2 + H2O → H2CO3 → H+ + HCO−3. 5–10% is dissolved in blood plasma 5–10% is bound to hemoglobin as carbamino compoundsHemoglobin, the main oxygen-carrying molecule in red blood cells, carries both oxygen and carbon dioxide. However, the CO2 bound to hemoglobin does not bind to the same site as oxygen. Instead, it combines with the N-terminal groups on the four globin chains. However, because of allosteric effects on the hemoglobin molecule, the binding of CO2 decreases the amount of oxygen that is bound for a given partial pressure of oxygen. This is known as the Haldane Effect, and is important in the transport of carbon dioxide from the tissues to the lungs. Conversely, a rise in the partial pressure of CO2 or a lower pH will cause offloading of oxygen from hemoglobin, which is known as the Bohr effect.  Regulation of respiration  Carbon dioxide is one of the mediators of local autoregulation of blood supply. If its concentration is high, the capillaries expand to allow a greater blood flow to that tissue.Bicarbonate ions are crucial for regulating blood pH. A person's breathing rate influences the level of CO2 in their blood. Breathing that is too slow or shallow causes respiratory acidosis, while breathing that is too rapid leads to hyperventilation, which can cause respiratory alkalosis.Although the body requires oxygen for metabolism, low oxygen levels normally do not stimulate breathing. Rather, breathing is stimulated by higher carbon dioxide levels. As a result, breathing low-pressure air or a gas mixture with no oxygen at all (such as pure nitrogen) can lead to loss of consciousness without ever experiencing air hunger. This is especially perilous for high-altitude fighter pilots. It is also why flight attendants instruct passengers, in case of loss of cabin pressure, to apply the oxygen mask to themselves first before helping others; otherwise, one risks losing consciousness.The respiratory centers try to maintain an arterial CO2 pressure of 40 mm Hg. With intentional hyperventilation, the CO2 content of arterial blood may be lowered to 10–20 mm Hg (the oxygen content of the blood is little affected), and the respiratory drive is diminished. This is why one can hold one's breath longer after hyperventilating than without hyperventilating. This carries the risk that unconsciousness may result before the need to breathe becomes overwhelming, which is why hyperventilation is particularly dangerous before free diving.  Concentrations and role in the environment   Atmosphere   Oceans   Ocean acidification  Carbon dioxide dissolves in the ocean to form carbonic acid (H2CO3), bicarbonate (HCO−3), and carbonate (CO2−3). There is about fifty times as much carbon dioxide dissolved in the oceans as exists in the atmosphere. The oceans act as an enormous carbon sink, and have taken up about a third of CO2 emitted by human activity.  Hydrothermal vents  Carbon dioxide is also introduced into the oceans through hydrothermal vents. The Champagne hydrothermal vent, found at the Northwest Eifuku volcano in the Mariana Trench, produces almost pure liquid carbon dioxide, one of only two known sites in the world as of 2004, the other being in the Okinawa Trough. The finding of a submarine lake of liquid carbon dioxide in the Okinawa Trough was reported in 2006.  Production   Biological processes  Carbon dioxide is a by-product of the fermentation of sugar in the brewing of beer, whisky and other alcoholic beverages and in the production of bioethanol. Yeast metabolizes sugar to produce CO2 and ethanol, also known as alcohol, as follows: C 6 H 12 O 6 ⟶ 2 CO 2 + 2 C 2 H 5 OH {displaystyle {ce {C6H12O6 -> 2 CO2 + 2 C2H5OH}}} All aerobic organisms produce CO2 when they oxidize carbohydrates, fatty acids, and proteins. The large number of reactions involved are exceedingly complex and not described easily. Refer to (cellular respiration, anaerobic respiration and photosynthesis). The equation for the respiration of glucose and other monosaccharides is: C 6 H 12 O 6 + 6 O 2 ⟶ 6 CO 2 + 6 H 2 O {displaystyle {ce {C6H12O6 + 6 O2 -> 6 CO2 + 6 H2O}}} Anaerobic organisms decompose organic material producing methane and carbon dioxide together with traces of other compounds. Regardless of the type of organic material, the production of gases follows well defined kinetic pattern. Carbon dioxide comprises about 40–45% of the gas that emanates from decomposition in landfills (termed ""landfill gas""). Most of the remaining 50–55% is methane.  Industrial processes  Carbon dioxide can be obtained by distillation from air, but the method is inefficient. Industrially, carbon dioxide is predominantly an unrecovered waste product, produced by several methods which may be practiced at various scales.  Combustion  The combustion of all carbon-based fuels, such as methane (natural gas), petroleum distillates (gasoline, diesel, kerosene, propane), coal, wood and generic organic matter produces carbon dioxide and, except in the case of pure carbon, water. As an example, the chemical reaction between methane and oxygen: CH 4 + 2 O 2 ⟶ CO 2 + 2 H 2 O {displaystyle {ce {CH4 + 2 O2-> CO2 + 2 H2O}}} Iron is reduced from its oxides with coke in a blast furnace, producing pig iron and carbon dioxide: Fe 2 O 3 + 3 CO ⟶ 3 CO 2 + 2 Fe {displaystyle {ce {Fe2O3 + 3 CO -> 3 CO2 + 2 Fe}}}  By-product from hydrogen production  Carbon dioxide is a byproduct of the industrial production of hydrogen by steam reforming and the water gas shift reaction in ammonia production. These processes begin with the reaction of water and natural gas (mainly methane). This is a major source of food-grade carbon dioxide for use in carbonation of beer and soft drinks, and is also used for stunning animals such as poultry. In the summer of 2018 a shortage of carbon dioxide for these purposes arose in Europe due to the temporary shut-down of several ammonia plants for maintenance.  Thermal decomposition of limestone  It is produced by thermal decomposition of limestone, CaCO3 by heating (calcining) at about 850 °C (1,560 °F), in the manufacture of quicklime (calcium oxide, CaO), a compound that has many industrial uses: CaCO 3 ⟶ CaO + CO 2 {displaystyle {ce {CaCO3 -> CaO + CO2}}} Acids liberate CO2 from most metal carbonates. Consequently, it may be obtained directly from natural carbon dioxide springs, where it is produced by the action of acidified water on limestone or dolomite. The reaction between hydrochloric acid and calcium carbonate (limestone or chalk) is shown below: CaCO 3 + 2 HCl ⟶ CaCl 2 + H 2 CO 3 {displaystyle {ce {CaCO3 + 2HCl -> CaCl2 + H2CO3}}} The carbonic acid (H2CO3) then decomposes to water and CO2: H 2 CO 3 ⟶ CO 2 + H 2 O {displaystyle {ce {H2CO3 -> CO2 + H2O}}} Such reactions are accompanied by foaming or bubbling, or both, as the gas is released. They have widespread uses in industry because they can be used to neutralize waste acid streams.  Commercial uses  Carbon dioxide is used by the food industry, the oil industry, and the chemical industry. The compound has varied commercial uses but one of its greatest uses as a chemical is in the production of carbonated beverages; it provides the sparkle in carbonated beverages such as soda water, beer and sparkling wine.  Precursor to chemicals  In the chemical industry, carbon dioxide is mainly consumed as an ingredient in the production of urea, with a smaller fraction being used to produce methanol and a range of other products. Some carboxylic acid derivatives such as sodium salicylate are prepared using CO2 by the Kolbe–Schmitt reaction.In addition to conventional processes using CO2 for chemical production, electrochemical methods are also being explored at a research level. In particular, the use of renewable energy for production of fuels from CO2 (such as methanol) is attractive as this could result in fuels that could be easily transported and used within conventional combustion technologies but have no net CO2 emissions.  Agriculture  Plants require carbon dioxide to conduct photosynthesis. The atmospheres of greenhouses may (if of large size, must) be enriched with additional CO2 to sustain and increase the rate of plant growth. At very high concentrations (100 times atmospheric concentration, or greater), carbon dioxide can be toxic to animal life, so raising the concentration to 10,000 ppm (1%) or higher for several hours will eliminate pests such as whiteflies and spider mites in a greenhouse.  Foods  Carbon dioxide is a food additive used as a propellant and acidity regulator in the food industry. It is approved for usage in the EU (listed as E number E290), US and Australia and New Zealand (listed by its INS number 290). A candy called Pop Rocks is pressurized with carbon dioxide gas at about 4,000 kPa (40 bar; 580 psi). When placed in the mouth, it dissolves (just like other hard candy) and releases the gas bubbles with an audible pop. Leavening agents cause dough to rise by producing carbon dioxide. Baker's yeast produces carbon dioxide by fermentation of sugars within the dough, while chemical leaveners such as baking powder and baking soda release carbon dioxide when heated or if exposed to acids.  Beverages  Carbon dioxide is used to produce carbonated soft drinks and soda water. Traditionally, the carbonation of beer and sparkling wine came about through natural fermentation, but many manufacturers carbonate these drinks with carbon dioxide recovered from the fermentation process. In the case of bottled and kegged beer, the most common method used is carbonation with recycled carbon dioxide. With the exception of British real ale, draught beer is usually transferred from kegs in a cold room or cellar to dispensing taps on the bar using pressurized carbon dioxide, sometimes mixed with nitrogen. The taste of soda water (and related taste sensations in other carbonated beverages) is an effect of the dissolved carbon dioxide rather than the bursting bubbles of the gas. Carbonic anhydrase 4 converts to carbonic acid leading to a sour taste, and also the dissolved carbon dioxide induces a somatosensory response.  Winemaking  Carbon dioxide in the form of dry ice is often used during the cold soak phase in winemaking to cool clusters of grapes quickly after picking to help prevent spontaneous fermentation by wild yeast. The main advantage of using dry ice over water ice is that it cools the grapes without adding any additional water that might decrease the sugar concentration in the grape must, and thus the alcohol concentration in the finished wine. Carbon dioxide is also used to create a hypoxic environment for carbonic maceration, the process used to produce Beaujolais wine. Carbon dioxide is sometimes used to top up wine bottles or other storage vessels such as barrels to prevent oxidation, though it has the problem that it can dissolve into the wine, making a previously still wine slightly fizzy. For this reason, other gases such as nitrogen or argon are preferred for this process by professional wine makers.  Stunning animals  Carbon dioxide is often used to ""stun"" animals before slaughter. ""Stunning"" may be a misnomer, as the animals are not knocked out immediately and may suffer distress.  Inert gas  Carbon dioxide is one of the most commonly used compressed gases for pneumatic (pressurized gas) systems in portable pressure tools. Carbon dioxide is also used as an atmosphere for welding, although in the welding arc, it reacts to oxidize most metals. Use in the automotive industry is common despite significant evidence that welds made in carbon dioxide are more brittle than those made in more inert atmospheres. When used for MIG welding, CO2 use is sometimes referred to as MAG welding, for Metal Active Gas, as CO2 can react at these high temperatures. It tends to produce a hotter puddle than truly inert atmospheres, improving the flow characteristics. Although, this may be due to atmospheric reactions occurring at the puddle site. This is usually the opposite of the desired effect when welding, as it tends to embrittle the site, but may not be a problem for general mild steel welding, where ultimate ductility is not a major concern. Carbon dioxide is used in many consumer products that require pressurized gas because it is inexpensive and nonflammable, and because it undergoes a phase transition from gas to liquid at room temperature at an attainable pressure of approximately 60 bar (870 psi; 59 atm), allowing far more carbon dioxide to fit in a given container than otherwise would. Life jackets often contain canisters of pressured carbon dioxide for quick inflation. Aluminium capsules of CO2 are also sold as supplies of compressed gas for air guns, paintball markers/guns, inflating bicycle tires, and for making carbonated water. High concentrations of carbon dioxide can also be used to kill pests. Liquid carbon dioxide is used in supercritical drying of some food products and technological materials, in the preparation of specimens for scanning electron microscopy and in the decaffeination of coffee beans.  Fire extinguisher  Carbon dioxide can be used to extinguish flames by flooding the environment around the flame with the gas. It does not itself react to extinguish the flame, but starves the flame of oxygen by displacing it. Some fire extinguishers, especially those designed for electrical fires, contain liquid carbon dioxide under pressure. Carbon dioxide extinguishers work well on small flammable liquid and electrical fires, but not on ordinary combustible fires, because they do not cool the burning substances significantly, and when the carbon dioxide disperses, they can catch fire upon exposure to atmospheric oxygen. They are mainly used in server rooms.Carbon dioxide has also been widely used as an extinguishing agent in fixed fire-protection systems for local application of specific hazards and total flooding of a protected space. International Maritime Organization standards recognize carbon-dioxide systems for fire protection of ship holds and engine rooms. Carbon-dioxide-based fire-protection systems have been linked to several deaths, because it can cause suffocation in sufficiently high concentrations. A review of CO2 systems identified 51 incidents between 1975 and the date of the report (2000), causing 72 deaths and 145 injuries.  Supercritical CO2 as solvent  Liquid carbon dioxide is a good solvent for many lipophilic organic compounds and is used to remove caffeine from coffee. Carbon dioxide has attracted attention in the pharmaceutical and other chemical processing industries as a less toxic alternative to more traditional solvents such as organochlorides. It is also used by some dry cleaners for this reason. It is used in the preparation of some aerogels because of the properties of supercritical carbon dioxide.  Medical and pharmacological uses  In medicine, up to 5% carbon dioxide (130 times atmospheric concentration) is added to oxygen for stimulation of breathing after apnea and to stabilize the O2/CO2 balance in blood. Carbon dioxide can be mixed with up to 50% oxygen, forming an inhalable gas; this is known as Carbogen and has a variety of medical and research uses. Another medical use are the mofette, dry spas that use carbon dioxide from post-volcanic discharge for therapeutic purposes.  Energy  Supercritical CO2 is used as the working fluid in the Allam power cycle engine.  Fossil fuel recovery  Carbon dioxide is used in enhanced oil recovery where it is injected into or adjacent to producing oil wells, usually under supercritical conditions, when it becomes miscible with the oil. This approach can increase original oil recovery by reducing residual oil saturation by 7–23% additional to primary extraction. It acts as both a pressurizing agent and, when dissolved into the underground crude oil, significantly reduces its viscosity, and changing surface chemistry enabling the oil to flow more rapidly through the reservoir to the removal well. In mature oil fields, extensive pipe networks are used to carry the carbon dioxide to the injection points. In enhanced coal bed methane recovery, carbon dioxide would be pumped into the coal seam to displace methane, as opposed to current methods which primarily rely on the removal of water (to reduce pressure) to make the coal seam release its trapped methane.  Bio transformation into fuel  It has been proposed that CO2 from power generation be bubbled into ponds to stimulate growth of algae that could then be converted into biodiesel fuel. A strain of the cyanobacterium Synechococcus elongatus has been genetically engineered to produce the fuels isobutyraldehyde and isobutanol from CO2 using photosynthesis.Researchers have developed a process called electrolysis, using enzymes isolated from bacteria to power the chemical reactions which convert CO2 into fuels.  Refrigerant  Liquid and solid carbon dioxide are important refrigerants, especially in the food industry, where they are employed during the transportation and storage of ice cream and other frozen foods. Solid carbon dioxide is called ""dry ice"" and is used for small shipments where refrigeration equipment is not practical. Solid carbon dioxide is always below −78.5 °C (−109.3 °F) at regular atmospheric pressure, regardless of the air temperature. Liquid carbon dioxide (industry nomenclature R744 or R-744) was used as a refrigerant prior to the use of dichlorodifluoromethane (R12, a chlorofluorocarbon (CFC) compound). CO2 might enjoy a renaissance because one of the main substitutes to CFCs, 1,1,1,2-tetrafluoroethane (R134a, a hydrofluorocarbon (HFC) compound) contributes to climate change more than CO2 does. CO2 physical properties are highly favorable for cooling, refrigeration, and heating purposes, having a high volumetric cooling capacity. Due to the need to operate at pressures of up to 130 bars (1,900 psi; 13,000 kPa), CO2 systems require highly mechanically resistant reservoirs and components that have already been developed for mass production in many sectors. In automobile air conditioning, in more than 90% of all driving conditions for latitudes higher than 50°, CO2 (R744) operates more efficiently than systems using HFCs (e.g., R134a). Its environmental advantages (GWP of 1, non-ozone depleting, non-toxic, non-flammable) could make it the future working fluid to replace current HFCs in cars, supermarkets, and heat pump water heaters, among others. Coca-Cola has fielded CO2-based beverage coolers and the U.S. Army is interested in CO2 refrigeration and heating technology.  Minor uses  Carbon dioxide is the lasing medium in a carbon-dioxide laser, which is one of the earliest type of lasers. Carbon dioxide can be used as a means of controlling the pH of swimming pools, by continuously adding gas to the water, thus keeping the pH from rising. Among the advantages of this is the avoidance of handling (more hazardous) acids. Similarly, it is also used in the maintaining reef aquaria, where it is commonly used in calcium reactors to temporarily lower the pH of water being passed over calcium carbonate in order to allow the calcium carbonate to dissolve into the water more freely, where it is used by some corals to build their skeleton. Used as the primary coolant in the British advanced gas-cooled reactor for nuclear power generation. Carbon dioxide induction is commonly used for the euthanasia of laboratory research animals. Methods to administer CO2 include placing animals directly into a closed, prefilled chamber containing CO2, or exposure to a gradually increasing concentration of CO2. The American Veterinary Medical Association's 2020 guidelines for carbon dioxide induction state that a displacement rate of 30–70% of the chamber or cage volume per minute is optimal for the humane euthanasia of small rodents.: 5, 31 Percentages of CO2 vary for different species, based on identified optimal percentages to minimize distress.: 22 Carbon dioxide is also used in several related cleaning and surface-preparation techniques.  History of discovery  Carbon dioxide was the first gas to be described as a discrete substance. In about 1640, the Flemish chemist Jan Baptist van Helmont observed that when he burned charcoal in a closed vessel, the mass of the resulting ash was much less than that of the original charcoal. His interpretation was that the rest of the charcoal had been transmuted into an invisible substance he termed a ""gas"" or ""wild spirit"" (spiritus sylvestris).The properties of carbon dioxide were further studied in the 1750s by the Scottish physician Joseph Black. He found that limestone (calcium carbonate) could be heated or treated with acids to yield a gas he called ""fixed air"". He observed that the fixed air was denser than air and supported neither flame nor animal life. Black also found that when bubbled through limewater (a saturated aqueous solution of calcium hydroxide), it would precipitate calcium carbonate. He used this phenomenon to illustrate that carbon dioxide is produced by animal respiration and microbial fermentation. In 1772, English chemist Joseph Priestley published a paper entitled Impregnating Water with Fixed Air in which he described a process of dripping sulfuric acid (or oil of vitriol as Priestley knew it) on chalk in order to produce carbon dioxide, and forcing the gas to dissolve by agitating a bowl of water in contact with the gas.Carbon dioxide was first liquefied (at elevated pressures) in 1823 by Humphry Davy and Michael Faraday. The earliest description of solid carbon dioxide (dry ice) was given by the French inventor Adrien-Jean-Pierre Thilorier, who in 1835 opened a pressurized container of liquid carbon dioxide, only to find that the cooling produced by the rapid evaporation of the liquid yielded a ""snow"" of solid CO2.Carbon dioxide in combination with nitrogen was known from earlier times as Blackdamp, stythe or choke damp, Along with the other types of damp it was encountered in mining operations and well sinking. Slow oxidation of coal and biological processes replaced the oxygen to create a suffocating mixture of nitrogen and carbon dioxide.  See also   References   External links  Current global map of carbon dioxide concentration CDC – NIOSH Pocket Guide to Chemical Hazards – Carbon Dioxide Trends in Atmospheric Carbon Dioxide (NOAA)","Carbon dioxide (CO2) is a chemical compound and is acidic. It is a gas at room temperature. It is made of one carbon and two oxygen atoms. People and most animals release carbon dioxide when they breathe out. Also, every time something organic is burnt (or a fire is made), it makes carbon dioxide. Plants use carbon dioxide to make food. This process is called photosynthesis. The properties of carbon dioxide were studied by the Scottish scientist Joseph Black in the 1750s. Carbon dioxide is a greenhouse gas. Greenhouse gases trap heat energy. Greenhouse gases change the climate and weather on our planet, Earth. This is called climate change. Greenhouse gases are a cause of global warming, the rise of Earth surface temperature. Its concentration in Earth's atmosphere since late in the Precambrian was regulated by photosynthetic organisms and geological phenomena (mainly volcanos).  Biological role  Carbon dioxide is an end product in organisms that obtain energy from breaking down sugars, fats and amino acids with oxygen as part of their metabolism. This is a process known as cellular respiration. This includes most animals, many fungi and some bacteria. In higher animals, the carbon dioxide travels in the blood from the body's tissues to the lungs where it is breathed out. Plants take in carbon dioxide from the atmosphere to use in photosynthesis.  Dry ice  Dry ice, or solid carbon dioxide, is the solid state of CO2 gas below -109.3 °F (-78.5°C). Dry ice does not occur naturally on earth but is man made. It is colorless. People use dry ice to make things cold, and to make drinks fizzy, kill gophers, and freeze warts. The vapor of dry ice causes suffocation and eventually, death. Caution and professional assistance is recommended whenever dry ice is in use. At usual pressure it will not melt from a solid to a liquid but instead changes directly from a solid to a gas. This is called sublimation. It will change directly from a solid to a gas at any temperature higher than extremely cold temperatures. Dry ice sublimates at normal air temperature. Dry ice exposed to normal air gives off carbon dioxide gas that has no color. Carbon dioxide can be liquified at pressure above 5.1 atmospheres. Carbon dioxide gas that comes off of dry ice is so cold that when it mixes with air it cools the water vapour in the air to fog, which looks like a thick white smoke. It is often used in the theater to create the appearance of fog or smoke.  Isolation and production  Chemists can get carbon dioxide from cooling air. They call this air distillation. This method is inefficient because a large amount of air must be refrigerated to extract a small amount of CO2. Chemists can also use several different chemical reactions to separate carbon dioxide. Carbon dioxide is made in the reactions between most acids and most metal carbonates. For example, the reaction between hydrochloric acid and calcium carbonate (limestone or chalk) makes carbon dioxide: 2 H C l + C a C O 3 ⟶ C a C l 2 + H 2 C O 3 {displaystyle mathrm {2 HCl+CaCO_{3}longrightarrow CaCl_{2}+H_{2}CO_{3}} } The carbonic acid (H2CO3) then decomposes to water and CO2. Such reactions cause foaming or bubbling, or both. In industry, such reactions are used many times to neutralize waste acid streams. Quicklime (CaO), a chemical that has widespread use, can be made heating limestone to about 850 °C. This reaction also makes CO2: C a C O 3 ⟶ C a O + C O 2 {displaystyle mathrm {CaCO_{3}longrightarrow CaO+CO_{2}} } Carbon dioxide is also made in the combustion of all carbon-containing fuels, such as methane (natural gas), petroleum distillates (gasoline, diesel, kerosene, propane), coal or wood. In most cases, water is also released. As an example the chemical reaction between methane and oxygen is: C H 4 + 2 O 2 ⟶ C O 2 + 2 H 2 O {displaystyle mathrm {CH_{4}+2 O_{2}longrightarrow CO_{2}+2 H_{2}O} } Carbon dioxide is made in steel mills. Iron is reduced from its oxides with coke in a blast furnace, producing pig iron and carbon dioxide: F e 2 O 3 + 3 C O ⟶ 2 F e + 3 C O 2 {displaystyle mathrm {Fe_{2}O_{3}+3 COlongrightarrow 2 Fe+3 CO_{2}} } Yeast metabolizes sugar to produce carbon dioxide and ethanol, also known as alcohol, in the production of wines, beers and other spirits, but also in the production of bioethanol: C 6 H 12 O 6 ⟶ 2 C O 2 + 2 C 2 H 5 O H {displaystyle mathrm {C_{6}H_{12}O_{6}longrightarrow 2 CO_{2}+2 C_{2}H_{5}OH} } All aerobic organisms produce CO2 when they oxidize carbohydrates, fatty acids, and proteins in the mitochondria of cells. The large number of reactions involved are exceedingly complex and not described easily. (They include cellular respiration, anaerobic respiration and photosynthesis). Photoautotrophs (i.e. plants, cyanobacteria) use another reaction: Plants absorb CO2 from the air, and, together with water, react it to form carbohydrates: n C O 2 + n H 2 O ⟶ ( C H 2 O ) n + n O 2 {displaystyle mathrm {nCO_{2}+nH_{2}Olongrightarrow (CH_{2}O)n+nO_{2}} } Carbon dioxide is soluble in water, in which it spontaneously interconverts between CO2 and H2CO3 (carbonic acid). The relative concentrations of CO2, H2CO3, and the deprotonated forms HCO−3 (bicarbonate) and CO2−3(carbonate) depend on the acidity (pH). In neutral or slightly alkaline water (pH > 6.5), the bicarbonate form predominates (>50%) becoming the most prevalent (>95%) at the pH of seawater, while in very alkaline water (pH > 10.4) the predominant (>50%) form is carbonate. The bicarbonate and carbonate forms are very soluble. So, air-equilibrated ocean water (mildly alkaline with typical pH  8.2–8.5) contains about 120 mg of bicarbonate per liter.  Industrial production  Industrial carbon dioxide is produced mainly from six processes: By capturing natural carbon dioxide springs where it is produced by the action of acidified water on limestone or dolomite. As a by-product of hydrogen production plants, where methane is converted to CO2; From combustion of fossil fuels or wood; As a by-product of fermentation of sugar in the brewing of beer, whisky and other alcoholic beverages; From thermal decomposition of limestone, CaCO3, in the making of lime (Calcium oxide, CaO);  Chemical reaction  Carbon dioxide can be created with a simple chemical reaction: C + O 2 ⟶ C O 2 {displaystyle mathrm {C+O_{2}longrightarrow CO_{2}} } carbon + oxygen → carbon dioxide  References "
"Hydrogen is the chemical element with the symbol H and atomic number 1. Hydrogen is the lightest element. At standard conditions hydrogen is a gas of diatomic molecules having the formula H2. It is colorless, odorless, tasteless, non-toxic, and highly combustible. Hydrogen is the most abundant chemical substance in the universe, constituting roughly 75% of all normal matter. Stars such as the Sun are mainly composed of hydrogen in the plasma state. Most of the hydrogen on Earth exists in molecular forms such as water and organic compounds. For the most common isotope of hydrogen (symbol 1H) each atom has one proton, one electron, and no neutrons. In the early universe, the formation of protons, the nuclei of hydrogen, occurred during the first second after the Big Bang. The emergence of neutral hydrogen atoms throughout the universe occurred about 370,000 years later during the recombination epoch, when the plasma had cooled enough for electrons to remain bound to protons.Hydrogen is nonmetallic (except it becomes metallic at extremely high pressures) and readily forms a single covalent bond with most nonmetallic elements, forming compounds such as water and nearly all organic compounds. Hydrogen plays a particularly important role in acid–base reactions because these reactions usually involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) where it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H+. The H+ cation is simply a proton (symbol p) but its behavior in aqueous solutions and in ionic compounds involves screening of its electric charge by nearby polar molecules or anions. Because hydrogen is the only neutral atom for which the Schrödinger equation can be solved analytically, the study of its energetics and chemical bonding has played a key role in the development of quantum mechanics. Hydrogen gas was first artificially produced in the early 16th century by the reaction of acids on metals. In 1766–1781, Henry Cavendish was the first to recognize that hydrogen gas was a discrete substance, and that it produces water when burned, the property for which it was later named: in Greek, hydrogen means ""water-former"". Industrial production is mainly from steam reforming of natural gas, oil reforming, or coal gasification. A small percentage is also produced using more energy-intensive methods such as the electrolysis of water. Most hydrogen is used near the site of its production, the two largest uses being fossil fuel processing (e.g., hydrocracking) and ammonia production. It can be burned to produce heat or combined with oxygen in fuel cells to generate electricity directly, with water being the only emissions at the point of usage. Hydrogen atoms may embrittle metals.  Properties   Combustion  Hydrogen gas (dihydrogen or molecular hydrogen) is highly flammable: 2 H2(g) + O2(g) → 2 H2O(l) (572 kJ/2 mol  286 kJ/mol  141.865 MJ/kg)The enthalpy of combustion is −286 kJ/mol.Hydrogen gas forms explosive mixtures with air in concentrations from 4–74% and with chlorine at 5–95%. The explosive reactions may be triggered by spark, heat, or sunlight. The hydrogen autoignition temperature, the temperature of spontaneous ignition in air, is 500 °C (932 °F).  Flame  Pure hydrogen-oxygen flames emit ultraviolet light and with high oxygen mix are nearly invisible to the naked eye, as illustrated by the faint plume of the Space Shuttle Main Engine, compared to the highly visible plume of a Space Shuttle Solid Rocket Booster, which uses an ammonium perchlorate composite. The detection of a burning hydrogen leak may require a flame detector; such leaks can be very dangerous. Hydrogen flames in other conditions are blue, resembling blue natural gas flames. The destruction of the Hindenburg airship was a notorious example of hydrogen combustion and the cause is still debated. The visible flames in the photographs were the result of carbon compounds in the airship skin burning.  Reactants  H2 is unreactive compared to diatomic elements such as halogens or oxygen. The thermodynamic basis of this low reactivity is the very strong H–H bond, with a bond dissociation energy of 435.7 kJ/mol. The kinetic basis of the low reactivity is the nonpolar nature of H2 and its weak polarizability. It spontaneously reacts with chlorine and fluorine to form hydrogen chloride and hydrogen fluoride, respectively. The reactivity of H2 is strongly affected by the presence of metal catalysts. Thus, while mixtures of H2 with O2 or air combust readily when heated to at least 500 °C by a spark or flame, they do not react at room temperature in the absence of a catalyst.  Electron energy levels  The ground state energy level of the electron in a hydrogen atom is −13.6 eV, which is equivalent to an ultraviolet photon of roughly 91 nm wavelength.The energy levels of hydrogen can be calculated fairly accurately using the Bohr model of the atom, which conceptualizes the electron as ""orbiting"" the proton in analogy to the Earth's orbit of the Sun. However, the atomic electron and proton are held together by electromagnetic force, while planets and celestial objects are held by gravity. Because of the discretization of angular momentum postulated in early quantum mechanics by Bohr, the electron in the Bohr model can only occupy certain allowed distances from the proton, and therefore only certain allowed energies.A more accurate description of the hydrogen atom comes from a purely quantum mechanical treatment that uses the Schrödinger equation, Dirac equation or Feynman path integral formulation to calculate the probability density of the electron around the proton. The most complicated treatments allow for the small effects of special relativity and vacuum polarization. In the quantum mechanical treatment, the electron in a ground state hydrogen atom has no angular momentum at all—illustrating how the ""planetary orbit"" differs from electron motion.  Spin isomers  Molecular H2 exists as two spin isomers, i.e. compounds that differ only in the spin states of their nuclei. In the orthohydrogen form, the spins of the two nuclei are parallel, forming a spin triplet state having a total molecular spin S  1 {displaystyle S1} ; in the parahydrogen form the spins are antiparallel and form a spin singlet state having spin S  0 {displaystyle S0} . The equilibrium ratio of ortho- to para-hydrogen depends on temperature. At room temperature or warmer, equilibrium hydrogen gas contains about 25% of the para form and 75% of the ortho form. The ortho form is an excited state, having higher energy than the para form by 1.455 kJ/mol, and it converts to the para form over the course of several minutes when cooled to low temperature. The thermal properties of the forms differ because they differ in their allowed rotational quantum states, resulting in different thermal properties such as the heat capacity.The ortho-to-para ratio in H2 is an important consideration in the liquefaction and storage of liquid hydrogen: the conversion from ortho to para is exothermic and produces enough heat to evaporate most of the liquid if not converted first to parahydrogen during the cooling process. Catalysts for the ortho-para interconversion, such as ferric oxide and activated carbon compounds, are used during hydrogen cooling to avoid this loss of liquid.  Phases  Gaseous hydrogen Liquid hydrogen Slush hydrogen Solid hydrogen Metallic hydrogen Plasma hydrogen  Compounds   Covalent and organic compounds  While H2 is not very reactive under standard conditions, it does form compounds with most elements. Hydrogen can form compounds with elements that are more electronegative, such as halogens (F, Cl, Br, I), or oxygen; in these compounds hydrogen takes on a partial positive charge. When bonded to a more electronegative element, particularly fluorine, oxygen, or nitrogen, hydrogen can participate in a form of medium-strength noncovalent bonding with another electronegative element with a lone pair, a phenomenon called hydrogen bonding that is critical to the stability of many biological molecules. Hydrogen also forms compounds with less electronegative elements, such as metals and metalloids, where it takes on a partial negative charge. These compounds are often known as hydrides.Hydrogen forms a vast array of compounds with carbon called the hydrocarbons, and an even vaster array with heteroatoms that, because of their general association with living things, are called organic compounds. The study of their properties is known as organic chemistry and their study in the context of living organisms is known as biochemistry. By some definitions, ""organic"" compounds are only required to contain carbon. However, most of them also contain hydrogen, and because it is the carbon-hydrogen bond that gives this class of compounds most of its particular chemical characteristics, carbon-hydrogen bonds are required in some definitions of the word ""organic"" in chemistry. Millions of hydrocarbons are known, and they are usually formed by complicated pathways that seldom involve elemental hydrogen. Hydrogen is highly soluble in many rare earth and transition metals and is soluble in both nanocrystalline and amorphous metals. Hydrogen solubility in metals is influenced by local distortions or impurities in the crystal lattice. These properties may be useful when hydrogen is purified by passage through hot palladium disks, but the gas's high solubility is a metallurgical problem, contributing to the embrittlement of many metals, complicating the design of pipelines and storage tanks.  Hydrides  Compounds of hydrogen are often called hydrides, a term that is used fairly loosely. The term ""hydride"" suggests that the H atom has acquired a negative or anionic character, denoted H−, and is used when hydrogen forms a compound with a more electropositive element. The existence of the hydride anion, suggested by Gilbert N. Lewis in 1916 for group 1 and 2 salt-like hydrides, was demonstrated by Moers in 1920 by the electrolysis of molten lithium hydride (LiH), producing a stoichiometric quantity of hydrogen at the anode. For hydrides other than group 1 and 2 metals, the term is quite misleading, considering the low electronegativity of hydrogen. An exception in group 2 hydrides is BeH2, which is polymeric. In lithium aluminium hydride, the [AlH4]− anion carries hydridic centers firmly attached to the Al(III). Although hydrides can be formed with almost all main-group elements, the number and combination of possible compounds varies widely; for example, more than 100 binary borane hydrides are known, but only one binary aluminium hydride. Binary indium hydride has not yet been identified, although larger complexes exist.In inorganic chemistry, hydrides can also serve as bridging ligands that link two metal centers in a coordination complex. This function is particularly common in group 13 elements, especially in boranes (boron hydrides) and aluminium complexes, as well as in clustered carboranes.  Protons and acids  Oxidation of hydrogen removes its electron and gives H+, which contains no electrons and a nucleus which is usually composed of one proton. That is why H+ is often called a proton. This species is central to discussion of acids. Under the Brønsted–Lowry acid–base theory, acids are proton donors, while bases are proton acceptors. A bare proton, H+, cannot exist in solution or in ionic crystals because of its unstoppable attraction to other atoms or molecules with electrons. Except at the high temperatures associated with plasmas, such protons cannot be removed from the electron clouds of atoms and molecules, and will remain attached to them. However, the term 'proton' is sometimes used loosely and metaphorically to refer to positively charged or cationic hydrogen attached to other species in this fashion, and as such is denoted ""H+"" without any implication that any single protons exist freely as a species. To avoid the implication of the naked ""solvated proton"" in solution, acidic aqueous solutions are sometimes considered to contain a less unlikely fictitious species, termed the ""hydronium ion"" ([H3O]+). However, even in this case, such solvated hydrogen cations are more realistically conceived as being organized into clusters that form species closer to [H9O4]+. Other oxonium ions are found when water is in acidic solution with other solvents.Although exotic on Earth, one of the most common ions in the universe is the H+3 ion, known as protonated molecular hydrogen or the trihydrogen cation.  Isotopes  Hydrogen has three naturally occurring isotopes, denoted 1H, 2H and 3H. Other, highly unstable nuclei (4H to 7H) have been synthesized in the laboratory but not observed in nature. 1H is the most common hydrogen isotope, with an abundance of more than 99.98%. Because the nucleus of this isotope consists of only a single proton, it is given the descriptive but rarely used formal name protium. It is unique among all stable isotopes in having no neutrons; see diproton for a discussion of why others do not exist. 2H, the other stable hydrogen isotope, is known as deuterium and contains one proton and one neutron in the nucleus. All deuterium in the universe is thought to have been produced at the time of the Big Bang, and has endured since that time. Deuterium is not radioactive, and does not represent a significant toxicity hazard. Water enriched in molecules that include deuterium instead of normal hydrogen is called heavy water. Deuterium and its compounds are used as a non-radioactive label in chemical experiments and in solvents for 1H-NMR spectroscopy. Heavy water is used as a neutron moderator and coolant for nuclear reactors. Deuterium is also a potential fuel for commercial nuclear fusion. 3H is known as tritium and contains one proton and two neutrons in its nucleus. It is radioactive, decaying into helium-3 through beta decay with a half-life of 12.32 years. It is so radioactive that it can be used in luminous paint, making it useful in such things as watches. The glass prevents the small amount of radiation from getting out. Small amounts of tritium are produced naturally by the interaction of cosmic rays with atmospheric gases; tritium has also been released during nuclear weapons tests. It is used in nuclear fusion reactions, as a tracer in isotope geochemistry, and in specialized self-powered lighting devices. Tritium has also been used in chemical and biological labeling experiments as a radiolabel.Unique among the elements, distinct names are assigned to its isotopes in common use today. During the early study of radioactivity, various heavy radioactive isotopes were given their own names, but such names are no longer used, except for deuterium and tritium. The symbols D and T (instead of 2H and 3H) are sometimes used for deuterium and tritium, but the symbol P is already in use for phosphorus and thus is not available for protium. In its nomenclatural guidelines, the International Union of Pure and Applied Chemistry (IUPAC) allows any of D, T, 2H, and 3H to be used, although 2H and 3H are preferred.The exotic atom muonium (symbol Mu), composed of an antimuon and an electron, can also be considered a light radioisotope of hydrogen. Because muons decay with lifetime 2.2 µs, muonium is too unstable to exhibit observable chemistry. Nevertheless, muonium compounds are important test cases for quantum simulation, due to the mass difference between the antimuon and the proton, and IUPAC nomenclature incorporates such hypothetical compounds as muonium chloride (MuCl) and sodium muonide (NaMu), analogous to hydrogen chloride and sodium hydride respectively.  Thermal and physical properties  Table of thermal and physical properties of hydrogen (H2) at atmospheric pressure:  History   Discovery and use  In 1671, Robert Boyle discovered and described the reaction between iron filings and dilute acids, which results in the production of hydrogen gas. Having provided a saline spirit [hydrochloric acid], which by an uncommon way of preparation was made exceeding sharp and piercing, we put into a vial, capable of containing three or four ounces of water, a convenient quantity of filings of steel, which were not such as are commonly sold in shops to Chymists and Apothecaries, (those being usually not free enough from rust) but such as I had a while before caus'd to be purposely fil'd off from a piece of good steel. This metalline powder being moistn'd in the viol with a little of the menstruum, was afterwards drench'd with more; whereupon the mixture grew very hot, and belch'd up copious and stinking fumes; which whether they consisted altogether of the volatile sulfur of the Mars [iron?], or of metalline steams participating of a sulfureous nature, and join'd with the saline exhalations of the menstruum, is not necessary to be here discuss'd. But whencesoever this stinking smoak proceeded, so inflammable it was, that upon the approach of a lighted candle to it, it would readily enough take fire, and burn with a blewish and somewhat greenish flame at the mouth of the viol for a good while together; and that, though with little light, yet with more strength than one would easily suspect. The word ""sulfureous"" may be somewhat confusing, especially since Boyle did a similar experiment with iron and sulfuric acid. However, in all likelihood, ""sulfureous"" should here be understood to mean combustible.In 1766, Henry Cavendish was the first to recognize hydrogen gas as a discrete substance, by naming the gas from a metal-acid reaction ""inflammable air"". He speculated that ""inflammable air"" was in fact identical to the hypothetical substance called ""phlogiston"" and further finding in 1781 that the gas produces water when burned. He is usually given credit for the discovery of hydrogen as an element. In 1783, Antoine Lavoisier gave the element the name hydrogen (from the Greek ὑδρο- hydro meaning ""water"" and -γενής genes meaning ""former"") when he and Laplace reproduced Cavendish's finding that water is produced when hydrogen is burned. Lavoisier produced hydrogen for his experiments on mass conservation by reacting a flux of steam with metallic iron through an incandescent iron tube heated in a fire. Anaerobic oxidation of iron by the protons of water at high temperature can be schematically represented by the set of following reactions: 1) Fe + H2O → FeO + H22) Fe + 3 H2O → Fe2O3 + 3 H23) Fe + 4 H2O → Fe3O4 + 4 H2Many metals such as zirconium undergo a similar reaction with water leading to the production of hydrogen. Hydrogen was liquefied for the first time by James Dewar in 1898 by using regenerative cooling and his invention, the vacuum flask. He produced solid hydrogen the next year. Deuterium was discovered in December 1931 by Harold Urey, and tritium was prepared in 1934 by Ernest Rutherford, Mark Oliphant, and Paul Harteck. Heavy water, which consists of deuterium in the place of regular hydrogen, was discovered by Urey's group in 1932. François Isaac de Rivaz built the first de Rivaz engine, an internal combustion engine powered by a mixture of hydrogen and oxygen in 1806. Edward Daniel Clarke invented the hydrogen gas blowpipe in 1819. The Döbereiner's lamp and limelight were invented in 1823.The first hydrogen-filled balloon was invented by Jacques Charles in 1783. Hydrogen provided the lift for the first reliable form of air-travel following the 1852 invention of the first hydrogen-lifted airship by Henri Giffard. German count Ferdinand von Zeppelin promoted the idea of rigid airships lifted by hydrogen that later were called Zeppelins; the first of which had its maiden flight in 1900. Regularly scheduled flights started in 1910 and by the outbreak of World War I in August 1914, they had carried 35,000 passengers without a serious incident. Hydrogen-lifted airships were used as observation platforms and bombers during the war. The first non-stop transatlantic crossing was made by the British airship R34 in 1919. Regular passenger service resumed in the 1920s and the discovery of helium reserves in the United States promised increased safety, but the U.S. government refused to sell the gas for this purpose. Therefore, H2 was used in the Hindenburg airship, which was destroyed in a midair fire over New Jersey on 6 May 1937. The incident was broadcast live on radio and filmed. Ignition of leaking hydrogen is widely assumed to be the cause, but later investigations pointed to the ignition of the aluminized fabric coating by static electricity. But the damage to hydrogen's reputation as a lifting gas was already done and commercial hydrogen airship travel ceased. Hydrogen is still used, in preference to non-flammable but more expensive helium, as a lifting gas for weather balloons. In the same year, the first hydrogen-cooled turbogenerator went into service with gaseous hydrogen as a coolant in the rotor and the stator in 1937 at Dayton, Ohio, by the Dayton Power & Light Co.; because of the thermal conductivity and very low viscosity of hydrogen gas, thus lower drag than air, this is the most common type in its field today for large generators (typically 60 MW and bigger; smaller generators are usually air-cooled). The nickel hydrogen battery was used for the first time in 1977 aboard the U.S. Navy's Navigation technology satellite-2 (NTS-2). For example, the ISS, Mars Odyssey and the Mars Global Surveyor are equipped with nickel-hydrogen batteries. In the dark part of its orbit, the Hubble Space Telescope is also powered by nickel-hydrogen batteries, which were finally replaced in May 2009, more than 19 years after launch and 13 years beyond their design life.  Role in quantum theory  Because of its simple atomic structure, consisting only of a proton and an electron, the hydrogen atom, together with the spectrum of light produced from it or absorbed by it, has been central to the development of the theory of atomic structure. Furthermore, study of the corresponding simplicity of the hydrogen molecule and the corresponding cation H+2 brought understanding of the nature of the chemical bond, which followed shortly after the quantum mechanical treatment of the hydrogen atom had been developed in the mid-1920s. One of the first quantum effects to be explicitly noticed (but not understood at the time) was a Maxwell observation involving hydrogen, half a century before full quantum mechanical theory arrived. Maxwell observed that the specific heat capacity of H2 unaccountably departs from that of a diatomic gas below room temperature and begins to increasingly resemble that of a monatomic gas at cryogenic temperatures. According to quantum theory, this behavior arises from the spacing of the (quantized) rotational energy levels, which are particularly wide-spaced in H2 because of its low mass. These widely spaced levels inhibit equal partition of heat energy into rotational motion in hydrogen at low temperatures. Diatomic gases composed of heavier atoms do not have such widely spaced levels and do not exhibit the same effect.Antihydrogen (H) is the antimatter counterpart to hydrogen. It consists of an antiproton with a positron. Antihydrogen is the only type of antimatter atom to have been produced as of 2015.  Cosmic prevalence and distribution  Hydrogen, as atomic H, is the most abundant chemical element in the universe, making up 75 percent of normal matter by mass and more than 90 percent by number of atoms. (Most of the mass of the universe, however, is not in the form of chemical-element type matter, but rather is postulated to occur as yet-undetected forms of mass such as dark matter and dark energy.) This element is found in great abundance in stars and gas giant planets. Molecular clouds of H2 are associated with star formation. Hydrogen plays a vital role in powering stars through the proton-proton reaction in case of stars with very low to approximately 1 mass of the Sun and the CNO cycle of nuclear fusion in case of stars more massive than the Sun.  States  Throughout the universe, hydrogen is mostly found in the atomic and plasma states, with properties quite distinct from those of molecular hydrogen. As a plasma, hydrogen's electron and proton are not bound together, resulting in very high electrical conductivity and high emissivity (producing the light from the Sun and other stars). The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind they interact with the Earth's magnetosphere giving rise to Birkeland currents and the aurora. Hydrogen is found in the neutral atomic state in the interstellar medium because the atoms seldom collide and combine. They are the source of the 21-cm hydrogen line at 1420 MHz that is detected in order to probe primordial hydrogen. The large amount of neutral hydrogen found in the damped Lyman-alpha systems is thought to dominate the cosmological baryonic density of the universe up to a redshift of z  4.Under ordinary conditions on Earth, elemental hydrogen exists as the diatomic gas, H2. Hydrogen gas is very rare in the Earth's atmosphere (around 0.53 ppm on a molar basis) because of its light weight, which enables it to escape from the atmosphere more rapidly than heavier gases. However, hydrogen is the third most abundant element on the Earth's surface, mostly in the form of chemical compounds such as hydrocarbons and water.A molecular form called protonated molecular hydrogen (H+3) is found in the interstellar medium, where it is generated by ionization of molecular hydrogen from cosmic rays. This ion has also been observed in the upper atmosphere of the planet Jupiter. The ion is relatively stable in the environment of outer space due to the low temperature and density. H+3 is one of the most abundant ions in the universe, and it plays a notable role in the chemistry of the interstellar medium. Neutral triatomic hydrogen H3 can exist only in an excited form and is unstable. By contrast, the positive hydrogen molecular ion (H+2) is a rare molecule in the universe.  Production  H2 is produced in chemistry and biology laboratories, often as a by-product of other reactions; in industry for the hydrogenation of unsaturated substrates; and in nature as a means of expelling reducing equivalents in biochemical reactions.  Commercial methods  Hydrogen is often produced by reacting water with methane and carbon monoxide, which causes the removal of hydrogen from hydrocarbons at very high temperatures, with 48% of hydrogen production coming from steam reforming. The water vapor is then reacted with the carbon monoxide produced by steam reforming to oxidize it to carbon dioxide and turn the water into hydrogen. Commercial bulk hydrogen is usually produced by the steam reforming of natural gas with release of atmospheric greenhouse gas or with capture using CCS and climate change mitigation. Steam reforming is also known as the Bosch process and is widely used for the industrial preparation of hydrogen. At high temperatures (1000–1400 K, 700–1100 °C or 1300–2000 °F), steam (water vapor) reacts with methane to yield carbon monoxide and H2. CH4 + H2O → CO + 3 H2This reaction is favored at low pressures but is nonetheless conducted at high pressures (2.0 MPa, 20 atm or 600 inHg). This is because high-pressure H2 is the most marketable product, and pressure swing adsorption (PSA) purification systems work better at higher pressures. The product mixture is known as ""synthesis gas"" because it is often used directly for the production of methanol and related compounds. Hydrocarbons other than methane can be used to produce synthesis gas with varying product ratios. One of the many complications to this highly optimized technology is the formation of coke or carbon: CH4 → C + 2 H2Consequently, steam reforming typically employs an excess of H2O. Additional hydrogen can be recovered from the steam by use of carbon monoxide through the water gas shift reaction, especially with an iron oxide catalyst. This reaction is also a common industrial source of carbon dioxide: CO + H2O → CO2 + H2Other important methods for CO and H2 production include partial oxidation of hydrocarbons: 2 CH4 + O2 → 2 CO + 4 H2and the coal reaction, which can serve as a prelude to the shift reaction above: C + H2O → CO + H2Hydrogen is sometimes produced and consumed in the same industrial process, without being separated. In the Haber process for the production of ammonia, hydrogen is generated from natural gas. Electrolysis of brine to yield chlorine also produces hydrogen as a co-product.Olefin production units may produce substantial quantities of byproduct hydrogen particularly from cracking light feedstocks like ethane or propane.  Water electrolysis  The electrolysis of water is a simple method of producing hydrogen. A current is run through the water, and gaseous oxygen forms at the anode while gaseous hydrogen forms at the cathode. Typically the cathode is made from platinum or another inert metal when producing hydrogen for storage. If, however, the gas is to be burnt on site, oxygen is desirable to assist the combustion, and so both electrodes would be made from inert metals. (Iron, for instance, would oxidize, and thus decrease the amount of oxygen given off.) The theoretical maximum efficiency (electricity used vs. energetic value of hydrogen produced) is in the range 88–94%. 2 H2O(l) → 2 H2(g) + O2(g)  Methane pyrolysis  Hydrogen production using natural gas methane pyrolysis is a process with a lower carbon footprint than commercial hydrogen production processes. Developing a commercial methane pyrolysis process could expedite the expanded use of hydrogen in industrial and transportation applications. Methane pyrolysis is accomplished by passing methane through a molten metal catalyst containing dissolved nickel. Methane is converted to hydrogen gas and solid carbon. CH4(g) → C(s) + 2 H2(g) (ΔH°  74 kJ/mol)The carbon may be sold as a manufacturing feedstock or fuel, or landfilled. Further research continues in several laboratories, including at Karlsruhe Liquid-metal Laboratory and at University of California – Santa Barbara. BASF built a methane pyrolysis pilot plant.  Metal-acid  Many metals react with water to produce H2, but the rate of hydrogen evolution depends on the metal, the pH, and the presence of alloying agents. Most commonly, hydrogen evolution is induced by acids. The alkali and alkaline earth metals, aluminium, zinc, manganese, and iron react readily with aqueous acids. This reaction is the basis of the Kipp's apparatus, which once was used as a laboratory gas source: Zn + 2 H+ → Zn2+ + H2In the absence of acid, the evolution of H2 is slower. Because iron is widely used structural material, its anaerobic corrosion is of technological significance: Fe + 2 H2O → Fe(OH)2 + H2Many metals, such as aluminium, are slow to react with water because they form passivated coatings of oxides. An alloy of aluminium and gallium, however, does react with water. At high pH, aluminium can produce H2: 2 Al + 6 H2O + 2 OH− → 2 [Al(OH)4]− + 3 H2Some metal-containing compounds react with acids to evolve H2. Under anaerobic conditions, ferrous hydroxide (Fe(OH)2) can be oxidized by the protons of water to form magnetite and H2. This process is described by the Schikorr reaction: 3 Fe(OH)2 → Fe3O4 + 2 H2O + H2This process occurs during the anaerobic corrosion of iron and steel in oxygen-free groundwater and in reducing soils below the water table.  Thermochemical  More than 200 thermochemical cycles can be used for water splitting. Many of these cycles such as the iron oxide cycle, cerium(IV) oxide–cerium(III) oxide cycle, zinc zinc-oxide cycle, sulfur-iodine cycle, copper-chlorine cycle and hybrid sulfur cycle have been evaluated for their commercial potential to produce hydrogen and oxygen from water and heat without using electricity. A number of laboratories (including in France, Germany, Greece, Japan, and the United States) are developing thermochemical methods to produce hydrogen from solar energy and water.  Applications   Petrochemical industry  Large quantities of H2 are used in the ""upgrading"" of fossil fuels. Key consumers of H2 include hydrodealkylation, hydrodesulfurization, and hydrocracking. Many of these reactions can be classified as hydrogenolysis, i.e., the cleavage of bonds to carbon. Illustrative is the separation of sulfur from liquid fossil fuels: R2S + 2 H2 → H2S + 2 RH  Hydrogenation  Hydrogenation, the addition of H2 to various substrates is conducted on a large scale. The hydrogenation of N2 to produce ammonia by the Haber–Bosch process consumes a few percent of the energy budget in the entire industry. The resulting ammonia is used to supply the majority of the protein consumed by humans. Hydrogenation is used to convert unsaturated fats and oils to saturated fats and oils. The major application is the production of margarine. Methanol is produced by hydrogenation of carbon dioxide. It is similarly the source of hydrogen in the manufacture of hydrochloric acid. H2 is also used as a reducing agent for the conversion of some ores to the metals.  Coolant  Hydrogen is commonly used in power stations as a coolant in generators due to a number of favorable properties that are a direct result of its light diatomic molecules. These include low density, low viscosity, and the highest specific heat and thermal conductivity of all gases.  Energy carrier  Elemental hydrogen has been widely discussed in the context of energy, as a possible future carrier of energy on an economy-wide scale. Hydrogen is a ''carrier'' of energy rather than an energy resource, because there is no naturally occurring source of hydrogen in useful quantities.Hydrogen can be burned to produce heat or combined with oxygen in fuel cells to generate electricity directly, with water being the only emissions at the point of usage. The overall lifecycle emissions of hydrogen depend on how it is produced. Nearly all of the world's current supply of hydrogen is created from fossil fuels. The main method is steam methane reforming, in which hydrogen is produced from a chemical reaction between steam and methane, the main component of natural gas. Producing one tonne of hydrogen through this process emits 6.6–9.3 tonnes of carbon dioxide. While carbon capture and storage can remove a large fraction of these emissions, the overall carbon footprint of hydrogen from natural gas is difficult to assess as of 2021, in part because of emissions created in the production of the natural gas itself.Electricity can be used to split water molecules, producing sustainable hydrogen provided the electricity was generated sustainably. However, this electrolysis process is currently more expensive than creating hydrogen from methane and the efficiency of energy conversion is inherently low. Hydrogen can be produced when there is a surplus of variable renewable electricity, then stored and used to generate heat or to re-generate electricity. Hydrogen created through electrolysis using renewable energy is commonly referred to as ""green hydrogen."" It can be further transformed into synthetic fuels such as ammonia and methanol.Innovation in hydrogen electrolysers could make large-scale production of hydrogen from electricity more cost-competitive. There is potential for hydrogen to play a significant role in decarbonising energy systems because in certain sectors, replacing fossil fuels with direct use of electricity would be very difficult. Hydrogen fuel can produce the intense heat required for industrial production of steel, cement, glass, and chemicals. For steelmaking, hydrogen can function as a clean energy carrier and simultaneously as a low-carbon catalyst replacing coal-derived coke. Hydrogen used in transportation would burn relatively cleanly, with some NOx emissions, but without carbon emissions. Disadvantages of hydrogen as an energy carrier include high costs of storage and distribution due to hydrogen's explosivity, its large volume compared to other fuels, and its tendency to make pipes brittle. The infrastructure costs associated with full conversion to a hydrogen economy would be substantial.  Semiconductor industry  Hydrogen is employed to saturate broken (""dangling"") bonds of amorphous silicon and amorphous carbon that helps stabilizing material properties. It is also a potential electron donor in various oxide materials, including ZnO, SnO2, CdO, MgO, ZrO2, HfO2, La2O3, Y2O3, TiO2, SrTiO3, LaAlO3, SiO2, Al2O3, ZrSiO4, HfSiO4, and SrZrO3.  Aerospace  Liquid hydrogen and liquid oxygen together serve as cryogenic fuel in liquid-propellant rockets, as in the Space Shuttle main engines.  Niche and evolving uses  Shielding gas: Hydrogen is used as a shielding gas in welding methods such as atomic hydrogen welding.Cryogenic research: Liquid H2 is used in cryogenic research, including superconductivity studies.Buoyant lifting: Because H2 is lighter than air, having only 7% of the density of air, it was once widely used as a lifting gas in balloons and airships. Leak detection: Pure or mixed with nitrogen (sometimes called forming gas), hydrogen is a tracer gas for detection of minute leaks. Applications can be found in the automotive, chemical, power generation, aerospace, and telecommunications industries. Hydrogen is an authorized food additive (E 949) that allows food package leak testing, as well as having anti-oxidizing properties.Neutron moderation: Deuterium (hydrogen-2) is used in nuclear fission applications as a moderator to slow neutrons. Nuclear fusion fuel: Deuterium is used in nuclear fusion reactions. Isotopic labeling: Deuterium compounds have applications in chemistry and biology in studies of isotope effects on reaction rates.Rocket propellant: NASA has investigated the use of rocket propellant made from atomic hydrogen, boron or carbon that is frozen into solid molecular hydrogen particles that are suspended in liquid helium. Upon warming, the mixture vaporizes to allow the atomic species to recombine, heating the mixture to high temperature. Tritium uses: Tritium (hydrogen-3), produced in nuclear reactors, is used in the production of hydrogen bombs, as an isotopic label in the biosciences, and as a source of beta radiation in radioluminescent paint for instrument dials and emergency signage.  Biological reactions  H2 is a product of some types of anaerobic metabolism and is produced by several microorganisms, usually via reactions catalyzed by iron- or nickel-containing enzymes called hydrogenases. These enzymes catalyze the reversible redox reaction between H2 and its component two protons and two electrons. Creation of hydrogen gas occurs in the transfer of reducing equivalents, produced during pyruvate fermentation, to water. The natural cycle of hydrogen production and consumption by organisms is called the hydrogen cycle. Bacteria such as Mycobacterium smegmatis can utilize the small amount of hydrogen in the atmosphere as a source of energy when other sources are lacking, using a hydrogenase with small channels that exclude oxygen and so permits the reaction to occur even though the hydrogen concentration is very low and the oxygen concentration is as in normal air.Hydrogen is the most abundant element in the human body in terms of numbers of atoms of the element but the third most abundant element by mass. H2 occurs in the breath of humans due to the metabolic activity of hydrogenase-containing microorganisms in the large intestine and is a natural component of flatus. The concentration in the breath of fasting people at rest is typically less than 5 parts per million (ppm) but can be 50 ppm when people with intestinal disorders consume molecules they cannot absorb during diagnostic hydrogen breath tests.Water splitting, in which water is decomposed into its component protons, electrons, and oxygen, occurs in the light reactions in all photosynthetic organisms. Some such organisms, including the alga Chlamydomonas reinhardtii and cyanobacteria, have evolved a second step in the dark reactions in which protons and electrons are reduced to form H2 gas by specialized hydrogenases in the chloroplast. Efforts have been undertaken to genetically modify cyanobacterial hydrogenases to efficiently synthesize H2 gas even in the presence of oxygen. Efforts have also been undertaken with genetically modified alga in a bioreactor.  Safety and precautions  Hydrogen poses a number of hazards to human safety, from potential detonations and fires when mixed with air to being an asphyxiant in its pure, oxygen-free form. In addition, liquid hydrogen is a cryogen and presents dangers (such as frostbite) associated with very cold liquids. Hydrogen dissolves in many metals and in addition to leaking out, may have adverse effects on them, such as hydrogen embrittlement, leading to cracks and explosions. Hydrogen gas leaking into external air may spontaneously ignite. Moreover, hydrogen fire, while being extremely hot, is almost invisible, and thus can lead to accidental burns.Even interpreting the hydrogen data (including safety data) is confounded by a number of phenomena. Many physical and chemical properties of hydrogen depend on the parahydrogen/orthohydrogen ratio (it often takes days or weeks at a given temperature to reach the equilibrium ratio, for which the data is usually given). Hydrogen detonation parameters, such as critical detonation pressure and temperature, strongly depend on the container geometry.  See also   Notes   References   Further reading  Chart of the Nuclides (17th ed.). Knolls Atomic Power Laboratory. 2010. ISBN 978-0-9843653-0-2. Ferreira-Aparicio, P.; Benito, M. J.; Sanz, J. L. (2005). ""New Trends in Reforming Technologies: from Hydrogen Industrial Plants to Multifuel Microreformers"". Catalysis Reviews. 47 (4): 491–588. doi:10.1080/01614940500364958. S2CID 95966974. Newton, David E. (1994). The Chemical Elements. New York: Franklin Watts. ISBN 978-0-531-12501-4. Rigden, John S. (2002). Hydrogen: The Essential Element. Cambridge, Massachusetts: Harvard University Press. ISBN 978-0-531-12501-4. Romm, Joseph J. (2004). The Hype about Hydrogen, Fact and Fiction in the Race to Save the Climate. Island Press. ISBN 978-1-55963-703-9. Scerri, Eric (2007). The Periodic System, Its Story and Its Significance. New York: Oxford University Press. ISBN 978-0-19-530573-9. Hydrogen safety covers the safe production, handling and use  External links  Basic Hydrogen Calculations of Quantum Mechanics Hydrogen at The Periodic Table of Videos (University of Nottingham) High temperature hydrogen phase diagram Wavefunction of hydrogen","Hydrogen is a chemical element. It has the symbol H and atomic number 1. It has a standard atomic weight of 1.008, meaning it is the lightest element in the periodic table. Hydrogen is the most common chemical element in the Universe, making up 75% of all normal (baryonic) matter (by mass). Most stars are mostly hydrogen. Hydrogen's most common isotope has one proton with one electron orbiting around it.  Properties  Hydrogen is classed as a reactive nonmetal, unlike the other elements appearing in the first column of the periodic table, which are classed alkali metals. The solid form of hydrogen is expected to behave like a metal, however. When alone, hydrogen usually binds with itself to make dihydrogen (H2) which is very stable, due to its high bond dissociation energy of 435.7 kJ/mol. At standard temperature and pressure, this hydrogen gas (H2) has no colour, smell or taste. It is not toxic. It is a nonmetal and burns very easily.  Combustion  Molecular hydrogen is flammable and reacts with oxygen: 2 H2(g) + O2(g) → 2 H2O(l) + 572 kJ (286 kJ/mol) At temperatures above 500 degrees Celsius, hydrogen spontaneously ignites in air.  Compounds  While hydrogen gas in its pure form is not reactive, it does form compounds with many elements, particularly halogens, which are very electronegative. Hydrogen also forms vast arrays with carbon atoms, forming hydrocarbons. The study of the properties of hydrocarbons are known as organic chemistry. The H- anion (negatively charged atom) is called a hydride, although the term is not widely used. An example of a hydride is lithium hydride (LiH), which is used as a ""spark plug"" in nuclear weapons.  Acids  Acids dissolved in water typically contain high levels of hydrogen ions, in other words, free protons. The level of them is usually used to determine its pH, which basically means the content of hydrogen ions in a particular volume. For example, hydrochloric acid, found in people's stomachs, can dissociate into a chloride anion and a free proton, and the property of the free proton is how it can digest food by corroding it. Although rare on Earth, the H3+ cation is one of the most common ions in the universe.  Isotopes  Main article: isotopes of hydrogenHydrogen has 7 known isotopes, two of which are stable (1H and 2H), which are commonly referred to protium and deuterium. The isotope 3H is known as tritium and has a half life of 12.33 years, and is produced in small amounts by cosmic rays. The remaining 4 isotopes have half lives on the scale of yoctoseconds.  Hydrogen in nature  In its pure form on Earth, hydrogen is usually a gas. Hydrogen is also one of the parts that make up a water molecule. Hydrogen is important because it is the fuel that powers the Sun and other stars. Hydrogen makes up about 74% of the entire universe. Hydrogen's symbol on the Periodic Table of Elements is H. Pure hydrogen is normally made of two hydrogen atoms connected together. Scientists call these diatomic molecules. Hydrogen will have a chemical reaction when mixed with most other elements. It has no color or smell. Pure hydrogen is very uncommon in the Earth's atmosphere, because nearly all primordial hydrogen would have escaped into space due to its weight. In nature, it is usually in water. Hydrogen is also in all living things, as a part of the organic compounds that living things are made of. In addition, hydrogen atoms can combine with carbon atoms to form hydrocarbons. Petroleum and other fossil fuels are made of these hydrocarbons and commonly used to create energy for human use. Some other facts about hydrogen: It is a gas at room temperature It acts like a metal when it is solid. It is the lightest element in the Universe. It is the most common element in the Universe. It burns or explodes above 1000°F / 528°C, such as in fire. glows purple when it is in plasma state.  History of Hydrogen  Hydrogen was first separated in 1671 by Robert Boyle. In 1776, Henry Cavendish identified it as its own element and called it ""inflammable air"". He realized in 1781 that burning it made water. Antoine Lavoisier gave Hydrogen its name, from the Greek word for water, 'υδορ (pronounced /HEEW-dor/) and gennen meaning to ""generate"" as it forms water in a chemical reaction with oxygen.  Uses of Hydrogen  The main uses are in the petroleum industry and in making ammonia by the Haber process. Some is used elsewhere in the chemical industry. A little of it is used as fuel, for example in rockets for spacecraft. Most of the hydrogen that people use comes from a chemical reaction between natural gas and steam.  Nuclear fusion  Nuclear fusion is a very powerful source of energy. It relies on forcing atoms together to make helium and energy, exactly as happens in a star like the Sun, or in a hydrogen bomb. This needs a large amount of energy to get started, and is not easy to do yet. A big advantage over nuclear fission, which is used in today's nuclear power stations, is that it makes less nuclear waste and does not use a toxic and rare fuel like uranium. More than 600 million tons of hydrogen undergo fusion every second on the Sun.  Using hydrogen  Hydrogen is mostly used in the petroleum industry, to change heavy petroleum fractions into lighter, more useful ones. It is also used to make ammonia. Smaller amounts are burned as fuel. Most hydrogen is made by a reaction between natural gas and steam. The electrolysis of water breaks water into hydrogen and oxygen, using electricity. Burning hydrogen combines with oxygen molecules to make steam (pure water vapor). A fuel cell combines hydrogen with an oxygen molecule, releasing an electron as electricity. For these reasons, many people believe hydrogen power will eventually replace other synthetic fuels. Hydrogen can also be burned to make heat for steam turbines or internal combustion engines. Like other synthetic fuels, hydrogen can be created from natural fuels such as coal or natural gas, or from electricity, and therefore represents a valuable addition to the power grid; in the same role as natural gas. Such a grid and infrastructure with fuel cell vehicles is now planned by a number of countries including Japan, Korea and many European countries. This allows these countries to buy less petroleum, which is an economic advantage. The other advantage is that used in a fuel cell or burned in a combustion engine as in a hydrogen car, the motor does not make pollution. Only water, and a small amount of nitrogen oxides, forms.  References   Other websites  Hydrogen -Citizendium"
"Tardive dyskinesia (TD) is a disorder that results in involuntary repetitive body movements, which may include grimacing, sticking out the tongue or smacking the lips. Additionally, there may be rapid jerking movements or slow writhing movements. In about 20% of people with TD, the disorder interferes with daily functioning.Tardive dyskinesia occurs in some people as a result of long-term use of dopamine-receptor-blocking medications such as antipsychotics and metoclopramide. These medications are usually used for mental illness but may also be given for gastrointestinal or neurological problems. The condition typically develops only after months to years of use. The diagnosis is based on the symptoms after ruling out other potential causes.Efforts to prevent the condition include either using the lowest possible dose or discontinuing use of neuroleptics. Treatment includes stopping the neuroleptic medication if possible or switching to clozapine. Other medications such as valbenazine, tetrabenazine, or botulinum toxin may be used to lessen the symptoms. With treatment, some see a resolution of symptoms, while others do not.Rates in those on atypical antipsychotics are about 20%, while those on typical antipsychotics have rates of about 30%. The risk of acquiring the condition is greater in older people, for women, as well as patients with mood disorders and/or medical diagnoses receiving antipsychotic medications. The term ""tardive dyskinesia"" first came into use in 1964.  Signs and symptoms  Tardive dyskinesia is characterized by repetitive, involuntary movements. Some examples of these types of involuntary movements include: Grimacing Tongue movements Lip smacking Lip puckering Pursing of the lips Excessive eye blinking Rapid, involuntary movements of the limbs, torso, and fingers may also occur.In some cases, an individual's legs can be so affected that walking becomes difficult or impossible. These symptoms are the opposite of people who are diagnosed with Parkinson's disease. People with Parkinson's have difficulty moving, whereas people with tardive dyskinesia have difficulty not moving.Respiratory irregularity, such as grunting and difficulty breathing, is another symptom associated with tardive dyskinesia, although studies have shown that the rate of people affected is relatively low.Tardive dyskinesia is often misdiagnosed as a mental illness rather than a neurological disorder, and as a result, people are prescribed neuroleptic drugs, which increase the probability that the person will develop a severe and disabling case, and shortening the typical survival period.Other closely related neurological disorders have been recognized as variants of tardive dyskinesia. Tardive dystonia is similar to standard dystonia but permanent. Tardive akathisia involves painful feelings of inner tension and anxiety and a compulsive drive to move the body. In some extreme cases, afflicted individuals experience so much internal tension that they lose their ability to sit still. Tardive tourettism is a tic disorder featuring the same symptoms as Tourette syndrome. The two disorders are extremely close in nature and often can only be differentiated by the details of their respective onsets. Tardive myoclonus, a rare disorder, presents as brief jerks of muscles in the face, neck, trunk, and extremities.""AIMS Examination"": This test is used when psychotropic medications have been prescribed because people sometimes develop tardive dyskinesia due to prolonged use of antipsychotic medications. The Abnormal Involuntary Movement Scale (AIMS) examination is a test used to identify the symptoms of tardive dyskinesia (TD). The test is not meant to tell whether there is an absence or presence of tardive dyskinesia. It just scales to the level of symptoms indicated by the actions observed. The levels range from none to severe. The AIMS examination was constructed in the 1970s to measure involuntary facial, trunk, and limb movements. It is best to do this test before and after the administration of the psychotropic drugs. Taking the AIMS consistently can help to track severity of TD over time.  Causes  Tardive dyskinesia was first described in the 1950s shortly after the introduction of chlorpromazine and other antipsychotic drugs. However, the exact mechanism of the disorder remains largely uncertain. The most compelling line of evidence suggests that tardive dyskinesia may result primarily from neuroleptic-induced dopamine supersensitivity in the nigrostriatal pathway, with the D2 dopamine receptor being most affected. Neuroleptics act primarily on this dopamine system, and older neuroleptics, which have greater affinity for the D2 binding site, are associated with high risk for tardive dyskinesia. The D2 hypersensitivity hypothesis is also supported by evidence of a dose–response relationship, withdrawal effects, studies on D2 agonists and antagonists, animal studies, and genetic polymorphism research.Given similar doses of the same neuroleptic, differences among individuals still exist in the likelihood of developing tardive dyskinesia. Such individual differences may be due to genetic polymorphisms, which code for D2 receptor binding site affinity, or prior exposure to environmental toxins. Decreased functional reserve or cognitive dysfunction, associated with aging, intellectual disability, alcohol and drug use, or traumatic head injuries, has also been shown to increase risk of developing the disorder among those treated with neuroleptics. Antipsychotic drugs can sometimes camouflage the signs of tardive dyskinesia from occurring in the early stages; this can happen from the individual having an increased dose of an antipsychotic drug. Often the symptoms of tardive dyskinesia are not apparent until the individual comes off of the antipsychotic drugs; however, when tardive dyskinesia worsens, the signs become visible.Other dopamine antagonists and antiemetics can cause tardive dyskinesia, such as metoclopramide and promethazine, used to treat gastrointestinal disorders. Atypical antipsychotics are considered lower-risk for causing TD than their typical counterparts with their relative rates of TD of 13.1% and 32.4% respectively in short-term trials with haloperidol being the main typical antipsychotic utilised in said trials. Quetiapine and clozapine are considered the lowest risk agents for precipitating TD. From 2008, there have been reported cases of the anti-psychotic medication aripiprazole, a partial agonist at D2 receptors, leading to tardive dyskinesia. As of 2013, reports of tardive dyskinesia in aripiprazole have grown in number. The available research seems to suggest that the concurrent prophylactic use of a neuroleptic and an antiparkinsonian drug is useless to avoid early extrapyramidal side-effects and may render the person more sensitive to tardive dyskinesia. Since 1973 the use of these drugs has been found to be associated with the development of tardive dyskinesia.  Risk factors  An increased risk of tardive dyskinesia has been associated with smoking in some studies, although a negative study does exist. There seems to be a cigarette smoke-exposure-dependent risk for TD in people who are antipsychotic-treated . Elderly people are also at a heightened risk for developing TD, as are females and those with organic brain injuries or diabetes mellitus and those with the negative symptoms of schizophrenia. TD is also more common in those that experience acute neurological side effects from antipsychotic drug treatment. Racial discrepancies in TD rate also exist, with Africans and African Americans having higher rates of TD after exposure to antipsychotics. Certain genetic risk factors for TD have been identified including polymorphisms in the genes encoding the D3, 5-HT2A and 5-HT2C receptors.  Diagnosis   Prevention  Prevention of tardive dyskinesia is achieved by using the lowest effective dose of a neuroleptic for the shortest time. However, with diseases of chronic psychosis such as schizophrenia, this strategy must be balanced with the fact that increased dosages of neuroleptics are more beneficial in preventing recurrence of psychosis. If tardive dyskinesia is diagnosed, the causative drug should be discontinued. Tardive dyskinesia may persist after withdrawal of the drug for months, years or even permanently. Some studies suggest that practitioners should consider using atypical antipsychotics as a substitute to typical antipsychotics for people requiring medication. These agents are associated with fewer neuromotor side effects and a lower risk of developing tardive dyskinesia.Studies have tested the use of melatonin, high dosage vitamins, and different antioxidants in concurrence with antipsychotic drugs (often used to treat schizophrenia) as a way of preventing and treating tardive dyskinesia. Although further research is needed, studies reported a much lower percentage of individuals developing tardive dyskinesia than the current rate of people for those taking antipsychotic drugs. Tentative evidence supports the use of vitamin E for prevention.  Treatment  Valbenazine was approved by the FDA for tardive dyskinesia in April 2017. Tetrabenazine, which is a dopamine depleting drug, is sometimes used to treat tardive dyskinesia and other movement disorders (e.g. Huntington's chorea). Deutetrabenazine, an isotopic isomer of tetrabenazine, was approved by the FDA for tardive dyskinesia in August 2017. Vitamin B6 has been reported to be an effective treatment for TD in two randomised double-blind placebo-controlled trials, but the overall evidence for its effectiveness is considered ""weak."" Clonidine may also be useful in the treatment of TD, although dose-limiting hypotension and sedation may hinder its usage. Botox injections are used for minor focal dystonia, but not in more advanced tardive dyskinesia. As of 2018 evidence is insufficient to support the use of benzodiazepines, baclofen, progabide, sodium valproate, gaboxadol, or calcium channel blockers (e.g. diltiazem).  Epidemiology  Tardive dyskinesia most commonly occurs in people with psychiatric conditions who are treated with antipsychotic medications for many years. The average rate of people affected has been estimated to be around 30% for individuals taking antipsychotic medication, such as that used to treat schizophrenia. A study being conducted at the Yale University School of Medicine has estimated that ""32% of people develop persistent tics after 5 years on major tranquilizers, 57% by 15 years, and 68% by 25 years."" More drastic data was found during a longitudinal study conducted on individuals 45 years of age and older who were taking antipsychotic drugs. According to this research study, 26% of people developed tardive dyskinesia after just one year on the medication. Another 60% of this at-risk group developed the disorder after 3 years, and 23% developed severe cases of tardive dyskinesia within 3 years. According to these estimates, the majority of people will eventually develop the disorder if they remain on the drugs long enough.Elderly people are more prone to develop tardive dyskinesia, and elderly women are more at-risk than elderly men. The risk is much lower for younger men and women, and also more equal across the sexes. People who have undergone electroconvulsive therapy or have a history of diabetes or heavy alcohol use also have a higher risk of developing tardive dyskinesia.Several studies have recently been conducted comparing the number of people affected of tardive dyskinesia with second generation, or more modern, antipsychotic drugs to that of first generation drugs. The newer antipsychotics appear to have a substantially reduced potential for causing tardive dyskinesia. However, some studies express concern that the number of people affected has decreased far less than expected, cautioning against the overestimation of the safety of modern antipsychotics.A practitioner can evaluate and diagnose a person with tardive dyskinesia by conducting a systematic examination. The practitioner should ask the person to relax, and look for symptoms like facial grimacing, eye or lip movements, tics, respiratory irregularities, and tongue movements. In some cases, people experience nutritional problems, so a practitioner can also look for a gain or loss in weight.Apart from the underlying psychiatric disorder, tardive dyskinesia may cause afflicted people to become socially isolated. It also increases the risk of body dysmorphic disorder (BDD) and can even lead to suicide. Emotional or physical stress can increase the severity of dyskinetic movements, whereas relaxation and sedation have the opposite effect.  References   External links ","Tardive dyskinesia (TD) is a serious neurological illness. It is a type of dyskinesia - a disorder that causes movements that happen over and over again, which a person cannot control. ""Tardive"" means these movements do not start right away, or they start slowly. Tardive dyskinesia is usually caused by taking antipsychotic medicines in high doses, or for a long time. This happens more often with older antipsychotic medicines. Usually, tardive dyskinesia happens when these medicines are taken for many months or years. But some people get tardive dyskinesia after taking these medicines for only 6 weeks.  Causes  The medicines that are most likely to cause tardive dyskinesia are these older antipsychotic medicines: Chlorpromazine (Thorazine) Fluphenazine (Prolixin) Haloperidol (Haldol) TrifluoperazineOther medicines that are similar to these antipsychotics can also cause tardive dyskinesia. These medicines are used to treat gastrointestinal problems, like nausea, vomiting, and delayed gastric emptying (when the stomach does not empty as quickly as normal). If they are taken for a long time, they can cause tardive dyskinesia: Metoclopramide (Reglan) Prochlorperazine (Compazine)Newer antipsychotic medicines (also called ""atypical antipsychotics"") are less likely to cause tardive dyskinesia, but they still can.  Who gets tardive dyskinesia?  Nobody knows why some people get tardive dyskinesia after taking antipsychotic medicines while others do not. But there are certain groups of people who are more likely to get tardive dyskinesia. The longer a person has been on antipsychotic medicines, the more likely they are to get TD.Most people who get tardive dyskinesia are people who have schizophrenia, schizoaffective disorder, or bipolar disorder, and have been on antipsychotic medicines for a long time. But some other people can get tardive dyskinesia too. Some people have a very high risk of getting tardive dyskinesia. They can get TD even after taking an antipsychotic medicine just once. People that have this very high risk include: People with fetal alcohol syndrome People with other developmental disabilities People with brain diseases or injuries  Symptoms  The symptoms of tardive dyskinesia are movements of the face, lips, tongue, torso, arms, and legs. The person with tardive dyskinesia cannot stop or control these movements. For example, people with tardive dyskinesia often cannot stop themselves from: Smacking their lips Pushing their tongue out Swinging their jaw Moving their mouth like they are chewing or sucking Moving their fingers, arms, or legsOften, people with tardive dyskinesia also have akathisia. This is a constant urge to move, or always being restless.  Prevention  Doctors can try to prevent tardive dyskinesia by: Using the lowest possible dose of antipsychotic medicine Using antipsychotic medicine for the shortest possible time Using newer (atypical) antipsychotic medicines instead of older antipsychotics which are more likely to cause TD Checking for symptoms of TD at every appointment with the patient  Treatment  Diagnosing tardive dyskinesia early is very important. Sometimes, if the drug that is causing TD is stopped early enough, the tardive dyskinesia will go away. This is more likely to happen if the TD is diagnosed soon after its symptoms start.Sometimes, even if the medication is stopped, the tardive dyskinesia never goes away.If a person with TD still needs antipsychotic medicines, a medication called clozapine (Clozaril) is the best choice. It is a newer antipsychotic, it often works well for schizophrenia that is hard to treat, and it has less of a risk of causing or worsening TD.The United States Food and Drug Administration (FDA) has not approved any medicines to treat the symptoms of tardive dyskinesia. Some doctors use these medications: Benzodiazepines, especially clonazepam (Klonopin) Clonidine (Catapres), a medication used for blood pressure and many other things Medicines given for Parkinson's disease, like pramipexole (Mirapex) and baclofenSome small experiments have said that these medicines may be helpful for TD symptoms: Ondansetron (Zofran), a medicine for nausea and vomiting Vitamin E Levodopa (L-DOPA), an old medicine used for Parkinson's disease Propranolol, a blood pressure medicine that can also be used for tremors Zonisamide (Zonegran), an anti-seizure medication Botulinum toxin (Botox)  References "
"A medical specialty is a branch of medical practice that is focused on a defined group of patients, diseases, skills, or philosophy. Examples include those branches of medicine that deal exclusively with children (paediatrics), cancer (oncology), laboratory medicine (pathology), or primary care (family medicine). After completing medical school or other basic training, physicians or surgeons and other clinicians usually further their medical education in a specific specialty of medicine by completing a multiple-year residency to become a specialist.  History of medical specialization  To a certain extent, medical practitioners have long been specialized. According to Galen, specialization was common among Roman physicians. The particular system of modern medical specialties evolved gradually during the 19th century. Informal social recognition of medical specialization evolved before the formal legal system. The particular subdivision of the practice of medicine into various specialties varies from country to country, and is somewhat arbitrary.  Classification of medical specialization  Medical specialties can be classified along several axes. These are: Surgical or internal medicine Age range of patients Diagnostic or therapeutic Organ-based or technique-basedThroughout history, the most important has been the division into surgical and internal medicine specialties. The surgical specialties are those in which an important part of diagnosis and treatment is achieved through major surgical techniques. The internal medicine specialties are the specialties in which the main diagnosis and treatment is never major surgery. In some countries, anesthesiology is classified as a surgical discipline, since it is vital in the surgical process, though anesthesiologists never perform major surgery themselves. Many specialties are organ-based. Many symptoms and diseases come from a particular organ. Others are based mainly around a set of techniques, such as radiology, which was originally based around X-rays. The age range of patients seen by any given specialist can be quite variable. Paediatricians handle most complaints and diseases in children that do not require surgery, and there are several subspecialties (formally or informally) in paediatrics that mimic the organ-based specialties in adults. Paediatric surgery may or may not be a separate specialty that handles some kinds of surgical complaints in children. A further subdivision is the diagnostic versus therapeutic specialties. While the diagnostic process is of great importance in all specialties, some specialists perform mainly or only diagnostic examinations, such as pathology, clinical neurophysiology, and radiology. This line is becoming somewhat blurred with interventional radiology, an evolving field that uses image expertise to perform minimally invasive procedures.  Specialties that are common worldwide   List of specialties recognized in the European Union and European Economic Area  The European Union publishes a list of specialties recognized in the European Union, and by extension, the European Economic Area. There is substantial overlap between some of the specialties and it is likely that for example ""Clinical radiology"" and ""Radiology"" refer to a large degree to the same pattern of practice across Europe.  List of North American medical specialties and others  In this table, as in many healthcare arenas, medical specialties are organized into the following groups: Surgical specialties focus on manually operative and instrumental techniques to treat disease. Medical specialties that focus on the diagnosis and non-surgical treatment of disease. Diagnostic specialties focus more purely on diagnosis of disorders.  Salaries  According to the 2022 Medscape Physician Compensation Report, physicians on average earn $339K annually. Primary care physicians earn $260K annually while specialists earned $368K annually.The table below details the average range of salaries for physicians in the US of medical specialties:  Specialties by country   Australia and New Zealand  There are 15 recognised specialty medical Colleges in Australia. The majority of these are Australasian Colleges and therefore also oversee New Zealand specialist doctors. These Colleges are: In addition, the Royal Australasian College of Dental Surgeons supervises training of specialist medical practitioners specializing in Oral and Maxillofacial Surgery in addition to its role in the training of dentists. There are approximately 260 faciomaxillary surgeons in Australia.The Royal New Zealand College of General Practitioners is a distinct body from the Australian Royal Australian College of General Practitioners. There are approximately 5100 members of the RNZCGP. Within some of the larger Colleges, there are sub-faculties, such as: Australasian Faculty of Rehabilitation Medicine Archived 2014-12-11 at the Wayback Machine within the Royal Australasian College of Physicians There are some collegiate bodies in Australia that are not officially recognised as specialities by the Australian Medical Council but have a college structure for members, such as: Australasian College of Physical Medicine There are some collegiate bodies in Australia of Allied Health non-medical practitioners with specialisation. They are not recognised as medical specialists, but can be treated as such by private health insurers, such as: Australasian College of Podiatric Surgeons  Canada  Specialty training in Canada is overseen by the Royal College of Physicians and Surgeons of Canada and the College of Family Physicians of Canada. For specialists working in the province of Quebec, the Collège des médecins du Québec also oversees the process.  Germany  In Germany these doctors use the term Facharzt.  India  Specialty training in India is overseen by the Medical Council of India, responsible for recognition of post graduate training and by the National Board of Examinations. Education of Ayurveda in overseen by Central Council of Indian Medicine (CCIM), the council conducts UG and PG courses all over India, while Central Council of Homoeopathy does the same in the field of Homeopathy.  Sweden  In Sweden, a medical license is required before commencing specialty training. Those graduating from Swedish medical schools are first required to do a rotational internship of about 1.5 to 2 years in various specialties before attaining a medical license. The specialist training lasts 5 years.  United States  There are three agencies or organizations in the United States that collectively oversee physician board certification of MD and DO physicians in the United States in the 26 approved medical specialties recognized in the country. These organizations are the American Board of Medical Specialties (ABMS) and the American Medical Association (AMA); the American Osteopathic Association Bureau of Osteopathic Specialists (AOABOS) and the American Osteopathic Association; the American Board of Physician Specialties (ABPS) and the American Association of Physician Specialists (AAPS). Each of these agencies and their associated national medical organization functions as its various specialty academies, colleges and societies. All boards of certification now require that medical practitioners demonstrate, by examination, continuing mastery of the core knowledge and skills for a chosen specialty. Recertification varies by particular specialty between every seven and every ten years. In the United States there are hierarchies of medical specialties in the cities of a region. Small towns and cities have primary care, middle sized cities offer secondary care, and metropolitan cities have tertiary care. Income, size of population, population demographics, distance to the doctor, all influence the numbers and kinds of specialists and physicians located in a city.  Demography  A population's income level determines whether sufficient physicians can practice in an area and whether public subsidy is needed to maintain the health of the population. Developing countries and poor areas usually have shortages of physicians and specialties, and those in practice usually locate in larger cities. For some underlying theory regarding physician location, see central place theory.The proportion of men and women in different medical specialties varies greatly. Such sex segregation is largely due to differential application.  Satisfaction and burnout  A survey of physicians in the United States came to the result that dermatologists are most satisfied with their choice of specialty followed by radiologists, oncologists, plastic surgeons, and gastroenterologists. In contrast, primary care physicians were the least satisfied, followed by nephrologists, obstetricians/gynecologists, and pulmonologists. Surveys have also revealed high levels of depression among medical students (25 - 30%) as well as among physicians in training (22 - 43%), which for many specialties, continue into regular practice. A UK survey conducted of cancer-related specialties in 1994 and 2002 found higher job satisfaction in those specialties with more patient contact. Rates of burnout also varied by specialty.  See also  Branches of medicine Interdisciplinary sub-specialties of medicine, including Occupational medicine – branch of clinical medicine that provides health advice to organizations and individuals concerning work-related health and safety issues and standards. See occupational safety and health. Disaster medicine – branch of medicine that provides healthcare services to disaster survivors; guides medically related disaster preparation, disaster planning, disaster response and disaster recovery throughout the disaster life cycle and serves as a liaison between and partner to the medical contingency planner, the emergency management professional, the incident command system, government and policy makers. Preventive medicine – part of medicine engaged with preventing disease rather than curing it. It can be contrasted not only with curative medicine, but also with public health methods (which work at the level of population health rather than individual health). Medical genetics – the application of genetics to medicine. Medical genetics is a broad and varied field. It encompasses many different individual fields, including clinical genetics, biochemical genetics, cytogenetics, molecular genetics, the genetics of common diseases (such as neural tube defects), and genetic counseling. Specialty Registrar Federation of National Specialty Societies of Canada Society of General Internal Medicine  References ","Medicine is a very complex field. In the past, a doctor could learn almost all that we knew about medicine. Now that is impossible. So after finishing medical school, young doctors choose what kind of doctor they wish to be. After school, they usually do more years of training to learn about the kind of medical specialty they want to do.  Primary care doctors  Some doctors try to learn some about all of the different subjects of medicine and how to treat all patients. These doctors are called 'primary care' doctors or ""primary care physicians"" (PCPs). Sometimes they are also called 'generalists' or even 'general practitioners.' In the United States, these kind of doctors are sometimes called family practitioners or family medicine doctors. When a problem is strange or complex, they give it to a specialist. There are other doctors who are also 'primary care' doctors. Pediatricians are primary care doctors, but only for children. Internists are primary care doctors for adults. Some gynecologists do primary care, but for women only.  Specialists  Other doctors are called 'specialists'. This means they have learned more about certain types of medical care. For example: A dermatologist is a doctor who knows more about the skin and diseases of the skin. A psychiatrist is a doctor who knows about thought, mood, and mental illnesses like depression and schizophrenia. An orthopedic surgeon is a doctor who knows about bones and joints, and fixes them when they are broken or diseased.  Medicine and surgery  In the broadest meaning of 'medicine', there are many different specialties. However, within medical circles, there are two broad categories: ""Medicine"" and ""Surgery."" ""Medicine"" doctors do not do surgery. To be a medical specialist, most doctors have to train in Internal medicine first. Examples of medical specialists include cardiologists, pulmonologists, and obstetricians. ""Surgery"" doctors (surgeons) do surgery. To be a surgical specialist, most surgeons have to train in ""General Surgery"" first. Examples of surgical specialists include orthopedic surgeons, neurosurgeons, and trauma surgeons.There are some medical specialties that do not fit into either of these categories, like radiology, pathology, and anesthesia.  Training  In the U.S., all specialties must pass all three steps of the national medical board examinations. Steps I and II happen during medical school. Step III happens during intern year, where a person works as a student at a hospital. After a person passes these exams, they then have to pass more exams that are specifically about their specialty. These tests are both written and oral. A doctor is board-certified in their specialty after: They finish their residency They have been working as a doctor for at least one year They have passed all of their examsThere are only a few training spots per specialty each year, so some specialties can be very competitive. Some medical students do not get to train in the specialty they want. Other specialties do not have nearly enough doctors. This can happen because not enough doctors apply for training spots; because more training spots are needed; or because many people fail out of their training program.  Surgical training  Surgical training requires at least five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last another one to three years. Because fellowships can be competitive, many trainees spend another two years on research. Because of this, for some people, their surgical training will not finish until more than a decade after medical school. Surgical training can be very difficult and can take a lot of time. An average surgical resident works 75 hours per week. Some subspecialties of surgery, like neurosurgery, require even longer hours. Residents training in these specialties often work 80 hours a week. Officially, these specialties only allow their residents to work up to 88 hours per week. However, many surgical programs still require residents to work more than 88 hours a week. Attempts to limit the amount of hours that surgical residents work have been difficult, because: Many patients need surgery There are not enough people who are willing to enter into surgery as a career) Doctors need to perform long surgeries, and still give care to all patients before and after surgery Surgeons always need to be available in the Operating Room (OR), where surgeries happen; the Intensive Care Unit (ICU); and the Emergency Room (ER).  Medical training  Medical training, unlike surgical training, requires three years of residency training after medical school. Doctors can then do a one- to two-year fellowship in their subspecialty. In general, medical residents work less hours than surgical residents.  Common medical specialties   References "
"Thermoregulation is the ability of an organism to keep its body temperature within certain boundaries, even when the surrounding temperature is very different. A thermoconforming organism, by contrast, simply adopts the surrounding temperature as its own body temperature, thus avoiding the need for internal thermoregulation. The internal thermoregulation process is one aspect of homeostasis: a state of dynamic stability in an organism's internal conditions, maintained far from thermal equilibrium with its environment (the study of such processes in zoology has been called physiological ecology). If the body is unable to maintain a normal temperature and it increases significantly above normal, a condition known as hyperthermia occurs. Humans may also experience lethal hyperthermia when the wet bulb temperature is sustained above 35 °C (95 °F) for six hours. The opposite condition, when body temperature decreases below normal levels, is known as hypothermia. It results when the homeostatic control mechanisms of heat within the body malfunction, causing the body to lose heat faster than producing it. Normal body temperature is around 37 °C (99 °F), and hypothermia sets in when the core body temperature gets lower than 35 °C (95 °F). Usually caused by prolonged exposure to cold temperatures, hypothermia is usually treated by methods that attempt to raise the body temperature back to a normal range.It was not until the introduction of thermometers that any exact data on the temperature of animals could be obtained. It was then found that local differences were present, since heat production and heat loss vary considerably in different parts of the body, although the circulation of the blood tends to bring about a mean temperature of the internal parts. Hence it is important to identify the parts of the body that most closely reflect the temperature of the internal organs. Also, for such results to be comparable, the measurements must be conducted under comparable conditions. The rectum has traditionally been considered to reflect most accurately the temperature of internal parts, or in some cases of sex or species, the vagina, uterus or bladder.Some animals undergo one of various forms of dormancy where the thermoregulation process temporarily allows the body temperature to drop, thereby conserving energy. Examples include hibernating bears and torpor in bats.  Classification of animals by thermal characteristics   Endothermy vs. ectothermy  Thermoregulation in organisms runs along a spectrum from endothermy to ectothermy. Endotherms create most of their heat via metabolic processes and are colloquially referred to as warm-blooded. When the surrounding temperatures are cold, endotherms increase metabolic heat production to keep their body temperature constant, thus making the internal body temperature of an endotherm more or less independent of the temperature of the environment. Endotherms possess a larger number of mitochondria per cell than ectotherms, enabling them to generate more heat by increasing the rate at which they metabolize fats and sugars. Ectotherms use external sources of temperature to regulate their body temperatures. They are colloquially referred to as cold-blooded despite the fact that body temperatures often stay within the same temperature ranges as warm-blooded animals. Ectotherms are the opposite of endotherms when it comes to regulating internal temperatures. In ectotherms, the internal physiological sources of heat are of negligible importance; the biggest factor that enables them to maintain adequate body temperatures is due to environmental influences. Living in areas that maintain a constant temperature throughout the year, like the tropics or the ocean, has enabled ectotherms to develop behavioral mechanisms that respond to external temperatures, such as sun-bathing to increase body temperature, or seeking the cover of shade to lower body temperature.  Ectotherms   Ectothermic cooling  Vaporization: Evaporation of sweat and other bodily fluids. Convection: Increasing blood flow to body surfaces to maximize heat transfer across the advective gradient. Conduction: Losing heat by being in contact with a colder surface. For instance: Lying on cool ground. Staying wet in a river, lake or sea. Covering in cool mud. Radiation: Releasing heat by radiating it away from the body.  Ectothermic heating (or minimizing heat loss)  Convection: Climbing to higher ground up trees, ridges, rocks. Entering a warm water or air current. Building an insulated nest or burrow. Conduction: Lying on a hot surface. Radiation: Lying in the sun (heating this way is affected by the body's angle in relation to the sun). Folding skin to reduce exposure. Concealing wing surfaces. Exposing wing surfaces. Insulation: Changing shape to alter surface/volume ratio. Inflating the body. To cope with low temperatures, some fish have developed the ability to remain functional even when the water temperature is below freezing; some use natural antifreeze or antifreeze proteins to resist ice crystal formation in their tissues. Amphibians and reptiles cope with heat gain by evaporative cooling and behavioral adaptations. An example of behavioral adaptation is that of a lizard lying in the sun on a hot rock in order to heat through radiation and conduction.  Endothermy  An endotherm is an animal that regulates its own body temperature, typically by keeping it at a constant level. To regulate body temperature, an organism may need to prevent heat gains in arid environments. Evaporation of water, either across respiratory surfaces or across the skin in those animals possessing sweat glands, helps in cooling body temperature to within the organism's tolerance range. Animals with a body covered by fur have limited ability to sweat, relying heavily on panting to increase evaporation of water across the moist surfaces of the lungs and the tongue and mouth. Mammals like cats, dogs and pigs, rely on panting or other means for thermal regulation and have sweat glands only in foot pads and snout. The sweat produced on pads of paws and on palms and soles mostly serves to increase friction and enhance grip. Birds also counteract overheating by gular fluttering, or rapid vibrations of the gular (throat) skin. Down feathers trap warm air acting as excellent insulators just as hair in mammals acts as a good insulator. Mammalian skin is much thicker than that of birds and often has a continuous layer of insulating fat beneath the dermis. In marine mammals, such as whales, or animals that live in very cold regions, such as the polar bears, this is called blubber. Dense coats found in desert endotherms also aid in preventing heat gain such as in the case of the camels. A cold weather strategy is to temporarily decrease metabolic rate, decreasing the temperature difference between the animal and the air and thereby minimizing heat loss. Furthermore, having a lower metabolic rate is less energetically expensive. Many animals survive cold frosty nights through torpor, a short-term temporary drop in body temperature. Organisms, when presented with the problem of regulating body temperature, have not only behavioural, physiological, and structural adaptations but also a feedback system to trigger these adaptations to regulate temperature accordingly. The main features of this system are stimulus, receptor, modulator, effector and then the feedback of the newly adjusted temperature to the stimulus. This cyclical process aids in homeostasis.  Homeothermy compared with poikilothermy  Homeothermy and poikilothermy refer to how stable an organism's deep-body temperature is. Most endothermic organisms are homeothermic, like mammals. However, animals with facultative endothermy are often poikilothermic, meaning their temperature can vary considerably. Most fish are ectotherms, as most of their heat comes from the surrounding water. However, almost all fish are poikilothermic.  Vertebrates  By numerous observations upon humans and other animals, John Hunter showed that the essential difference between the so-called warm-blooded and cold-blooded animals lies in observed constancy of the temperature of the former, and the observed variability of the temperature of the latter. Almost all birds and mammals have a high temperature almost constant and independent of that of the surrounding air (homeothermy). Almost all other animals display a variation of body temperature, dependent on their surroundings (poikilothermy).  Brain control  Thermoregulation in both ectotherms and endotherms is controlled mainly by the preoptic area of the anterior hypothalamus. Such homeostatic control is separate from the sensation of temperature.  In birds and mammals  In cold environments, birds and mammals employ the following adaptations and strategies to minimize heat loss: Using small smooth muscles (arrector pili in mammals), which are attached to feather or hair shafts; this distorts the surface of the skin making feather/hair shaft stand erect (called goose bumps or pimples) which slows the movement of air across the skin and minimizes heat loss. Increasing body size to more easily maintain core body temperature (warm-blooded animals in cold climates tend to be larger than similar species in warmer climates (see Bergmann's Rule)) Having the ability to store energy as fat for metabolism Have shortened extremities Have countercurrent blood flow in extremities – this is where the warm arterial blood travelling to the limb passes the cooler venous blood from the limb and heat is exchanged warming the venous blood and cooling the arterial (e.g., Arctic wolf or penguins)In warm environments, birds and mammals employ the following adaptations and strategies to maximize heat loss: Behavioural adaptations like living in burrows during the day and being nocturnal Evaporative cooling by perspiration and panting Storing fat reserves in one place (e.g., camel's hump) to avoid its insulating effect Elongated, often vascularized extremities to conduct body heat to the air  In humans  As in other mammals, thermoregulation is an important aspect of human homeostasis. Most body heat is generated in the deep organs, especially the liver, brain, and heart, and in contraction of skeletal muscles. Humans have been able to adapt to a great diversity of climates, including hot humid and hot arid. High temperatures pose serious stresses for the human body, placing it in great danger of injury or even death. For example, one of the most common reactions to hot temperatures is heat exhaustion, which is an illness that could happen if one is exposed to high temperatures, resulting in some symptoms such as dizziness, fainting, or a rapid heartbeat. For humans, adaptation to varying climatic conditions includes both physiological mechanisms resulting from evolution and behavioural mechanisms resulting from conscious cultural adaptations. The physiological control of the body's core temperature takes place primarily through the hypothalamus, which assumes the role as the body's ""thermostat"". This organ possesses control mechanisms as well as key temperature sensors, which are connected to nerve cells called thermoreceptors. Thermoreceptors come in two subcategories; ones that respond to cold temperatures and ones that respond to warm temperatures. Scattered throughout the body in both peripheral and central nervous systems, these nerve cells are sensitive to changes in temperature and are able to provide useful information to the hypothalamus through the process of negative feedback, thus maintaining a constant core temperature. There are four avenues of heat loss: evaporation, convection, conduction, and radiation. If skin temperature is greater than that of the surrounding air temperature, the body can lose heat by convection and conduction. But, if air temperature of the surroundings is greater than that of the skin, the body gains heat by convection and conduction. In such conditions, the only means by which the body can rid itself of heat is by evaporation. So, when the surrounding temperature is higher than the skin temperature, anything that prevents adequate evaporation will cause the internal body temperature to rise. During intense physical activity (e.g. sports), evaporation becomes the main avenue of heat loss. Humidity affects thermoregulation by limiting sweat evaporation and thus heat loss.  In reptiles  Thermoregulation is also an integral part of a reptile's life, specifically lizards such as the Microlophus occipitalis and Ctenophorus decresii who must change microhabitats to keep a constant body temperature. By moving to cooler areas when it is too hot and to warmer areas when it is cold, they can thermoregulate their temperature to stay within their necessary bounds.  In plants  Thermogenesis occurs in the flowers of many plants in the family Araceae as well as in cycad cones. In addition, the sacred lotus (Nelumbo nucifera) is able to thermoregulate itself, remaining on average 20 °C (36 °F) above air temperature while flowering. Heat is produced by breaking down the starch that was stored in their roots, which requires the consumption of oxygen at a rate approaching that of a flying hummingbird.One possible explanation for plant thermoregulation is to provide protection against cold temperature. For example, the skunk cabbage is not frost-resistant, yet it begins to grow and flower when there is still snow on the ground. Another theory is that thermogenicity helps attract pollinators, which is borne out by observations that heat production is accompanied by the arrival of beetles or flies.Some plants are known to protect themselves against colder temperatures using antifreeze proteins. This occurs in wheat (Triticum aestivum), potatoes (Solanum tuberosum) and several other angiosperm species.  Behavioral temperature regulation  Animals other than humans regulate and maintain their body temperature with physiological adjustments and behavior. Desert lizards are ectotherms and so unable to metabolically control their temperature but can do this by altering their location. They may do this, in the morning only by raising their head from its burrow and then exposing their entire body. By basking in the sun, the lizard absorbs solar heat. It may also absorb heat by conduction from heated rocks that have stored radiant solar energy. To lower their temperature, lizards exhibit varied behaviors. Sand seas, or ergs, produce up to 57.7 °C (135.9 °F), and the sand lizard will hold its feet up in the air to cool down, seek cooler objects with which to contact, find shade or return to their burrow. They also go to their burrows to avoid cooling when the sun goes down or the temperature falls. Aquatic animals can also regulate their temperature behaviorally by changing their position in the thermal gradient. Sprawling prone in a cool shady spot, ""splooting,"" has been observed in squirrels on hot days. Animals also engage in kleptothermy in which they share or even steal each other's body warmth. In endotherms such as bats and birds (such as the mousebird and emperor penguin) it allows the sharing of body heat (particularly amongst juveniles). This allows the individuals to increase their thermal inertia (as with gigantothermy) and so reduce heat loss. Some ectotherms share burrows of ectotherms. Other animals exploit termite mounds.Some animals living in cold environments maintain their body temperature by preventing heat loss. Their fur grows more densely to increase the amount of insulation. Some animals are regionally heterothermic and are able to allow their less insulated extremities to cool to temperatures much lower than their core temperature—nearly to 0 °C (32 °F). This minimizes heat loss through less insulated body parts, like the legs, feet (or hooves), and nose. Different species of Sonoran Desert Drosophila will exploit different species of cacti based on the thermotolerance differences between species and hosts. For example, Drosophila mettleri is found in cacti like the Saguaro and Senita; these two cacti remain cool by storing water. Over time, the genes selecting for higher heat tolerance were reduced in the population due to the cooler host climate the fly is able to exploit. Some flies, such as Lucilia sericata, lay their eggs en masse. The resulting group of larvae, depending on its size, is able to thermoregulate and keep itself at the optimum temperature for development.  Hibernation, estivation and daily torpor  To cope with limited food resources and low temperatures, some mammals hibernate during cold periods. To remain in ""stasis"" for long periods, these animals build up brown fat reserves and slow all body functions. True hibernators (e.g., groundhogs) keep their body temperatures low throughout hibernation whereas the core temperature of false hibernators (e.g., bears) varies; occasionally the animal may emerge from its den for brief periods. Some bats are true hibernators and rely upon a rapid, non-shivering thermogenesis of their brown fat deposit to bring them out of hibernation.Estivation is similar to hibernation, however, it usually occurs in hot periods to allow animals to avoid high temperatures and desiccation. Both terrestrial and aquatic invertebrate and vertebrates enter into estivation. Examples include lady beetles (Coccinellidae), North American desert tortoises, crocodiles, salamanders, cane toads, and the water-holding frog.Daily torpor occurs in small endotherms like bats and hummingbirds, which temporarily reduces their high metabolic rates to conserve energy.  Variation in animals   Normal human temperature  Previously, average oral temperature for healthy adults had been considered 37.0 °C (98.6 °F), while normal ranges are 36.1 to 37.8 °C (97.0 to 100.0 °F). In Poland and Russia, the temperature had been measured axillarily (under the arm). 36.6 °C (97.9 °F) was considered ""ideal"" temperature in these countries, while normal ranges are 36.0 to 36.9 °C (96.8 to 98.4 °F).Recent studies suggest that the average temperature for healthy adults is 36.8 °C (98.2 °F) (same result in three different studies). Variations (one standard deviation) from three other studies are: 36.4–37.1 °C (97.5–98.8 °F) 36.3–37.1 °C (97.3–98.8 °F) for males,36.5–37.3 °C (97.7–99.1 °F) for females 36.6–37.3 °C (97.9–99.1 °F)Measured temperature varies according to thermometer placement, with rectal temperature being 0.3–0.6 °C (0.5–1.1 °F) higher than oral temperature, while axillary temperature is 0.3–0.6 °C (0.5–1.1 °F) lower than oral temperature. The average difference between oral and axillary temperatures of Indian children aged 6–12 was found to be only 0.1 °C (standard deviation 0.2 °C), and the mean difference in Maltese children aged 4–14 between oral and axillary temperature was 0.56 °C, while the mean difference between rectal and axillary temperature for children under 4 years old was 0.38 °C.  Variations due to circadian rhythms  In humans, a diurnal variation has been observed dependent on the periods of rest and activity, lowest at 11 p.m. to 3 a.m. and peaking at 10 a.m. to 6 p.m. Monkeys also have a well-marked and regular diurnal variation of body temperature that follows periods of rest and activity, and is not dependent on the incidence of day and night; nocturnal monkeys reach their highest body temperature at night and lowest during the day. Sutherland Simpson and J.J. Galbraith observed that all nocturnal animals and birds – whose periods of rest and activity are naturally reversed through habit and not from outside interference – experience their highest temperature during the natural period of activity (night) and lowest during the period of rest (day). Those diurnal temperatures can be reversed by reversing their daily routine.In essence, the temperature curve of diurnal birds is similar to that of humans and other homoeothermic animals, except that the maximum occurs earlier in the afternoon and the minimum earlier in the morning. Also, the curves obtained from rabbits, guinea pigs, and dogs were quite similar to those from humans. These observations indicate that body temperature is partially regulated by circadian rhythms.  Variations due to human menstrual cycles  During the follicular phase (which lasts from the first day of menstruation until the day of ovulation), the average basal body temperature in women ranges from 36.45 to 36.7 °C (97.61 to 98.06 °F). Within 24 hours of ovulation, women experience an elevation of 0.15–0.45 °C (0.27–0.81 °F) due to the increased metabolic rate caused by sharply elevated levels of progesterone. The basal body temperature ranges between 36.7–37.3 °C (98.1–99.1 °F) throughout the luteal phase, and drops down to pre-ovulatory levels within a few days of menstruation. Women can chart this phenomenon to determine whether and when they are ovulating, so as to aid conception or contraception.  Variations due to fever  Fever is a regulated elevation of the set point of core temperature in the hypothalamus, caused by circulating pyrogens produced by the immune system. To the subject, a rise in core temperature due to fever may result in feeling cold in an environment where people without fever do not.  Variations due to biofeedback  Some monks are known to practice Tummo, biofeedback meditation techniques, that allow them to raise their body temperatures substantially.  Effect on lifespan  The effects of such a genetic change in body temperature on longevity is difficult to study in humans.  Limits compatible with life  There are limits both of heat and cold that an endothermic animal can bear and other far wider limits that an ectothermic animal may endure and yet live. The effect of too extreme a cold is to decrease metabolism, and hence to lessen the production of heat. Both catabolic and anabolic pathways share in this metabolic depression, and, though less energy is used up, still less energy is generated. The effects of this diminished metabolism become telling on the central nervous system first, especially the brain and those parts concerning consciousness; both heart rate and respiration rate decrease; judgment becomes impaired as drowsiness supervenes, becoming steadily deeper until the individual loses consciousness; without medical intervention, death by hypothermia quickly follows. Occasionally, however, convulsions may set in towards the end, and death is caused by asphyxia.In experiments on cats performed by Sutherland Simpson and Percy T. Herring, the animals were unable to survive when rectal temperature fell below 16 °C (61 °F). At this low temperature, respiration became increasingly feeble; heart-impulse usually continued after respiration had ceased, the beats becoming very irregular, appearing to cease, then beginning again. Death appeared to be mainly due to asphyxia, and the only certain sign that it had taken place was the loss of knee-jerks.However, too high a temperature speeds up the metabolism of different tissues to such a rate that their metabolic capital is soon exhausted. Blood that is too warm produces dyspnea by exhausting the metabolic capital of the respiratory centre; heart rate is increased; the beats then become arrhythmic and eventually cease. The central nervous system is also profoundly affected by hyperthermia and delirium, and convulsions may set in. Consciousness may also be lost, propelling the person into a comatose condition. These changes can sometimes also be observed in patients experiencing an acute fever. Mammalian muscle becomes rigid with heat rigor at about 50 °C, with the sudden rigidity of the whole body rendering life impossible.H.M. Vernon performed work on the death temperature and paralysis temperature (temperature of heat rigor) of various animals. He found that species of the same class showed very similar temperature values, those from the Amphibia examined being 38.5 °C, fish 39 °C, reptiles 45 °C, and various molluscs 46 °C. Also, in the case of pelagic animals, he showed a relation between death temperature and the quantity of solid constituents of the body. In higher animals, however, his experiments tend to show that there is greater variation in both the chemical and physical characteristics of the protoplasm and, hence, greater variation in the extreme temperature compatible with life.  Arthropoda  The maximum temperatures tolerated by certain thermophilic arthropods exceeds the lethal temperatures for most vertebrates.The most heat-resistant insects are three genera of desert ants recorded from three different parts of the world. The ants have developed a lifestyle of scavenging for short durations during the hottest hours of the day, in excess of 50 °C (122 °F), for the carcasses of insects and other forms of life which have died from heat stress.In April 2014, the South Californian mite Paratarsotomus macropalpis has been recorded as the world's fastest land animal relative to body length, at a speed of 322 body lengths per second. Besides the unusually great speed of the mites, the researchers were surprised to find the mites running at such speeds on concrete at temperatures up to 60 °C (140 °F), which is significant because this temperature is well above the lethal limit for the majority of animal species. In addition, the mites are able to stop and change direction very quickly.Spiders like Nephila pilipes exhibits active thermal regulation behavior. During high temperature sunny days, it aligns its body with the direction of sunlight to reduce the body area under direct sunlight.  See also  Human body temperature Innate heat Insect thermoregulation Thermal neutral zone Thermoregulation in birds  References   Further reading   External links  Australian Government Bureau of Meteorology. Thermal Comfort Observations. Retrieved 28 January 2013. Royal Institution Christmas Lectures 1998 Archived 29 March 2015 at the Wayback Machine Wong, Lena (1997). ""Temperature of a Healthy Human (Body Temperature)"". The Physics Factbook. Archived from the original on 26 September 2010. Retrieved 24 October 2013. Thermoregulation at the U.S. National Library of Medicine Medical Subject Headings (MeSH)","Thermoregulation is the ability of an organism to control its body temperature within certain limits, even when the surrounding temperature is different. This is an aspect of homeostasis: the keeping of a constant internal environment.  Endotherms  So-called warm-blooded animals control the temperature of their body at quite a high level. This ability is called endothermy. All mammals and birds are endotherms (homeotherms or homoiotherms). The basic source of the heat is chemical energy from the body's metabolism. They have a number of temperature-control devices: When they are cold they can do things to make themselves warmer. For example, they ""shiver"", or shake, or run about, or move into a warmer place. This is because all movement by animals creates heat from the chemical reactions of respiration. So polar bears do not freeze because their metabolism produces heat, and movement produces more heat. During hibernation bears exist several degrees lower that they do in active life. Of course, warm-blooded animals have thermal insulation: hair, feathers, or in water blubber (thick fat). These adaptations help keep heat energy inside the animal. When they are warm they sweat to become cooler, or pant, or open their feathers, or move to a less hot place and lie down.  Hibernation  In the colder climates many mammals hibernate or aestivate. This means they have a two-level metabolism. Their temperature is held at a high level when they are active, and at a lower level when they are hibernating. This has the advantage of saving energy during times when they cannot get enough food to keep up the higher temperature.  Humans  The human body has automatic responses to help regulate temperature. When the external environment heats up, arterioles leading to the capillary loops in the dermis dilate (widen). This increases blood flow to the surface of the skin where its heat can more easily radiate away. This process is called vasodilation. Sweat glands also produce greater amounts of sweat. This liquid is secreted onto the surface of the skin. Sweat needs energy to turn from a liquid into a gas and evaporate. This energy is called the latent heat of vaporisation. The body supplies this heat and so it cools down as the sweat evaporates.If the body is unable to maintain a normal temperature and it increases significantly above normal, a condition known as hyperthermia occurs. This occurs when the body is exposed to temperatures of approximately 55 °C; any exposure longer than a few hours at this temperature or up to around 70 °C kills. The opposite condition, when body temperature decreases below normal levels, is known as hypothermia.  Fossil groups  Palaeontologists are fairly certain that some fossil groups were endotherms. Obvious examples are pterosaurs, whose bodies were covered by hair (or hair-like filaments), and the smaller carnivorous dinosaurs which evolved feathers (""dinobirds""). It is thought that feathers originally functioned to keep body temperature higher. They appear on bird-like dinosaurs before there were any flying birds (Anchiornis huxlei), and they appear on dinosaurs which are too heavy to fly at all.  Heterotherms  Heterothermy is a term for animals that have features of both ectothermy and endothermy. They can switch between strategies.  Basic physiology  The fundamental idea is that smaller endothermic animals have, relative to their mass, a larger body surface. ""Heat loss takes place from the surface, and in order to keep warm, an animal must produce heat at a rate equal to its loss"".Animals 'make' heat by the metabolism inside their bodies, but lose heat through their surface (mostly their skin). Now, their bodies are three-dimensional, whereas their surface is two-dimensional. So, if an animal of length X doubles its length, then its surface area increases by about X2, but its body mass increases by about X3. Example: A three-inch-long animal doubles its length to six inches. As a result, its surface area increases in proportion 3x3  9 square inches. Its body mass increases in proportion 3x3x3  27 cubic inches. Since energy production is related to body mass, the animal is better off in its energy balance.Thus larger animals are much more ""energy efficient"" than smaller animals. Large animals lose heat relatively slower than small animals because their surface area is smaller in proportion.  Strategies for small animals  Small warm-blooded animals have three main tactics for overcoming this problem of heat loss. First, they have a higher metabolic rate than large animals. This is universal in birds and mammals: only the details differ. A higher metabolic rate affects the whole of their lives, and is the main reason why they have shorter lives than large animals.p58/9 The smallest mammals (shrews) and the smallest hummingbirds are about the same size and weight. They have fast heartbeats, up to 1,200 per minute,p129 and they use up more calories per gram than any other endotherms. The rate of oxygen use is similarly high. As a result of the metabolism running at such a high rate, they do produce more heat per gram than any other living things. Second, many allow their temperature to drop at night. Many hummingbirds go into a trance-like torpor at night. ""One bird... increased its heart rate [in the morning] from about 150 beats per minute at 21 degrees C to over 1000 beats per minute at 36 degrees C"".In that state, they are less aware and less able to take flight, so there is a greater risk of predators. However, when they are asleep they cannot feed, and at their normal rate of metabolism they need sugar regularly. The torpor is their way of saving energy which they cannot replace until the next day. Thirdly, almost all endotherms are insulated to reduce heat loss. Obviously that is true of birds (which have feathers) and land mammals (which have fur). Marine mammals have thick layers of fat under their skin, which is better insulation than wet fur. The exceptions are some very large mammals such as elephants, which have almost no fur. Their problem is how to get rid of heat, and that is a problem for all really large land animals. The African elephant's solution is to have large ears, which are well supplied with blood vessels, and to wallow in water if that is available. It is very likely that the same problem affected large dinosaurs. After all, the largest titanosaurs were far larger than any land animal alive today.  Ectotherms  Ectotherms are what is often called ""cold-blooded"". To function properly they need some heat, and usually this is heat from their surroundings. Many need heat in order to digest their food.Many supposedly cold-blooded animals do things to keep their temperature higher than the surrounding air or water. Fast-moving fish, like tunny, and some sharks, keep their temperature above the level of the surrounding water. Reptiles such as lizards and snakes sit in the sun when they are cold and in the shade when they are hot. Some insects control their temperature, especially colonial insects. Termite mounds have 'air conditioning': their system of openings and galleries allows currents of air to flow through the mound. Honey bees fan their wings to cool their colony. However, many smaller invertebrates do not control their body temperature at all.  Variable temperature  An animal whose internal temperature varies considerably. is a poikilotherm (noun), poikilothermic (adjective). The term is preferred to cold-blooded by some scientists.  References   Further reading  Schmidt-Nielsen, Knut 1972. How animals work. Cambridge University Press. ISBN 0-521-09692-8. Basic information on heat balance and heat exchange in animals."
"In biology, homeostasis (British also homoeostasis) (/hɒmɪə(ʊ)ˈsteɪsɪs/) is the state of steady internal, physical, chemical, and social conditions maintained by living systems. This is the condition of optimal functioning for the organism and includes many variables, such as body temperature and fluid balance, being kept within certain pre-set limits (homeostatic range). Other variables include the pH of extracellular fluid, the concentrations of sodium, potassium, and calcium ions, as well as the blood sugar level, and these need to be regulated despite changes in the environment, diet, or level of activity. Each of these variables is controlled by one or more regulators or homeostatic mechanisms, which together maintain life. Homeostasis is brought about by a natural resistance to change when already in optimal conditions, and equilibrium is maintained by many regulatory mechanisms; it is thought to be the central motivation for all organic action. All homeostatic control mechanisms have at least three interdependent components for the variable being regulated: a receptor, a control center, and an effector. The receptor is the sensing component that monitors and responds to changes in the environment, either external or internal. Receptors include thermoreceptors and mechanoreceptors. Control centers include the respiratory center and the renin-angiotensin system. An effector is the target acted on, to bring about the change back to the normal state. At the cellular level, effectors include nuclear receptors that bring about changes in gene expression through up-regulation or down-regulation and act in negative feedback mechanisms. An example of this is in the control of bile acids in the liver.Some centers, such as the renin–angiotensin system, control more than one variable. When the receptor senses a stimulus, it reacts by sending action potentials to a control center. The control center sets the maintenance range—the acceptable upper and lower limits—for the particular variable, such as temperature. The control center responds to the signal by determining an appropriate response and sending signals to an effector, which can be one or more muscles, an organ, or a gland. When the signal is received and acted on, negative feedback is provided to the receptor that stops the need for further signaling.The cannabinoid receptor type 1 (CB1), located at the presynaptic neuron, is a receptor that can stop stressful neurotransmitter release to the postsynaptic neuron; it is activated by endocannabinoids (ECs) such as anandamide (N-arachidonoylethanolamide; AEA) and 2-arachidonoylglycerol (2-AG) via a retrograde signaling process in which these compounds are synthesized by and released from postsynaptic neurons, and travel back to the presynaptic terminal to bind to the CB1 receptor for modulation of neurotransmitter release to obtain homeostasis.The polyunsaturated fatty acids (PUFAs) are lipid derivatives of omega-3 (docosahexaenoic acid, DHA, and eicosapentaenoic acid, EPA) or of omega-6 (arachidonic acid, ARA) are synthesized from membrane phospholipids and used as a precursor for endocannabinoids (ECs) mediate significant effects in the fine-tuning adjustment of body homeostasis.  Etymology  The word homeostasis () uses combining forms of homeo- and -stasis, Neo-Latin from Greek: ὅμοιος homoios, ""similar"" and στάσις stasis, ""standing still"", yielding the idea of ""staying the same"".  History  The concept of the regulation of the internal environment was described by French physiologist Claude Bernard in 1849, and the word homeostasis was coined by Walter Bradford Cannon in 1926. In 1932, Joseph Barcroft a British physiologist, was the first to say that higher brain function required the most stable internal environment. Thus, to Barcroft homeostasis was not only organized by the brain—homeostasis served the brain. Homeostasis is an almost exclusively biological term, referring to the concepts described by Bernard and Cannon, concerning the constancy of the internal environment in which the cells of the body live and survive. The term cybernetics is applied to technological control systems such as thermostats, which function as homeostatic mechanisms but are often defined much more broadly than the biological term of homeostasis.  Overview  The metabolic processes of all organisms can only take place in very specific physical and chemical environments. The conditions vary with each organism, and with whether the chemical processes take place inside the cell or in the interstitial fluid bathing the cells. The best-known homeostatic mechanisms in humans and other mammals are regulators that keep the composition of the extracellular fluid (or the ""internal environment"") constant, especially with regard to the temperature, pH, osmolality, and the concentrations of sodium, potassium, glucose, carbon dioxide, and oxygen. However, a great many other homeostatic mechanisms, encompassing many aspects of human physiology, control other entities in the body. Where the levels of variables are higher or lower than those needed, they are often prefixed with hyper- and hypo-, respectively such as hyperthermia and hypothermia or hypertension and hypotension. If an entity is homeostatically controlled it does not imply that its value is necessarily absolutely steady in health. Core body temperature is, for instance, regulated by a homeostatic mechanism with temperature sensors in, amongst others, the hypothalamus of the brain. However, the set point of the regulator is regularly reset. For instance, core body temperature in humans varies during the course of the day (i.e. has a circadian rhythm), with the lowest temperatures occurring at night, and the highest in the afternoons. Other normal temperature variations include those related to the menstrual cycle. The temperature regulator's set point is reset during infections to produce a fever. Organisms are capable of adjusting somewhat to varied conditions such as temperature changes or oxygen levels at altitude, by a process of acclimatisation. Homeostasis does not govern every activity in the body. For instance, the signal (be it via neurons or hormones) from the sensor to the effector is, of necessity, highly variable in order to convey information about the direction and magnitude of the error detected by the sensor. Similarly, the effector's response needs to be highly adjustable to reverse the error – in fact it should be very nearly in proportion (but in the opposite direction) to the error that is threatening the internal environment. For instance, arterial blood pressure in mammals is homeostatically controlled and measured by stretch receptors in the walls of the aortic arch and carotid sinuses at the beginnings of the internal carotid arteries. The sensors send messages via sensory nerves to the medulla oblongata of the brain indicating whether the blood pressure has fallen or risen, and by how much. The medulla oblongata then distributes messages along motor or efferent nerves belonging to the autonomic nervous system to a wide variety of effector organs, whose activity is consequently changed to reverse the error in the blood pressure. One of the effector organs is the heart whose rate is stimulated to rise (tachycardia) when the arterial blood pressure falls, or to slow down (bradycardia) when the pressure rises above the set point. Thus the heart rate (for which there is no sensor in the body) is not homeostatically controlled but is one of the effector responses to errors in arterial blood pressure. Another example is the rate of sweating. This is one of the effectors in the homeostatic control of body temperature, and therefore highly variable in rough proportion to the heat load that threatens to destabilize the body's core temperature, for which there is a sensor in the hypothalamus of the brain.  Controls of variables   Core temperature  Mammals regulate their core temperature using input from thermoreceptors in the hypothalamus, brain, spinal cord, internal organs, and great veins. Apart from the internal regulation of temperature, a process called allostasis can come into play that adjusts behaviour to adapt to the challenge of very hot or cold extremes (and to other challenges). These adjustments may include seeking shade and reducing activity, seeking warmer conditions and increasing activity, or huddling. Behavioral thermoregulation takes precedence over physiological thermoregulation since necessary changes can be affected more quickly and physiological thermoregulation is limited in its capacity to respond to extreme temperatures.When the core temperature falls, the blood supply to the skin is reduced by intense vasoconstriction. The blood flow to the limbs (which have a large surface area) is similarly reduced and returned to the trunk via the deep veins which lie alongside the arteries (forming venae comitantes). This acts as a counter-current exchange system that short-circuits the warmth from the arterial blood directly into the venous blood returning into the trunk, causing minimal heat loss from the extremities in cold weather. The subcutaneous limb veins are tightly constricted, not only reducing heat loss from this source but also forcing the venous blood into the counter-current system in the depths of the limbs. The metabolic rate is increased, initially by non-shivering thermogenesis, followed by shivering thermogenesis if the earlier reactions are insufficient to correct the hypothermia. When core temperature rises are detected by thermoreceptors, the sweat glands in the skin are stimulated via cholinergic sympathetic nerves to secrete sweat onto the skin, which, when it evaporates, cools the skin and the blood flowing through it. Panting is an alternative effector in many vertebrates, which cools the body also by the evaporation of water, but this time from the mucous membranes of the throat and mouth.  Blood glucose  Blood sugar levels are regulated within fairly narrow limits. In mammals, the primary sensors for this are the beta cells of the pancreatic islets. The beta cells respond to a rise in the blood sugar level by secreting insulin into the blood and simultaneously inhibiting their neighboring alpha cells from secreting glucagon into the blood. This combination (high blood insulin levels and low glucagon levels) act on effector tissues, the chief of which is the liver, fat cells, and muscle cells. The liver is inhibited from producing glucose, taking it up instead, and converting it to glycogen and triglycerides. The glycogen is stored in the liver, but the triglycerides are secreted into the blood as very low-density lipoprotein (VLDL) particles which are taken up by adipose tissue, there to be stored as fats. The fat cells take up glucose through special glucose transporters (GLUT4), whose numbers in the cell wall are increased as a direct effect of insulin acting on these cells. The glucose that enters the fat cells in this manner is converted into triglycerides (via the same metabolic pathways as are used by the liver) and then stored in those fat cells together with the VLDL-derived triglycerides that were made in the liver. Muscle cells also take glucose up through insulin-sensitive GLUT4 glucose channels, and convert it into muscle glycogen.A fall in blood glucose, causes insulin secretion to be stopped, and glucagon to be secreted from the alpha cells into the blood. This inhibits the uptake of glucose from the blood by the liver, fats cells, and muscle. Instead the liver is strongly stimulated to manufacture glucose from glycogen (through glycogenolysis) and from non-carbohydrate sources (such as lactate and de-aminated amino acids) using a process known as gluconeogenesis. The glucose thus produced is discharged into the blood correcting the detected error (hypoglycemia). The glycogen stored in muscles remains in the muscles, and is only broken down, during exercise, to glucose-6-phosphate and thence to pyruvate to be fed into the citric acid cycle or turned into lactate. It is only the lactate and the waste products of the citric acid cycle that are returned to the blood. The liver can take up only the lactate, and, by the process of energy-consuming gluconeogenesis, convert it back to glucose.  Iron levels  Controlling iron levels in the body is a critically important part of many aspects of human health and disease. In humans iron is both necessary to the body and potentially harmful.  Copper regulation  Copper is absorbed, transported, distributed, stored, and excreted in the body according to complex homeostatic processes which ensure a constant and sufficient supply of the micronutrient while simultaneously avoiding excess levels. If an insufficient amount of copper is ingested for a short period of time, copper stores in the liver will be depleted. Should this depletion continue, a copper health deficiency condition may develop. If too much copper is ingested, an excess condition can result. Both of these conditions, deficiency and excess, can lead to tissue injury and disease. However, due to homeostatic regulation, the human body is capable of balancing a wide range of copper intakes for the needs of healthy individuals. Many aspects of copper homeostasis are known at the molecular level. Copper's essentiality is due to its ability to act as an electron donor or acceptor as its oxidation state fluxes between Cu1+(cuprous) and Cu2+ (cupric). As a component of about a dozen cuproenzymes, copper is involved in key redox (i.e., oxidation-reduction) reactions in essential metabolic processes such as mitochondrial respiration, synthesis of melanin, and cross-linking of collagen. Copper is an integral part of the antioxidant enzyme copper-zinc superoxide dismutase, and has a role in iron homeostasis as a cofactor in ceruloplasmin.  Levels of blood gases  Changes in the levels of oxygen, carbon dioxide, and plasma pH are sent to the respiratory center, in the brainstem where they are regulated. The partial pressure of oxygen and carbon dioxide in the arterial blood is monitored by the peripheral chemoreceptors (PNS) in the carotid artery and aortic arch. A change in the partial pressure of carbon dioxide is detected as altered pH in the cerebrospinal fluid by central chemoreceptors (CNS) in the medulla oblongata of the brainstem. Information from these sets of sensors is sent to the respiratory center which activates the effector organs – the diaphragm and other muscles of respiration. An increased level of carbon dioxide in the blood, or a decreased level of oxygen, will result in a deeper breathing pattern and increased respiratory rate to bring the blood gases back to equilibrium. Too little carbon dioxide, and, to a lesser extent, too much oxygen in the blood can temporarily halt breathing, a condition known as apnea, which freedivers use to prolong the time they can stay underwater. The partial pressure of carbon dioxide is more of a deciding factor in the monitoring of pH. However, at high altitude (above 2500 m) the monitoring of the partial pressure of oxygen takes priority, and hyperventilation keeps the oxygen level constant. With the lower level of carbon dioxide, to keep the pH at 7.4 the kidneys secrete hydrogen ions into the blood and excrete bicarbonate into the urine. This is important in acclimatization to high altitude.  Blood oxygen content  The kidneys measure the oxygen content rather than the partial pressure of oxygen in the arterial blood. When the oxygen content of the blood is chronically low, oxygen-sensitive cells secrete erythropoietin (EPO) into the blood. The effector tissue is the red bone marrow which produces red blood cells (RBCs)(erythrocytes). The increase in RBCs leads to an increased hematocrit in the blood, and a subsequent increase in hemoglobin that increases the oxygen carrying capacity. This is the mechanism whereby high altitude dwellers have higher hematocrits than sea-level residents, and also why persons with pulmonary insufficiency or right-to-left shunts in the heart (through which venous blood by-passes the lungs and goes directly into the systemic circulation) have similarly high hematocrits.Regardless of the partial pressure of oxygen in the blood, the amount of oxygen that can be carried, depends on the hemoglobin content. The partial pressure of oxygen may be sufficient for example in anemia, but the hemoglobin content will be insufficient and subsequently as will be the oxygen content. Given enough supply of iron, vitamin B12 and folic acid, EPO can stimulate RBC production, and hemoglobin and oxygen content restored to normal.  Arterial blood pressure  The brain can regulate blood flow over a range of blood pressure values by vasoconstriction and vasodilation of the arteries.High pressure receptors called baroreceptors in the walls of the aortic arch and carotid sinus (at the beginning of the internal carotid artery) monitor the arterial blood pressure. Rising pressure is detected when the walls of the arteries stretch due to an increase in blood volume. This causes heart muscle cells to secrete the hormone atrial natriuretic peptide (ANP) into the blood. This acts on the kidneys to inhibit the secretion of renin and aldosterone causing the release of sodium, and accompanying water into the urine, thereby reducing the blood volume. This information is then conveyed, via afferent nerve fibers, to the solitary nucleus in the medulla oblongata. From here motor nerves belonging to the autonomic nervous system are stimulated to influence the activity of chiefly the heart and the smallest diameter arteries, called arterioles. The arterioles are the main resistance vessels in the arterial tree, and small changes in diameter cause large changes in the resistance to flow through them. When the arterial blood pressure rises the arterioles are stimulated to dilate making it easier for blood to leave the arteries, thus deflating them, and bringing the blood pressure down, back to normal. At the same time, the heart is stimulated via cholinergic parasympathetic nerves to beat more slowly (called bradycardia), ensuring that the inflow of blood into the arteries is reduced, thus adding to the reduction in pressure, and correcting the original error. Low pressure in the arteries, causes the opposite reflex of constriction of the arterioles, and a speeding up of the heart rate (called tachycardia). If the drop in blood pressure is very rapid or excessive, the medulla oblongata stimulates the adrenal medulla, via ""preganglionic"" sympathetic nerves, to secrete epinephrine (adrenaline) into the blood. This hormone enhances the tachycardia and causes severe vasoconstriction of the arterioles to all but the essential organ in the body (especially the heart, lungs, and brain). These reactions usually correct the low arterial blood pressure (hypotension) very effectively.  Calcium levels  The plasma ionized calcium (Ca2+) concentration is very tightly controlled by a pair of homeostatic mechanisms. The sensor for the first one is situated in the parathyroid glands, where the chief cells sense the Ca2+ level by means of specialized calcium receptors in their membranes. The sensors for the second are the parafollicular cells in the thyroid gland. The parathyroid chief cells secrete parathyroid hormone (PTH) in response to a fall in the plasma ionized calcium level; the parafollicular cells of the thyroid gland secrete calcitonin in response to a rise in the plasma ionized calcium level. The effector organs of the first homeostatic mechanism are the bones, the kidney, and, via a hormone released into the blood by the kidney in response to high PTH levels in the blood, the duodenum and jejunum. Parathyroid hormone (in high concentrations in the blood) causes bone resorption, releasing calcium into the plasma. This is a very rapid action which can correct a threatening hypocalcemia within minutes. High PTH concentrations cause the excretion of phosphate ions via the urine. Since phosphates combine with calcium ions to form insoluble salts (see also bone mineral), a decrease in the level of phosphates in the blood, releases free calcium ions into the plasma ionized calcium pool. PTH has a second action on the kidneys. It stimulates the manufacture and release, by the kidneys, of calcitriol into the blood. This steroid hormone acts on the epithelial cells of the upper small intestine, increasing their capacity to absorb calcium from the gut contents into the blood.The second homeostatic mechanism, with its sensors in the thyroid gland, releases calcitonin into the blood when the blood ionized calcium rises. This hormone acts primarily on bone, causing the rapid removal of calcium from the blood and depositing it, in insoluble form, in the bones.The two homeostatic mechanisms working through PTH on the one hand, and calcitonin on the other can very rapidly correct any impending error in the plasma ionized calcium level by either removing calcium from the blood and depositing it in the skeleton, or by removing calcium from it. The skeleton acts as an extremely large calcium store (about 1 kg) compared with the plasma calcium store (about 180 mg). Longer term regulation occurs through calcium absorption or loss from the gut. Another example are the most well-characterised endocannabinoids like anandamide (N-arachidonoylethanolamide; AEA) and 2-arachidonoylglycerol (2-AG), whose synthesis occurs through the action of a series of intracellular enzymes activated in response to a rise in intracellular calcium levels to introduce homeostasis and prevention of tumor development through putative protective mechanisms that prevent cell growth and migration by activation of CB1 and/or CB2 and adjoining receptors.  Sodium concentration  The homeostatic mechanism which controls the plasma sodium concentration is rather more complex than most of the other homeostatic mechanisms described on this page. The sensor is situated in the juxtaglomerular apparatus of kidneys, which senses the plasma sodium concentration in a surprisingly indirect manner. Instead of measuring it directly in the blood flowing past the juxtaglomerular cells, these cells respond to the sodium concentration in the renal tubular fluid after it has already undergone a certain amount of modification in the proximal convoluted tubule and loop of Henle. These cells also respond to rate of blood flow through the juxtaglomerular apparatus, which, under normal circumstances, is directly proportional to the arterial blood pressure, making this tissue an ancillary arterial blood pressure sensor. In response to a lowering of the plasma sodium concentration, or to a fall in the arterial blood pressure, the juxtaglomerular cells release renin into the blood. Renin is an enzyme which cleaves a decapeptide (a short protein chain, 10 amino acids long) from a plasma α-2-globulin called angiotensinogen. This decapeptide is known as angiotensin I. It has no known biological activity. However, when the blood circulates through the lungs a pulmonary capillary endothelial enzyme called angiotensin-converting enzyme (ACE) cleaves a further two amino acids from angiotensin I to form an octapeptide known as angiotensin II. Angiotensin II is a hormone which acts on the adrenal cortex, causing the release into the blood of the steroid hormone, aldosterone. Angiotensin II also acts on the smooth muscle in the walls of the arterioles causing these small diameter vessels to constrict, thereby restricting the outflow of blood from the arterial tree, causing the arterial blood pressure to rise. This, therefore, reinforces the measures described above (under the heading of ""Arterial blood pressure""), which defend the arterial blood pressure against changes, especially hypotension. The angiotensin II-stimulated aldosterone released from the zona glomerulosa of the adrenal glands has an effect on particularly the epithelial cells of the distal convoluted tubules and collecting ducts of the kidneys. Here it causes the reabsorption of sodium ions from the renal tubular fluid, in exchange for potassium ions which are secreted from the blood plasma into the tubular fluid to exit the body via the urine. The reabsorption of sodium ions from the renal tubular fluid halts further sodium ion losses from the body, and therefore preventing the worsening of hyponatremia. The hyponatremia can only be corrected by the consumption of salt in the diet. However, it is not certain whether a ""salt hunger"" can be initiated by hyponatremia, or by what mechanism this might come about. When the plasma sodium ion concentration is higher than normal (hypernatremia), the release of renin from the juxtaglomerular apparatus is halted, ceasing the production of angiotensin II, and its consequent aldosterone-release into the blood. The kidneys respond by excreting sodium ions into the urine, thereby normalizing the plasma sodium ion concentration. The low angiotensin II levels in the blood lower the arterial blood pressure as an inevitable concomitant response. The reabsorption of sodium ions from the tubular fluid as a result of high aldosterone levels in the blood does not, of itself, cause renal tubular water to be returned to the blood from the distal convoluted tubules or collecting ducts. This is because sodium is reabsorbed in exchange for potassium and therefore causes only a modest change in the osmotic gradient between the blood and the tubular fluid. Furthermore, the epithelium of the distal convoluted tubules and collecting ducts is impermeable to water in the absence of antidiuretic hormone (ADH) in the blood. ADH is part of the control of fluid balance. Its levels in the blood vary with the osmolality of the plasma, which is measured in the hypothalamus of the brain. Aldosterone's action on the kidney tubules prevents sodium loss to the extracellular fluid (ECF). So there is no change in the osmolality of the ECF, and therefore no change in the ADH concentration of the plasma. However, low aldosterone levels cause a loss of sodium ions from the ECF, which could potentially cause a change in extracellular osmolality and therefore of ADH levels in the blood.  Potassium concentration  High potassium concentrations in the plasma cause depolarization of the zona glomerulosa cells' membranes in the outer layer of the adrenal cortex. This causes the release of aldosterone into the blood. Aldosterone acts primarily on the distal convoluted tubules and collecting ducts of the kidneys, stimulating the excretion of potassium ions into the urine. It does so, however, by activating the basolateral Na+/K+ pumps of the tubular epithelial cells. These sodium/potassium exchangers pump three sodium ions out of the cell, into the interstitial fluid and two potassium ions into the cell from the interstitial fluid. This creates an ionic concentration gradient which results in the reabsorption of sodium (Na+) ions from the tubular fluid into the blood, and secreting potassium (K+) ions from the blood into the urine (lumen of collecting duct).  Fluid balance  The total amount of water in the body needs to be kept in balance. Fluid balance involves keeping the fluid volume stabilized, and also keeping the levels of electrolytes in the extracellular fluid stable. Fluid balance is maintained by the process of osmoregulation and by behavior. Osmotic pressure is detected by osmoreceptors in the median preoptic nucleus in the hypothalamus. Measurement of the plasma osmolality to give an indication of the water content of the body, relies on the fact that water losses from the body, (through unavoidable water loss through the skin which is not entirely waterproof and therefore always slightly moist, water vapor in the exhaled air, sweating, vomiting, normal feces and especially diarrhea) are all hypotonic, meaning that they are less salty than the body fluids (compare, for instance, the taste of saliva with that of tears. The latter has almost the same salt content as the extracellular fluid, whereas the former is hypotonic with respect to the plasma. Saliva does not taste salty, whereas tears are decidedly salty). Nearly all normal and abnormal losses of body water therefore cause the extracellular fluid to become hypertonic. Conversely, excessive fluid intake dilutes the extracellular fluid causing the hypothalamus to register hypotonic hyponatremia conditions. When the hypothalamus detects a hypertonic extracellular environment, it causes the secretion of an antidiuretic hormone (ADH) called vasopressin which acts on the effector organ, which in this case is the kidney. The effect of vasopressin on the kidney tubules is to reabsorb water from the distal convoluted tubules and collecting ducts, thus preventing aggravation of the water loss via the urine. The hypothalamus simultaneously stimulates the nearby thirst center causing an almost irresistible (if the hypertonicity is severe enough) urge to drink water. The cessation of urine flow prevents the hypovolemia and hypertonicity from getting worse; the drinking of water corrects the defect. Hypo-osmolality results in very low plasma ADH levels. This results in the inhibition of water reabsorption from the kidney tubules, causing high volumes of very dilute urine to be excreted, thus getting rid of the excess water in the body. Urinary water loss, when the body water homeostat is intact, is a compensatory water loss, correcting any water excess in the body. However, since the kidneys cannot generate water, the thirst reflex is the all-important second effector mechanism of the body water homeostat, correcting any water deficit in the body.  Blood pH  The plasma pH can be altered by respiratory changes in the partial pressure of carbon dioxide; or altered by metabolic changes in the carbonic acid to bicarbonate ion ratio. The bicarbonate buffer system regulates the ratio of carbonic acid to bicarbonate to be equal to 1:20, at which ratio the blood pH is 7.4 (as explained in the Henderson–Hasselbalch equation). A change in the plasma pH gives an acid–base imbalance. In acid–base homeostasis there are two mechanisms that can help regulate the pH. Respiratory compensation a mechanism of the respiratory center, adjusts the partial pressure of carbon dioxide by changing the rate and depth of breathing, to bring the pH back to normal. The partial pressure of carbon dioxide also determines the concentration of carbonic acid, and the bicarbonate buffer system can also come into play. Renal compensation can help the bicarbonate buffer system. The sensor for the plasma bicarbonate concentration is not known for certain. It is very probable that the renal tubular cells of the distal convoluted tubules are themselves sensitive to the pH of the plasma. The metabolism of these cells produces carbon dioxide, which is rapidly converted to hydrogen and bicarbonate through the action of carbonic anhydrase. When the ECF pH falls (becoming more acidic) the renal tubular cells excrete hydrogen ions into the tubular fluid to leave the body via urine. Bicarbonate ions are simultaneously secreted into the blood that decreases the carbonic acid, and consequently raises the plasma pH. The converse happens when the plasma pH rises above normal: bicarbonate ions are excreted into the urine, and hydrogen ions released into the plasma. When hydrogen ions are excreted into the urine, and bicarbonate into the blood, the latter combines with the excess hydrogen ions in the plasma that stimulated the kidneys to perform this operation. The resulting reaction in the plasma is the formation of carbonic acid which is in equilibrium with the plasma partial pressure of carbon dioxide. This is tightly regulated to ensure that there is no excessive build-up of carbonic acid or bicarbonate. The overall effect is therefore that hydrogen ions are lost in the urine when the pH of the plasma falls. The concomitant rise in the plasma bicarbonate mops up the increased hydrogen ions (caused by the fall in plasma pH) and the resulting excess carbonic acid is disposed of in the lungs as carbon dioxide. This restores the normal ratio between bicarbonate and the partial pressure of carbon dioxide and therefore the plasma pH. The converse happens when a high plasma pH stimulates the kidneys to secrete hydrogen ions into the blood and to excrete bicarbonate into the urine. The hydrogen ions combine with the excess bicarbonate ions in the plasma, once again forming an excess of carbonic acid which can be exhaled, as carbon dioxide, in the lungs, keeping the plasma bicarbonate ion concentration, the partial pressure of carbon dioxide and, therefore, the plasma pH, constant.  Cerebrospinal fluid  Cerebrospinal fluid (CSF) allows for regulation of the distribution of substances between cells of the brain, and neuroendocrine factors, to which slight changes can cause problems or damage to the nervous system. For example, high glycine concentration disrupts temperature and blood pressure control, and high CSF pH causes dizziness and syncope.  Neurotransmission  Inhibitory neurons in the central nervous system play a homeostatic role in the balance of neuronal activity between excitation and inhibition. Inhibitory neurons using GABA, make compensating changes in the neuronal networks preventing runaway levels of excitation. An imbalance between excitation and inhibition is seen to be implicated in a number of neuropsychiatric disorders.  Neuroendocrine system  The neuroendocrine system is the mechanism by which the hypothalamus maintains homeostasis, regulating metabolism, reproduction, eating and drinking behaviour, energy utilization, osmolarity and blood pressure. The regulation of metabolism, is carried out by hypothalamic interconnections to other glands. Three endocrine glands of the hypothalamic–pituitary–gonadal axis (HPG axis) often work together and have important regulatory functions. Two other regulatory endocrine axes are the hypothalamic–pituitary–adrenal axis (HPA axis) and the hypothalamic–pituitary–thyroid axis (HPT axis). The liver also has many regulatory functions of the metabolism. An important function is the production and control of bile acids. Too much bile acid can be toxic to cells and its synthesis can be inhibited by activation of FXR a nuclear receptor.  Gene regulation  At the cellular level, homeostasis is carried out by several mechanisms including transcriptional regulation that can alter the activity of genes in response to changes.  Energy balance  The amount of energy taken in through nutrition needs to match the amount of energy used. To achieve energy homeostasis appetite is regulated by two hormones, grehlin and leptin. Grehlin stimulates hunger and the intake of food and leptin acts to signal satiety (fullness). A 2019 review of weight-change interventions, including dieting, exercise and overeating, found that body weight homeostasis could not precisely correct for ""energetic errors"", the loss or gain of calories, in the short-term.  Clinical significance  Many diseases are the result of a homeostatic failure. Almost any homeostatic component can malfunction either as a result of an inherited defect, an inborn error of metabolism, or an acquired disease. Some homeostatic mechanisms have inbuilt redundancies, which ensures that life is not immediately threatened if a component malfunctions; but sometimes a homeostatic malfunction can result in serious disease, which can be fatal if not treated. A well-known example of a homeostatic failure is shown in type 1 diabetes mellitus. Here blood sugar regulation is unable to function because the beta cells of the pancreatic islets are destroyed and cannot produce the necessary insulin. The blood sugar rises in a condition known as hyperglycemia.The plasma ionized calcium homeostat can be disrupted by the constant, unchanging, over-production of parathyroid hormone by a parathyroid adenoma resulting in the typically features of hyperparathyroidism, namely high plasma ionized Ca2+ levels and the resorption of bone, which can lead to spontaneous fractures. The abnormally high plasma ionized calcium concentrations cause conformational changes in many cell-surface proteins (especially ion channels and hormone or neurotransmitter receptors) giving rise to lethargy, muscle weakness, anorexia, constipation and labile emotions.The body water homeostat can be compromised by the inability to secrete ADH in response to even the normal daily water losses via the exhaled air, the feces, and insensible sweating. On receiving a zero blood ADH signal, the kidneys produce huge unchanging volumes of very dilute urine, causing dehydration and death if not treated. As organisms age, the efficiency of their control systems becomes reduced. The inefficiencies gradually result in an unstable internal environment that increases the risk of illness, and leads to the physical changes associated with aging.Various chronic diseases are kept under control by homeostatic compensation, which masks a problem by compensating for it (making up for it) in another way. However, the compensating mechanisms eventually wear out or are disrupted by a new complicating factor (such as the advent of a concurrent acute viral infection), which sends the body reeling through a new cascade of events. Such decompensation unmasks the underlying disease, worsening its symptoms. Common examples include decompensated heart failure, kidney failure, and liver failure.  Biosphere  In the Gaia hypothesis, James Lovelock stated that the entire mass of living matter on Earth (or any planet with life) functions as a vast homeostatic superorganism that actively modifies its planetary environment to produce the environmental conditions necessary for its own survival. In this view, the entire planet maintains several homeostasis (the primary one being temperature homeostasis). Whether this sort of system is present on Earth is open to debate. However, some relatively simple homeostatic mechanisms are generally accepted. For example, it is sometimes claimed that when atmospheric carbon dioxide levels rise, certain plants may be able to grow better and thus act to remove more carbon dioxide from the atmosphere. However, warming has exacerbated droughts, making water the actual limiting factor on land. When sunlight is plentiful and the atmospheric temperature climbs, it has been claimed that the phytoplankton of the ocean surface waters, acting as global sunshine, and therefore heat sensors, may thrive and produce more dimethyl sulfide (DMS). The DMS molecules act as cloud condensation nuclei, which produce more clouds, and thus increase the atmospheric albedo, and this feeds back to lower the temperature of the atmosphere. However, rising sea temperature has stratified the oceans, separating warm, sunlit waters from cool, nutrient-rich waters. Thus, nutrients have become the limiting factor, and plankton levels have actually fallen over the past 50 years, not risen. As scientists discover more about Earth, vast numbers of positive and negative feedback loops are being discovered, that, together, maintain a metastable condition, sometimes within a very broad range of environmental conditions.  Predictive  Predictive homeostasis is an anticipatory response to an expected challenge in the future, such as the stimulation of insulin secretion by gut hormones which enter the blood in response to a meal. This insulin secretion occurs before the blood sugar level rises, lowering the blood sugar level in anticipation of a large influx into the blood of glucose resulting from the digestion of carbohydrates in the gut. Such anticipatory reactions are open loop systems which are based, essentially, on ""guess work"", and are not self-correcting. Anticipatory responses always require a closed loop negative feedback system to correct the 'over-shoots' and 'under-shoots' to which the anticipatory systems are prone.  Other fields  The term has come to be used in other fields, for example:  Risk  An actuary may refer to risk homeostasis, where (for example) people who have anti-lock brakes have no better safety record than those without anti-lock brakes, because the former unconsciously compensate for the safer vehicle via less-safe driving habits. Previous to the innovation of anti-lock brakes, certain maneuvers involved minor skids, evoking fear and avoidance: Now the anti-lock system moves the boundary for such feedback, and behavior patterns expand into the no-longer punitive area. It has also been suggested that ecological crises are an instance of risk homeostasis in which a particular behavior continues until proven dangerous or dramatic consequences actually occur.  Stress  Sociologists and psychologists may refer to stress homeostasis, the tendency of a population or an individual to stay at a certain level of stress, often generating artificial stresses if the ""natural"" level of stress is not enough.Jean-François Lyotard, a postmodern theorist, has applied this term to societal 'power centers' that he describes in The Postmodern Condition, as being 'governed by a principle of homeostasis,' for example, the scientific hierarchy, which will sometimes ignore a radical new discovery for years because it destabilizes previously accepted norms.  Technology  Familiar technological homeostatic mechanisms include: A thermostat operates by switching heaters or air-conditioners on and off in response to the output of a temperature sensor. Cruise control adjusts a car's throttle in response to changes in speed. An autopilot operates the steering controls of an aircraft or ship in response to deviation from a pre-set compass bearing or route. Process control systems in a chemical plant or oil refinery maintain fluid levels, pressures, temperature, chemical composition, etc. by controlling heaters, pumps and valves. The centrifugal governor of a steam engine, as designed by James Watt in 1788, reduces the throttle valve in response to increases in the engine speed, or opens the valve if the speed falls below the pre-set rate.  Society and Culture  The use of sovereign power, codes of conduct, religious and cultural practices and other dynamic processes in a society can be described as a part of an evolved homeostatic system of regularizing life and maintaining an overall equilibrium that protects the security of the whole from internal and external imbalances or dangers. Healthy civic cultures can be said to have achieved an optimal homeostatic balance between multiple contradictory concerns such as in the tension between respect for individual rights and concern for the public good, or that between governmental effectiveness and responsiveness to the interests of citizens.  See also   References   Further reading  Clausen, M. J.; Poulsen, H. (2013). ""Chapter 3 Sodium/Potassium homeostasis, Chapter 5 Calcium homeostasis, Chapter 6 Manganese homeostasis"". In Banci, Lucia (ed.). Metallomics and the Cell. Metal Ions in Life Sciences. Vol. 12. Springer. pp. 41–67. doi:10.1007/978-94-007-5561-1_3. ISBN 978-94-007-5560-4. PMID 23595670. electronic-book ISBN 978-94-007-5561-1 ISSN 1559-0836 electronic-ISSN 1868-0402  External links  Homeostasis Archived 15 August 2017 at the Wayback Machine Walter Bradford Cannon, Homeostasis (1932)","Homeostasis is self-regulation, a basic property of all self-organising systems. In biology, it is the keeping of a stable internal environment.Homeostasis is life's ability to stay balanced, when the environment changes. Animals keep their body in a stable condition. They do so by regulating their inner equilibrium . For example, they adjust their pH, temperature, amount of oxygen or carbon dioxide in the blood and so on. In living things, the study of how they keep in a stable condition is called physiology. Mostly, our physiology works unconsciously throughout life. We have many negative feedback systems which adjust our physiology so that we stay alive. These systems are self-organising and do not need to be learnt. They are inherited. The concept was described by Claude Bernard, and the term was later coined by Walter Cannon in 1926, 1929, and 1932. Walter Cannon thought these were the features of homeostasis: Constancy in an open system, such as our bodies, is done by mechanisms which maintain this constancy. Cannon based this on insights into the ways by which steady states such as glucose concentrations, body temperature and acid-base balance were regulated. To keep a steady-state condition, any change automatically meets with factors that resist change. An increase in blood salt results in thirst as the body attempts to dilute the concentration of salt in the extracellular fluid. The regulating system doing homeostasis has a number of cooperating mechanisms which act simultaneously or successively. Blood sugar is regulated by insulin, glucagons, and other hormones that control its release from the liver or its uptake by the tissues.Examples of homeostasis: The operation of a thermostat The regulation of water and minerals in the body The regulation of body temperature: mammals and birds have complicated systems which keep their body temperature within close limits.In mammals, the main organs involved with homeostasis are: The hypothalamus and pituitary gland the lungs the skin the muscles the kidneys the liver and pancreasThe brain is also central to homeostasis. It controls behaviour, and the basic function of behaviour is to support life by taking action.  References   Related pages  Biology Biochemistry Physiology Cybernetics"
"In chemistry, pH (), also referred to as acidity, historically denotes ""potential of hydrogen"" (or ""power of hydrogen""). It is a scale used to specify the acidity or basicity of an aqueous solution. Acidic solutions (solutions with higher concentrations of hydrogen (H+) ions) are measured to have lower pH values than basic or alkaline solutions. The pH scale is logarithmic and inversely indicates the activity of hydrogen ions ( in the solution. pH  − log ⁡ ( a H + ) ≈ − log ⁡ ( [ H + ] ) {displaystyle {ce {pH}}-log(a_{{ce {H+}}})thickapprox -log([{ce {H+}}])} where [H+] is the equilibrium molar concentration (mol/L) of H+ in the solution. At 25 °C (77°F), solutions with a pH less than 7 are acidic, and solutions with a pH greater than 7 are basic. Solutions with a pH of 7 at 25 °C are neutral (i.e. have the same concentration of H+ ions as OH− ions, i.e. the same as pure water). The neutral value of the pH depends on the temperature and is lower than 7 if the temperature increases above 25 °C. The pH value can be less than 0 for very concentrated strong acids or greater than 14 for very concentrated strong bases.The pH scale is traceable to a set of standard solutions whose pH is established by international agreement. Primary pH standard values are determined using a concentration cell with transference by measuring the potential difference between a hydrogen electrode and a standard electrode such as the silver chloride electrode. The pH of aqueous solutions can be measured with a glass electrode and a pH meter or a color-changing indicator. Measurements of pH are important in chemistry, agronomy, medicine, water treatment, and many other applications.  History  In 1909, the Danish chemist Søren Peter Lauritz Sørensen introduced the concept of pH at the Carlsberg Laboratory, originally using the notation ""pH•"", with H• as a subscript to the lowercase p. The concept was later revised in 1924 to the modern pH to accommodate definitions and measurements in terms of electrochemical cells.For the sign p, I propose the name 'hydrogen ion exponent' and the symbol pH•. Then, for the hydrogen ion exponent (pH•) of a solution, the negative value of the Briggsian logarithm of the related hydrogen ion normality factor is to be understood.Sørensen did not explain why he used the letter p, and the exact meaning of the letter is still disputed. Sørensen described a way of measuring pH using potential differences, and it represents the negative power of 10 in the concentration of hydrogen ions. The letter p could stand for the French puissance, German Potenz, or Danish potens, all meaning ""power"", or it could mean ""potential"". All of these words start with the letter p in French, German, and Danish, which where the languages Sørensen published in (Carlsberg Laboratory was French-speaking, German was the dominant language of scientific publishing, and Sørensen was Danish). He also used the letter q in much the same way elsewhere in the paper, and he might have arbitrarily labelled the test solution ""p"" and the reference solution ""q""; these letters are often paired. Some literature sources suggest that ""pH"" stands for the Latin term pondus hydrogenii (quantity of hydrogen) or potentia hydrogenii (power of hydrogen), although this is not supported by Sørensen's writings.In modern chemistry, the p stands for ""the negative decimal logarithm of"", and is used in the term pKa for acid dissociation constants, so pH is ""the negative decimal logarithm of H+ ion concentration"", while pOH is ""the negative decimal logarithm of OH- ion concentration"". Bacteriologist Alice Catherine Evans, who influenced dairying and food safety, credited William Mansfield Clark and colleagues, including herself, with developing pH measuring methods in the 1910s, which had a wide influence on laboratory and industrial use thereafter. In her memoir, she does not mention how much, or how little, Clark and colleagues knew about Sørensen's work a few years prior. She said:In these studies [of bacterial metabolism] Dr. Clark's attention was directed to the effect of acid on the growth of bacteria. He found that it is the intensity of the acid in terms of hydrogen-ion concentration that affects their growth. But existing methods of measuring acidity determined the quantity, not the intensity, of the acid. Next, with his collaborators, Dr. Clark developed accurate methods for measuring hydrogen-ion concentration. These methods replaced the inaccurate titration method of determining the acid content in use in biologic laboratories throughout the world. Also they were found to be applicable in many industrial and other processes in which they came into wide usage.The first electronic method for measuring pH was invented by Arnold Orville Beckman, a professor at the California Institute of Technology in 1934. It was in response to a request from the local citrus grower Sunkist, which wanted a better method for quickly testing the pH of lemons they were picking from their nearby orchards.  Definition   pH  The pH of a solution is defined as the decimal logarithm of the reciprocal of the hydrogen ion activity, aH+. Mathematically, pH is expressed as: pH  − log 10 ⁡ ( a H + )  log 10 ⁡ ( 1 a H + ) {displaystyle {ce {pH}}-log _{10}(a_{{ce {H+}}})log _{10}left({frac {1}{a_{{ce {H+}}}}}right)} For example, for a solution with a hydrogen ion activity of 5×10−6 (i.e., the concentration of hydrogen ions in moles per litre), the pH of the solution can be calculated as follows: pH  − log 10 ⁡ ( 5 ∗ 10 − 6 )  5.3 {displaystyle {ce {pH}}-log _{10}(510^{-}6)5.3} The concept of pH was developed because ion-selective electrodes, which are used to measure pH, respond to activity. The electrode potential, E, follows the Nernst equation for the hydrogen ion, which can be expressed as: E  E 0 + R T F ln ⁡ ( a H + )  E 0 − 2.303 R T F pH {displaystyle EE^{0}+{frac {RT}{F}}ln(a_{{ce {H+}}})E^{0}-{frac {2.303RT}{F}}{ce {pH}}} where E is a measured potential, E0 is the standard electrode potential, R is the gas constant, T is the temperature in kelvins, F is the Faraday constant. For H+, the number of electrons transferred is one. The electrode potential is proportional to pH when pH is defined in terms of activity. The precise measurement of pH is presented in International Standard ISO 31-8 as follows: A galvanic cell is set up to measure the electromotive force (e.m.f.) between a reference electrode and an electrode sensitive to the hydrogen ion activity when they are both immersed in the same aqueous solution. The reference electrode may be a silver chloride electrode or a calomel electrode, and the hydrogen-ion selective electrode is a standard hydrogen electrode. Reference electrode | concentrated solution of KCl || test solution | H2 | PtFirstly, the cell is filled with a solution of known hydrogen ion activity and the electromotive force, ES, is measured. Then the electromotive force, EX, of the same cell containing the solution of unknown pH is measured. pH ( X )  pH ( S ) + E S − E X z {displaystyle {ce {pH(X)}}{ce {pH(S)}}+{frac {E_{{ce {S}}}-E_{{ce {X}}}}{z}}} The difference between the two measured electromotive force values is proportional to pH. This method of calibration avoids the need to know the standard electrode potential. The proportionality constant, 1/z, is ideally equal to 1 2.303 R T / F {displaystyle {frac {1}{2.303RT/F}} } , the ""Nernstian slope"". In practice, a glass electrode is used instead of the cumbersome hydrogen electrode. A combined glass electrode has an in-built reference electrode. It is calibrated against buffer solutions of known hydrogen ion (H+) activity proposed by the International Union of Pure and Applied Chemistry (IUPAC). Two or more buffer solutions are used in order to accommodate the fact that the ""slope"" may differ slightly from ideal. To calibrate the electrode, it is first immersed in a standard solution, and the reading on a pH meter is adjusted to be equal to the standard buffer's value. The reading from a second standard buffer solution is then adjusted using the ""slope"" control to be equal to the pH for that solution. Further details, are given in the IUPAC recommendations. When more than two buffer solutions are used the electrode is calibrated by fitting observed pH values to a straight line with respect to standard buffer values. Commercial standard buffer solutions usually come with information on the value at 25 °C and a correction factor to be applied for other temperatures. The pH scale is logarithmic and therefore pH is a dimensionless quantity. The pH scale ranges from 0 to 14, with a pH of 7 indicating neutrality, values less than 7 indicating acidity, and values greater than 7 indicating basicity. The pH scale is based on the hydrogen ion concentration, with each pH value representing a tenfold difference in hydrogen ion concentration.  p[H]  This was the original definition of Sørensen in 1909, which was superseded in favor of pH in 1924. [H] is the concentration of hydrogen ions, denoted [H+] in modern chemistry. More correctly, the thermodynamic activity of H+ in dilute solution should be replaced by [H+]/c0, where the standard state concentration c0  1 mol/L. This ratio is a pure number whose logarithm can be defined. It is possible to measure the concentration of hydrogen ions directly using an electrode calibrated in terms of hydrogen ion concentrations. One common method is to titrate a solution of known concentration of a strong acid with a solution of known concentration of strong base in the presence of a relatively high concentration of background electrolyte. By knowing the concentrations of the acid and base, the concentration of hydrogen ions can be calculated and the measured potential can be correlated with concentrations. The calibration is usually carried out using a Gran plot. This procedure makes the activity of hydrogen ions equal to the numerical value of concentration. The glass electrode (and other ion selective electrodes) should be calibrated in a medium similar to the one being investigated. For instance, if one wishes to measure the pH of a seawater sample, the electrode should be calibrated in a solution resembling seawater in its chemical composition. The difference between p[H] and pH is quite small, and it has been stated that pH  p[H] + 0.04. However, it is common practice to use the term ""pH"" for both types of measurement.  pOH  pOH is sometimes used as a measure of the concentration of hydroxide ions, OH−. pOH values are derived from pH measurements. The concentration of hydroxide ions in water is related to the concentration of hydrogen ions by [ OH − ]  K W [ H + ] {displaystyle [{ce {OH^-}}]{frac {K_{{ce {W}}}}{[{ce {H^+}}]}}} where KW is the self-ionization constant of water. Taking logarithms pOH  p K W − pH {displaystyle {ce {pOH}}{ce {p}}K_{{ce {W}}}-{ce {pH}}} So, at room temperature, pOH ≈ 14 − pH. However this relationship is not strictly valid in other circumstances, such as in measurements of soil alkalinity.  Measurement   pH Indicators  pH can be measured using indicators, which change color depending on the pH of the solution they are in. By comparing the color of a test solution to a standard color chart, the pH can be estimated to the nearest whole number. For more precise measurements, the color can be measured using a colorimeter or spectrophotometer. Universal indicator is a mixture of several indicators that can provide a continuous color change over a range of pH values, typically from about pH 2 to pH 10. Universal indicator paper is made from absorbent paper that has been impregnated with universal indicator. An alternative method of measuring pH is using an electronic pH meter, which directly measures the voltage difference between a pH-sensitive electrode and a reference electrode.  Non-aqueous solutions  pH values can be measured in non-aqueous solutions, but they are based on a different scale from aqueous pH values, because the standard states used for calculating hydrogen ion concentrations (activities) are different. The hydrogen ion activity, aH+, is defined as: a H +  exp ⁡ ( μ H + − μ H + ⊖ R T ) {displaystyle a_{{ce {H+}}}exp left({frac {mu _{{ce {H+}}}-mu _{{ce {H+}}}^{ominus }}{RT}}right)} where μH+ is the chemical potential of the hydrogen ion, μ H + ⊖ {displaystyle mu _{{ce {H+}}}^{ominus }} is its chemical potential in the chosen standard state, R is the gas constant and T is the thermodynamic temperature. Therefore, pH values on the different scales cannot be compared directly because of differences in the solvated proton ions, such as lyonium ions, which require an intersolvent scale which involves the transfer activity coefficient of hydronium/lyonium ion. pH is an example of an acidity function, but there are others that can be defined. For example, the Hammett acidity function, H0, has been developed in connection with superacids.  Unified absolute pH scale  In 2010, a new approach to measuring pH was proposed, called the ""unified absolute pH scale"". This approach allows for a common reference standard to be used across different solutions, regardless of their pH range. The unified absolute pH scale is based on the absolute chemical potential of the proton, as defined by the Lewis acid–base theory. This scale is applicable to liquids, gases, and even solids. The advantages of the unified absolute pH scale include consistency, accuracy, and applicability to a wide range of sample types. It is precise and versatile because it serves as a common reference standard for pH measurements. However, implementation efforts, compatibility with existing data, complexity, and potential costs are some challenges.  Extremes of pH measurements  The measurement of pH can become difficult at extremely acidic or alkaline conditions, such as below pH 2.5 (ca. 0.003 mol/dm3 acid) or above pH 10.5 (above ca. 0.0003 mol/dm3 alkaline). This is due to the breakdown of the Nernst equation in this conditions when using a glass electrode. There are several factors contribute to this problem. Firstly, liquid junction potentials may not be independent of pH. Secondly, the high ionic strength of concentrated solutions can affect the electrode potentials. At high pH the glass electrode may be affected by ""alkaline error"", because the electrode becomes sensitive to the concentration of cations such as Na+ and K+ in the solution. To overcome these problems, specially constructed electrodes are available. Runoff from mines or mine tailings can produce some extremely low pH values.  Applications  The pH scale ranges from 0 to 14, with 7 being neutral. Pure water has a pH of 7 at 25°C, meaning it is neutral. When an acid is dissolved in water, the pH will be less than 7, while a base, or alkali, will have a pH greater than 7. A strong acid, such as hydrochloric acid, at concentration 1 mol dm−3 has a pH of 0, while a strong alkali like sodium hydroxide, at the same concentration, has a pH of 14. Since pH is a logarithmic scale, a difference of one in pH is equivalent to a tenfold difference in hydrogen ion concentration. It's important to note that neutrality isn't exactly 7 at 25°C, although it's a good approximation in most cases. Neutrality occurs when the concentration of hydrogen ions ([H+]) equals the concentration of hydroxide ions ([OH−]), or when their activities are equal. Since self-ionization of water holds the product of these concentration [H+] × [OH−]  Kw, it can be seen that at neutrality [H+]  [OH−]  √Kw, or pH  pKw/2. pKw is approximately 14 but depends on ionic strength and temperature, and so the pH of neutrality does also. Pure water and a solution of NaCl in pure water are both neutral, since dissociation of water produces equal numbers of both ions. However the pH of the neutral NaCl solution will be slightly different from that of neutral pure water because the hydrogen and hydroxide ions' activity is dependent on ionic strength, so Kw varies with ionic strength. When pure water is exposed to air, it becomes mildly acidic. This is because water absorbs carbon dioxide from the air, which is then slowly converted into bicarbonate and hydrogen ions (essentially creating carbonic acid). CO2+ H2O ⇌ HCO−3+ H+  pH in soil  The United States Department of Agriculture Natural Resources Conservation Service, formerly Soil Conservation Service classifies soil pH ranges as follows: In Europe, topsoil pH is influenced by soil parent material, erosional effects, climate and vegetation. A recent map of topsoil pH in Europe shows the alkaline soils in Mediterranean, Hungary, East Romania, North France. Scandinavian countries, Portugal, Poland and North Germany have more acid soils.  pH in plants  Plants contain pH-dependent pigments that can be used as pH indicators, such as those found in hibiscus, red cabbage (anthocyanin), and grapes (red wine). Citrus fruits have acidic juice primarily due to the presence of citric acid, while other carboxylic acids can be found in various living systems. For instance, muscle activity results in the production of lactic acid. The protonation state of phosphate derivatives, including ATP, is pH-dependent. Hemoglobin, an oxygen-transport enzyme, is also affected by pH in a phenomenon known as the Root effect.  pH in the ocean  The pH of seawater plays an important role in the ocean's carbon cycle. There is evidence of ongoing ocean acidification (meaning a drop in pH value): Between 1950 and 2020, the average pH of the ocean surface fell from approximately 8.15 to 8.05. Carbon dioxide emissions from human activities are the primary cause of ocean acidification, with atmospheric carbon dioxide (CO2) levels exceeding 410 ppm (in 2020). CO2 from the atmosphere is absorbed by the oceans. This produces carbonic acid (H2CO3) which dissociates into a bicarbonate ion (HCO−3) and a hydrogen ion (H+). The presence of free hydrogen ions (H+) lowers the pH of the ocean.  Three pH scales in oceanography  The measurement of pH in seawater is complicated by the chemical properties of seawater, and three distinct pH scales exist in chemical oceanography. In practical terms, the three seawater pH scales differ in their pH values up to 0.10, differences that are much larger than the accuracy of pH measurements typically required, in particular, in relation to the ocean's carbonate system. Since it omits consideration of sulfate and fluoride ions, the free scale is significantly different from both the total and seawater scales. Because of the relative unimportance of the fluoride ion, the total and seawater scales differ only very slightly. As part of its operational definition of the pH scale, the IUPAC defines a series of buffer solutions across a range of pH values (often denoted with National Bureau of Standards (NBS) or National Institute of Standards and Technology (NIST) designation). These solutions have a relatively low ionic strength (≈0.1) compared to that of seawater (≈0.7), and, as a consequence, are not recommended for use in characterizing the pH of seawater, since the ionic strength differences cause changes in electrode potential. To resolve this problem, an alternative series of buffers based on artificial seawater was developed. This new series resolves the problem of ionic strength differences between samples and the buffers, and the new pH scale is referred to as the total scale, often denoted as pHT. The total scale was defined using a medium containing sulfate ions. These ions experience protonation, H+ + SO2−4↔ HSO−4, such that the total scale includes the effect of both protons (free hydrogen ions) and hydrogen sulfate ions: [H+]T  [H+]F + [HSO−4]An alternative scale, the free scale, often denoted pHF, omits this consideration and focuses solely on [H+]F, in principle making it a simpler representation of hydrogen ion concentration. Only [H+]T can be determined, therefore [H+]F must be estimated using the [SO2−4] and the stability constant of HSO−4, KS: [H+]F  [H+]T − [HSO−4]  [H+]T ( 1 + [SO2−4] / KS )−1However, it is difficult to estimate KS in seawater, limiting the utility of the otherwise more straightforward free scale. Another scale, known as the seawater scale, often denoted pHSWS, takes account of a further protonation relationship between hydrogen ions and fluoride ions, H+ + F− ⇌ HF. Resulting in the following expression for [H+]SWS: [H+]SWS  [H+]F + [HSO−4] + [HF]However, the advantage of considering this additional complexity is dependent upon the abundance of fluoride in the medium. In seawater, for instance, sulfate ions occur at much greater concentrations (>400 times) than those of fluoride. As a consequence, for most practical purposes, the difference between the total and seawater scales is very small. The following three equations summarize the three scales of pH: pHF  −log [H+]F pHT  −log([H+]F + [HSO−4])  −log[H+]T pHSWS  −log(H+]F + [HSO−4] + [HF])  −log[v]SWS  pH of various body fluids  In living organisms, the pH of various body fluids, cellular compartments, and organs is tightly regulated to maintain a state of acid-base balance known as acid–base homeostasis. Acidosis, defined by a pH below 7.35, is the most common disorder of acid–base homeostasis and occurs when there is an excess of acid in the body. In contrast, alkalosis is characterized by excessively high blood pH. Blood pH is usually slightly basic, with a pH of 7.365, referred to as physiological pH in biology and medicine. Plaque formation in teeth can create a local acidic environment that results in tooth decay through demineralization. Enzymes and other proteins have an optimal pH range for function and can become inactivated or denatured outside this range.  pH calculations  When calculating the pH of a solution containing acids and/or bases, a chemical speciation calculation is used to determine the concentration of all chemical species present in the solution. The complexity of the procedure depends on the nature of the solution. Strong acids and bases are compounds that are almost completely dissociated in water, which simplifies the calculation. However, for weak acids, a quadratic equation must be solved, and for weak bases, a cubic equation is required. In general, a set of non-linear simultaneous equations must be solved. Water itself is a weak acid and a weak base, so its dissociation must be taken into account at high pH and low solute concentration (see amphoterism). It dissociates according to the equilibrium 2 H2O ⇌ H3O+ (aq) + OH− (aq)with a dissociation constant, Kw defined as K w  [ H + ] [ OH − ] {displaystyle K_{w}{ce {[H+][OH^{-}]}}} where [H+] stands for the concentration of the aqueous hydronium ion and [OH−] represents the concentration of the hydroxide ion. This equilibrium needs to be taken into account at high pH and when the solute concentration is extremely low.  Strong acids and bases  Strong acids and bases are compounds that are essentially fully dissociated in water. This means that in an acidic solution, the concentration of hydrogen ions (H+) can be considered equal to the concentration of the acid. Similarly, in a basic solution, the concentration of hydroxide ions (OH-) can be considered equal to the concentration of the base. The pH of a solution is defined as the negative logarithm of the concentration of H+, and the pOH is defined as the negative logarithm of the concentration of OH-. For example, the pH of a 0.01M solution of hydrochloric acid (HCl) is equal to 2 (pH  −log10(0.01)), while the pOH of a 0.01M solution of sodium hydroxide (NaOH) is equal to 2 (pOH  −log10(0.01)), which corresponds to a pH of about 12. However, self-ionization of water must also be considered when concentrations of a strong acid or base is very low or high. For instance, a 5×10−8M solution of HCl would be expected to have a pH of 7.3 based on the above procedure, which is incorrect as it is acidic and should have a pH of less than 7. In such cases, the system can be treated as a mixture of the acid or base and water, which is an amphoteric substance. By accounting for the self-ionization of water, the true pH of the solution can be calculated. For example, a 5×10−8M solution of HCl would have a pH of 6.89 when treated as a mixture of HCl and water. The self-ionization equilibrium of solutions of sodium hydroxide at higher concentrations must also be considered.  Weak acids and bases  A weak acid or the conjugate acid of a weak base can be treated using the same formalism. Acid HA: HA ⇌ H+ + A− Base A: HA+ ⇌ H+ + AFirst, an acid dissociation constant is defined as follows. Electrical charges are omitted from subsequent equations for the sake of generality K a  [ H ] [ A ] [ HA ] {displaystyle K_{a}{frac {{ce {[H] [A]}}}{{ce {[HA]}}}}} and its value is assumed to have been determined by experiment. This being so, there are three unknown concentrations, [HA], [H+] and [A−] to determine by calculation. Two additional equations are needed. One way to provide them is to apply the law of mass conservation in terms of the two ""reagents"" H and A. C A  [ A ] + [ HA ] {displaystyle C_{{ce {A}}}{ce {[A]}}+{ce {[HA]}}} C H  [ H ] + [ HA ] {displaystyle C_{{ce {H}}}{ce {[H]}}+{ce {[HA]}}} C stands for analytical concentration. In some texts, one mass balance equation is replaced by an equation of charge balance. This is satisfactory for simple cases like this one, but is more difficult to apply to more complicated cases as those below. Together with the equation defining Ka, there are now three equations in three unknowns. When an acid is dissolved in water CA  CH  Ca, the concentration of the acid, so [A]  [H]. After some further algebraic manipulation an equation in the hydrogen ion concentration may be obtained. [ H ] 2 + K a [ H ] − K a C a  0 {displaystyle [{ce {H}}]^{2}+K_{a}[{ce {H}}]-K_{a}C_{a}0} Solution of this quadratic equation gives the hydrogen ion concentration and hence p[H] or, more loosely, pH. This procedure is illustrated in an ICE table which can also be used to calculate the pH when some additional (strong) acid or alkaline has been added to the system, that is, when CA ≠ CH. For example, what is the pH of a 0.01M solution of benzoic acid, pKa  4.19? Step 1: K a  10 − 4.19  6.46 × 10 − 5 {displaystyle K_{a}10^{-4.19}6.46times 10^{-5}} Step 2: Set up the quadratic equation. [ H ] 2 + 6.46 × 10 − 5 [ H ] − 6.46 × 10 − 7  0 {displaystyle [{ce {H}}]^{2}+6.46times 10^{-5}[{ce {H}}]-6.46times 10^{-7}0} Step 3: Solve the quadratic equation. [ H + ]  7.74 × 10 − 4 ; p H  3.11 {displaystyle [{ce {H+}}]7.74times 10^{-4};quad mathrm {pH} 3.11} For alkaline solutions, an additional term is added to the mass-balance equation for hydrogen. Since the addition of hydroxide reduces the hydrogen ion concentration, and the hydroxide ion concentration is constrained by the self-ionization equilibrium to be equal to K w [ H + ] {displaystyle {frac {K_{w}}{{ce {[H+]}}}}} , the resulting equation is: C H  [ H ] + [ HA ] − K w [ H ] {displaystyle C_{ce {H}}{frac {[{ce {H}}]+[{ce {HA}}]-K_{w}}{ce {[H]}}}}  General method  Some systems, such as with polyprotic acids, are amenable to spreadsheet calculations. With three or more reagents or when many complexes are formed with general formulae such as ApBqHr, the following general method can be used to calculate the pH of a solution. For example, with three reagents, each equilibrium is characterized by an equilibrium constant, β. [ A p B q H r ]  β p q r [ A ] p [ B ] q [ H ] r {displaystyle [{ce {A}}_{p}{ce {B}}_{q}{ce {H}}_{r}]beta _{pqr}[{ce {A}}]^{p}[{ce {B}}]^{q}[{ce {H}}]^{r}} Next, write down the mass-balance equations for each reagent: C A  [ A ] + Σ p β p q r [ A ] p [ B ] q [ H ] r C B  [ B ] + Σ q β p q r [ A ] p [ B ] q [ H ] r C H  [ H ] + Σ r β p q r [ A ] p [ B ] q [ H ] r − K w [ H ] − 1 {displaystyle {begin{aligned}C_{ce {A}}&[{ce {A}}]+Sigma pbeta _{pqr}[{ce {A}}]^{p}[{ce {B}}]^{q}[{ce {H}}]^{r}C_{ce {B}}&[{ce {B}}]+Sigma qbeta _{pqr}[{ce {A}}]^{p}[{ce {B}}]^{q}[{ce {H}}]^{r}C_{ce {H}}&[{ce {H}}]+Sigma rbeta _{pqr}[{ce {A}}]^{p}[{ce {B}}]^{q}[{ce {H}}]^{r}-K_{w}[{ce {H}}]^{-1}end{aligned}}} Note that there are no approximations involved in these equations, except that each stability constant is defined as a quotient of concentrations, not activities. Much more complicated expressions are required if activities are to be used. There are three non-linear simultaneous equations in the three unknowns, [A], [B] and [H]. Because the equations are non-linear and their concentrations may range over many powers of 10, the solution of these equations is not straightforward. However, many computer programs are available which can be used to perform these calculations. There may be more than three reagents. The calculation of hydrogen ion concentrations, using this approach, is a key element in the determination of equilibrium constants by potentiometric titration.  See also  pH indicator Arterial blood gas Chemical equilibrium pCO2 pKa  References   External links ","pH is a scale of acidity from 0 to 14. It tells how acidic or alkaline a substance is. More acidic solutions have lower pH. More alkaline solutions have higher pH. Substances that aren't acidic or alkaline (that is, neutral solutions) usually have a pH of 7. Acids have a pH that is less than 7. Alkalis have a pH that is greater than 7. pH is a measure of the concentration of protons (H+) in a solution. S.P.L. Sørensen introduced this concept in the year 1909. The p stands for the German potenz, meaning power or concentration, and the H for the hydrogen ion (H+). The most common formula for calculating pH is: pH  − log 10 ⁡ [ H + ] {displaystyle {mbox{pH}}-log _{10}left[{mbox{H}}^{+}right]} [H+] indicates the concentration of H+ ions (also written [H3O+], the equal concentration of hydronium ions), measured in moles per litre (also known as molarity). However, the correct equation is actually: pH  − log 10 ⁡ [ a H + ] {displaystyle {mbox{pH}}-log _{10}left[a_{mathrm {H^{+}} }right]} where a H + {displaystyle a_{mathrm {H^{+}} }} indicates the activity of H+ ions. But, this equation in most cases provides the same value as the more common formula, so in introductory chemistry the previous equation is given as the definition of pH. Most substances have a pH in the range of 0 to 14, although extremely acidic or alkaline substances may have pH < 0, or pH > 14. Alkaline substances have, instead of hydrogen ions, a concentration of hydroxide ions (OH-).  pH indicators  Certain dyes change colour depending on whether they are in an acid solution or an alkaline solution . pH indicator is a chemical compound added in small amounts to a solution so the pH (acidity or basicity) of the solution can be seen. The pH indicator is a chemical detector for hydronium ions (H3O+) or hydrogen ions (H+). Normally, the indicator causes the colour of the solution to change depending on the pH. Typical indicators are phenolphthalein, methyl orange, methyl red, bromothymol blue, and thymol blue. They each change colour at different points on the pH scale, and can be used together as a universal indicator.Another way is to use litmus paper, which is based on a natural pH indicators. The paper can tell you how strong the chemical is, whether it is a stronger acid or a stronger base.  Some common pH values   Neutralization  Neutralization can be summed up by the equation: H+ + OH− → H2O(acid + base → water)  Related pages  Acid Base Alkali Titration Transpiration  Notes   Other websites  pH-Spectra Database Archived 2016-09-11 at the Wayback Machine í pH Test Archived 2020-12-02 at the Wayback Machine pH Calculator"
"The electron (e− or β−) is a subatomic particle with a negative one elementary electric charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron\'s mass is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, ħ. Being fermions, no two electrons can occupy the same quantum state, per the Pauli exclusion principle. Like all elementary particles, electrons exhibit properties of both particles and waves: They can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy. Electrons play an essential role in numerous physical phenomena, such as electricity, magnetism, chemistry, and thermal conductivity; they also participate in gravitational, electromagnetic, and weak interactions. Since an electron has charge, it has a surrounding electric field; if that electron is moving relative to an observer, the observer will observe it to generate a magnetic field. Electromagnetic fields produced from other sources will affect the motion of an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when they are accelerated. Laboratory instruments are capable of trapping individual electrons as well as electron plasma by the use of electromagnetic fields. Special telescopes can detect electron plasma in outer space. Electrons are involved in many applications, such as tribology or frictional charging, electrolysis, electrochemistry, battery technologies, electronics, welding, cathode-ray tubes, photoelectricity, photovoltaic solar panels, electron microscopes, radiation therapy, lasers, gaseous ionization detectors, and particle accelerators. Interactions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms. Irish physicist George Johnstone Stoney named this charge \'electron\' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode-ray tube experiment. Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons can be created through beta decay of radioactive isotopes and in high-energy collisions, for instance, when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron, except that it carries electrical charge of the opposite sign. When an electron collides with a positron, both particles can be annihilated, producing gamma ray photons.  History   Discovery of effect of electric force  The ancient Greeks noticed that amber attracted small objects when rubbed with fur. Along with lightning, this phenomenon is one of humanity\'s earliest recorded experiences with electricity. In his 1600 treatise De Magnete, the English scientist William Gilbert coined the Neo-Latin term electrica, to refer to those substances with property similar to that of amber which attract smaller objects after being rubbed. Both electric and electricity are derived from the Latin ēlectrum (also the root of the alloy of the same name), which came from the Greek word for amber, ἤλεκτρον (ēlektron).  Discovery of two kinds of charges  In the early 1700s, French chemist Charles François du Fay found that if a charged gold-leaf is repulsed by glass rubbed with silk, then the same charged gold-leaf is attracted by amber rubbed with wool. From this and other results of similar types of experiments, du Fay concluded that electricity consists of two electrical fluids, vitreous fluid from glass rubbed with silk and resinous fluid from amber rubbed with wool. These two fluids can neutralize each other when combined. American scientist Ebenezer Kinnersley later also independently reached the same conclusion.: 118 A decade later Benjamin Franklin proposed that electricity was not from different types of electrical fluid, but a single electrical fluid showing an excess (+) or deficit (−). He gave them the modern charge nomenclature of positive and negative respectively. Franklin thought of the charge carrier as being positive, but he did not correctly identify which situation was a surplus of the charge carrier, and which situation was a deficit.Between 1838 and 1851, British natural philosopher Richard Laming developed the idea that an atom is composed of a core of matter surrounded by subatomic particles that had unit electric charges. Beginning in 1846, German physicist Wilhelm Eduard Weber theorized that electricity was composed of positively and negatively charged fluids, and their interaction was governed by the inverse square law. After studying the phenomenon of electrolysis in 1874, Irish physicist George Johnstone Stoney suggested that there existed a ""single definite quantity of electricity"", the charge of a monovalent ion. He was able to estimate the value of this elementary charge e by means of Faraday\'s laws of electrolysis. However, Stoney believed these charges were permanently attached to atoms and could not be removed. In 1881, German physicist Hermann von Helmholtz argued that both positive and negative charges were divided into elementary parts, each of which ""behaves like atoms of electricity"".Stoney initially coined the term electrolion in 1881. Ten years later, he switched to electron to describe these elementary charges, writing in 1894: ""... an estimate was made of the actual amount of this most remarkable fundamental unit of electricity, for which I have since ventured to suggest the name electron"". A 1906 proposal to change to electrion failed because Hendrik Lorentz preferred to keep electron. The word electron is a combination of the words electric and ion. The suffix -on which is now used to designate other subatomic particles, such as a proton or neutron, is in turn derived from electron.  Discovery of free electrons outside matter  While studying electrical conductivity in rarefied gases in 1859, the German physicist Julius Plücker observed the radiation emitted from the cathode caused phosphorescent light to appear on the tube wall near the cathode; and the region of the phosphorescent light could be moved by application of a magnetic field. In 1869, Plücker\'s student Johann Wilhelm Hittorf found that a solid body placed in between the cathode and the phosphorescence would cast a shadow upon the phosphorescent region of the tube. Hittorf inferred that there are straight rays emitted from the cathode and that the phosphorescence was caused by the rays striking the tube walls. In 1876, the German physicist Eugen Goldstein showed that the rays were emitted perpendicular to the cathode surface, which distinguished between the rays that were emitted from the cathode and the incandescent light. Goldstein dubbed the rays cathode rays.: 393 Decades of experimental and theoretical research involving cathode rays were important in J. J. Thomson\'s eventual discovery of electrons.During the 1870s, the English chemist and physicist Sir William Crookes developed the first cathode-ray tube to have a high vacuum inside. He then showed in 1874 that the cathode rays can turn a small paddle wheel when placed in their path. Therefore, he concluded that the rays carried momentum. Furthermore, by applying a magnetic field, he was able to deflect the rays, thereby demonstrating that the beam behaved as though it were negatively charged. In 1879, he proposed that these properties could be explained by regarding cathode rays as composed of negatively charged gaseous molecules in a fourth state of matter in which the mean free path of the particles is so long that collisions may be ignored.: 394–395 The German-born British physicist Arthur Schuster expanded upon Crookes\'s experiments by placing metal plates parallel to the cathode rays and applying an electric potential between the plates. The field deflected the rays toward the positively charged plate, providing further evidence that the rays carried negative charge. By measuring the amount of deflection for a given electric and magnetic field, in 1890 Schuster was able to estimate the charge-to-mass ratio of the ray components. However, this produced a value that was more than a thousand times greater than what was expected, so little credence was given to his calculations at the time. This is because it was assumed that the charge carriers were much heavier hydrogen or nitrogen atoms. Schuster\'s estimates would subsequently turn out to be largely correct. In 1892 Hendrik Lorentz suggested that the mass of these particles (electrons) could be a consequence of their electric charge. While studying naturally fluorescing minerals in 1896, the French physicist Henri Becquerel discovered that they emitted radiation without any exposure to an external energy source. These radioactive materials became the subject of much interest by scientists, including the New Zealand physicist Ernest Rutherford who discovered they emitted particles. He designated these particles alpha and beta, on the basis of their ability to penetrate matter. In 1900, Becquerel showed that the beta rays emitted by radium could be deflected by an electric field, and that their mass-to-charge ratio was the same as for cathode rays. This evidence strengthened the view that electrons existed as components of atoms.In 1897, the British physicist J. J. Thomson, with his colleagues John S. Townsend and H. A. Wilson, performed experiments indicating that cathode rays really were unique particles, rather than waves, atoms or molecules as was believed earlier. Thomson made good estimates of both the charge e and the mass m, finding that cathode ray particles, which he called ""corpuscles"", had perhaps one thousandth of the mass of the least massive ion known: hydrogen. He showed that their charge-to-mass ratio, e/m, was independent of cathode material. He further showed that the negatively charged particles produced by radioactive materials, by heated materials and by illuminated materials were universal. The name electron was adopted for these particles by the scientific community, mainly due to the advocation by G. F. FitzGerald, J. Larmor, and H. A. Lorentz.: 273 In the same year Emil Wiechert and Walter Kaufmann also calculated the e/m ratio but they failed short of interpreting their results while J. J. Thomson would subsequently in 1899 give estimates for the electron charge and mass as well: e~6.8×10−10 esu and m~3×10−26 g The electron\'s charge was more carefully measured by the American physicists Robert Millikan and Harvey Fletcher in their oil-drop experiment of 1909, the results of which were published in 1911. This experiment used an electric field to prevent a charged droplet of oil from falling as a result of gravity. This device could measure the electric charge from as few as 1–150 ions with an error margin of less than 0.3%. Comparable experiments had been done earlier by Thomson\'s team, using clouds of charged water droplets generated by electrolysis, and in 1911 by Abram Ioffe, who independently obtained the same result as Millikan using charged microparticles of metals, then published his results in 1913. However, oil drops were more stable than water drops because of their slower evaporation rate, and thus more suited to precise experimentation over longer periods of time.Around the beginning of the twentieth century, it was found that under certain conditions a fast-moving charged particle caused a condensation of supersaturated water vapor along its path. In 1911, Charles Wilson used this principle to devise his cloud chamber so he could photograph the tracks of charged particles, such as fast-moving electrons.  Atomic theory  By 1914, experiments by physicists Ernest Rutherford, Henry Moseley, James Franck and Gustav Hertz had largely established the structure of an atom as a dense nucleus of positive charge surrounded by lower-mass electrons. In 1913, Danish physicist Niels Bohr postulated that electrons resided in quantized energy states, with their energies determined by the angular momentum of the electron\'s orbit about the nucleus. The electrons could move between those states, or orbits, by the emission or absorption of photons of specific frequencies. By means of these quantized orbits, he accurately explained the spectral lines of the hydrogen atom. However, Bohr\'s model failed to account for the relative intensities of the spectral lines and it was unsuccessful in explaining the spectra of more complex atoms.Chemical bonds between atoms were explained by Gilbert Newton Lewis, who in 1916 proposed that a covalent bond between two atoms is maintained by a pair of electrons shared between them. Later, in 1927, Walter Heitler and Fritz London gave the full explanation of the electron-pair formation and chemical bonding in terms of quantum mechanics. In 1919, the American chemist Irving Langmuir elaborated on the Lewis\'s static model of the atom and suggested that all electrons were distributed in successive ""concentric (nearly) spherical shells, all of equal thickness"". In turn, he divided the shells into a number of cells each of which contained one pair of electrons. With this model Langmuir was able to qualitatively explain the chemical properties of all elements in the periodic table, which were known to largely repeat themselves according to the periodic law.In 1924, Austrian physicist Wolfgang Pauli observed that the shell-like structure of the atom could be explained by a set of four parameters that defined every quantum energy state, as long as each state was occupied by no more than a single electron. This prohibition against more than one electron occupying the same quantum energy state became known as the Pauli exclusion principle. The physical mechanism to explain the fourth parameter, which had two distinct possible values, was provided by the Dutch physicists Samuel Goudsmit and George Uhlenbeck. In 1925, they suggested that an electron, in addition to the angular momentum of its orbit, possesses an intrinsic angular momentum and magnetic dipole moment. This is analogous to the rotation of the Earth on its axis as it orbits the Sun. The intrinsic angular momentum became known as spin, and explained the previously mysterious splitting of spectral lines observed with a high-resolution spectrograph; this phenomenon is known as fine structure splitting.  Quantum mechanics  In his 1924 dissertation Recherches sur la théorie des quanta (Research on Quantum Theory), French physicist Louis de Broglie hypothesized that all matter can be represented as a de Broglie wave in the manner of light. That is, under the appropriate conditions, electrons and other matter would show properties of either particles or waves. The corpuscular properties of a particle are demonstrated when it is shown to have a localized position in space along its trajectory at any given moment. The wave-like nature of light is displayed, for example, when a beam of light is passed through parallel slits thereby creating interference patterns. In 1927, George Paget Thomson discovered the interference effect was produced when a beam of electrons was passed through thin metal foils and by American physicists Clinton Davisson and Lester Germer by the reflection of electrons from a crystal of nickel. De Broglie\'s prediction of a wave nature for electrons led Erwin Schrödinger to postulate a wave equation for electrons moving under the influence of the nucleus in the atom. In 1926, this equation, the Schrödinger equation, successfully described how electron waves propagated. Rather than yielding a solution that determined the location of an electron over time, this wave equation also could be used to predict the probability of finding an electron near a position, especially a position near where the electron was bound in space, for which the electron wave equations did not change in time. This approach led to a second formulation of quantum mechanics (the first by Heisenberg in 1925), and solutions of Schrödinger\'s equation, like Heisenberg\'s, provided derivations of the energy states of an electron in a hydrogen atom that were equivalent to those that had been derived first by Bohr in 1913, and that were known to reproduce the hydrogen spectrum. Once spin and the interaction between multiple electrons were describable, quantum mechanics made it possible to predict the configuration of electrons in atoms with atomic numbers greater than hydrogen.In 1928, building on Wolfgang Pauli\'s work, Paul Dirac produced a model of the electron – the Dirac equation, consistent with relativity theory, by applying relativistic and symmetry considerations to the hamiltonian formulation of the quantum mechanics of the electro-magnetic field. In order to resolve some problems within his relativistic equation, Dirac developed in 1930 a model of the vacuum as an infinite sea of particles with negative energy, later dubbed the Dirac sea. This led him to predict the existence of a positron, the antimatter counterpart of the electron. This particle was discovered in 1932 by Carl Anderson, who proposed calling standard electrons negatrons and using electron as a generic term to describe both the positively and negatively charged variants.In 1947, Willis Lamb, working in collaboration with graduate student Robert Retherford, found that certain quantum states of the hydrogen atom, which should have the same energy, were shifted in relation to each other; the difference came to be called the Lamb shift. About the same time, Polykarp Kusch, working with Henry M. Foley, discovered the magnetic moment of the electron is slightly larger than predicted by Dirac\'s theory. This small difference was later called anomalous magnetic dipole moment of the electron. This difference was later explained by the theory of quantum electrodynamics, developed by Sin-Itiro Tomonaga, Julian Schwinger and Richard Feynman in the late 1940s.  Particle accelerators  With the development of the particle accelerator during the first half of the twentieth century, physicists began to delve deeper into the properties of subatomic particles. The first successful attempt to accelerate electrons using electromagnetic induction was made in 1942 by Donald Kerst. His initial betatron reached energies of 2.3 MeV, while subsequent betatrons achieved 300 MeV. In 1947, synchrotron radiation was discovered with a 70 MeV electron synchrotron at General Electric. This radiation was caused by the acceleration of electrons through a magnetic field as they moved near the speed of light.With a beam energy of 1.5 GeV, the first high-energy particle collider was ADONE, which began operations in 1968. This device accelerated electrons and positrons in opposite directions, effectively doubling the energy of their collision when compared to striking a static target with an electron. The Large Electron–Positron Collider (LEP) at CERN, which was operational from 1989 to 2000, achieved collision energies of 209 GeV and made important measurements for the Standard Model of particle physics.  Confinement of individual electrons  Individual electrons can now be easily confined in ultra small (L  20 nm, W  20 nm) CMOS transistors operated at cryogenic temperature over a range of −269 °C (4 K) to about −258 °C (15 K). The electron wavefunction spreads in a semiconductor lattice and negligibly interacts with the valence band electrons, so it can be treated in the single particle formalism, by replacing its mass with the effective mass tensor.  Characteristics   Classification  In the Standard Model of particle physics, electrons belong to the group of subatomic particles called leptons, which are believed to be fundamental or elementary particles. Electrons have the lowest mass of any charged lepton (or electrically charged particle of any type) and belong to the first-generation of fundamental particles. The second and third generation contain charged leptons, the muon and the tau, which are identical to the electron in charge, spin and interactions, but are more massive. Leptons differ from the other basic constituent of matter, the quarks, by their lack of strong interaction. All members of the lepton group are fermions, because they all have half-odd integer spin; the electron has spin 1/2.  Fundamental properties  The invariant mass of an electron is approximately 9.109×10−31 kilograms, or 5.489×10−4 atomic mass units. Due to mass–energy equivalence, this corresponds to a rest energy of 0.511 MeV (8.19×10−14 J). The ratio between the mass of a proton and that of an electron is about 1836. Astronomical measurements show that the proton-to-electron mass ratio has held the same value, as is predicted by the Standard Model, for at least half the age of the universe.Electrons have an electric charge of −1.602176634×10−19 coulombs, which is used as a standard unit of charge for subatomic particles, and is also called the elementary charge. Within the limits of experimental accuracy, the electron charge is identical to the charge of a proton, but with the opposite sign. The electron is commonly symbolized by e−, and the positron is symbolized by e+.The electron has an intrinsic angular momentum or spin of ħ/2. This property is usually stated by referring to the electron as a spin-1/2 particle. For such particles the spin magnitude is ħ/2, while the result of the measurement of a projection of the spin on any axis can only be ±ħ/2. In addition to spin, the electron has an intrinsic magnetic moment along its spin axis. It is approximately equal to one Bohr magneton, which is a physical constant equal to 9.27400915(23)×10−24 joules per tesla. The orientation of the spin with respect to the momentum of the electron defines the property of elementary particles known as helicity.The electron has no known substructure. Nevertheless, in condensed matter physics, spin–charge separation can occur in some materials. In such cases, electrons \'split\' into three independent particles, the spinon, the orbiton and the holon (or chargon). The electron can always be theoretically considered as a bound state of the three, with the spinon carrying the spin of the electron, the orbiton carrying the orbital degree of freedom and the chargon carrying the charge, but in certain conditions they can behave as independent quasiparticles.The issue of the radius of the electron is a challenging problem of modern theoretical physics. The admission of the hypothesis of a finite radius of the electron is incompatible to the premises of the theory of relativity. On the other hand, a point-like electron (zero radius) generates serious mathematical difficulties due to the self-energy of the electron tending to infinity. Observation of a single electron in a Penning trap suggests the upper limit of the particle\'s radius to be 10−22 meters. The upper bound of the electron radius of 10−18 meters can be derived using the uncertainty relation in energy. There is also a physical constant called the ""classical electron radius"", with the much larger value of 2.8179×10−15 m, greater than the radius of the proton. However, the terminology comes from a simplistic calculation that ignores the effects of quantum mechanics; in reality, the so-called classical electron radius has little to do with the true fundamental structure of the electron.There are elementary particles that spontaneously decay into less massive particles. An example is the muon, with a mean lifetime of 2.2×10−6 seconds, which decays into an electron, a muon neutrino and an electron antineutrino. The electron, on the other hand, is thought to be stable on theoretical grounds: the electron is the least massive particle with non-zero electric charge, so its decay would violate charge conservation. The experimental lower bound for the electron\'s mean lifetime is 6.6×1028 years, at a 90% confidence level.  Quantum properties  As with all particles, electrons can act as waves. This is called the wave–particle duality and can be demonstrated using the double-slit experiment. The wave-like nature of the electron allows it to pass through two parallel slits simultaneously, rather than just one slit as would be the case for a classical particle. In quantum mechanics, the wave-like property of one particle can be described mathematically as a complex-valued function, the wave function, commonly denoted by the Greek letter psi (ψ). When the absolute value of this function is squared, it gives the probability that a particle will be observed near a location—a probability density.: 162–218 Electrons are identical particles because they cannot be distinguished from each other by their intrinsic physical properties. In quantum mechanics, this means that a pair of interacting electrons must be able to swap positions without an observable change to the state of the system. The wave function of fermions, including electrons, is antisymmetric, meaning that it changes sign when two electrons are swapped; that is, ψ(r1, r2)  −ψ(r2, r1), where the variables r1 and r2 correspond to the first and second electrons, respectively. Since the absolute value is not changed by a sign swap, this corresponds to equal probabilities. Bosons, such as the photon, have symmetric wave functions instead.: 162–218 In the case of antisymmetry, solutions of the wave equation for interacting electrons result in a zero probability that each pair will occupy the same location or state. This is responsible for the Pauli exclusion principle, which precludes any two electrons from occupying the same quantum state. This principle explains many of the properties of electrons. For example, it causes groups of bound electrons to occupy different orbitals in an atom, rather than all overlapping each other in the same orbit.: 162–218  Virtual particles  In a simplified picture, which often tends to give the wrong idea but may serve to illustrate some aspects, every photon spends some time as a combination of a virtual electron plus its antiparticle, the virtual positron, which rapidly annihilate each other shortly thereafter. The combination of the energy variation needed to create these particles, and the time during which they exist, fall under the threshold of detectability expressed by the Heisenberg uncertainty relation, ΔE · Δt ≥ ħ. In effect, the energy needed to create these virtual particles, ΔE, can be ""borrowed"" from the vacuum for a period of time, Δt, so that their product is no more than the reduced Planck constant, ħ ≈ 6.6×10−16 eV·s. Thus, for a virtual electron, Δt is at most 1.3×10−21 s. While an electron–positron virtual pair is in existence, the Coulomb force from the ambient electric field surrounding an electron causes a created positron to be attracted to the original electron, while a created electron experiences a repulsion. This causes what is called vacuum polarization. In effect, the vacuum behaves like a medium having a dielectric permittivity more than unity. Thus the effective charge of an electron is actually smaller than its true value, and the charge decreases with increasing distance from the electron. This polarization was confirmed experimentally in 1997 using the Japanese TRISTAN particle accelerator. Virtual particles cause a comparable shielding effect for the mass of the electron.The interaction with virtual particles also explains the small (about 0.1%) deviation of the intrinsic magnetic moment of the electron from the Bohr magneton (the anomalous magnetic moment). The extraordinarily precise agreement of this predicted difference with the experimentally determined value is viewed as one of the great achievements of quantum electrodynamics.The apparent paradox in classical physics of a point particle electron having intrinsic angular momentum and magnetic moment can be explained by the formation of virtual photons in the electric field generated by the electron. These photons can heuristically be thought of as causing the electron to shift about in a jittery fashion (known as zitterbewegung), which results in a net circular motion with precession. This motion produces both the spin and the magnetic moment of the electron. In atoms, this creation of virtual photons explains the Lamb shift observed in spectral lines. The Compton Wavelength shows that near elementary particles such as the electron, the uncertainty of the energy allows for the creation of virtual particles near the electron. This wavelength explains the ""static"" of virtual particles around elementary particles at a close distance.  Interaction  An electron generates an electric field that exerts an attractive force on a particle with a positive charge, such as the proton, and a repulsive force on a particle with a negative charge. The strength of this force in nonrelativistic approximation is determined by Coulomb\'s inverse square law.: 58–61 When an electron is in motion, it generates a magnetic field.: 140 The Ampère–Maxwell law relates the magnetic field to the mass motion of electrons (the current) with respect to an observer. This property of induction supplies the magnetic field that drives an electric motor. The electromagnetic field of an arbitrary moving charged particle is expressed by the Liénard–Wiechert potentials, which are valid even when the particle\'s speed is close to that of light (relativistic).: 429–434 When an electron is moving through a magnetic field, it is subject to the Lorentz force that acts perpendicularly to the plane defined by the magnetic field and the electron velocity. This centripetal force causes the electron to follow a helical trajectory through the field at a radius called the gyroradius. The acceleration from this curving motion induces the electron to radiate energy in the form of synchrotron radiation.: 160 The energy emission in turn causes a recoil of the electron, known as the Abraham–Lorentz–Dirac Force, which creates a friction that slows the electron. This force is caused by a back-reaction of the electron\'s own field upon itself. Photons mediate electromagnetic interactions between particles in quantum electrodynamics. An isolated electron at a constant velocity cannot emit or absorb a real photon; doing so would violate conservation of energy and momentum. Instead, virtual photons can transfer momentum between two charged particles. This exchange of virtual photons, for example, generates the Coulomb force. Energy emission can occur when a moving electron is deflected by a charged particle, such as a proton. The deceleration of the electron results in the emission of Bremsstrahlung radiation.An inelastic collision between a photon (light) and a solitary (free) electron is called Compton scattering. This collision results in a transfer of momentum and energy between the particles, which modifies the wavelength of the photon by an amount called the Compton shift. The maximum magnitude of this wavelength shift is h/mec, which is known as the Compton wavelength. For an electron, it has a value of 2.43×10−12 m. When the wavelength of the light is long (for instance, the wavelength of the visible light is 0.4–0.7 μm) the wavelength shift becomes negligible. Such interaction between the light and free electrons is called Thomson scattering or linear Thomson scattering.The relative strength of the electromagnetic interaction between two charged particles, such as an electron and a proton, is given by the fine-structure constant. This value is a dimensionless quantity formed by the ratio of two energies: the electrostatic energy of attraction (or repulsion) at a separation of one Compton wavelength, and the rest energy of the charge. It is given by α ≈ 7.297353×10−3, which is approximately equal to 1/137.When electrons and positrons collide, they annihilate each other, giving rise to two or more gamma ray photons. If the electron and positron have negligible momentum, a positronium atom can form before annihilation results in two or three gamma ray photons totalling 1.022 MeV. On the other hand, a high-energy photon can transform into an electron and a positron by a process called pair production, but only in the presence of a nearby charged particle, such as a nucleus.In the theory of electroweak interaction, the left-handed component of electron\'s wavefunction forms a weak isospin doublet with the electron neutrino. This means that during weak interactions, electron neutrinos behave like electrons. Either member of this doublet can undergo a charged current interaction by emitting or absorbing a W and be converted into the other member. Charge is conserved during this reaction because the W boson also carries a charge, canceling out any net change during the transmutation. Charged current interactions are responsible for the phenomenon of beta decay in a radioactive atom. Both the electron and electron neutrino can undergo a neutral current interaction via a Z0 exchange, and this is responsible for neutrino-electron elastic scattering.  Atoms and molecules  An electron can be bound to the nucleus of an atom by the attractive Coulomb force. A system of one or more electrons bound to a nucleus is called an atom. If the number of electrons is different from the nucleus\'s electrical charge, such an atom is called an ion. The wave-like behavior of a bound electron is described by a function called an atomic orbital. Each orbital has its own set of quantum numbers such as energy, angular momentum and projection of angular momentum, and only a discrete set of these orbitals exist around the nucleus. According to the Pauli exclusion principle each orbital can be occupied by up to two electrons, which must differ in their spin quantum number. Electrons can transfer between different orbitals by the emission or absorption of photons with an energy that matches the difference in potential.: 159–160 Other methods of orbital transfer include collisions with particles, such as electrons, and the Auger effect. To escape the atom, the energy of the electron must be increased above its binding energy to the atom. This occurs, for example, with the photoelectric effect, where an incident photon exceeding the atom\'s ionization energy is absorbed by the electron.: 127–132 The orbital angular momentum of electrons is quantized. Because the electron is charged, it produces an orbital magnetic moment that is proportional to the angular momentum. The net magnetic moment of an atom is equal to the vector sum of orbital and spin magnetic moments of all electrons and the nucleus. The magnetic moment of the nucleus is negligible compared with that of the electrons. The magnetic moments of the electrons that occupy the same orbital (so called, paired electrons) cancel each other out.The chemical bond between atoms occurs as a result of electromagnetic interactions, as described by the laws of quantum mechanics. The strongest bonds are formed by the sharing or transfer of electrons between atoms, allowing the formation of molecules. Within a molecule, electrons move under the influence of several nuclei, and occupy molecular orbitals; much as they can occupy atomic orbitals in isolated atoms. A fundamental factor in these molecular structures is the existence of electron pairs. These are electrons with opposed spins, allowing them to occupy the same molecular orbital without violating the Pauli exclusion principle (much like in atoms). Different molecular orbitals have different spatial distribution of the electron density. For instance, in bonded pairs (i.e. in the pairs that actually bind atoms together) electrons can be found with the maximal probability in a relatively small volume between the nuclei. By contrast, in non-bonded pairs electrons are distributed in a large volume around nuclei.  Conductivity  If a body has more or fewer electrons than are required to balance the positive charge of the nuclei, then that object has a net electric charge. When there is an excess of electrons, the object is said to be negatively charged. When there are fewer electrons than the number of protons in nuclei, the object is said to be positively charged. When the number of electrons and the number of protons are equal, their charges cancel each other and the object is said to be electrically neutral. A macroscopic body can develop an electric charge through rubbing, by the triboelectric effect.Independent electrons moving in vacuum are termed free electrons. Electrons in metals also behave as if they were free. In reality the particles that are commonly termed electrons in metals and other solids are quasi-electrons—quasiparticles, which have the same electrical charge, spin, and magnetic moment as real electrons but might have a different mass. When free electrons—both in vacuum and metals—move, they produce a net flow of charge called an electric current, which generates a magnetic field. Likewise a current can be created by a changing magnetic field. These interactions are described mathematically by Maxwell\'s equations.At a given temperature, each material has an electrical conductivity that determines the value of electric current when an electric potential is applied. Examples of good conductors include metals such as copper and gold, whereas glass and Teflon are poor conductors. In any dielectric material, the electrons remain bound to their respective atoms and the material behaves as an insulator. Most semiconductors have a variable level of conductivity that lies between the extremes of conduction and insulation. On the other hand, metals have an electronic band structure containing partially filled electronic bands. The presence of such bands allows electrons in metals to behave as if they were free or delocalized electrons. These electrons are not associated with specific atoms, so when an electric field is applied, they are free to move like a gas (called Fermi gas) through the material much like free electrons. Because of collisions between electrons and atoms, the drift velocity of electrons in a conductor is on the order of millimeters per second. However, the speed at which a change of current at one point in the material causes changes in currents in other parts of the material, the velocity of propagation, is typically about 75% of light speed. This occurs because electrical signals propagate as a wave, with the velocity dependent on the dielectric constant of the material.Metals make relatively good conductors of heat, primarily because the delocalized electrons are free to transport thermal energy between atoms. However, unlike electrical conductivity, the thermal conductivity of a metal is nearly independent of temperature. This is expressed mathematically by the Wiedemann–Franz law, which states that the ratio of thermal conductivity to the electrical conductivity is proportional to the temperature. The thermal disorder in the metallic lattice increases the electrical resistivity of the material, producing a temperature dependence for electric current.When cooled below a point called the critical temperature, materials can undergo a phase transition in which they lose all resistivity to electric current, in a process known as superconductivity. In BCS theory, pairs of electrons called Cooper pairs have their motion coupled to nearby matter via lattice vibrations called phonons, thereby avoiding the collisions with atoms that normally create electrical resistance. (Cooper pairs have a radius of roughly 100 nm, so they can overlap each other.) However, the mechanism by which higher temperature superconductors operate remains uncertain. Electrons inside conducting solids, which are quasi-particles themselves, when tightly confined at temperatures close to absolute zero, behave as though they had split into three other quasiparticles: spinons, orbitons and holons. The former carries spin and magnetic moment, the next carries its orbital location while the latter electrical charge.  Motion and energy  According to Einstein\'s theory of special relativity, as an electron\'s speed approaches the speed of light, from an observer\'s point of view its relativistic mass increases, thereby making it more and more difficult to accelerate it from within the observer\'s frame of reference. The speed of an electron can approach, but never reach, the speed of light in vacuum, c. However, when relativistic electrons—that is, electrons moving at a speed close to c—are injected into a dielectric medium such as water, where the local speed of light is significantly less than c, the electrons temporarily travel faster than light in the medium. As they interact with the medium, they generate a faint light called Cherenkov radiation. The effects of special relativity are based on a quantity known as the Lorentz factor, defined as γ  1 / 1 − v 2 / c 2 {displaystyle scriptstyle gamma 1/{sqrt {1-{v^{2}}/{c^{2}}}}} where v is the speed of the particle. The kinetic energy Ke of an electron moving with velocity v is: K e  ( γ − 1 ) m e c 2 , {displaystyle displaystyle K_{mathrm {e} }(gamma -1)m_{mathrm {e} }c^{2},} where me is the mass of electron. For example, the Stanford linear accelerator can accelerate an electron to roughly 51 GeV. Since an electron behaves as a wave, at a given velocity it has a characteristic de Broglie wavelength. This is given by λe  h/p where h is the Planck constant and p is the momentum. For the 51 GeV electron above, the wavelength is about 2.4×10−17 m, small enough to explore structures well below the size of an atomic nucleus.  Formation  The Big Bang theory is the most widely accepted scientific theory to explain the early stages in the evolution of the Universe. For the first millisecond of the Big Bang, the temperatures were over 10 billion kelvins and photons had mean energies over a million electronvolts. These photons were sufficiently energetic that they could react with each other to form pairs of electrons and positrons. Likewise, positron-electron pairs annihilated each other and emitted energetic photons: γ + γ ↔ e+ + e−An equilibrium between electrons, positrons and photons was maintained during this phase of the evolution of the Universe. After 15 seconds had passed, however, the temperature of the universe dropped below the threshold where electron-positron formation could occur. Most of the surviving electrons and positrons annihilated each other, releasing gamma radiation that briefly reheated the universe.For reasons that remain uncertain, during the annihilation process there was an excess in the number of particles over antiparticles. Hence, about one electron for every billion electron-positron pairs survived. This excess matched the excess of protons over antiprotons, in a condition known as baryon asymmetry, resulting in a net charge of zero for the universe. The surviving protons and neutrons began to participate in reactions with each other—in the process known as nucleosynthesis, forming isotopes of hydrogen and helium, with trace amounts of lithium. This process peaked after about five minutes. Any leftover neutrons underwent negative beta decay with a half-life of about a thousand seconds, releasing a proton and electron in the process, n → p + e− + νeFor about the next 300000–400000 years, the excess electrons remained too energetic to bind with atomic nuclei. What followed is a period known as recombination, when neutral atoms were formed and the expanding universe became transparent to radiation.Roughly one million years after the big bang, the first generation of stars began to form. Within a star, stellar nucleosynthesis results in the production of positrons from the fusion of atomic nuclei. These antimatter particles immediately annihilate with electrons, releasing gamma rays. The net result is a steady reduction in the number of electrons, and a matching increase in the number of neutrons. However, the process of stellar evolution can result in the synthesis of radioactive isotopes. Selected isotopes can subsequently undergo negative beta decay, emitting an electron and antineutrino from the nucleus. An example is the cobalt-60 (60Co) isotope, which decays to form nickel-60 (60Ni). At the end of its lifetime, a star with more than about 20 solar masses can undergo gravitational collapse to form a black hole. According to classical physics, these massive stellar objects exert a gravitational attraction that is strong enough to prevent anything, even electromagnetic radiation, from escaping past the Schwarzschild radius. However, quantum mechanical effects are believed to potentially allow the emission of Hawking radiation at this distance. Electrons (and positrons) are thought to be created at the event horizon of these stellar remnants. When a pair of virtual particles (such as an electron and positron) is created in the vicinity of the event horizon, random spatial positioning might result in one of them to appear on the exterior; this process is called quantum tunnelling. The gravitational potential of the black hole can then supply the energy that transforms this virtual particle into a real particle, allowing it to radiate away into space. In exchange, the other member of the pair is given negative energy, which results in a net loss of mass-energy by the black hole. The rate of Hawking radiation increases with decreasing mass, eventually causing the black hole to evaporate away until, finally, it explodes.Cosmic rays are particles traveling through space with high energies. Energy events as high as 3.0×1020 eV have been recorded. When these particles collide with nucleons in the Earth\'s atmosphere, a shower of particles is generated, including pions. More than half of the cosmic radiation observed from the Earth\'s surface consists of muons. The particle called a muon is a lepton produced in the upper atmosphere by the decay of a pion. π− → μ− + νμA muon, in turn, can decay to form an electron or positron. μ− → e− + νe + νμ  Observation  Remote observation of electrons requires detection of their radiated energy. For example, in high-energy environments such as the corona of a star, free electrons form a plasma that radiates energy due to Bremsstrahlung radiation. Electron gas can undergo plasma oscillation, which is waves caused by synchronized variations in electron density, and these produce energy emissions that can be detected by using radio telescopes.The frequency of a photon is proportional to its energy. As a bound electron transitions between different energy levels of an atom, it absorbs or emits photons at characteristic frequencies.","An electron is a very small piece of matter. Its symbol is e−, and it was discovered by J. J.Thomson in 1897. The electron is a subatomic particle. Every atom is made of some electrons that surround the nucleus of the atom. An electron can also be separate from any atom. It is believed to be an elementary particle because it cannot be broken down into anything smaller. Its electric charge is negative. Electrons have very little mass (little weight) so very little energy is needed to move them fast. They may move almost at the speed of light, for instance, as beta particles, and in the inner electron shells of elements with a large atomic number. Electrons take part in gravitational, electromagnetic and weak interactions. The electromagnetic force is strongest in common situations. Electrons repel (push apart) from each other because they have the same electric charge. Electrons are attracted to protons because they have opposite electric charge. An electron has an electric field, which describes these forces. The electricity that powers televisions, motors, mobile phones, and many other things is actually many electrons moving through wires or other conductors.  Description  Electrons have the smallest electrical charge. This electrical charge equals the charge of a proton, but has the opposite sign. For this reason, electrons are attracted towards the protons in atomic nuclei. This attraction makes electrons near a nucleus form an atom. An electron has a mass of about 1/1836 times a proton. One way to think about the location of electrons in an atom is to imagine that they orbit at fixed distances from the nucleus. This way, electrons in an atom exist in a number of electron shells surrounding the central nucleus. Each electron shell is given a number 1, 2, 3, and so on, starting from the one closest to the nucleus (the innermost shell). Each shell can hold up to a certain maximum number of electrons. The distribution of electrons in the various shells is called electronic arrangement (or electronic form or shape). Electronic arrangement can be shown by numbering or an electron diagram. (A different way to think about the location of electrons is to use quantum mechanics to calculate their atomic orbitals.)The electron is one of a type of subatomic particles called leptons. The electron has a negative electric charge. The electron has another property, called spin. Its spin value is 1/2, which makes it a fermion. While most electrons are found in atoms, others move independently in matter, or together as cathode rays in a vacuum. In some superconductors, electrons move in pairs. When electrons flow, this flow is called electricity, or an electric current. An object can be described as 'negatively charged' if there are more electrons than protons in an object, or 'positively charged' when there are more protons than electrons. Electrons can move from one object to another when touched. They may be attracted to another object with opposite charge, or repelled when they both have the same charge. When an object is 'grounded', electrons from the charged object go into the ground, making the object neutral. This is what lightning rods (lightning conductors) do.  Chemical reactions  Electrons in their shells round an atom are the basis of chemical reactions. Complete outer shells, with maximum electrons, are less reactive. Outer shells with less than maximum electrons are reactive. The number of electrons in atoms is the underlying basis of the chemical periodic table.  Measurement  Electric charge can be directly measured with a device called an electrometer. Electric current can be directly measured with a galvanometer. The measurement given off by a galvanometer is different from the measurement given off by an electrometer. Today laboratory instruments are capable of containing and observing individual electrons.  'Seeing' an electron  In laboratory conditions, the interactions of individual electrons can be observed by means of particle detectors, which allow measurement of specific properties such as energy, spin and charge. In one instance a Penning trap was used to contain a single electron for 10 months. The magnetic moment of the electron was measured to a precision of eleven digits, which, in 1980, was a greater accuracy than for any other physical constant.The first video images of an electron's energy distribution were captured by a team at Lund University in Sweden, February 2008. The scientists used extremely short flashes of light, called attosecond pulses, which allowed an electron's motion to be observed for the first time. The distribution of the electrons in solid materials can also be visualized.  Anti-particle  The antiparticle of the electron is called a positron. This is identical to the electron, but carries electrical and other charges of the opposite sign. When an electron collides with a positron, they may scatter off each other or be totally annihilated, producing a pair (or more) of gamma ray photons.  History of its discovery  The effects of electrons were known long before it could be explained. The Ancient Greeks knew that rubbing amber against fur attracted small objects. Now we know the rubbing strips off electrons, and that gives an electric charge to the amber. Many physicists worked on the electron. J.J. Thomson proved it existed, in 1897, but another man gave it the name 'electron'.  The electron cloud model  The model views electrons as holding indeterminate positions in a diffuse cloud around the nucleus of the atom. The uncertainty principle means a person cannot know an electron's position and energy level at the same time. These potential states form a cloud around the atom. The potential states of electrons in a single atom form a single, uniform cloud.  Related pages  Positron Proton Neutron  References   Other websites  ""The Discovery of the Electron"". American Institute of Physics, Center for History of Physics. Archived from the original on 2008-03-16. Retrieved 2012-11-26. ""Particle Data Group"". University of California. Bock, R.K.; Vasilescu, A. (1998). The Particle Detector BriefBook (14th ed.). Springer. ISBN 3-540-64120-3."
"A leg is a weight-bearing and locomotive anatomical structure, usually having a columnar shape. During locomotion, legs function as ""extensible struts"". The combination of movements at all joints can be modeled as a single, linear element capable of changing length and rotating about an omnidirectional ""hip"" joint. As an anatomical animal structure it is used for locomotion. The distal end is often modified to distribute force (such as a foot). Most animals have an even number of legs. As a component of furniture, it is used for the economy of materials needed to provide the support for the useful surface, such as the table top or chair seat.  Terminology  Uniped: 1 leg, such as clams Biped: 2 legs, such as humans and birds Triped: 3 legs, which typically does not occur naturally in healthy animals Quadruped: 4 legs, such as dogs and horsesMany taxa are characterized by the number of legs: Tetrapods have four legs. Squamates of genus Bipes have only two. Caecilians and many squamate lineages convergently lost their legs. Panarthropoda: no less than 4 legs. Velvet worms and some arthropods have more than a dozen legs; a few species possess over 100. Despite what their names might suggest, centipedes (""hundred feet"") may have fewer than 20 or more than 300 legs, and millipedes (""thousand feet"") have fewer than 1,000 legs, but up to 750.  Components  A leg is a structure of gross anatomy, meaning that it is large enough to be seen unaided. The components depend on the animal. In humans and other mammals, a leg includes the bones, muscles, tendons, ligaments, blood vessels, nerves, and skin. In insects, the leg includes most of these things, except that insects have an exoskeleton that replaces the function of both the bones and the skin. Sometimes the end of the leg, or foot, is considered part of the leg; other times it is considered separate. Similarly, the hip joint or other place where the leg attaches to the main body may be considered separate or part of the leg.  Tetrapod legs  In tetrapod anatomy, leg is used to refer to the entire limb. In human medicine the precise definition refers only to the segment between the knee and the ankle. This lower segment is also called the shank, and the front (anterior) of the segment is called the shin or pretibia. In bipedal tetrapods, the two lower limbs are referred to as the ""legs"" and the two upper limbs as ""arms"" or ""wings"" as the case may be. Human leg  Arthropod leg  Arthropod leg  Robotic leg  A robotic leg is moved by an actuator, which is a type of motor for moving or controlling a mechanism or system. It is operated by a source of energy, usually in the form of an electric current, hydraulic fluid pressure or pneumatic pressure, and converts that energy into some kind of motion.  Prosthetic leg  A prosthetic leg is an artificial leg that is used to replace one that has been lost.  References   External links  Media related to Leg at Wikimedia Commons","A leg is a weight-bearing and locomotion device. Birds and humans have two legs, but many animals have four or six or even more. A biped is an animal with two legs and quadruped is an animal with four legs. Centipedes and millipedes have many more legs. By extension, the word is also used for some objects. For example tables and chairs, also have legs to hold them up. People also use the word ""leg"" in idioms, for example: you do not have a leg to stand on (that means ""you have no support; you have no chance in this discussion"") to leg it (to run) to pull someone's leg (to play a little joke on someone for fun by trying to make them believe something that is not true)  Components  A leg is a structure of gross anatomy, meaning that it is large enough to be seen unaided. The components depend on the animal. In humans and other mammals, a leg includes the bones, muscles, tendons, ligaments, blood vessels, nerves, and skin. In insects, the leg includes most of these things, except that insects have an exoskeleton that replaces the function of both the bones and the skin. Sometimes the end of the leg, or foot, is considered part of the leg; other times it is considered separate. Similarly, the hip joint or other place where the leg attaches to the main body may be considered separate or part of the leg.  Robotic leg  A robotic leg is moved by an actuator, which is a type of motor for moving or controlling a mechanism or system. It is operated by a source of energy, usually in the form of an electric current and converts that energy into some kind of motion.  Prosthetic leg  A prosthetic leg is an artificial leg that is used to replace one that has been lost"
"The foot (PL: feet) is an anatomical structure found in many vertebrates. It is the terminal portion of a limb which bears weight and allows locomotion. In many animals with feet, the foot is a separate organ at the terminal part of the leg made up of one or more segments or bones, generally including claws and or nails.  Etymology  The word ""foot"", in the sense of meaning the ""terminal part of the leg of a vertebrate animal"" comes from ""Old English fot ""foot,"" from Proto-Germanic fot (source also of Old Frisian fot, Old Saxon fot, Old Norse fotr, Danish fod, Swedish fot, Dutch voet, Old High German fuoz, German Fuß, Gothic fotus ""foot""), from PIE root ped- ""foot"". The ""plural form feet is an instance of i-mutation.""  Structure  The human foot is a strong and complex mechanical structure containing 26 bones, 33 joints (20 of which are actively articulated), and more than a hundred muscles, tendons, and ligaments. The joints of the foot are the ankle and subtalar joint and the interphalangeal joints of the foot. An anthropometric study of 1197 North American adult Caucasian males (mean age 35.5 years) found that a man's foot length was 26.3 cm with a standard deviation of 1.2 cm.The foot can be subdivided into the hindfoot, the midfoot, and the forefoot: The hindfoot is composed of the talus (or ankle bone) and the calcaneus (or heel bone). The two long bones of the lower leg, the tibia and fibula, are connected to the top of the talus to form the ankle. Connected to the talus at the subtalar joint, the calcaneus, the largest bone of the foot, is cushioned underneath by a layer of fat.The five irregular bones of the midfoot, the cuboid, navicular, and three cuneiform bones, form the arches of the foot which serves as a shock absorber. The midfoot is connected to the hind- and fore-foot by muscles and the plantar fascia.The forefoot is composed of five toes and the corresponding five proximal long bones forming the metatarsus. Similar to the fingers of the hand, the bones of the toes are called phalanges and the big toe has two phalanges while the other four toes have three phalanges each. The joints between the phalanges are called interphalangeal and those between the metatarsus and phalanges are called metatarsophalangeal (MTP). Both the midfoot and forefoot constitute the dorsum (the area facing upward while standing) and the planum (the area facing downward while standing). The instep is the arched part of the top of the foot between the toes and the ankle.  Bones  tibia, fibula tarsus (7): talus, calcaneus, cuneiformes (3), cuboid, and navicular metatarsus (5): first, second, third, fourth, and fifth metatarsal bone phalanges (14)There can be many sesamoid bones near the metatarsophalangeal joints, although they are only regularly present in the distal portion of the first metatarsal bone.  Arches  The human foot has two longitudinal arches and a transverse arch maintained by the interlocking shapes of the foot bones, strong ligaments, and pulling muscles during activity. The slight mobility of these arches when weight is applied to and removed from the foot makes walking and running more economical in terms of energy. As can be examined in a footprint, the medial longitudinal arch curves above the ground. This arch stretches from the heel bone over the ""keystone"" ankle bone to the three medial metatarsals. In contrast, the lateral longitudinal arch is very low. With the cuboid serving as its keystone, it redistributes part of the weight to the calcaneus and the distal end of the fifth metatarsal. The two longitudinal arches serve as pillars for the transverse arch which run obliquely across the tarsometatarsal joints. Excessive strain on the tendons and ligaments of the feet can result in fallen arches or flat feet.  Muscles  The muscles acting on the foot can be classified into extrinsic muscles, those originating on the anterior or posterior aspect of the lower leg, and intrinsic muscles, originating on the dorsal (top) or plantar (base) aspects of the foot.  Extrinsic  All muscles originating on the lower leg except the popliteus muscle are attached to the bones of the foot. The tibia and fibula and the interosseous membrane separate these muscles into anterior and posterior groups, in their turn subdivided into subgroups and layers.  Anterior group  Extensor group: the tibialis anterior originates on the proximal half of the tibia and the interosseous membrane and is inserted near the tarsometatarsal joint of the first digit. In the non-weight-bearing leg, the tibialis anterior dorsiflexes the foot and lift its medial edge (supination). In the weight-bearing leg, it brings the leg toward the back of the foot, like in rapid walking. The extensor digitorum longus arises on the lateral tibial condyle and along the fibula, and is inserted on the second to fifth digits and proximally on the fifth metatarsal. The extensor digitorum longus acts similar to the tibialis anterior except that it also dorsiflexes the digits. The extensor hallucis longus originates medially on the fibula and is inserted on the first digit. It dorsiflexes the big toe and also acts on the ankle in the unstressed leg. In the weight-bearing leg, it acts similarly to the tibialis anterior.Peroneal group: the peroneus longus arises on the proximal aspect of the fibula and peroneus brevis below it. Together, their tendons pass behind the lateral malleolus. Distally, the peroneus longus crosses the plantar side of the foot to reach its insertion on the first tarsometatarsal joint, while the peroneus brevis reaches the proximal part of the fifth metatarsal. These two muscles are the strongest pronators and aid in plantar flexion. The peroneus longus also acts like a bowstring that braces the transverse arch of the foot.  Posterior group  The superficial layer of posterior leg muscles is formed by the triceps surae and the plantaris. The triceps surae consists of the soleus and the two heads of the gastrocnemius. The heads of gastrocnemius arise on the femur, proximal to the condyles, and the soleus arises on the proximal dorsal parts of the tibia and fibula. The tendons of these muscles merge to be inserted onto the calcaneus as the Achilles tendon. The plantaris originates on the femur proximal to the lateral head of the gastrocnemius and its long tendon is embedded medially into the Achilles tendon. The triceps surae is the primary plantar flexor. Its strength becomes most obvious during ballet dancing. It is fully activated only with the knee extended, because the gastrocnemius is shortened during flexion of the knee. During walking it not only lifts the heel, but also flexes the knee, assisted by the plantaris.In the deep layer of posterior muscles, the tibialis posterior arises proximally on the back of the interosseous membrane and adjoining bones, and divides into two parts in the sole of the foot to attach to the tarsus. In the non-weight-bearing leg, it produces plantar flexion and supination, and, in the weight-bearing leg, it proximates the heel to the calf. The flexor hallucis longus arises on the back of the fibula on the lateral side, and its relatively thick muscle belly extends distally down to the flexor retinaculum where it passes over to the medial side to stretch across the sole to the distal phalanx of the first digit. The popliteus is also part of this group, but, with its oblique course across the back of the knee, does not act on the foot.  Intrinsic  On the top of the foot, the tendons of extensor digitorum brevis and extensor hallucis brevis lie deep in the system of long extrinsic extensor tendons. They both arise on the calcaneus and extend into the dorsal aponeurosis of digits one to four, just beyond the penultimate joints. They act to dorsiflex the digits. Similar to the intrinsic muscles of the hand, there are three groups of muscles in the sole of foot, those of the first and last digits, and a central group: Muscles of the big toe: the abductor hallucis stretches medially along the border of the sole, from the calcaneus to the first digit. Below its tendon, the tendons of the long flexors pass through the tarsal canal. The abductor hallucis is an abductor and a weak flexor, and also helps maintain the arch of the foot. The flexor hallucis brevis arises on the medial cuneiform bone and related ligaments and tendons. An important plantar flexor, it is crucial to ballet dancing. Both these muscles are inserted with two heads proximally and distally to the first metatarsophalangeal joint. The adductor hallucis is part of this group, though it originally formed a separate system (see Contrahens). It has two heads, the oblique head originating obliquely across the central part of the midfoot, and the transverse head originating near the metatarsophalangeal joints of digits five to three. Both heads are inserted into the lateral sesamoid bone of the first digit. The adductor hallucis acts as a tensor of the plantar arches and also adducts the big toe and might plantar flex the proximal phalanx.Muscles of the little toe: Stretching laterally from the calcaneus to the proximal phalanx of the fifth digit, the abductor digiti minimi form the lateral margin of the foot and are the largest of the muscles of the fifth digit. Arising from the base of the fifth metatarsal, the flexor digiti minimi is inserted together with abductor on the first phalanx. Often absent, the opponens digiti minimi originates near the cuboid bone and is inserted on the fifth metatarsal bone. These three muscles act to support the arch of the foot and to plantar flex the fifth digit. Central muscle group: The four lumbricals arise on the medial side of the tendons of flexor digitorum longus and are inserted on the medial margins of the proximal phalanges. The quadratus plantae originates with two slips from the lateral and medial margins of the calcaneus and inserts into the lateral margin of the flexor digitorum tendon. It is also known as the flexor accessorius. The flexor digitorum brevis arises inferiorly on the calcaneus and its three tendons are inserted into the middle phalanges of digits two to four (sometimes also the fifth digit). These tendons divide before their insertions and the tendons of flexor digitorum longus pass through these divisions. Flexor digitorum brevis flexes the middle phalanges. It is occasionally absent. Between the toes, the dorsal and plantar interossei stretch from the metatarsals to the proximal phalanges of digits two to five. The plantar interossei adduct and the dorsal interossei abduct these digits, and are also plantar flexors at the metatarsophalangeal joints.  Clinical significance  Due to their position and function, feet are exposed to a variety of potential infections and injuries, including athlete's foot, bunions, ingrown toenails, Morton's neuroma, plantar fasciitis, plantar warts, and stress fractures. In addition, there are several genetic disorders that can affect the shape and function of the feet, including clubfoot or flat feet. This leaves humans more vulnerable to medical problems that are caused by poor leg and foot alignments. Also, the wearing of shoes, sneakers and boots can impede proper alignment and movement within the ankle and foot. For example, high-heeled shoes are known to throw off the natural weight balance (this can also affect the lower back). For the sake of posture, flat soles with no heels are advised. A doctor who specializes in the treatment of the feet practices podiatry and is called a podiatrist. A pedorthist specializes in the use and modification of footwear to treat problems related to the lower limbs. Fractures of the foot include: Lisfranc fracture – in which one or all of the metatarsals are displaced from the tarsus Jones fracture – a fracture of the fifth metatarsal March fracture – a fracture of the distal third of one of the metatarsals occurring because of recurrent stress Calcaneal fracture Broken toe – a fracture of a phalanx Cuneiform fracture – Due to the ligamentous support of the midfoot, isolated cuneiform fractures are rare.  Pronation  In anatomy, pronation is a rotational movement of the forearm (at the radioulnar joint) or foot (at the subtalar and talocalcaneonavicular joints). Pronation of the foot refers to how the body distributes weight as it cycles through the gait. During the gait cycle the foot can pronate in many different ways based on rearfoot and forefoot function. Types of pronation include neutral pronation, underpronation (supination), and overpronation. Neutral pronationAn individual who neutrally pronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will roll in a medial direction, such that the weight is distributed evenly across the metatarsus. In this stage of the gait, the knee will generally, but not always, track directly over the hallux. This rolling inward motion as the foot progresses from heel to toe is the way that the body naturally absorbs shock. Neutral pronation is the most ideal, efficient type of gait when using a heel strike gait; in a forefoot strike, the body absorbs shock instead via flexion of the foot. OverpronationAs with a neutral pronator, an individual who overpronates initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, however, the foot will roll too far in a medial direction, such that the weight is distributed unevenly across the metatarsus, with excessive weight borne on the hallux. In this stage of the gait, the knee will generally, but not always, track inward. An overpronator does not absorb shock efficiently. Imagine someone jumping onto a diving board, but the board is so flimsy that when it is struck, it bends and allows the person to plunge straight down into the water instead of back into the air. Similarly, an overpronator's arches will collapse, or the ankles will roll inward (or a combination of the two) as they cycle through the gait. An individual whose bone structure involves external rotation at the hip, knee, or ankle will be more likely to overpronate than one whose bone structure has internal rotation or central alignment. An individual who overpronates tends to wear down their running shoes on the medial (inside) side of the shoe toward the toe area.When choosing a running or walking shoe, a person with overpronation can choose shoes that have good inside support—usually by strong material at the inside sole and arch of the shoe. It is usually visible. The inside support area is marked by strong greyish material to support the weight when a person lands on the outside foot and then roll onto the inside foot. Underpronation (supination) An individual who underpronates also initially strikes the ground on the lateral side of the heel. As the individual transfers weight from the heel to the metatarsus, the foot will not roll far enough in a medial direction. The weight is distributed unevenly across the metatarsus, with excessive weight borne on the fifth metatarsal, toward the lateral side of the foot. In this stage of the gait, the knee will generally, but not always, track laterally of the hallux. Like an overpronator, an underpronator does not absorb shock efficiently – but for the opposite reason. The underpronated foot is like a diving board that, instead of failing to spring someone in the air because it is too flimsy, fails to do so because it is too rigid. There is virtually no give. An underpronator's arches or ankles don't experience much motion as they cycle through the gait. An individual whose bone structure involves internal rotation at the hip, knee, or ankle will be more likely to underpronate than one whose bone structure has external rotation or central alignment. Usually – but not always – those who are bow-legged tend to underpronate. An individual who underpronates tends to wear down their running shoes on the lateral (outside) side of the shoe toward the rear of the shoe in the heel area.  Society and culture  Humans usually wear shoes or similar footwear for protection from hazards when walking outside. There are a number of contexts where it is considered inappropriate to wear shoes. Some people consider it rude to wear shoes into a house and a Māori Marae should only be entered with bare feet. Foot fetishism is the most common sexual fetish.  Other animals  A paw is the soft foot of a mammal, generally a quadruped, that has claws or nails (e.g., a cat or dog's paw). A hard foot is called a hoof. Depending on style of locomotion, animals can be classified as plantigrade (sole walking), digitigrade (toe walking), or unguligrade (nail walking). The metatarsals are the bones that make up the main part of the foot in humans, and part of the leg in large animals or paw in smaller animals. The number of metatarsals are directly related to the mode of locomotion with many larger animals having their digits reduced to two (elk, cow, sheep) or one (horse). The metatarsal bones of feet and paws are tightly grouped compared to, most notably, the human hand where the thumb metacarpal diverges from the rest of the metacarpus.  Metaphorical and cultural usage  The word ""foot"" is used to refer to a ""...linear measure was in Old English (the exact length has varied over time), this being considered the length of a man's foot; a unit of measure used widely and anciently. In this sense the plural is often foot. The current inch and foot are implied from measurements in 12c."" The word ""foot"" also has a musical meaning; a ""...metrical foot (late Old English, translating Latin pes, Greek pous in the same sense) is commonly taken to represent one rise and one fall of a foot: keeping time according to some, dancing according to others.""The word ""foot"" was used in Middle English to mean ""a person"" (c. 1200). The expression ""...to put one's best foot foremost first recorded 1849 (Shakespeare has the better foot before, 1596)"". The expression to ""...put one's foot in (one's) mouth ""say something stupid"" was first used in 1942. The expression ""put (one's) foot in something"" meaning to ""make a mess of it"" was used in 1823.The word ""footloose"" was first used in the 1690s, meaning ""free to move the feet, unshackled""; the more ""figurative sense of ""free to act as one pleases"" was first used in 1873. Like ""footloose"", ""flat-footed"" at first had its obvious literal meaning (in 1600, it meant ""with flat feet"") but by 1912 it meant ""unprepared"" (U.S. baseball slang).  See also   References   Bibliography  France, Diane L. (2008). Human and Nonhuman Bone Identification: A Color Atlas. CRC Press. ISBN 978-1-4200-6286-1. Marieb, Elaine Nicpon; Hoehn, Katja (2007). Human anatomy & physiology. Pearson Education. ISBN 978-0-321-37294-9. Platzer, Werner (2004). Color Atlas of Human Anatomy, Vol. 1: Locomotor System (5th ed.). Thieme. ISBN 3-13-533305-1. ""Anatomy of the foot and ankle"". Podiatry Channel. Archived from the original on 31 August 2009. Retrieved 21 August 2009.  External links  Foot at Curlie","Foot is also the name of a unit of measurement. See foot (unit). A foot (one foot, two or more feet) is a body part on the end of a leg. It is used when walking. It is also important for balance: it helps people stand straight. People also use it to kick, in both fighting and sports, football being an example. People's hands and feet have the same shape: they both have five digits (the fingers and toes). Many other animals with backbones also have five digits. The part of the foot which joins it to the leg is called the heel. The bottom of the foot is called the sole. Most land vertebrates have feet, and there are many different sorts of foot. The feet of monkeys are much like the hands. The hard foot of an ungulate is a hoof. When an animal has soft feet, or feet with soft parts on the underside, it is called a paw. Many invertebrates also have feet. Many use footwear to protect themselves from weather and dirt. There are multiple kinds of footwear, for example sandals, shoes, and boots. When people do not remove footwear, especially in hot places or when they are very active, their feet can smell badly (foot odour). Wearing footwear that is too big or small can be bad for the feet, causing blisters. People who have foot, leg, and back problems can also get help from special shoes. People have different traditions in different parts of the world for when to wear footwear. For example, in many countries, usually do not wear their shoes or boots in a home. In the United States people often wear shoes inside a home. In Japan, people do not wear shoes in homes, and floors are often made of very soft materials. In Japan it is also important to keep the floors clean. In cultures where people always wear shoes, people sometimes think it is bad not to wear them. Not wearing shoes can be good for the feet, especially if they are damaged. Conditions like Athlete's foot affect the feet, causing the feet to feel dry and cracked. Doctors who work with people's feet are podiatrists or chiropodists.  Bones  Half the bones in a human body are in the foot. There are 26 bones there. They are 14 phalanges (toes), 5 metatarsals (arch of the foot), and 7 tarsals (ankle bones)."
"An ear is the organ that enables hearing and, in mammals, body balance using the vestibular system. In mammals, the ear is usually described as having three parts—the outer ear, the middle ear and the inner ear. The outer ear consists of the pinna and the ear canal. Since the outer ear is the only visible portion of the ear in most animals, the word ""ear"" often refers to the external part alone. The middle ear includes the tympanic cavity and the three ossicles. The inner ear sits in the bony labyrinth, and contains structures which are key to several senses: the semicircular canals, which enable balance and eye tracking when moving; the utricle and saccule, which enable balance when stationary; and the cochlea, which enables hearing. The ears of vertebrates are placed somewhat symmetrically on either side of the head, an arrangement that aids sound localization. The ear develops from the first pharyngeal pouch and six small swellings that develop in the early embryo called otic placodes, which are derived from ectoderm. The ear may be affected by disease, including infection and traumatic damage. Diseases of the ear may lead to hearing loss, tinnitus and balance disorders such as vertigo, although many of these conditions may also be affected by damage to the brain or neural pathways leading from the ear. The ear has been adorned by earrings and other jewelry in numerous cultures for thousands of years, and has been subjected to surgical and cosmetic alterations.  Structure  The human ear consists of three parts—the outer ear, middle ear and inner ear. The ear canal of the outer ear is separated from the air-filled tympanic cavity of the middle ear by the eardrum. The middle ear contains the three small bones—the ossicles—involved in the transmission of sound, and is connected to the throat at the nasopharynx, via the pharyngeal opening of the Eustachian tube. The inner ear contains the otolith organs—the utricle and saccule—and the semicircular canals belonging to the vestibular system, as well as the cochlea of the auditory system.  Outer ear  The outer ear is the external portion of the ear and includes the fleshy visible pinna (also called the auricle), the ear canal, and the outer layer of the eardrum (also called the tympanic membrane).The pinna consists of the curving outer rim called the helix, the inner curved rim called the antihelix, and opens into the ear canal. The tragus protrudes and partially obscures the ear canal, as does the facing antitragus. The hollow region in front of the ear canal is called the concha. The ear canal stretches for about 1 inch (2.5 cm). The first part of the canal is surrounded by cartilage, while the second part near the eardrum is surrounded by bone. This bony part is known as the auditory bulla and is formed by the tympanic part of the temporal bone. The skin surrounding the ear canal contains ceruminous and sebaceous glands that produce protective ear wax. The ear canal ends at the external surface of the eardrum.Two sets of muscles are associated with the outer ear: the intrinsic and extrinsic muscles. In some mammals, these muscles can adjust the direction of the pinna. In humans, these muscles have little or no effect. The ear muscles are supplied by the facial nerve, which also supplies sensation to the skin of the ear itself, as well as to the external ear cavity. The great auricular nerve, auricular nerve, auriculotemporal nerve, and lesser and greater occipital nerves of the cervical plexus all supply sensation to parts of the outer ear and the surrounding skin.The pinna consists of a single piece of elastic cartilage with a complicated relief on its inner surface and a fairly smooth configuration on its posterior surface. A tubercle, known as Darwin's tubercle, is sometimes present, lying in the descending part of the helix and corresponding to the ear-tip of mammals. The earlobe consists of areola and adipose tissue. The symmetrical arrangement of the two ears allows for the localisation of sound. The brain accomplishes this by comparing arrival-times and intensities from each ear, in circuits located in the superior olivary complex and the trapezoid bodies which are connected via pathways to both ears.  Middle ear  The middle ear lies between the outer ear and the inner ear. It consists of an air-filled cavity called the tympanic cavity and includes the three ossicles and their attaching ligaments; the auditory tube; and the round and oval windows. The ossicles are three small bones that function together to receive, amplify, and transmit the sound from the eardrum to the inner ear. The ossicles are the malleus (hammer), incus (anvil), and the stapes (stirrup). The stapes is the smallest named bone in the body. The middle ear also connects to the upper throat at the nasopharynx via the pharyngeal opening of the Eustachian tube.The three ossicles transmit sound from the outer ear to the inner ear. The malleus receives vibrations from sound pressure on the eardrum, where it is connected at its longest part (the manubrium or handle) by a ligament. It transmits vibrations to the incus, which in turn transmits the vibrations to the small stapes bone. The wide base of the stapes rests on the oval window. As the stapes vibrates, vibrations are transmitted through the oval window, causing movement of fluid within the cochlea.The round window allows for the fluid within the inner ear to move. As the stapes pushes the secondary tympanic membrane, fluid in the inner ear moves and pushes the membrane of the round window out by a corresponding amount into the middle ear. The ossicles help amplify sound waves by nearly 15–20 times.  Inner ear  The inner ear sits within the temporal bone in a complex cavity called the bony labyrinth. A central area known as the vestibule contains two small fluid-filled recesses, the utricle and saccule. These connect to the semicircular canals and the cochlea. There are three semicircular canals angled at right angles to each other which are responsible for dynamic balance. The cochlea is a spiral shell-shaped organ responsible for the sense of hearing. These structures together create the membranous labyrinth.The bony labyrinth refers to the bony compartment which contains the membranous labyrinth, contained within the temporal bone. The inner ear structurally begins at the oval window, which receives vibrations from the incus of the middle ear. Vibrations are transmitted into the inner ear into a fluid called endolymph, which fills the membranous labyrinth. The endolymph is situated in two vestibules, the utricle and saccule, and eventually transmits to the cochlea, a spiral-shaped structure. The cochlea consists of three fluid-filled spaces: the vestibular duct, the cochlear duct, and the tympanic duct. Hair cells responsible for transduction—changing mechanical changes into electrical stimuli are present in the organ of Corti in the cochlea.  Blood supply  The blood supply of the ear differs according to each part of the ear. The outer ear is supplied by a number of arteries. The posterior auricular artery provides the majority of the blood supply. The anterior auricular arteries provide some supply to the outer rim of the ear and scalp behind it. The posterior auricular artery is a direct branch of the external carotid artery, and the anterior auricular arteries are branches from the superficial temporal artery. The occipital artery also plays a role.The middle ear is supplied by the mastoid branch of either the occipital or posterior auricular arteries and the deep auricular artery, a branch of the maxillary artery. Other arteries which are present but play a smaller role include branches of the middle meningeal artery, ascending pharyngeal artery, internal carotid artery, and the artery of the pterygoid canal.The inner ear is supplied by the anterior tympanic branch of the maxillary artery; the stylomastoid branch of the posterior auricular artery; the petrosal branch of middle meningeal artery; and the labyrinthine artery, arising from either the anterior inferior cerebellar artery or the basilar artery.  Function   Hearing  Sound waves travel through the outer ear, are modulated by the middle ear, and are transmitted to the vestibulocochlear nerve in the inner ear. This nerve transmits information to the temporal lobe of the brain, where it is registered as sound. Sound that travels through the outer ear impacts on the eardrum, and causes it to vibrate. The three ossicles bones transmit this sound to a second window (the oval window) which protects the fluid-filled inner ear. In detail, the pinna of the outer ear helps to focus a sound, which impacts on the eardrum. The malleus rests on the membrane, and receives the vibration. This vibration is transmitted along the incus and stapes to the oval window. Two small muscles, the tensor tympani and stapedius, also help modulate noise. The two muscles reflexively contract to dampen excessive vibrations. Vibration of the oval window causes vibration of the endolymph within the vestibule and the cochlea.The inner ear houses the apparatus necessary to change the vibrations transmitted from the outside world via the middle ear into signals passed along the vestibulocochlear nerve to the brain. The hollow channels of the inner ear are filled with liquid, and contain a sensory epithelium that is studded with hair cells. The microscopic ""hairs"" of these cells are structural protein filaments that project out into the fluid. The hair cells are mechanoreceptors that release a chemical neurotransmitter when stimulated. Sound waves moving through fluid flows against the receptor cells of the organ of Corti. The fluid pushes the filaments of individual cells; movement of the filaments causes receptor cells to become open to receive the potassium-rich endolymph. This causes the cell to depolarise, and creates an action potential that is transmitted along the spiral ganglion, which sends information through the auditory portion of the vestibulocochlear nerve to the temporal lobe of the brain.The human ear can generally hear sounds with frequencies between 20 Hz and 20 kHz (the audio range). Sounds outside this range are considered infrasound (below 20 Hz) or ultrasound (above 20 kHz) Although hearing requires an intact and functioning auditory portion of the central nervous system as well as a working ear, human deafness (extreme insensitivity to sound) most commonly occurs because of abnormalities of the inner ear, rather than in the nerves or tracts of the central auditory system.  Balance  Providing balance, when moving or stationary, is also a central function of the ear. The ear facilitates two types of balance: static balance, which allows a person to feel the effects of gravity, and dynamic balance, which allows a person to sense acceleration. Static balance is provided by two ventricles, the utricle and the saccule. Cells lining the walls of these ventricles contain fine filaments, and the cells are covered with a fine gelatinous layer. Each cell has 50–70 small filaments, and one large filament, the kinocilium. Within the gelatinous layer lie otoliths, tiny formations of calcium carbonate. When a person moves, these otoliths shift position. This shift alters the positions of the filaments, which opens ion channels within the cell membranes, creating depolarisation and an action potential that is transmitted to the brain along the vestibulocochlear nerve.Dynamic balance is provided through the three semicircular canals. These three canals are orthogonal (at right angles) to each other. At the end of each canal is a slight enlargement, known as the ampulla, which contains numerous cells with filaments in a central area called the cupula. The fluid in these canals rotates according to the momentum of the head. When a person changes acceleration, the inertia of the fluid changes. This affects the pressure on the cupula, and results in the opening of ion channels. This causes depolarisation, which is passed as a signal to the brain along the vestibulocochlear nerve. Dynamic balance also helps maintain eye tracking when moving, via the vestibulo–ocular reflex.  Development  During embryogenesis the ear develops as three distinct structures: the inner ear, the middle ear and the outer ear. Each structure originates from a different germ layer: the ectoderm, endoderm and mesenchyme.  Inner ear  After implantation, around the second to third week the developing embryo consists of three layers: endoderm, mesoderm and ectoderm. The first part of the ear to develop is the inner ear, which begins to form from the ectoderm around the 22nd day of the embryo's development. Specifically, the inner ear derives from two thickenings called otic placodes on either side of the head. Each otic placode recedes below the ectoderm, forms an otic pit and then an otic vesicle. This entire mass will eventually become surrounded by mesenchyme to form the bony labyrinth.Around the 33rd day of development, the vesicles begin to differentiate. Closer to the back of the embryo, they form what will become the utricle and semicircular canals. Closer to the front of the embryo, the vesicles differentiate into a rudimentary saccule, which will eventually become the saccule and cochlea. Part of the saccule will eventually give rise and connect to the cochlear duct. This duct appears approximately during the sixth week and connects to the saccule through the ductus reuniens.As the cochlear duct's mesenchyme begins to differentiate, three cavities are formed: the scala vestibuli, the scala tympani and the scala media. Both the scala vestibuli and the scala tympani contain an extracellular fluid called perilymph. The scala media contains endolymph. A set of membranes called the vestibular membrane and the basilar membrane develop to separate the cochlear duct from the vestibular duct and the tympanic duct, respectively.Parts of the otic vesicle in turn form the vestibulocochlear nerve. These form bipolar neurons which supply sensation to parts of the inner ear (namely the sensory parts of the semicircular canals, macular of the utricle and saccule, and organ of Corti). The nerve begins to form around the 28th day. Molecular regulationMost of the genes responsible for the regulation of inner ear formation and its morphogenesis are members of the homeobox gene family such as Pax, Msx and Otx homeobox genes. The development of inner ear structures such as the cochlea is regulated by Dlx5/Dlx6, Otx1/Otx2 and Pax2, which in turn are controlled by the master gene Shh. Shh is secreted by the notochord.  Middle ear  The middle ear and its components develop from the first and second pharyngeal arches. The tympanic cavity and auditory tube develop from the first part of the pharyngeal pouch between the first two arches in an area which will also go on to develop the pharynx. This develops as a structure called the tubotympanic recess. The ossicles (malleus, incus and stapes) normally appear during the first half of fetal development. The first two (malleus and incus) derive from the first pharyngeal arch and the stapes derives from the second. All three ossicles develop from the neural crest. Eventually cells from the tissue surrounding the ossicles will experience apoptosis and a new layer of endodermal epithelial will constitute the formation of the tympanic cavity wall.  Outer ear  Unlike structures of the inner and middle ear, which develop from pharyngeal pouches, the ear canal originates from the dorsal portion of the first pharyngeal cleft. It is fully expanded by the end of the 18th week of development. The eardrum is made up of three layers (ectoderm, endoderm and connective tissue). The pinna originates as a fusion of six hillocks. The first three hillocks are derived from the lower part of the first pharyngeal arch and form the tragus, crus of the helix, and helix, respectively. The final three hillocks are derived from the upper part of the second pharyngeal arch and form the antihelix, antitragus, and earlobe. The outer ears develop in the lower neck. As the mandible forms they move towards their final position level with the eyes.  Clinical significance   Hearing loss  Hearing loss may be either partial or total. This may be a result of injury or damage, congenital disease, or physiological causes. When hearing loss is a result of injury or damage to the outer ear or middle ear, it is known as conductive hearing loss. When deafness is a result of injury or damage to the inner ear, vestibulochoclear nerve, or brain, it is known as sensorineural hearing loss. Causes of conductive hearing loss include an ear canal blocked by ear wax, ossicles that are fixed together or absent, or holes in the eardrum. Conductive hearing loss may also result from middle ear inflammation causing fluid build-up in the normally air-filled space, such as by otitis media. Tympanoplasty is the general name of the operation to repair the middle ear's eardrum and ossicles. Grafts from muscle fascia are ordinarily used to rebuild an intact eardrum. Sometimes artificial ear bones are placed to substitute for damaged ones, or a disrupted ossicular chain is rebuilt in order to conduct sound effectively. Hearing aids or cochlear implants may be used if the hearing loss is severe or prolonged. Hearing aids work by amplifying the sound of the local environment and are best suited to conductive hearing loss. Cochlear implants transmit the sound that is heard as if it were a nervous signal, bypassing the cochlea. Active middle ear implants send sound vibrations to the ossicles in the middle ear, bypassing any non-functioning parts of the outer and middle ear.  Congenital abnormalities  Anomalies and malformations of the pinna are common. These anomalies include chromosome syndromes such as ring 18. Children may also present cases of abnormal ear canals and low ear implantation. In rare cases no pinna is formed (atresia), or is extremely small (microtia). Small pinnae can develop when the auricular hillocks do not develop properly. The ear canal can fail to develop if it does not channelise properly or if there is an obstruction. Reconstructive surgery to treat hearing loss is considered as an option for children older than five, with a cosmetic surgical procedure to reduce the size or change the shape of the ear is called an otoplasty. The initial medical intervention is aimed at assessing the baby's hearing and the condition of the ear canal, as well as the middle and inner ear. Depending on the results of tests, reconstruction of the outer ear is done in stages, with planning for any possible repairs of the rest of the ear.Approximately one out of one thousand children suffer some type of congenital deafness related to the development of the inner ear. Inner ear congenital anomalies are related to sensorineural hearing loss and are generally diagnosed with a computed tomography (CT) scan or a magnetic resonance imaging (MRI) scan. Hearing loss problems also derive from inner ear anomalies because its development is separate from that of the middle and external ear. Middle ear anomalies can occur because of errors during head and neck development. The first pharyngeal pouch syndrome associates middle ear anomalies to the malleus and incus structures as well as to the non-differentiation of the annular stapedial ligament. Temporal bone and ear canal anomalies are also related to this structure of the ear and are known to be associated with sensorineural hearing loss and conductive hearing loss.  Vertigo  Vertigo refers to the inappropriate perception of motion. This is due to dysfunction of the vestibular system. One common type of vertigo is benign paroxysmal positional vertigo, when an otolith is displaced from the ventricles to the semicircular canal. The displaced otolith rests on the cupola, causing a sensation of movement when there is none. Ménière's disease, labyrinthitis, strokes, and other infective and congenital diseases may also result in the perception of vertigo.  Injury  Outer earInjuries to the external ear occur fairly frequently, and can leave minor to major deformity. Injuries include: laceration, avulsion injuries, burn and repeated twisting or pulling of an ear, for discipline or torture. Chronic damage to the ears can cause cauliflower ear, a common condition in boxers and wrestlers in which the cartilage around the ears becomes lumpy and distorted owing to persistence of a haematoma around the perichondrium, which can impair blood supply and healing. Owing to its exposed position, the external ear is susceptible to frostbite as well as skin cancers, including squamous-cell carcinoma and basal-cell carcinomas. Middle earThe ear drum may become perforated in the event of a large sound or explosion, when diving or flying (called barotrauma), or by objects inserted into the ear. Another common cause of injury is due to an infection such as otitis media. These may cause a discharge from the ear called otorrhea, and are often investigated by otoscopy and audiometry. Treatment may include watchful waiting, antibiotics and possibly surgery, if the injury is prolonged or the position of the ossicles is affected. Skull fractures that go through the part of the skull containing the ear structures (the temporal bone) can also cause damage to the middle ear. A cholesteatoma is a cyst of squamous skin cells that may develop from birth or secondary to other causes such as chronic ear infections. It may impair hearing or cause dizziness or vertigo, and is usually investigated by otoscopy and may require a CT scan. The treatment for cholesteatoma is surgery. Inner earThere are two principal damage mechanisms to the inner ear in industrialised society, and both injure hair cells. The first is exposure to elevated sound levels (noise trauma), and the second is exposure to drugs and other substances (ototoxicity). A large number of people are exposed to sound levels on a daily basis that are likely to lead to significant hearing loss. The National Institute for Occupational Safety and Health has recently published research on the estimated numbers of persons with hearing difficulty (11%) and the percentage of those that can be attributed to occupational noise exposure (24%). Furthermore, according to the National Health and Nutrition Examination Survey (NHANES), approximately twenty-two million (17%) US workers reported exposure to hazardous workplace noise. Workers exposed to hazardous noise further exacerbate the potential for developing noise-induced hearing loss when they do not wear hearing protection.  Tinnitus  Tinnitus is the hearing of sound when no external sound is present. While often described as a ringing, it may also sound like a clicking, hiss or roaring. Rarely, unclear voices or music are heard. The sound may be soft or loud, low pitched or high pitched and appear to be coming from one ear or both. Most of the time, it comes on gradually. In some people, the sound causes depression, anxiety, or concentration difficulties.Tinnitus is not a disease but a symptom that can result from a number of underlying causes. One of the most common causes is noise-induced hearing loss. Other causes include: ear infections, disease of the heart or blood vessels, Ménière's disease, brain tumors, emotional stress, exposure to certain medications, a previous head injury, and earwax. It is more common in those with depression and anxiety.  Society and culture  The ears have been ornamented with jewelry for thousands of years, traditionally by piercing of the earlobe. In ancient and modern cultures, ornaments have been placed to stretch and enlarge the earlobes, allowing for larger plugs to be slid into a large fleshy gap in the lobe. Tearing of the earlobe from the weight of heavy earrings, or from traumatic pull of an earring (for example, by snagging on a sweater), is fairly common.Injury to the ears has been present since Roman times as a method of reprimand or punishment – ""In Roman times, when a dispute arose that could not be settled amicably, the injured party cited the name of the person thought to be responsible before the Praetor; if the offender did not appear within the specified time limit, the complainant summoned witnesses to make statements. If they refused, as often happened, the injured party was allowed to drag them by the ear and to pinch them hard if they resisted. Hence the French expression ""se faire tirer l’oreille"", of which the literal meaning is ""to have one's ear pulled"" and the figurative meaning ""to take a lot of persuading"". We use the expression ""to tweak (or pull) someone's ears"" to mean ""inflict a punishment"".""The pinnae have an effect on facial appearance. In Western societies, protruding ears (present in about 5% of ethnic Europeans) have been considered unattractive, particularly if asymmetric. The first surgery to reduce the projection of prominent ears was published in the medical literature by Ernst Dieffenbach in 1845, and the first case report in 1881. Pointy ears are a characteristic of some creatures in folklore such as the French croquemitaine, Brazilian curupira or Japanese earth spider. It has been a feature of characters on art as old as that of Ancient Greece and medieval Europe. Pointy ears are a common characteristic of many creatures in the fantasy genre, including elves, faeries, pixies, hobbits, or orcs. They are a characteristic of creatures in the horror genre, such as vampires. Pointy ears are also found in the science fiction genre; for example among the Vulcan and Romulan races of the Star Trek universe and the Nightcrawler character from the X-Men universe.Georg von Békésy was a Hungarian biophysicist born in Budapest, Hungary. In 1961, he was awarded the Nobel Prize in Physiology or Medicine for his research on the function of the cochlea in the mammalian hearing organ.The Vacanti mouse was a laboratory mouse that had what looked like a human ear grown on its back. The ""ear"" was actually an ear-shaped cartilage structure grown by seeding cow cartilage cells into a biodegradable ear-shaped mold and then implanted under the skin of the mouse; then the cartilage naturally grew by itself. It was developed as an alternative to ear repair or grafting procedures and the results met with much publicity and controversy in 1997.  Other animals  The pinna helps direct sound through the ear canal to the eardrum. The complex geometry of ridges on the inner surface of some mammalian ears helps to sharply focus sounds produced by prey, using echolocation signals. These ridges can be regarded as the acoustic equivalent of a fresnel lens, and may be seen in a wide range of animals, including the bat, aye-aye, lesser galago, bat-eared fox, mouse lemur and others.Some large primates such as gorillas and orang-utans (and also humans) have undeveloped ear muscles that are non-functional vestigial structures, yet are still large enough to be easily identified. An ear muscle that cannot move the ear, for whatever reason, has lost that biological function. This serves as evidence of homology between related species. In humans, there is variability in these muscles, such that some people are able to move their ears in various directions, and it has been said that it may be possible for others to gain such movement by repeated trials. In such primates, the inability to move the ear is compensated for mainly by the ability to easily turn the head on a horizontal plane, an ability which is not common to most monkeys—a function once provided by one structure is now replaced by another.In some animals with mobile pinnae (like the horse), each pinna can be aimed independently to better receive the sound. For these animals, the pinnae help localise the direction of the sound source. The ear, with its blood vessels close to the surface, is an essential thermoregulator in some land mammals, including the elephant, the fox, and the rabbit. There are five types of ear carriage in domestic rabbits, some of which have been bred for exaggerated ear length—a potential health risk that is controlled in some countries. Abnormalities in the skull of a half-lop rabbit were studied by Charles Darwin in 1868. In marine mammals, earless seals are one of three groups of Pinnipedia.  Invertebrates  Only vertebrate animals have ears, though many invertebrates detect sound using other kinds of sense organs. In insects, tympanal organs are used to hear distant sounds. They are located either on the head or elsewhere, depending on the insect family. The tympanal organs of some insects are extremely sensitive, offering acute hearing beyond that of most other animals. The female cricket fly Ormia ochracea has tympanal organs on each side of her abdomen. They are connected by a thin bridge of exoskeleton and they function like a tiny pair of eardrums, but, because they are linked, they provide acute directional information. The fly uses her ""ears"" to detect the call of her host, a male cricket. Depending on where the song of the cricket is coming from, the fly's hearing organs will reverberate at slightly different frequencies. This difference may be as little as 50 billionths of a second, but it is enough to allow the fly to home in directly on a singing male cricket and parasitise it.Simpler structures allow other arthropods to detect near-field sounds. Spiders and cockroaches, for example, have hairs on their legs which are used for detecting sound. Caterpillars may also have hairs on their body that perceive vibrations and allow them to respond to sound.  See also  Hear, hear Hearing test Righting reflex  References   External links  The dictionary definition of ear at Wiktionary Media related to Ears at Wikimedia Commons","The ear is the part of the body which allows animals (including people) to hear. People and most mammals have ears. Non-mammals, such as lizards or frogs, can also hear, but may have holes instead of external ears. The ear works by directing sound waves to the inner ear. These vibrations are sent to the brain by an organized group of nerves. This system is called the auditory system. (Auditory meaning relating to hearing and how we hear) The inner ear is in most vertebrates, but mammals have special adaptations for hearing which even other land vertebrates do not have. These include the external ear and the three little bones which transmit sounds to the brain (the ossicles). The part of the ear that sticks out and can be seen is called the pinna. Ears are also used in other ways. African elephants use their large ears to cool themselves when it is very hot. Bats rely on their ears to find prey by echolocation. Some animals use their ears for signalling to each other.  Other hearing  In ordinary language, ""ear"" refers to this receptor which conducts sound and sends signals to the brain. It does not refer to the many other methods of hearing found in fish and invertebrates. Many animals do not hear through ears. Spiders have small hairs on their legs that they can hear with.  Related pages  Inner ear"
"In animal anatomy, the mouth, also known as the oral cavity, or in Latin cavum oriscode: lat promoted to code: la , is the opening through which many animals take in food and issue vocal sounds. It is also the cavity lying at the upper end of the alimentary canal, bounded on the outside by the lips and inside by the pharynx. In tetrapods, it contains the tongue and, except for some like birds, teeth. This cavity is also known as the buccal cavity, from the Latin buccacode: lat promoted to code: la (""cheek"").Some animal phyla, including arthropods, molluscs and chordates, have a complete digestive system, with a mouth at one end and an anus at the other. Which end forms first in ontogeny is a criterion used to classify bilaterian animals into protostomes and deuterostomes.  Development  In the first multicellular animals, there was probably no mouth or gut and food particles were engulfed by the cells on the exterior surface by a process known as endocytosis. The particles became enclosed in vacuoles into which enzymes were secreted and digestion took place intracellularly. The digestive products were absorbed into the cytoplasm and diffused into other cells. This form of digestion is used nowadays by simple organisms such as Amoeba and Paramecium and also by sponges which, despite their large size, have no mouth or gut and capture their food by endocytosis.However, most animals have a mouth and a gut, the lining of which is continuous with the epithelial cells on the surface of the body. A few animals which live parasitically originally had guts but have secondarily lost these structures. The original gut of diploblastic animals probably consisted of a mouth and one-way gut. Some modern invertebrates still have such a system: food being ingested through the mouth, partially broken down by enzymes secreted in the gut, and the resulting particles engulfed by the other cells in the gut lining. Indigestible waste is ejected through the mouth.In animals at least as complex as an earthworm, the embryo forms a dent on one side, the blastopore, which deepens to become the archenteron, the first phase in the formation of the gut. In deuterostomes, the blastopore becomes the anus while the gut eventually tunnels through to make another opening, which forms the mouth. In the protostomes, it used to be thought that the blastopore formed the mouth (proto– meaning ""first"") while the anus formed later as an opening made by the other end of the gut. More recent research, however, shows that in protostomes the edges of the slit-like blastopore close up in the middle, leaving openings at both ends that become the mouth and anus.  Anatomy   Invertebrates  Apart from sponges and placozoans, almost all animals have an internal gut cavity which is lined with gastrodermal cells. In less advanced invertebrates such as the sea anemone, the mouth also acts as an anus. Circular muscles around the mouth are able to relax or contract in order to open or close it. A fringe of tentacles thrusts food into the cavity and it can gape widely enough to accommodate large prey items. Food passes first into a pharynx and digestion occurs extracellularly in the gastrovascular cavity. Annelids have simple tube-like guts, and the possession of an anus allows them to separate the digestion of their foodstuffs from the absorption of the nutrients. Many molluscs have a radula which is used to scrape microscopic particles off surfaces. In invertebrates with hard exoskeletons, various mouthparts may be involved in feeding behaviour. Insects have a range of mouthparts suited to their mode of feeding. These include mandibles, maxillae and labium and can be modified into suitable appendages for chewing, cutting, piercing, sponging and sucking. Decapods have six pairs of mouth appendages, one pair of mandibles, two pairs of maxillae and three of maxillipeds. Sea urchins have a set of five sharp calcareous plates which are used as jaws and are known as Aristotle's lantern.  Vertebrates  In vertebrates, the first part of the digestive system is the buccal cavity, commonly known as the mouth. The buccal cavity of a fish is separated from the opercular cavity by the gills. Water flows in through the mouth, passes over the gills and exits via the operculum or gill slits. Nearly all fish have jaws and may seize food with them but most feed by opening their jaws, expanding their pharynx and sucking in food items. The food may be held or chewed by teeth located in the jaws, on the roof of the mouth, on the pharynx or on the gill arches. Nearly all amphibians are carnivorous as adults. Many catch their prey by flicking out an elongated tongue with a sticky tip and drawing it back into the mouth, where they hold the prey with their jaws. They then swallow their food whole without much chewing. They typically have many small hinged pedicellate teeth, the bases of which are attached to the jaws, while the crowns break off at intervals and are replaced. Most amphibians have one or two rows of teeth in both jaws but some frogs lack teeth in the lower jaw. In many amphibians, there are also vomerine teeth attached to the bone in the roof of the mouth.The mouths of reptiles are largely similar to those of mammals. The crocodilians are the only reptiles to have teeth anchored in sockets in their jaws. They are able to replace each of their approximately 80 teeth up to 50 times during their lives. Most reptiles are either carnivorous or insectivorous but turtles are herbivorous. Lacking teeth that are suitable for efficiently chewing of their food, turtles often have gastroliths in their stomach to further grind the plant material. Snakes have a very flexible lower jaw, the two halves of which are not rigidly attached, and numerous other joints in their skull. These modifications allow them to open their mouths wide enough to swallow their prey whole, even if it is wider than they are.Birds do not have teeth, relying instead on other means of gripping and macerating their food. Their beaks have a range of sizes and shapes according to their diet and are composed of elongated mandibles. The upper mandible may have a nasofrontal hinge allowing the beak to open wider than would otherwise be possible. The exterior surface of beaks is composed of a thin, horny sheath of keratin. Nectar feeders such as hummingbirds have specially adapted brushy tongues for sucking up nectar from flowers.In mammals the buccal cavity is typically roofed by the hard and soft palates, floored by the tongue and surrounded by the cheeks, salivary glands, and upper and lower teeth. The upper teeth are embedded in the upper jaw and the lower teeth in the lower jaw, which articulates with the temporal bones of the skull. The lips are soft and fleshy folds which shape the entrance into the mouth. The buccal cavity empties through the pharynx into the oesophagus.  Other functions of the mouth  Crocodilians living in the tropics can gape with their mouths to provide cooling by evaporation from the mouth lining. Some mammals rely on panting for thermoregulation as it increases evaporation of water across the moist surfaces of the lungs, the tongue and mouth. Birds also avoid overheating by gular fluttering, flapping the wings near the gular (throat) skin, similar to panting in mammals. Various animals use their mouths in threat displays. They may gape widely, exhibit their teeth prominently, or flash the startling colours of the mouth lining. This display allows each potential combatant an opportunity to assess the weapons of their opponent and lessens the likelihood of actual combat being necessary.A number of species of bird use a gaping, open beak in their fear and threat displays. Some augment the display by hissing or breathing heavily, while others clap their beaks.Mouths are also used as part of the mechanism for producing sounds for communication. To produce sounds, air is forced from the lungs over vocal cords in the larynx. In humans, the pharynx, soft palate, hard palate, alveolar ridge, tongue, teeth and lips are termed articulators and play their part in the production of speech. Varying the position of the tongue in relation to the other articulators or moving the lips restricts the airflow from the lungs in different ways and changes the mouth's resonating properties, producing a range of different sounds. In frogs, the sounds can be amplified using sacs in the throat region. The vocal sacs can be inflated and deflated and act as resonators to transfer the sound to the outside world. A bird's song is produced by the flow of air over a vocal organ at the base of the trachea, the syrinx. For each burst of song, the bird opens its beak and closes it again afterwards. The beak may move slightly and may contribute to the resonance but the song originates elsewhere.  See also  Human mouth Oral manifestations of systemic disease  References   External links  The dictionary definition of mouth at Wiktionary Quotations related to Mouths at Wikiquote Media related to Mouths at Wikimedia Commons","For the geographical meaning of mouth see RiverThe mouth is an opening in the face and is the first part of the alimentary canal (digestive system). It is the place where food is chewed. The mouth has teeth to help eat/chew the food. In addition to its main role as the start of the digestive system, in humans the mouth also plays a great part in communication. The tongue, lips, and jaw, which are parts of the mouth, are needed to produce the number of sounds in human language. People also kiss and show their feelings with the mouth."
"Alzheimer\'s disease (AD) is a neurodegenerative disease that usually starts slowly and progressively worsens. It is the cause of 60–70% of cases of dementia. The most common early symptom is difficulty in remembering recent events. As the disease advances, symptoms can include problems with language, disorientation (including easily getting lost), mood swings, loss of motivation, self-neglect, and behavioral issues. As a person\'s condition declines, they often withdraw from family and society. Gradually, bodily functions are lost, ultimately leading to death. Although the speed of progression can vary, the typical life expectancy following diagnosis is three to nine years.The cause of Alzheimer\'s disease is poorly understood. There are many environmental and genetic risk factors associated with its development. The strongest genetic risk factor is from an allele of APOE. Other risk factors include a history of head injury, clinical depression, and high blood pressure. The disease process is largely associated with amyloid plaques, neurofibrillary tangles, and loss of neuronal connections in the brain. A probable diagnosis is based on the history of the illness and cognitive testing with medical imaging and blood tests to rule out other possible causes. Initial symptoms are often mistaken for normal brain aging. Examination of brain tissue is needed for a definite diagnosis, but this can only take place after death. Good nutrition, physical activity, and engaging socially are known to be of benefit generally in aging, and these may help in reducing the risk of cognitive decline and Alzheimer\'s; in 2019 clinical trials were underway to look at these possibilities. There are no medications or supplements that have been shown to decrease risk.No treatments stop or reverse its progression, though some may temporarily improve symptoms. Affected people increasingly rely on others for assistance, often placing a burden on the caregiver. The pressures can include social, psychological, physical, and economic elements. Exercise programs may be beneficial with respect to activities of daily living and can potentially improve outcomes. Behavioral problems or psychosis due to dementia are often treated with antipsychotics, but this is not usually recommended, as there is little benefit and an increased risk of early death.As of 2020, there were approximately 50 million people worldwide with Alzheimer\'s disease. It most often begins in people over 65 years of age, although up to 10% of cases are early-onset affecting those in their 30s to mid-60s. It affects about 6% of people 65 years and older, and women more often than men. The disease is named after German psychiatrist and pathologist Alois Alzheimer, who first described it in 1906. Alzheimer\'s financial burden on society is large, with an estimated global annual cost of US$1 trillion. Alzheimer\'s disease is currently ranked as the seventh leading cause of death in the United States.  Signs and symptoms  The course of Alzheimer\'s is generally described in three stages, with a progressive pattern of cognitive and functional impairment. The three stages are described as early or mild, middle or moderate, and late or severe. The disease is known to target the hippocampus which is associated with memory, and this is responsible for the first symptoms of memory impairment. As the disease progresses so does the degree of memory impairment.  First symptoms  The first symptoms are often mistakenly attributed to aging or stress. Detailed neuropsychological testing can reveal mild cognitive difficulties up to eight years before a person fulfills the clinical criteria for diagnosis of Alzheimer\'s disease. These early symptoms can affect the most complex activities of daily living. The most noticeable deficit is short term memory loss, which shows up as difficulty in remembering recently learned facts and inability to acquire new information.Subtle problems with the executive functions of attentiveness, planning, flexibility, and abstract thinking, or impairments in semantic memory (memory of meanings, and concept relationships) can also be symptomatic of the early stages of Alzheimer\'s disease. Apathy and depression can be seen at this stage, with apathy remaining as the most persistent symptom throughout the course of the disease. Mild cognitive impairment (MCI) is often found to be a transitional stage between normal aging and dementia. MCI can present with a variety of symptoms, and when memory loss is the predominant symptom, it is termed amnestic MCI and is frequently seen as a prodromal stage of Alzheimer\'s disease. Amnestic MCI has a greater than 90% likelihood of being associated with Alzheimer\'s.  Early stage  In people with Alzheimer\'s disease, the increasing impairment of learning and memory eventually leads to a definitive diagnosis. In a small percentage, difficulties with language, executive functions, perception (agnosia), or execution of movements (apraxia) are more prominent than memory problems. Alzheimer\'s disease does not affect all memory capacities equally. Older memories of the person\'s life (episodic memory), facts learned (semantic memory), and implicit memory (the memory of the body on how to do things, such as using a fork to eat or how to drink from a glass) are affected to a lesser degree than new facts or memories.Language problems are mainly characterised by a shrinking vocabulary and decreased word fluency, leading to a general impoverishment of oral and written language. In this stage, the person with Alzheimer\'s is usually capable of communicating basic ideas adequately. While performing fine motor tasks such as writing, drawing, or dressing, certain movement coordination and planning difficulties (apraxia) may be present, but they are commonly unnoticed. As the disease progresses, people with Alzheimer\'s disease can often continue to perform many tasks independently, but may need assistance or supervision with the most cognitively demanding activities.  Middle stage  Progressive deterioration eventually hinders independence, with subjects being unable to perform most common activities of daily living. Speech difficulties become evident due to an inability to recall vocabulary, which leads to frequent incorrect word substitutions (paraphasias). Reading and writing skills are also progressively lost. Complex motor sequences become less coordinated as time passes and Alzheimer\'s disease progresses, so the risk of falling increases. During this phase, memory problems worsen, and the person may fail to recognise close relatives. Long-term memory, which was previously intact, becomes impaired.Behavioral and neuropsychiatric changes become more prevalent. Common manifestations are wandering, irritability and emotional lability, leading to crying, outbursts of unpremeditated aggression, or resistance to caregiving. Sundowning can also appear. Approximately 30% of people with Alzheimer\'s disease develop illusionary misidentifications and other delusional symptoms. Subjects also lose insight of their disease process and limitations (anosognosia). Urinary incontinence can develop. These symptoms create stress for relatives and caregivers, which can be reduced by moving the person from home care to other long-term care facilities.  Late stage  During the final stage, known as the late-stage or severe stage, there is complete dependence on caregivers. Language is reduced to simple phrases or even single words, eventually leading to complete loss of speech. Despite the loss of verbal language abilities, people can often understand and return emotional signals. Although aggressiveness can still be present, extreme apathy and exhaustion are much more common symptoms. People with Alzheimer\'s disease will ultimately not be able to perform even the simplest tasks independently; muscle mass and mobility deteriorates to the point where they are bedridden and unable to feed themselves. The cause of death is usually an external factor, such as infection of pressure ulcers or pneumonia, not the disease itself.  Familial and nonfamilial Alzheimer\'s disease  Familial Alzheimer\'s disease is an inherited and uncommon form of Alzheimer\'s disease. Familial AD usually strikes earlier in life, defined as before the age of 65. FAD usually implies multiple persons affected in one or more generation. Sporadic Alzheimer\'s disease (or Nonfamilial Alzheimer\'s disease) describes all other cases, where genetic risk factors are minor or unclear.  Causes  Proteins fail to function normally. This disrupts the work of the brain cells affected and triggers a toxic cascade, ultimately leading to cell death and later brain shrinkage.Alzheimer\'s disease is believed to occur when abnormal amounts of amyloid beta (Aβ), accumulating extracellularly as amyloid plaques and tau proteins, or intracellularly as neurofibrillary tangles, form in the brain, affecting neuronal functioning and connectivity, resulting in a progressive loss of brain function. This altered protein clearance ability is age-related, regulated by brain cholesterol, and associated with other neurodegenerative diseases.Advances in brain imaging techniques allow researchers to see the development and spread of abnormal amyloid and tau proteins in the living brain, as well as changes in brain structure and function. Beta-amyloid is a fragment of a larger protein. When these fragments cluster together, a toxic effect appears on neurons and disrupt cell-to-cell communication. Larger deposits called amyloid plaques are thus further formed.Tau proteins are responsible in neuron\'s internal support and transport system to carry nutrients and other essential materials. In Alzheimer\'s disease, the shape of tau proteins is altered and thus organize themselves into structures called neurofibrillary tangles. The tangles disrupt the transport system and are toxic to cells. The cause for most Alzheimer\'s cases is still mostly unknown, except for 1–2% of cases where deterministic genetic differences have been identified. Several competing hypotheses attempt to explain the underlying cause; the two predominant hypotheses are the amyloid beta (Aβ) hypothesis and the cholinergic hypothesis.The oldest hypothesis, on which most drug therapies are based, is the cholinergic hypothesis, which proposes that Alzheimer\'s disease is caused by reduced synthesis of the neurotransmitter acetylcholine. The loss of cholinergic neurons noted in the limbic system and cerebral cortex, is a key feature in the progression of Alzheimer\'s. The 1991 amyloid hypothesis postulated that extracellular amyloid beta (Aβ) deposits are the fundamental cause of the disease. Support for this postulate comes from the location of the gene for the amyloid precursor protein (APP) on chromosome 21, together with the fact that people with trisomy 21 (Down syndrome) who have an extra gene copy almost universally exhibit at least the earliest symptoms of Alzheimer\'s disease by 40 years of age. A specific isoform of apolipoprotein, APOE4, is a major genetic risk factor for Alzheimer\'s disease. While apolipoproteins enhance the breakdown of beta amyloid, some isoforms are not very effective at this task (such as APOE4), leading to excess amyloid buildup in the brain.  Genetic  Only 1–2% of Alzheimer\'s cases are inherited (autosomal dominant). These types are known as early onset familial Alzheimer\'s disease, can have a very early onset, and a faster rate of progression. Early onset familial Alzheimer\'s disease can be attributed to mutations in one of three genes: those encoding amyloid-beta precursor protein (APP) and presenilins PSEN1 and PSEN2. Most mutations in the APP and presenilin genes increase the production of a small protein called amyloid beta (Aβ)42, which is the main component of amyloid plaques. Some of the mutations merely alter the ratio between Aβ42 and the other major forms—particularly Aβ40—without increasing Aβ42 levels. Two other genes associated with autosomal dominant Alzheimer\'s disease are ABCA7 and SORL1.Most cases of Alzheimer\'s are not inherited and are termed sporadic Alzheimer\'s disease, in which environmental and genetic differences may act as risk factors. Most cases of sporadic Alzheimer\'s disease in contrast to familial Alzheimer\'s disease are late-onset Alzheimer\'s disease (LOAD) developing after the age of 65 years. Less than 5% of sporadic Alzheimer\'s disease have an earlier onset. The strongest genetic risk factor for sporadic Alzheimer\'s disease is APOEε4. APOEε4 is one of four alleles of apolipoprotein E (APOE). APOE plays a major role in lipid-binding proteins in lipoprotein particles and the epsilon4 allele disrupts this function. Between 40 and 80% of people with Alzheimer\'s disease possess at least one APOEε4 allele. The APOEε4 allele increases the risk of the disease by three times in heterozygotes and by 15 times in homozygotes. Like many human diseases, environmental effects and genetic modifiers result in incomplete penetrance. For example, certain Nigerian populations do not show the relationship between dose of APOEε4 and incidence or age-of-onset for Alzheimer\'s disease seen in other human populations.Alleles in the TREM2 gene have been associated with a 3 to 5 times higher risk of developing Alzheimer\'s disease.A Japanese pedigree of familial Alzheimer\'s disease was found to be associated with a deletion mutation of codon 693 of APP. This mutation and its association with Alzheimer\'s disease was first reported in 2008, and is known as the Osaka mutation. Only homozygotes with this mutation have an increased risk of developing Alzheimer\'s disease. This mutation accelerates Aβ oligomerization but the proteins do not form the amyloid fibrils that aggregate into amyloid plaques, suggesting that it is the Aβ oligomerization rather than the fibrils that may be the cause of this disease. Mice expressing this mutation have all the usual pathologies of Alzheimer\'s disease.  Other hypotheses  The tau hypothesis proposes that tau protein abnormalities initiate the disease cascade. In this model, hyperphosphorylated tau begins to pair with other threads of tau as paired helical filaments. Eventually, they form neurofibrillary tangles inside nerve cell bodies. When this occurs, the microtubules disintegrate, destroying the structure of the cell\'s cytoskeleton which collapses the neuron\'s transport system.A number of studies connect the misfolded amyloid beta and tau proteins associated with the pathology of Alzheimer\'s disease, as bringing about oxidative stress that leads to chronic inflammation. Sustained inflammation (neuroinflammation) is also a feature of other neurodegenerative diseases including Parkinson\'s disease, and ALS. Spirochete infections have also been linked to dementia. DNA damages accumulate in AD brains; reactive oxygen species may be the major source of this DNA damage.Sleep disturbances are seen as a possible risk factor for inflammation in Alzheimer\'s disease. Sleep problems have been seen as a consequence of Alzheimer\'s disease but studies suggest that they may instead be a causal factor. Sleep disturbances are thought to be linked to persistent inflammation. The cellular homeostasis of biometals such as ionic copper, iron, and zinc is disrupted in Alzheimer\'s disease, though it remains unclear whether this is produced by or causes the changes in proteins. Smoking is a significant Alzheimer\'s disease risk factor. Systemic markers of the innate immune system are risk factors for late-onset Alzheimer\'s disease. Exposure to air pollution may be a contributing factor to the development of Alzheimer\'s disease.According to one theory, dysfunction of oligodendrocytes and their associated myelin during aging contributes to axon damage, which in turn generates in amyloid production and tau hyper-phosphorylation. Retrogenesis is a medical hypothesis that just as the fetus goes through a process of neurodevelopment beginning with neurulation and ending with myelination, the brains of people with Alzheimer\'s disease go through a reverse neurodegeneration process starting with demyelination and death of axons (white matter) and ending with the death of grey matter. Likewise the hypothesis is, that as infants go through states of cognitive development, people with Alzheimer\'s disease go through the reverse process of progressive cognitive impairment.The association with celiac disease is unclear, with a 2019 study finding no increase in dementia overall in those with CD, while a 2018 review found an association with several types of dementia including Alzheimer\'s disease.  Pathophysiology   Neuropathology  Alzheimer\'s disease is characterised by loss of neurons and synapses in the cerebral cortex and certain subcortical regions. This loss results in gross atrophy of the affected regions, including degeneration in the temporal lobe and parietal lobe, and parts of the frontal cortex and cingulate gyrus. Degeneration is also present in brainstem nuclei particularly the locus coeruleus in the pons. Studies using MRI and PET have documented reductions in the size of specific brain regions in people with Alzheimer\'s disease as they progressed from mild cognitive impairment to Alzheimer\'s disease, and in comparison with similar images from healthy older adults.Both Aβ plaques and neurofibrillary tangles are clearly visible by microscopy in brains of those with Alzheimer\'s disease, especially in the hippocampus. However, Alzheimer\'s disease may occur without neurofibrillary tangles in the neocortex. Plaques are dense, mostly insoluble deposits of beta-amyloid peptide and cellular material outside and around neurons. Tangles (neurofibrillary tangles) are aggregates of the microtubule-associated protein tau which has become hyperphosphorylated and accumulate inside the cells themselves. Although many older individuals develop some plaques and tangles as a consequence of aging, the brains of people with Alzheimer\'s disease have a greater number of them in specific brain regions such as the temporal lobe. Lewy bodies are not rare in the brains of people with Alzheimer\'s disease.  Biochemistry  Alzheimer\'s disease has been identified as a protein misfolding disease, a proteopathy, caused by the accumulation of abnormally folded amyloid beta protein into amyloid plaques, and tau protein into neurofibrillary tangles in the brain. Plaques are made up of small peptides, 39–43 amino acids in length, called amyloid beta (Aβ). Amyloid beta is a fragment from the larger amyloid-beta precursor protein (APP) a transmembrane protein that penetrates the neuron\'s membrane. APP is critical to neuron growth, survival, and post-injury repair. In Alzheimer\'s disease, gamma secretase and beta secretase act together in a proteolytic process which causes APP to be divided into smaller fragments. One of these fragments gives rise to fibrils of amyloid beta, which then form clumps that deposit outside neurons in dense formations known as amyloid plaques.Alzheimer\'s disease is also considered a tauopathy due to abnormal aggregation of the tau protein. Every neuron has a cytoskeleton, an internal support structure partly made up of structures called microtubules. These microtubules act like tracks, guiding nutrients and molecules from the body of the cell to the ends of the axon and back. A protein called tau stabilises the microtubules when phosphorylated, and is therefore called a microtubule-associated protein. In Alzheimer\'s disease, tau undergoes chemical changes, becoming hyperphosphorylated; it then begins to pair with other threads, creating neurofibrillary tangles and disintegrating the neuron\'s transport system. Pathogenic tau can also cause neuronal death through transposable element dysregulation.  Disease mechanism  Exactly how disturbances of production and aggregation of the beta-amyloid peptide give rise to the pathology of Alzheimer\'s disease is not known. The amyloid hypothesis traditionally points to the accumulation of beta-amyloid peptides as the central event triggering neuron degeneration. Accumulation of aggregated amyloid fibrils, which are believed to be the toxic form of the protein responsible for disrupting the cell\'s calcium ion homeostasis, induces programmed cell death (apoptosis). It is also known that Aβ selectively builds up in the mitochondria in the cells of Alzheimer\'s-affected brains, and it also inhibits certain enzyme functions and the utilisation of glucose by neurons.Various inflammatory processes and cytokines may also have a role in the pathology of Alzheimer\'s disease. Inflammation is a general marker of tissue damage in any disease, and may be either secondary to tissue damage in Alzheimer\'s disease or a marker of an immunological response. There is increasing evidence of a strong interaction between the neurons and the immunological mechanisms in the brain. Obesity and systemic inflammation may interfere with immunological processes which promote disease progression.Alterations in the distribution of different neurotrophic factors and in the expression of their receptors such as the brain-derived neurotrophic factor (BDNF) have been described in Alzheimer\'s disease.  Diagnosis  Alzheimer\'s disease can only be definitively diagnosed with autopsy findings; in the absence of autopsy, clinical diagnoses of AD are ""possible"" or ""probable"", based on other findings. Up to 23% of those clinically diagnosed with AD may be misdiagnosed and may have pathology suggestive of another condition with symptoms that mimic those of AD.AD is usually clinically diagnosed based on the person\'s medical history, history from relatives, and behavioral observations. The presence of characteristic neurological and neuropsychological features and the absence of alternative conditions supports the diagnosis. Advanced medical imaging with computed tomography (CT) or magnetic resonance imaging (MRI), and with single-photon emission computed tomography (SPECT) or positron emission tomography (PET), can be used to help exclude other cerebral pathology or subtypes of dementia. Moreover, it may predict conversion from prodromal stages (mild cognitive impairment) to Alzheimer\'s disease. FDA-approved radiopharmaceutical diagnostic agents used in PET for Alzheimer\'s disease are florbetapir (2012), flutemetamol (2013), florbetaben (2014), and flortaucipir (2020). Because many insurance companies in the United States do not cover this procedure, its use in clinical practice is largely limited to clinical trials as of 2018.Assessment of intellectual functioning including memory testing can further characterise the state of the disease. Medical organizations have created diagnostic criteria to ease and standardise the diagnostic process for practising physicians. Definitive diagnosis can only be confirmed with post-mortem evaluations when brain material is available and can be examined histologically for senile plaques and neurofibrillary tangles.  Criteria  There are three sets of criteria for the clinical diagnoses of the spectrum of Alzheimer\'s disease: the 2013 fifth edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM-5); the National Institute on Aging-Alzheimer\'s Association (NIA-AA) definition as revised in 2011; and the International Working Group criteria as revised in 2010. Three broad time periods, which can span decades, define the progression of Alzheimer\'s disease from the preclinical phase, to mild cognitive impairment (MCI), followed by Alzheimer\'s disease dementia.Eight intellectual domains are most commonly impaired in AD—memory, language, perceptual skills, attention, motor skills, orientation, problem solving and executive functional abilities, as listed in the fourth text revision of the DSM (DSM-IV-TR).The DSM-5 defines criteria for probable or possible Alzheimer\'s for both major and mild neurocognitive disorder. Major or mild neurocognitive disorder must be present along with at least one cognitive deficit for a diagnosis of either probable or possible AD. For major neurocognitive disorder due to Alzheimer\'s disease, probable Alzheimer\'s disease can be diagnosed if the individual has genetic evidence of Alzheimer\'s or if two or more acquired cognitive deficits, and a functional disability that is not from another disorder, are present. Otherwise, possible Alzheimer\'s disease can be diagnosed as the diagnosis follows an atypical route. For mild neurocognitive disorder due to Alzheimer\'s, probable Alzheimer\'s disease can be diagnosed if there is genetic evidence, whereas possible Alzheimer\'s disease can be met if all of the following are present: no genetic evidence, decline in both learning and memory, two or more cognitive deficits, and a functional disability not from another disorder.The NIA-AA criteria are used mainly in research rather than in clinical assessments. They define Alzheimer\'s disease through three major stages: preclinical, mild cognitive impairment (MCI), and Alzheimer\'s dementia. Diagnosis in the preclinical stage is complex and focuses on asymptomatic individuals; the latter two stages describe individuals experiencing symptoms. The core clinical criteria for MCI is used along with identification of biomarkers, predominantly those for neuronal injury (mainly tau-related) and amyloid beta deposition. The core clinical criteria itself rests on the presence of cognitive impairment without the presence of comorbidities. The third stage is divided into probable and possible Alzheimer\'s disease dementia. In probable Alzheimer\'s disease dementia there is steady impairment of cognition over time and a memory-related or non-memory-related cognitive dysfunction. In possible Alzheimer\'s disease dementia, another causal disease such as cerebrovascular disease is present.  Techniques  Neuropsychological tests including cognitive tests such as the Mini–Mental State Examination (MMSE), the Montreal Cognitive Assessment (MoCA) and the Mini-Cog are widely used to aid in diagnosis of the cognitive impairments in AD. These tests may not always be accurate, as they lack sensitivity to mild cognitive impairment, and can be biased by language or attention problems; more comprehensive test arrays are necessary for high reliability of results, particularly in the earliest stages of the disease.Further neurological examinations are crucial in the differential diagnosis of Alzheimer\'s disease and other diseases. Interviews with family members are used in assessment; caregivers can supply important information on daily living abilities and on the decrease in the person\'s mental function. A caregiver\'s viewpoint is particularly important, since a person with Alzheimer\'s disease is commonly unaware of their deficits. Many times, families have difficulties in the detection of initial dementia symptoms and may not communicate accurate information to a physician.Supplemental testing can rule out other potentially treatable diagnoses and help avoid misdiagnoses. Common supplemental tests include blood tests, thyroid function tests, as well as tests to assess vitamin B12 levels, rule out neurosyphilis and rule out metabolic problems (including tests for kidney function, electrolyte levels and for diabetes). MRI or CT scans might also be used to rule out other potential causes of the symptoms – including tumors or strokes. Delirium and depression can be common among individuals and are important to rule out.Psychological tests for depression are used, since depression can either be concurrent with Alzheimer\'s disease (see Depression of Alzheimer disease), an early sign of cognitive impairment, or even the cause.Due to low accuracy, the C-PIB-PET scan is not recommended as an early diagnostic tool or for predicting the development of Alzheimer\'s disease when people show signs of mild cognitive impairment (MCI). The use of 18F-FDG PET scans, as a single test, to identify people who may develop Alzheimer\'s disease is not supported by evidence.  Prevention  There are no disease-modifying treatments available to cure Alzheimer\'s disease and because of this, AD research has focused on interventions to prevent the onset and progression. There is no evidence that supports any particular measure in preventing Alzheimer\'s, and studies of measures to prevent the onset or progression have produced inconsistent results. Epidemiological studies have proposed relationships between an individual\'s likelihood of developing AD and modifiable factors, such as medications, lifestyle, and diet. There are some challenges in determining whether interventions for Alzheimer\'s disease act as a primary prevention method, preventing the disease itself, or a secondary prevention method, identifying the early stages of the disease. These challenges include duration of intervention, different stages of disease at which intervention begins, and lack of standardization of inclusion criteria regarding biomarkers specific for Alzheimer\'s disease. Further research is needed to determine factors that can help prevent Alzheimer\'s disease.  Medication  Cardiovascular risk factors, such as hypercholesterolaemia, hypertension, diabetes, and smoking, are associated with a higher risk of onset and worsened course of AD. The use of statins to lower cholesterol may be of benefit in Alzheimer\'s. Antihypertensive and antidiabetic medications in individuals without overt cognitive impairment may decrease the risk of dementia by influencing cerebrovascular pathology. More research is needed to examine the relationship with Alzheimer\'s disease specifically; clarification of the direct role medications play versus other concurrent lifestyle changes (diet, exercise, smoking) is needed.Depression is associated with an increased risk for Alzheimer\'s disease; management with antidepressants may provide a preventative measure.Historically, long-term usage of non-steroidal anti-inflammatory drugs (NSAIDs) were thought to be associated with a reduced likelihood of developing Alzheimer\'s disease as it reduces inflammation; however, NSAIDs do not appear to be useful as a treatment. Additionally, because women have a higher incidence of Alzheimer\'s disease than men, it was once thought that estrogen deficiency during menopause was a risk factor. However, there is a lack of evidence to show that hormone replacement therapy (HRT) in menopause decreases risk of cognitive decline.Plant-made metallochaperones could be a novel approach for the treatment of Alzheimer\'s disease.  Lifestyle  Certain lifestyle activities, such as physical and cognitive exercises, higher education and occupational attainment, cigarette smoking, stress, sleep, and the management of other comorbidities, including diabetes and hypertension, may affect the risk of developing Alzheimer\'s.Physical exercise is associated with a decreased rate of dementia, and is effective in reducing symptom severity in those with AD. Memory and cognitive functions can be improved with aerobic exercises including brisk walking three times weekly for forty minutes. It may also induce neuroplasticity of the brain. Participating in mental exercises, such as reading, crossword puzzles, and chess have shown a potential to be preventative. Meeting the WHO recommendations for physical activity is associated with a lower risk of AD.Higher education and occupational attainment, and participation in leisure activities, contribute to a reduced risk of developing Alzheimer\'s, or of delaying the onset of symptoms. This is compatible with the cognitive reserve theory, which states that some life experiences result in more efficient neural functioning providing the individual a cognitive reserve that delays the onset of dementia manifestations. Education delays the onset of Alzheimer\'s disease syndrome without changing the duration of the disease.Cessation in smoking may reduce risk of developing Alzheimer\'s\' disease, specifically in those who carry APOE ɛ4 allele. The increased oxidative stress caused by smoking results in downstream inflammatory or neurodegenerative processes that may increase risk of developing AD. Avoidance of smoking, counseling and pharmacotherapies to quit smoking are used, and avoidance of environmental tobacco smoke is recommended.Alzheimer\'s disease is associated with sleep disorders but the precise relationship is unclear. It was once thought that as people get older, the risk of developing sleep disorders and AD independently increase, but research is examining whether sleep disorders may increase the prevalence of AD. One theory is that the mechanisms to increase clearance of toxic substances, including Aβ, are active during sleep. With decreased sleep, a person is increasing Aβ production and decreasing Aβ clearance, resulting in Aβ accumulation. Receiving adequate sleep (approximately 7–8 hours) every night has become a potential lifestyle intervention to prevent the development of AD.Stress is a risk factor for the development of Alzheimer\'s. The mechanism by which stress predisposes someone to development of Alzheimer\'s is unclear, but it is suggested that lifetime stressors may affect a person\'s epigenome, leading to an overexpression or under expression of specific genes. Although the relationship of stress and Alzheimer\'s is unclear, strategies to reduce stress and relax the mind may be helpful strategies in preventing the progression or Alzheimer\'s disease. Meditation, for instance, is a helpful lifestyle change to support cognition and well-being, though further research is needed to assess long-term effects.  Management  There is no cure for Alzheimer\'s disease; available treatments offer relatively small symptomatic benefits but remain palliative in nature. Treatments can be divided into pharmaceutical, psychosocial, and caregiving.  Pharmaceutical  Medications used to treat the cognitive problems of Alzheimer\'s disease include: four acetylcholinesterase inhibitors (tacrine, rivastigmine, galantamine, and donepezil) and memantine, an NMDA receptor antagonist. The acetylcholinesterase inhibitors are intended for those with mild to severe Alzheimer\'s, whereas memantine is intended for those with moderate or severe Alzheimer\'s disease. The benefit from their use is small.Reduction in the activity of the cholinergic neurons is a well-known feature of Alzheimer\'s disease. Acetylcholinesterase inhibitors are employed to reduce the rate at which acetylcholine (ACh) is broken down, thereby increasing the concentration of ACh in the brain and combating the loss of ACh caused by the death of cholinergic neurons. There is evidence for the efficacy of these medications in mild to moderate Alzheimer\'s disease, and some evidence for their use in the advanced stage. The use of these drugs in mild cognitive impairment has not shown any effect in a delay of the onset of Alzheimer\'s disease. The most common side effects are nausea and vomiting, both of which are linked to cholinergic excess. These side effects arise in approximately 10–20% of users, are mild to moderate in severity, and can be managed by slowly adjusting medication doses. Less common secondary effects include muscle cramps, decreased heart rate (bradycardia), decreased appetite and weight, and increased gastric acid production.Glutamate is an excitatory neurotransmitter of the nervous system, although excessive amounts in the brain can lead to cell death through a process called excitotoxicity which consists of the overstimulation of glutamate receptors. Excitotoxicity occurs not only in Alzheimer\'s disease, but also in other neurological diseases such as Parkinson\'s disease and multiple sclerosis. Memantine is a noncompetitive NMDA receptor antagonist first used as an anti-influenza agent. It acts on the glutamatergic system by blocking NMDA receptors and inhibiting their overstimulation by glutamate. Memantine has been shown to have a small benefit in the treatment of moderate to severe Alzheimer\'s disease. Reported adverse events with memantine are infrequent and mild, including hallucinations, confusion, dizziness, headache and fatigue. The combination of memantine and donepezil has been shown to be ""of statistically significant but clinically marginal effectiveness"".An extract of Ginkgo biloba known as EGb 761 has been used for treating Alzheimer\'s and other neuropsychiatric disorders. Its use is approved throughout Europe. The World Federation of Biological Psychiatry guidelines lists EGb 761 with the same weight of evidence (level B) given to acetylcholinesterase inhibitors and memantine. EGb 761 is the only one that showed improvement of symptoms in both Alzheimer\'s disease and vascular dementia. EGb 761 may have a role either on its own or as an add-on if other therapies prove ineffective. A 2016 review concluded that the quality of evidence from clinical trials on Ginkgo biloba has been insufficient to warrant its use for treating Alzheimer\'s disease.Atypical antipsychotics are modestly useful in reducing aggression and psychosis in people with Alzheimer\'s disease, but their advantages are offset by serious adverse effects, such as stroke, movement difficulties or cognitive decline. When used in the long-term, they have been shown to associate with increased mortality. Stopping antipsychotic use in this group of people appears to be safe.  Psychosocial  Psychosocial interventions are used as an adjunct to pharmaceutical treatment and can be classified within behavior-, emotion-, cognition- or stimulation-oriented approaches.Behavioral interventions attempt to identify and reduce the antecedents and consequences of problem behaviors. This approach has not shown success in improving overall functioning, but can help to reduce some specific problem behaviors, such as incontinence. There is a lack of high quality data on the effectiveness of these techniques in other behavior problems such as wandering. Music therapy is effective in reducing behavioral and psychological symptoms.Emotion-oriented interventions include reminiscence therapy, validation therapy, supportive psychotherapy, sensory integration, also called snoezelen, and simulated presence therapy. A Cochrane review has found no evidence that this is effective. Reminiscence therapy (RT) involves the discussion of past experiences individually or in group, many times with the aid of photographs, household items, music and sound recordings, or other familiar items from the past. A 2018 review of the effectiveness of RT found that effects were inconsistent, small in size and of doubtful clinical significance, and varied by setting. Simulated presence therapy (SPT) is based on attachment theories and involves playing a recording with voices of the closest relatives of the person with Alzheimer\'s disease. There is partial evidence indicating that SPT may reduce challenging behaviors.The aim of cognition-oriented treatments, which include reality orientation and cognitive retraining, is the reduction of cognitive deficits. Reality orientation consists of the presentation of information about time, place, or person to ease the understanding of the person about its surroundings and his or her place in them. On the other hand, cognitive retraining tries to improve impaired capacities by exercising mental abilities. Both have shown some efficacy improving cognitive capacities.Stimulation-oriented treatments include art, music and pet therapies, exercise, and any other kind of recreational activities. Stimulation has modest support for improving behavior, mood, and, to a lesser extent, function. Nevertheless, as important as these effects are, the main support for the use of stimulation therapies is the change in the person\'s routine.  Caregiving  Since Alzheimer\'s has no cure and it gradually renders people incapable of tending to their own needs, caregiving is essentially the treatment and must be carefully managed over the course of the disease. During the early and moderate stages, modifications to the living environment and lifestyle can increase safety and reduce caretaker burden. Examples of such modifications are the adherence to simplified routines, the placing of safety locks, the labeling of household items to cue the person with the disease or the use of modified daily life objects. If eating becomes problematic, food will need to be prepared in smaller pieces or even puréed. When swallowing difficulties arise, the use of feeding tubes may be required. In such cases, the medical efficacy and ethics of continuing feeding is an important consideration of the caregivers and family members. The use of physical restraints is rarely indicated in any stage of the disease, although there are situations when they are necessary to prevent harm to the person with Alzheimer\'s disease or their caregivers.During the final stages of the disease, treatment is centred on relieving discomfort until death, often with the help of hospice.  Diet  Diet may be a modifiable risk factor for the development of Alzheimer\'s disease. The Mediterranean diet, and the DASH diet are both associated with less cognitive decline. A different approach has been to incorporate elements of both of these diets into one known as the MIND diet. Studies of individual dietary components, minerals and supplements are conflicting as to whether they prevent AD or cognitive decline.  Prognosis  The early stages of Alzheimer\'s disease are difficult to diagnose. A definitive diagnosis is usually made once cognitive impairment compromises daily living activities, although the person may still be living independently. The symptoms will progress from mild cognitive problems, such as memory loss through increasing stages of cognitive and non-cognitive disturbances, eliminating any possibility of independent living, especially in the late stages of the disease.Life expectancy of people with Alzheimer\'s disease is reduced. The normal life expectancy for 60 to 70 years old is 23 to 15 years; for 90 years old it is 4.5 years. Following Alzheimer\'s disease diagnosis it ranges from 7 to 10 years for those in their 60s and early 70s (a loss of 13 to 8 years), to only about 3 years or less (a loss of 1.5 years) for those in their 90s.Fewer than 3% of people live more than fourteen years. Disease features significantly associated with reduced survival are an increased severity of cognitive impairment, decreased functional level, history of falls, and disturbances in the neurological examination. Other coincident diseases such as heart problems, diabetes, or history of alcohol abuse are also related with shortened survival. While the earlier the age at onset the higher the total survival years, life expectancy is particularly reduced when compared to the healthy population among those who are younger. Men have a less favourable survival prognosis than women.Pneumonia and dehydration are the most frequent immediate causes of death brought by Alzheimer\'s disease, while cancer is a less frequent cause of death than in the general population.  Epidemiology  Two main measures are used in epidemiological studies: incidence and prevalence. Incidence is the number of new cases per unit of person-time at risk (usually number of new cases per thousand person-years); while prevalence is the total number of cases of the disease in the population at any given time. Regarding incidence, cohort longitudinal studies (studies where a disease-free population is followed over the years) provide rates between 10 and 15 per thousand person-years for all dementias and 5–8 for Alzheimer\'s disease, which means that half of new dementia cases each year are Alzheimer\'s disease. Advancing age is a primary risk factor for the disease and incidence rates are not equal for all ages: every 5 years after the age of 65, the risk of acquiring the disease approximately doubles, increasing from 3 to as much as 69 per thousand person years. Females with Alzheimer\'s disease are more common than males, but this difference is likely due to women\'s\' longer life spans. When adjusted for age, both sexes are affected by Alzheimer\'s at equal rates. In the United States, the risk of dying from Alzheimer\'s disease in 2010 was 26% higher among the non-Hispanic white population than among the non-Hispanic black population, and the Hispanic population had a 30% lower risk than the non-Hispanic white population. However, much Alzheimer\'s research remains to be done in minority groups, such as the African American and the Hispanic/Latino populations. Studies have shown that these groups are underrepresented in clinical trials and do not have the same risk of developing Alzheimer\'s when carrying certain genetic risk factors (i.e. APOE4), compared to their caucasian counterparts.The prevalence of Alzheimer\'s disease in populations is dependent upon factors including incidence and survival. Since the incidence of Alzheimer\'s disease increases with age, prevalence depends on the mean age of the population for which prevalence is given. In the United States in 2020, Alzheimer\'s dementia prevalence was estimated to be 5.3% for those in the 60–74 age group, with the rate increasing to 13.8% in the 74–84 group and to 34.6% in those greater than 85. Prevalence rates in some less developed regions around the globe are lower. As the incidence and prevalence are steadily increasing, the prevalence itself is projected to triple by 2050. As of 2020, 50 million people globally have AD, with this number expected to increase to 152 million by 2050.  History  The ancient Greek and Roman philosophers and physicians associated old age with increasing dementia. It was not until 1901 that German psychiatrist Alois Alzheimer identified the first case of what became known as Alzheimer\'s disease, named after him, in a fifty-year-old woman he called Auguste D. He followed her case until she died in 1906 when he first reported publicly on it. During the next five years, eleven similar cases were reported in the medical literature, some of them already using the term Alzheimer\'s disease. The disease was first described as a distinctive disease by Emil Kraepelin after suppressing some of the clinical (delusions and hallucinations) and pathological features (arteriosclerotic changes) contained in the original report of Auguste D. He included Alzheimer\'s disease, also named presenile dementia by Kraepelin, as a subtype of senile dementia in the eighth edition of his Textbook of Psychiatry, published on 15 July, 1910.For most of the 20th century, the diagnosis of Alzheimer\'s disease was reserved for individuals between the ages of 45 and 65 who developed symptoms of dementia. The terminology changed after 1977 when a conference on Alzheimer\'s disease concluded that the clinical and pathological manifestations of presenile and senile dementia were almost identical, although the authors also added that this did not rule out the possibility that they had different causes.","Alzheimer's Disease (AD) is a brain disease that slowly destroys brain cells. As of now, there is no cure for Alzheimer's disease. With time, the different symptoms of the disease become more marked. Many people die because of Alzheimer's disease. The disease affects different parts of the brain but has its worst effects on the areas of the brain that control memory, language, and thinking skills. Alzheimer's Disease is the most common form of senile dementia accounting for up to 70% of cases. The clinical symptoms of AD usually occurs after age 65, but changes in the brain which do not cause symptoms and are caused by Alzheimer's, may begin years or in some cases decades before. Although the symptoms of AD begin in older people it is not a normal part of aging. At this time there is no cure for Alzheimer's, but there are treatments that can help some patients with the signs and symptoms so they do not affect them as badly. There are also treatments which slow down the disease so the damage to the brain does not happen as quickly. There are also certain personal habits that people can learn which may help to delay the onset of the disease. While it is not yet known exactly what causes Alzheimer's disease, there are a number of risk factors which may make a person more likely to get it. Some of these risk factors are genetic; changes to four different genes have been found which increase the risk. The current lifetime risk for a 65-year-old person to get Alzheimer's disease is estimated to be at 10.5%. It is the sixth leading cause of death in the United States causing about 83,500 deaths a year. In 2007, there were more than 26.6 million people throughout the world who were affected by AD.Alzheimer's disease was named after Alois Alzheimer, a German psychiatrist and neuropathologist who first described the disease after studying the case of a middle-aged woman, Auguste Deter, who was a patient at a hospital in Frankfurt, Germany in 1906. The disease was named Alzheimer's disease in 1910 by Dr. Emil Kraepilin a co-worker of Alzheimer.  Tangles and plaque  Two of the main features found in the brains of people with of Alzheimer's disease, are neurobrillary tangles ('tangles' for short), which are made up of a protein called tau, and senile plaques (which are made mostly from another protein called beta-amyloid, they are also sometimes called beta-amyloid bundles or 'bundles' for short). The tau proteins that form the tangles previously held together a structure inside the neurons called a microtubule which is an important part of the neuron; it forms part of the cytoskeleton (cell skeleton) which is what maintains a cell's shape, and microtubules plays a part in cell communication.Both tangles and plaques may be caused by other diseases, such as Herpes simplex virus Type 1 which is being investigated as a possible cause or contributor in developing Alzheimer's. It is not known for sure if tangles and plaques are part of what causes Alzheimer's, or if they are the results. Microtubules Microtubules are made of a protein called tubulin. The tubulin is polymerized, which is when molecules form the same shapes over and over again that are linked together in groups, and these groups are linked together. They can form long chains or other shapes; in this case the polymerized tubulin forms microtubules. The microtubules are rigid tubes like microscopic straws which are hollow inside. Microtubules help keep the shape of the neuron, and are inolved in passing signals through the neuron.Tau Tau is a protein that is found mostly in the neurons of the central nervous system. They help hold together the microtubules within the neurons. and when changes happen in the way the tau proteins are supposed to work the microtubules break apart. The tau proteins which are no longer holding the microtubules together form strands called fibrils, which then clump together inside the neuron to make what are called neurofibrillary tangles . These clumps, also known as 'tau tangles', are all that remain after a neuron has died. Beta-amyloid Beta-amyloid(Aβ) (also called 'amyloid beta') plaques start with a protein called amyloid precursor protein (APP). APP is one of the proteins that make up a cell's membrane or outer covering, that protects the cell. In this case a neuron.. As it is made inside the cell, APP sticks out through the membrane of the cell. In different parts of the of cell including the outermost part of the cell membrane, chemicals called enzymes snip the APP into small pieces. These enzymes that do the snipping are alpha-secretase, beta-secretase, and gamma-secretase. Depending on which enzyme is doing the snipping and what parts of the APP are snipped, two different things can happen. One that is helpful and one that causes the formation of beta-amyloid plaques. The plaques are formed when beta-secretase snips the APP molecule at one end of the beta-amyloid peptide, releasing sAPPβ from the cell. Gamma-secretase then cuts the pieces of APP that is left and, still sticking out of the neuron’s membrane, at the other end of the beta-amyloid peptide. After this snipping the beta-amyloid peptide is released into the space outside the neuron and begins to stick to other beta-amyloid peptides. These pieces stick together to form oligomers. Different oligomers of various sizes are now floating around in the spaces between the neurons, which may be responsible for reacting with receptors on neighboring cells and synapses, affecting their ability to function. Some of these oligomers are cleared from the brain. Those that are not cleared out clump together with more pieces of beta-amyloid. As more pieces clump togther the oligomers get bigger larger, and the next size up are called protofibrils and the next size after that are called fibrils. After a while, these fibrils clump together with other protein molecules, neurons and non-nerve cells floating around in the space between the cells and form what are called plaques. Cerebral amyloid angiopathy (CAA) Deposits of beta-amyloid also form in the walls (in the tunica media, the middle layer, and tunica adventitia or tunica externa, the outer layer) of small and mid-sized arteries (and sometimes veins) in the cerebral cortex and the leptomeninges (the leptomeninges are the two inner layers - pia mater and arachnoid - of the meninges, a protective 3-layer membrane covering the brain.) CAA is found in 30% of people over the age of 60 years who do not have any dementia but is found in 90%-96% of people with Alzheimer disease and is severe in one third to two thirds of these cases.  Stages  The first area of the brain to be affected by Alzheimer's is the ""transentorhinal region"" which is part of the medial temporal lobe located deep within the brain. Neurons start dying in this area first. It then spreads into the adjacent entorhinal cortex (EC) which acts as a central hub, for a widespread network that handles signals for memory and movement(like a main train station with train tracks going to different areas). The EC is the main area for communication between the hippocampus, and the neocortex - which is the outer portion of the brain responsible for higher functioning such as how the brain perceives information from the five senses; (smell, sight, taste, touch and hearing; Ex. seeing a person's face and recognizing them,) generating motor commands (Ex, moving and arm or leg, walking, running) spatial reasoning, conscious thought and language. The disease then spreads into the hippocampus which is part of the limbic system. The hippocampus is the part of the brain that is involved in forming new memories, organizing them, and storing them for later recall. It is also where emotions and senses, such as smell and sound are attached to specific memories. Example 1.: A memory might make you happy or sad. Example 2.: A smell might bring up a certain memory. The hippocampus then sends memories to the different parts of the cerebral hemisphere where they are placed in long-term storage and it helps retrieve them when necessary. Example: An adult trying to remember the name of a classmate from kindergarten. In addition to handling memory the hippocampus is also involved in emotional responses, navigation (getting around) and spatial orientation (knowing your sense of place as you move around Example: Knowing your way around your bedroom even with the lights off). There are actually two parts of the hippocampus which is shaped like a horseshoe with one in the left part of the brain and the other in the right part of the brain.  Diagnosis  Preclinical With current research using advances in neuroimaging such as FDG-PET and PIB-PET scans, and cerebrospinal fluid (CSF) assays, it is now possible to detect the beginning processes of Alzheimer's disease that occur before symptoms begin. The research suggests that clinically normal older people (no symptoms at all) have biomarker evidence of amyloid beta (Aβ) build-up in the brain. This amyloid beta (Aβ) is linked to changes in the structure of the brain and how it works that is the similar to what is seen in people with mild cognitive impairment (MCI) - which may lead to Alzheimer's - and people with Alzheimer's. These small preclinical changes (no symptoms) in the brain may occur many years, to even a few decades before a person is diagnosed with Alzheimer's. With a stage where there is some memory loss, or mild cognitive impairment. These changes put a person at risk of developing the clinical symptoms of full-blown Alzheimer's but not everyone who has these changes will get the disease. Even though there is no cure for Alzheimer's, there are new treatments which are being developed which would work better in the very first stages of the disease.At this time exactly what makes up the preclinical phase of Alzheimer's is still being researched, such as why some people with go on to develop Alzheimer's and others do not. So the term preclinical phase is being used for research only. There is a worldwide effort in various countries doing research in this area known as the World Wide Alzheimer's Disease Neuroimaging Initiative (WW-ADNI) which is the umbrella organization for neuroimaging studies being carried out through the North American ADNI, European ADNI (E-ADNI), Japan ADNI, Australian ADNI (AIBL), Taiwan ADNI, Korea ADNI, China ADNI and Argentina ADNI.Beginning stages ""Misdiagnosis in very early stages of Alzheimer's is a significant problem, as there are more than 100 conditions that can mimic the disease. In people with mild memory complaints, our accuracy is barely better than chance,"" according to study researcher P. Murali Doraiswamy, MBBS, professor of psychiatry and medicine at Duke Medicine, ""Given that the definitive gold standard for diagnosing Alzheimer's is autopsy, we need a better way to look into the brain.""  History  In 1901, a 51-year-old woman named Auguste Deter, was committed to the City Asylum for the Insane and Epileptic, (Städtischen Anstalt für Irre und Epileptische) in Frankfurt am Main, Germany which had the nickname ""Irrenschloss"" (Castle of the Insane). She was married and had a normal life until eight months prior to her commitment, when she started having psychological and neurological problems, such as problems with memory and language, paranoia, becoming disorientated and having hallucinations. She was studied by a doctor on staff named Alois Alzheimer (1864–1915). Alzheimer became interested in her case because of her age; while the effects of senile dementia were known at the time, they usually did not start until a person was in their early to mid-sixties. Her case was also notable because of the rapid onset of dementia, only eight months, from the first reported symptoms, until she was committed. While conducting one of his examinations of Ms. Deter, he asked her to perform a series of simple writing tasks. Unable to do what was asked such as write her name, she said ""I have lost myself, so to speak"" (""Ich habe mich sozusagen selbst verloren""). Alzheimer left the hospital in Franfkurt in 1902 to begin working with Emil Kraepelin at the Psychiatric University Hospital in Heidelberg-Bergheim, and in 1903 both he and Kraepelin began working at Ludwig Maximilian University in Munich. When Ms. Deter died of septicemia on 8 April 1906, Alzheimer was informed and her brain was sent to Munich for him to study. Studying samples of her brain under a microscope he noticed neurofibriallry tangles and bundles made up of beta-amyloid plaque, which are two of the main features of the disease. On 3 November 1906, Alzheimer presented the results of his findings in Auguste's case at the Conference of South-West German Psychiatrists in Tübingen, and he published his findings in the case in 1907. In 1910, Emil Kraepelin named the disease 'Alzheimer's disease'. Alzheimer's disease usually beigins affecting people between ages 60–65, in Ms. Deter's case - who was 55-years-old when she died - she had a form of what is now known as Early-onset Alzhiemer's disease.  Famous cases  Anyone can get Alzheimer's disease, rich people or poor famous people and unfamous people. Some of the famous people who have gotten Alzheimer's disease are former United States President Ronald Reagan and Irish writer Iris Murdoch, both of whom were the subjects of scientific articles examining how their cognitive capacities got worse with the disease.Other cases include the retired footballer Ferenc Puskás, the former Prime Ministers Harold Wilson (United Kingdom) and Adolfo Suárez (Spain), the actress Rita Hayworth, the Nobel Prize-winner Raymond Davis, Jr., the actors Charlton Heston and Gene Wilder, the novelist Terry Pratchett, politician and activist Sargent Shriver, the Blues musician B.B. King, director Jacques Rivette, Indian politician George Fernandes, and the 2009 Nobel Prize in Physics recipient Charles K. Kao. In 2012, Nobel Prize writer Gabriel García Márquez was diagnosed with the disease. Former Finnish President Mauno Koivisto died of the disease in May 2017. Country singer Glen Campbell died of the disease in August 2017.  References   Other websites  ""Cognitive Test for Alzheimer's"". NLM. Retrieved 2007-04-01. video ""Healthy aging"". Retrieved 2007-11-30. ""This is Alzheimer's"". Retrieved 2014-12-28. ""What is Alzheimer's Disease?"". Retrieved 2018-02-13."
"Dementia is a disorder which manifests as a set of related symptoms which results from a variety injuries and diseases. The most common form of dementia is Alzheimer disease. The symptoms involve progressive impairments in memory, thinking, and behavior, which negatively affects a person\'s ability to function and carry out everyday activities. Aside from memory impairment and a disruption in thought patterns, the most common symptoms include emotional problems, difficulties with language, and decreased motivation. The symptoms may be described as occurring in a continuum over several stages. Dementia ultimately has a significant effect on the individual, caregivers, and on social relationships in general. A diagnosis of dementia requires the observation of a change from a person\'s usual mental functioning and a greater cognitive decline than what is caused by normal aging.Several diseases and injuries to the brain such as a stroke can give rise to dementia. However, the most common cause is Alzheimer\'s disease, a neurodegenerative disorder. The Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5), has re-described dementia as either a mild or major neurocognitive disorder with varying degrees of severity and many causative subtypes. The International Classification of Diseases (ICD-11) also classes dementia as a neurocognitive disorder (NCD) with many forms or subclasses. Dementia is listed as an acquired brain syndrome, marked by a decline in cognitive function, and is contrasted with neurodevelopmental disorders. Dementia is also described as a spectrum of disorders with causative subtypes of dementia based on a known disorder, such as Parkinson\'s disease, for Parkinson\'s disease dementia; Huntington\'s disease, for Huntington\'s disease dementia; vascular disease, for vascular dementia; HIV infection, causing HIV dementia; frontotemporal lobar degeneration for frontotemporal dementia; or Lewy body disease for dementia with Lewy bodies, and prion diseases. Subtypes of neurodegenerative dementias may also be based on the underlying pathology of misfolded proteins such as synucleinopathies, and tauopathies. More than one type of dementia existing together is known as mixed dementia.Many neurocognitive disorders may be caused by another medical condition or disorder that includes brain tumours, and subdural hematoma; endocrine disorders such as hypothyroidism, and hypoglycemia; nutritional deficiencies including thiamine, and niacin; infections, immune disorders, liver or kidney failure, metabolic disorders such as Kufs disease, and some leukodystrophies, and neurological disorders such as epilepsy, and multiple sclerosis. Some of the neurocognitive deficits may sometimes show improvement with treatment of the medical condition.Diagnosis is usually based on history of the illness and cognitive testing with imaging. Blood tests may be taken to rule out other possible causes that may be reversible, such as hypothyroidism (an underactive thyroid), and to determine the dementia subtype. One commonly used cognitive test is the Mini-Mental State Examination. The greatest risk factor for developing dementia is aging, however dementia is not a normal part of aging. Many people aged 90 and above show no signs of dementia. Several risk factors for dementia, such as smoking and obesity, are preventable by lifestyle changes. Screening the general older population for the disorder is not seen to affect the outcome.Dementia is currently the seventh leading cause of death worldwide and has 10 million new cases reported every year (one every ~3 seconds). There is no known cure for dementia. Acetylcholinesterase inhibitors such as donepezil are often used and may be beneficial in mild to moderate disorder. The overall benefit, however, may be minor. There are many measures that can improve the quality of life of people with dementia and their caregivers. Cognitive and behavioral interventions may be appropriate for treating associated symptoms of depression.  Signs and symptoms  The signs and symptoms of dementia are termed as the neuropsychiatric symptoms, also known as the behavioral and psychological symptoms of dementia. Behavioral symptoms can include agitation, restlessness, inappropriate behavior, sexual disinhibition, and aggression, which can be verbal or physical. These symptoms may result from impairments in cognitive inhibition. Psychological symptoms can include depression, hallucinations (most often visual), and delusions, apathy, and anxiety. The most commonly affected areas include memory, visuospatial function affecting perception and orientation, language, attention and problem solving. The rate at which symptoms progress occurs on a continuum over several stages, and they vary across the dementia subtypes. Most types of dementia are slowly progressive with some deterioration of the brain well established before signs of the disorder become apparent. Often there are other conditions present such as high blood pressure, or diabetes, and there can sometimes be as many as four of these comorbidities.People with dementia are also more likely to have problems with incontinence: they are three times more likely to have urinary and four times more likely to have fecal incontinence compared to people of similar ages.Dementia symptoms can vary widely from person to person. It affects memory, attention span, communication, reasoning, judgement, problem solving and visual perception, etc. Signs that may point to dementia include getting lost in a familiar neighborhood, using unusual words to refer to familiar objects, forgetting the name of a close family member or friend, forgetting old memories, not being able to complete tasks independently, etc.  Stages  The course of dementia is often described in four stages that show a pattern of progressive cognitive and functional impairment. However, the use of numeric scales allows for more detailed descriptions. These scales include the Global Deterioration Scale for Assessment of Primary Degenerative Dementia (GDS or Reisberg Scale), the Functional Assessment Staging Test (FAST), and the Clinical Dementia Rating (CDR). Using the GDS, which more accurately identifies each stage of the disease progression, a more detailed course is described in seven stages – two of which are broken down further into five and six degrees. Stage 7(f) is the final stage.  Pre-dementia  Pre-dementia states include pre-clinical and prodromal stages. The prodromal stages includes (1) mild cognitive impairment (MCI), (2) delirium-onset, and psychiatric-onset presentations.  Pre-clinical  Sensory dysfunction is claimed for this stage which may precede the first clinical signs of dementia by up to ten years. Most notably the sense of smell is lost. The loss of the sense of smell is associated with depression and loss of appetite leading to poor nutrition. It is suggested that this dysfunction may come about because the olfactory epithelium is exposed to the environment. The lack of blood–brain barrier protection here means that toxic elements can enter and cause damage to the chemosensory networks.  Prodromal  Pre-dementia states considered as prodromal are mild cognitive impairment (MCI), and mild behavioral impairment (MBI).Kynurenine is a metabolite of tryptophan that regulates microbiome signalling, immune cell response, and neuronal excitation. A disruption in the kynurenine pathway may be associated with the neuropsychiatric symptoms and cognitive prognosis in mild dementia.In this stage signs and symptoms may be subtle. Often, the early signs become apparent when looking back. 70% of those diagnosed with MCI later progress to dementia. In MCI, changes in the person\'s brain have been happening for a long time, but symptoms are just beginning to appear. These problems, however, are not severe enough to affect daily function. If and when they do, the diagnosis becomes dementia. They may have some memory trouble and trouble finding words, but they solve everyday problems and competently handle their life affairs. During this stage, it is ideal to ensure that advance care planning has occurred to protect the wishes of the person. Advance directives which are specific to dementia exist, which can be particularly helpful in addressing the decisions related to feeding which come with the progression of the illness. Mild cognitive impairment has been relisted in both DSM-5, and ICD-11, as mild neurocognitive disorders – milder forms of the major neurocognitive disorder (dementia) subtypes.  Early  In the early stage of dementia, symptoms become noticeable to other people. In addition, the symptoms begin to interfere with daily activities, and will register a score on a Mini-Mental State Examination (MMSE). MMSE scores are set at 24 to 30 for a normal cognitive rating and lower scores reflect severity of symptoms. The symptoms are dependent on the type of dementia. More complicated chores and tasks around the house or at work become more difficult. The person can usually still take care of themselves but may forget things like taking pills or doing laundry and may need prompting or reminders.The symptoms of early dementia usually include memory difficulty, but can also include some word-finding problems, and problems with executive functions of planning and organization. Managing finances may prove difficult. Other signs might be getting lost in new places, repeating things, and personality changes.In some types of dementia, such as dementia with Lewy bodies and frontotemporal dementia, personality changes and difficulty with organization and planning may be the first signs.  Middle  As dementia progresses, initial symptoms generally worsen. The rate of decline is different for each person. MMSE scores between 6–17 signal moderate dementia. For example, people with moderate Alzheimer\'s dementia lose almost all new information. People with dementia may be severely impaired in solving problems, and their social judgment is usually also impaired. They cannot usually function outside their own home, and generally should not be left alone. They may be able to do simple chores around the house but not much else, and begin to require assistance for personal care and hygiene beyond simple reminders. A lack of insight into having the condition will become evident.  Late  People with late-stage dementia typically turn increasingly inward and need assistance with most or all of their personal care. Persons with dementia in the late stages usually need 24-hour supervision to ensure their personal safety, and meeting of basic needs. If left unsupervised, they may wander or fall; may not recognize common dangers such as a hot stove; or may not realize that they need to use the bathroom and become incontinent. They may not want to get out of bed, or may need assistance doing so. Commonly, the person no longer recognizes familiar faces. They may have significant changes in sleeping habits or have trouble sleeping at all.Changes in eating frequently occur. Cognitive awareness is needed for eating and swallowing and progressive cognitive decline results in eating and swallowing difficulties. This can cause food to be refused, or choked on, and help with feeding will often be required. For ease of feeding, food may be liquidized into a thick purée. They may also struggle to walk, particularly among those with Alzheimer\'s disease.  Subtypes  Many of the subtypes of dementia are neurodegenerative, and protein misfolding is a cardinal feature of these.  Alzheimer\'s disease  Alzheimer\'s disease accounts for 60–70% of cases of dementia worldwide. The most common symptoms of Alzheimer\'s disease are short-term memory loss and word-finding difficulties. Trouble with visuospatial functioning (getting lost often), reasoning, judgment and insight fail. Insight refers to whether or not the person realizes they have memory problems. The part of the brain most affected by Alzheimer\'s is the hippocampus. Other parts that show atrophy (shrinking) include the temporal and parietal lobes. Although this pattern of brain shrinkage suggests Alzheimer\'s, it is variable and a brain scan is insufficient for a diagnosis. The relationship between general anesthesia and Alzheimer\'s in elderly people is unclear.Little is known about the events that occur during and that actually cause Alzheimer\'s disease. This is due to the fact that brain tissue from patients with the disease can only be studied after the person\'s death. However, it is known that one of the first aspects of the disease is a dysfunction in the gene that produces amyloid. Extracellular senile plaques (SPs), consisting of beta-amyloid (Aβ) peptides, and intracellular neurofibrillary tangles (NFTs) that are formed by hyperphosphorylated tau proteins, are two well-established pathological hallmarks of AD. Amyloid causes inflammation around the senile plaques of the brain, and too much build up of this inflammation leads to changes in the brain that cannot be controlled, leading to the symptoms of Alzheimer\'s.  Vascular  Vascular dementia accounts for at least 20% of dementia cases, making it the second most common type. It is caused by disease or injury affecting the blood supply to the brain, typically involving a series of mini-strokes. The symptoms of this dementia depend on where in the brain the strokes occurred and whether the blood vessels affected were large or small. Repeated injury can cause progressive dementia over time, while a single injury located in an area critical for cognition such as the hippocampus, or thalamus, can lead to sudden cognitive decline. Elements of vascular dementia may be present in all other forms of dementia.Brain scans may show evidence of multiple strokes of different sizes in various locations. People with vascular dementia tend to have risk factors for disease of the blood vessels, such as tobacco use, high blood pressure, atrial fibrillation, high cholesterol, diabetes, or other signs of vascular disease such as a previous heart attack or angina.  Lewy bodies  The prodromal symptoms of dementia with Lewy bodies (DLB) include mild cognitive impairment, and delirium onset. The symptoms of DLB are more frequent, more severe, and earlier presenting than in the other dementia subtypes. Dementia with Lewy bodies has the primary symptoms of fluctuating cognition, alertness or attention; REM sleep behavior disorder (RBD); one or more of the main features of parkinsonism, not due to medication or stroke; and repeated visual hallucinations. The visual hallucinations in DLB are generally vivid hallucinations of people or animals and they often occur when someone is about to fall asleep or wake up. Other prominent symptoms include problems with planning (executive function) and difficulty with visual-spatial function, and disruption in autonomic bodily functions. Abnormal sleep behaviors may begin before cognitive decline is observed and are a core feature of DLB. RBD is diagnosed either by sleep study recording or, when sleep studies cannot be performed, by medical history and validated questionnaires.  Parkinson\'s disease  Parkinson\'s disease is a Lewy body disease that often progresses to Parkinson\'s disease dementia following a period of dementia-free Parkinson\'s disease.  Frontotemporal  Frontotemporal dementias (FTDs) are characterized by drastic personality changes and language difficulties. In all FTDs, the person has a relatively early social withdrawal and early lack of insight. Memory problems are not a main feature. There are six main types of FTD. The first has major symptoms in personality and behavior. This is called behavioral variant FTD (bv-FTD) and is the most common. The hallmark feature of bv-FTD is impulsive behavior, and this can be detected in pre-dementia states. In bv-FTD, the person shows a change in personal hygiene, becomes rigid in their thinking, and rarely acknowledges problems; they are socially withdrawn, and often have a drastic increase in appetite. They may become socially inappropriate. For example, they may make inappropriate sexual comments, or may begin using pornography openly. One of the most common signs is apathy, or not caring about anything. Apathy, however, is a common symptom in many dementias.Two types of FTD feature aphasia (language problems) as the main symptom. One type is called semantic variant primary progressive aphasia (SV-PPA). The main feature of this is the loss of the meaning of words. It may begin with difficulty naming things. The person eventually may lose the meaning of objects as well. For example, a drawing of a bird, dog, and an airplane in someone with FTD may all appear almost the same. In a classic test for this, a patient is shown a picture of a pyramid and below it a picture of both a palm tree and a pine tree. The person is asked to say which one goes best with the pyramid. In SV-PPA the person cannot answer that question. The other type is called non-fluent agrammatic variant primary progressive aphasia (NFA-PPA). This is mainly a problem with producing speech. They have trouble finding the right words, but mostly they have a difficulty coordinating the muscles they need to speak. Eventually, someone with NFA-PPA only uses one-syllable words or may become totally mute. A frontotemporal dementia associated with amyotrophic lateral sclerosis (ALS) known as (FTD-ALS) includes the symptoms of FTD (behavior, language and movement problems) co-occurring with amyotrophic lateral sclerosis (loss of motor neurons). Two FTD-related disorders are progressive supranuclear palsy (also classed as a Parkinson-plus syndrome), and corticobasal degeneration. These disorders are tau-associated.  Huntington\'s disease  Huntington\'s disease is a neurodegenerative disease caused by mutations in a single gene HTT, that encodes for huntingtin protein. Symptoms include cognitive impairment and this usually declines further into dementia.The first main symptoms of Huntington\'s disease often include: difficulty concentrating memory lapses depression - this can include low mood, lack of interest in things, or just abnormal feelings of hopelessness stumbling and clumsiness that is out of the ordinary mood swings, such as irritability or aggressive behavior to insignificant things  HIV  HIV-associated dementia results as a late stage from HIV infection, and mostly affects younger people. The essential features of HIV-associated dementia are disabling cognitive impairment accompanied by motor dysfunction, speech problems and behavioral change. Cognitive impairment is characterised by mental slowness, trouble with memory and poor concentration. Motor symptoms include a loss of fine motor control leading to clumsiness, poor balance and tremors. Behavioral changes may include apathy, lethargy and diminished emotional responses and spontaneity. Histopathologically, it is identified by the infiltration of monocytes and macrophages into the central nervous system (CNS), gliosis, pallor of myelin sheaths, abnormalities of dendritic processes and neuronal loss.  Creutzfeldt–Jakob disease  Creutzfeldt–Jakob disease is a rapidly progressive prion disease that typically causes dementia that worsens over weeks to months. Prions are disease-causing pathogens created from abnormal proteins.  Alcoholism  Alcohol-related dementia, also called alcohol-related brain damage, occurs as a result of excessive use of alcohol particularly as a substance abuse disorder. Different factors can be involved in this development including thiamine deficiency and age vulnerability. A degree of brain damage is seen in more than 70% of those with alcohol use disorder. Brain regions affected are similar to those that are affected by aging, and also by Alzheimer\'s disease. Regions showing loss of volume include the frontal, temporal, and parietal lobes, as well as the cerebellum, thalamus, and hippocampus. This loss can be more notable, with greater cognitive impairments seen in those aged 65 years and older.  Mixed dementia  More than one type of dementia, known as mixed dementia, may exist together in about 10% of dementia cases. The most common type of mixed dementia is Alzheimer\'s disease and vascular dementia. This particular type of mixed dementia\'s main onsets are a mixture of old age, high blood pressure, and damage to blood vessels in the brain.Diagnosis of mixed dementia can be difficult, as often only one type will predominate. This makes the treatment of people with mixed dementia uncommon, with many people missing out on potentially helpful treatments. Mixed dementia can mean that symptoms onset earlier, and worsen more quickly since more parts of the brain will be affected.Genetics Although it is not very common to inherit dementia from a parent or grandparent, there are genetic linked causes of dementia. These are only a small overall portion of the overall cases of dementia, but it is possible.  Other  Chronic inflammatory conditions that may affect the brain and cognition include Behçet\'s disease, multiple sclerosis, sarcoidosis, Sjögren\'s syndrome, lupus, celiac disease, and non-celiac gluten sensitivity. These types of dementias can rapidly progress, but usually have a good response to early treatment. This consists of immunomodulators or steroid administration, or in certain cases, the elimination of the causative agent. A 2019 review found no association between celiac disease and dementia overall but a potential association with vascular dementia. A 2018 review found a link between celiac disease or non-celiac gluten sensitivity and cognitive impairment and that celiac disease may be associated with Alzheimer\'s disease, vascular dementia, and frontotemporal dementia. A strict gluten-free diet started early may protect against dementia associated with gluten-related disorders.Cases of easily reversible dementia include hypothyroidism, vitamin B12 deficiency, Lyme disease, and neurosyphilis. For Lyme disease and neurosyphilis, testing should be done if risk factors are present. Because risk factors are often difficult to determine, testing for neurosyphilis and Lyme disease, as well as other mentioned factors, may be undertaken as a matter of course where dementia is suspected.: 31–32 Many other medical and neurological conditions include dementia only late in the illness. For example, a proportion of patients with Parkinson\'s disease develop dementia, though widely varying figures are quoted for this proportion. When dementia occurs in Parkinson\'s disease, the underlying cause may be dementia with Lewy bodies or Alzheimer\'s disease, or both. Cognitive impairment also occurs in the Parkinson-plus syndromes of progressive supranuclear palsy and corticobasal degeneration (and the same underlying pathology may cause the clinical syndromes of frontotemporal lobar degeneration). Although the acute porphyrias may cause episodes of confusion and psychiatric disturbance, dementia is a rare feature of these rare diseases. Limbic-predominant age-related TDP-43 encephalopathy (LATE) is a type of dementia that primarily affects people in their 80s or 90s and in which TDP-43 protein deposits in the limbic portion of the brain.Hereditary disorders that can also cause dementia include: some metabolic disorders such as lysosomal storage disorders, leukodystrophies, and spinocerebellar ataxias.  Diagnosis  Symptoms are similar across dementia types and it is difficult to diagnose by symptoms alone. Diagnosis may be aided by brain scanning techniques. In many cases, the diagnosis requires a brain biopsy to become final, but this is rarely recommended (though it can be performed at autopsy). In those who are getting older, general screening for cognitive impairment using cognitive testing or early diagnosis of dementia has not been shown to improve outcomes. However, screening exams are useful in 65+ persons with memory complaints.Normally, symptoms must be present for at least six months to support a diagnosis. Cognitive dysfunction of shorter duration is called delirium. Delirium can be easily confused with dementia due to similar symptoms. Delirium is characterized by a sudden onset, fluctuating course, a short duration (often lasting from hours to weeks), and is primarily related to a somatic (or medical) disturbance. In comparison, dementia has typically a long, slow onset (except in the cases of a stroke or trauma), slow decline of mental functioning, as well as a longer trajectory (from months to years).Some mental illnesses, including depression and psychosis, may produce symptoms that must be differentiated from both delirium and dementia. These are differently diagnosed as pseudodementias, and any dementia evaluation needs to include a depression screening such as the Neuropsychiatric Inventory or the Geriatric Depression Scale. Physicians used to think that people with memory complaints had depression and not dementia (because they thought that those with dementia are generally unaware of their memory problems). However, researchers have realized that many older people with memory complaints in fact have mild cognitive impairment the earliest stage of dementia. Depression should always remain high on the list of possibilities, however, for an elderly person with memory trouble. Changes in thinking, hearing and vision are associated with normal ageing and can cause problems when diagnosing dementia due to the similarities. Given the challenging nature of predicting the onset of dementia and making a dementia diagnosis clinical decision making aids underpinned by machine learning and artificial intelligence have the potential to enhance clinical practice.  Cognitive testing  Various brief cognitive tests (5–15 minutes) have reasonable reliability to screen for dementia, but may be affected by factors such as age, education and ethnicity. Age and education have a significant influence on the diagnosis of dementia. For example, Individuals with lower education are more likely to be diagnosed with dementia than their educated counterparts. While many tests have been studied, presently the mini mental state examination (MMSE) is the best studied and most commonly used. The MMSE is a useful tool for helping to diagnose dementia if the results are interpreted along with an assessment of a person\'s personality, their ability to perform activities of daily living, and their behaviour. Other cognitive tests include the abbreviated mental test score (AMTS), the, Modified Mini-Mental State Examination (3MS), the Cognitive Abilities Screening Instrument (CASI), the Trail-making test, and the clock drawing test. The MoCA (Montreal Cognitive Assessment) is a reliable screening test and is available online for free in 35 different languages. The MoCA has also been shown somewhat better at detecting mild cognitive impairment than the MMSE. The AD-8 – a screening questionnaire used to assess changes in function related to cognitive decline – is potentially useful, but is not diagnostic, is variable, and has risk of bias. An integrated cognitive assessment (CognICA) is a five-minute test that is highly sensitive to the early stages of dementia, and uses an application deliverable to an iPad. Previously in use in the UK, in 2021 CognICA was given FDA approval for its commercial use as a medical device.Another approach to screening for dementia is to ask an informant (relative or other supporter) to fill out a questionnaire about the person\'s everyday cognitive functioning. Informant questionnaires provide complementary information to brief cognitive tests. Probably the best known questionnaire of this sort is the Informant Questionnaire on Cognitive Decline in the Elderly (IQCODE). Evidence is insufficient to determine how accurate the IQCODE is for diagnosing or predicting dementia. The Alzheimer\'s Disease Caregiver Questionnaire is another tool. It is about 90% accurate for Alzheimer\'s when by a caregiver. The General Practitioner Assessment Of Cognition combines both a patient assessment and an informant interview. It was specifically designed for use in the primary care setting. Clinical neuropsychologists provide diagnostic consultation following administration of a full battery of cognitive testing, often lasting several hours, to determine functional patterns of decline associated with varying types of dementia. Tests of memory, executive function, processing speed, attention and language skills are relevant, as well as tests of emotional and psychological adjustment. These tests assist with ruling out other etiologies and determining relative cognitive decline over time or from estimates of prior cognitive abilities.  Laboratory tests  Routine blood tests are usually performed to rule out treatable causes. These include tests for vitamin B12, folic acid, thyroid-stimulating hormone (TSH), C-reactive protein, full blood count, electrolytes, calcium, renal function, and liver enzymes. Abnormalities may suggest vitamin deficiency, infection, or other problems that commonly cause confusion or disorientation in the elderly.  Imaging  A CT scan or MRI scan is commonly performed to possibly find either normal pressure hydrocephalus, a potentially reversible cause of dementia, or connected tumor. The scans can also yield information relevant to other types of dementia, such as infarction (stroke) that would point at a vascular type of dementia. These tests do not pick up diffuse metabolic changes associated with dementia in a person who shows no gross neurological problems (such as paralysis or weakness) on a neurological exam.The functional neuroimaging modalities of SPECT and PET are more useful in assessing long-standing cognitive dysfunction, since they have shown similar ability to diagnose dementia as a clinical exam and cognitive testing. The ability of SPECT to differentiate vascular dementia from Alzheimer\'s disease, appears superior to differentiation by clinical exam.The value of PiB-PET imaging using Pittsburgh compound B (PiB) as a radiotracer has been established in predictive diagnosis, particularly Alzheimer\'s disease.  Prevention   Risk factors  An influential review increased the number of associated risk factors for dementia from nine to twelve in 2020. The three newly added risks are over-indulgence in alcohol, traumatic brain injury, and air pollution. The other nine risk factors are: lower levels of education, high blood pressure, hearing loss, smoking, obesity, depression, inactivity, diabetes, and low social contact. Many of these identified risk factors including, the lower level of education, smoking, physical inactivity and diabetes, are modifiable. Several of the group are known vascular risk factors that may be able to be reduced or eliminated. Managing these risk factors can reduce the risk of dementia in individuals in their late midlife or older age. A reduction in a number of these risk factors can give a positive outcome. The decreased risk achieved by adopting a healthy lifestyle is seen even in those with a high genetic risk.In addition to the above risk factors, meta-analyses indicate that there is robust evidence that other psychological traits, including personality (high neuroticism, and low conscientiousness), low purpose in life, and high loneliness, are risk factors for Alzheimer\'s disease and related dementias. For example, based on the English Longitudinal Study of Ageing (ELSA), research found that loneliness in older people increased the risk of dementia by one-third. Not having a partner (being single, divorced, or widowed) doubled the risk of dementia. However, having two or three closer relationships reduced the risk by three-fifths.The two most modifiable risk factors for dementia are physical inactivity and lack of cognitive stimulation. Physical activity, in particular aerobic exercise, is associated with a reduction in age-related brain tissue loss, and neurotoxic factors thereby preserving brain volume and neuronal integrity. Cognitive activity strengthens neural plasticity and together they help to support cognitive reserve. The neglect of these risk factors diminishes this reserve.Studies suggest that sensory impairments of vision and hearing are modifiable risk factors for dementia. These impairments may precede the cognitive symptoms of Alzheimer\'s disease for example, by many years. Hearing loss may lead to social isolation which negatively affects cognition. Social isolation is also identified as a modifiable risk factor. Age-related hearing loss in midlife is linked to cognitive impairment in late life, and is seen as a risk factor for the development of Alzheimer\'s disease and dementia. Such hearing loss may be caused by a central auditory processing disorder that makes the understanding of speech against background noise difficult. Age-related hearing loss is characterised by slowed central processing of auditory information. Worldwide, mid-life hearing loss may account for around 9% of dementia cases.Evidence suggests that frailty may increase the risk of cognitive decline, and dementia, and that the inverse also holds of cognitive impairment increasing the risk of frailty. Prevention of frailty may help to prevent cognitive decline.A 2018 review however concluded that no medications have good evidence of a preventive effect, including blood pressure medications. A 2020 review found a decrease in the risk of dementia or cognitive problems from 7.5% to 7.0% with blood pressure lowering medications.Economic disadvantage has been shown to have a strong link to higher dementia prevalence, which cannot yet be fully explained by other risk factors.  Dental health  Limited evidence links poor oral health to cognitive decline. However, failure to perform tooth brushing and gingival inflammation can be used as dementia risk predictors.  Oral bacteria  The link between Alzheimer\'s and gum disease is oral bacteria. In the oral cavity, bacterial species include P. gingivalis, F. nucleatum, P. intermedia, and T. forsythia. Six oral treponema spirochetes have been examined in the brains of Alzheimer\'s patients. Spirochetes are neurotropic in nature, meaning they act to destroy nerve tissue and create inflammation. Inflammatory pathogens are an indicator of Alzheimer\'s disease and bacteria related to gum disease have been found in the brains of patients with Alzheimer\'s disease. The bacteria invade nerve tissue in the brain, increasing the permeability of the blood–brain barrier and promoting the onset of Alzheimer\'s. Individuals with a plethora of tooth plaque risk cognitive decline. Poor oral hygiene can have an adverse effect on speech and nutrition, causing general and cognitive health decline.  Oral viruses  Herpes simplex virus (HSV) has been found in more than 70% of those aged over 50. HSV persists in the peripheral nervous system and can be triggered by stress, illness or fatigue. High proportions of viral-associated proteins in amyloid plaques or neurofibrillary tangles (NFTs) confirm the involvement of HSV-1 in Alzheimer\'s disease pathology. NFTs are known as the primary marker of Alzheimer\'s disease. HSV-1 produces the main components of NFTs.  Diet  Diet is seen to be a modifiable risk factor for the development of dementia. Thiamine deficiency is identified to increase the risk of Alzheimer\'s disease in adults. The role of thiamine in brain physiology is unique and essential for the normal cognitive function of older people. Many dietary choices of the elderly population, including the higher intake of gluten-free products, compromise the intake of thiamine as these products are not fortified with thiamine.The Mediterranean and DASH diets are both associated with less cognitive decline. A different approach has been to incorporate elements of both of these diets into one known as the MIND diet. These diets are generally low in saturated fats while providing a good source of carbohydrates, mainly those that help stabilize blood sugar and insulin levels. Raised blood sugar levels over a long time, can damage nerves and cause memory problems if they are not managed. Nutritional factors associated with the proposed diets for reducing dementia risk include unsaturated fatty acids, vitamin E, vitamin C, flavonoids, vitamin B, and vitamin D. A study conducted at the University of Exeter in the United Kingdom seems to have confirmed these findings with fruits, vegetables, whole grains, and healthy fats creating an optimum diet that can help reduce the risk of dementia by roughly 25%.The MIND diet may be more protective but further studies are needed. The Mediterranean diet seems to be more protective against Alzheimer\'s than DASH but there are no consistent findings against dementia in general. The role of olive oil needs further study as it may be one of the most important components in reducing the risk of cognitive decline and dementia.In those with celiac disease or non-celiac gluten sensitivity, a strict gluten-free diet may relieve the symptoms given a mild cognitive impairment. Once dementia is advanced no evidence suggests that a gluten-free diet is useful.Omega-3 fatty acid supplements do not appear to benefit or harm people with mild to moderate symptoms. However, there is good evidence that omega-3 incorporation into the diet is of benefit in treating depression, a common symptom, and potentially modifiable risk factor for dementia.  Management  There are limited options for treating dementia, with most approaches focused on managing or reducing individual symptoms. There are no treatment options available to delay the onset of dementia. Acetylcholinesterase inhibitors are often used early in the disorder course; however, benefit is generally small. More than half of people with dementia may experience psychological or behavioral symptoms including agitation, sleep problems, aggression, and/or psychosis. Treatment for these symptoms is aimed at reducing the person\'s distress and keeping the person safe. Treatments other than medication appear to be better for agitation and aggression. Cognitive and behavioral interventions may be appropriate. Some evidence suggests that education and support for the person with dementia, as well as caregivers and family members, improves outcomes. Palliative care interventions may lead to improvements in comfort in dying, but the evidence is low. Exercise programs are beneficial with respect to activities of daily living, and potentially improve dementia.The effect of therapies can be evaluated for example by assessing agitation using the Cohen-Mansfield Agitation Inventory (CMAI); by assessing mood and engagement with the Menorah Park Engagement Scale (MPES); and the Observed Emotion Rating Scale (OERS) or by assessing indicators for depression using the Cornell Scale for Depression in Dementia (CSDD) or a simplified version thereof.Often overlooked in treating and managing dementia is the role of the caregiver and what is known about how they can support multiple interventions. Findings from a 2021 systematic review of the literature found caregivers of people with dementia in nursing homes do not have sufficient tools or clinical guidance for behavioral and psychological symptoms of dementia (BPSD) along with medication use. Simple measures like talking to people about their interests can improve the quality of life for care home residents living with dementia. A programme showed that such simple measures reduced residents\' agitation and depression. They also needed fewer GP visits and hospital admissions, which also meant that the programme was cost-saving.  Psychological and psychosocial therapies  Psychological therapies for dementia include some limited evidence for reminiscence therapy (namely, some positive effects in the areas of quality of life, cognition, communication and mood – the first three particularly in care home settings), some benefit for cognitive reframing for caretakers, unclear evidence for validation therapy and tentative evidence for mental exercises, such as cognitive stimulation programs for people with mild to moderate dementia. Offering personally tailored activities may help reduce challenging behavior and may improve quality of life. It is not clear if personally tailored activities have an impact on affect or improve for the quality of life for the caregiver.Adult daycare centers as well as special care units in nursing homes often provide specialized care for dementia patients. Daycare centers offer supervision, recreation, meals, and limited health care to participants, as well as providing respite for caregivers. In addition, home care can provide one-to-one support and care in the home allowing for more individualized attention that is needed as the disorder progresses. Psychiatric nurses can make a distinctive contribution to people\'s mental health.Since dementia impairs normal communication due to changes in receptive and expressive language, as well as the ability to plan and problem solve, agitated behavior is often a form of communication for the person with dementia. Actively searching for a potential cause, such as pain, physical illness, or overstimulation can be helpful in reducing agitation. Additionally, using an ""ABC analysis of behavior"" can be a useful tool for understanding behavior in people with dementia. It involves looking at the antecedents (A), behavior (B), and consequences (C) associated with an event to help define the problem and prevent further incidents that may arise if the person\'s needs are misunderstood. The strongest evidence for non-pharmacological therapies for the management of changed behaviors in dementia is for using such approaches. Low quality evidence suggests that regular (at least five sessions of) music therapy may help institutionalized residents. It may reduce depressive symptoms and improve overall behaviors. It may also supply a beneficial effect on emotional well-being and quality of life, as well as reduce anxiety. In 2003, The Alzheimer\'s Society established \'Singing for the Brain\' (SftB) a project based on pilot studies which suggested that the activity encouraged participation and facilitated the learning of new songs. The sessions combine aspects of reminiscence therapy and music. Musical and interpersonal connectedness can underscore the value of the person and improve quality of life.Some London hospitals found that using color, designs, pictures and lights helped people with dementia adjust to being at the hospital. These adjustments to the layout of the dementia wings at these hospitals helped patients by preventing confusion.Life story work as part of reminiscence therapy, and video biographies have been found to address the needs of clients and their caregivers in various ways, offering the client the opportunity to leave a legacy and enhance their personhood and also benefitting youth who participate in such work. Such interventions can be more beneficial when undertaken at a relatively early stage of dementia. They may also be problematic in those who have difficulties in processing past experiencesAnimal-assisted therapy has been found to be helpful. Drawbacks may be that pets are not always welcomed in a communal space in the care setting. An animal may pose a risk to residents, or may be perceived to be dangerous. Certain animals may also be regarded as ""unclean"" or ""dangerous"" by some cultural groups.Occupational therapy also addresses psychological and psychosocial needs of patients with dementia through improving daily occupational performance and caregivers\' competence. When compensatory intervention strategies are added to their daily routine, the level of performance is enhanced and reduces the burden commonly placed on their caregivers. Occupational therapists can also work with other disciplines to create a client centered intervention. To manage cognitive disability, and coping with behavioral and psychological symptoms of dementia, combined occupational and behavioral therapies can support patients with dementia even further.  Cognitive training  There is no strong evidence to suggest that cognitive training is beneficial for people with Parkinson\'s disease, dementia, or mild cognitive impairment.  Personally tailored activities  Offering personally tailored activity sessions to people with dementia in long-term care homes may slightly reduce challenging behavior.  Medications  No medications have been shown to prevent or cure dementia. Medications may be used to treat the behavioral and cognitive symptoms, but have no effect on the underlying disease process.Acetylcholinesterase inhibitors, such as donepezil, may be useful for Alzheimer\'s disease, Parkinson\'s disease dementia, DLB, or vascular dementia. The quality of the evidence is poor and the benefit is small. No difference has been shown between the agents in this family. In a minority of people side effects include a slow heart rate and fainting. Rivastigmine is recommended for treating symptoms in Parkinson\'s disease dementia.Medications that have anticholinergic effects increase all-cause mortality in people with dementia, although the effect of these medications on cognitive function remains uncertain, according to a systematic review published in 2021.Before prescribing antipsychotic medication in the elderly, an assessment for an underlying cause of the behavior is needed. Severe and life-threatening reactions occur in almost half of people with DLB, and can be fatal after a single dose. People with Lewy body dementias who take neuroleptics are at risk for neuroleptic malignant syndrome, a life-threatening illness. Extreme caution is required in the use of antipsychotic medication in people with DLB because of their sensitivity to these agents. Antipsychotic drugs are used to treat dementia only if non-drug therapies have not worked, and the person\'s actions threaten themselves or others. Aggressive behavior changes are sometimes the result of other solvable problems, that could make treatment with antipsychotics unnecessary. Because people with dementia can be aggressive, resistant to their treatment, and otherwise disruptive, sometimes antipsychotic drugs are considered as a therapy in response. These drugs have risky adverse effects, including increasing the person\'s chance of stroke and death. Given these adverse events and small benefit antipsychotics are avoided whenever possible. Generally, stopping antipsychotics for people with dementia does not cause problems, even in those who have been on them a long time.N-methyl-D-aspartate (NMDA) receptor blockers such as memantine may be of benefit but the evidence is less conclusive than for AChEIs. Due to their differing mechanisms of action memantine and acetylcholinesterase inhibitors can be used in combination however the benefit is slight.An extract of Ginkgo biloba known as EGb 761 has been widely used for treating mild to moderate dementia and other neuropsychiatric disorders. Its use is approved throughout Europe. The World Federation of Biological Psychiatry guidelines lists EGb 761 with the same weight of evidence (level B) given to acetylcholinesterase inhibitors, and mementine.","Dementia is a group of diseases with symptoms, which affect the way people think and interact with each other. It can often be linked to a disease or damage done to the brain. Very often, short-time memory, mind, speech and motor skills are affected. Certain forms of dementia cause a change in the personality of the sufferer. A person suffering from dementia will lose certain skills and knowledge they already had. This is the main difference to other conditions affecting the mind. People who suffer from learning problems, or lower intelligence will never acquire certain skills, people suffering from dementia will lose skills they have acquired. Dementia is more common in older people, but younger people can be affected as well. Certain forms of dementia can be treated, to some extent. The most common form of dementia is Alzheimer's disease, which accounts for between 50 and 60 percent of all cases. Other types include vascular dementia and lewy body dementia.Famous people who suffered from dementia include Augusto Pinochet, the Chilean leader, and also Rosa Parks, the civil rights activist. People who see the following worsen may suffer from dementia: Decision-making ability Judgment Orientation in time and space Problem solving Verbal communicationBehavioral changes may include: Eating Dressing (may need assistance) Interests Routine activities (may become unable to perform household tasks) Personality (inappropriate responses, lack of emotional control)Some types dementia are reversible. This means the damage can be undone. Other types are irreversible. This means that they cannot be undone. Irreversible dementia is usually caused by an incurable disease, such as Alzheimer's disease. Reversible causes of dementia also include diffuse axonal injury after injuries to the head or the brain, known medically as Traumatic brain injury. Creutzfeldt-Jakob disease causes a dementia that gets worse quickly, over weeks or months, and is caused by prions. ,other forms like encephalopathy or delirium may develop relatively slowly, over a number of years. The two leading causes of dementia are Alzheimer's disease and Multi-infarct disease. Glioma related tumors are another kmown cause. Alcohol dementia, is sometimes associated with Wernicke-Korsakoff syndrome, and is caused by long-term or uncontrolled, heavy alcohol abuse. Possible metabolic causes are such as liver failure or kidney failure; and chronic subdural hematoma. Possible other causes may include brain infection by illnesses like meningitis leading in cases to viral encephalitis drug toxicity (e.g. anticonvulsant drugs). A recent report by Science Daily says that researchers at the University of Bergen, in Norway have discovered a connection between Oral health and Alzheimers disease.  Related pages  Alzheimer's disease Vascular dementia Meningitis Encephalitis Primary central nervous system lymphoma  References   Other websites  ""What is Dementia?"". Retrieved 2010-01-30."
"Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body. These contrast with benign tumors, which do not spread. Possible signs and symptoms include a lump, abnormal bleeding, prolonged cough, unexplained weight loss, and a change in bowel movements. While these symptoms may indicate cancer, they can also have other causes. Over 100 types of cancers affect humans.Tobacco use is the cause of about 22% of cancer deaths. Another 10% are due to obesity, poor diet, lack of physical activity or excessive drinking of alcohol. Other factors include certain infections, exposure to ionizing radiation, and environmental pollutants. In the developing world, 15% of cancers are due to infections such as Helicobacter pylori, hepatitis B, hepatitis C, human papillomavirus infection, Epstein–Barr virus and human immunodeficiency virus (HIV). These factors act, at least partly, by changing the genes of a cell. Typically, many genetic changes are required before cancer develops. Approximately 5–10% of cancers are due to inherited genetic defects. Cancer can be detected by certain signs and symptoms or screening tests. It is then typically further investigated by medical imaging and confirmed by biopsy.The risk of developing certain cancers can be reduced by not smoking, maintaining a healthy weight, limiting alcohol intake, eating plenty of vegetables, fruits, and whole grains, eating resistant starch, vaccination against certain infectious diseases, limiting consumption of processed meat and red meat, and limiting exposure to direct sunlight. Early detection through screening is useful for cervical and colorectal cancer. The benefits of screening for breast cancer are controversial. Cancer is often treated with some combination of radiation therapy, surgery, chemotherapy and targeted therapy. Pain and symptom management are an important part of care. Palliative care is particularly important in people with advanced disease. The chance of survival depends on the type of cancer and extent of disease at the start of treatment. In children under 15 at diagnosis, the five-year survival rate in the developed world is on average 80%. For cancer in the United States, the average five-year survival rate is 66% for all ages.In 2015, about 90.5 million people worldwide had cancer. In 2019, annual cancer cases grew by 23.6 million people and there were 10 million deaths worldwide, representing over the previous decade increases of 26% and 21%, respectively.The most common types of cancer in males are lung cancer, prostate cancer, colorectal cancer, and stomach cancer. In females, the most common types are breast cancer, colorectal cancer, lung cancer, and cervical cancer. If skin cancer other than melanoma were included in total new cancer cases each year, it would account for around 40% of cases. In children, acute lymphoblastic leukemia and brain tumors are most common, except in Africa, where non-Hodgkin lymphoma occurs more often. In 2012, about 165,000 children under 15 years of age were diagnosed with cancer. The risk of cancer increases significantly with age, and many cancers occur more commonly in developed countries. Rates are increasing as more people live to an old age and as lifestyle changes occur in the developing world. The global total economic costs of cancer were estimated at US$1.16 trillion (equivalent to $1.44 trillion in 2021) per year as of 2010.  Etymology and definitions  The word comes from the ancient Greek καρκίνος, meaning \'crab\' and \'tumor\'. Greek physicians Hippocrates and Galen, among others, noted the similarity of crabs to some tumors with swollen veins. The word was introduced in English in the modern medical sense around 1600.Cancers comprise a large family of diseases that involve abnormal cell growth with the potential to invade or spread to other parts of the body. They form a subset of neoplasms. A neoplasm or tumor is a group of cells that have undergone unregulated growth and will often form a mass or lump, but may be distributed diffusely.All tumor cells show the six hallmarks of cancer. These characteristics are required to produce a malignant tumor. They include: Cell growth and division absent the proper signals Continuous growth and division even given contrary signals Avoidance of programmed cell death Limitless number of cell divisions Promoting blood vessel construction Invasion of tissue and formation of metastasesThe progression from normal cells to cells that can form a detectable mass to outright cancer involves multiple steps known as malignant progression.  Signs and symptoms  When cancer begins, it produces no symptoms. Signs and symptoms appear as the mass grows or ulcerates. The findings that result depend on cancer\'s type and location. Few symptoms are specific. Many frequently occur in individuals who have other conditions. Cancer can be difficult to diagnose and can be considered a ""great imitator.""People may become anxious or depressed post-diagnosis. The risk of suicide in people with cancer is approximately double.  Local symptoms  Local symptoms may occur due to the mass of the tumor or its ulceration. For example, mass effects from lung cancer can block the bronchus resulting in cough or pneumonia; esophageal cancer can cause narrowing of the esophagus, making it difficult or painful to swallow; and colorectal cancer may lead to narrowing or blockages in the bowel, affecting bowel habits. Masses in breasts or testicles may produce observable lumps. Ulceration can cause bleeding that can lead to symptoms such as coughing up blood (lung cancer), anemia or rectal bleeding (colon cancer), blood in the urine (bladder cancer), or abnormal vaginal bleeding (endometrial or cervical cancer). Although localized pain may occur in advanced cancer, the initial tumor is usually painless. Some cancers can cause a buildup of fluid within the chest or abdomen.  Systemic symptoms  Systemic symptoms may occur due to the body\'s response to the cancer. This may include fatigue, unintentional weight loss, or skin changes. Some cancers can cause a systemic inflammatory state that leads to ongoing muscle loss and weakness, known as cachexia.Some cancers, such as Hodgkin\'s disease, leukemias, and liver or kidney cancers, can cause a persistent fever.Some systemic symptoms of cancer are caused by hormones or other molecules produced by the tumor, known as paraneoplastic syndromes. Common paraneoplastic syndromes include hypercalcemia, which can cause altered mental state, constipation and dehydration, or hyponatremia, which can also cause altered mental status, vomiting, headaches, or seizures.  Metastasis  Metastasis is the spread of cancer to other locations in the body. The dispersed tumors are called metastatic tumors, while the original is called the primary tumor. Almost all cancers can metastasize. Most cancer deaths are due to cancer that has metastasized.Metastasis is common in the late stages of cancer and it can occur via the blood or the lymphatic system or both. The typical steps in metastasis are local invasion, intravasation into the blood or lymph, circulation through the body, extravasation into the new tissue, proliferation and angiogenesis. Different types of cancers tend to metastasize to particular organs, but overall the most common places for metastases to occur are the lungs, liver, brain, and the bones.  Causes  The majority of cancers, some 90–95% of cases, are due to genetic mutations from environmental and lifestyle factors. The remaining 5–10% are due to inherited genetics. Environmental refers to any cause that is not inherited, such as lifestyle, economic, and behavioral factors and not merely pollution. Common environmental factors that contribute to cancer death include tobacco use (25–30%), diet and obesity (30–35%), infections (15–20%), radiation (both ionizing and non-ionizing, up to 10%), lack of physical activity, and pollution. Psychological stress does not appear to be a risk factor for the onset of cancer, though it may worsen outcomes in those who already have cancer.It is not generally possible to prove what caused a particular cancer because the various causes do not have specific fingerprints. For example, if a person who uses tobacco heavily develops lung cancer, then it was probably caused by the tobacco use, but since everyone has a small chance of developing lung cancer as a result of air pollution or radiation, the cancer may have developed for one of those reasons. Excepting the rare transmissions that occur with pregnancies and occasional organ donors, cancer is generally not a transmissible disease, however factors that may have contributed to the development of cancer can be transmissible; such as oncoviruses like hepatitis B, Epstein-Barr virus and HIV.  Chemicals  Exposure to particular substances have been linked to specific types of cancer. These substances are called carcinogens. Tobacco smoke, for example, causes 90% of lung cancer. It also causes cancer in the larynx, head, neck, stomach, bladder, kidney, esophagus and pancreas. Tobacco smoke contains over fifty known carcinogens, including nitrosamines and polycyclic aromatic hydrocarbons.Tobacco is responsible for about one in five cancer deaths worldwide and about one in three in the developed world. Lung cancer death rates in the United States have mirrored smoking patterns, with increases in smoking followed by dramatic increases in lung cancer death rates and, more recently, decreases in smoking rates since the 1950s followed by decreases in lung cancer death rates in men since 1990.In Western Europe, 10% of cancers in males and 3% of cancers in females are attributed to alcohol exposure, especially liver and digestive tract cancers. Cancer from work-related substance exposures may cause between 2 and 20% of cases, causing at least 200,000 deaths. Cancers such as lung cancer and mesothelioma can come from inhaling tobacco smoke or asbestos fibers, or leukemia from exposure to benzene.Exposure to perfluorooctanoic acid (PFOA), which is predominantly used in the production of Teflon, is known to cause two kinds of cancer.  Diet and exercise  Diet, physical inactivity, and obesity are related to up to 30–35% of cancer deaths. In the United States, excess body weight is associated with the development of many types of cancer and is a factor in 14–20% of cancer deaths. A UK study including data on over 5 million people showed higher body mass index to be related to at least 10 types of cancer and responsible for around 12,000 cases each year in that country. Physical inactivity is believed to contribute to cancer risk, not only through its effect on body weight but also through negative effects on the immune system and endocrine system. More than half of the effect from the diet is due to overnutrition (eating too much), rather than from eating too few vegetables or other healthful foods. Some specific foods are linked to specific cancers. A high-salt diet is linked to gastric cancer. Aflatoxin B1, a frequent food contaminant, causes liver cancer. Betel nut chewing can cause oral cancer. National differences in dietary practices may partly explain differences in cancer incidence. For example, gastric cancer is more common in Japan due to its high-salt diet while colon cancer is more common in the United States. Immigrant cancer profiles mirror those of their new country, often within one generation.  Infection  Worldwide approximately 18% of cancer deaths are related to infectious diseases. This proportion ranges from a high of 25% in Africa to less than 10% in the developed world. Viruses are the usual infectious agents that cause cancer but cancer bacteria and parasites may also play a role. Oncoviruses (viruses that can cause cancer) include human papillomavirus (cervical cancer), Epstein–Barr virus (B-cell lymphoproliferative disease and nasopharyngeal carcinoma), Kaposi\'s sarcoma herpesvirus (Kaposi\'s sarcoma and primary effusion lymphomas), hepatitis B and hepatitis C viruses (hepatocellular carcinoma) and human T-cell leukemia virus-1 (T-cell leukemias). Bacterial infection may also increase the risk of cancer, as seen in Helicobacter pylori-induced gastric carcinoma. Parasitic infections associated with cancer include Schistosoma haematobium (squamous cell carcinoma of the bladder) and the liver flukes, Opisthorchis viverrini and Clonorchis sinensis (cholangiocarcinoma).  Radiation  Radiation exposure such as ultraviolet radiation and radioactive material is a risk factor for cancer. Many non-melanoma skin cancers are due to ultraviolet radiation, mostly from sunlight. Sources of ionizing radiation include medical imaging and radon gas.Ionizing radiation is not a particularly strong mutagen. Residential exposure to radon gas, for example, has similar cancer risks as passive smoking. Radiation is a more potent source of cancer when combined with other cancer-causing agents, such as radon plus tobacco smoke. Radiation can cause cancer in most parts of the body, in all animals and at any age. Children are twice as likely to develop radiation-induced leukemia as adults; radiation exposure before birth has ten times the effect.Medical use of ionizing radiation is a small but growing source of radiation-induced cancers. Ionizing radiation may be used to treat other cancers, but this may, in some cases, induce a second form of cancer. It is also used in some kinds of medical imaging.Prolonged exposure to ultraviolet radiation from the sun can lead to melanoma and other skin malignancies. Clear evidence establishes ultraviolet radiation, especially the non-ionizing medium wave UVB, as the cause of most non-melanoma skin cancers, which are the most common forms of cancer in the world.Non-ionizing radio frequency radiation from mobile phones, electric power transmission and other similar sources has been described as a possible carcinogen by the World Health Organization\'s International Agency for Research on Cancer. Evidence, however, has not supported a concern. This includes that studies have not found a consistent link between mobile phone radiation and cancer risk.  Heredity  The vast majority of cancers are non-hereditary (sporadic). Hereditary cancers are primarily caused by an inherited genetic defect. Less than 0.3% of the population are carriers of a genetic mutation that has a large effect on cancer risk and these cause less than 3–10% of cancer. Some of these syndromes include: certain inherited mutations in the genes BRCA1 and BRCA2 with a more than 75% risk of breast cancer and ovarian cancer, and hereditary nonpolyposis colorectal cancer (HNPCC or Lynch syndrome), which is present in about 3% of people with colorectal cancer, among others. Statistically for cancers causing most mortality, the relative risk of developing colorectal cancer when a first-degree relative (parent, sibling or child) has been diagnosed with it is about 2. The corresponding relative risk is 1.5 for lung cancer, and 1.9 for prostate cancer. For breast cancer, the relative risk is 1.8 with a first-degree relative having developed it at 50 years of age or older, and 3.3 when the relative developed it when being younger than 50 years of age.Taller people have an increased risk of cancer because they have more cells than shorter people. Since height is genetically determined to a large extent, taller people have a heritable increase of cancer risk.  Physical agents  Some substances cause cancer primarily through their physical, rather than chemical, effects. A prominent example of this is prolonged exposure to asbestos, naturally occurring mineral fibers that are a major cause of mesothelioma (cancer of the serous membrane) usually the serous membrane surrounding the lungs. Other substances in this category, including both naturally occurring and synthetic asbestos-like fibers, such as wollastonite, attapulgite, glass wool and rock wool, are believed to have similar effects. Non-fibrous particulate materials that cause cancer include powdered metallic cobalt and nickel and crystalline silica (quartz, cristobalite and tridymite). Usually, physical carcinogens must get inside the body (such as through inhalation) and require years of exposure to produce cancer.Physical trauma resulting in cancer is relatively rare. Claims that breaking bones resulted in bone cancer, for example, have not been proven. Similarly, physical trauma is not accepted as a cause for cervical cancer, breast cancer or brain cancer. One accepted source is frequent, long-term application of hot objects to the body. It is possible that repeated burns on the same part of the body, such as those produced by kanger and kairo heaters (charcoal hand warmers), may produce skin cancer, especially if carcinogenic chemicals are also present. Frequent consumption of scalding hot tea may produce esophageal cancer. Generally, it is believed that cancer arises, or a pre-existing cancer is encouraged, during the process of healing, rather than directly by the trauma. However, repeated injuries to the same tissues might promote excessive cell proliferation, which could then increase the odds of a cancerous mutation. Chronic inflammation has been hypothesized to directly cause mutation. Inflammation can contribute to proliferation, survival, angiogenesis and migration of cancer cells by influencing the tumor microenvironment. Oncogenes build up an inflammatory pro-tumorigenic microenvironment.  Hormones  Some hormones play a role in the development of cancer by promoting cell proliferation. Insulin-like growth factors and their binding proteins play a key role in cancer cell proliferation, differentiation and apoptosis, suggesting possible involvement in carcinogenesis.Hormones are important agents in sex-related cancers, such as cancer of the breast, endometrium, prostate, ovary and testis and also of thyroid cancer and bone cancer. For example, the daughters of women who have breast cancer have significantly higher levels of estrogen and progesterone than the daughters of women without breast cancer. These higher hormone levels may explain their higher risk of breast cancer, even in the absence of a breast-cancer gene. Similarly, men of African ancestry have significantly higher levels of testosterone than men of European ancestry and have a correspondingly higher level of prostate cancer. Men of Asian ancestry, with the lowest levels of testosterone-activating androstanediol glucuronide, have the lowest levels of prostate cancer.Other factors are relevant: obese people have higher levels of some hormones associated with cancer and a higher rate of those cancers. Women who take hormone replacement therapy have a higher risk of developing cancers associated with those hormones. On the other hand, people who exercise far more than average have lower levels of these hormones and lower risk of cancer. Osteosarcoma may be promoted by growth hormones. Some treatments and prevention approaches leverage this cause by artificially reducing hormone levels and thus discouraging hormone-sensitive cancers.  Autoimmune diseases  There is an association between celiac disease and an increased risk of all cancers. People with untreated celiac disease have a higher risk, but this risk decreases with time after diagnosis and strict treatment, probably due to the adoption of a gluten-free diet, which seems to have a protective role against development of malignancy in people with celiac disease. However, the delay in diagnosis and initiation of a gluten-free diet seems to increase the risk of malignancies. Rates of gastrointestinal cancers are increased in people with Crohn\'s disease and ulcerative colitis, due to chronic inflammation. Also, immunomodulators and biologic agents used to treat these diseases may promote developing extra-intestinal malignancies.  Pathophysiology   Genetics  Cancer is fundamentally a disease of tissue growth regulation. For a normal cell to transform into a cancer cell, the genes that regulate cell growth and differentiation must be altered.The affected genes are divided into two broad categories. Oncogenes are genes that promote cell growth and reproduction. Tumor suppressor genes are genes that inhibit cell division and survival. Malignant transformation can occur through the formation of novel oncogenes, the inappropriate over-expression of normal oncogenes, or by the under-expression or disabling of tumor suppressor genes. Typically, changes in multiple genes are required to transform a normal cell into a cancer cell.Genetic changes can occur at different levels and by different mechanisms. The gain or loss of an entire chromosome can occur through errors in mitosis. More common are mutations, which are changes in the nucleotide sequence of genomic DNA. Large-scale mutations involve the deletion or gain of a portion of a chromosome. Genomic amplification occurs when a cell gains copies (often 20 or more) of a small chromosomal locus, usually containing one or more oncogenes and adjacent genetic material. Translocation occurs when two separate chromosomal regions become abnormally fused, often at a characteristic location. A well-known example of this is the Philadelphia chromosome, or translocation of chromosomes 9 and 22, which occurs in chronic myelogenous leukemia and results in production of the BCR-abl fusion protein, an oncogenic tyrosine kinase. Small-scale mutations include point mutations, deletions, and insertions, which may occur in the promoter region of a gene and affect its expression, or may occur in the gene\'s coding sequence and alter the function or stability of its protein product. Disruption of a single gene may also result from integration of genomic material from a DNA virus or retrovirus, leading to the expression of viral oncogenes in the affected cell and its descendants. Replication of the data contained within the DNA of living cells will probabilistically result in some errors (mutations). Complex error correction and prevention are built into the process and safeguard the cell against cancer. If a significant error occurs, the damaged cell can self-destruct through programmed cell death, termed apoptosis. If the error control processes fail, then the mutations will survive and be passed along to daughter cells. Some environments make errors more likely to arise and propagate. Such environments can include the presence of disruptive substances called carcinogens, repeated physical injury, heat, ionising radiation, or hypoxia.The errors that cause cancer are self-amplifying and compounding, for example: A mutation in the error-correcting machinery of a cell might cause that cell and its children to accumulate errors more rapidly. A further mutation in an oncogene might cause the cell to reproduce more rapidly and more frequently than its normal counterparts. A further mutation may cause loss of a tumor suppressor gene, disrupting the apoptosis signaling pathway and immortalizing the cell. A further mutation in the signaling machinery of the cell might send error-causing signals to nearby cells.The transformation of a normal cell into cancer is akin to a chain reaction caused by initial errors, which compound into more severe errors, each progressively allowing the cell to escape more controls that limit normal tissue growth. This rebellion-like scenario is an undesirable survival of the fittest, where the driving forces of evolution work against the body\'s design and enforcement of order. Once cancer has begun to develop, this ongoing process, termed clonal evolution, drives progression towards more invasive stages. Clonal evolution leads to intra-tumour heterogeneity (cancer cells with heterogeneous mutations) that complicates designing effective treatment strategies and requires an evolutionary approach to designing treatment. Characteristic abilities developed by cancers are divided into categories, specifically evasion of apoptosis, self-sufficiency in growth signals, insensitivity to anti-growth signals, sustained angiogenesis, limitless replicative potential, metastasis, reprogramming of energy metabolism and evasion of immune destruction.  Epigenetics  The classical view of cancer is a set of diseases driven by progressive genetic abnormalities that include mutations in tumor-suppressor genes and oncogenes, and in chromosomal abnormalities. A role for epigenetic alterations was identified in the early 21st century.Epigenetic alterations are functionally relevant modifications to the genome that do not change the nucleotide sequence. Examples of such modifications are changes in DNA methylation (hypermethylation and hypomethylation), histone modification and changes in chromosomal architecture (caused by inappropriate expression of proteins such as HMGA2 or HMGA1). Each of these alterations regulates gene expression without altering the underlying DNA sequence. These changes may remain through cell divisions, endure for multiple generations, and can be considered as equivalent to mutations. Epigenetic alterations occur frequently in cancers. As an example, one study listed protein coding genes that were frequently altered in their methylation in association with colon can. These included 147 hypermethylatecerd and 27 hypomethylated genes. Of the hypermethylated genes, 10 were hypermethylated in 100% of colon cancers and many others were hypermethylated in more than 50% of colon cancers.While epigenetic alterations are found in cancers, the epigenetic alterations in DNA repair genes, causing reduced expression of DNA repair proteins, may be of particular importance. Such alterations may occur early in progression to cancer and are a possible cause of the genetic instability characteristic of cancers.Reduced expression of DNA repair genes disrupts DNA repair. This is shown in the figure at the 4th level from the top. (In the figure, red wording indicates the central role of DNA damage and defects in DNA repair in progression to cancer.) When DNA repair is deficient DNA damage remains in cells at a higher than usual level (5th level) and causes increased frequencies of mutation and/or epimutation (6th level). Mutation rates increase substantially in cells defective in DNA mismatch repair or in homologous recombinational repair (HRR). Chromosomal rearrangements and aneuploidy also increase in HRR defective cells.Higher levels of DNA damage cause increased mutation (right side of figure) and increased epimutation. During repair of DNA double strand breaks, or repair of other DNA damage, incompletely cleared repair sites can cause epigenetic gene silencing.Deficient expression of DNA repair proteins due to an inherited mutation can increase cancer risks. Individuals with an inherited impairment in any of 34 DNA repair genes (see article DNA repair-deficiency disorder) have increased cancer risk, with some defects ensuring a 100% lifetime chance of cancer (e.g. p53 mutations). Germ line DNA repair mutations are noted on the figure\'s left side. However, such germline mutations (which cause highly penetrant cancer syndromes) are the cause of only about 1 percent of cancers.In sporadic cancers, deficiencies in DNA repair are occasionally caused by a mutation in a DNA repair gene but are much more frequently caused by epigenetic alterations that reduce or silence expression of DNA repair genes. This is indicated in the figure at the 3rd level. Many studies of heavy metal-induced carcinogenesis show that such heavy metals cause a reduction in expression of DNA repair enzymes, some through epigenetic mechanisms. DNA repair inhibition is proposed to be a predominant mechanism in heavy metal-induced carcinogenicity. In addition, frequent epigenetic alterations of the DNA sequences code for small RNAs called microRNAs (or miRNAs). miRNAs do not code for proteins, but can ""target"" protein-coding genes and reduce their expression. Cancers usually arise from an assemblage of mutations and epimutations that confer a selective advantage leading to clonal expansion (see Field defects in progression to cancer). Mutations, however, may not be as frequent in cancers as epigenetic alterations. An average cancer of the breast or colon can have about 60 to 70 protein-altering mutations, of which about three or four may be ""driver"" mutations and the remaining ones may be ""passenger"" mutations.  Metastasis  Metastasis is the spread of cancer to other locations in the body. The dispersed tumors are called metastatic tumors, while the original is called the primary tumor. Almost all cancers can metastasize. Most cancer deaths are due to cancer that has metastasized.Metastasis is common in the late stages of cancer and it can occur via the blood or the lymphatic system or both. The typical steps in metastasis are local invasion, intravasation into the blood or lymph, circulation through the body, extravasation into the new tissue, proliferation and angiogenesis. Different types of cancers tend to metastasize to particular organs, but overall the most common places for metastases to occur are the lungs, liver, brain and the bones.  Metabolism  Normal cells typically generate only about 30% of energy from glycolysis, whereas most cancers rely on glycolysis for energy production (Warburg effect). But a minority of cancer types rely on oxidative phosphorylation as the primary energy source, including lymphoma, leukemia, and endometrial cancer. Even in these cases, however, the use of glycolysis as an energy source rarely exceeds 60%. A few cancers use glutamine as the major energy source, partly because it provides nitrogen required for nucleotide (DNA, RNA) synthesis. Cancer stem cells often use oxidative phosphorylation or glutamine as a primary energy source.Several studies have indicated that the enzyme sirtuin 6 is selectively inactivated during oncogenesis in a variety of tumor types by inducing glycolysis. Another sirtuin, sirtuin 3 inhibits cancers that depend upon glycolysis, but promotes cancers that depend upon oxidative phosphorylation.A low-carbohydrate diet (ketogenic diet) has sometimes been recommended as a supportive therapy for cancer treatment.  Diagnosis  Most cancers are initially recognized either because of the appearance of signs or symptoms or through screening. Neither of these leads to a definitive diagnosis, which requires the examination of a tissue sample by a pathologist. People with suspected cancer are investigated with medical tests. These commonly include blood tests, X-rays, (contrast) CT scans and endoscopy. The tissue diagnosis from the biopsy indicates the type of cell that is proliferating, its histological grade, genetic abnormalities and other features. Together, this information is useful to evaluate the prognosis and to choose the best treatment. Cytogenetics and immunohistochemistry are other types of tissue tests. These tests provide information about molecular changes (such as mutations, fusion genes and numerical chromosome changes) and may thus also indicate the prognosis and best treatment. Cancer diagnosis can cause psychological distress and psychosocial interventions, such as talking therapy, may help people with this.  Classification  Cancers are classified by the type of cell that the tumor cells resemble and is therefore presumed to be the origin of the tumor. These types include: Carcinoma: Cancers derived from epithelial cells. This group includes many of the most common cancers and include nearly all those in the breast, prostate, lung, pancreas and colon. Sarcoma: Cancers arising from connective tissue (i.e. bone, cartilage, fat, nerve), each of which develops from cells originating in mesenchymal cells outside the bone marrow. Lymphoma and leukemia: These two classes arise from hematopoietic (blood-forming) cells that leave the marrow and tend to mature in the lymph nodes and blood, respectively. Germ cell tumor: Cancers derived from pluripotent cells, most often presenting in the testicle or the ovary (seminoma and dysgerminoma, respectively). Blastoma: Cancers derived from immature ""precursor"" cells or embryonic tissue.Cancers are usually named using -carcinoma, -sarcoma or -blastoma as a suffix, with the Latin or Greek word for the organ or tissue of origin as the root. For example, cancers of the liver parenchyma arising from malignant epithelial cells is called hepatocarcinoma, while a malignancy arising from primitive liver precursor cells is called a hepatoblastoma and a cancer arising from fat cells is called a liposarcoma. For some common cancers, the English organ name is used. For example, the most common type of breast cancer is called ductal carcinoma of the breast. Here, the adjective ductal refers to the appearance of cancer under the microscope, which suggests that it has originated in the milk ducts. Benign tumors (which are not cancers) are named using -oma as a suffix with the organ name as the root. For example, a benign tumor of smooth muscle cells is called a leiomyoma (the common name of this frequently occurring benign tumor in the uterus is fibroid). Confusingly, some types of cancer use the -noma suffix, examples including melanoma and seminoma. Some types of cancer are named for the size and shape of the cells under a microscope, such as giant cell carcinoma, spindle cell carcinoma and small-cell carcinoma.  Prevention  Cancer prevention is defined as active measures to decrease cancer risk. The vast majority of cancer cases are due to environmental risk factors. Many of these environmental factors are controllable lifestyle choices. Thus, cancer is generally preventable. Between 70% and 90% of common cancers are due to environmental factors and therefore potentially preventable.Greater than 30% of cancer deaths could be prevented by avoiding risk factors including: tobacco, excess weight/obesity, poor diet, physical inactivity, alcohol, sexually transmitted infections and air pollution. Further, poverty could be considered as an indirect risk factor in human cancers. Not all environmental causes are controllable, such as naturally occurring background radiation and cancers caused through hereditary genetic disorders and thus are not preventable via personal behavior. In 2019, ~44% of all cancer deaths – or ~4.5 M deaths or ~105 million lost disability-adjusted life years – were due to known clearly preventable risk factors, led by smoking, alcohol use and high BMI, according to a GBD systematic analysis.  Dietary  While many dietary recommendations have been proposed to reduce cancer risks, the evidence to support them is not definitive. The primary dietary factors that increase risk are obesity and alcohol consumption. Diets low in fruits and vegetables and high in red meat have been implicated but reviews and meta-analyses do not come to a consistent conclusion. A 2014 meta-analysis found no relationship between fruits and vegetables and cancer. Coffee is associated with a reduced risk of liver cancer. Studies have linked excessive consumption of red or processed meat to an increased risk of breast cancer, colon cancer and pancreatic cancer, a phenomenon that could be due to the presence of carcinogens in meats cooked at high temperatures. In 2015 the IARC reported that eating processed meat (e.g., bacon, ham, hot dogs, sausages) and, to a lesser degree, red meat was linked to some cancers.Dietary recommendations for cancer prevention typically include an emphasis on vegetables, fruit, whole grains and fish and an avoidance of processed and red meat (beef, pork, lamb), animal fats, pickled foods and refined carbohydrates.  Medication  Medications can be used to prevent cancer in a few circumstances. In the general population, NSAIDs reduce the risk of colorectal cancer; however, due to cardiovascular and gastrointestinal side effects, they cause overall harm when used for prevention. Aspirin has been found to reduce the risk of death from cancer by about 7%. COX-2 inhibitors may decrease the rate of polyp formation in people with familial adenomatous polyposis; however, it is associated with the same adverse effects as NSAIDs. Daily use of tamoxifen or raloxifene reduce the risk of breast cancer in high-risk women. The benefit versus harm for 5-alpha-reductase inhibitor such as finasteride is not clear.Vitamin supplementation does not appear to be effective at preventing cancer. While low blood levels of vitamin D are correlated with increased cancer risk, whether this relationship is causal and vitamin D supplementation is protective is not determined. One 2014 review found that supplements had no significant effect on cancer risk. Another 2014 review concluded that vitamin D3 may decrease the risk of death from cancer (one fewer death in 150 people treated over 5 years), but concerns with the quality of the data were noted.Beta-Carotene supplementation increases lung cancer rates in those who are high risk. Folic acid supplementation is not effective in preventing colon cancer and may increase colon polyps. Selenium supplementation has not been shown to reduce the risk of cancer.  Vaccination  Vaccines have been developed that prevent infection by some carcinogenic viruses. Human papillomavirus vaccine (Gardasil and Cervarix) decrease the risk of developing cervical cancer. The hepatitis B vaccine prevents infection with hepatitis B virus and thus decreases the risk of liver cancer. The administration of human papillomavirus and hepatitis B vaccinations is recommended where resources allow.  Screening  Unlike diagnostic efforts prompted by symptoms and medical signs, cancer screening involves efforts to detect cancer after it has formed, but before any noticeable symptoms appear. This may involve physical examination, blood or urine tests or medical imaging.Cancer screening is not available for many types of cancers. Even when tests are available, they may not be recommended for everyone. Universal screening or mass screening involves screening everyone. Selective screening identifies people who are at higher risk, such as people with a family history. Several factors are considered to determine whether the benefits of screening outweigh the risks and the costs of screening. These factors include: Possible harms from the screening test: for example, X-ray images involve exposure to potentially harmful ionizing radiation The likelihood of the test correctly identifying cancer The likelihood that cancer is present: Screening is not normally useful for rare cancers. Possible harms from follow-up procedures Whether suitable treatment is available Whether early detection improves treatment outcomes Whether cancer will ever need treatment Whether the test is acceptable to the people: If a screening test is too burdensome (for example, extremely painful), then people will refuse to participate. Cost  Recommendations   U.S. Preventive Services Task Force  The U.S. Preventive Services Task Force (USPSTF) issues recommendations for various cancers: Strongly recommends cervical cancer screening in women who are sexually active and have a cervix at least until the age of 65. Recommend that Americans be screened for colorectal cancer via fecal occult blood testing, sigmoidoscopy, or colonoscopy starting at age 50 until age 75. Evidence is insufficient to recommend for or against screening for skin cancer, oral cancer, lung cancer, or prostate cancer in men under 75. Routine screening is not recommended for bladder cancer, testicular cancer, ovarian cancer, pancreatic cancer, or prostate cancer. Recommends mammography for breast cancer screening every two years from ages 50–74, but does not recommend either breast self-examination or clinical breast examination. A 2013 Cochrane review concluded that breast cancer screening by mammography had no effect in reducing mortality because of overdiagnosis and overtreatment.  Japan  Screens for gastric cancer using photofluorography due to the high incidence there.  Genetic testing  Genetic testing for individuals at high-risk of certain cancers is recommended by unofficial groups. Carriers of these mutations may then undergo enhanced surveillance, chemoprevention, or preventative surgery to reduce their subsequent risk.  Management  Many treatment options for cancer exist. The primary ones include surgery, chemotherapy, radiation therapy, hormonal therapy, targeted therapy and palliative care. Which treatments are used depends on the type, location and grade of the cancer as well as the patient\'s health and preferences. The treatment intent may or may not be curative.  Chemotherapy  Chemotherapy is the treatment of cancer with one or more cytotoxic anti-neoplastic drugs (chemotherapeutic agents) as part of a standardized regimen. The term encompasses a variety of drugs, which are divided into broad categories such as alkylating agents and antimetabolites. Traditional chemotherapeutic agents act by killing cells that divide rapidly, a critical property of most cancer cells. It was found that providing combined cytotoxic drugs is better than a single drug, a process called the combination therapy, which has an advantage in the statistics of survival and response to the tumor and in the progress of the disease. A Cochrane review concluded that combined therapy was more effective to treat metastasized breast cancer. However, generally it is not certain whether combination chemotherapy leads to better health outcomes, when both survival and toxicity are considered.Targeted therapy is a form of chemotherapy that targets specific molecular differences between cancer and normal cells. The first targeted therapies blocked the estrogen receptor molecule, inhibiting the growth of breast cancer. Another common example is the class of Bcr-Abl inhibitors, which are used to treat chronic myelogenous leukemia (CML). Currently, targeted therapies exist for many of the most common cancer types, including bladder cancer, breast cancer, colorectal cancer, kidney cancer, leukemia, liver cancer, lung cancer, lymphoma, pancreatic cancer, prostate cancer, skin cancer, and thyroid cancer as well as other cancer types.The efficacy of chemotherapy depends on the type of cancer and the stage. In combination with surgery, chemotherapy has proven useful in cancer types including breast cancer, colorectal cancer, pancreatic cancer, osteogenic sarcoma, testicular cancer, ovarian cancer and certain lung cancers. Chemotherapy is curative for some cancers, such as some leukemias, ineffective in some brain tumors, and needless in others, such as most non-melanoma skin cancers. The effectiveness of chemotherapy is often limited by its toxicity to other tissues in the body. Even when chemotherapy does not provide a permanent cure, it may be useful to reduce symptoms such as pain or to reduce the size of an inoperable tumor in the hope that surgery will become possible in the future.  Radiation  Radiation therapy involves the use of ionizing radiation in an attempt to either cure or improve symptoms. It works by damaging the DNA of cancerous tissue, causing mitotic catastrophe resulting in the death of the cancer cells. To spare normal tissues (such as skin or organs, which radiation must pass through to treat the tumor), shaped radiation beams are aimed from multiple exposure angles to intersect at the tumor, providing a much larger dose there than in the surrounding, healthy tissue. As with chemotherapy, cancers vary in their response to radiation therapy.Radiation therapy is used in about half of cases. The radiation can be either from internal sources (brachytherapy) or external sources. The radiation is most commonly low energy X-rays for treating skin cancers, while higher energy X-rays are used for cancers within the body. Radiation is typically used in addition to surgery and or chemotherapy. For certain types of cancer, such as early head and neck cancer, it may be used alone. For painful bone metastasis, it has been found to be effective in about 70% of patients.  Surgery  Surgery is the primary method of treatment for most isolated, solid cancers and may play a role in palliation and prolongation of survival. It is typically an important part of definitive diagnosis and staging of tumors, as biopsies are usually required. In localized cancer, surgery typically attempts to remove the entire mass along with, in certain cases, the lymph nodes in the area. For some types of cancer this is sufficient to eliminate the cancer.  Palliative care  Palliative care is treatment that attempts to help the patient feel better and may be combined with an attempt to treat the cancer. Palliative care includes action to reduce physical, emotional, spiritual and psycho-social distress. Unlike treatment that is aimed at directly killing cancer cells, the primary goal of palliative care is to improve quality of life. People at all stages of cancer treatment typically receive some kind of palliative care. In some cases, medical specialty professional organizations recommend that patients and physicians respond to cancer only with palliative care. This applies to patients who: display low performance status, implying limited ability to care for themselves received no benefit from prior evidence-based treatments are not eligible to participate in any appropriate clinical trial no strong evidence implies that treatment would be effectivePalliative care may be confused with hospice and therefore only indicated when people approach end of life. Like hospice care, palliative care attempts to help the patient cope with their immediate needs and to increase comfort. Unlike hospice care, palliative care does not require people to stop treatment aimed at the cancer. Multiple national medical guidelines recommend early palliative care for patients whose cancer has produced distressing symptoms or who need help coping with their illness. In patients first diagnosed with metastatic disease, palliative care may be immediately indicated. Palliative care is indicated for patients with a prognosis of less than 12 months of life even given aggressive treatment.  Immunotherapy  A variety of therapies using immunotherapy, stimulating or helping the immune system to fight cancer, have come into use since 1997. Approaches include antibodies, checkpoint therapy, and adoptive cell transfer.  Laser therapy  Laser therapy uses high-intensity light to treat cancer by shrinking or destroying tumors or precancerous growths. Lasers are most commonly used to treat superficial cancers that are on the surface of the body or the lining of internal organs. It is used to treat basal cell skin cancer and the very early stages of others like cervical, penile, vaginal, vulvar, and non-small cell lung cancer. It is often combined with other treatments, such as surgery, chemotherapy, or radiation therapy. Laser-induced interstitial thermotherapy (LITT), or interstitial laser photocoagulation, uses lasers to treat some cancers using hyperthermia, which uses heat to shrink tumors by damaging or killing cancer cells. Laser are more precise than surgery and cause less damage, pain, bleeding, swelling, and scarring. A disadvantage is surgeons must have specialized training. It may be more expensive than other treatments.","Cancer is a type of disease where cells grow out of control, divide and invade other tissues. In a person without cancer, cell division is under control. In most tissues, healthy cells divide in a controlled way and copy themselves to create new healthy cells. With cancer, this normal cell division goes out of control. Cells change their nature because mutations have occurred in their genes. All the daughter cells of cancer cells are also cancerous. Cancerous cells are responsible for growing more cancer cells in the body. If the abnormal cells do not invade other tissues or organs, but just divide and swell up their original tissue, this is not called ""cancer"". It is called a tumour. Tumours are usually not a threat to life because they can be cut out. However, some tumours occur in places where they cannot be cut out, and they can be fatal. Some brain tumors are of this type. The symptoms of cancer are caused by the cancerous cells invading other tissues. This is called metastasis. Metastasis is when cancer cells move through the bloodstream or lymphatic system. When this happens, a person's cancer can be spread to other places in the body. Eventually those other tissues cannot work as well, and the whole body begins to get worse, and may die. Cancer can affect anybody at any age. Most types of cancer are more likely to affect people as they get older. This is because as a person's DNA gets older, their DNA may become damaged, or damage that happened in the past may get worse. One type of cancer that is more common in young men, rather than older people, is testicular cancer (cancer of the testicles). Cancer is one of the biggest and most researched causes of death in developed countries. Studying cancer and its treatment is called oncology.  Causes  Cancer is one of the most common causes of death around the world. It causes about 16% (or one out of every six) of all deaths worldwide, according to the World Health Organization.Different types of cancer have different causes. Some things are known to cause cancer in a specific body part; other things are known to be able to cause many different types of cancer. For example, using tobacco (smoked or smokeless) can cause many types of cancers, such as lung, mouth, tongue, and throat cancers. Other things that are known to be able to cause cancer - or make a person more likely to get cancer - include: radiation including sunlight and X-rays in large or many doses, and exposure to radiation (for example in a nuclear power plant); chemicals and materials used in building and manufacturing (for example, asbestos and benzene); high-fat or low-fiber diets; air and water pollution; eating very little fruits and vegetables; obesity; not enough physical activity; drinking too much alcohol; and certain chemicals commonly used at home. Some cancers can also be caused by viruses. Many people who are exposed to these things do get cancer - but some do not.  Kinds  There are many different kinds of cancers. The most common cancers in the world are: breast cancer, lung cancer, colorectal cancer, prostate cancer and stomach cancer.  Treatment of cancer  There is no sure cure for cancer. It can only be cured if all of the cancerous cells are cut out or killed in place. This means that the earlier the cancer is treated, the better the chances are for a cure (because the cancer cells may not have had enough time to copy themselves and spread so much that the person cannot be cured). There are a few different types of treatments that may kill cancer cells. These treatments are: Radiotherapy (radiation therapy), which uses radiation to kill cancer cells Chemotherapy, which uses strong medications to kill cancer cells Surgery to take out part or all of a tumor. After surgery, many patients may need radiotherapy or chemotherapy to keep the tumor from growing again. Immunotherapy works by ""inducing, enhancing, or suppressing an immune response"".  Treating cancer is complicated  There are a few reasons why treating cancer is complicated. For example: Most things that kill cancer cells also kill normal, healthy cells. This can cause many side effects, like hair loss and vomiting. The body's immune system usually will not attack cancer cells, even though they could easily kill the body. This is because the cancer has actually become a part of the body by invading cells and tissues. So the immune system sees the cancer as part of the body it is trying to protect, not as a threat to be attacked. There are many different types of cancer, and each has its own symptoms and causes. Even with the same type of cancer, different people may have different symptoms, and may react to treatments differently; their cancer also may grow or spread at different speeds. Treatment has to be a good fit to both the type of cancer and the individual patient who has the cancer.Many, many people in many countries study cancer and work on finding treatments. There has been some good progress in finding treatments, and many kinds of cancers are treated with success. Along with looking for different medical treatments to treat cancer, some studies also look for things that people with cancer can do themselves to try to make themselves healthier. For example, one study showed that if a person with lymphedema (a swelling of the arm linked to breast cancer) lifts weights, he may be able to fight his cancer better than somebody who does not lift weights.  History  Cancer has been around for many thousands of years. Today, a lot of the medical terms used to describe cancer come from ancient Greek and Latin. For example, the Latinized Greek word carcinoma is used to describe a malignant tumor - a tumor made up of cancer cells. The Greeks also used the word ""karkinos"", which would be translated by Aulus Cornelius Celsus into the Latin word cancer. The prefix 'carcino' is still used in medical words like carcinoma and carcinogenic. A famous Greek doctor, Galen, helped create another word that is very important to medicine today by using the word ""onkos"" to describe all tumours. This is where the word oncology, the branch of medicine that deals with cancer, comes from.  Ancient history  Hippocrates (a very famous ancient doctor who is often called the father of modern medicine) named many kinds of cancer. He called benign tumours (tumors that are not made up of cancer cells) oncos. In Greek, onkos means 'swelling'. He called malignant tumours karkinos. This means crab or crayfish in Greek. He used this term because he thought that if a solid malignant tumor was cut into, its veins looked like a crab: ""the veins stretched on all sides as the animal the crab has its feet, whence it derives (gets) its name"". Hippocrates later added -oma (Greek for 'swelling') after the word 'carcinos'. This is how the word carcinoma came about. Because the ancient Greeks did not believe in opening up dead bodies to study them, Hippocrates was only able to describe and make drawings of tumors he saw from the outside of the body. He drew tumors that had been on the skin, nose, and breasts. Hippocrates and other doctors at that time treated people based on the humor theory. This theory said that there were four types of fluid in the body (black, yellow bile, blood, and phlegm). Doctors tried to figure out whether these four ""humors"" (or body fluids) were in balance. They would then use treatments like blood-letting (cutting the patient and letting him bleed so that he would lose blood); laxatives (giving the patient foods or herbs to make him go to the bathroom), and/or changing the patient's diet. The doctors thought that these treatments would work to get the patient's four humors back into the right balance. The humor theory treatment was popular until the 19th century (the 1800s), when cells were discovered. By this time, people had realized that cancer can happen anywhere in the body.  Early surgery  The oldest known document that talks about cancer was discovered in Egypt and is thought to be from about 1600 B.C. The document talks about using surgery to treat eight cases of ulcers of the breast. These were treated by cauterization - by burning them - using a tool called ""the fire drill"". The document also says about cancer, ""There is no treatment"".Another very early type of surgery used to treat cancer was written about in the 1020s. In The Canon of Medicine, Avicenna (Ibn Sina) said that treatment should involve cutting out all diseased tissue. This included the use of amputation (removing a part of the body completely) or removing veins that ran in the direction of the tumor. Avicenna also suggested that the area that had been treated should be cauterized (or burned) if needed.  The 16th and 17th centuries  In the 16th and 17th centuries (the 1500s and 1600s), doctors started to be allowed to dissect bodies (or cut them open after death) in order to figure out the cause of death. Around this time, there were many different ideas about what caused cancer. The German professor Wilhelm Fabry believed that breast cancer was caused by a clot of milk in the part of a woman's breast that produces milk. The Dutch professor Francois de la Boe Sylvius believed that all disease was caused by chemical processes. He thought that cancer, in particular, was caused by acidic lymph. Nicolaes Tulp, who lived at the same time as Sylvius, believed that cancer was a poison that slowly spreads and was contagious.A British surgeon named Percivall Pott was the first person to figure out one of the real causes of cancer. In 1775, he discovered that cancer of the scrotum was a common disease among chimney sweeps (people who cleaned out chimneys). Other doctors started studying this topic and coming up with other ideas about what causes cancer. Doctors then started working together and coming up with better ideas.  The 18th century  In the 18th century (the 1700s), many people started to use the microscope, and this made a big difference in helping doctors and scientists understand more about cancer. Using the microscope, scientists were able to see that the 'cancer poison' spread from one tumor through the lymph nodes to other sites (""metastasis""). This was first made clear by the English surgeon Campbell De Morgan, between 1871 and 1874.Before the 19th century (the 1800s), using surgery to treat cancer usually had bad results. Doctors did not understand how important hygiene (or keeping things clean) is for preventing disease, especially after surgery. Because things were not kept clean during or after surgery, patients often got infections and died. For example, one well-known Scottish surgeon, Alexander Monro, kept records and found that 58 patients out of every 60 who had surgery for breast tumors died within the next two years.  The 19th century  In the 19th century, surgical hygiene got better because of asepsis. Doctors realized that dirtiness and germs cause infections, so they started to keep things cleaner and do things to kill germs in order to prevent their patients from getting infections. It became more common for people to survive after having surgery. Surgical removal of the tumor (taking the tumor out of the body by doing surgery) became the first-choice treatment for cancer. For this kind of treatment to work, the surgeon doing the operation had to be very good at removing tumors. (This meant that even if people had the same kind of cancer, they could get very different results, with some getting good treatment that worked and others getting treatment that did not work, because of differences in how good different surgeons were.) In the late 1800s, doctors and scientists started to realize that the body is made up of many kinds of tissues, which in turn are made up of millions of cells. The discovery started the age of cellular pathology (studying cells to learn about diseases and figure out what is wrong with the body).  Discovery of radiation  In the 1890s, French scientists discovered radioactive decay. Radiation therapy became the first cancer treatment that worked and did not involve surgery. It required a new multi-disciplinary approach to cancer treatment (people doing different jobs were working together to treat patients). The surgeon was no longer working by himself - he worked together with hospital radiologists (people who gave and read X-rays) to help patients. This team approach meant changes in how they worked. The different people on the team had to communicate with each other and work together, which they were not used to doing. It also meant that treatment had to be done in a hospital rather than at the patient's home. Because of this, patients' information had to be put together into files kept at the hospital (called ""medical records""). Because this information was now being kept and written down, scientists were able to do the first statistical patient studies using numbers to study questions like how many people who have a certain type of cancer or get a certain treatment survive.  The 20th century  Another important step forward in understanding cancer happened in 1926, when Janet Lane-Claypon published a paper on cancer epidemiology. (Epidemiology is a field of study which looks at how common a disease is, what patterns the disease takes in different kinds of people, and what this means for understanding and treating the disease.) This historic paper was a comparative study, which tries to find out what causes a disease by looking at a group of people who have the disease and figuring out how they are different from another group that does not have the disease. Lane-Clayton's study looked at 1000 people who all had the same background and lifestyle (or way of living): 500 people with breast cancer and 500 control patients (people without breast cancer). These people were the same in many ways, but some got breast cancer and some did not. To figure out what might be causing certain people to get breast cancer, the study looked at what was different about these people when they were compared to (or looked at alongside) the people who did not get cancer. Lane-Clayton's study was published by the British Ministry of Health. Her work on cancer epidemiology was continued by Richard Doll and Austin Bradford Hill. They used the same ways of studying cancer as Lane-Clayton, but they looked at a different kind of cancer: lung cancer. In 1956, they published their results in a paper called ""Lung Cancer and Other Causes of Death In Relation to Smoking. A Second Report on the Mortality of British Doctors"" (also called the British doctors study). Later, Richard Doll left the London Medical Research Center (MRC), and started the Oxford unit for Cancer epidemiology in 1968. By using computers, this unit was able to do something new and very important: it brought together large amounts of cancer data (pieces of information about cancer). This way of studying cancer is very important to cancer epidemiology today, and it has also been very important in shaping what we now know about cancer and what the rules and laws about the disease and public health are today. Over the past 50 years, many different people have done a lot of work to collect data from different doctors, hospitals, areas, states, and even countries. This data is used to study whether different kinds of cancer are more or less common in different areas, environments (for example, in big cities compared to the countryside), or cultures. This helps people who study cancer to figure out what makes people more or less likely to get different kinds of cancer.  Effects of World War II  Before World War II, doctors and hospitals were getting better at collecting (or getting and keeping) data about their patients who had cancer, but it was rare for this data to be shared with other doctors or hospitals. This changed after WWII, when medical research centers found out that different countries had very different number of cases of cancer. Because of this, many countries created national public health organizations (which studied public health issues in an entire country). These national public health organizations began to bring together health data from many different doctors and hospitals. This helped them figure out some of the reasons why cancer was so much more common in certain places. For example, in Japan, people studying cancer found out that people who had survived the atomic bombings of Hiroshima and Nagasaki had bone marrow that was completely destroyed. This helped them realize that diseased bone marrow could also be destroyed with radiation, which was a very important step in figuring out that leukemia (a blood cancer) can be treated with bone marrow transplants. Since World War II, scientists have kept finding better cancer treatments. However, there are some things that still need to get better. For example, while there are good treatments for many kinds of cancer, there are still no treatments for certain kinds of cancer, or for some cancers once they progress (or get worse) to a certain stage of the disease. Also, the cancer treatments that do exist are not all standardized (there is not one agreed-upon way of giving every treatment which is used each time the treatment is given). Cancer treatments are also not available everywhere in the world. People need to keep studying cancer epidemiology and forming international partnerships (where different countries work together) to find cures and make cancer treatments available everywhere.  Other websites  What is Cancer? (Simple English) - American Cancer Society  References "
"The Epstein–Barr virus (EBV), formally called Human gammaherpesvirus 4, is one of the nine known human herpesvirus types in the herpes family, and is one of the most common viruses in humans. EBV is a double-stranded DNA virus.The virus causes infectious mononucleosis (""mono"" or ""glandular fever""). It is also associated with various non-malignant, premalignant, and malignant Epstein–Barr virus-associated lymphoproliferative diseases such as Burkitt lymphoma, hemophagocytic lymphohistiocytosis, and Hodgkin's lymphoma; non-lymphoid malignancies such as gastric cancer and nasopharyngeal carcinoma; and conditions associated with human immunodeficiency virus such as hairy leukoplakia and central nervous system lymphomas. The virus is also associated with the childhood disorders of Alice in Wonderland syndrome and acute cerebellar ataxia and, by some evidence, higher risks of developing certain autoimmune diseases, especially dermatomyositis, systemic lupus erythematosus, rheumatoid arthritis, and Sjögren's syndrome. About 200,000 cancer cases globally per year are thought to be attributable to EBV. In 2022, a large study (population of 10 million over 20 years) suggested EBV as the leading cause of multiple sclerosis, with a recent EBV infection causing a 32-fold increase in the risk of developing multiple sclerosis.Infection with EBV occurs by the oral transfer of saliva and genital secretions. Most people become infected with EBV and gain adaptive immunity. In the United States, about half of all five-year-old children and about 90% of adults have evidence of previous infection. Infants become susceptible to EBV as soon as maternal antibody protection disappears. Many children become infected with EBV, and these infections usually cause no symptoms or are indistinguishable from the other mild, brief illnesses of childhood. In the United States and other developed countries, many people are not infected with EBV in their childhood years. When infection with EBV occurs during adolescence or young adulthood, it causes infectious mononucleosis 35 to 50% of the time.EBV infects B cells of the immune system and epithelial cells. Once EBV's initial lytic infection is brought under control, EBV latency persists in the individual's memory B cells for the rest of their life.  Virology   Structure and genome  The virus is about 122–180 nm in diameter and is composed of a double helix of deoxyribonucleic acid (DNA) which contains about 172,000 base pairs encoding 85 genes. The DNA is surrounded by a protein nucleocapsid, which is surrounded by a tegument made of protein, which in turn is surrounded by an envelope containing both lipids and surface projections of glycoproteins, which are essential to infection of the host cell. In July 2020, a team of researchers reported the first complete atomic model of the nucleocapsid of the virus. This ""first complete atomic model [includes] the icosahedral capsid, the capsid-associated tegument complex (CATC) and the dodecameric portal--the viral genome translocation apparatus.""  Tropism  The term viral tropism refers to which cell types that EBV infects. EBV can infect different cell types, including B cells and epithelial cells.The viral three-part glycoprotein complexes of gHgL gp42 mediate B cell membrane fusion; although the two-part complexes of gHgL mediate epithelial cell membrane fusion. EBV that are made in the B cells have low numbers of gHgLgp42 complexes, because these three-part complexes interact with Human-leukocyte-antigen class II molecules present in B cells in the endoplasmic reticulum and are degraded. In contrast, EBV from epithelial cells are rich in the three-part complexes because these cells do not normally contain HLA class II molecules. As a consequence, EBV made from B cells are more infectious to epithelial cells, and EBV made from epithelial cells are more infectious to B cells. Viruses lacking the gp42 portion are able to bind to human B cells, but unable to infect.  Replication cycle   Entry to the cell  EBV can infect both B cells and epithelial cells. The mechanisms for entering these two cells are different. To enter B cells, viral glycoprotein gp350 binds to cellular receptor CD21 (also known as CR2). Then, viral glycoprotein gp42 interacts with cellular MHC class II molecules. This triggers fusion of the viral envelope with the cell membrane, allowing EBV to enter the B cell. Human CD35, also known as complement receptor 1 (CR1), is an additional attachment factor for gp350/220, and can provide a route for entry of EBV into CD21-negative cells, including immature B-cells. EBV infection downregulates expression of CD35.To enter epithelial cells, viral protein BMRF-2 interacts with cellular β1 integrins. Then, viral protein gH/gL interacts with cellular αvβ6/αvβ8 integrins. This triggers fusion of the viral envelope with the epithelial cell membrane, allowing EBV to enter the epithelial cell. Unlike B-cell entry, epithelial-cell entry is actually impeded by viral glycoprotein gp42.Once EBV enters the cell, the viral capsid dissolves and the viral genome is transported to the cell nucleus.  Lytic replication  The lytic cycle, or productive infection, results in the production of infectious virions. EBV can undergo lytic replication in both B cells and epithelial cells. In B cells, lytic replication normally only takes place after reactivation from latency. In epithelial cells, lytic replication often directly follows viral entry.For lytic replication to occur, the viral genome must be linear. The latent EBV genome is circular, so it must linearize in the process of lytic reactivation. During lytic replication, viral DNA polymerase is responsible for copying the viral genome. This contrasts with latency, in which host-cell DNA polymerase copies the viral genome.Lytic gene products are produced in three consecutive stages: immediate-early, early, and late. Immediate-early lytic gene products act as transactivators, enhancing the expression of later lytic genes. Immediate-early lytic gene products include BZLF1 (also known as Zta, EB1, associated with its product gene ZEBRA) and BRLF1 (associated with its product gene Rta). Early lytic gene products have many more functions, such as replication, metabolism, and blockade of antigen processing. Early lytic gene products include BNLF2. Finally, late lytic gene products tend to be proteins with structural roles, such as VCA, which forms the viral capsid. Other late lytic gene products, such as BCRF1, help EBV evade the immune system.EGCG, a polyphenol in green tea, has shown in a study to inhibit EBV spontaneous lytic infection at the DNA, gene transcription, and protein levels in a time- and dose-dependent manner; the expression of EBV lytic genes Zta, Rta, and early antigen complex EA-D (induced by Rta), however, the highly stable EBNA-1 gene found across all stages of EBV infection is unaffected. Specific inhibitors (to the pathways) suggest that Ras/MEK/MAPK pathway contributes to EBV lytic infection though BZLF1 and PI3-K pathway through BRLF1, the latter completely abrogating the ability of a BRLF1 adenovirus vector to induce the lytic form of EBV infection. Additionally, the activation of some genes but not others is being studied to determine just how to induce immune destruction of latently infected B-cells by use of either TPA or sodium butyrate.  Latency  Unlike lytic replication, latency does not result in production of virions. Instead, the EBV genome circular DNA resides in the cell nucleus as an episome and is copied by cellular DNA polymerase. Epigenetic changes such as DNA methylation and cellular chromatin constituents, suppress the majority of the viral genes in latently infected cells. Only a portion of EBV's genes are expressed, which support the latent state of the virus. Latent EBV expresses its genes in one of three patterns, known as latency programs. EBV can latently persist within B cells and epithelial cells, but different latency programs are possible in the two types of cell.EBV can exhibit one of three latency programs: Latency I, Latency II, or Latency III. Each latency program leads to the production of a limited, distinct set of viral proteins and viral RNAs. Also, a program is postulated in which all viral protein expression is shut off (Latency 0).Within B cells, all three latency programs are possible. EBV latency within B cells usually progresses from Latency III to Latency II to Latency I. Each stage of latency uniquely influences B cell behavior. Upon infecting a resting naive B cell, EBV enters Latency III. The set of proteins and RNAs produced in Latency III transforms the B cell into a proliferating blast (also known as B cell activation). Later, the virus restricts its gene expression and enters Latency II. The more limited set of proteins and RNAs produced in Latency II induces the B cell to differentiate into a memory B cell. Finally, EBV restricts gene expression even further and enters Latency I. Expression of EBNA-1 allows the EBV genome to replicate when the memory B cell divides.Within epithelial cells, only Latency II is possible.In primary infection, EBV replicates in oropharyngeal epithelial cells and establishes Latency III, II, and I infections in B-lymphocytes. EBV latent infection of B-lymphocytes is necessary for virus persistence, subsequent replication in epithelial cells, and release of infectious virus into saliva. EBV Latency III and II infections of B-lymphocytes, Latency II infection of oral epithelial cells, and Latency II infection of NK- or T-cell can result in malignancies, marked by uniform EBV genome presence and gene expression.  Reactivation  Latent EBV in B cells can be reactivated to switch to lytic replication. This is known to happen in vivo, but what triggers it is not known precisely. In vitro, latent EBV in B cells can be reactivated by stimulating the B cell receptor, so it is likely reactivation in vivo takes place after latently infected B cells respond to unrelated infections.  Transformation of B-lymphocytes  When EBV infects B cells in vitro, lymphoblastoid cell lines eventually emerge that are capable of indefinite growth. The growth transformation of these cell lines is the consequence of viral protein expression.EBNA-2, EBNA-3C, and LMP-1 are essential for transformation, whereas EBNA-LP and the EBERs are not.Following natural infection with EBV, the virus is thought to execute some or all of its repertoire of gene expression programs to establish a persistent infection. Given the initial absence of host immunity, the lytic cycle produces large numbers of virions to infect other (presumably) B-lymphocytes within the host. The latent programs reprogram and subvert infected B-lymphocytes to proliferate and bring infected cells to the sites at which the virus presumably persists. Eventually, when host immunity develops, the virus persists by turning off most (or possibly all) of its genes and only occasionally reactivates and produces progeny virions. A balance is eventually struck between occasional viral reactivation and host immune surveillance removing cells that activate viral gene expression. The manipulation of the human body's epigenetics by EBV can alter the genome of the cell to leave oncogenic phenotypes. As a result the modification by the EBV increases the hosts likelihood of developing EBV related cancer. EBV related cancers are unique in that they are frequent to making epigenetic changes but are less likely to mutate.The site of persistence of EBV may be bone marrow. EBV-positive patients who have had their own bone marrow replaced with bone marrow from an EBV-negative donor are found to be EBV-negative after transplantation.  Latent antigens  All EBV nuclear proteins are produced by alternative splicing of a transcript starting at either the Cp or Wp promoters at the left end of the genome (in the conventional nomenclature). The genes are ordered EBNA-LP/EBNA-2/EBNA-3A/EBNA-3B/EBNA-3C/EBNA-1 within the genome. The initiation codon of the EBNA-LP coding region is created by an alternate splice of the nuclear protein transcript. In the absence of this initiation codon, EBNA-2/EBNA-3A/EBNA-3B/EBNA-3C/EBNA-1 will be expressed depending on which of these genes is alternatively spliced into the transcript.  Protein/genes   Subtypes of EBV  EBV can be divided into two major types, EBV type 1 and EBV type 2. These two subtypes have different EBNA-3 genes. As a result, the two subtypes differ in their transforming capabilities and reactivation ability. Type 1 is dominant throughout most of the world, but the two types are equally prevalent in Africa. One can distinguish EBV type 1 from EBV type 2 by cutting the viral genome with a restriction enzyme and comparing the resulting digestion patterns by gel electrophoresis.  Detection  Epstein–Barr virus-encoded small RNAs (EBERs) are by far the most abundant EBV products transcribed in cells infected by EBV. They are commonly used as targets for the detection of EBV in histological tissues.  Role in disease  See also Infectious mononucleosis and the other diseases listed in this sectionEBV causes infectious mononucleosis. Children infected with EBV have few symptoms or can appear asymptomatic, but when infection is delayed to adolescence or adulthood, it can cause fatigue, fever, inflamed throat, swollen lymph nodes in the neck, enlarged spleen, swollen liver, or rash. Post-infectious chronic fatigue syndrome has also been associated with EBV infection.EBV has also been implicated in several other diseases, including Burkitt's lymphoma, hemophagocytic lymphohistiocytosis, Hodgkin's lymphoma, stomach cancer, nasopharyngeal carcinoma, multiple sclerosis, and lymphomatoid granulomatosis.Specifically, EBV infected B-cells have been shown to reside within the brain lesions of multiple sclerosis patients, and a 2022 study of 10 million soldiers' historical blood samples showed that ""Individuals who were not infected with the Epstein-Barr virus virtually never get multiple sclerosis. It's only after Epstein-Barr virus infection that the risk of multiple sclerosis jumps up by over 30-fold,"" and that only EBV of many infections had such a clear connection with the disease.Additional diseases that have been linked to EBV include Gianotti–Crosti syndrome, erythema multiforme, acute genital ulcers, and oral hairy leukoplakia. The viral infection is also associated with, and often contributes to the development of, a wide range of non-malignant lymphoproliferative diseases such as severe hypersensitivity mosquito bite allergy reactions, Epstein-Barr virus-positive mucocutaneous ulcers, and hydroa vacciniforme as well as malignant lymphoproliferative diseases such as Epstein–Barr virus-positive Burkitt lymphoma, Epstein–Barr virus-positive Hodgkin lymphoma, and primary effusion lymphoma.The Epstein–Barr virus has been implicated in disorders related to alpha-synuclein aggregation (e.g. Parkinson's disease, dementia with Lewy bodies, and multiple system atrophy).It has been found that EBNA1 may induce chromosomal breakage in the 11th chromosome, specifically in the 11q23 region between the FAM55D gene and FAM55B, which EBNA-1 appears to have a high affinity for due to its DNA-binding domain having an interest in a specific palindromic repeat in this section of the genome. While the cause and exact mechanism for this is unknown, the byproduct results in errors and breakage of the chromosomal structure as cells stemming from the line of the tainted genome undergo mitosis. Since genes in this area have been implicated in leukemia and is home to a tumor suppressor gene that is modified or not present in most tumor gene expression, it's been hypothesized that breakage in this area is the main culprit behind the cancers that EBV increases the chance of. The breakage is also dose-dependent, a person with a latent infection will have less breakage than a person with a novel or reactivated infection since EBNA1 levels in the nucleus and nucleolus are higher during active attack of the body because of the constant replication and take-over of cells in the body.  History  The Epstein–Barr virus was named after Michael Anthony Epstein, and Yvonne Barr, who discovered the virus together with Bert Achong. In 1961, Epstein, a pathologist and expert electron microscopist, attended a lecture on ""The Commonest Children's Cancer in Tropical Africa—A Hitherto Unrecognised Syndrome"" by Denis Parsons Burkitt, a surgeon practicing in Uganda, in which Burkitt described the ""endemic variant"" (pediatric form) of the disease that bears his name. In 1963, a specimen was sent from Uganda to Middlesex Hospital to be cultured. Virus particles were identified in the cultured cells, and the results were published in The Lancet in 1964 by Epstein, Achong, and Barr. Cell lines were sent to Werner and Gertrude Henle at the Children's Hospital of Philadelphia who developed serological markers. In 1967, a technician in their laboratory developed mononucleosis and they were able to compare a stored serum sample, showing that antibodies to the virus developed. In 1968, they discovered that EBV can directly immortalize B cells after infection, mimicking some forms of EBV-related infections, and confirmed the link between the virus and infectious mononucleosis.  Research  As a relatively complex virus, EBV is not yet fully understood. Laboratories around the world continue to study the virus and develop new ways to treat the diseases it causes. One popular way of studying EBV in vitro is to use bacterial artificial chromosomes. Epstein–Barr virus can be maintained and manipulated in the laboratory in continual latency (a property shared with Kaposi's sarcoma-associated herpesvirus, another of the eight human herpesviruses). Although many viruses are assumed to have this property during infection of their natural hosts, there is not an easily managed system for studying this part of the viral lifecycle. Genomic studies of EBV have been able to explore lytic reactivation and regulation of the latent viral episome.Although under active research, an Epstein–Barr virus vaccine is not yet available. The development of an effective vaccine could prevent up to 200,000 cancers globally per year. The absence of effective animal models is an obstacle to development of prophylactic and therapeutic vaccines against EBV.Like other human herpesviruses Epstein-Barr might allow eradication via a course of the pro-drug valaciclovir, but further research is needed to determine if eradication is actually achievable. Antiviral agents act by inhibiting viral DNA replication, but there is little evidence that they are effective against Epstein–Barr virus. Moreover, they are expensive, risk causing resistance to antiviral agents, and (in 1% to 10% of cases) can cause unpleasant side effects.  See also  Epstein–Barr virus infection Epstein–Barr virus-associated lymphoproliferative diseases James Corson Niederman, the physician who proved how the Epstein–Barr virus is transmitted in infectious mononucleosis  References   Further reading  Zhang S (3 March 2022). ""The Puzzling Virus That Infects Almost Everyone"". The Atlantic.  External links  Media related to Epstein-Barr virus at Wikimedia Commons Data related to Epstein–Barr virus at Wikispecies Transcriptome and epigenome of EBV Archived 18 January 2019 at the Wayback Machine","The Epstein–Barr virus (EBV), also called human herpesvirus 4 (HHV-4), is one of eight viruses in the herpes family. It is one of the most common viruses in humans. EBV is best known as the cause of infectious mononucleosis (glandular fever). It is also associated with some forms of cancer, such as Hodgkin's lymphoma, and conditions associated with human immunodeficiency virus (HIV). EBV may be associated with a higher risk of certain autoimmune diseases. Some 200,000 cancer cases per year may be caused by (or associated with) EBV.Infection with EBV occurs by the transfer by mouth (oral transfer) of saliva and genital secretions.Most people become infected with EBV and gain adaptive immunity. In the United States, about half of all five-year-old children and about 90 percent of adults have evidence of previous infection. Infants become susceptible to EBV as soon as maternal antibody protection disappears. Many children become infected with EBV, and these infections usually cause no symptoms or are just mild, brief illnesses of childhood. In the United States and other developed countries, many people are not infected with EBV in their childhood years. When infection with EBV occurs during adolescence, it causes glandular fever 35 to 50 percent of the time.EBV infects B cells of the immune system and epithelial cells. Once EBV's initial infection is brought under control, non-active EBV stays in the person's B cells for the rest of their life.  References "
"Speech is a human vocal communication using language. Each language uses phonetic combinations of vowel and consonant sounds that form the sound of its words (that is, all English words sound different from all French words, even if they are the same word, e.g., ""role"" or ""hotel""), and using those words in their semantic character as words in the lexicon of a language according to the syntactic constraints that govern lexical words' function in a sentence. In speaking, speakers perform many different intentional speech acts, e.g., informing, declaring, asking, persuading, directing, and can use enunciation, intonation, degrees of loudness, tempo, and other non-representational or paralinguistic aspects of vocalization to convey meaning. In their speech, speakers also unintentionally communicate many aspects of their social position such as sex, age, place of origin (through accent), physical states (alertness and sleepiness, vigor or weakness, health or illness), psychological states (emotions or moods), physico-psychological states (sobriety or drunkenness, normal consciousness and trance states), education or experience, and the like. Although people ordinarily use speech in dealing with other persons (or animals), when people swear they do not always mean to communicate anything to anyone, and sometimes in expressing urgent emotions or desires they use speech as a quasi-magical cause, as when they encourage a player in a game to do or warn them not to do something. There are also many situations in which people engage in solitary speech. People talk to themselves sometimes in acts that are a development of what some psychologists (e.g., Lev Vygotsky) have maintained is the use of silent speech in an interior monologue to vivify and organize cognition, sometimes in the momentary adoption of a dual persona as self addressing self as though addressing another person. Solo speech can be used to memorize or to test one's memorization of things, and in prayer or in meditation (e.g., the use of a mantra). Researchers study many different aspects of speech: speech production and speech perception of the sounds used in a language, speech repetition, speech errors, the ability to map heard spoken words onto the vocalizations needed to recreate them, which plays a key role in children's enlargement of their vocabulary, and what different areas of the human brain, such as Broca's area and Wernicke's area, underlie speech. Speech is the subject of study for linguistics, cognitive science, communication studies, psychology, computer science, speech pathology, otolaryngology, and acoustics. Speech compares with written language, which may differ in its vocabulary, syntax, and phonetics from the spoken language, a situation called diglossia. The evolutionary origins of speech are unknown and subject to much debate and speculation. While animals also communicate using vocalizations, and trained apes such as Washoe and Kanzi can use simple sign language, no animals' vocalizations are articulated phonemically and syntactically, and do not constitute speech.  Evolution  Although related to the more general problem of the origin of language, the evolution of distinctively human speech capacities has become a distinct and in many ways separate area of scientific research. The topic is a separate one because language is not necessarily spoken: it can equally be written or signed. Speech is in this sense optional, although it is the default modality for language. Monkeys, non-human apes and humans, like many other animals, have evolved specialised mechanisms for producing sound for purposes of social communication. On the other hand, no monkey or ape uses its tongue for such purposes. The human species' unprecedented use of the tongue, lips and other moveable parts seems to place speech in a quite separate category, making its evolutionary emergence an intriguing theoretical challenge in the eyes of many scholars.Determining the timeline of human speech evolution is made additionally challenging by the lack of data in the fossil record. The human vocal tract does not fossilize, and indirect evidence of vocal tract changes in hominid fossils has proven inconclusive.  Production  Speech production is an unconscious multi-step process by which thoughts are generated into spoken utterances. Production involves the unconscious mind selecting appropriate words and the appropriate form of those words from the lexicon and morphology, and the organization of those words through the syntax. Then, the phonetic properties of the words are retrieved and the sentence is articulated through the articulations associated with those phonetic properties.In linguistics, articulatory phonetics is the study of how the tongue, lips, jaw, vocal cords, and other speech organs are used to make sounds. Speech sounds are categorized by manner of articulation and place of articulation. Place of articulation refers to where in the neck or mouth the airstream is constricted. Manner of articulation refers to the manner in which the speech organs interact, such as how closely the air is restricted, what form of airstream is used (e.g. pulmonic, implosive, ejectives, and clicks), whether or not the vocal cords are vibrating, and whether the nasal cavity is opened to the airstream. The concept is primarily used for the production of consonants, but can be used for vowels in qualities such as voicing and nasalization. For any place of articulation, there may be several manners of articulation, and therefore several homorganic consonants. Normal human speech is pulmonic, produced with pressure from the lungs, which creates phonation in the glottis in the larynx, which is then modified by the vocal tract and mouth into different vowels and consonants. However humans can pronounce words without the use of the lungs and glottis in alaryngeal speech, of which there are three types: esophageal speech, pharyngeal speech and buccal speech (better known as Donald Duck talk).  Errors  Speech production is a complex activity, and as a consequence errors are common, especially in children. Speech errors come in many forms and are used to provide evidence to support hypotheses about the nature of speech. As a result, speech errors are often used in the construction of models for language production and child language acquisition. For example, the fact that children often make the error of over-regularizing the -ed past tense suffix in English (e.g. saying 'singed' instead of 'sang') shows that the regular forms are acquired earlier. Speech errors associated with certain kinds of aphasia have been used to map certain components of speech onto the brain and see the relation between different aspects of production; for example, the difficulty of expressive aphasia patients in producing regular past-tense verbs, but not irregulars like 'sing-sang' has been used to demonstrate that regular inflected forms of a word are not individually stored in the lexicon, but produced from affixation to the base form.  Perception  Speech perception refers to the processes by which humans can interpret and understand the sounds used in language. The study of speech perception is closely linked to the fields of phonetics and phonology in linguistics and cognitive psychology and perception in psychology. Research in speech perception seeks to understand how listeners recognize speech sounds and use this information to understand spoken language. Research into speech perception also has applications in building computer systems that can recognize speech, as well as improving speech recognition for hearing- and language-impaired listeners.Speech perception is categorical, in that people put the sounds they hear into categories rather than perceiving them as a spectrum. People are more likely to be able to hear differences in sounds across categorical boundaries than within them. A good example of this is voice onset time (VOT), one aspect of the phonetic production of consonant sounds. For example, Hebrew speakers, who distinguish voiced /b/ from voiceless /p/, will more easily detect a change in VOT from -10 ( perceived as /b/ ) to 0 ( perceived as /p/ ) than a change in VOT from +10 to +20, or -10 to -20, despite this being an equally large change on the VOT spectrum.  Development  Most human children develop proto-speech babbling behaviors when they are four to six months old. Most will begin saying their first words at some point during the first year of life. Typical children progress through two or three word phrases before they are three to short sentences by four years of age.  Repetition  In speech repetition, speech being heard is quickly turned from sensory input into motor instructions needed for its immediate or delayed vocal imitation (in phonological memory). This type of mapping plays a key role in enabling children to expand their spoken vocabulary. Masur (1995) found that how often children repeat novel words versus those they already have in their lexicon is related to the size of their lexicon later on, with young children who repeat more novel words having a larger lexicon later in development. Speech repetition could help facilitate the acquisition of this larger lexicon.  Problems  There are several organic and psychological factors that can affect speech. Among these are: Diseases and disorders of the lungs or the vocal cords, including paralysis, respiratory infections (bronchitis), vocal fold nodules and cancers of the lungs and throat. Diseases and disorders of the brain, including alogia, aphasias, dysarthria, dystonia and speech processing disorders, where impaired motor planning, nerve transmission, phonological processing or perception of the message (as opposed to the actual sound) leads to poor speech production. Hearing problems, such as otitis media with effusion, and listening problems, auditory processing disorders, can lead to phonological problems. In addition to dysphasia, anomia and auditory processing disorder impede the quality of auditory perception, and therefore, expression. Those who are deaf or hard of hearing may be considered to fall into this category. Articulatory problems, such as slurred speech, stuttering, lisping, cleft palate, ataxia, or nerve damage leading to problems in articulation. Tourette syndrome and tics can also affect speech. Various congenital and acquired tongue diseases can affect speech as can motor neuron disease. Psychiatric disorders have been shown to change speech acoustic features, where for instance, fundamental frequency of voice (perceived as pitch) tends to be significantly lower in major depressive disorder than in healthy controls. Therefore, speech is being investigated as a potential biomarker for mental health disorders.Speech and language disorders can also result from stroke, brain injury, hearing loss, developmental delay, a cleft palate, cerebral palsy, or emotional issues.  Treatment  Speech-related diseases, disorders, and conditions can be treated by a speech-language pathologist (SLP) or speech therapist. SLPs assess levels of speech needs, make diagnoses based on the assessments, and then treat the diagnoses or address the needs.  Brain physiology   Classical model  The classical or Wernicke-Geschwind model of the language system in the brain focuses on Broca's area in the inferior prefrontal cortex, and Wernicke's area in the posterior superior temporal gyrus on the dominant hemisphere of the brain (typically the left hemisphere for language). In this model, a linguistic auditory signal is first sent from the auditory cortex to Wernicke's area. The lexicon is accessed in Wernicke's area, and these words are sent via the arcuate fasciculus to Broca's area, where morphology, syntax, and instructions for articulation are generated. This is then sent from Broca's area to the motor cortex for articulation.Paul Broca identified an approximate region of the brain in 1861 which, when damaged in two of his patients, caused severe deficits in speech production, where his patients were unable to speak beyond a few monosyllabic words. This deficit, known as Broca's or expressive aphasia, is characterized by difficulty in speech production where speech is slow and labored, function words are absent, and syntax is severely impaired, as in telegraphic speech. In expressive aphasia, speech comprehension is generally less affected except in the comprehension of grammatically complex sentences. Wernicke's area is named after Carl Wernicke, who in 1874 proposed a connection between damage to the posterior area of the left superior temporal gyrus and aphasia, as he noted that not all aphasic patients had had damage to the prefrontal cortex. Damage to Wernicke's area produces Wernicke's or receptive aphasia, which is characterized by relatively normal syntax and prosody but severe impairment in lexical access, resulting in poor comprehension and nonsensical or jargon speech.  Modern research  Modern models of the neurological systems behind linguistic comprehension and production recognize the importance of Broca's and Wernicke's areas, but are not limited to them nor solely to the left hemisphere. Instead, multiple streams are involved in speech production and comprehension. Damage to the left lateral sulcus has been connected with difficulty in processing and producing morphology and syntax, while lexical access and comprehension of irregular forms (e.g. eat-ate) remain unaffected. Moreover, the circuits involved in human speech comprehension dynamically adapt with learning, for example, by becoming more efficient in terms of processing time when listening to familiar messages such as learned verses.  Animal communication  Some non-human animals can produce sounds or gestures resembling those of a human language. Several species or groups of animals have developed forms of communication which superficially resemble verbal language, however, these usually are not considered a language because they lack one or more of the defining characteristics, e.g. grammar, syntax, recursion, and displacement. Researchers have been successful in teaching some animals to make gestures similar to sign language, although whether this should be considered a language has been disputed.  See also  FOXP2 Freedom of speech Imagined speech Index of linguistics articles List of language disorders Spatial hearing loss Speechwriter Talking birds Vocology Public speaking  References   Further reading  (in French) Fitzpatrick, Élizabeth M. Apprendre à écouter et à parler. University of Ottawa Press, 2013. Available at Project MUSE.  External links  Speaking captured by real-time MRI, YouTube","For 'speech', meaning a talk, see Public speakingSpeech is when spoken language is used to communicate. Only humans have language. Animals do not have speech, but some can communicate with each other by using sounds and gestures. Speech is made by sounds vibrating the vocal folds. Sounds through the voice box is shaped by the jaw, tongue, teeth, palate, lips, and nose. To make speech a person has to be able to: choose speech sounds put them into a sequence produce sound in the voice box use the lips, tongue, teeth, nose and palate to shape the soundsDifficulties can happen at any stage of this four-stage process. A speech and language therapist can help work out the stage of the sequence that has difficulties and give therapy.Effective speech includes the following elements – fluency, flexibility, accuracy, and comprehensibility. Fluency is the ability to communicate an intended message, or affect the listener in the way that is intended by the speaker.Flexibility is the ability to adjust the message according to the responses of the listener. It also involves choosing words and expressions which will be understood by the listener(s). Compare with Cross-cultural communication.Accuracy is the use of proper grammar in spoken language.Comprehensibility is the ability to be understood by others. There are three components of sound which influence one’s comprehensibility:Pronunciation: saying the sounds of words correctly; Intonation: applying proper stress and rhythm while speaking; and Enunciation: speaking clearly at an appropriate pace and volume.  References "
"Multiple sclerosis (MS) is the most common demyelinating disease, in which the insulating covers of nerve cells in the brain and spinal cord are damaged. This damage disrupts the ability of parts of the nervous system to transmit signals, resulting in a range of signs and symptoms, including physical, mental, and sometimes psychiatric problems. Specific symptoms can include double vision, visual loss, muscle weakness, and trouble with sensation or coordination. MS takes several forms, with new symptoms either occurring in isolated attacks (relapsing forms) or building up over time (progressive forms). In the relapsing forms of MS, between attacks, symptoms may disappear completely, although some permanent neurological problems often remain, especially as the disease advances.While the cause is unclear, the underlying mechanism is thought to be either destruction by the immune system or failure of the myelin-producing cells. Proposed causes for this include genetics and environmental factors, such as viral infections. MS is usually diagnosed based on the presenting signs and symptoms and the results of supporting medical tests.No cure for multiple sclerosis is known. Treatments attempt to improve function after an attack and prevent new attacks. Physical therapy and occupational therapy can help with people's ability to function. Many people pursue alternative treatments, despite a lack of evidence of benefit. The long-term outcome is difficult to predict; better outcomes are more often seen in women, those who develop the disease early in life, those with a relapsing course, and those who initially experienced few attacks.Multiple sclerosis is the most common immune-mediated disorder affecting the central nervous system. Nearly one million people have MS in the United States in 2022, and in 2020, about 2.8 million people were affected globally, with rates varying widely in different regions and among different populations. The disease usually begins between the ages of 20 and 50 and is twice as common in women as in men. MS was first described in 1868 by French neurologist Jean-Martin Charcot. The name ""multiple sclerosis"" is short for multiple cerebro-spinal sclerosis, which refers to the numerous glial scars (or sclerae – essentially plaques or lesions) that develop on the white matter of the brain and spinal cord.  Signs and symptoms  A person with MS can have almost any neurological symptom or sign, with autonomic, visual, motor, and sensory problems being the most common. The specific symptoms are determined by the locations of the lesions within the nervous system, and may include loss of sensitivity or changes in sensation, such as tingling, pins and needles, or numbness; muscle weakness, blurred vision, pronounced reflexes, muscle spasms, difficulty in moving, difficulties with coordination, and balance (ataxia); problems with speech or swallowing, visual problems (nystagmus, optic neuritis, or double vision), feeling tired, acute or chronic pain; and bladder and bowel difficulties (such as neurogenic bladder), among others. When multiple sclerosis is more advanced, walking difficulties can occur and the risk of falling increases.Difficulties thinking and emotional problems such as depression or unstable mood are also common. The primary deficit in cognitive function that people with MS experience is slowed information-processing speed, with memory also commonly affected, and executive function less commonly. Intelligence, language, and semantic memory are usually preserved, and the level of cognitive impairment varies considerably between people with MS.Uhthoff's phenomenon, a worsening of symptoms due to exposure to higher-than-usual temperatures, and Lhermitte's sign, an electrical sensation that runs down the back when bending the neck, are particularly characteristic of MS. The main measure of disability and severity is the expanded disability status scale (EDSS), with other measures such as the multiple sclerosis functional composite being increasingly used in research. EDSS is also correlated with falls in people with MS. While it is a popular measure, EDSS has been criticized for some of its limitations, such as relying too much on walking.The condition begins in 85% of cases as a clinically isolated syndrome (CIS) over a number of days with 45% having motor or sensory problems, 20% having optic neuritis, and 10% having symptoms related to brainstem dysfunction, while the remaining 25% have more than one of the previous difficulties. The course of symptoms occurs in two main patterns initially: either as episodes of sudden worsening that last a few days to months (called relapses, exacerbations, bouts, attacks, or flare-ups) followed by improvement (85% of cases) or as a gradual worsening over time without periods of recovery (10–15% of cases). A combination of these two patterns may also occur or people may start in a relapsing and remitting course that then becomes progressive later on.Relapses are usually not predictable, occurring without warning. Exacerbations rarely occur more frequently than twice per year. Some relapses, however, are preceded by common triggers and they occur more frequently during spring and summer. Similarly, viral infections such as the common cold, influenza, or gastroenteritis increase their risk. Stress may also trigger an attack. Women with MS who become pregnant experience fewer relapses; however, during the first months after delivery the risk increases. Overall, pregnancy does not seem to influence long-term disability. Many events have been found not to affect relapse rates including vaccination, breast feeding, physical trauma, and Uhthoff's phenomenon.  Prodromal phase  MS may have a prodromal phase in the years leading up to MS manifestation, characterized by psychiatric issues, cognitive impairment, and increased use of healthcare.  Causes  The cause of MS is unknown, but it is believed to occur as a result of some combination of genetic and environmental factors, such as infectious agents.  Infectious agents  Many microbes have been proposed as triggers of MS. One hypothesis is that infection by a widespread microbe contributes to disease development, and the geographic distribution of this organism influences the epidemiology of MS. Two opposing versions of this hypothesis include the hygiene hypothesis and the prevalence hypothesis, the former being more favored. The hygiene hypothesis proposes that exposure to certain infectious agents early in life is protective; the disease is a response to a late encounter with such agents. The prevalence hypothesis proposes that an early, persistent, and silent infection increases risk of disease, thus the disease is more common where the infectious agent is more common. Only in a few cases and after many years does it cause demyelination. Evidence for a virus as a cause include the presence of oligoclonal bands in the brain and cerebrospinal fluid of most people with MS, the association of several viruses with human demyelinating encephalomyelitis, and the occurrence of demyelination in animals caused by some viral infections.Epstein-Barr herpes virus (EBV) can cause infectious mononucleosis and infects about 95% of adults. In combination with other genetic and environmental factors, there is ""compelling epidemiological and mechanistic evidence for a causal role of EBV in multiple sclerosis"", though only a small proportion of those infected with EBV later develop MS. A study of individuals in the United States military between 1993 and 2013 (total population greater than 10 million) compared 801 people who developed MS on or after military service to 1,566 matched controls who did not develop MS during this observation period. The study found a 32-fold increased risk of developing MS after infection with EBV. It did not find an increased risk after infection with other viruses, including the similarly transmitted cytomegalovirus. The finding strongly suggests that EBV plays a role in the onset of MS, although EBV alone may be insufficient to cause it.  Genetics  MS is not considered a hereditary disease, but several genetic variations have been shown to increase the risk. Some of these genes appear to have higher levels of expression in microglial cells than expected by chance. The probability of developing the disease is higher in relatives of an affected person, with a greater risk among those more closely related. An identical twin of an affected individual has a 30% chance of developing MS, 5% for a nonidentical twin, 2.5% for a sibling, and an even lower chance for a half sibling. If both parents are affected, the risk in their children is 10 times that of the general population. MS is also more common in some ethnic groups than others.Specific genes that have been linked with MS include differences in the human leukocyte antigen (HLA) system—a group of genes on chromosome 6 that serves as the major histocompatibility complex (MHC). That differences in the HLA region are related to susceptibility has been known since the 1980s, and this same region has also been implicated in the development of other autoimmune diseases, such as diabetes type I and systemic lupus erythematosus. The most consistent finding is the association between multiple sclerosis and alleles of the MHC defined as DR15 and DQ6. Other loci have shown a protective effect, such as HLA-C554 and HLA-DRB111. HLA differences account for an estimated 20 to 60% of the genetic predisposition. Modern genetic methods (genome-wide association studies) have revealed at least 200 variants outside the HLA locus that modestly increase the probability of MS.  Geography  MS is more common in people who live farther from the equator, although exceptions exist. These exceptions include ethnic groups that are at low risk and that live far from the equator such as the Sami, Amerindians, Canadian Hutterites, New Zealand Māori, and Canada's Inuit, as well as groups that have a relatively high risk and that live closer to the equator such as Sardinians, inland Sicilians, Palestinians, and Parsi. The cause of this geographical pattern is not clear. While the north–south gradient of incidence is decreasing, as of 2010 it is still present.MS is more common in regions with northern European populations, so the geographic variation may simply reflect the global distribution of these high-risk populations.A relationship between season of birth and MS lends support to this idea, with fewer people born in the Northern Hemisphere in November compared to May being affected later in life.Environmental factors may play a role during childhood, with several studies finding that people who move to a different region of the world before the age of 15 acquire the new region's risk of MS. If migration takes place after age 15, the persons retain the risk of their home country. Some evidence indicates that the effect of moving may still apply to people older than 15.  Other  Smoking may be an independent risk factor for MS. Stress may be a risk factor, although the evidence to support this is weak. Association with occupational exposures and toxins—mainly organic solvents—has been evaluated, but no clear conclusions have been reached. Vaccinations were studied as causal factors; most studies, though, show no association. Several other possible risk factors, such as diet and hormone intake, have been evaluated, but evidence on their relation with the disease is ""sparse and unpersuasive"". Gout occurs less than would be expected and lower levels of uric acid have been found in people with MS. This has led to the theory that uric acid is protective, although its exact importance remains unknown. Obesity during adolescence and young adulthood is a risk factor for MS.  Pathophysiology  The three main characteristics of MS are the formation of lesions in the central nervous system (also called plaques), inflammation, and the destruction of myelin sheaths of neurons. These features interact in a complex and not yet fully understood manner to produce the breakdown of nerve tissue, and in turn, the signs and symptoms of the disease.Cholesterol crystals are believed both to impair myelin repair and aggravate inflammation. MS is believed to be an immune-mediated disorder that develops from an interaction of the individual's genetics and as yet unidentified environmental causes. Damage is believed to be caused, at least in part, by attack on the nervous system by a person's own immune system.  Lesions  The name multiple sclerosis refers to the scars (sclerae – better known as plaques or lesions) that form in the nervous system. These lesions most commonly affect the white matter in the optic nerve, brain stem, basal ganglia, and spinal cord, or white matter tracts close to the lateral ventricles. The function of white matter cells is to carry signals between grey matter areas, where the processing is done, and the rest of the body. The peripheral nervous system is rarely involved.To be specific, MS involves the loss of oligodendrocytes, the cells responsible for creating and maintaining a fatty layer—known as the myelin sheath—which helps the neurons carry electrical signals (action potentials). This results in a thinning or complete loss of myelin, and as the disease advances, the breakdown of the axons of neurons. When the myelin is lost, a neuron can no longer effectively conduct electrical signals. A repair process, called remyelination, takes place in early phases of the disease, but the oligodendrocytes are unable to completely rebuild the cell's myelin sheath. Repeated attacks lead to successively less effective remyelinations, until a scar-like plaque is built up around the damaged axons. These scars are the origin of the symptoms and during an attack magnetic resonance imaging (MRI) often shows more than 10 new plaques. This could indicate that some number of lesions exist, below which the brain is capable of repairing itself without producing noticeable consequences. Another process involved in the creation of lesions is an abnormal increase in the number of astrocytes due to the destruction of nearby neurons. A number of lesion patterns have been described.  Inflammation  Apart from demyelination, the other sign of the disease is inflammation. Fitting with an immunological explanation, the inflammatory process is caused by T cells, a kind of lymphocytes that plays an important role in the body's defenses. T cells gain entry into the brain as a result of disruptions in the blood–brain barrier. The T cells recognize myelin as foreign and attack it, explaining why these cells are also called ""autoreactive lymphocytes.""The attack on myelin starts inflammatory processes, which trigger other immune cells and the release of soluble factors like cytokines and antibodies. A further breakdown of the blood-brain barrier, in turn, causes a number of other damaging effects, such as swelling, activation of macrophages, and more activation of cytokines and other destructive proteins. Inflammation can potentially reduce transmission of information between neurons in at least three ways. The soluble factors released might stop neurotransmission by intact neurons. These factors could lead to or enhance the loss of myelin, or they may cause the axon to break down completely.  Blood–brain barrier  The blood–brain barrier (BBB) is a part of the capillary system that prevents the entry of T cells into the central nervous system. It may become permeable to these types of cells secondary to an infection by a virus or bacteria. After it repairs itself, typically once the infection has cleared, T cells may remain trapped inside the brain. Gadolinium cannot cross a normal BBB, so gadolinium-enhanced MRI is used to show BBB breakdowns.  Diagnosis  Multiple sclerosis is typically diagnosed based on the presenting signs and symptoms, in combination with supporting medical imaging and laboratory testing. It can be difficult to confirm, especially early on, since the signs and symptoms may be similar to those of other medical problems.The McDonald criteria, which focus on clinical, laboratory, and radiologic evidence of lesions at different times and in different areas, is the most commonly used method of diagnosis with the Schumacher and Poser criteria being of mostly historical significance.As of 2017, no single test (including biopsy) can provide a definitive diagnosis.Magnetic resonance imaging (MRI) of the brain and spine may show areas of demyelination (lesions or plaques). Gadolinium can be administered intravenously as a contrast agent to highlight active plaques, and by elimination, demonstrate the existence of historical lesions not associated with symptoms at the moment of the evaluation.Central vein signs (CVSs) have been proposed as a good indicator of MS in comparison with other conditions causing white lesions. One small study found fewer CVSs in older and hypertensive people. Further research on CVS as a biomarker for MS is ongoing.Brain atrophy is seen as an indicator of MS.Testing of cerebrospinal fluid obtained from a lumbar puncture can provide evidence of chronic inflammation in the central nervous system. The cerebrospinal fluid is tested for oligoclonal bands of IgG on electrophoresis, which are inflammation markers found in 75–85% of people with MS.  Differential diagnosis  Several diseases present similarly to MS. Medical professionals use a patient's specific presentation, history, and exam findings to make an individualized differential. Red flags are findings that suggest an alternate diagnosis, although they do not rule out MS. Red flags include a patient younger than 15 or older than 60, less than 24 hours of symptoms, involvement of multiple cranial nerves, involvement of organs outside of the nervous system, and atypical lab and exam findings.In an emergency setting, it is important to rule out a stroke or bleeding in the brain. Intractable vomiting, severe optic neuritis, or bilateral optic neuritis raises suspicion for neuromyelitis optica spectrum disorder (NMOSD). Infectious diseases that may look similar to multiple sclerosis include HIV, Lyme disease, and Syphilis. Autoimmune diseases include Sarcoidosis, Lupus, Guillain-Barré syndrome, Acute disseminated encephalomyelitis, and Behçet's disease. Psychiatric conditions such as Anxiety or Conversion disorder may also present in a similar way. Other rare diseases on the differential include CNS lymphoma, congenital leukodystrophies, and anti-MOG-associated myelitis.  Types and variants  Several phenotypes (commonly termed ""types""), or patterns of progression, have been described. Phenotypes use the past course of the disease in an attempt to predict the future course. They are important not only for prognosis, but also for treatment decisions. The International Advisory Committee on Clinical Trials of MS describes four types of MS (revised in 2013) in what is known as the Lublin classification: Clinically isolated syndrome (CIS) Relapsing-remitting MS (RRMS) Primary progressive MS (PPMS) Secondary progressive MS (SPMS)RRMS is characterized by unpredictable relapses followed by periods of months to years of relative quiet (remission) with no new signs of disease activity. Deficits that occur during attacks may either resolve or leave problems, the latter in about 40% of attacks and being more common the longer a person has had the disease. This describes the initial course of 80% of individuals with MS.The relapsing-remitting subtype usually begins with a clinically isolated syndrome (CIS). In CIS, a person has an attack suggestive of demyelination, but does not fulfill the criteria for multiple sclerosis. 30 to 70% of persons who experience CIS, later develop MS.PPMS occurs in roughly 10–20% of individuals with the disease, with no remission after the initial symptoms. It is characterized by progression of disability from onset, with no, or only occasional and minor, remissions and improvements. The usual age of onset for the primary progressive subtype is later than of the relapsing-remitting subtype. It is similar to the age that secondary progressive usually begins in RRMS, around 40 years of age.SPMS occurs in around 65% of those with initial RRMS, who eventually have progressive neurologic decline between acute attacks without any definite periods of remission. Occasional relapses and minor remissions may appear. The most common length of time between disease onset and conversion from RRMS to SPMS is 19 years.  Special courses  Independently of the types published by the MS associations, regulatory agencies such as the FDA often consider special courses, trying to reflect some clinical trials results on their approval documents. Some examples could be ""highly active MS"" (HAMS), ""active secondary MS"" (similar to the old progressive-relapsing) and ""rapidly progressing PPMS"".Also, deficits always resolving between attacks is sometimes referred to as ""benign"" MS, although people still build up some degree of disability in the long term. On the other hand, the term malignant multiple sclerosis is used to describe people with MS having reached significant level of disability in a short period.An international panel has published a standardized definition for the course HAMS.  Variants  Atypical variants of MS have been described; these include tumefactive multiple sclerosis, Balo concentric sclerosis, Schilder's diffuse sclerosis, and Marburg multiple sclerosis. Debate remains on whether they are MS variants or different diseases. Some diseases previously considered MS variants, such as Devic's disease, are now considered outside the MS spectrum.  Management  Although no cure for multiple sclerosis has been found, several therapies have proven helpful. Several effective treatments can decrease the number of attacks and the rate of progression. The primary aims of therapy are returning function after an attack, preventing new attacks, and preventing disability. Starting medications is generally recommended in people after the first attack when more than two lesions are seen on MRI.The first approved medications used to treat MS were modestly effective, though were poorly tolerated and had many adverse effects. Several treatment options with better safety and tolerability profiles have been introduced, improving the prognosis of MS. As with any medical treatment, medications used in the management of MS have several adverse effects. Alternative treatments are pursued by some people, despite the shortage of supporting evidence of efficacy.  Initial management of acute flare  During symptomatic attacks, administration of high doses of intravenous corticosteroids, such as methylprednisolone, is the usual therapy, with oral corticosteroids seeming to have a similar efficacy and safety profile. Although effective in the short term for relieving symptoms, corticosteroid treatments do not appear to have a significant impact on long-term recovery. The long-term benefit is unclear in optic neuritis as of 2020. The consequences of severe attacks that do not respond to corticosteroids might be treatable by plasmapheresis.  Chronic management   Relapsing remitting multiple sclerosis  Multiple disease-modifying medications were approved by regulatory agencies for RRMS; they are modestly effective at decreasing the number of attacks. Interferons and glatiramer acetate are first-line treatments and are roughly equivalent, reducing relapses by approximately 30%. Early-initiated long-term therapy is safe and improves outcomes.Treatment of CIS with interferons decreases the chance of progressing to clinical MS. Efficacy of interferons and glatiramer acetate in children has been estimated to be roughly equivalent to that of adults. The role of some newer agents such as fingolimod, teriflunomide, and dimethyl fumarate, is not yet entirely clear. Making firm conclusions about the best treatment is difficult, especially regarding the long‐term benefit and safety of early treatment, given the lack of studies directly comparing disease-modifying therapies or long-term monitoring of patient outcomes.The relative effectiveness of different treatments is unclear, as most have only been compared to placebo or a small number of other therapies. Direct comparisons of interferons and glatiramer acetate indicate similar effects or only small differences in effects on relapse rate, disease progression, and MRI measures. Alemtuzumab, natalizumab, and fingolimod may be more effective than other drugs in reducing relapses over the short term in people with RRMS. Natalizumab and interferon beta-1a (Rebif) may reduce relapses compared to both placebo and interferon beta-1a (Avonex) while Interferon beta-1b (Betaseron), glatiramer acetate, and mitoxantrone may also prevent relapses. Evidence on relative effectiveness in reducing disability progression is unclear. All medications are associated with adverse effects that may influence their risk to benefit profiles.Ublituximab was approved for medical use in the United States in December 2022.  Progressive multiple sclerosis  In 2011, mitoxantrone was the first medication approved for secondary progressive MS. In this population, tentative evidence supports mitoxantrone moderately slowing the progression of the disease and decreasing rates of relapses over two years.New approved medications continue to emerge in modern medicine. In March 2017, the FDA approved ocrelizumab as a treatment for primary progressive MS in adults, the first drug to gain that approval, with requirements for several Phase IV clinical trials. It is also used for the treatment of relapsing forms of multiple sclerosis, to include clinically isolated syndrome, relapsing-remitting disease, and active secondary progressive disease in adults. According to a 2021 Cochrane review, ocrelizumab may reduce worsening of symptoms for primary progressive MS and probably increases unwanted effects but makes little or no difference to the number of serious unwanted effects.In 2019, siponimod and cladribine were approved in the United States for the treatment of secondary progressive multiple sclerosis (SPMS). Subsequently, ozanimod was approved in 2020, and ponesimod was approved in 2021, which were both approved for management of CIS, relapsing MS, and SPMS in the U.S., and RRMS in Europe.  Adverse effects  The disease-modifying treatments have several adverse effects. One of the most common is irritation at the injection site for glatiramer acetate and the interferons (up to 90% with subcutaneous injections and 33% with intramuscular injections). Over time, a visible dent at the injection site, due to the local destruction of fat tissue, known as lipoatrophy, may develop. Interferons may produce flu-like symptoms; some people taking glatiramer experience a post-injection reaction with flushing, chest tightness, heart palpitations, and anxiety, which usually lasts less than thirty minutes. More dangerous but much less common are liver damage from interferons, systolic dysfunction (12%), infertility, and acute myeloid leukemia (0.8%) from mitoxantrone, and progressive multifocal leukoencephalopathy occurring with natalizumab (occurring in 1 in 600 people treated).Fingolimod may give rise to hypertension and slowed heart rate, macular edema, elevated liver enzymes, or a reduction in lymphocyte levels. Tentative evidence supports the short-term safety of teriflunomide, with common side effects including: headaches, fatigue, nausea, hair loss, and limb pain. There have also been reports of liver failure and PML with its use and it is dangerous for fetal development. Most common side effects of dimethyl fumarate are flushing and gastrointestinal problems. While dimethyl fumarate may lead to a reduction in the white blood cell count there were no reported cases of opportunistic infections during trials.  Associated symptoms  Both medications and neurorehabilitation have been shown to improve some symptoms, though neither changes the course of the disease. Some symptoms have a good response to medication, such as bladder spasticity, while others are little changed. Equipment such as catheters for neurogenic bladder dysfunction or mobility aids can be helpful in improving functional status. A multidisciplinary approach is important for improving quality of life; however, it is difficult to specify a 'core team' as many health services may be needed at different points in time. Multidisciplinary rehabilitation programs increase activity and participation of people with MS but do not influence impairment level. Studies investigating information provision in support of patient understanding and participation suggest that while interventions (written information, decision aids, coaching, educational programmes) may increase knowledge, the evidence of an effect on decision making and quality of life is mixed and low certainty. There is limited evidence for the overall efficacy of individual therapeutic disciplines, though there is good evidence that specific approaches, such as exercise, and psychological therapies are effective. Cognitive training, alone or combined with other neuropsychological interventions, may show positive effects for memory and attention though firm conclusions are not possible given small sample numbers, variable methodology, interventions and outcome measures. The effectiveness of palliative approaches in addition to standard care is uncertain, due to lack of evidence. The effectiveness of interventions, including exercise, specifically for the prevention of falls in people with MS is uncertain, while there is some evidence of an effect on balance function and mobility. Cognitive behavioral therapy has shown to be moderately effective for reducing MS fatigue. The evidence for the effectiveness of non-pharmacological interventions for chronic pain is insufficient to recommend such interventions alone, however their use in combination with medications may be reasonable.  Non-pharmaceutical  There is some evidence that aquatic therapy is a beneficial intervention.The spasticity associated with MS can be difficult to manage because of the progressive and fluctuating course of the disease. Although there is no firm conclusion on the efficacy in reducing spasticity, PT interventions can be a safe and beneficial option for patients with multiple sclerosis. Physical therapy including vibration interventions, electrical stimulation, exercise therapy, standing therapy, and radial shock wave therapy (RSWT), were beneficial for limiting spasticity, helping limit excitability, or increasing range of motion.  Alternative treatments  Over 50% of people with MS may use complementary and alternative medicine, although percentages vary depending on how alternative medicine is defined. Regarding the characteristics of users, they are more frequently women, have had MS for a longer time, tend to be more disabled and have lower levels of satisfaction with conventional healthcare. The evidence for the effectiveness for such treatments in most cases is weak or absent. Treatments of unproven benefit used by people with MS include dietary supplementation and regimens, vitamin D, relaxation techniques such as yoga, herbal medicine (including medical cannabis), hyperbaric oxygen therapy, self-infection with hookworms, reflexology, acupuncture, and mindfulness. Evidence suggests vitamin D supplementation, irrespective of the form and dose, provides no benefit for people with MS; this includes for measures such as relapse recurrence, disability, and MRI lesions while effects on health‐related quality of life and fatigue are unclear. There is insufficient evidence supporting high-dose biotin and some evidence for increased disease activity and higher risk of relapse with its use.  Prognosis  The availability of treatments that modify the course of multiple sclerosis beginning in the 1990s, known as disease-modifying therapies (DMTs), has improved prognosis. These treatments can reduce relapses and slow progression, but as of 2022 there is no cure.The prognosis of MS depends on the subtype of the disease, and there is considerable individual variation in the progression of the disease. In relapsing MS, the most common subtype, a 2016 cohort study found that after a median of 16.8 years from onset, one in ten needed a walking aid, and almost two in ten transitioned to secondary progressive MS, a form characterized by more progressive decline. With treatments available in the 2020s, relapses can be eliminated or substantially reduced. However, ""silent progression"" of the disease still occurs.In addition to secondary progressive MS (SPMS), a small proportion of people with MS (10–15%) experience progressive decline from the onset, known as primary progressive MS (PPMS). Most treatments have been approved for use in relapsing MS; there are fewer treatments with lower efficacy for progressive forms of MS. The prognosis for progressive MS is worse, with faster accumulation of disability, though with considerable individual variation. In untreated PPMS, the median time from onset to requiring a walking aid is estimated as seven years. In SPMS, a 2014 cohort study reported that people required a walking aid after an average of five years from onset of SPMS, and were chair or bed-bound after an average of fifteen years.After diagnosis of MS, characteristics that predict a worse course are male sex, older age, and greater disability at the time of diagnosis; female sex is associated with a higher relapse rate. As of 2018, no biomarker can accurately predict disease progression in every patient. Spinal cord lesions, abnormalities on MRI, and more brain atrophy are predictive of a worse course, though brain atrophy as a predictor of disease course is experimental and not used in clinical practice as of 2018. Early treatment leads to a better prognosis, but a higher relapse frequency when treated with DMTs is associated with a poorer prognosis. A 60-year longitudinal population study conducted in Norway found a 7-year shorter life expectancy in MS compared with the general population and a rise in survival in MS during the observation period. Median life expectancy for RRMS patients was 77.8 years and 71.4 years for PPMS, compared to 81.8 years for the general population. Life expectancy for men was 5 years shorter than for women.  Epidemiology  MS is the most common autoimmune disorder of the central nervous system. The latest estimation of the total number of people with MS was 2.8 million globally, with a prevalence of 36 per 100,000 people. Moreover, prevalence varies widely in different regions around the world. In Africa, there are 5 people per 100,000 diagnosed with MS, compared to South East Asia where the prevalence is 9 per 100,000, 112 per 100,000 in the Americas, and 133 per 100,000 in Europe.Increasing rates of MS may be explained simply by better diagnosis. Studies on populational and geographical patterns have been common and have led to a number of theories about the cause.MS usually appears in adults in their late twenties or early thirties but it can rarely start in childhood and after 50 years of age. The primary progressive subtype is more common in people in their fifties. Similarly to many autoimmune disorders, the disease is more common in women, and the trend may be increasing. As of 2020, globally it is about two times more common in women than in men, and the ratio of women to men with MS is as high as 4:1 in some countries. In children, it is even more common in females than males, while in people over fifty, it affects males and females almost equally.  History   Medical discovery  Robert Carswell (1793–1857), a British professor of pathology, and Jean Cruveilhier (1791–1873), a French professor of pathologic anatomy, described and illustrated many of the disease's clinical details, but did not identify it as a separate disease. Specifically, Carswell described the injuries he found as ""a remarkable lesion of the spinal cord accompanied with atrophy"". Under the microscope, Swiss pathologist Georg Eduard Rindfleisch (1836–1908) noted in 1863 that the inflammation-associated lesions were distributed around blood vessels.The French neurologist Jean-Martin Charcot (1825–1893) was the first person to recognize multiple sclerosis as a distinct disease in 1868. Summarizing previous reports and adding his own clinical and pathological observations, Charcot called the disease sclerose en plaques.  Diagnosis history  The first attempt to establish a set of diagnostic criteria was also due to Charcot in 1868. He published what now is known as the ""Charcot Triad"", consisting in nystagmus, intention tremor, and telegraphic speech (scanning speech). Charcot also observed cognition changes, describing his patients as having a ""marked enfeeblement of the memory"" and ""conceptions that formed slowly"".Diagnosis was based on Charcot triad and clinical observation until Schumacher made the first attempt to standardize criteria in 1965 by introducing some fundamental requirements: Dissemination of the lesions in time (DIT) and space (DIS), and that ""signs and symptoms cannot be explained better by another disease process"". The DIT and DIS requirement was later inherited by the Poser and McDonald criteria, whose 2017 revision is in use.During the 20th century, theories about the cause and pathogenesis were developed and effective treatments began to appear in the 1990s. Since the beginning of the 21st century, refinements of the concepts have taken place. The 2010 revision of the McDonald criteria allowed for the diagnosis of MS with only one proved lesion (CIS).In 1996, the US National Multiple Sclerosis Society (NMSS) (Advisory Committee on Clinical Trials) defined the first version of the clinical phenotypes that is in use. In this first version they provided standardized definitions for four MS clinical courses: relapsing-remitting (RR), secondary progressive (SP), primary progressive (PP), and progressive relapsing (PR). In 2010, PR was dropped and CIS was incorporated. Three years later, the 2013 revision of the ""phenotypes for the disease course"" were forced to consider CIS as one of the phenotypes of MS, making obsolete some expressions like ""conversion from CIS to MS"". Other organizations have proposed later new clinical phenotypes, like HAMS (Highly Active MS).  Historical cases  There are several historical accounts of people who probably had MS and lived before or shortly after the disease was described by Charcot. A young woman called Halldora who lived in Iceland around 1200 suddenly lost her vision and mobility but recovered them seven days after. Saint Lidwina of Schiedam (1380–1433), a Dutch nun, may be one of the first clearly identifiable people with MS. From the age of 16 until her death at 53, she had intermittent pain, weakness of the legs and vision loss: symptoms typical of MS. Both cases have led to the proposal of a ""Viking gene"" hypothesis for the dissemination of the disease.Augustus Frederick d'Este (1794–1848), son of Prince Augustus Frederick, Duke of Sussex and Lady Augusta Murray and a grandson of George III of the United Kingdom, almost certainly had MS. D'Este left a detailed diary describing his 22 years living with the disease. His diary began in 1822 and ended in 1846, although it remained unknown until 1948. His symptoms began at age 28 with a sudden transient visual loss (amaurosis fugax) after the funeral of a friend. During his disease, he developed weakness of the legs, clumsiness of the hands, numbness, dizziness, bladder disturbance and erectile dysfunction. In 1844, he began to use a wheelchair. Despite his illness, he kept an optimistic view of life. Another early account of MS was kept by the British diarist W. N. P. Barbellion, pen name of Bruce Frederick Cummings (1889–1919), who maintained a detailed log of his diagnosis and struggle. His diary was published in 1919 as The Journal of a Disappointed Man. Charles Dickens, a keen observer, described possible bilateral optic neuritis with reduced contrast vision and Uhthoff phenomenon in the main female character of Bleak House (1852–1853), Esther Summerville.  Research   Epstein-Barr virus ongoing studies  As of 2022, the pathogenesis of MS as it relates to EBV is actively investigated, as are disease-modifying therapies; understanding of how risk factors combine with EBV to initiate MS is sought. Whether EBV is the only cause of MS might be better understood if an EBV vaccine is developed and shown to prevent MS as well.Even though a variety of studies showed the connection between an EBV infection and a later development of multiple sclerosis, the mechanisms behind this correlation are still not completely clear. Though there are some leading theories which are explaining the relationship between the two diseases closer. It is expected that the involvement of EBV-infected B-cells and the involvement of anti-EBNA antibodies, which appear to be significantly higher in multiple sclerosis patients, play a crucial role in the development of the disease. This is supported by the fact that with treatment against B-cells, e.g. through Ocrelizumab therapy, the course of multiple sclerosis symptoms will be improved. Annual relapses will appear in a minor rate and disability progression is slower. A study led by a Stanford research unit which was published in 2022, has shown that during an EBV infection, molecular mimicry can occur, where the immune system will produce antibodies against the EBNA1 protein, which at the same time is able to bind to GlialCAM in the myelin. Additionally, they observed a phenomenon which is uncommon in healthy individuals but often detected in multiple sclerosis patients – B-cells are trafficking to the brain and spinal cord, where they are producing oligoclonal antibody bands. A majority of these oligoclonal bands do have an affinity to the viral protein EBNA1, which is cross-reactive to GlialCAM. These antibodies are abundant in approximately 20–25% of multiple sclerosis patients and worsen the autoimmune demyelination which leads consequently to an pathophysiologocal exacerbation of the disease. Furthermore, the intrathecal oligoclonal expansion with a constant somatic hypermutation is unique in multiple sclerosis when compared to other neuroinflammatory diseases. In the study there was also the abundance of antibodies with IGHV 3–7 genes measured, which appears to be connected to the disease progress. Antibodies which are IGHV3–7-based are binding with a high affinity to EBNA1 and GlialCAM. This process is actively thriving the demyelination. It is probable that B-cells, expressing IGHV 3–7 genes entered the CSF and underwent there affinity maturation after facing GlialCAM, which led consequently to the production of high affinity anti-GlialCAM antibodies. This was additionally shown in the EAE mouse model where immunization with EBNA1 lead to a strong B-cell response against GlialCAM, which worsened the EAE.  Medications  Medications that influence voltage-gated sodium ion channels are under investigation as a potential neuroprotective strategy because of hypothesized role of sodium in the pathological process leading to axonal injury and accumulating disability. There is insufficient evidence of an effect of sodium channel blockers for people with MS.  Pathogenesis  MS is a clinically defined entity with several atypical presentations. Some auto-antibodies have been found in atypical MS cases, giving birth to separate disease families and restricting the previously wider concept of MS. Anti-AQP4 autoantibodies were found in neuromyelitis optica (NMO), which was previously considered a MS variant. A spectrum of diseases named NMOSD (NMO spectrum diseases) or anti-AQP4 diseases has been accepted. Some cases of MS were presenting anti-MOG autoantibodies, mainly overlapping with the Marburg variant. Anti-MOG autoantibodies were found to be also present in ADEM, and a second spectrum of separated diseases is being considered. This spectrum is named inconsistently across different authors, but it is normally something similar to anti-MOG demyelinating diseases.A third kind of auto-antibodies is accepted. They are several anti-neurofascin auto-antibodies which damage the Ranvier nodes of the neurons. These antibodies are more related to the peripheral nervous demyelination, but they were also found in chronic progressive PPMS and combined central and peripheral demyelination (CCPD, which is considered another atypical MS presentation).In addition to the significance of auto-antibodies in MS, four different patterns of demyelination have been reported, opening the door to consider MS as a heterogeneous disease.  Disease biomarkers  Since disease progression is the result of degeneration of neurons, the roles of proteins showing loss of nerve tissue such as neurofilaments, tau, and N-acetylaspartate are under investigation.Improvement in neuroimaging techniques such as positron emission tomography (PET) or MRI carry a promise for better diagnosis and prognosis predictions. Regarding MRI, there are several techniques that have already shown some usefulness in research settings and could be introduced into clinical practice, such as double-inversion recovery sequences, magnetization transfer, diffusion tensor, and functional magnetic resonance imaging. These techniques are more specific for the disease than existing ones, but still lack some standardization of acquisition protocols and the creation of normative values. This is particularly the case for proton magnetic resonance spectroscopy, for which a number of methodological variations observed in the literature may underlie continued inconsistencies in central nervous system metabolic abnormalities, particularly in N-acetyl aspartate, myoinositol, choline, glutamate, GABA, and GSH, observed for multiple sclerosis and its subtypes. There are other techniques under development that include contrast agents capable of measuring levels of peripheral macrophages, inflammation, or neuronal dysfunction, and techniques that measure iron deposition that could serve to determine the role of this feature in MS, or that of cerebral perfusion.  COVID-19  The hospitalization rate was found to be higher among individuals with MS and COVID-19 infection, at 10%, while the pooled infection rate is estimated at 4%. The pooled prevalence of death in hospitalized individuals with MS is estimated as 4%.  Other emerging theories  One emerging hypothesis, referred to as the hygiene hypothesis, suggests that early-life exposure to infectious agents helps to develop the immune system and reduces susceptibility to allergies and autoimmune disorders, including MS. Germ-free mice infected with transplanted fecal matter from MS patients exhibit an increased risk of developing EAE, an animal model of MS. It has also been proposed that certain bacteria found in the gut use molecular mimicry to infiltrate the brain via the gut-brain axis, initiating an inflammatory response and increasing blood-brain barrier permeability. Vitamin D levels have also been correlated with MS; lower levels of vitamin D correspond to an increased risk of MS, suggesting a reduced prevalence in the tropics – an area with more Vitamin D-rich sunlight – strengthening the impact of geographical location on MS development. MS mechanisms begin when peripheral autoreactive effector CD4+ T cells get activated and move into the CNS. Antigen-presenting cells localize the reactivation of autoreactive effector CD4-T cells once they have entered the CNS, attracting more T cells and macrophages to form the inflammatory lesion. In MS patients, macrophages and microglia assemble at locations where demyelination and neurodegeneration are actively occurring, and microglial activation is more apparent in the normal-appearing white matter of MS patients. Astrocytes generate neurotoxic chemicals like nitric oxide and TNFα, attract neurotoxic inflammatory monocytes to the CNS, and are responsible for astrogliosis, the scarring that prevents the spread of neuroinflammation and kills neurons inside the scarred area.  See also  List of multiple sclerosis organizations List of people with multiple sclerosis  References   External links  Multiple sclerosis at Curlie Database for analysis and comparison of global data on the epidemiology of MS","Multiple sclerosis (MS) is a serious health condition that gets worse over time. In this disease, the body’s natural guard against illness (the immune system) damages fatty coverings called myelin sheaths around the nerve cells (neurons) in the central nervous system (CNS). The disease has different effects in different people, and can make people’s bodies, eyesight, speech, and minds work poorly. People with MS do not normally live as long as healthy people.In healthy people, myelin sheaths help neurons work. Electric signals in neurons move quickly through long, narrow axons like electricity in a wire. The myelin is like the insulator around the wire that keeps the signal strong by keeping it from moving out of the wire before the end. In people with MS, infiltration of immune cells causes inflammation within the CNS resulting in the loss of the protective insulator, called ""demyelination."" The progressive loss of the myelin sheath, as well as the loss of myelin-producing cells, impair the ability of the body to regrow its myelin. Without the protective covering, the signals between neurons do not travel well. Because of this, the mind and body cannot work like they normally do.  Possible causes  Scientists and doctors do not know for certain the cause of MS, but they think some things put some people at a higher risk for MS: A person’s genetics (the qualities they are born with) Too few vitamins in the body Too much stress in a person’s life Smoking cigars or cigarettes Being ill many times as a childResearch about the causes of MS is still incomplete. Some scientists think that a relatively unknown pathogen called Chlamydia pneumoniae may cause MS. Also, some viruses can cause myelin damage, there are other viruses that have been shown to make people more likely to get MS. Even though scientists and doctors have theories, no one has found one cause that explains every case of the disease.  Symptoms  Quite a few forms of MS exist, which can create difficulty in deciding how to manage the illness. The disease damages myelin. Sometimes, the body can do limited repairs to myelin. When this happens, symptoms (the problems caused by the disease) go away for a short time. This is called remission. When the body attacks the myelin again, the symptoms return and this is called relapse. The type of MS that has remissions and relapses is called Remitting-Relapsing MS. In less common cases, the body continues attacking myelin and the symptoms get worse rapidly, a form called ""Primary Progressive MS"". Sometimes a combination of the two types of disease can occur simultaneously.People with MS have many problems. Their muscles are usually weak, they may shake uncontrollably, they have trouble moving, and they have trouble balancing. People with MS often feel a great amount of pain and tire easily. Their speech and sight sometimes become very poor. Thinking and solving problems is more difficult for people with MS than for healthy people.Inside the body, MS causes damage that cannot be seen or measured without special medical equipment. The immune system attacks either the fatty parts of the myelin or the protein parts of the myelin. The body may also attack the cells that produce the myelin sheath, called glial cells. When myelin is damaged or missing, large areas of axons affected by the damage are visible as scars or lesions in the central nervous system tissue that build up with repeated repair attempts by the body over time. Lesions appear in different areas of the central nervous system depending on what form of MS a person has.Inflammation is an important part of MS symptoms. Inflammation occurs whenever an injury or illness is detected by the body. It is the first part of an immune system response. In MS patients, inflammation against myelin causes swelling and other harmful effects in the nervous system. Inflammation can happen due to infection by Chlamydia Pneumoniae.  People with MS  The people who get MS are usually between 20 and 40 years old, although it can happen to older or, very rarely, younger people too. MS is significantly more common in areas of the world that are far away from the equator. Areas far from the equator get less sunlight than areas near the equator, and the human body requires sunlight to make vitamin D for itself. This observation supports the idea that MS is caused partly by too little vitamin D. People who move from one part of the world to another when they are children are more likely to develop MS than people who do not move long distances until later in life or who never move long distances.  Diagnosis  To diagnose MS, or to tell if a person has it, a doctor will determine what kind of symptoms are present and how often they occur. The most common guidelines used for this are called the McDonald criteria, which define the symptoms of MS and how often they must occur in order to make a diagnosis. A doctor can also order tests to be done by a laboratory, which can determine how active the immune system is in the patient. A special machine called an MRI can photograph the inside of the central nervous system to show if the person has lesions from damaged myelin. Certain types of neurons can be checked to see how responsive they are. Neurons with damaged myelin around their axons will respond more slowly than normal neurons.  Treatment  Once a person is diagnosed with MS, a doctor can help ease the symptoms. Scientists have not yet found a way to cure MS, or take it away entirely. The form of MS that comes and goes regularly can be treated more easily than other forms. Some treatments are used only during attacks to make the attacks easier on the patient or to help recovery after the attacks are over. Other treatments are used all the time to help make attacks happen less often. These kinds of treatments are usually injections or infusions directly into veins, but newer treatments can be taken daily by mouth instead. Some people seek other treatments outside of usual medicine, but these have not been shown in scientific studies to be effective.  References   Other websites  Multiple sclerosis -Citizendium"
"Parkinson\'s disease (PD), or simply Parkinson\'s, is a chronic degenerative disorder of the central nervous system that mainly affects the motor system. The symptoms usually emerge slowly, and as the disease worsens, non-motor symptoms become more common. Early symptoms are tremor, rigidity, slowness of movement, and difficulty with walking. Problems may also arise with cognition, behaviour, sleep, and sensory systems. Parkinson\'s disease dementia becomes common in advanced stages of the disease. The motor symptoms of the disease result from the death of nerve cells in the substantia nigra, a region of the midbrain that supplies dopamine to the basal ganglia. The cause of this cell death is poorly understood, but involves the aggregation of the protein alpha-synuclein into Lewy bodies within the neurons. Collectively, the main motor symptoms are known as parkinsonism or a parkinsonian syndrome.The cause of PD is unknown, but a combination of genetic and environmental factors are believed to play a role. Those with an affected family member are at an increased risk of getting the disease, with certain genes known to be inheritable risk factors. Environmental risks include exposure to pesticides, and prior head injuries; a history of exposure to trichloroethylene is also suspected. Conversely, caffeine and nicotine appear to be protective.Diagnosis is mainly based on symptoms, with motor symptoms being the most frequently presented. Tests such as neuroimaging (magnetic resonance imaging or imaging to look at dopamine neuronal dysfunction known as DaT scan) are used to help rule out other diseases. Parkinson\'s disease typically occurs in people over the age of 60, of whom about one percent are affected. Males are affected at a ratio of around 3:2 compared with females. When it is seen in people before the age of 50, it is called early-onset PD. By 2015, PD affected 6.2 million people and resulted in about 117,400 deaths globally. The number of people with PD older than fifty is expected to double by 2030. The average life expectancy following diagnosis is 7–15 years.No cure for PD is known; treatment aims to reduce the effects of the symptoms. Initial treatment is typically with the medications levodopa (L-DOPA), MAO-B inhibitors, or dopamine agonists. As the disease progresses, these medications become less effective, while at the same time producing a side effect marked by involuntary muscle movements. At that time, medications may be used in combination and doses may be increased. Diet and certain forms of rehabilitation have shown some effectiveness at improving symptoms. Surgery to place microelectrodes for deep brain stimulation has been used to reduce severe motor symptoms where drugs are ineffective. Evidence for treatments for the nonmovement-related symptoms of PD, such as sleep disturbances and emotional problems, is less strong.The disease is named after English doctor James Parkinson, who published the first detailed description in An Essay on the Shaking Palsy, in 1817. Public awareness campaigns include World Parkinson\'s Day (on 11 April, the birthday of James Parkinson) and the use of a red tulip as the symbol of the disease. People with PD who have increased the public\'s awareness of the condition include boxer Muhammad Ali, comedian Billy Connolly, actor Michael J. Fox, Olympic cyclist Davis Phinney, and actor Alan Alda.  Classification  Parkinson\'s disease is the most common form of parkinsonism and is also called idiopathic parkinsonism, meaning that it has no identifiable cause. The accumulation of a misfolded protein alpha-synuclein in the brain, and its spread throughout the brain makes Parkinson\'s disease a neurodegenerative disease classed as a synucleinopathy, and more specifically as an alpha-synucleinopathy (αsynucleinopathy).Other Parkinson-plus syndromes can have similar movement symptoms but have a variety of associated symptoms. Some of these are also synucleinopathies. Lewy body dementia involves motor symptoms with early onset of cognitive dysfunction and hallucinations which precede motor symptoms. Alternatively, multiple systems atrophy or MSA usually has early onset of autonomic dysfunction (such as orthostasis), and may have autonomic predominance, cerebellar symptom predominance, or Parkinsonian predominance.Other Parkinson-plus syndromes involve tau, rather than alpha-synuclein. These include progressive supranuclear palsy (PSP) and corticobasal syndrome (CBS). PSP predominantly involves rigidity, early falls, bulbar symptoms, and vertical gaze restriction; it can be associated with frontotemporal dementia symptoms. CBS involves asymmetric parkinsonism, dystonia, alien limb, and myoclonic jerking. These presentation timelines and associated symptoms can help differentiate these similar movement disorders from idiopathic Parkinson disease.  Signs and symptoms  The most recognizable symptoms are movement (motor) related, and include tremor, bradykinesia, rigidity, and shuffling/stooped gait. Non-motor symptoms, including autonomic dysfunction (dysautonomia), neuropsychiatric problems (mood, cognition, behavior or thought alterations), and sensory (especially altered sense of smell) and sleep difficulties may be present as well. Patients may have nonmotor symptoms that precede the onset of motor symptoms including constipation, anosmia, and REM Behavior Disorder. Generally, symptoms such as dementia, psychosis, orthostasis, and more severe falls occur later. Dysphagia can begin at any time during the course of Parkinson\'s, and affects more than 80% of patients.  Motor  Four motor symptoms are considered as cardinal signs in PD: tremor, slowness of movement (bradykinesia), rigidity, and postural instability.The most common presenting sign is a coarse, slow tremor of the hand at rest, which disappears during voluntary movement of the affected arm and in the deeper stages of sleep. It typically appears in only one hand, eventually affecting both hands as the disease progresses. Frequency of PD tremor is between 4–6 hertz (cycles per second). A common characteristic of tremor is pill-rolling, the tendency of the index finger and thumb to touch and perform together with a circular movement. The term derives from the similarity between the movement of people with PD and the early pharmaceutical technique of manually making pills.Bradykinesia is due to disturbances in motor planning of movement initiation, and associated with difficulties along the whole course of the movement process, from planning to initiation to execution of a movement. Performance of sequential and simultaneous movement is impaired. Bradykinesia is the most handicapping symptom of Parkinson\'s disease, presenting as difficulties with everyday tasks such as dressing, feeding, and bathing. It leads to particular difficulty in carrying out two independent motor activities at the same time, and can be made worse by emotional stress or concurrent illnesses. Paradoxically, people with PD can ride a bicycle or climb stairs more easily than walk on the level. Although most physicians may readily notice bradykinesia, formal assessment requires persons to do repetitive movements with their fingers and feet.In parkinsonism, rigidity or hypokinesia can be uniform, known as lead-pipe rigidity, or ratcheted, known as cogwheel rigidity. The combination of tremor and increased tone is considered to be at the origin of cogwheel rigidity. Rigidity may be associated with joint pain; such pain being a frequent initial manifestation of the disease. In early stages of PD, rigidity is asymmetrical and tends to affect the neck and shoulder muscles before the muscles of the face and extremities. With the progression of the disease, rigidity typically affects the whole body and reduces the ability to move. Postural instability is typical in the later stages of the disease, leading to impaired balance and frequent falls, and secondarily to bone fractures, loss of confidence, and reduced mobility. Instability is absent in the initial stages, especially in younger people, especially before the development of bilateral symptoms. Up to 40% of people diagnosed with PD may experience falls, and around 10% may have falls weekly, with the number of falls being related to the severity of PD.Other recognized motor signs and symptoms include gait and posture disturbances such as festination (rapid shuffling steps and a forward-flexed posture when walking with no flexed arm swing). Other common signs include freezing of gait (brief arrests when the feet seem to get stuck to the floor, especially on turning or changing direction), a slurred, monotonous, quiet voice, mask-like facial expression, and handwriting that gets smaller and smaller.  Cognitive  PD causes neuropsychiatric disturbances ranging from mild to severe including disorders of cognition, mood, behavior, and thought. Cognitive disturbances can occur in the early stages or before diagnosis, and increase in prevalence with duration of the disease. The most common cognitive deficit is executive dysfunction, which can include problems with planning, cognitive flexibility, abstract thinking, rule acquisition, inhibiting inappropriate actions, initiating appropriate actions, working memory, and control of attention. Other cognitive difficulties include slowed cognitive processing speed, impaired recall, and impaired perception and estimation of time. Nevertheless, improvement appears when recall is aided by cues. Visuospatial difficulties are a part of the disease, seen for example when the individual is asked to perform tests of facial recognition and perception of the orientation of drawn lines.A person with PD has two to six times the risk of dementia compared with the general population. Up to 78% of people with PD have Parkinson\'s disease dementia. The prevalence of dementia increases with age, and to a lesser degree, duration of the disease. Dementia is associated with a reduced quality of life in people with PD and their caregivers, increased mortality, and a higher probability of needing nursing home care.  Psychosis  Psychosis can be considered a symptom with a prevalence at its widest range from 26 to 83%. Hallucinations or delusions occur in about 50% of people with PD over the course of the illness, and may herald the emergence of dementia. These range from minor hallucinations – sense of passage (something quickly passing beside the person) or sense of presence (the perception of something or someone standing to the side or behind the person) – to full blown vivid, formed visual hallucinations and paranoid ideation. Auditory hallucinations are uncommon in PD, and are rarely described as voices. Psychosis is believed to be an integral part of the disease. A psychosis with delusions and associated delirium is a recognized complication of anti-Parkinson drug treatment. Urinary tract infections (frequent in the elderly) and underlying brain pathology or changes in neurotransmitters or their receptors (e.g., acetylcholine, serotonin) are thought to play a role in psychosis in PD.  Neuropsychiatric  Behavior and mood alterations are more common in PD without cognitive impairment than in the general population and are usually present in PD with dementia. The most frequent mood difficulties are depression, apathy, and anxiety. Depression impacts an estimated 20% to 35% of patients, and may appear at any stage of the disease. It can manifest with symptoms common to the disease process (fatigue, insomnia, and difficulty with concentration), which makes diagnosis difficult. The imbalance and changes in dopamine, serotonin, and noradrenergic hormones and functional imparment are causes of depression in PD-affected people. Suicidal ideation is higher than in the general population, but suicidal attempts themselves are lower. Risk factors for depression include disease onset under age 50, being female, previous history of depression, or severe motor symptoms.Anxiety has been estimated to have a prevalence in PD-affected people usually around 30–40% and up to 60% has been found. Anxiety with PD is complex and consists of symptoms specific to PD. Anxiety can be higher during motor ""off"" periods (times when medication is ineffective) and is likely to be diagnosed after diagnosis due to dysfunction of neurotransmitter pathways. PD-affected people experience panic attacks more frequently compared with the general population. Both anxiety and depression have been found to be associated with decreased quality of life. Symptoms can range from mild and episodic to chronic with potential causes being abnormal gamma-aminobutyric acid levels and embarrassment or fear about symptoms or disease. Risk factors for anxiety in PD are disease onset under age 50, women, and off periods. No standard treatment for PD-associated anxiety exists.Apathy and anhedonia can be defined as a loss of motivation and an impaired ability to experience pleasure and are symptoms classically associated with depression, but differ in PD-affected people in treatment and mechanism. Apathy presents in around 16.5–40%. Symptoms of apathy include reduced initiative/interests in new activities or the world around them, emotional indifference, and loss of affection or concern for others. Apathy is associated with deficits in cognitive functions including executive and verbal memory. Anhedonia occurs in 5–75% of people with PD, depending on the study population assessed and overlap with apathy.Impulse-control disorders, including pathological gambling, compulsive sexual behavior, binge eating, compulsive shopping, and reckless generosity, can be medication-related, particularly orally active dopamine agonists. The dopamine dysregulation syndrome – with wanting of medication contributing to overuse – is a rare complication of levodopa use.Punding, complicated, repetitive, aimless, stereotyped behaviors, is another side effect of anti-Parkinson medication.  Gastrointestinal  Gastrointestinal issues in Parkinson\'s disease include constipation, impaired stomach emptying (gastric dysmotility), and excessive production of saliva can be severe enough to cause discomfort or endanger health. Other upper gastrointestinal symptoms include swallowing impairment (Oropharyngeal dysphagia) and small intestinal bacterial overgrowth.Invidividuals with Parkinson\'s have alpha-synuclein deposits in the digestive tract as well as the brain. Constipation is one of the symptoms associated with an increased risk of PD and may precede diagnosis of PD.  Other  Sleep disorders occur with PD and can be worsened by medications. Symptoms can manifest as daytime drowsiness (including sudden sleep attacks resembling narcolepsy), disturbances in Rapid eye movement sleep, or insomnia. REM behavior disorder may begin years before the development of motor or cognitive elements of PD or dementia with Lewy bodies.Alterations in the autonomic nervous system can lead to orthostatic hypotension (low blood pressure on standing), oily skin, excessive sweating, urinary incontinence, and altered sexual function.Changes in perception may include an impaired sense of smell, disturbed vision, pain, and paresthesia (tingling and numbness). These symptoms can occur years before diagnosis of the disease.  Causes  None of the proposed risk factors have been conclusively proven. The most frequently replicated relationships are an increased risk in those exposed to pesticides and a reduced risk in smokers. A possible link exists between PD and Helicobacter pylori infection that can prevent the absorption of some drugs, including levodopa.  Genetic  Research indicates that PD results from a complex interaction between genetic and environmental factors. Around 15% of diagnosed individuals have a first-degree relative who has the disease, and 5–10% have a mutation in genes. Harboring one of these gene mutations may not lead to the disease; susceptibility factors put them at an increased risk, in combination with other factors, which affect age of onset, severity and progression. At least 11 autosomal dominant and nine autosomal recessive gene mutations have been implicated in the development of PD. The autosomal dominant genes include SNCA, PARK3, UCHL1, LRRK2, GIGYF2, HTRA2, EIF4G1, TMEM230, CHCHD2, RIC3, and VPS35. Autosomal recessive genes include PRKN, PINK1, PARK7, ATP13A2, PLA2G6, FBXO7, DNAJC6, SYNJ1, and VPS13C. Some genes are X-linked or have unknown inheritance pattern; those include PARK10, PARK12, and PARK16. A 22q11 deletion is known to be associated with PD. An autosomal dominant form has been associated with mutations in the LRP10 gene.About 5% of people with PD have mutations in the GBA1 gene. These mutations are present in fewer than 1% of the unaffected population. The risk of developing PD is increased 20–30-fold if these mutations are present. PD associated with these mutations has the same clinical presentation, but an earlier age of onset and a more rapid cognitive and motor decline. This gene encodes glucocerebrosidase. Low levels of this enzyme cause Gaucher\'s disease. Alpha-synuclein, a protein encoded by SNCA gene mutations, is the main component of the Lewy bodies that accumulate in the brains of people with PD. Alpha-synuclein activates ataxia telangiectasia mutated, a major DNA damage-repair signaling kinase. In addition, alpha-synuclein activates the non-homologous end joining DNA repair pathway. The aggregation of alpha-synuclein in Lewy bodies appears to be a link between reduced DNA repair and brain-cell death in PD.Mutations in some genes, including SNCA, LRRK2, and GBA, have been found to be risk factors for sporadic (nonfamilial) PD. Mutations in the gene LRRK2 are the most common known cause of familial and sporadic PD, accounting for around 5% of individuals with a family history of the disease and 3% of sporadic PD. A mutation in GBA presents the greatest genetic risk of developing Parkinsons disease.Parkinson-related genes are involved in the function of lysosomes, organelles that digest cellular waste products. Lysosomal disorders that reduce the ability of cells to break down alpha-synuclein may cause PD.  Non-genetic  Exposure to pesticides and head injury have each been linked with PD, but the risks are low. Not drinking caffeinated beverages is associated with small increases in risk. Some toxins can cause parkinsonism, including manganese and carbon disulfide.Medical drugs are implicated in parkinsonism. Drug-induced parkinsonism is normally reversible by stopping the offending agent, such as phenothiazines (chlorpromazine, promazine, etc.); butyrophenones (haloperidol, benperidol, etc.); metoclopramide and Tetrabenazine. 1-Methyl-4-phenyl-1,2,3,6-tetrahydropyridine (MPTP) is a drug known for causing irreversible parkinsonism that is commonly used in animal-model research.Low concentrations of urate in the blood are associated with an increased risk.Other identifiable causes include infections and metabolic derangement. Neurodegenerative disorders may present with parkinsonism, and are also referred to as atypical parkinsonism or parkinson plus syndromes (illnesses with parkinsonism plus some other symptoms distinguishing them from PD) including multiple system atrophy, progressive supranuclear palsy, corticobasal degeneration, and dementia with Lewy bodies. Dementia with Lewy bodies is another synucleinopathy and it has close pathological similarities with PD, especially with the subset of PD with dementia known as Parkinson\'s disease dementia. The relationship between PD and DLB is complex and incompletely understood. It represents a continuum with variable distinguishing clinical and pathological attributes, or it may prove to be separate diseases.Vascular parkinsonism is the phenomenon of the presence of Parkinson\'s disease symptoms combined with findings of vascular events (such as a cerebral stroke). The damaging of the dopaminergic pathways is similar in cause for both vascular parkinsonism and idiopathic PD, and so present with similar symptoms. Differentiation can be made with careful bedside examination, history evaluation, and imaging.  Pathophysiology  The main pathological characteristics of PD are cell death in the brain\'s basal ganglia (affecting up to 70% of the dopamine-secreting neurons in the substantia nigra pars compacta by the end of life). In Parkinson\'s disease, alpha-synuclein becomes misfolded and clump together with other alpha-synuclein. Cells are unable to remove these clumps, and the alpha-synuclein becomes cytotoxic, damaging the cells. These clumps can be seen in neurons under a microscope and are called Lewy bodies. Loss of neurons is accompanied by the death of astrocytes (star-shaped glial cells) and an increase in the number of microglia (another type of glial cell) in the substantia nigra. Severity of progression of the parts of the brain affected by PD can be measured with Braak staging. According to this staging, PD starts in the medulla and the olfactory bulb before moving to the substantia nigra pars compacta and the rest of the midbrain/basal forebrain. Movement symptom onset is associated when the disease begins to affect the substantia nigra pars compacta. Five major pathways in the brain connect other brain areas to the basal ganglia. These are known as the motor, oculomotor, associative, limbic, and orbitofrontal circuits. Names indicate the main projection area of each circuit. All are affected in PD, and their disruption causes movement-, attention- and learning-related symptoms of the disease. Scientifically, the motor circuit has been examined the most intensively. Since 1980, a particular conceptual model of the motor circuit and its alteration with PD has been of influence although some limitations have been pointed out which have led to modifications. In this model, the basal ganglia normally exert a constant inhibitory influence on a wide range of motor systems, preventing them from becoming active at inappropriate times. When a decision is made to perform a particular action, inhibition is reduced for the required motor system, thereby releasing it for activation. Dopamine acts to facilitate this release of inhibition, so high levels of dopamine function tend to promote motor activity, while low levels of dopamine function, such as occur in PD, demand greater exertions of effort for any given movement. The end result of dopamine depletion is to produce hypokinesia, an overall reduction in motor output. Drugs that are used to treat PD, conversely, may produce excessive dopamine activity, allowing motor systems to be activated at inappropriate times and thereby producing dyskinesias.  Brain cell death  One mechanism causing brain cell death results from abnormal accumulation of the protein alpha-synuclein bound to ubiquitin in damaged cells. This insoluble protein accumulates inside neurons forming inclusions, known as Lewy bodies. These bodies first appear in the olfactory bulb, medulla oblongata and pontine tegmentum; individuals at this stage may be asymptomatic or have early nonmotor symptoms (such as loss of sense of smell or some sleep or automatic dysfunction). As the disease progresses, Lewy bodies develop in the substantia nigra, areas of the midbrain and basal forebrain, and finally, the neocortex. These brain sites are the main places of neuronal degeneration in PD, but Lewy bodies may be protective from cell death (with the abnormal protein sequestered or walled off). Other forms of alpha-synuclein (eg oligomers) that are not aggregated into Lewy bodies and Lewy neurites, may in fact be the toxic forms of the protein. In people with dementia, a generalized presence of Lewy bodies is common in cortical areas. Neurofibrillary tangles and senile plaques, characteristic of Alzheimer\'s disease, are uncommon unless the person has dementia.Other mechanisms include proteasomal and lysosomal systems dysfunction and reduced mitochondrial activity. Iron accumulation in the substantia nigra is typically observed in conjunction with the protein inclusions. It may be related to oxidative stress, protein aggregation, and neuronal death, but the mechanisms are obscure.  The neuroimmune connection  The neuroimmune interaction is heavily implicated in PD pathology. PD and autoimmune disorders share genetic variations and molecular pathways. Some autoimmune diseases may even increase one\'s risk of developing PD, up to 33% in one study. Autoimmune diseases linked to protein expression profiles of monocytes and CD4+ T cells are linked to PD. Herpes virus infections can trigger autoimmune reactions to alpha-synuclein, perhaps through molecular mimicry of viral proteins. Alpha-synuclein, and its aggregate form, Lewy bodies, can bind to microglia. Microglia can proliferate and be over-activated by alpha-synuclein binding to MHC receptors on inflammasomes, bringing about a release of proinflammatory cytokines like IL-1β, IFNγ, and TNFα. Activated microglia influence the activation of astrocytes, converting their neuroprotective phenotype to a neurotoxic one. Astrocytes in healthy brains serve to protect neuronal connections. In PD patients, astrocytes cannot protect the dopaminergic connections in the striatum. Microglia present antigens via MHC-I and MHC-II to T cells. CD4+ T cells, activated by this process, are able to cross the blood brain barrier (BBB) and release more proinflammatory cytokines, like interferon-γ (IFNγ), TNFα, and IL-1β. Mast cell degranulation and subsequent proinflammatory cytokine release is implicated in BBB breakdown in PD. Another immune cell implicated in PD are peripheral monocytes and have been found in the substantia nigra of PD patients. These monocytes can lead to more dopaminergic connection breakdown. In addition, monocytes isolated from PD patients express higher levels of the PD-associated protein, LRRK2, compared with non-PD individuals via vasodilation. In addition, high levels of pro-inflammatory cytokines, such as IL-6, can lead to the production of C-reactive protein by the liver, another protein commonly found in PD patients, that can lead to an increase in peripheral inflammation. Peripheral inflammation can affect the gut-brain axis, an area of the body highly implicated in PD. PD patients have altered gut microbiota and colon problems years before motor issues arise. Alpha-synuclein is produced in the gut and may migrate via the vagus nerve to the brainstem, and then to the substantia nigra. Furthermore, the bacteria Proteus mirabilis has been associated with higher levels of alpha-synuclein and an increase of motor symptoms in PD patients. Further elucidation of the causal role of alpha-synuclein, the role of inflammation, the gut-brain axis, as well as an understanding of the individual differences in immune stress responses is needed to better understand the pathological development of PD.  Diagnosis  Physician\'s initial assessment is typically based on medical history and neurological examination. They access motor symptoms (bradykinesia, rest tremors, etc) using clinical diagnostic criteria. The finding of Lewy bodies in the midbrain on autopsy is usually considered final proof that the person had PD. The clinical course of the illness over time may diverge from PD, requiring that presentation is periodically reviewed to confirm the accuracy of the diagnosis.Multiple causes can occur for parkinsonism or diseases that look similar. Stroke, certain medications, and toxins can cause ""secondary parkinsonism"" and need to be assessed during visit. Parkinson-plus syndromes, such as progressive supranuclear palsy and multiple system atrophy, must be considered and ruled out appropriately to begin a different treatment and disease progression (anti-Parkinson\'s medications are typically less effective at controlling symptoms in Parkinson-plus syndromes). Faster progression rates, early cognitive dysfunction or postural instability, minimal tremor, or symmetry at onset may indicate a Parkinson-plus disease rather than PD itself.Medical organizations have created diagnostic criteria to ease and standardize the diagnostic process, especially in the early stages of the disease. The most widely known criteria come from the UK Queen Square Brain Bank for Neurological Disorders and the U.S. National Institute of Neurological Disorders and Stroke. The Queen Square Brain Bank criteria require slowness of movement (bradykinesia) plus either rigidity, resting tremor, or postural instability. Other possible causes of these symptoms need to be ruled out. Finally, three or more of the following supportive symptoms are required during onset or evolution: unilateral onset, tremor at rest, progression in time, asymmetry of motor symptoms, response to levodopa for at least five years, the clinical course of at least ten years and appearance of dyskinesias induced by the intake of excessive levodopa. Assessment of sudomotor function through electrochemical skin conductance can be helpful in diagnosing dysautonomia.When PD diagnoses are checked by autopsy, movement disorders experts are found on average to be 79.6% accurate at initial assessment and 83.9% accurate after refining diagnoses at follow-up examinations. When clinical diagnoses performed mainly by nonexperts are checked by autopsy, the average accuracy is 73.8%. Overall, 80.6% of PD diagnoses are accurate, and 82.7% of diagnoses using the Brain Bank criteria are accurate.  Imaging  Computed tomography (CT) scans of people with PD usually appear normal. Magnetic resonance imaging has become more accurate in diagnosis of the disease over time, specifically through iron-sensitive T2 and susceptibility weighted imaging sequences at a magnetic field strength of at least 3T, both of which can demonstrate absence of the characteristic \'swallow tail\' imaging pattern in the dorsolateral substantia nigra. In a meta-analysis, absence of this pattern was highly sensitive and specific for the disease. A meta-analysis found that neuromelanin-MRI can discriminate individuals with Parkinson\'s from healthy subjects. Diffusion MRI has shown potential in distinguishing between PD and Parkinson-plus syndromes, as well as between PD motor subtypes, though its diagnostic value is still under investigation. CT and MRI are used to rule out other diseases that can be secondary causes of parkinsonism, most commonly encephalitis and chronic ischemic insults, as well as less-frequent entities such as basal ganglia tumors and hydrocephalus.The metabolic activity of dopamine transporters in the basal ganglia can be directly measured with positron emission tomography and single-photon emission computed tomography scans. It has shown high agreement with clinical diagnoses of PD. Reduced dopamine-related activity in the basal ganglia can help exclude drug-induced Parkinsonism. This finding is nonspecific and can be seen with both PD and Parkinson-plus disorders. In the United States, DaTSCANs are only FDA approved to distinguish PD or Parkinsonian syndromes from essential tremor.Iodine-123-meta-iodobenzylguanidine myocardial scintigraphy can help locate denervation of the muscles of the heart which can support a PD diagnosis.  Differential diagnosis  Secondary parkinsonism – The multiple causes of parkinsonism can be differentiated through careful history, physical examination, and appropriate imaging. This topic is further discussed in the causes section here. Parkinson-plus syndrome – Multiple diseases can be considered part of the Parkinson\'s plus group, including corticobasal syndrome, multiple system atrophy, progressive supranuclear palsy, and dementia with Lewy bodies. Differential diagnosis can be narrowed down with careful history and physical exam (especially focused on the sequential onset of specific symptoms), progression of the disease, and response to treatment. Some key symptoms: Corticobasal syndrome – levodopa-resistance, myoclonus, dystonia, corticosensory loss, apraxia, and non-fluent aphasia Dementia with Lewy bodies – levodopa resistance, cognitive predominance before motor symptoms, and fluctuating cognitive symptoms, (visual hallucinations are common in this disease) Essential tremor – This can at first look like parkinsonism, but has key differentiators. In essential tremor, the tremor gets worse with action (improves in PD), a lack of other symptoms is common in PD, and normal DatSCAN is seen. Multiple system atrophy – levodopa resistance, rapidly progressive, autonomic failure, stridor, present Babinski sign, cerebellar ataxia, and specific MRI findings Progressive supranuclear palsy – levodopa resistance, restrictive vertical gaze, specific MRI findings, and early and different postural difficultiesOther conditions that can have similar presentations to PD include:  Prevention  Exercise in middle age may reduce the risk of PD later in life. Caffeine appears protective with a greater decrease in risk occurring with a larger intake of caffeinated beverages such as coffee.Antioxidants, such as vitamins C and E, have been proposed to protect against the disease, but results of studies have been contradictory and no positive effect has been shown. The results regarding fat and fatty acids have been contradictory. Use of nonsteroidal anti-inflammatory drugs (NSAIDs) and calcium channel blockers may be protective. A 2010 meta-analysis found that NSAIDs (apart from aspirin), have been associated with at least a 15% (higher in long-term and regular users) reduction in the incidence of the development of PD. As of 2019 meta-analyses have failed to confirm this link. Multiple studies have demonstrated a link between the use of ibuprofen and a decreased risk of Parkinson\'s development.  Management  No cure for Parkinson\'s disease is known. Medications, surgery, and physical treatment may provide relief, improve the quality of a person\'s life, and are much more effective than treatments for other neurological disorders such as Alzheimer\'s disease, motor neuron disease, and Parkinson-plus syndromes. The main families of drugs useful for treating motor symptoms are levodopa always combined with a dopa decarboxylase inhibitor and with a COMT inhibitor, dopamine agonists, and MAO-B inhibitors. The stage of the disease and the age at disease onset determine which group is most useful.Braak staging of PD uses six stages that can identify early, middle, and late stages. The initial stage in which some disability has already developed and requires pharmacological treatment is followed by later stages associated with the development of complications related to levodopa usage, and a third stage when symptoms unrelated to dopamine deficiency or levodopa treatment may predominate.Treatment in the first stage aims for an optimal trade-off between symptom control and treatment side effects. The start of levodopa treatment may be postponed by initially using other medications, such as MAO-B inhibitors and dopamine agonists, instead, in the hope of delaying the onset of complications due to levodopa use. Levodopa is still the most effective treatment for the motor symptoms of PD and treatment should be prompt in people when their quality of life is impaired. Levodopa-related dyskinesias correlate more strongly with duration and severity of the disease than duration of levodopa treatment.In later stages, the aim is to reduce PD symptoms, while controlling fluctuations in the effect of the medication. Sudden withdrawals from medication or its overuse must be managed. When oral medications are inadequate in controlling symptoms, surgery (deep brain stimulation or high-intensity focused ultrasound), subcutaneous waking-day apomorphine infusion, and enteral dopa pumps may be useful. Late-stage PD presents challenges requiring a variety of treatments, including those for psychiatric symptoms particularly depression, orthostatic hypotension, bladder dysfunction, and erectile dysfunction. In the final stages of the disease, palliative care is provided to improve a person\'s quality of life.A 2020 Cochrane review found no certain evidence that cognitive training is beneficial for people with Parkinson\'s disease, dementia or mild cognitive impairment. The findings are based on low certainty evidence of seven studies.  Medications   Levodopa  Levodopa is usually the first drug of choice when treating Parkinson\'s disease and has been the most widely used PD treatment since the 1980s. The motor symptoms of PD are the result of reduced dopamine production in the brain\'s basal ganglia. Dopamine fails to cross the blood–brain barrier so it cannot be taken as a medicine to boost the brain\'s depleted levels of dopamine. A precursor of dopamine, levodopa, can pass through to the brain where it is readily converted to dopamine. Administration of levodopa temporarily diminishes the motor symptoms of PD. Only 5–10% of levodopa crosses the blood–brain barrier. Much of the remainder is metabolized to dopamine elsewhere in the body, causing a variety of side effects, including nausea, vomiting, and orthostatic hypotension. Carbidopa and benserazide are dopa decarboxylase inhibitors that fails to cross the blood–brain barrier and inhibit the conversion of levodopa to dopamine outside the brain, reducing side effects and improving the availability of levodopa for passage into the brain. One of these drugs is usually taken along with levodopa and is availible combined with levodopa in the same pill.Prlonged use of levodopa is associated with the development of complications, such as involuntary movements (dyskinesias) and fluctuations in the impact of the medication. When fluctuations occur, a person can cycle through phases with good response to medication and reduced PD symptoms (on state), and phases with poor response to medication and increased PD symptoms (off state).: 1989 Using lower doses of levodopa may reduce the risk and severity of these levodopa-induced complications. A former strategy, called ""drug holidays"", to reduce levodopa-related dyskinesia and fluctuations was to withdraw levodopa medication for some time which can bring on dangerous side effects such as neuroleptic malignant syndrome and is discouraged. Most people with PD eventually need levodopa and later develop levodopa-induced fluctuations and dyskinesias. Adverse effects of levodopa, including dyskinesias, mistakenly influence patients and providers to delay treatment which reduces potential for optimal results. Levodopa by itself is available in oral (tablets and capsules), oral inhalation, and infusion form. Inhaled levodopa can be used when oral levodopa therapy has reached a point where ""off"" periods have increased in length.  COMT inhibitors  During the course of PD, affected people can experience a wearing-off phenomenon, where a recurrence of symptoms occurs after a dose of levodopa, but right before their next dose. Catechol-O-methyltransferase (COMT) is a protein that degrades levodopa before it can cross the blood–brain barrier and these inhibitors allow for more levodopa to cross. They are normally used in the management of later symptoms, but can be used in conjunction with levodopa/carbidopa when a person is experiencing the wearing off-phenomenon with their motor symptoms.Three COMT inhibitors are used to treat adults with PD and end-of-dose motor fluctuations – opicapone, entacapone, and tolcapone. Tolcapone has been available for but its usefulness is limited by possible liver damage complications requiring liver-function monitoring. Entacapone and opicapone cause little alteration to liver function. Licensed preparations of entacapone contain entacapone alone or in combination with carbidopa and levodopa. Opicapone is a once-daily COMT inhibitor.  Dopamine agonists  Dopamine agonists that bind to dopamine receptors in the brain have similar effects to levodopa. These were initially used as a complementary therapy to levodopa for individuals experiencing levodopa complications (on-off fluctuations and dyskinesias); they are mainly used on their own as first therapy for the motor symptoms of PD with the aim of delaying the initiation of levodopa therapy, thus delaying the onset of levodopa\'s complications. Dopamine agonists include bromocriptine, pergolide, pramipexole, ropinirole, piribedil, cabergoline, apomorphine, and lisuride. Though dopamine agonists are less effective than levodopa at controlling PD motor symptoms, they are effective enough to manage these symptoms in the first years of treatment. Dyskinesias due to dopamine agonists are rare in younger people who have PD, but along with other complications, become more common with older age at onset. Thus, dopamine agonists are the preferred initial treatment for younger-onset PD, and levodopa is preferred for older-onset PD.Dopamine agonists produce side effects, including drowsiness, hallucinations, insomnia, nausea, and constipation. Side effects appear with minimal clinically effective doses giving the physician reason to search for a different drug. Agonists have been related to impulse-control disorders (such as increased sexual activity, eating, gambling, and shopping) more strongly than other antiparkinson medications. They tend to be more expensive than levodopa.Apomorphine, a dopamine agonist, may be used to reduce off periods and dyskinesia in late PD. It is administered only by intermittent injections or continuous subcutaneous infusions. Secondary effects such as confusion and hallucinations are common, individuals receiving apomorphine treatment should be closely monitored. Two dopamine agonists administered through skin patches (lisuride and rotigotine) are useful for people in the initial stages and possibly to control off states in those in advanced states. Due to an increased risk of cardiac fibrosis with ergot-derived dopamine agonists (bromocriptine, cabergoline, dihydroergocryptine, lisuride, and pergolide), they should only be considered for adjunct therapy to levodopa.  MAO-B inhibitors  MAO-B inhibitors (safinamide, selegiline and rasagiline) increase the amount of dopamine in the basal ganglia by inhibiting the activity of monoamine oxidase B, an enzyme that breaks down dopamine. They have been found to help alleviate motor symptoms when used as monotherapy (on their own); when used in conjunction with levodopa, time spent in the off phase is reduced.: 1924 Selegiline has been shown to delay the need for beginning levodopa, suggesting that it might be neuroprotective and slow the progression of the disease. An initial study indicated that selegiline in combination with levodopa increased the risk of death, but this has been refuted.Common side effects are nausea, dizziness, insomnia, sleepiness, and (in selegiline and rasagiline) orthostatic hypotension. MAO-Bs are known to increase serotonin and cause a potentially dangerous condition known as serotonin syndrome.  Other drugs  Other drugs such as amantadine may be useful as treatment of motor symptoms, but evidence for use is lacking. Anticholinergics should not be used for dyskinesia or motor fluctuations but may be considered topically for drooling. A diverse range of symptoms beyond those related to motor function can be treated pharmaceutically. Examples are the use of quetiapine or clozapine for psychosis, cholinesterase inhibitors or memantine for dementia, and modafinil for excessive daytime sleepiness. In 2016, pimavanserin was approved for the management of PD psychosis. Doxepin and rasagline may reduce physical fatigue in PD.  Surgery  Treating motor symptoms with surgery was once a common practice but the discovery of levodopa has decreased the amount of procedures. Studies have led to great improvements in surgical techniques, so surgery can be used in people with advanced PD for who drug therapy is no longer sufficient. Surgery for PD can be divided in two main groups – lesional and deep brain stimulation (DBS). Target areas for DBS or lesions include the thalamus, globus pallidus, or subthalamic nucleus. DBS involves the implantation of a medical device called a neurostimulator, which sends electrical impulses to specific parts of the brain. DBS is recommended for people who have PD with motor fluctuations and tremor inadequately controlled by medication, or to those who are intolerant to medication lacking severe neuropsychiatric problems. Other less common surgical therapies involve intentional formation of lesions to suppress overactivity of specific subcortical areas. For example, pallidotomy involves surgical destruction of the globus pallidus to control dyskinesia.Four areas of the brain have been treated with neural stimulators in PD. These are the globus pallidus interna, thalamus, subthalamic nucleus, and pedunculopontine nucleus. DBS of the globus pallidus interna improves motor function, while DBS of the thalamic DBS improves tremor, but has little impact on bradykinesia or rigidity. DBS of the subthalamic nucleus is usually avoided if a history of depression or neurocognitive impairment is present. DBS of the subthalamic nucleus is associated with a reduction in medication. Pedunculopontine nucleus DBS remains experimental at present. Generally, DBS is associated with 30–60% improvement in motor score evaluations.  Rehabilitation  Exercise programs are recommended in people with PD. Some evidence shows that speech or mobility problems can improve with rehabilitation, although studies are scarce and of low quality. Regular physical exercise with or without physical therapy can be beneficial to maintain and improve mobility, flexibility, strength, gait speed, and quality of life. When an exercise program is performed under the supervision of a physiotherapist, more improvements occur in motor symptoms, mental and emotional functions, daily living activities, and quality of life compared with a self-supervised exercise program at home. Clinical exercises may be an effective intervention targeting overall well-being of individuals with Parkinson\'s. Improvement in motor function and depression may happen.In improving flexibility and range of motion for people experiencing rigidity, generalized relaxation techniques such as gentle rocking have been found to decrease excessive muscle tension. Other effective techniques to promote relaxation include slow rotational movements of the extremities and trunk, rhythmic initiation, diaphragmatic breathing, and meditation techniques. As for gait and addressing the challenges associated with the disease such as hypokinesia, shuffling, and decreased arm swing, physiotherapists have a variety of strategies to improve functional mobility and safety. Areas of interest concerning gait during rehabilitation programs focus on improving gait speed, the base of support, stride length, and trunk and arm-swing movement. Strategies include using assistive equipment (pole walking and treadmill walking), verbal cueing (manual, visual, and auditory), exercises (marching and PNF patterns), and altering environments (surfaces, inputs, open vs. closed).","Parkinson's disease (or PD, sometimes simply ""Parkinson's"") is a disease that slowly damages the central nervous system. The central nervous system is made up of the brain and spine. When a person gets Parkinson's disease, the cells that make dopamine in a part of the brain die. Dopamine cells send information to other cells which makes us do the actions we do. Because of this, Parkinson's disease mainly affects the body's motor system. Parkinson's disease is a disease that gets worse over time. People normally get Parkinson's disease when they are over 50 years old. It is sometimes very hard for doctors to detect.  Causes  Doctors are studying the exact causes of Parkinson's. It is said that Parkinson's develops through a combination of genetic errors and several possible influences, but not much is known. Doctors have discovered some clues about the cause(s). It is caused by the destruction of specialised ganglions in the brain. The production of dopamine, a neurotransmitter, reduces. Parkinson's can also be genetic. But research shows that genetic Parkinson's is not normal, and is uncommon. Parkinson's disease is more frequent among those who work with pesticides or have had a history of head injuries.Research suggests that people are slightly less likely to get Parkinson's disease if they smoke cigarettes.  Symptoms  Parkinson's disease can cause the brain to not respond. The patient may become paralyzed. The disease can give the patient slow reaction time and poor coordination between the hand and the brain. It hurts the patient's movement skills and their speech. It can also affect mood, behavior and thinking. A common symptom of Parkinson’s disease is tremors. Tremors cause people's hands, legs, and arms to shake. Some symptoms include skin problems, depression, and difficulty swallowing.The symptoms of Parkinson's disease include stiff muscles and trouble with movement. This disease gives patients slow reaction time. It makes it hard for them to do simple things like walking and talking. It also causes depression and other emotional changes.  Treatments  Parkinson's disease cannot be completely cured yet. Still, people have tried to cure it with drugs. One treatment is to put back the lost dopamine. A group of drugs called dopamine receptor agonists acts similarly to dopamine when put in the brain. There are four different drugs included in that group. Many patients take one of those with another drug. That other drug is called L-dopa. Unlike the dopamine, the L-dopa can enter the brain. The dopamine cannot enter the brain. This is why many patients take L-dopa and dopamine together. In the beginning, L-dopa helps a lot. But as the disease develops, the L-dopa doesn't work as well. Two other drugs used are anticholinergics and selegiline. They both help lessen symptoms. Anticholinergics help the patient stop shaking. Selegiline is meant to protect the nerves in the central nervous system. Selegiline is not often used. This is because there is no real proof that it helps.Deep Brain Stimulation (DBS) is a surgery that is used some people who suffer from Parkinson's disease.  References   Other websites  National Parkinson Foundation Asociacion Parkinson TARAY Aranjuez MADRID ESPAÑA Parkinson's Disease Society of the United Kingdom Blechman Foundation for Parkinson's Research"
"A stroke is a medical condition in which poor blood flow to the brain causes cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. Both cause parts of the brain to stop functioning properly.Signs and symptoms of a stroke may include an inability to move or feel on one side of the body, problems understanding or speaking, dizziness, or loss of vision to one side. Signs and symptoms often appear soon after the stroke has occurred. If symptoms last less than one or two hours, the stroke is a transient ischemic attack (TIA), also called a mini-stroke. A hemorrhagic stroke may also be associated with a severe headache. The symptoms of a stroke can be permanent. Long-term complications may include pneumonia and loss of bladder control.The biggest risk factor for stroke is high blood pressure. Other risk factors include high blood cholesterol, tobacco smoking, obesity, diabetes mellitus, a previous TIA, end-stage kidney disease, and atrial fibrillation. An ischemic stroke is typically caused by blockage of a blood vessel, though there are also less common causes. A hemorrhagic stroke is caused by either bleeding directly into the brain or into the space between the brain\'s membranes. Bleeding may occur due to a ruptured brain aneurysm. Diagnosis is typically based on a physical exam and supported by medical imaging such as a CT scan or MRI scan. A CT scan can rule out bleeding, but may not necessarily rule out ischemia, which early on typically does not show up on a CT scan. Other tests such as an electrocardiogram (ECG) and blood tests are done to determine risk factors and rule out other possible causes. Low blood sugar may cause similar symptoms.Prevention includes decreasing risk factors, surgery to open up the arteries to the brain in those with problematic carotid narrowing, and warfarin in people with atrial fibrillation. Aspirin or statins may be recommended by physicians for prevention. A stroke or TIA often requires emergency care. An ischemic stroke, if detected within three to four and half hours, may be treatable with a medication that can break down the clot. Some hemorrhagic strokes benefit from surgery. Treatment to attempt recovery of lost function is called stroke rehabilitation, and ideally takes place in a stroke unit; however, these are not available in much of the world.In 2013, approximately 6.9 million people had an ischemic stroke and 3.4 million people had a hemorrhagic stroke. In 2015, there were about 42.4 million people who had previously had a stroke and were still alive. Between 1990 and 2010 the number of strokes which occurred each year decreased by approximately 10% in the developed world and increased by 10% in the developing world. In 2015, stroke was the second most frequent cause of death after coronary artery disease, accounting for 6.3 million deaths (11% of the total). About 3.0 million deaths resulted from ischemic stroke while 3.3 million deaths resulted from hemorrhagic stroke. About half of people who have had a stroke live less than one year. Overall, two thirds of strokes occurred in those over 65 years old.  Classification  Strokes can be classified into two major categories: ischemic and hemorrhagic. Ischemic strokes are caused by interruption of the blood supply to the brain, while hemorrhagic strokes result from the rupture of a blood vessel or an abnormal vascular structure. About 87% of strokes are ischemic, the rest being hemorrhagic. Bleeding can develop inside areas of ischemia, a condition known as ""hemorrhagic transformation."" It is unknown how many hemorrhagic strokes actually start as ischemic strokes.  Definition  In the 1970s the World Health Organization defined stroke as a ""neurological deficit of cerebrovascular cause that persists beyond 24 hours or is interrupted by death within 24 hours"", although the word ""stroke"" is centuries old. This definition was supposed to reflect the reversibility of tissue damage and was devised for the purpose, with the time frame of 24 hours being chosen arbitrarily. The 24-hour limit divides stroke from transient ischemic attack, which is a related syndrome of stroke symptoms that resolve completely within 24 hours. With the availability of treatments that can reduce stroke severity when given early, many now prefer alternative terminology, such as brain attack and acute ischemic cerebrovascular syndrome (modeled after heart attack and acute coronary syndrome, respectively), to reflect the urgency of stroke symptoms and the need to act swiftly.  Ischemic  In an ischemic stroke, blood supply to part of the brain is decreased, leading to dysfunction of the brain tissue in that area. There are four reasons why this might happen: Thrombosis (obstruction of a blood vessel by a blood clot forming locally) Embolism (obstruction due to an embolus from elsewhere in the body), Systemic hypoperfusion (general decrease in blood supply, e.g., in shock) Cerebral venous sinus thrombosis.A stroke without an obvious explanation is termed a cryptogenic stroke (idiopathic); this constitutes 30–40% of all ischemic strokes.There are various classification systems for acute ischemic stroke. The Oxford Community Stroke Project classification (OCSP, also known as the Bamford or Oxford classification) relies primarily on the initial symptoms; based on the extent of the symptoms, the stroke episode is classified as total anterior circulation infarct (TACI), partial anterior circulation infarct (PACI), lacunar infarct (LACI) or posterior circulation infarct (POCI). These four entities predict the extent of the stroke, the area of the brain that is affected, the underlying cause, and the prognosis. The TOAST (Trial of Org 10172 in Acute Stroke Treatment) classification is based on clinical symptoms as well as results of further investigations; on this basis, a stroke is classified as being due to (1) thrombosis or embolism due to atherosclerosis of a large artery, (2) an embolism originating in the heart, (3) complete blockage of a small blood vessel, (4) other determined cause, (5) undetermined cause (two possible causes, no cause identified, or incomplete investigation). Users of stimulants such as cocaine and methamphetamine are at a high risk for ischemic strokes.  Hemorrhagic  There are two main types of hemorrhagic stroke: Intracerebral hemorrhage, which is basically bleeding within the brain itself (when an artery in the brain bursts, flooding the surrounding tissue with blood), due to either intraparenchymal hemorrhage (bleeding within the brain tissue) or intraventricular hemorrhage (bleeding within the brain\'s ventricular system). Subarachnoid hemorrhage, which is basically bleeding that occurs outside of the brain tissue but still within the skull, and precisely between the arachnoid mater and pia mater (the delicate innermost layer of the three layers of the meninges that surround the brain).The above two main types of hemorrhagic stroke are also two different forms of intracranial hemorrhage, which is the accumulation of blood anywhere within the cranial vault; but the other forms of intracranial hemorrhage, such as epidural hematoma (bleeding between the skull and the dura mater, which is the thick outermost layer of the meninges that surround the brain) and subdural hematoma (bleeding in the subdural space), are not considered ""hemorrhagic strokes"".Hemorrhagic strokes may occur on the background of alterations to the blood vessels in the brain, such as cerebral amyloid angiopathy, cerebral arteriovenous malformation and an intracranial aneurysm, which can cause intraparenchymal or subarachnoid hemorrhage.In addition to neurological impairment, hemorrhagic strokes usually cause specific symptoms (for instance, subarachnoid hemorrhage classically causes a severe headache known as a thunderclap headache) or reveal evidence of a previous head injury.  Signs and symptoms  Stroke symptoms typically start suddenly, over seconds to minutes, and in most cases do not progress further. The symptoms depend on the area of the brain affected. The more extensive the area of the brain affected, the more functions that are likely to be lost. Some forms of stroke can cause additional symptoms. For example, in intracranial hemorrhage, the affected area may compress other structures. Most forms of stroke are not associated with a headache, apart from subarachnoid hemorrhage and cerebral venous thrombosis and occasionally intracerebral hemorrhage.  Early recognition  Various systems have been proposed to increase recognition of stroke. Different findings are able to predict the presence or absence of stroke to different degrees. Sudden-onset face weakness, arm drift (i.e., if a person, when asked to raise both arms, involuntarily lets one arm drift downward) and abnormal speech are the findings most likely to lead to the correct identification of a case of stroke, increasing the likelihood by 5.5 when at least one of these is present. Similarly, when all three of these are absent, the likelihood of stroke is decreased (– likelihood ratio of 0.39). While these findings are not perfect for diagnosing stroke, the fact that they can be evaluated relatively rapidly and easily make them very valuable in the acute setting. A mnemonic to remember the warning signs of stroke is FAST (facial droop, arm weakness, speech difficulty, and time to call emergency services), as advocated by the Department of Health (United Kingdom) and the Stroke Association, the American Stroke Association, the National Stroke Association (US), the Los Angeles Prehospital Stroke Screen (LAPSS) and the Cincinnati Prehospital Stroke Scale (CPSS). Use of these scales is recommended by professional guidelines. FAST is less reliable in the recognition of posterior circulation strokes.For people referred to the emergency room, early recognition of stroke is deemed important as this can expedite diagnostic tests and treatments. A scoring system called ROSIER (recognition of stroke in the emergency room) is recommended for this purpose; it is based on features from the medical history and physical examination.  Subtypes  If the area of the brain affected includes one of the three prominent central nervous system pathways—the spinothalamic tract, corticospinal tract, and the dorsal column–medial lemniscus pathway, symptoms may include: hemiplegia and muscle weakness of the face numbness reduction in sensory or vibratory sensation initial flaccidity (reduced muscle tone), replaced by spasticity (increased muscle tone), excessive reflexes, and obligatory synergies.In most cases, the symptoms affect only one side of the body (unilateral). Depending on the part of the brain affected, the defect in the brain is usually on the opposite side of the body. However, since these pathways also travel in the spinal cord and any lesion there can also produce these symptoms, the presence of any one of these symptoms does not necessarily indicate a stroke. In addition to the above CNS pathways, the brainstem gives rise to most of the twelve cranial nerves. A brainstem stroke affecting the brainstem and brain, therefore, can produce symptoms relating to deficits in these cranial nerves: altered smell, taste, hearing, or vision (total or partial) drooping of eyelid (ptosis) and weakness of ocular muscles decreased reflexes: gag, swallow, pupil reactivity to light decreased sensation and muscle weakness of the face balance problems and nystagmus altered breathing and heart rate weakness in sternocleidomastoid muscle with inability to turn head to one side weakness in tongue (inability to stick out the tongue or move it from side to side)If the cerebral cortex is involved, the CNS pathways can again be affected, but also can produce the following symptoms: aphasia (difficulty with verbal expression, auditory comprehension, reading and writing; Broca\'s or Wernicke\'s area typically involved) dysarthria (motor speech disorder resulting from neurological injury) apraxia (altered voluntary movements) visual field defect memory deficits (involvement of temporal lobe) hemineglect (involvement of parietal lobe) disorganized thinking, confusion, hypersexual gestures (with involvement of frontal lobe) lack of insight of his or her, usually stroke-related, disabilityIf the cerebellum is involved, ataxia might be present and this includes: altered walking gait altered movement coordination vertigo and or disequilibrium  Associated symptoms  Loss of consciousness, headache, and vomiting usually occur more often in hemorrhagic stroke than in thrombosis because of the increased intracranial pressure from the leaking blood compressing the brain. If symptoms are maximal at onset, the cause is more likely to be a subarachnoid hemorrhage or an embolic stroke.  Causes   Thrombotic stroke  In thrombotic stroke, a thrombus (blood clot) usually forms around atherosclerotic plaques. Since blockage of the artery is gradual, onset of symptomatic thrombotic strokes is slower than that of a hemorrhagic stroke. A thrombus itself (even if it does not completely block the blood vessel) can lead to an embolic stroke (see below) if the thrombus breaks off and travels in the bloodstream, at which point it is called an embolus. Two types of thrombosis can cause stroke: Large vessel disease involves the common and internal carotid arteries, the vertebral artery, and the Circle of Willis. Diseases that may form thrombi in the large vessels include (in descending incidence): atherosclerosis, vasoconstriction (tightening of the artery), aortic, carotid or vertebral artery dissection, various inflammatory diseases of the blood vessel wall (Takayasu arteritis, giant cell arteritis, vasculitis), noninflammatory vasculopathy, Moyamoya disease and fibromuscular dysplasia. Small vessel disease involves the smaller arteries inside the brain: branches of the circle of Willis, middle cerebral artery, stem, and arteries arising from the distal vertebral and basilar artery. Diseases that may form thrombi in the small vessels include (in descending incidence): lipohyalinosis (build-up of fatty hyaline matter in the blood vessel as a result of high blood pressure and aging) and fibrinoid degeneration (a stroke involving these vessels is known as a lacunar stroke) and microatheroma (small atherosclerotic plaques).Anemia causes increase blood flow in the blood circulatory system. This causes the endothelial cells of the blood vessels to express adhesion factors which encourages the clotting of blood and formation of thrombus. Sickle-cell anemia, which can cause blood cells to clump up and block blood vessels, can also lead to stroke. A stroke is the second leading cause of death in people under 20 with sickle-cell anemia. Air pollution may also increase stroke risk.  Embolic stroke  An embolic stroke refers to an arterial embolism (a blockage of an artery) by an embolus, a traveling particle or debris in the arterial bloodstream originating from elsewhere. An embolus is most frequently a thrombus, but it can also be a number of other substances including fat (e.g., from bone marrow in a broken bone), air, cancer cells or clumps of bacteria (usually from infectious endocarditis).Because an embolus arises from elsewhere, local therapy solves the problem only temporarily. Thus, the source of the embolus must be identified. Because the embolic blockage is sudden in onset, symptoms usually are maximal at the start. Also, symptoms may be transient as the embolus is partially resorbed and moves to a different location or dissipates altogether. Emboli most commonly arise from the heart (especially in atrial fibrillation) but may originate from elsewhere in the arterial tree. In paradoxical embolism, a deep vein thrombosis embolizes through an atrial or ventricular septal defect in the heart into the brain.Causes of stroke related to the heart can be distinguished between high and low-risk: High risk: atrial fibrillation and paroxysmal atrial fibrillation, rheumatic disease of the mitral or aortic valve disease, artificial heart valves, known cardiac thrombus of the atrium or ventricle, sick sinus syndrome, sustained atrial flutter, recent myocardial infarction, chronic myocardial infarction together with ejection fraction <28 percent, symptomatic congestive heart failure with ejection fraction <30 percent, dilated cardiomyopathy, Libman-Sacks endocarditis, Marantic endocarditis, infective endocarditis, papillary fibroelastoma, left atrial myxoma and coronary artery bypass graft (CABG) surgery. Low risk/potential: calcification of the annulus (ring) of the mitral valve, patent foramen ovale (PFO), atrial septal aneurysm, atrial septal aneurysm with patent foramen ovale, left ventricular aneurysm without thrombus, isolated left atrial ""smoke"" on echocardiography (no mitral stenosis or atrial fibrillation), complex atheroma in the ascending aorta or proximal arch.Among those who have a complete blockage of one of the carotid arteries, the risk of stroke on that side is about one percent per year.A special form of embolic stroke is the embolic stroke of undetermined source (ESUS). This subset of cryptogenic stroke is defined as a non-lacunar brain infarct without proximal arterial stenosis or cardioembolic sources. About one out of six ischemic strokes could be classified as ESUS.  Cerebral hypoperfusion  Cerebral hypoperfusion is the reduction of blood flow to all parts of the brain. The reduction could be to a particular part of the brain depending on the cause. It is most commonly due to heart failure from cardiac arrest or arrhythmias, or from reduced cardiac output as a result of myocardial infarction, pulmonary embolism, pericardial effusion, or bleeding. Hypoxemia (low blood oxygen content) may precipitate the hypoperfusion. Because the reduction in blood flow is global, all parts of the brain may be affected, especially vulnerable ""watershed"" areas—border zone regions supplied by the major cerebral arteries. A watershed stroke refers to the condition when the blood supply to these areas is compromised. Blood flow to these areas does not necessarily stop, but instead it may lessen to the point where brain damage can occur.  Venous thrombosis  Cerebral venous sinus thrombosis leads to stroke due to locally increased venous pressure, which exceeds the pressure generated by the arteries. Infarcts are more likely to undergo hemorrhagic transformation (leaking of blood into the damaged area) than other types of ischemic stroke.  Intracerebral hemorrhage  It generally occurs in small arteries or arterioles and is commonly due to hypertension, intracranial vascular malformations (including cavernous angiomas or arteriovenous malformations), cerebral amyloid angiopathy, or infarcts into which secondary hemorrhage has occurred. Other potential causes are trauma, bleeding disorders, amyloid angiopathy, illicit drug use (e.g., amphetamines or cocaine). The hematoma enlarges until pressure from surrounding tissue limits its growth, or until it decompresses by emptying into the ventricular system, CSF or the pial surface. A third of intracerebral bleed is into the brain\'s ventricles. ICH has a mortality rate of 44 percent after 30 days, higher than ischemic stroke or subarachnoid hemorrhage (which technically may also be classified as a type of stroke).  Other  Other causes may include spasm of an artery. This may occur due to cocaine.  Silent stroke  A silent stroke is a stroke that does not have any outward symptoms, and people are typically unaware they have had a stroke. Despite not causing identifiable symptoms, a silent stroke still damages the brain and places the person at increased risk for both transient ischemic attack and major stroke in the future. Conversely, those who have had a major stroke are also at risk of having silent strokes. In a broad study in 1998, more than 11 million people were estimated to have experienced a stroke in the United States. Approximately 770,000 of these strokes were symptomatic and 11 million were first-ever silent MRI infarcts or hemorrhages. Silent strokes typically cause lesions which are detected via the use of neuroimaging such as MRI. Silent strokes are estimated to occur at five times the rate of symptomatic strokes. The risk of silent stroke increases with age, but may also affect younger adults and children, especially those with acute anemia.  Pathophysiology   Ischemic  Ischemic stroke occurs because of a loss of blood supply to part of the brain, initiating the ischemic cascade. Atherosclerosis may disrupt the blood supply by narrowing the lumen of blood vessels leading to a reduction of blood flow by causing the formation of blood clots within the vessel or by releasing showers of small emboli through the disintegration of atherosclerotic plaques. Embolic infarction occurs when emboli formed elsewhere in the circulatory system, typically in the heart as a consequence of atrial fibrillation, or in the carotid arteries, break off, enter the cerebral circulation, then lodge in and block brain blood vessels. Since blood vessels in the brain are now blocked, the brain becomes low in energy, and thus it resorts to using anaerobic metabolism within the region of brain tissue affected by ischemia. Anaerobic metabolism produces less adenosine triphosphate (ATP) but releases a by-product called lactic acid. Lactic acid is an irritant which could potentially destroy cells since it is an acid and disrupts the normal acid-base balance in the brain. The ischemia area is referred to as the ""ischemic penumbra"". After the initial ischemic event the penumbra transitions from a tissue remodeling characterized by damage to a remodeling characterized by repair. As oxygen or glucose becomes depleted in ischemic brain tissue, the production of high energy phosphate compounds such as adenosine triphosphate (ATP) fails, leading to failure of energy-dependent processes (such as ion pumping) necessary for tissue cell survival. This sets off a series of interrelated events that result in cellular injury and death. A major cause of neuronal injury is the release of the excitatory neurotransmitter glutamate. The concentration of glutamate outside the cells of the nervous system is normally kept low by so-called uptake carriers, which are powered by the concentration gradients of ions (mainly Na+) across the cell membrane. However, stroke cuts off the supply of oxygen and glucose which powers the ion pumps maintaining these gradients. As a result, the transmembrane ion gradients run down, and glutamate transporters reverse their direction, releasing glutamate into the extracellular space. Glutamate acts on receptors in nerve cells (especially NMDA receptors), producing an influx of calcium which activates enzymes that digest the cells\' proteins, lipids, and nuclear material. Calcium influx can also lead to the failure of mitochondria, which can lead further toward energy depletion and may trigger cell death due to programmed cell death.Ischemia also induces production of oxygen free radicals and other reactive oxygen species. These react with and damage a number of cellular and extracellular elements. Damage to the blood vessel lining or endothelium may occur. These processes are the same for any type of ischemic tissue and are referred to collectively as the ischemic cascade. However, brain tissue is especially vulnerable to ischemia since it has little respiratory reserve and is completely dependent on aerobic metabolism, unlike most other organs.  Collateral flow  The brain can compensate inadequate blood flow in a single artery by the collateral system. This system relies on the efficient connection between the carotid and vertebral arteries through the circle of Willis and, to a lesser extent, the major arteries supplying the cerebral hemispheres. However, variations in the circle of Willis, caliber of collateral vessels, and acquired arterial lesions such as atherosclerosis can disrupt this compensatory mechanism, increasing the risk of brain ischemia resulting from artery blockage.The extent of damage depends on the duration and severity of the ischemia. If ischemia persists for more than 5 minutes with perfusion below 5% of normal, some neurons will die. However, if ischemia is mild, the damage will occur slowly and may take up to 6 hours to completely destroy the brain tissue. In case of severe ischemia lasting more than 15 to 30 minutes, all of the affected tissue will die, leading to infarction. The rate of damage is affected by temperature, with hyperthermia accelerating damage and hypothermia slowing it down and various other factors. Prompt restoration of blood flow to ischemic tissues can reduce or reverse injury, especially if the tissues are not yet irreversibly damaged. This is particularly important for the moderately ischemic areas (penumbras) surrounding areas of severe ischemia, which may still be salvageable due to collateral flow.  Hemorrhagic  Hemorrhagic strokes are classified based on their underlying pathology. Some causes of hemorrhagic stroke are hypertensive hemorrhage, ruptured aneurysm, ruptured AV fistula, transformation of prior ischemic infarction, and drug-induced bleeding. They result in tissue injury by causing compression of tissue from an expanding hematoma or hematomas. In addition, the pressure may lead to a loss of blood supply to affected tissue with resulting infarction, and the blood released by brain hemorrhage appears to have direct toxic effects on brain tissue and vasculature. Inflammation contributes to the secondary brain injury after hemorrhage.  Diagnosis  Stroke is diagnosed through several techniques: a neurological examination (such as the NIHSS), CT scans (most often without contrast enhancements) or MRI scans, Doppler ultrasound, and arteriography. The diagnosis of stroke itself is clinical, with assistance from the imaging techniques. Imaging techniques also assist in determining the subtypes and cause of stroke. There is yet no commonly used blood test for the stroke diagnosis itself, though blood tests may be of help in finding out the likely cause of stroke. In deceased people, an autopsy of stroke may help establishing the time between stroke onset and death.  Physical examination  A physical examination, including taking a medical history of the symptoms and a neurological status, helps giving an evaluation of the location and severity of a stroke. It can give a standard score on e.g., the NIH stroke scale.  Imaging  For diagnosing ischemic (blockage) stroke in the emergency setting: CT scans (without contrast enhancements) sensitivity 16% (less than 10% within first 3 hours of symptom onset) specificity 96%MRI scan sensitivity 83% specificity 98%For diagnosing hemorrhagic stroke in the emergency setting: CT scans (without contrast enhancements) sensitivity 89% specificity 100%MRI scan sensitivity 81% specificity 100%For detecting chronic hemorrhages, an MRI scan is more sensitive.For the assessment of stable stroke, nuclear medicine scans such as single-photon emission computed tomography (SPECT) and positron emission tomography–computed tomography (PET/CT) may be helpful. SPECT documents cerebral blood flow, whereas PET with an FDG isotope shows cerebral glucose metabolism. CT scans may not detect an ischemic stroke, especially if it is small, of recent onset, or in the brainstem or cerebellum areas (posterior circulation infarct). MRI is better at detecting a posterior circulation infarct with diffusion-weighted imaging. A CT scan is used more to rule out certain stroke mimics and detect bleeding. The presence of leptomeningeal collateral circulation in the brain is associated with better clinical outcomes after recanalization treatment. Cerebrovascular reserve capacity is another factor that affects stroke outcome – it is the amount of increase in cerebral blood flow after a purposeful stimulation of blood flow by the physician, such as by giving inhaled carbon dioxide or intravenous acetazolamide. The increase in blood flow can be measured by PET scan or transcranial doppler sonography. However, in people with obstruction of the internal carotid artery of one side, the presence of leptomeningeal collateral circulation is associated with reduced cerebral reserve capacity.  Underlying cause  When a stroke has been diagnosed, various other studies may be performed to determine the underlying cause. With the current treatment and diagnosis options available, it is of particular importance to determine whether there is a peripheral source of emboli. Test selection may vary since the cause of stroke varies with age, comorbidity and the clinical presentation. The following are commonly used techniques: an ultrasound/doppler study of the carotid arteries (to detect carotid stenosis) or dissection of the precerebral arteries; an electrocardiogram (ECG) and echocardiogram (to identify arrhythmias and resultant clots in the heart which may spread to the brain vessels through the bloodstream); a Holter monitor study to identify intermittent abnormal heart rhythms; an angiogram of the cerebral vasculature (if a bleed is thought to have originated from an aneurysm or arteriovenous malformation); blood tests to determine if blood cholesterol is high, if there is an abnormal tendency to bleed, and if some rarer processes such as homocystinuria might be involved.For hemorrhagic strokes, a CT or MRI scan with intravascular contrast may be able to identify abnormalities in the brain arteries (such as aneurysms) or other sources of bleeding, and structural MRI if this shows no cause. If this too does not identify an underlying reason for the bleeding, invasive cerebral angiography could be performed but this requires access to the bloodstream with an intravascular catheter and can cause further strokes as well as complications at the insertion site and this investigation is therefore reserved for specific situations. If there are symptoms suggesting that the hemorrhage might have occurred as a result of venous thrombosis, CT or MRI venography can be used to examine the cerebral veins.  Misdiagnosis  Among people with ischemic strokes, misdiagnosis occurs 2 to 26% of the time. A ""stroke chameleon"" (SC) is stroke which is diagnosed as something else.People not having a stroke may also be misdiagnosed as a stroke. Giving thrombolytics (clot-busting) in such cases causes intracerebral bleeding 1 to 2% of the time, which is less than that of people with strokes. This unnecessary treatment adds to health care costs. Even so, the AHA/ASA guidelines state that starting intravenous tPA in possible mimics is preferred to delaying treatment for additional testing.Women, African-Americans, Hispanic-Americans, Asian and Pacific Islanders are more often misdiagnosed for a condition other than stroke when in fact having a stroke. In addition, adults under 44 years of age are seven times more likely to have a stroke missed than are adults over 75 years of age. This is especially the case for younger people with posterior circulation infarcts. Some medical centers have used hyperacute MRI in experimental studies for persons initially thought to have a low likelihood of stroke. And in some of these persons, strokes have been found which were then treated with thrombolytic medication.  Prevention  Given the disease burden of strokes, prevention is an important public health concern. Primary prevention is less effective than secondary prevention (as judged by the number needed to treat to prevent one stroke per year). Recent guidelines detail the evidence for primary prevention in stroke. In those who are otherwise healthy, aspirin does not appear beneficial and thus is not recommended. In people who have had a myocardial infarction or those with a high cardiovascular risk, it provides some protection against a first stroke. In those who have previously had a stroke, treatment with medications such as aspirin, clopidogrel, and dipyridamole may be beneficial. The U.S. Preventive Services Task Force (USPSTF) recommends against screening for carotid artery stenosis in those without symptoms.  Risk factors  The most important modifiable risk factors for stroke are high blood pressure and atrial fibrillation although the size of the effect is small; 833 people have to be treated for 1 year to prevent one stroke. Other modifiable risk factors include high blood cholesterol levels, diabetes mellitus, end-stage kidney disease, cigarette smoking (active and passive), heavy alcohol use, drug use, lack of physical activity, obesity, processed red meat consumption, and unhealthy diet. Smoking just one cigarette per day increases the risk more than 30%. Alcohol use could predispose to ischemic stroke, as well as intracerebral and subarachnoid hemorrhage via multiple mechanisms (for example, via hypertension, atrial fibrillation, rebound thrombocytosis and platelet aggregation and clotting disturbances). Drugs, most commonly amphetamines and cocaine, can induce stroke through damage to the blood vessels in the brain and acute hypertension. Migraine with aura doubles a person\'s risk for ischemic stroke. Untreated, celiac disease regardless of the presence of symptoms can be an underlying cause of stroke, both in children and adults.High levels of physical activity reduce the risk of stroke by about 26%. There is a lack of high quality studies looking at promotional efforts to improve lifestyle factors. Nonetheless, given the large body of circumstantial evidence, best medical management for stroke includes advice on diet, exercise, smoking and alcohol use. Medication is the most common method of stroke prevention; carotid endarterectomy can be a useful surgical method of preventing stroke.  Blood pressure  High blood pressure accounts for 35–50% of stroke risk. Blood pressure reduction of 10 mmHg systolic or 5 mmHg diastolic reduces the risk of stroke by ~40%. Lowering blood pressure has been conclusively shown to prevent both ischemic and hemorrhagic strokes. It is equally important in secondary prevention. Even people older than 80 years and those with isolated systolic hypertension benefit from antihypertensive therapy. The available evidence does not show large differences in stroke prevention between antihypertensive drugs—therefore, other factors such as protection against other forms of cardiovascular disease and cost should be considered. The routine use of beta-blockers following a stroke or TIA has not been shown to result in benefits.  Blood lipids  High cholesterol levels have been inconsistently associated with (ischemic) stroke. Statins have been shown to reduce the risk of stroke by about 15%. Since earlier meta-analyses of other lipid-lowering drugs did not show a decreased risk, statins might exert their effect through mechanisms other than their lipid-lowering effects.  Diabetes mellitus  Diabetes mellitus increases the risk of stroke by 2 to 3 times. While intensive blood sugar control has been shown to reduce small blood vessel complications such as kidney damage and damage to the retina of the eye it has not been shown to reduce large blood vessel complications such as stroke.  Anticoagulation drugs  Oral anticoagulants such as warfarin have been the mainstay of stroke prevention for over 50 years. However, several studies have shown that aspirin and other antiplatelets are highly effective in secondary prevention after a stroke or transient ischemic attack. Low doses of aspirin (for example 75–150 mg) are as effective as high doses but have fewer side effects; the lowest effective dose remains unknown. Thienopyridines (clopidogrel, ticlopidine) might be slightly more effective than aspirin and have a decreased risk of gastrointestinal bleeding, but are more expensive. Both aspirin and clopidogrel may be useful in the first few weeks after a minor stroke or high risk TIA. Clopidogrel has less side effects than ticlopidine. Dipyridamole can be added to aspirin therapy to provide a small additional benefit, even though headache is a common side effect. Low-dose aspirin is also effective for stroke prevention after having a myocardial infarction.Those with atrial fibrillation have a 5% a year risk of stroke, and this risk is higher in those with valvular atrial fibrillation. Depending on the stroke risk, anticoagulation with medications such as warfarin or aspirin is useful for prevention. Except in people with atrial fibrillation, oral anticoagulants are not advised for stroke prevention—any benefit is offset by bleeding risk.In primary prevention, however, antiplatelet drugs did not reduce the risk of ischemic stroke but increased the risk of major bleeding. Further studies are needed to investigate a possible protective effect of aspirin against ischemic stroke in women.  Surgery  Carotid endarterectomy or carotid angioplasty can be used to remove atherosclerotic narrowing of the carotid artery. There is evidence supporting this procedure in selected cases. Endarterectomy for a significant stenosis has been shown to be useful in preventing further strokes in those who have already had one. Carotid artery stenting has not been shown to be equally useful. People are selected for surgery based on age, gender, degree of stenosis, time since symptoms and the person\'s preferences. Surgery is most efficient when not delayed too long—the risk of recurrent stroke in a person who has a 50% or greater stenosis is up to 20% after 5 years, but endarterectomy reduces this risk to around 5%. The number of procedures needed to cure one person was 5 for early surgery (within two weeks after the initial stroke), but 125 if delayed longer than 12 weeks.Screening for carotid artery narrowing has not been shown to be a useful test in the general population. Studies of surgical intervention for carotid artery stenosis without symptoms have shown only a small decrease in the risk of stroke. To be beneficial, the complication rate of the surgery should be kept below 4%. Even then, for 100 surgeries, 5 people will benefit by avoiding stroke, 3 will develop stroke despite surgery, 3 will develop stroke or die due to the surgery itself, and 89 will remain stroke-free but would also have done so without intervention.  Diet  Nutrition, specifically the Mediterranean-style diet, has the potential for decreasing the risk of having a stroke by more than half. It does not appear that lowering levels of homocysteine with folic acid affects the risk of stroke.  Women  A number of specific recommendations have been made for women including taking aspirin after the 11th week of pregnancy if there is a history of previous chronic high blood pressure and taking blood pressure medications during pregnancy if the blood pressure is greater than 150 mmHg systolic or greater than 100 mmHg diastolic. In those who have previously had preeclampsia other risk factors should be treated more aggressively.  Previous stroke or TIA  Keeping blood pressure below 140/90 mmHg is recommended. Anticoagulation can prevent recurrent ischemic strokes. Among people with nonvalvular atrial fibrillation, anticoagulation can reduce stroke by 60% while antiplatelet agents can reduce stroke by 20%. However, a recent meta-analysis suggests harm from anticoagulation started early after an embolic stroke. Stroke prevention treatment for atrial fibrillation is determined according to the CHA2DS2–VASc score. The most widely used anticoagulant to prevent thromboembolic stroke in people with nonvalvular atrial fibrillation is the oral agent warfarin while a number of newer agents including dabigatran are alternatives which do not require prothrombin time monitoring.Anticoagulants, when used following stroke, should not be stopped for dental procedures.If studies show carotid artery stenosis, and the person has a degree of residual function on the affected side, carotid endarterectomy (surgical removal of the stenosis) may decrease the risk of recurrence if performed rapidly after stroke.  Management   Ischemic stroke  Aspirin reduces the overall risk of recurrence by 13% with greater benefit early on. Definitive therapy within the first few hours is aimed at removing the blockage by breaking the clot down (thrombolysis), or by removing it mechanically (thrombectomy). The philosophical premise underlying the importance of rapid stroke intervention was summed up as Time is Brain! in the early 1990s. Years later, that same idea, that rapid cerebral blood flow restoration results in fewer brain cells dying, has been proved and quantified.Tight blood sugar control in the first few hours does not improve outcomes and may cause harm. High blood pressure is also not typically lowered as this has not been found to be helpful. Cerebrolysin, a mixture of pig-derived neurotrophic factors used to treat acute ischemic stroke in many Asian and European countries, does not improve outcomes and may increase the risk of severe adverse events.  Thrombolysis  Thrombolysis, such as with recombinant tissue plasminogen activator (rtPA), in acute ischemic stroke, when given within three hours of symptom onset, results in an overall benefit of 10% with respect to living without disability. It does not, however, improve chances of survival. Benefit is greater the earlier it is used. Between three and four and a half hours the effects are less clear. The AHA/ASA recommend it for certain people in this time frame. A 2014 review found a 5% increase in the number of people living without disability at three to six months; however, there was a 2% increased risk of death in the short term. After four and a half hours thrombolysis worsens outcomes. These benefits or lack of benefits occurred regardless of the age of the person treated. There is no reliable way to determine who will have an intracranial bleed post-treatment versus who will not. In those with findings of savable tissue on medical imaging between 4.5 hours and 9 hours or who wake up with a stroke, alteplase results in some benefit.Its use is endorsed by the American Heart Association, the American College of Emergency Physicians and the American Academy of Neurology as the recommended treatment for acute stroke within three hours of onset of symptoms as long as there are no other contraindications (such as abnormal lab values, high blood pressure, or recent surgery). This position for tPA is based upon the findings of two studies by one group of investigators which showed that tPA improves the chances for a good neurological outcome. When administered within the first three hours thrombolysis improves functional outcome without affecting mortality. 6.4% of people with large strokes developed substantial brain bleeding as a complication from being given tPA thus part of the reason for increased short term mortality. The American Academy of Emergency Medicine had previously stated that objective evidence regarding the applicability of tPA for acute ischemic stroke was insufficient. In 2013 the American College of Emergency Medicine refuted this position, acknowledging the body of evidence for the use of tPA in ischemic stroke; but debate continues. Intra-arterial fibrinolysis, where a catheter is passed up an artery into the brain and the medication is injected at the site of thrombosis, has been found to improve outcomes in people with acute ischemic stroke.  Endovascular treatment  Mechanical removal of the blood clot causing the ischemic stroke, called mechanical thrombectomy, is a potential treatment for occlusion of a large artery, such as the middle cerebral artery. In 2015, one review demonstrated the safety and efficacy of this procedure if performed within 12 hours of the onset of symptoms. It did not change the risk of death, but reduced disability compared to the use of intravenous thrombolysis which is generally used in people evaluated for mechanical thrombectomy. Certain cases may benefit from thrombectomy up to 24 hours after the onset of symptoms.  Craniectomy  Strokes affecting large portions of the brain can cause significant brain swelling with secondary brain injury in surrounding tissue. This phenomenon is mainly encountered in strokes affecting brain tissue dependent upon the middle cerebral artery for blood supply and is also called ""malignant cerebral infarction"" because it carries a dismal prognosis. Relief of the pressure may be attempted with medication, but some require hemicraniectomy, the temporary surgical removal of the skull on one side of the head. This decreases the risk of death, although some people – who would otherwise have died – survive with disability.  Hemorrhagic stroke  People with intracerebral hemorrhage require supportive care, including blood pressure control if required. People are monitored for changes in the level of consciousness, and their blood sugar and oxygenation are kept at optimum levels. Anticoagulants and antithrombotics can make bleeding worse and are generally discontinued (and reversed if possible). A proportion may benefit from neurosurgical intervention to remove the blood and treat the underlying cause, but this depends on the location and the size of the hemorrhage as well as patient-related factors, and ongoing research is being conducted into the question as to which people with intracerebral hemorrhage may benefit.In subarachnoid hemorrhage, early treatment for underlying cerebral aneurysms may reduce the risk of further hemorrhages. Depending on the site of the aneurysm this may be by surgery that involves opening the skull or endovascularly (through the blood vessels).  Stroke unit  Ideally, people who have had a stroke are admitted to a ""stroke unit"", a ward or dedicated area in a hospital staffed by nurses and therapists with experience in stroke treatment. It has been shown that people admitted to a stroke unit have a higher chance of surviving than those admitted elsewhere in hospital, even if they are being cared for by doctors without experience in stroke. Nursing care is fundamental in maintaining skin care, feeding, hydration, positioning, and monitoring vital signs such as temperature, pulse, and blood pressure.  Rehabilitation  Stroke rehabilitation is the process by which those with disabling strokes undergo treatment to help them return to normal life as much as possible by regaining and relearning the skills of everyday living. It also aims to help the survivor understand and adapt to difficulties, prevent secondary complications, and educate family members to play a supporting role. Stroke rehabilitation should begin almost immediately with a multidisciplinary approach. The rehabilitation team may involve physicians trained in rehabilitation medicine, neurologists, clinical pharmacists, nursing staff, physiotherapists, occupational therapists, speech-language pathologists, and orthotists. Some teams may also include psychologists and social workers, since at least one-third of affected people manifests post stroke depression. Validated instruments such as the Barthel scale may be used to assess the likelihood of a person who has had a stroke being able to manage at home with or without support subsequent to discharge from a hospital.Stroke rehabilitation should be started as quickly as possible and can last anywhere from a few days to over a year. Most return of function is seen in the first few months, and then improvement falls off with the ""window"" considered officially by U.S. state rehabilitation units and others to be closed after six months, with little chance of further improvement. However, some people have reported that they continue to improve for years, regaining and strengthening abilities like writing, walking, running, and talking. Daily rehabilitation exercises should continue to be part of the daily routine for people who have had a stroke. Complete recovery is unusual but not impossible and most people will improve to some extent: proper diet and exercise are known to help the brain to recover.","A stroke is an illness in which part of the brain loses its blood supply. This can happen if an artery that feeds blood to the brain gets clogged, or if it tears and leaks. A stroke is when there is a lack of blood flow to the brain. There are two types of strokes. One is when there is a blood clot blocking the artery. The other type of stroke is when a blood vessel bursts and there is blood moving around freely in the brain.A stroke is the rapid loss of brain function(s) due to disturbance in the blood supply to the brain. This can happen because of ischemia (lack of blood flow) caused by blockage (thrombosis, arterial embolism), or a haemorrhage (leakage of blood).As a result, the affected area of the brain cannot work properly. Symptoms might include: hemiplegia (an inability to move one or more limbs on one side of the body), aphasia (inability to understand or use language), or an inability to see one side of the visual field.A stroke is a medical emergency. It can cause permanent damage. If it is not quickly treated, it may lead to death. It is the third most common cause of death and the most common cause of disability for adults in the United States and Europe. Strokes happen on both the left and right side of the brain. When a stroke happens on the left side of someone’s brain, it affects the right side of the body. It can also cause problems with the patient’s speech and language. If a stroke affects the right side of the brain, it affects the left side of the body. It also changes patient’s spatial (relating to space) perceptions. Getting a stroke on the right side of the brain can also cause people to not acknowledge their illness. Patients behave impulsively and neglect the side of their body.Factors that increase the risk of a stroke include old age, high blood pressure, a previous stroke, diabetes, high cholesterol, smoking, atrial fibrillation, migraine with aura, and thrombophilia (a tendency to thrombosis). Of those factors, the most easy to fix are high blood pressure and smoking.  How are strokes identified?   Pre-hospital  The Cincinnati Prehospital Stroke Scale was designed to help ""pre-hospital"" medical professionals (like EMTs) identify a possible stroke before the patient gets to the hospital. It tests three basic signs. If any of these signs are not normal, the patient may be having a stroke and should be transported to a hospital as soon as possible. Facial droop: Have the person smile or show his or her teeth. Normal: Both sides of face move equally Abnormal: One side of face does not move as well as the other (or at all); part of the face looks like it is drooping Arm drift: Have the person close his or her eyes and hold his or her arms straight out for about 10 seconds. Normal: Both arms move equally or not at all Abnormal: One arm does not move, or one arm drifts down compared with the other side Speech: Have the person say, ""You can't teach an old dog new tricks,"" or some other simple, familiar saying. Normal: Patient uses correct words with no slurring Abnormal: Patient's speech is slurred, patient uses incorrect words, or is unable to speakAbout 72% of patients who cannot do one of these three tasks normally are having an ischemic stroke. More than 85% of patients who cannot do all three tasks are having an acute stroke.  ""Spot a stroke""  The 'spot a stroke' campaign, created by the American Heart Association and the American Stroke Association, teaches everyday people how to recognize a stroke. It teaches the basic tests from the Cincinnati Stroke Scale, using the acronym FAST: F: Face - Facial Droop. Is one side of the face drooping or numb? Ask the person to smile. Is the person's smile uneven? A: Arm - Arm Weakness. Is one arm weak or numb? Ask the person to raise both arms. Does one arm drift downward? S: Speech - Speech Difficulty. Is speech slurred? Is the person unable to speak or hard to understand? Ask the person to repeat a simple sentence, like ""The sky is blue."" Is the sentence repeated correctly? T: Time - Time to Call 911. If someone shows any of these symptoms, even if the symptoms go away, it is time to call 9-1-1.  In the hospital  Once the patient is in the hospital, doctors can find out for sure whether they are having a stroke by looking at their brain with special scanning machines, like an MRI or a CT scanner.  Prevention  Strokes can kill. To prevent a stroke, doctors advise people to: Control blood pressure Stop smoking Exercise at least once a week Stay at a healthy weight Do not drink too much Get regular checkups  Statistics  795,000 people in the United States get a stroke each year One out of four people who have a stroke die (137,000 deaths from stroke per year) Currently, 3 million people in the US have disabilities from strokes In US, strokes cost $57.9 billion per year (damage and loss of work) ⅔ of stroke happen in people 65 and up Strokes affect men more than women Women more likely to die from stroke than men Strokes are more common in African Americans Strokes are more likely to be fatal in African Americans Stroke rates in older adults are declining but rates in younger people are rising (scientists think that it’s related to obesity) Physical therapy can help patients Some people are in a wheelchair after getting a stroke 10% of survivors suffer no long term disabilities 10% of survivors suffer from so many disabilities that they have to stay in 24 hour care  References   More reading  J.P. Mohr; et al. (2004). Stroke: pathophysiology, medical diagnosis, and management. New York: Churchill Livingstone. ISBN 0-443-06600-0. Perry, Thomas and Miller Frank (1961). Pathology: a dynamic introduction to medicine and surgery. Boston: Little, Brown and Company.  Other websites  The basis for this article was the National Institute of Neurological Disorders and Stroke public domain resource at this page Canadian Stroke Network Archived 2021-04-14 at the Wayback Machine Registry of the Canadian Stroke Network Archived 2006-05-27 at the Wayback Machine StrokEngine Archived 2006-02-13 at the Wayback Machine (McGill University, Montreal, Quebec, Canada) Focuses on stroke rehabilitation and interventions Cerebrovascular disease and risk of stroke Archived 2008-05-17 at the Wayback Machine ""What happens during a stroke"". NLM. Retrieved 2007-04-15. video American Stroke Association Archived 2009-10-21 at the Wayback Machine National Stroke Association Heart and Stroke Foundation of Canada The Stroke Association UK Heart attack, stroke and cardiac arrest warning signs, from the American Heart Association StrokeMD.net National Stroke Association of Malaysia Outcome of childhood stroke UK"
"An injury is any physiological damage to living tissue caused by immediate physical stress. An injury can occur intentionally or unintentionally and may be caused by blunt trauma, penetrating trauma, burning, toxic exposure, asphyxiation, or overexertion. Injuries can occur in any part of the body, and different symptoms are associated with different injuries. Treatment of a major injury is typically carried out by a health professional and varies greatly depending on the nature of the injury. Traffic collisions are the most common cause of accidental injury and injury-related death among humans. Injuries are distinct from chronic conditions, psychological trauma, infections, or medical procedures, though injury can be a contributing factor to any of these. Several major health organizations have established systems for the classification and description of human injuries.  Occurrence  Injuries may be intentional or unintentional. Intentional injuries may be acts of violence against others or self-harm against one's own person. Accidental injuries may be unforeseeable or they may be caused by negligence The most common types of unintentional injuries in order are traffic accidents, falls, drowning, burns, and accidental poisoning. Certain types of injuries are more common in developed countries or developing countries. Traffic injuries are more likely to kill pedestrians than drivers in developing countries. Scalding burns are more common in developed countries, while open-flame injuries are more common in developing countries.As of 2021, approximately 4.4 million people are killed due to injuries each year worldwide, constituting nearly 8% of all deaths. 3.16 million of these injuries are unintentional and 1.25 million are intentional. Traffic accidents are the most common form of deadly injury, causing about one-third of injury-related deaths. One-sixth are caused by suicide, and one-tenth are caused by homicide. Tens of millions of individuals require medical treatment for nonfatal injuries each year, and injuries are responsible for about 10% of all years lived with disability. Men are twice as likely to be killed through injury than women. In 2013, 367,000 children under the age of five died from injuries, down from 766,000 in 1990.  Classification systems  The World Health Organization (WHO) developed the International Classification of External Causes of Injury (ICECI). Under this system, injuries are classified by mechanism of injury, objects/substances producing injury, place of occurrence, activity when injured, the role of human intent, and additional modules. These codes allow the identification of distributions of injuries in specific populations and case identification for more detailed research on causes and preventive efforts.The United States Bureau of Labor Statistics developed the Occupational Injury and Illness Classification System (OIICS). Under this system injuries are classified by nature, part of body affected, source and secondary source, and event or exposure. The OIICS was first published in 1992 and has been updated several times since. The Orchard Sports Injury and Illness Classification System (OSIICS), previously OSICS, is used to classify injuries to enable research into specific sports injuries.The injury severity score (ISS) is a medical score to assess trauma severity. It correlates with mortality, morbidity, and hospitalization time after trauma. It is used to define the term major trauma (polytrauma), recognized when the ISS is greater than 15. The AIS Committee of the Association for the Advancement of Automotive Medicine designed and updates the scale.  Mechanisms   Trauma  Traumatic injury is caused by an external object making forceful contact with the body, resulting in a wound. Major trauma is a severe traumatic injury that has the potential to cause disability or death. Serious traumatic injury most often occurs as a result of traffic collisions. Traumatic injury is the leading cause of death in people under the age of 45.Blunt trauma injuries are caused by the forceful impact of an external object. Injuries from blunt trauma may cause internal bleeding and bruising from ruptured capillaries beneath the skin, abrasion from scraping against the superficial epidermis, lacerated tears on the skin or internal organs, or bone fractures. Crush injuries are a severe form of blunt trauma damage that apply large force to a large area over a longer period of time. Penetrating trauma injuries are caused by external objects entering the tissue of the body through the skin. Low-velocity penetration injuries are caused by sharp objects, such as stab wounds, while high-velocity penetration injuries are caused by ballistic projectiles, such as gunshot wounds or injuries caused by shell fragments. Perforated injuries result in an entry wound and an exit wound, while puncture wounds result only in an entry wound. Puncture injuries result in a cavity in the tissue.  Burns  Burn injury is caused by contact with extreme temperature, chemicals, or radiation. The effects of burns vary depending on the depth and size. Superficial or first-degree burns only affect the epidermis, causing pain for a short period of time. Superficial partial-thickness burns cause weeping blisters and require dressing. Deep partial-thickness burns are dry and less painful due to the burning away of the skin and require surgery. Full-thickness or third-degree burns affect the entire dermis and is susceptible to infection. Fourth-degree burns reach deep tissues such as muscles and bones, causing loss of the affected area.Thermal burns are the most common type of burn, caused by contact with excessive heat, including contact with flame, contact with hot surfaces, or scalding burns caused by contact with hot water or steam. Frostbite is a type of burn caused by contact with excessive cold, causing cellular injury and deep tissue damage through the crystallization of water in the tissue. Friction burns are caused by friction with external objects, resulting in a burn and abrasion. Radiation burns are caused by exposure to ionizing radiation. Most radiation burns are sunburns caused by ultraviolet radiation or high exposure to radiation through medical treatments such as repeated radiography or radiation therapy.Electrical burns are caused by contact with electricity as it enters and passes through the body. They are often deeper than other burns, affecting lower tissues as electricity penetrates the skin, and the full extent of electrical burns are often obscured. They will also cause extensive destruction of tissue at the entry and exit points. Electrical injuries in the home are often minor, while high tension power cables cause serious electrical injuries in the workplace. Lightning strikes can also cause severe electrical injuries. Fatal electrical injuries are often caused by tetanic spasm inducing respiratory arrest or interference with the heart causing cardiac arrest.Chemical burns are caused by contact with corrosive substances such as acid or alkali. Chemical burns are rarer than most other burns, though there are many chemicals that can damage tissue. The most common chemical-related injuries are those caused by carbon monoxide, ammonia, chlorine, hydrochloric acid, and sulfuric acid. Some chemical weapons induce chemical burns, such as white phosphorus. Most chemical burns are treated with extensive application of water to remove the chemical contaminant, though some burn-inducing chemicals react with water to create more severe injuries. The ingestion of corrosive substances can cause chemical burns to the larynx and stomach.  Other mechanisms  Toxic injury is caused by the ingestion, inhalation, injection, or absorption of a toxin. This may occur through an interaction caused by a drug or the ingestion of a poison. Different toxins may cause different types of injuries, and many will cause injury to specific organs. Toxins in gases, dusts, aerosols, and smoke can be inhaled, potentially causing respiratory failure. Respiratory toxins can be released by structural fires, industrial accidents, domestic mishaps, or through chemical weapons. Some toxicants may affect other parts of the body after inhalation, such as carbon monoxide.Asphyxia causes injury to the body from a lack of oxygen. It can be caused by drowning, inhalation of certain substances, strangulation, blockage of the airway, traumatic injury to the airway, apnea, and other means. The most immediate injury caused by asphyxia is hypoxia, which can in turn cause acute lung injury or acute respiratory distress syndrome as well as damage to the circulatory system. The most severe injury associated with asphyxiation is cerebral hypoxia and ischemia, in which the brain receives insufficient oxygen or blood, resulting in neurological damage or death. Specific injuries are associated with water inhalation, including alveolar collapse, atelectasis, intrapulmonary shunting, and ventilation perfusion mismatch. Simple asphyxia is caused by a lack of external oxygen supply. Systemic asphyxia is caused by exposure to a compound that prevents oxygen from being transported or used by the body. This can be caused by azides, carbon monoxide, cyanide, smoke inhalation, hydrogen sulfide, methemoglobinemia-inducing substances, opioids, or other systemic asphyxiants. Ventilation and oxygenation are necessary for treatment of asphyxiation, and some asphyxiants can be treated with antidotes.Injuries of overuse or overexertion can occur when the body is strained through use, affecting the bones, muscles, ligaments, or tendons. Sports injuries are often overuse injuries such as tendinopathy. Over-extension of the ligaments and tendons can result in sprains and strains, respectively. Repetitive sedentary behaviors such as extended use of a computer or a physically repetitive occupation may cause a repetitive strain injury. Extended use of brightly lit screens may also cause eye strain.  Locations   Abdomen  Abdominal trauma includes injuries to the stomach, intestines, liver, pancreas, kidneys, gallbladder, and spleen. Abdominal injuries are typically caused by traffic accidents, assaults, falls, and work-related injuries, and physical examination is often unreliable in diagnosing blunt abdominal trauma. Splenic injury can cause low blood volume or blood in the peritoneal cavity. The treatment and prognosis of splenic injuries are dependent on cardiovascular stability. The gallbladder is rarely injured in blunt trauma, occurring in about 2% of blunt abdominal trauma cases. Injuries to the gallbladder are typically associated with injuries to other abdominal organs. The intestines are susceptible to injury following blunt abdominal trauma. The kidneys are protected by other structures in the abdomen, and most injuries to the kidney are a result of blunt trauma. Kidney injuries typically cause blood in the urine.Due to its location in the body, pancreatic injury is relatively uncommon but more difficult to diagnose. Most injuries to the pancreas are caused by penetrative trauma, such as gunshot wounds and stab wounds. Pancreatic injuries occur in under 5% of blunt abdominal trauma cases. The severity of pancreatic injury depends primarily on the amount of harm caused to the pancreatic duct. The stomach is also well protected from injury due to its heavy layering, its extensive blood supply, and its position relative to the rib cage. As with pancreatic injuries, most traumatic stomach injuries are caused by penetrative trauma, and most civilian weapons do not cause long-term tissue damage to the stomach. Blunt trauma injuries to the stomach are typically caused by traffic accidents. Ingestion of corrosive substances can cause chemical burns to the stomach. Liver injury is the most common type of organ damage in cases of abdominal trauma. The liver's size and location in the body makes injury relatively common compared to other abdominal organs, and blunt trauma injury to the liver is typically treated with nonoperative management. Liver injuries are rarely serious, though most injuries to the liver are concomitant with other injuries, particularly to the spleen, ribs, pelvis, or spinal cord. The liver is also susceptible to toxic injury, with overdose of paracetamol being a common cause of liver failure.  Face  Facial trauma may affect the eyes, nose, ears, or mouth. Nasal trauma is a common injury and the most common type of facial injury. Oral injuries are typically caused by traffic accidents or alcohol-related violence, though falls are a more common cause in young children. The primary concerns regarding oral injuries are that the airway is clear and that there are no concurrent injuries to other parts of the head or neck. Oral injuries may occur in the soft tissue of the face, the hard tissue of the mandible, or as dental trauma.The ear is susceptible to trauma in head injuries due to its prominent location and exposed structure. Ear injuries may be internal or external. Injuries of the external ear are typically lacerations of the cartilage or the formation of a hematoma. Injuries of the middle and internal ear may include a perforated eardrum or trauma caused by extreme pressure changes. The ear is also highly sensitive to blast injury. The bones of the ear are connected to facial nerves, and ear injuries can cause paralysis of the face. Trauma to the ear can cause hearing loss.Eye injuries often take place in the cornea, and they have the potential to permanently damage vision. Corneal abrasions are a common injury caused by contact with foreign objects. The eye can also be injured by a foreign object remaining in the cornea. Radiation damage can be caused by exposure to excessive light, often caused by welding without eye protection or being exposed to excessive ultraviolet radiation, such as sunlight. Exposure to corrosive chemicals can permanently damage the eyes, causing blindness if not sufficiently irrigated. The eye is protected from most blunt injuries by the infraorbital margin, but in some cases blunt force may cause an eye to hemorrhage or tear. Overuse of the eyes can cause eye strain, particularly when looking at brightly lit screens for an extended period.  Heart  Cardiac injuries affect the heart and blood vessels. Blunt cardiac injury in a common injury caused by blunt trauma to the heart. It can be difficult to diagnose, and it can have many effects on the heart, including contusions, ruptures, acute valvular disorders, arrhythmia, or heart failure. Penetrative trauma to the heart is typically caused by stab wounds or gunshot wounds. Accidental cardiac penetration can also occur in rare cases from a fractured sternum or rib. Stab wounds to the heart are typically survivable with medical attention, though gunshot wounds to the heart are not. The right ventricle is most susceptible to injury due to its prominent location. The two primary consequences of traumatic injury to the heart are severe hemorrhaging and fluid buildup around the heart.  Musculoskeletal  Musculoskeletal injuries affect the skeleton and the muscular system. Soft tissue injuries affect the skeletal muscles, ligaments, and tendons. Ligament and tendon injuries account for half of all musculoskeletal injuries. Ligament sprains and tendon strains are common injuries that do not require intervention, but the healing process is slow. Physical therapy can be used to assist reconstruction and use of injured ligaments and tendons. Torn ligaments or tendons typically require surgery. Skeletal muscles are abundant in the body and commonly injured when engaging in athletic activity. Muscle injuries trigger an inflammatory response to facilitate healing. Blunt trauma to the muscles can cause contusions and hematomas. Excessive tensile strength can overstretch a muscle, causing a strain. Strains may present with torn muscle fibers, hemorrhaging, or fluid in the muscles. Severe muscle injuries in which a tear extends across the muscle can cause total loss of function. Penetrative trauma can cause laceration to muscles, which may take an extended time to heal. Unlike contusions and strains, lacerations are uncommon in sports injuries.Traumatic injury may cause various bone fractures depending on the amount of force, direction of the force, and width of the area affected. Pathologic fractures occur when a previous condition weakens the bone until it can be easily fractured. Stress fractures occur when the bone is overused or suffers under excessive or traumatic pressure, often during athletic activity. Hematomas occur immediately following a bone fracture, and the healing process often takes from six weeks to three months to complete, though continued use of the fractured bone will prevent healing. Articular cartilage damage may also affect function of the skeletal system, and it can cause posttraumatic osteoarthritis. Unlike most bodily structures, cartilage cannot be healed once it is damaged.  Nervous system  Injuries to the nervous system include brain injury, spinal cord injury, and nerve injury. Trauma to the brain causes traumatic brain injury (TBI), causing ""long-term physical, emotional, behavioral, and cognitive consequences"". Mild TBI, including concussion, often occurs during athletic activity, military service, or as a result of untreated epilepsy, and its effects are typically short-term. More severe injuries to the brain cause moderate TBI, which may cause confusion or lethargy, or severe TBI, which may result in a coma or a secondary brain injury. TBI is a leading cause of mortality. Approximately half of all trauma-related deaths involve TBI. Non-traumatic injuries to the brain cause acquired brain injury (ABI). This can be caused by stroke, a brain tumor, poison, infection, cerebral hypoxia, drug use, or the secondary effect of a TBI.Injury to the spinal cord is not immediately terminal, but it is associated with concomitant injuries, lifelong medical complications, and reduction in life expectancy. It may result in complications in several major organ systems and a significant reduction in mobility or paralysis. Spinal shock causes temporary paralysis and loss of reflexes. Unlike most other injuries, damage to the peripheral nerves is not healed through cellular proliferation. Following nerve injury, the nerves undergo degeneration before regenerating, and other pathways can be strengthened or reprogrammed to make up for lost function. The most common form of peripheral nerve injury is stretching, due to their inherent elasticity. Nerve injuries may also be caused by laceration or compression.  Pelvis  Injuries to the pelvic area include injuries to the bladder, rectum, colon, and reproductive organs. Traumatic injury to the bladder is rare and often occurs with other injuries to the abdomen and pelvis. The bladder is protected by the peritoneum, and most cases of bladder injury are concurrent with a fracture of the pelvis. Bladder trauma typically causes hematuria, or blood in the urine. Ingestion of alcohol may cause distension of the bladder, increasing the risk of injury. A catheter may be used to extract blood from the bladder in the case of hemorrhaging, though injuries that break the peritoneum typically require surgery. The colon is rarely injured by blunt trauma, with most cases occurring from penetrative trauma through the abdomen. Rectal injury is less common than injury to the colon, though the rectum is more susceptible to injury following blunt force trauma to the pelvis.Injuries to the male reproductive system are rarely fatal and typically treatable through grafts and reconstruction. The elastic nature of the scrotum makes it resistant to injury, accounting for 1% of traumatic injuries. Trauma to the scrotum may cause damage to the testis or the spermatic cord. Trauma to the penis can cause penile fracture, typically as a result of vigorous intercourse. Injuries to the female reproductive system are often a result of pregnancy and childbirth or sexual activity. They are rarely fatal, but they can produce a variety of complications, such as chronic discomfort, dyspareunia, infertility, or the formation of fistulas. Age can greatly affect the nature of genital injuries in women due to changes in hormone composition. Childbirth is the most common cause of genital injury to women of reproductive age. Many cultures practice female genital mutilation, which is estimated to affect over 125 million women and girls worldwide as of 2018. Tears and abrasions to the vagina are common during sexual intercourse, and these may be exacerbated in instances of non-consensual sexual activity.  Respiratory tract  Injuries to the respiratory tract affect the lungs, diaphragm, trachea, bronchus, pharynx, or larynx. Tracheobronchial injuries are rare and often associated with other injuries. Bronchoscopy is necessary for an accurate diagnosis of tracheobronchial injury. The neck, including the pharynx and larynx, is highly vulnerable to injury due to its complex, compacted anatomy. Injuries to this area can cause airway obstruction. Ingestion of corrosive chemicals can cause chemical burns to the larynx. Inhalation of toxic materials can also cause serious injury to the respiratory tract.Severe trauma to the chest can cause damage to the lungs, including pulmonary contusions, accumulation of blood, or a collapsed lung. The inflammation response to a lung injury can cause acute respiratory distress syndrome. Injuries to the lungs may cause symptoms ranging from shortness of breath to terminal respiratory failure. Injuries to the lungs are often fatal, and survivors often have a reduced quality of life. Injuries to the diaphragm are uncommon and rarely serious, but blunt trauma to the diaphragm can result in the formation of a hernia over time. Injuries to the diaphragm may present in many ways, including abnormal blood pressure, cardiac arrest, gastroinetestinal obstruction, and respiratory insufficiency. Injuries to the diaphragm are often associated with other injuries in the chest or abdomen, and its position between two major cavities of the human body may complicate diagnosis.  Skin  Most injuries to the skin are minor and do not require specialist treatment. Lacerations of the skin are typically repaired with sutures, staples, or adhesives. The skin is susceptible to burns, and burns to the skin often cause blistering. Abrasive trauma scrapes or rubs off the skin, and severe abrasions require skin grafting to repair. Skin tears involve the removal of the epidermis or dermis through friction or shearing forces, often in vulnerable populations such as the elderly. Skin injuries are potentially complicated by foreign bodies such as glass, metal, or dirt that entered the wound, and skin wounds often require cleaning.  Treatment  Much of medical practice is dedicated to the treatment of injuries. Traumatology is the study of traumatic injuries and injury repair. Certain injuries may be treated by specialists. Serious injuries sometimes require trauma surgery. Following serious injuries, physical therapy and occupational therapy are sometimes used for rehabilitation. Medication is commonly used to treat injuries. Emergency medicine during major trauma prioritizes the immediate consideration of life-threatening injuries that can be quickly addressed. The airway is evaluated, clearing bodily fluids with suctioning or creating an artificial airway if necessary. Breathing is evaluated by evaluating motion of the chest wall and checking for blood or air in the pleural cavity. Circulation is evaluated to resuscitate the patient, including the application of intravenous therapy. Disability is evaluated by checking for responsiveness and reflexes. Exposure is then used to examine the patient for external injury. Following immediate life-saving procedures, a CT scan is used for a more thorough diagnosis. Further resuscitation may be required, including ongoing blood transfusion, mechanical ventilation and nutritional support.Pain management is another aspect of injury treatment. Pain serves as an indicator to determine the nature and severity of an injury, but it can also worsen an injury, reduce mobility, and affect quality of life. Analgesic drugs are used to reduce the pain associated with injuries, depending on the person's age, the severity of the injury, and previous medical conditions that may affect pain relief. NSAIDs such as aspirin and ibuprofen are commonly used for acute pain. Opioid medications such as fentanyl, methadone, and morphine are used to treat severe pain in major trauma, but their use is limited due to associated long-term risks such as addiction. In addition to medications, non-pharmacological interventions can be beneficial when treating pain. The mnemonic TWEED SASH summarises some of these:  Complications  Complications may arise as a result of certain injuries, increasing the recovery time, further exasperating the symptoms, or potentially causing death. The extent of the injury and the age of the injured person may contribute to the likelihood of complications. Infection of wounds is a common complication in traumatic injury, resulting in diagnoses such as pneumonia or sepsis. Wound infection prevents the healing process from taking place and can cause further damage to the body. A majority of wounds are contaminated with microbes from other parts of the body, and infection takes place when the immune system is unable to address this contamination. The surgical removing of devitalized tissue and the use of topical antimicrobial agents can prevent infection.Hemorrhaging of blood is a common result of injuries, and it can cause several complications. Pooling of blood under the skin can cause a hematoma, particularly after blunt trauma or the suture of a laceration. Hematomas are susceptible to infection and are typically treated compression, though surgery is necessary in severe cases. Excessive blood loss can cause hypovolemic shock in which cellular oxygenation can no longer take place. This can cause tachycardia, hypotension, coma, or organ failure. Fluid replacement is often necessary to treat blood loss. Other complications of injuries include cavitation, development of fistulas, and organ failure.  Social and psychological aspects  Injuries often cause psychological harm in addition to physical harm. Traumatic injuries are associated with psychological trauma and distress, and some victims of traumatic injuries will display symptoms of post-traumatic stress disorder during and after the recovery of the injury. The specific symptoms and their triggers vary depending on the nature of the injury. Body image and self-esteem can also be affected by injury. Injuries that cause permanent disabilities, such as spinal cord injuries, can have severe effects on self-esteem. Disfiguring injuries can negatively affect body image, leading to a lower quality of life. Burn injuries in particular can cause dramatic changes in a person's appearance that may negatively affect body image.Severe injury can also cause social harm. Disfiguring injuries may also result in stigma due to scarring or other changes in appearance. Certain injuries may necessitate a change in occupation or prevent employment entirely. Leisure activities are similarly limited, and athletic activities in particular may be impossible following severe injury. In some cases, the effects of injury may strain personal relationships, such as marriages. Psychological and social variables have been found to affect the likelihood of injuries among athletes. Increased life stress can cause an increase in the likelihood of athletic injury, while social support can decrease the likelihood of injury. Social support also assists in the recovery process after athletic injuries occur.  See also  Injury prevention List of causes of death by rate First aid Medical emergency Traumatology  References   External links  International Trauma Conferences (registered trauma charity providing trauma education for medical professionals worldwide) Trauma.org (trauma resources for medical professionals) Emergency Medicine Research and Perspectives (emergency medicine procedure videos) American Trauma Society Scandinavian Journal of Trauma, Resuscitation and Emergency Medicine",Injury means a harm or hurt. Usually an injury is when the body or a part of the body is damaged by something outside of the body. Another word for injury to a body is trauma. Injury can be by: Environmental – Burns from heat or injury from cold Penetrating injury – when a sharp object like a knife pierces the body Blunt injury – when something hits the body (like punching someone or falling from a tree) Chemical – being hurt by chemicals like burns from acidInjury can be accidental or intentional. In an intentional injury a person tries to hurt another. (Intentional injury is also called non-accidental injury). Accidental injury is without meaning to hurt someone. A traffic collision for example may injure someone accidentally.
"A myocardial infarction (MI), commonly known as a heart attack, occurs when blood flow decreases or stops in the coronary artery of the heart, causing damage to the heart muscle. The most common symptom is chest pain or discomfort which may travel into the shoulder, arm, back, neck or jaw. Often it occurs in the center or left side of the chest and lasts for more than a few minutes. The discomfort may occasionally feel like heartburn. Other symptoms may include shortness of breath, nausea, feeling faint, a cold sweat or feeling tired. About 30% of people have atypical symptoms. Women more often present without chest pain and instead have neck pain, arm pain or feel tired. Among those over 75 years old, about 5% have had an MI with little or no history of symptoms. An MI may cause heart failure, an irregular heartbeat, cardiogenic shock or cardiac arrest.Most MIs occur due to coronary artery disease. Risk factors include high blood pressure, smoking, diabetes, lack of exercise, obesity, high blood cholesterol, poor diet and excessive alcohol intake. The complete blockage of a coronary artery caused by a rupture of an atherosclerotic plaque is usually the underlying mechanism of an MI. MIs are less commonly caused by coronary artery spasms, which may be due to cocaine, significant emotional stress (commonly known as Takotsubo syndrome or broken heart syndrome) and extreme cold, among others. A number of tests are useful to help with diagnosis, including electrocardiograms (ECGs), blood tests and coronary angiography. An ECG, which is a recording of the heart's electrical activity, may confirm an ST elevation MI (STEMI), if ST elevation is present. Commonly used blood tests include troponin and less often creatine kinase MB.Treatment of an MI is time-critical. Aspirin is an appropriate immediate treatment for a suspected MI. Nitroglycerin or opioids may be used to help with chest pain; however, they do not improve overall outcomes. Supplemental oxygen is recommended in those with low oxygen levels or shortness of breath. In a STEMI, treatments attempt to restore blood flow to the heart and include percutaneous coronary intervention (PCI), where the arteries are pushed open and may be stented, or thrombolysis, where the blockage is removed using medications. People who have a non-ST elevation myocardial infarction (NSTEMI) are often managed with the blood thinner heparin, with the additional use of PCI in those at high risk. In people with blockages of multiple coronary arteries and diabetes, coronary artery bypass surgery (CABG) may be recommended rather than angioplasty. After an MI, lifestyle modifications, along with long-term treatment with aspirin, beta blockers and statins, are typically recommended.Worldwide, about 15.9 million myocardial infarctions occurred in 2015. More than 3 million people had an ST elevation MI, and more than 4 million had an NSTEMI. STEMIs occur about twice as often in men as women. About one million people have an MI each year in the United States. In the developed world, the risk of death in those who have had an STEMI is about 10%. Rates of MI for a given age have decreased globally between 1990 and 2010. In 2011, an MI was one of the top five most expensive conditions during inpatient hospitalizations in the US, with a cost of about $11.5 billion for 612,000 hospital stays.  Terminology  Myocardial infarction (MI) refers to tissue death (infarction) of the heart muscle (myocardium) caused by ischaemia, the lack of oxygen delivery to myocardial tissue. It is a type of acute coronary syndrome, which describes a sudden or short-term change in symptoms related to blood flow to the heart. Unlike the other type of acute coronary syndrome, unstable angina, a myocardial infarction occurs when there is cell death, which can be estimated by measuring by a blood test for biomarkers (the cardiac protein troponin). When there is evidence of an MI, it may be classified as an ST elevation myocardial infarction (STEMI) or Non-ST elevation myocardial infarction (NSTEMI) based on the results of an ECG.The phrase ""heart attack"" is often used non-specifically to refer to myocardial infarction. An MI is different from—but can cause—cardiac arrest, where the heart is not contracting at all or so poorly that all vital organs cease to function, thus might lead to death. It is also distinct from heart failure, in which the pumping action of the heart is impaired. However, an MI may lead to heart failure.  Signs and symptoms  Chest pain that may or may not radiate to other parts of the body is the most typical and significant symptom of myocardial infarction. It might be accompanied by other symptoms such as sweating.  Pain  Chest pain is one of the most common symptoms of acute myocardial infarction and is often described as a sensation of tightness, pressure, or squeezing. Pain radiates most often to the left arm, but may also radiate to the lower jaw, neck, right arm, back, and upper abdomen. The pain most suggestive of an acute MI, with the highest likelihood ratio, is pain radiating to the right arm and shoulder. Similarly, chest pain similar to a previous heart attack is also suggestive. The pain associated with MI is usually diffuse, does not change with position, and lasts for more than 20 minutes. It might be described as pressure, tightness, knifelike, tearing, burning sensation (all these are also manifested during other diseases). It could be felt as an unexplained anxiety, and pain might be absent altogether. Levine's sign, in which a person localizes the chest pain by clenching one or both fists over their sternum, has classically been thought to be predictive of cardiac chest pain, although a prospective observational study showed it had a poor positive predictive value.Typically, chest pain because of ischemia, be it unstable angina or myocardial infarction, lessens with the use of nitroglycerin, but nitroglycerin may also relieve chest pain arising from non-cardiac causes.  Other  Chest pain may be accompanied by sweating, nausea or vomiting, and fainting, and these symptoms may also occur without any pain at all. In women, the most common symptoms of myocardial infarction include shortness of breath, weakness, and fatigue. Women are more likely to have unusual or unexplained tiredness and nausea or vomiting as symptoms. Women having heart attacks are more likely to have palpitations, back pain, labored breath, vomiting, and left arm pain than men, although the studies showing these differences had high variability. Women are less likely to report chest pain during a heart attack and more likely to report nausea, jaw pain, neck pain, cough, and fatigue, although these findings are inconsistent across studies. Women with heart attacks also had more indigestion, dizziness, loss of appetite, and loss of consciousness. Shortness of breath is a common, and sometimes the only symptom, occurring when damage to the heart limits the output of the left ventricle, with breathlessness arising either from low oxygen in the blood, or pulmonary edema. Other less common symptoms include weakness, light-headedness, palpitations, and abnormalities in heart rate or blood pressure. These symptoms are likely induced by a massive surge of catecholamines from the sympathetic nervous system, which occurs in response to pain and, where present, low blood pressure. Loss of consciousness due to inadequate blood flow to the brain and cardiogenic shock, and sudden death, frequently due to the development of ventricular fibrillation, can occur in myocardial infarctions. Cardiac arrest, and atypical symptoms such as palpitations, occur more frequently in women, the elderly, those with diabetes, in people who have just had surgery, and in critically ill patients.  Absence  ""Silent"" myocardial infarctions can happen without any symptoms at all. These cases can be discovered later on electrocardiograms, using blood enzyme tests, or at autopsy after a person has died. Such silent myocardial infarctions represent between 22 and 64% of all infarctions, and are more common in the elderly, in those with diabetes mellitus and after heart transplantation. In people with diabetes, differences in pain threshold, autonomic neuropathy, and psychological factors have been cited as possible explanations for the lack of symptoms. In heart transplantation, the donor heart is not fully innervated by the nervous system of the recipient.  Risk factors  The most prominent risk factors for myocardial infarction are older age, actively smoking, high blood pressure, diabetes mellitus, and total cholesterol and high-density lipoprotein levels. Many risk factors of myocardial infarction are shared with coronary artery disease, the primary cause of myocardial infarction, with other risk factors including male sex, low levels of physical activity, a past family history, obesity, and alcohol use. Risk factors for myocardial disease are often included in risk factor stratification scores, such as the Framingham Risk Score. At any given age, men are more at risk than women for the development of cardiovascular disease. High levels of blood cholesterol is a known risk factor, particularly high low-density lipoprotein, low high-density lipoprotein, and high triglycerides.Many risk factors for myocardial infarction are potentially modifiable, with the most important being tobacco smoking (including secondhand smoke). Smoking appears to be the cause of about 36% and obesity the cause of 20% of coronary artery disease. Lack of physical activity has been linked to 7–12% of cases. Less common causes include stress-related causes such as job stress, which accounts for about 3% of cases, and chronic high stress levels.  Diet  There is varying evidence about the importance of saturated fat in the development of myocardial infarctions. Eating polyunsaturated fat instead of saturated fats has been shown in studies to be associated with a decreased risk of myocardial infarction, while other studies find little evidence that reducing dietary saturated fat or increasing polyunsaturated fat intake affects heart attack risk. Dietary cholesterol does not appear to have a significant effect on blood cholesterol and thus recommendations about its consumption may not be needed. Trans fats do appear to increase risk. Acute and prolonged intake of high quantities of alcoholic drinks (3–4 or more daily) increases the risk of a heart attack.  Genetics  Family history of ischemic heart disease or MI, particularly if one has a male first-degree relative (father, brother) who had a myocardial infarction before age 55 years, or a female first-degree relative (mother, sister) less than age 65 increases a person's risk of MI.Genome-wide association studies have found 27 genetic variants that are associated with an increased risk of myocardial infarction. The strongest association of MI has been found with chromosome 9 on the short arm p at locus 21, which contains genes CDKN2A and 2B, although the single nucleotide polymorphisms that are implicated are within a non-coding region. The majority of these variants are in regions that have not been previously implicated in coronary artery disease. The following genes have an association with MI: PCSK9, SORT1, MIA3, WDR12, MRAS, PHACTR1, LPA, TCF21, MTHFDSL, ZC3HC1, CDKN2A, 2B, ABO, PDGF0, APOA5, MNF1ASM283, COL4A1, HHIPC1, SMAD3, ADAMTS7, RAS1, SMG6, SNF8, LDLR, SLC5A3, MRPS6, KCNE2.  Other  The risk of having a myocardial infarction increases with older age, low physical activity, and low socioeconomic status. Heart attacks appear to occur more commonly in the morning hours, especially between 6AM and noon. Evidence suggests that heart attacks are at least three times more likely to occur in the morning than in the late evening. Shift work is also associated with a higher risk of MI. One analysis has found an increase in heart attacks immediately following the start of daylight saving time.Women who use combined oral contraceptive pills have a modestly increased risk of myocardial infarction, especially in the presence of other risk factors. The use of non-steroidal anti inflammatory drugs (NSAIDs), even for as short as a week, increases risk.Endometriosis in women under the age of 40 is an identified risk factor.Air pollution is also an important modifiable risk. Short-term exposure to air pollution such as carbon monoxide, nitrogen dioxide, and sulfur dioxide (but not ozone) have been associated with MI and other acute cardiovascular events. For sudden cardiac deaths, every increment of 30 units in Pollutant Standards Index correlated with an 8% increased risk of out-of-hospital cardiac arrest on the day of exposure. Extremes of temperature are also associated.A number of acute and chronic infections including Chlamydophila pneumoniae, influenza, Helicobacter pylori, and Porphyromonas gingivalis among others have been linked to atherosclerosis and myocardial infarction. As of 2013, there is no evidence of benefit from antibiotics or vaccination, however, calling the association into question. Myocardial infarction can also occur as a late consequence of Kawasaki disease.Calcium deposits in the coronary arteries can be detected with CT scans. Calcium seen in coronary arteries can provide predictive information beyond that of classical risk factors. High blood levels of the amino acid homocysteine is associated with premature atherosclerosis; whether elevated homocysteine in the normal range is causal is controversial.In people without evident coronary artery disease, possible causes for the myocardial infarction are coronary spasm or coronary artery dissection.  Mechanism   Atherosclerosis  The most common cause of a myocardial infarction is the rupture of an atherosclerotic plaque on an artery supplying heart muscle. Plaques can become unstable, rupture, and additionally promote the formation of a blood clot that blocks the artery; this can occur in minutes. Blockage of an artery can lead to tissue death in tissue being supplied by that artery. Atherosclerotic plaques are often present for decades before they result in symptoms.The gradual buildup of cholesterol and fibrous tissue in plaques in the wall of the coronary arteries or other arteries, typically over decades, is termed atherosclerosis. Atherosclerosis is characterized by progressive inflammation of the walls of the arteries. Inflammatory cells, particularly macrophages, move into affected arterial walls. Over time, they become laden with cholesterol products, particularly LDL, and become foam cells. A cholesterol core forms as foam cells die. In response to growth factors secreted by macrophages, smooth muscle and other cells move into the plaque and act to stabilize it. A stable plaque may have a thick fibrous cap with calcification. If there is ongoing inflammation, the cap may be thin or ulcerate. Exposed to the pressure associated with blood flow, plaques, especially those with a thin lining, may rupture and trigger the formation of a blood clot (thrombus). The cholesterol crystals have been associated with plaque rupture through mechanical injury and inflammation.  Other causes  Atherosclerotic disease is not the only cause of myocardial infarction, but it may exacerbate or contribute to other causes. A myocardial infarction may result from a heart with a limited blood supply subject to increased oxygen demands, such as in fever, a fast heart rate, hyperthyroidism, too few red blood cells in the bloodstream, or low blood pressure. Damage or failure of procedures such as percutaneous coronary intervention or coronary artery bypass grafts may cause a myocardial infarction. Spasm of coronary arteries, such as Prinzmetal's angina may cause blockage.  Tissue death  If impaired blood flow to the heart lasts long enough, it triggers a process called the ischemic cascade; the heart cells in the territory of the blocked coronary artery die (infarction), chiefly through necrosis, and do not grow back. A collagen scar forms in their place. When an artery is blocked, cells lack oxygen, needed to produce ATP in mitochondria. ATP is required for the maintenance of electrolyte balance, particularly through the Na/K ATPase. This leads to an ischemic cascade of intracellular changes, necrosis and apoptosis of affected cells.Cells in the area with the worst blood supply, just below the inner surface of the heart (endocardium), are most susceptible to damage. Ischemia first affects this region, the subendocardial region, and tissue begins to die within 15–30 minutes of loss of blood supply. The dead tissue is surrounded by a zone of potentially reversible ischemia that progresses to become a full-thickness transmural infarct. The initial ""wave"" of infarction can take place over 3–4 hours. These changes are seen on gross pathology and cannot be predicted by the presence or absence of Q waves on an ECG. The position, size and extent of an infarct depends on the affected artery, totality of the blockage, duration of the blockage, the presence of collateral blood vessels, oxygen demand, and success of interventional procedures.Tissue death and myocardial scarring alter the normal conduction pathways of the heart, and weaken affected areas. The size and location puts a person at risk of abnormal heart rhythms (arrhythmias) or heart block, aneurysm of the heart ventricles, inflammation of the heart wall following infarction, and rupture of the heart wall that can have catastrophic consequences.Injury to the myocardium also occurs during re-perfusion. This might manifest as ventricular arrhythmia. The re-perfusion injury is a consequence of the calcium and sodium uptake from the cardiac cells and the release of oxygen radicals during reperfusion. No-reflow phenomenon—when blood is still unable to be distributed to the affected myocardium despite clearing the occlusion—also contributes to myocardial injury. Topical endothelial swelling is one of many factors contributing to this phenomenon.  Diagnosis   Criteria  A myocardial infarction, according to current consensus, is defined by elevated cardiac biomarkers with a rising or falling trend and at least one of the following: Symptoms relating to ischemia Changes on an electrocardiogram (ECG), such as ST segment changes, new left bundle branch block, or pathologic Q waves Changes in the motion of the heart wall on imaging Demonstration of a thrombus on angiogram or at autopsy.  Types  A myocardial infarction is usually clinically classified as an ST-elevation MI (STEMI) or a non-ST elevation MI (NSTEMI). These are based on ST elevation, a portion of a heartbeat graphically recorded on an ECG. STEMIs make up about 25–40% of myocardial infarctions. A more explicit classification system, based on international consensus in 2012, also exists. This classifies myocardial infarctions into five types: Spontaneous MI related to plaque erosion and/or rupture fissuring, or dissection MI related to ischemia, such as from increased oxygen demand or decreased supply, e.g. coronary artery spasm, coronary embolism, anemia, arrhythmias, high blood pressure, or low blood pressure Sudden unexpected cardiac death, including cardiac arrest, where symptoms may suggest MI, an ECG may be taken with suggestive changes, or a blood clot is found in a coronary artery by angiography and/or at autopsy, but where blood samples could not be obtained, or at a time before the appearance of cardiac biomarkers in the blood Associated with coronary angioplasty or stents Associated with percutaneous coronary intervention (PCI) Associated with stent thrombosis as documented by angiography or at autopsy Associated with CABG Associated with spontaneous coronary artery dissection in young, fit women  Cardiac biomarkers  There are many different biomarkers used to determine the presence of cardiac muscle damage. Troponins, measured through a blood test, are considered to be the best, and are preferred because they have greater sensitivity and specificity for measuring injury to the heart muscle than other tests. A rise in troponin occurs within 2–3 hours of injury to the heart muscle, and peaks within 1–2 days. The level of the troponin, as well as a change over time, are useful in measuring and diagnosing or excluding myocardial infarctions, and the diagnostic accuracy of troponin testing is improving over time. One high-sensitivity cardiac troponin can rule out a heart attack as long as the ECG is normal.Other tests, such as CK-MB or myoglobin, are discouraged. CK-MB is not as specific as troponins for acute myocardial injury, and may be elevated with past cardiac surgery, inflammation or electrical cardioversion; it rises within 4–8 hours and returns to normal within 2–3 days. Copeptin may be useful to rule out MI rapidly when used along with troponin.  Electrocardiogram  Electrocardiograms (ECGs) are a series of leads placed on a person's chest that measure electrical activity associated with contraction of the heart muscle. The taking of an ECG is an important part of the workup of an AMI, and ECGs are often not just taken once but may be repeated over minutes to hours, or in response to changes in signs or symptoms.ECG readouts product a waveform with different labelled features. In addition to a rise in biomarkers, a rise in the ST segment, changes in the shape or flipping of T waves, new Q waves, or a new left bundle branch block can be used to diagnose an AMI. In addition, ST elevation can be used to diagnose an ST segment myocardial infarction (STEMI). A rise must be new in V2 and V3 ≥2 mm (0,2 mV) for males or ≥1.5 mm (0.15 mV) for females or ≥1 mm (0.1 mV) in two other adjacent chest or limb leads. ST elevation is associated with infarction, and may be preceded by changes indicating ischemia, such as ST depression or inversion of the T waves. Abnormalities can help differentiate the location of an infarct, based on the leads that are affected by changes. Early STEMIs may be preceded by peaked T waves. Other ECG abnormalities relating to complications of acute myocardial infarctions may also be evident, such as atrial or ventricular fibrillation.  Imaging  Noninvasive imaging plays an important role in the diagnosis and characterisation of myocardial infarction. Tests such as chest X-rays can be used to explore and exclude alternate causes of a person's symptoms. Echocardiography may assist in modifying clinical suspicion of ongoing myocardial infarction in patients that can't be ruled out or ruled in following initial ECG and Troponin testing. Myocardial perfusion imaging has no role in the acute diagnostic algorithm, however it can confirm a clinical suspicion of Chronic Coronary Syndrome when the patient's history, physical examination (including cardiac examination) ECG, and cardiac biomarkers suggest coronary artery disease.Echocardiography, an ultrasound scan of the heart, is able to visualize the heart, its size, shape, and any abnormal motion of the heart walls as they beat that may indicate a myocardial infarction. The flow of blood can be imaged, and contrast dyes may be given to improve image. Other scans using radioactive contrast include SPECT CT-scans using thallium, sestamibi (MIBI scans) or tetrofosmin; or a PET scan using Fludeoxyglucose or rubidium-82. These nuclear medicine scans can visualize the perfusion of heart muscle. SPECT may also be used to determine viability of tissue, and whether areas of ischemia are inducible.Medical societies and professional guidelines recommend that the physician confirm a person is at high risk for Chronic Coronary Syndrome before conducting diagnostic non-invasive imaging tests to make a diagnosis, as such tests are unlikely to change management and result in increased costs. Patients who have a normal ECG and who are able to exercise, for example, most likely do not merit routine imaging.  Differential diagnosis  There are many causes of chest pain, which can originate from the heart, lungs, gastrointestinal tract, aorta, and other muscles, bones and nerves surrounding the chest. In addition to myocardial infarction, other causes include angina, insufficient blood supply (ischemia) to the heart muscles without evidence of cell death, gastroesophageal reflux disease; pulmonary embolism, tumors of the lungs, pneumonia, rib fracture, costochondritis, heart failure and other musculoskeletal injuries. Rarer severe differential diagnoses include aortic dissection, esophageal rupture, tension pneumothorax, and pericardial effusion causing cardiac tamponade. The chest pain in an MI may mimic heartburn. Causes of sudden-onset breathlessness generally involve the lungs or heart – including pulmonary edema, pneumonia, allergic reactions and asthma, and pulmonary embolus, acute respiratory distress syndrome and metabolic acidosis. There are many different causes of fatigue, and myocardial infarction is not a common cause.  Prevention  There is a large crossover between the lifestyle and activity recommendations to prevent a myocardial infarction, and those that may be adopted as secondary prevention after an initial myocardial infarction, because of shared risk factors and an aim to reduce atherosclerosis affecting heart vessels. The influenza vaccine also appear to protect against myocardial infarction with a benefit of 15 to 45%.  Primary prevention   Lifestyle  Physical activity can reduce the risk of cardiovascular disease, and people at risk are advised to engage in 150 minutes of moderate or 75 minutes of vigorous-intensity aerobic exercise a week. Keeping a healthy weight, drinking alcohol within the recommended limits, and quitting smoking reduce the risk of cardiovascular disease.Substituting unsaturated fats such as olive oil and rapeseed oil instead of saturated fats may reduce the risk of myocardial infarction, although there is not universal agreement. Dietary modifications are recommended by some national authorities, with recommendations including increasing the intake of wholegrain starch, reducing sugar intake (particularly of refined sugar), consuming five portions of fruit and vegetables daily, consuming two or more portions of fish per week, and consuming 4–5 portions of unsalted nuts, seeds, or legumes per week. The dietary pattern with the greatest support is the Mediterranean diet. Vitamins and mineral supplements are of no proven benefit, and neither are plant stanols or sterols.Public health measures may also act at a population level to reduce the risk of myocardial infarction, for example by reducing unhealthy diets (excessive salt, saturated fat, and trans fat) including food labeling and marketing requirements as well as requirements for catering and restaurants, and stimulating physical activity. This may be part of regional cardiovascular disease prevention programs or through the health impact assessment of regional and local plans and policies.Most guidelines recommend combining different preventive strategies. A 2015 Cochrane Review found some evidence that such an approach might help with blood pressure, body mass index and waist circumference. However, there was insufficient evidence to show an effect on mortality or actual cardio-vascular events.  Medication  Statins, drugs that act to lower blood cholesterol, decrease the incidence and mortality rates of myocardial infarctions. They are often recommended in those at an elevated risk of cardiovascular diseases.Aspirin has been studied extensively in people considered at increased risk of myocardial infarction. Based on numerous studies in different groups (e.g. people with or without diabetes), there does not appear to be a benefit strong enough to outweigh the risk of excessive bleeding. Nevertheless, many clinical practice guidelines continue to recommend aspirin for primary prevention, and some researchers feel that those with very high cardiovascular risk but low risk of bleeding should continue to receive aspirin.  Secondary prevention  There is a large crossover between the lifestyle and activity recommendations to prevent a myocardial infarction, and those that may be adopted as secondary prevention after an initial myocardial infarct. Recommendations include stopping smoking, a gradual return to exercise, eating a healthy diet, low in saturated fat and low in cholesterol, drinking alcohol within recommended limits, exercising, and trying to achieve a healthy weight. Exercise is both safe and effective even if people have had stents or heart failure, and is recommended to start gradually after 1–2 weeks. Counselling should be provided relating to medications used, and for warning signs of depression. Previous studies suggested a benefit from omega-3 fatty acid supplementation but this has not been confirmed.  Medications  Following a heart attack, nitrates, when taken for two days, and ACE-inhibitors decrease the risk of death. Other medications include: Aspirin is continued indefinitely, as well as another antiplatelet agent such as clopidogrel or ticagrelor (""dual antiplatelet therapy"" or DAPT) for up to twelve months. If someone has another medical condition that requires anticoagulation (e.g. with warfarin) this may need to be adjusted based on risk of further cardiac events as well as bleeding risk. In those who have had a stent, more than 12 months of clopidogrel plus aspirin does not affect the risk of death.Beta blocker therapy such as metoprolol or carvedilol is recommended to be started within 24 hours, provided there is no acute heart failure or heart block. The dose should be increased to the highest tolerated. Contrary to what was long believed, the use of beta blockers does not appear to affect the risk of death, possibly because other treatments for MI have improved. When beta blocker medication is given within the first 24–72 hours of a STEMI no lives are saved. However, 1 in 200 people were prevented from a repeat heart attack, and another 1 in 200 from having an abnormal heart rhythm. Additionally, for 1 in 91 the medication causes a temporary decrease in the heart's ability to pump blood.ACE inhibitor therapy should be started within 24 hours, and continued indefinitely at the highest tolerated dose. This is provided there is no evidence of worsening kidney failure, high potassium, low blood pressure, or known narrowing of the renal arteries. Those who cannot tolerate ACE inhibitors may be treated with an angiotensin II receptor antagonist.Statin therapy has been shown to reduce mortality and subsequent cardiac events and should be commenced to lower LDL cholesterol. Other medications, such as ezetimibe, may also be added with this goal in mind.Aldosterone antagonists (spironolactone or eplerenone) may be used if there is evidence of left ventricular dysfunction after an MI, ideally after beginning treatment with an ACE inhibitor.  Other  A defibrillator, an electric device connected to the heart and surgically inserted under the skin, may be recommended. This is particularly if there are any ongoing signs of heart failure, with a low left ventricular ejection fraction and a New York Heart Association grade II or III after 40 days of the infarction. Defibrillators detect potentially fatal arrhythmia and deliver an electrical shock to the person to depolarize a critical mass of the heart muscle.  Management  A myocardial infarction requires immediate medical attention. Treatment aims to preserve as much heart muscle as possible, and to prevent further complications. Treatment depends on whether the myocardial infarction is a STEMI or NSTEMI. Treatment in general aims to unblock blood vessels, reduce blood clot enlargement, reduce ischemia, and modify risk factors with the aim of preventing future MIs. In addition, the main treatment for myocardial infarctions with ECG evidence of ST elevation (STEMI) include thrombolysis or percutaneous coronary intervention, although PCI is also ideally conducted within 1–3 days for NSTEMI. In addition to clinical judgement, risk stratification may be used to guide treatment, such as with the TIMI and GRACE scoring systems.  Pain  The pain associated with myocardial infarction is often treated with nitroglycerin, a vasodilator, or opioid medications such as morphine. Nitroglycerin (given under the tongue or injected into a vein) may improve blood supply to the heart. It is an important part of therapy for its pain relief effects, though there is no proven benefit to mortality. Morphine or other opioid medications may also be used, and are effective for the pain associated with STEMI. There is poor evidence that morphine shows any benefit to overall outcomes, and there is some evidence of potential harm.  Antithrombotics  Aspirin, an antiplatelet drug, is given as a loading dose to reduce the clot size and reduce further clotting in the affected artery. It is known to decrease mortality associated with acute myocardial infarction by at least 50%. P2Y12 inhibitors such as clopidogrel, prasugrel and ticagrelor are given concurrently, also as a loading dose, with the dose depending on whether further surgical management or fibrinolysis is planned. Prasugrel and ticagrelor are recommended in European and American guidelines, as they are active more quickly and consistently than clopidogrel. P2Y12 inhibitors are recommended in both NSTEMI and STEMI, including in PCI, with evidence also to suggest improved mortality. Heparins, particularly in the unfractionated form, act at several points in the clotting cascade, help to prevent the enlargement of a clot, and are also given in myocardial infarction, owing to evidence suggesting improved mortality rates. In very high-risk scenarios, inhibitors of the platelet glycoprotein αIIbβ3a receptor such as eptifibatide or tirofiban may be used.There is varying evidence on the mortality benefits in NSTEMI. A 2014 review of P2Y12 inhibitors such as clopidogrel found they do not change the risk of death when given to people with a suspected NSTEMI prior to PCI, nor do heparins change the risk of death. They do decrease the risk of having a further myocardial infarction.  Angiogram  Primary percutaneous coronary intervention (PCI) is the treatment of choice for STEMI if it can be performed in a timely manner, ideally within 90–120 minutes of contact with a medical provider. Some recommend it is also done in NSTEMI within 1–3 days, particularly when considered high-risk. A 2017 review, however, did not find a difference between early versus later PCI in NSTEMI.PCI involves small probes, inserted through peripheral blood vessels such as the femoral artery or radial artery into the blood vessels of the heart. The probes are then used to identify and clear blockages using small balloons, which are dragged through the blocked segment, dragging away the clot, or the insertion of stents. Coronary artery bypass grafting is only considered when the affected area of heart muscle is large, and PCI is unsuitable, for example with difficult cardiac anatomy. After PCI, people are generally placed on aspirin indefinitely and on dual antiplatelet therapy (generally aspirin and clopidogrel) for at least a year.  Fibrinolysis  If PCI cannot be performed within 90 to 120 minutes in STEMI then fibrinolysis, preferably within 30 minutes of arrival to hospital, is recommended. If a person has had symptoms for 12 to 24 hours evidence for effectiveness of thrombolysis is less and if they have had symptoms for more than 24 hours it is not recommended. Thrombolysis involves the administration of medication that activates the enzymes that normally dissolve blood clots. These medications include tissue plasminogen activator, reteplase, streptokinase, and tenecteplase. Thrombolysis is not recommended in a number of situations, particularly when associated with a high risk of bleeding or the potential for problematic bleeding, such as active bleeding, past strokes or bleeds into the brain, or severe hypertension. Situations in which thrombolysis may be considered, but with caution, include recent surgery, use of anticoagulants, pregnancy, and proclivity to bleeding. Major risks of thrombolysis are major bleeding and intracranial bleeding. Pre-hospital thrombolysis reduces time to thrombolytic treatment, based on studies conducted in higher income countries, however it is unclear whether this has an impact on mortality rates.  Other  In the past, high flow oxygen was recommended for everyone with a possible myocardial infarction. More recently, no evidence was found for routine use in those with normal oxygen levels and there is potential harm from the intervention. Therefore, oxygen is currently only recommended if oxygen levels are found to be low or if someone is in respiratory distress.If despite thrombolysis there is significant cardiogenic shock, continued severe chest pain, or less than a 50% improvement in ST elevation on the ECG recording after 90 minutes, then rescue PCI is indicated emergently.Those who have had cardiac arrest may benefit from targeted temperature management with evaluation for implementation of hypothermia protocols. Furthermore, those with cardiac arrest, and ST elevation at any time, should usually have angiography. Aldosterone antagonists appear to be useful in people who have had an STEMI and do not have heart failure.  Rehabilitation and exercise  Cardiac rehabilitation benefits many who have experienced myocardial infarction, even if there has been substantial heart damage and resultant left ventricular failure. It should start soon after discharge from the hospital. The program may include lifestyle advice, exercise, social support, as well as recommendations about driving, flying, sports participation, stress management, and sexual intercourse. Returning to sexual activity after myocardial infarction is a major concern for most patients, and is an important area to be discussed in the provision of holistic care.In the short-term, exercise-based cardiovascular rehabilitation programs may reduce the risk of a myocardial infarction, reduces a large number of hospitalizations from all causes, reduces hospital costs, improves health-related quality of life, and has a small effect on all-cause mortality. Longer-term studies indicate that exercise-based cardiovascular rehabilitation programs may reduce cardiovascular mortality and myocardial infarction.  Prognosis  The prognosis after myocardial infarction varies greatly depending on the extent and location of the affected heart muscle, and the development and management of complications. Prognosis is worse with older age and social isolation. Anterior infarcts, persistent ventricular tachycardia or fibrillation, development of heart blocks, and left ventricular impairment are all associated with poorer prognosis. Without treatment, about a quarter of those affected by MI die within minutes and about forty percent within the first month. Morbidity and mortality from myocardial infarction has however improved over the years due to earlier and better treatment: in those who have a STEMI in the United States, between 5 and 6 percent die before leaving the hospital and 7 to 18 percent die within a year.It is unusual for babies to experience a myocardial infarction, but when they do, about half die. In the short-term, neonatal survivors seem to have a normal quality of life.  Complications  Complications may occur immediately following the myocardial infarction or may take time to develop. Disturbances of heart rhythms, including atrial fibrillation, ventricular tachycardia and fibrillation and heart block can arise as a result of ischemia, cardiac scarring, and infarct location. Stroke is also a risk, either as a result of clots transmitted from the heart during PCI, as a result of bleeding following anticoagulation, or as a result of disturbances in the heart's ability to pump effectively as a result of the infarction. Regurgitation of blood through the mitral valve is possible, particularly if the infarction causes dysfunction of the papillary muscle. Cardiogenic shock as a result of the heart being unable to adequately pump blood may develop, dependent on infarct size, and is most likely to occur within the days following an acute myocardial infarction. Cardiogenic shock is the largest cause of in-hospital mortality. Rupture of the ventricular dividing wall or left ventricular wall may occur within the initial weeks. Dressler's syndrome, a reaction following larger infarcts and a cause of pericarditis is also possible.Heart failure may develop as a long-term consequence, with an impaired ability of heart muscle to pump, scarring, and an increase in the size of the existing muscle. Aneurysm of the left ventricle myocardium develops in about 10% of MI and is itself a risk factor for heart failure, ventricular arrhythmia, and the development of clots.Risk factors for complications and death include age, hemodynamic parameters (such as heart failure, cardiac arrest on admission, systolic blood pressure, or Killip class of two or greater), ST-segment deviation, diabetes, serum creatinine, peripheral vascular disease, and elevation of cardiac markers.  Epidemiology  Myocardial infarction is a common presentation of coronary artery disease. The World Health Organization estimated in 2004, that 12.2% of worldwide deaths were from ischemic heart disease; with it being the leading cause of death in high- or middle-income countries and second only to lower respiratory infections in lower-income countries. Worldwide, more than 3 million people have STEMIs and 4 million have NSTEMIs a year. STEMIs occur about twice as often in men as women.Rates of death from ischemic heart disease (IHD) have slowed or declined in most high-income countries, although cardiovascular disease still accounted for one in three of all deaths in the US in 2008. For example, rates of death from cardiovascular disease have decreased almost a third between 2001 and 2011 in the United States.In contrast, IHD is becoming a more common cause of death in the developing world. For example, in India, IHD had become the leading cause of death by 2004, accounting for 1.46 million deaths (14% of total deaths) and deaths due to IHD were expected to double during 1985–2015. Globally, disability adjusted life years (DALYs) lost to ischemic heart disease are predicted to account for 5.5% of total DALYs in 2030, making it the second-most-important cause of disability (after unipolar depressive disorder), as well as the leading cause of death by this date.  Social determinants of health  Social determinants such as neighborhood disadvantage, immigration status, lack of social support, social isolation, access to health services play an important role in myocardial infarction risk and survival. Studies have shown that low socioeconomic status is associated with an increased risk of poorer survival. There are well-documented disparities in myocardial infarction survival by socioeconomic status, race, education, and census-tract-level poverty.Race: In the U.S. African Americans have a greater burden of myocardial infarction and other cardiovascular events. On a population level, there is a higher overall prevalence of risk factors that are unrecognized and therefore not treated, which places these individuals at a greater likelihood of experiencing adverse outcomes and therefore potentially higher morbidity and mortality.Socioeconomic status: Among individuals who live in the low-socioeconomic (SES) areas, which is close to 25% of the US population, myocardial infarctions (MIs) occurred twice as often compared with people who lived in higher SES areas.Immigration status: In 2018 many lawfully present immigrants who are eligible for coverage remain uninsured because immigrant families face a range of enrollment barriers, including fear, confusion about eligibility policies, difficulty navigating the enrollment process, and language and literacy challenges. Uninsured undocumented immigrants are ineligible for coverage options due to their immigration status.Health care access: Lack of health insurance and financial concerns about accessing care were associated with delays in seeking emergency care for acute myocardial infarction which can have significant, adverse consequences on patient outcomes.Education: Researchers found that compared to people with graduate degrees, those with lower educational attainment appeared to have a higher risk of heart attack, dying from a cardiovascular event, and overall death.  Society and culture  Depictions of heart attacks in popular media often include collapsing or loss of consciousness which are not common symptoms; these depictions contribute to widespread misunderstanding about the symptoms of myocardial infarctions, which in turn contributes to people not getting care when they should.  Legal implications  At common law, in general, a myocardial infarction is a disease, but may sometimes be an injury. This can create coverage issues in the administration of no-fault insurance schemes such as workers' compensation. In general, a heart attack is not covered; however, it may be a work-related injury if it results, for example, from unusual emotional stress or unusual exertion. In addition, in some jurisdictions, heart attacks had by persons in particular occupations such as police officers may be classified as line-of-duty injuries by statute or policy. In some countries or states, a person having had an MI may be prevented from participating in activity that puts other people's lives at risk, for example driving a car or flying an airplane.  References   Sources  Allison TG (6 December 2012). ""Stress Test Selection"". In Margaret A. Lloyd (ed.). Mayo Clinic Cardiology: Concise Textbook. Joseph G. Murphy. OUP US. pp. 196–202. ISBN 978-0-19-991571-2. Blumenthal RS, Margolis S (2007). Heart Attack Prevention 2007. Johns Hopkins Health. ISBN 978-1-933087-47-4. Dwight J (16 June 2016). ""Chest pain, breathlessness, fatigue"". In Timothy Cox (ed.). Oxford Textbook of Medicine: Cardiovascular Disorders. Jeremy Dwight. Oxford University Press. pp. 39–47. ISBN 978-0-19-871702-7. Gaziano TA, Gaziano JM (15 September 2016). ""Global Evolving Epidemiology, Natural History, and Treatment Trends of Myocardial Infarction"". In Morrow DA (ed.). Myocardial Infarction: A Companion to Braunwald's Heart Disease. Elsevier. pp. 11–21. ISBN 978-0-323-35943-6. Morrow DA, Bohula EA (15 September 2016). ""Heart Failure and Cardiogenic Shock After Myocardial Infarction"". In Morrow DA (ed.). Myocardial Infarction: A Companion to Braunwald's Heart Disease. Elsevier. pp. 295–313. ISBN 978-0-323-35943-6. Morrow DA, Braunwald E (15 September 2016). ""Classification and Diagnosis of Acute Coronary Syndromes"". In Morrow DA (ed.). Myocardial Infarction: A Companion to Braunwald's Heart Disease. Elsevier. pp. 1–10. ISBN 978-0-323-35943-6. Morrow DA (15 September 2016). ""Clinical Approach to Suspected Acute Myocardial Infarction"". In Morrow DA (ed.). Myocardial Infarction: A Companion to Braunwald's Heart Disease. Elsevier. pp. 55–65. ISBN 978-0-323-35943-6.  Further reading   External links  Myocardial infarction at Curlie American Heart Association's Heart Attack web site — Information and resources for preventing, recognizing, and treating a heart attack. TIMI Score for UA/NSTEMI Archived 2016-11-05 at the Wayback Machine and STEMI Archived 2009-03-19 at the Wayback Machine HEART Score for Major Cardiac Events Archived 2016-10-28 at the Wayback Machine ""Heart Attack"". MedlinePlus. U.S. National Library of Medicine.","A myocardial infarction, also and commonly called a heart attack, happens when a blood vessel in the heart suddenly becomes blocked. Blood vessels carry blood and oxygen. When a blood vessel in the heart gets blocked, blood cannot get to part of the heart. This part of the heart does not get enough oxygen. This is called ischemia. When the heart muscle becomes ischemic (does not get enough blood and oxygen), the ischemia often causes chest pain. This is called Angina Pectoris. If the ischemia lasts long enough, the heart muscle that is not getting enough oxygen dies. This is called an infarction. ""Myocardial infarction"" means ""infarction (muscle death) in the heart muscle."" A heart attack is a medical emergency. The first few minutes are very important for keeping the person alive. Some of the damage from the heart attack can be repaired if the person gets treatment during the first hour of the attack.  Causes  Most heart attacks are caused by Coronary Artery Disease (CAD). In coronary artery disease, a wax-like material called plaque builds up on the inside walls of arteries in the heart. This is called atherosclerosis. Plaque is made of cholesterol and other cells. The amount of plaque increases slowly. As more plaque builds up, the insides of the heart's blood vessels get narrower. This means that less blood can flow through the blood vessels. This can cause platelets (which make the blood clot) to build up in front of the plaque. This causes a blood clot in the blood vessel. If the clot breaks free and gets stuck in part of the blood vessel made narrower by the plaque, the plaque and the clot together block the blood vessel completely. This makes it impossible for blood to get to part of the heart, and causes a heart attack. A person can lower their chances of getting coronary artery disease by eating healthy foods, exercising, not smoking cigarettes, and not drinking too much alcohol.  Symptoms  Signs that a person is having a heart attack show over several minutes, and rarely come immediately. Most people having a heart attack have chest pain. Sometimes, people also have pain in the left arm, the lower jaw, the neck, the right arm, the back, or in parts of the abdomen. Many women have different symptoms than men. The most common symptoms include shortness of breath (trouble breathing), weakness, and feeling very tired. Some women feel tired, do not sleep properly, and have shortness of breath for up to a month before they have a heart attack. Women may also have nausea and stomach upset when having a heart attack. Sometimes, people have ""silent heart attacks."" These are heart attacks that do not cause any pain. They are more common in elderly people, women, and people with diabetes. In these people, suddenly feeling very tired, or fainting, may be the only sign of a heart attack.  Treatment  A heart attack is a medical emergency that needs treatment as quickly as possible. The most important thing is to save as much myocardium (heart muscle) as possible and prevent more complications. As time passes, the risk of damage to the heart muscle increases. Doctors or paramedics usually start certain treatments as soon as a heart attack is suspected. These treatments include: Aspirin. Aspirin is an early and important treatment for a heart attack. Aspirin keeps platelets from sticking together, and can help prevent more blood clots from forming inside the blood vessels and the heart. Nitroglycerin (nitro). Nitro widens the blood vessels in the heart. This makes it easier for blood to flow through those vessels to the heart. Oxygen (if needed). If the patient is having trouble breathing, oxygen can be given. Pain medicine for chest pain (if needed).Once doctors are sure that a person is having a heart attack, there are two main treatments: ""clot-busting medicines"" (thrombolytics) and percutaneous coronary intervention.  Clot busters  ""Clot-busting medicines"" (called thrombolytics) can dissolve blood clots that are blocking the blood vessels in the heart. This makes it possible for blood and oxygen to flow again to the part of the heart that was not getting enough blood and oxygen. The most common clot-busting medicine is called tissue plasminogen activator (tPA).Clot-busters work best if patients get them within 30 minutes after getting to the hospital. However, if a patient gets a clot-busting medicine within 12 hours after the heart attack starts, they have a better chance of surviving.Clot-busting medicines do have some risks. Sometimes they can thin the blood too much and cause bleeding.  Percutaneous coronary intervention  Percutaneous coronary intervention is a way of opening blocked coronary arteries. Percutaneous means that the procedure is not done by cutting a person open in surgery. Coronary intervention means ""way to help the heart"". Percutaneous coronary intervention is also called ""coronary angioplasty"". In a percutaneous coronary intervention, a doctor threads a flexible tube into one of the patient's blood vessels, usually one in the upper thigh. The doctor threads the tube up to the blocked blood vessels in the heart. On the end of the tube is a balloon. The doctor blows up the balloon, which pushes the plaque and blood clot against the side of the blocked blood vessel. This allows blood to flow through that blood vessel again. Sometimes, a doctor might also place a small mesh tube called a stent into the blood vessel. The stent will make sure the blood vessel stays open and does not get blocked again in the future.  First Aid  As soon as a person thinks they may be having signs of a heart attack, they should call emergency service right away. (Emergency services can be reached dialling 911 in the US, and 112 in most of continental Europe) However, the average person waits about three hours before asking for help. When a person waits to get help, they are more likely to have more serious damage to their heart. The American Heart Association says ""time is muscle"": the more time a person waits to get treatment, the more heart muscle dies. If a person is having trouble breathing, sitting straight up can help. The person should follow any instructions they get from the emergency operator or their doctor.  References "
"Heartburn, also known as pyrosis, cardialgia or acid indigestion, is a burning sensation in the central chest or upper central abdomen. Heartburn is usually due to regurgitation of gastric acid (gastric reflux) into the esophagus. It is the major symptom of gastroesophageal reflux disease (GERD).Other common descriptors for heartburn (besides burning) are belching, nausea, squeezing, stabbing, or a sensation of pressure on the chest. The pain often rises in the chest (directly behind the breastbone) and may radiate to the neck, throat, or angle of the arm. Because the chest houses other important organs besides the esophagus (including the heart and lungs), not all symptoms related to heartburn are esophageal in nature.The cause will vary depending on one's family and medical history, genetics, if a person is pregnant or lactating, and age. As a result, the diagnosis will vary depending on the suspected organ and the inciting disease process. Work-up will vary depending on the clinical suspicion of the provider seeing the patient, but generally includes endoscopy and a trial of antacids to assess for relief.Treatment for heartburn may include medications and dietary changes. Medication include antacids. Dietary changes may require avoiding foods that are high in fats, spicy, high in artificial flavors, heavily reducing NSAID use, heavy alcohol consumption, and decreasing peppermint consumption. Lifestyle changes may help such as reducing weight.  Definition  The term indigestion includes heartburn along with a number of other symptoms. Indigestion is sometimes defined as a combination of epigastric pain and heartburn. Heartburn is commonly used interchangeably with gastroesophageal reflux disease (GERD) rather than just to describe a symptom of burning in one's chest.  Differential diagnosis  Heartburn-like symptoms and/or lower chest or upper abdomen may be indicative of much more sinister and/or deadly disease. Of greatest concern is to confuse heartburn (generally related to the esophagus) with a heart attack as these organs share a common nerve supply. Numerous abdominal and thoracic organs are present in that region of the body. Many different organ systems might explain the discomfort called heartburn.  Heart  The most common symptom for a heart attack is chest pain. However, as many as 30% of chest pain patients undergoing cardiac catheterization have findings that do not account for their chest discomfort. These are often defined as having ""atypical chest pain"" or chest pain of undetermined origin. Women experiencing heart attacks may also deny classic signs and symptoms and instead complain of GI symptoms. One article estimates that ischemic heart disease may appear to be GERD in 0.6% of people.  Esophagus  GERD (most common cause of heartburn) occurs when acid refluxes from the stomach and inflames the esophagus. Esophageal spasms typically occur after eating or drinking and may be combined with difficulty swallowing. Esophageal strictures Esophageal cancers  Esophagitis  GERD Eosinophilic esophagitis – a disease commonly associated with other atopic diseases such as asthma, food allergies, seasonal allergies, and atopic skin disease Mallory-Weis tears – tears of the superficial mucosa of the esophagus that are subsequently exposed to gastric acid commonly due to vomiting and/or retching Chemical esophagitis – related to the intake of caustic substances, excessive amounts of hot liquids, alcohol, or tobacco smoke Infections may explain heartburn symptoms. These especially include CMV and certain fungal infections, most common in immunocompromised persons  Stomach  Peptic ulcer disease – can be secondary to H. Pylori infection or heavy NSAID use that weakens stomach mucosal layer. Pain often worsens with eating. Stomach cancer  Intestines  Intestinal ulcers – generally secondary to other conditions such as H. Pylori infection or cancers of the GI tract. Pain often improves with eating. Duodenitis – inflammation of the small intestine. May be the result of several conditions  Gallbladder  Gallstones  Pancreas  Pancreatitis – can be autoimmune, due to a gallstone obstructing the lumen, related to alcohol consumption.  Hematology  Pernicious anemia – can be autoimmune, due to atrophic gastritis.  Pregnancy  Heartburn is common during pregnancy having been reported in as high as 80% of pregnancies. It is most often due to GERD and results from relaxation of the lower esophageal sphincter (LES), changes in gastric motility, and/or increasing intra-abdominal pressure. The onset of symptoms can be during any trimester of pregnancy. Hormonal – related to the increasing amounts of estrogen and progesterone and their effect on the LES Mechanical – the enlarging uterus increasing intra-abdominal pressure, inducing reflux of gastric acid Behavioral – as with other instances of heartburn, behavioral modifications can exacerbate or alleviate symptoms  Unknown origin  Functional heartburn is heartburn of unknown cause. It is commonly associated with psychiatric conditions like depression, anxiety, and panic attacks. It is also seen with other functional gastrointestinal disorders like irritable bowel syndrome and is the primary cause of lack of improvement post treatment with proton pump inhibitors (PPIs). Despite this, PPIs are still the primary treatment with response rates in about 50% of people. The diagnosis is one of elimination, based upon the Rome III criteria. It was found to be present in 22.3% of Canadians in one survey.  Diagnostic approach  Heartburn can be caused by several conditions and a preliminary diagnosis of GERD is based on additional signs and symptoms. The chest pain caused by GERD has a distinct 'burning' sensation, occurs after eating or at night, and worsens when a person lies down or bends over. It also is common in pregnant women, and may be triggered by consuming food in large quantities, or specific foods containing certain spices, high fat content, or high acid content. In young persons (typically <40 years) who present with heartburn symptoms consistent with GERD (onset after eating, when lying down, when pregnant), a physician may begin a course of PPIs to assess clinical improvement before additional testing is undergone. Resolution or improvement of symptoms on this course may result in a diagnosis of GERD.Other tests or symptoms suggesting acid reflux is causing heartburn include: Onset of symptoms after eating or drinking, at night, and/or with pregnancy, and improvement with PPIs Endoscopy looking for erosive changes of the esophagus consistent with prolonged acid exposure (e.g. - Barrett's esophagus) Upper GI series looking for the presence of acid reflux  GI cocktail  Relief of symptoms 5 to 10 minutes after the administration of viscous lidocaine and an antacid increases the suspicion that the pain is esophageal in origin. This however does not rule out a potential cardiac cause as 10% of cases of discomfort due to cardiac causes are improved with antacids.  Biochemical  Esophageal pH monitoring: a probe can be placed via the nose into the esophagus to record the level of acidity in the lower esophagus. Because some degree of variation in acidity is normal, and small reflux events are relatively common, esophageal pH monitoring can be used to document reflux in real-time. Patients are able to record symptom onset to correlate lower esophageal pH with time of symptom onset.  Mechanical  Manometry: in this test, a pressure sensor (manometer) is passed via the mouth into the esophagus and measures the pressure of the LES directly.Endoscopy: the esophageal mucosa can be visualized directly by passing a thin, lighted tube with a tiny camera known as an endoscope attached through the mouth to examine the oesophagus and stomach. In this way, evidence of esophageal inflammation can be detected, and biopsies taken if necessary. Since an endoscopy allows a doctor to visually inspect the upper digestive tract the procedure may help identify any additional damage to the tract that may not have been detected otherwise.Biopsy: a small sample of tissue from the oesophagus is removed. It is then studied to check for inflammation, cancer, or other problems.  Treatment  Treatment plans are tailored to the specific diagnosis and etiology of the heartburn. Management of heartburn can be sorted into various categories.  Pharmacologic management  Antacids (i.e. calcium carbonate and sodium bicarbonate) are often taken to treat the immediate problem H2 receptor antagonists or proton pump inhibitors are effective for the two most common causes of heartburn (e.g. gastritis and GERD) Antibiotics are used if H. pylori is present.  Behavioral management  Taking medications 30–45 minutes before eating suppresses the stomach's acid generating response to food Avoiding spicy foods, foods high in fats, peppermint, and chocolate Avoiding reclining 2.5–3.5 hours after a meal to prevent the reflux of stomach's contents  Lifestyle modifications  Early studies show that diets that are high in fiber may show evidence in decreasing symptoms of dyspepsia. Weight loss can decrease abdominal pressure that both delays gastric emptying and increases gastric acid reflux into the esophagus  Alternative and complementary therapies  Symptoms of heartburn may not always be the result of an organic cause. Patients may respond better to therapies targeting anxiety and symptoms of hyper-vigilance, through medications aimed towards a psychiatric etiology, osteopathic manipulation and acupuncture. Psychotherapy may show a positive role in treatment of heartburn and the reduction of distress experienced during symptoms. Acupuncture - in cases of functional heartburn (e.g. heartburn of unknown origin) acupuncture may be as effective if not more than PPIs alone.  Surgical management  In the case of GERD causing heartburn symptoms, surgery may be required if PPI is not effective. Surgery is not undergone if functional heartburn is the leading diagnosis.  Epidemiology  About 42% of the United States population has had heartburn at some point.  References ","Heartburn is an uncomfortable feeling in the chest that happens when acids from the stomach travel up the esophagus (the tube leading from the mouth to the stomach). When stomach acids hurt the lining of the esophagus, the feeling is a symptom.The burning sensation is commonly called ""heartburn,"" but it has nothing to do with the heart.The symptom may be helped by taking antacids, such as calcium carbonate and sodium bicarbonate.  Related pages  Gastroesophageal reflux disease  References   Other websites  MedicineNet, GERD National Digestive Diseases Information Clearinghouse (NDDIC), GERD Archived 2012-04-11 at the Wayback Machine MedlinePlus, GERD"
"Nausea is a diffuse sensation of unease and discomfort, sometimes perceived as an urge to vomit. While not painful, it can be a debilitating symptom if prolonged and has been described as placing discomfort on the chest, abdomen, or back of the throat.Over 30 definitions of nausea were proposed in a 2011 book on the topic.Nausea is a non-specific symptom, which means that it has many possible causes. Some common causes of nausea are gastroenteritis and other gastrointestinal disorders, food poisoning, motion sickness, dizziness, migraine, fainting, low blood sugar, anxiety, hyperthermia, dehydration and lack of sleep. Nausea is a side effect of many medications including chemotherapy, or morning sickness in early pregnancy. Nausea may also be caused by disgust and depression.Medications taken to prevent and treat nausea and vomiting are called antiemetics. The most commonly prescribed antiemetics in the US are promethazine, metoclopramide, and the newer ondansetron. The word nausea is from Latin nausea, from Greek ναυσία – nausia, ""ναυτία"" – nautia, motion sickness, ""feeling sick or queasy"".  Causes  Gastrointestinal infections (37%) and food poisoning are the two most common causes of acute nausea and vomiting. Side effects from medications (3%) and pregnancy are also relatively frequent. There are many causes of chronic nausea. Nausea and vomiting remain undiagnosed in 10% of the cases. Aside from morning sickness, there are no sex differences in complaints of nausea. After childhood, doctor consultations decrease steadily with age. Only a fraction of one percent of doctor visits by those over 65 are due to nausea.  Gastrointestinal  Gastrointestinal infection is one of the most common causes of acute nausea and vomiting. Chronic nausea may be the presentation of many gastrointestinal disorders, occasionally as the major symptom, such as gastroesophageal reflux disease, functional dyspepsia, gastritis, biliary reflux, gastroparesis, peptic ulcer, celiac disease, non-celiac gluten sensitivity, Crohn's disease, hepatitis, upper gastrointestinal malignancy, and pancreatic cancer. Uncomplicated Helicobacter pylori infection does not cause chronic nausea.  Food poisoning  Food poisoning usually causes an abrupt onset of nausea and vomiting one to six hours after ingestion of contaminated food and lasts for one to two days. It is due to toxins produced by bacteria in food.  Medications  Many medications can potentially cause nausea. Some of the most frequently associated include cytotoxic chemotherapy regimens for cancer and other diseases, and general anaesthetic agents. An old cure for migraine, ergotamine, is well known to cause devastating nausea in some patients; a person using it for the first time will be prescribed an antiemetic for relief if needed.  Pregnancy  Nausea or ""morning sickness"" is common during early pregnancy but may occasionally continue into the second and third trimesters. In the first trimester nearly 80% of women have some degree of nausea. Pregnancy should therefore be considered as a possible cause of nausea in any sexually active woman of child-bearing age. While usually it is mild and self-limiting, severe cases known as hyperemesis gravidarum may require treatment.  Disequilibrium  A number of conditions involving balance such as motion sickness and vertigo can lead to nausea and vomiting.  Gynecologic  Dysmenorrhea can cause nausea.  Psychiatric  Nausea may be caused by depression, anxiety disorders and eating disorders.  Potentially serious  While most causes of nausea are not serious, some serious conditions are associated with nausea. These include pancreatitis, small bowel obstruction, appendicitis, cholecystitis, hepatitis, Addisonian crisis, diabetic ketoacidosis, increased intracranial pressure, spontaneous intracranial hypotension, brain tumors, meningitis, heart attack, rabies carbon monoxide poisoning and many others.  Comprehensive list   Inside the abdomen  Obstructing disorders Gastric outlet obstruction Small bowel obstruction Colonic obstruction Superior mesenteric artery syndromeEnteric infections Viral infection Bacterial infectionInflammatory diseases Celiac disease Cholecystitis Pancreatitis Appendicitis HepatitisSensorimotor dysfunction Gastroparesis Intestinal pseudo-obstruction Gastroesophageal reflux disease Irritable bowel syndrome Cyclic vomiting syndromeOther Non-celiac gluten sensitivity Biliary colic Kidney stone Cirrhosis Abdominal irradiation  Outside the abdomen  Cardiopulmonary Cardiomyopathy Myocardial infarction (heart attack) Paroxysmal coughInner-ear diseases Motion sickness Labyrinthitis MalignancyIntracerebral disorders Malignancy Hemorrhage Abscess Hydrocephalus Meningitis Encephalitis RabiesPsychiatric illnesses Anorexia and bulimia nervosa DepressionOther Post-operative vomiting Nociception  Medications and metabolic disorders  Drugs Chemotherapy Antibiotics Antiarrhythmics Digoxin Oral hypoglycemic medications Oral contraceptivesEndocrine/metabolic disease Pregnancy Uremia Ketoacidosis Thyroid and parathyroid disease Adrenal insufficiencyToxins Liver failure Alcohol  Pathophysiology  Research on nausea and vomiting has relied on using animal models to mimic the anatomy and neuropharmacologic features of the human body. The physiologic mechanism of nausea is a complex process that has yet to be fully elucidated. There are four general pathways that are activated by specific triggers in the human body that go on to create the sensation of nausea and vomiting. Central nervous system (CNS): Stimuli can affect areas of the CNS including the cerebral cortex and the limbic system. These areas are activated by elevated intracranial pressure, irritation of the meninges (i.e. blood or infection), and extreme emotional triggers such as anxiety. The supratentorial region is also responsible for the sensation of nausea. Chemoreceptor trigger zone (CTZ): The CTZ is located in the area postrema in the floor of the fourth ventricle within the brain. This area is outside the blood brain barrier, and is therefore readily exposed to substances circulating through the blood and cerebral spinal fluid. Common triggers of the CTZ include metabolic abnormalities, toxins, and medications. Activation of the CTZ is mediated by dopamine (D2) receptors, serotonin (5HT3) receptors, and neurokinin receptors (NK1). Vestibular system: This system is activated by disturbances to the vestibular apparatus in the inner ear. These include movements that cause motion sickness and dizziness. This pathway is triggered via histamine (H1) receptors and acetylcholine (ACh) receptors. Peripheral Pathways: These pathways are triggered via chemoreceptors and mechanoreceptors in the gastrointestinal tract, as well as other organs such as the heart and kidneys. Common activators of these pathways include toxins present in the gastrointestinal lumen and distension of the gastrointestinal lumen from blockage or dysmotility of the bowels. Signals from these pathways travel via multiple neural tracts including the vagus, glossopharyngeal, splanchnic, and sympathetic nerves.Signals from any of these pathways then travel to the brainstem, activating several structures including the nucleus of the solitary tract, the dorsal motor nucleus of the vagus, and central pattern generator. These structures go on to signal various downstream effects of nausea and vomiting. The body's motor muscle responses involve halting the muscles of the gastrointestinal tract, and in fact causing reversed propulsion of gastric contents towards the mouth while increasing abdominal muscle contraction. Autonomic effects involve increased salivation and the sensation of feeling faint that often occurs with nausea and vomiting.  Pre-nausea pathophysiology  It has been described that alterations in heart rate can occur as well as the release of vasopressin from the posterior pituitary.  Diagnosis   Patient history  Taking a thorough patient history may reveal important clues to the cause of nausea and vomiting. If the patient's symptoms have an acute onset, then drugs, toxins, and infections are likely. In contrast, a long-standing history of nausea will point towards a chronic illness as the culprit. The timing of nausea and vomiting after eating food is an important factor to pay attention to. Symptoms that occur within an hour of eating may indicate an obstruction proximal to the small intestine, such as gastroparesis or pyloric stenosis. An obstruction further down in the intestine or colon will cause delayed vomiting. An infectious cause of nausea and vomiting such as gastroenteritis may present several hours to days after the food was ingested. The contents of the emesis is a valuable clue towards determining the cause. Bits of fecal matter in the emesis indicate obstruction in the distal intestine or the colon. Emesis that is of a bilious nature (greenish in color) localizes the obstruction to a point past the stomach. Emesis of undigested food points to an obstruction prior to the gastric outlet, such as achalasia or Zenker's diverticulum. If patient experiences reduced abdominal pain after vomiting, then obstruction is a likely etiology. However, vomiting does not relieve the pain brought on by pancreatitis or cholecystitis.  Physical exam  It is important to watch out for signs of dehydration, such as orthostatic hypotension and loss of skin turgor. Auscultation of the abdomen can produce several clues to the cause of nausea and vomiting. A high-pitched tinkling sound indicates possible bowel obstruction, while a splashing ""succussion"" sound is more indicative of gastric outlet obstruction. Eliciting pain on the abdominal exam when pressing on the patient may indicate an inflammatory process. Signs such as papilledema, visual field losses, or focal neurological deficits are red flag signs for elevated intracranial pressure.  Diagnostic testing  When a history and physical exam are not enough to determine the cause of nausea and vomiting, certain diagnostic tests may prove useful. A chemistry panel would be useful for electrolyte and metabolic abnormalities. Liver function tests and lipase would identify pancreaticobiliary diseases. Abdominal X-rays showing air-fluid levels indicate bowel obstruction, while an X-ray showing air-filled bowel loops are more indicative of ileus. More advanced imaging and procedures may be necessary, such as a CT scan, upper endoscopy, colonoscopy, barium enema, or MRI. Abnormal GI motility can be assessed using specific tests like gastric scintigraphy, wireless motility capsules, and small-intestinal manometry.  Treatment  If dehydration is present due to loss of fluids from severe vomiting, rehydration with oral electrolyte solutions is preferred. If this is not effective or possible, intravenous rehydration may be required. Medical care is recommended if: a person cannot keep any liquids down, has symptoms more than 2 days, is weak, has a fever, has stomach pain, vomits more than two times in a day or does not urinate for more than 8 hours.  Medications  Many pharmacologic medications are available for the treatment of nausea. There is no medication that is clearly superior to other medications for all cases of nausea. The choice of antiemetic medication may be based on the situation during which the person experiences nausea. For people with motion sickness and vertigo, antihistamines and anticholinergics such as meclizine and scopolamine are particularly effective. Nausea and vomiting associated with migraine headaches respond best to dopamine antagonists such as metoclopramide, prochlorperazine, and chlorpromazine. In cases of gastroenteritis, serotonin antagonists such as ondansetron were found to suppress nausea and vomiting, as well as reduce the need for IV fluid resuscitation. The combination of pyridoxine and doxylamine is the first line treatment for pregnancy-related nausea and vomiting. Dimenhydrinate is an inexpensive and effective over the counter medication for preventing postoperative nausea and vomiting. Other factors to consider when choosing an antiemetic medication include the person's preference, side-effect profile, and cost. Nabilone is also indicated for this purpose.  Alternative medicine  In certain people, cannabinoids may be effective in reducing chemotherapy associated nausea and vomiting. Several studies have demonstrated the therapeutic effects of cannabinoids for nausea and vomiting in the advanced stages of illnesses such as cancer and AIDS.In hospital settings topical anti-nausea gels are not indicated because of lack of research backing their efficacy. Topical gels containing lorazepam, diphenhydramine, and haloperidol are sometimes used for nausea but are not equivalent to more established therapies.Ginger has also been shown to be potentially effective in treating several types of nausea.  Prognosis  The outlook depends on the cause. Most people recover within few hours or a day. While short-term nausea and vomiting are generally harmless, they may sometimes indicate a more serious condition. When associated with prolonged vomiting, it may lead to dehydration or dangerous electrolyte imbalances or both. Repeated intentional vomiting, characteristic of bulimia, can cause stomach acid to wear away at the enamel in teeth.  Epidemiology  Nausea and or vomiting is the main complaint in 1.6% of visits to family physicians in Australia. However, only 25% of people with nausea visit their family physician. In Australia, nausea, as opposed to vomiting, occurs most frequently in persons aged 15–24 years, and is less common in other age groups.  See also  Cancer and nausea Vasodilation  References   External links  The dictionary definition of nausea at Wiktionary","Nausea is a general feeling of unease and discomfort in the stomach, often with the urge to vomit. The word nausea comes from the Latin word for seasickness.Nausea is a symptom, rather than an illness or disease. The causes for it very often are not in the stomach itself, but somewhere else in the body. Nausea is often caused by a stomach virus. Nausea is usually harmless, in the short term. A good treatment for it can be not to take solid food (and to only drink non-alcoholic drinks, like water). Nausea can also occur during pregnancy, and is quite normal in that context. People can suffer nausea without vomiting.  References "
"Migraine (UK: , US: ) is a common neurological disorder characterized by recurrent headaches. Typically, the associated headache affects one side of the head, is pulsating in nature, may be moderate to severe in intensity, and could last from a few hours to three days. Non-headache symptoms may include nausea, vomiting, and sensitivity to light, sound, or smell. The pain is generally made worse by physical activity during an attack, although regular physical exercise may prevent future attacks. Up to one-third of people affected have aura: typically, it is a short period of visual disturbance that signals that the headache will soon occur. Occasionally, aura can occur with little or no headache following, but not everyone has this symptom.Migraine is believed to be due to a mixture of environmental and genetic factors. About two-thirds of cases run in families. Changing hormone levels may also play a role, as migraine affects slightly more boys than girls before puberty and two to three times more women than men. The risk of migraine usually decreases during pregnancy and after menopause. The underlying mechanisms are not fully known. They are, however, believed to involve the nerves and blood vessels of the brain.Initial recommended treatment is with simple pain medication such as ibuprofen and paracetamol (acetaminophen) for the headache, medication for the nausea, and the avoidance of triggers. Specific medications such as triptans or ergotamines may be used in those for whom simple pain medications are not effective. Caffeine in combination with other analgesics is safe and effective in treatment of acute migraine. Systematic reviews show a range of pharmacological treatments and medical devices reduce migraine frequency and intensity. Non-pharmacological interventions have also been shown to be effective, including oral magnesium, aerobic exercise, progressive strength training, and mindfulness-based therapy (including meditation, yoga, and acceptance-based approaches). There is suggestive evidence for the efficacy of acupuncture, CoQ10, and vitamin B2.Globally, approximately 15% of people are affected by migraine. In the Global Burden of Disease Study, conducted in 2010, migraines ranked as the third-most prevalent disorder in the world. It most often starts at puberty and is worst during middle age. As of 2016, it is one of the most common causes of disability. An early description consistent with migraines is contained in the Ebers papyrus, written around 1500 BC in ancient Egypt. The word migraine is from the Greek ἡμικρᾱνίᾱ (hēmikrāníā), 'pain in half of the head', from ἡμι- (hēmi-), 'half' and κρᾱνίον (krāníon), 'skull'.  Signs and symptoms  Migraine typically presents with self-limited, recurrent severe headache associated with autonomic symptoms. About 15–30% of people living with migraine experience episodes with aura, and they also frequently experience episodes without aura. The severity of the pain, duration of the headache, and frequency of attacks are variable. A migraine attack lasting longer than 72 hours is termed status migrainosus. There are four possible phases to a migraine attack, although not all the phases are necessarily experienced: The prodrome, which occurs hours or days before the headache The aura, which immediately precedes the headache The pain phase, also known as headache phase The postdrome, the effects experienced following the end of a migraine attackMigraine is associated with major depression, bipolar disorder, anxiety disorders, and obsessive–compulsive disorder. These psychiatric disorders are approximately 2–5 times more common in people without aura, and 3–10 times more common in people with aura.  Prodrome phase  Prodromal or premonitory symptoms occur in about 60% of those with migraines, with an onset that can range from two hours to two days before the start of pain or the aura. These symptoms may include a wide variety of phenomena, including altered mood, irritability, depression or euphoria, fatigue, craving for certain food(s), stiff muscles (especially in the neck), constipation or diarrhea, and sensitivity to smells or noise. This may occur in those with either migraine with aura or migraine without aura. Neuroimaging indicates the limbic system and hypothalamus as the origin of prodromal symptoms in migraine.  Aura phase  Aura is a transient focal neurological phenomenon that occurs before or during the headache. Aura appears gradually over a number of minutes (usually occurring over 5–60 minutes) and generally lasts less than 60 minutes. Symptoms can be visual, sensory or motoric in nature, and many people experience more than one. Visual effects occur most frequently: they occur in up to 99% of cases and in more than 50% of cases are not accompanied by sensory or motor effects. If any symptom remains after 60 minutes, the state is known as prolonged aura.Visual disturbances often consist of a scintillating scotoma (an area of partial alteration in the field of vision which flickers and may interfere with a person's ability to read or drive). These typically start near the center of vision and then spread out to the sides with zigzagging lines which have been described as looking like fortifications or walls of a castle. Usually the lines are in black and white but some people also see colored lines. Some people lose part of their field of vision known as hemianopsia while others experience blurring.Sensory aura are the second most common type; they occur in 30–40% of people with auras. Often a feeling of pins-and-needles begins on one side in the hand and arm and spreads to the nose–mouth area on the same side. Numbness usually occurs after the tingling has passed with a loss of position sense. Other symptoms of the aura phase can include speech or language disturbances, world spinning, and less commonly motor problems. Motor symptoms indicate that this is a hemiplegic migraine, and weakness often lasts longer than one hour unlike other auras. Auditory hallucinations or delusions have also been described.  Pain phase  Classically the headache is unilateral, throbbing, and moderate to severe in intensity. It usually comes on gradually and is aggravated by physical activity during a migraine attack. However, the effects of physical activity on migraine are complex, and some researchers have concluded that, while exercise can trigger migraine attacks, regular exercise may have a prophylactic effect and decrease frequency of attacks. The feeling of pulsating pain is not in phase with the pulse. In more than 40% of cases, however, the pain may be bilateral (both sides of the head), and neck pain is commonly associated with it. Bilateral pain is particularly common in those who have migraine without aura. Less commonly pain may occur primarily in the back or top of the head. The pain usually lasts 4 to 72 hours in adults; however, in young children frequently lasts less than 1 hour. The frequency of attacks is variable, from a few in a lifetime to several a week, with the average being about one a month.The pain is frequently accompanied by nausea, vomiting, sensitivity to light, sensitivity to sound, sensitivity to smells, fatigue and irritability. Many thus seek a dark and quiet room. In a basilar migraine, a migraine with neurological symptoms related to the brain stem or with neurological symptoms on both sides of the body, common effects include a sense of the world spinning, light-headedness, and confusion. Nausea occurs in almost 90% of people, and vomiting occurs in about one-third. Other symptoms may include blurred vision, nasal stuffiness, diarrhea, frequent urination, pallor, or sweating. Swelling or tenderness of the scalp may occur as can neck stiffness. Associated symptoms are less common in the elderly.  Silent migraine  Sometimes, aura occurs without a subsequent headache. This is known in modern classification as a typical aura without headache, or acephalgic migraine in previous classification, or commonly as a silent migraine. However, silent migraine can still produce debilitating symptoms, with visual disturbance, vision loss in half of both eyes, alterations in color perception, and other sensory problems, like sensitivity to light, sound, and odors, and aura sudden outbreak without headache can be scary. It can last from 15 to 30 minutes, usually no longer than 60 minutes, and it can recur or appear as an isolated event.  Postdrome  The migraine postdrome could be defined as that constellation of symptoms occurring once the acute headache has settled. Many report a sore feeling in the area where the migraine was, and some report impaired thinking for a few days after the headache has passed. The person may feel tired or ""hung over"" and have head pain, cognitive difficulties, gastrointestinal symptoms, mood changes, and weakness. According to one summary, ""Some people feel unusually refreshed or euphoric after an attack, whereas others note depression and malaise."" For some individuals this can vary each time.  Cause  The underlying causes of migraines are unknown. However, they are believed to be related to a mix of environmental and genetic factors. They run in families in about two-thirds of cases and rarely occur due to a single gene defect. While migraines were once believed to be more common in those of high intelligence, this does not appear to be true. A number of psychological conditions are associated, including depression, anxiety, and bipolar disorder, as are many biological events or triggers.  Genetics  Studies of twins indicate a 34% to 51% genetic influence of likelihood to develop migraine. This genetic relationship is stronger for migraine with aura than for migraines without aura. A number of specific variants of genes increase the risk by a small to moderate amount.Single gene disorders that result in migraines are rare. One of these is known as familial hemiplegic migraine, a type of migraine with aura, which is inherited in an autosomal dominant fashion. Four genes have been shown to be involved in familial hemiplegic migraine. Three of these genes are involved in ion transport. The fourth is an axonal protein associated with the exocytosis complex. Another genetic disorder associated with migraine is CADASIL syndrome or cerebral autosomal dominant arteriopathy with subcortical infarcts and leukoencephalopathy. One meta-analysis found a protective effect from angiotensin converting enzyme polymorphisms on migraine. The TRPM8 gene, which codes for a cation channel, has been linked to migraines.  Triggers  Migraine may be induced by triggers, with some reporting it as an influence in a minority of cases and others the majority. Many things such as fatigue, certain foods, alcohol, and weather have been labeled as triggers; however, the strength and significance of these relationships are uncertain. Most people with migraines report experiencing triggers. Symptoms may start up to 24 hours after a trigger.  Physiological aspects  Common triggers quoted are stress, hunger, and fatigue (these equally contribute to tension headaches). Psychological stress has been reported as a factor by 50 to 80% of people. Migraine has also been associated with post-traumatic stress disorder and abuse. Migraine episodes are more likely to occur around menstruation. Other hormonal influences, such as menarche, oral contraceptive use, pregnancy, perimenopause, and menopause, also play a role. These hormonal influences seem to play a greater role in migraine without aura. Migraine episodes typically do not occur during the second and third trimesters of pregnancy, or following menopause.  Dietary aspects  Between 12 and 60% of people report foods as triggers.There are many reports that tyramine – which is naturally present in chocolate, alcoholic beverages, most cheeses, processed meats, and other foods – can trigger migraine symptoms in some individuals. Likewise, monosodium glutamate (MSG) is frequently reported as a trigger for migraine symptoms.  Environmental aspects  A 2009 review on potential triggers in the indoor and outdoor environment concluded that while there were insufficient studies to confirm environmental factors as causing migraine, ""migraineurs worldwide consistently report similar environmental triggers"". The article suggests that people living with migraine take some preventive measures related to indoor air quality and lighting.  Pathophysiology  Migraine is believed to be primarily a neurological disorder, while others believe it to be a neurovascular disorder with blood vessels playing the key role, although current evidence does not support this completely. Others believe both are likely important. One theory is related to increased excitability of the cerebral cortex and abnormal control of pain neurons in the trigeminal nucleus of the brainstem.  Aura  Cortical spreading depression, or spreading depression according to Leão, is a burst of neuronal activity followed by a period of inactivity, which is seen in those with migraines with aura. There are a number of explanations for its occurrence, including activation of NMDA receptors leading to calcium entering the cell. After the burst of activity, the blood flow to the cerebral cortex in the area affected is decreased for two to six hours. It is believed that when depolarization travels down the underside of the brain, nerves that sense pain in the head and neck are triggered.  Pain  The exact mechanism of the head pain which occurs during a migraine episode is unknown. Some evidence supports a primary role for central nervous system structures (such as the brainstem and diencephalon), while other data support the role of peripheral activation (such as via the sensory nerves that surround blood vessels of the head and neck). The potential candidate vessels include dural arteries, pial arteries and extracranial arteries such as those of the scalp. The role of vasodilatation of the extracranial arteries, in particular, is believed to be significant.  Neuromodulators  Adenosine, a neuromodulator, may be involved. Released after the progressive cleavage of adenosine triphosphate (ATP), adenosine acts on adenosine receptors to put the body and brain in a low activity state by dilating blood vessels and slowing the heart rate, such as before and during the early stages of sleep. Adenosine levels have been found to be high during migraine attacks. Caffeine's role as an inhibitor of adenosine may explain its effect in reducing migraine. Low levels of the neurotransmitter serotonin, also known as 5-hydroxytryptamine (5-HT), are also believed to be involved.Calcitonin gene-related peptides (CGRPs) have been found to play a role in the pathogenesis of the pain associated with migraine, as levels of it become elevated during an attack.  Diagnosis  The diagnosis of a migraine is based on signs and symptoms. Neuroimaging tests are not necessary to diagnose migraine, but may be used to find other causes of headaches in those whose examination and history do not confirm a migraine diagnosis. It is believed that a substantial number of people with the condition remain undiagnosed.The diagnosis of migraine without aura, according to the International Headache Society, can be made according to the following criteria, the ""5, 4, 3, 2, 1 criteria"": Five or more attacks—for migraine with aura, two attacks are sufficient for diagnosis. Four hours to three days in duration Two or more of the following: Unilateral (affecting one side of the head) Pulsating Moderate or severe pain intensity Worsened by or causing avoidance of routine physical activity One or more of the following: Nausea and/or vomiting Sensitivity to both light (photophobia) and sound (phonophobia)If someone experiences two of the following: photophobia, nausea, or inability to work or study for a day, the diagnosis is more likely. In those with four out of five of the following: pulsating headache, duration of 4–72 hours, pain on one side of the head, nausea, or symptoms that interfere with the person's life, the probability that this is a migraine attack is 92%. In those with fewer than three of these symptoms, the probability is 17%.  Classification  Migraine was first comprehensively classified in 1988. The International Headache Society updated their classification of headaches in 2004. A third version was published in 2018. According to this classification, migraine is a primary headache disorder along with tension-type headaches and cluster headaches, among others.Migraine is divided into seven subclasses (some of which include further subdivisions): Migraine without aura, or ""common migraine"", involves migraine headaches that are not accompanied by aura. Migraine with aura, or ""classic migraine"", usually involves migraine headaches accompanied by aura. Less commonly, aura can occur without a headache, or with a nonmigraine headache. Two other varieties are familial hemiplegic migraine and sporadic hemiplegic migraine, in which a person has migraine with aura and with accompanying motor weakness. If a close relative has had the same condition, it is called ""familial"", otherwise it is called ""sporadic"". Another variety is basilar-type migraine, where a headache and aura are accompanied by difficulty speaking, world spinning, ringing in ears, or a number of other brainstem-related symptoms, but not motor weakness. This type was initially believed to be due to spasms of the basilar artery, the artery that supplies the brainstem. Now that this mechanism is not believed to be primary, the symptomatic term migraine with brainstem aura (MBA) is preferred. Childhood periodic syndromes that are commonly precursors of migraine include cyclical vomiting (occasional intense periods of vomiting), abdominal migraine (abdominal pain, usually accompanied by nausea), and benign paroxysmal vertigo of childhood (occasional attacks of vertigo). Retinal migraine involves migraine headaches accompanied by visual disturbances or even temporary blindness in one eye. Complications of migraine describe migraine headaches and/or auras that are unusually long or unusually frequent, or associated with a seizure or brain lesion. Probable migraine describes conditions that have some characteristics of migraines, but where there is not enough evidence to diagnose it as a migraine with certainty (in the presence of concurrent medication overuse). Chronic migraine is a complication of migraines, and is a headache that fulfills diagnostic criteria for migraine headache and occurs for a greater time interval. Specifically, greater or equal to 15 days/month for longer than 3 months.  Abdominal migraine  The diagnosis of abdominal migraine is controversial. Some evidence indicates that recurrent episodes of abdominal pain in the absence of a headache may be a type of migraine or are at least a precursor to migraines. These episodes of pain may or may not follow a migraine-like prodrome and typically last minutes to hours. They often occur in those with either a personal or family history of typical migraine. Other syndromes that are believed to be precursors include cyclical vomiting syndrome and benign paroxysmal vertigo of childhood.  Differential diagnosis  Other conditions that can cause similar symptoms to a migraine headache include temporal arteritis, cluster headaches, acute glaucoma, meningitis and subarachnoid hemorrhage. Temporal arteritis typically occurs in people over 50 years old and presents with tenderness over the temple, cluster headache presents with one-sided nose stuffiness, tears and severe pain around the orbits, acute glaucoma is associated with vision problems, meningitis with fevers, and subarachnoid hemorrhage with a very fast onset. Tension headaches typically occur on both sides, are not pounding, and are less disabling.Those with stable headaches that meet criteria for migraines should not receive neuroimaging to look for other intracranial disease. This requires that other concerning findings such as papilledema (swelling of the optic disc) are not present. People with migraines are not at an increased risk of having another cause for severe headaches.  Prevention  Preventive treatments of migraine include medications, nutritional supplements, lifestyle alterations, and surgery. Prevention is recommended in those who have headaches more than two days a week, cannot tolerate the medications used to treat acute attacks, or those with severe attacks that are not easily controlled. Recommended lifestyle changes include stopping tobacco use and reducing behaviors that interfere with sleep.The goal is to reduce the frequency, painfulness, and duration of migraine episodes, and to increase the effectiveness of abortive therapy. Another reason for prevention is to avoid medication overuse headache. This is a common problem and can result in chronic daily headache.  Medication  Preventive migraine medications are considered effective if they reduce the frequency or severity of the migraine attacks by at least 50%. Due to few medications being approved specifically for the preventative treatment of migraine headaches; many medications such as beta-blockers, anticonvulsive agents such as topiramate or sodium valproate, antidepressants such as amitriptyline and calcium channel blockers such as flunarizine are used off label for the preventative treatment of migraine headaches. Guidelines are fairly consistent in rating the anticonvulsants topiramate and divalproex/sodium valproate, and the beta blockers propranolol and metoprolol as having the highest level of evidence for first-line use for migraine prophylaxis in adults. Propranolol and topiramate have the best evidence in children; however, evidence only supports short-term benefit as of 2020.The beta blocker timolol is also effective for migraine prevention and in reducing migraine attack frequency and severity. While beta blockers are often used for first-line treatment, other antihypertensives also have a proven efficiency in migraine prevention, namely the calcium channel blocker verapamil and the angiotensin receptor blocker candesartan.Tentative evidence also supports the use of magnesium supplementation. Increasing dietary intake may be better. Recommendations regarding effectiveness varied for the anticonvulsants gabapentin and pregabalin. Frovatriptan is effective for prevention of menstrual migraine.The antidepressants amitriptyline and venlafaxine are probably also effective. Angiotensin inhibition by either an angiotensin-converting enzyme inhibitor or angiotensin II receptor antagonist may reduce attacks.Medications in the anti-calcitonin gene-related peptide, including eptinezumab, erenumab, fremanezumab, and galcanezumab, appear to decrease the frequency of migraines by one to two per month. They are, however, expensive: a year of erenumab costs $6,900 as of 2019.  Alternative therapies  Acupuncture has a small effect in reducing migraine frequency, compared to sham acupuncture, a practice where needles are placed randomly or do not penetrate the skin. Physiotherapy, massage and relaxation, and chiropractic manipulation might be as effective as propranolol or topiramate in the prevention of migraine headaches; however, the research had some problems with methodology. Another review, however, found evidence to support spinal manipulation to be poor and insufficient to support its use.Tentative evidence supports the use of stress reduction techniques such as cognitive behavioral therapy, biofeedback, and relaxation techniques. Regular physical exercise may decrease the frequency. Numerous psychological approaches have been developed that are aimed at preventing or reducing the frequency of migraine in adults including educational approaches, relaxation techniques, assistance in developing coping strategies, strategies to change the way one thinks of a migraine attack, and strategies to reduce symptoms. Other strategies include: progressive muscle relaxation, biofeedback, behavioral training, acceptance and commitment therapy, and mindfulness-based interventions. The medical evidence supporting the effectiveness of these types of psychological approaches is very limited.Among alternative medicines, butterbur has the best evidence for its use. However, unprocessed butterbur contains chemicals called pyrrolizidine alkaloids (PAs) which can cause liver damage, however there are versions that are PA free. In addition, butterbur may cause allergic reactions in people who are sensitive to plants such as ragweed. There is tentative evidence that coenzyme Q10 reduces migraine frequency.Feverfew has traditionally been used as a treatment for fever, headache and migraine, women's conditions such as difficulties in labour and regulation of menstruation, relief of stomach ache, toothache and insect bites. During the last decades, it has mainly been used for headache and as a preventive treatment for migraine. The plant parts used for medicinal use are the dried leaves or the dried aerial parts. Several historical data supports feverfew's traditional medicinal uses. In addition, several clinical studies have been performed assessing the efficacy and safety of feverfew monotherapy in the prevention of migraine. The majority of the clinical trials favoured feverfew over placebo. The data also suggest that feverfew is associated with only mild and transient adverse effects. The frequency of migraine was positively affected after treatment with feverfew. Reduction of migraine severity was also reported after intake of feverfew and incidence of nausea and vomiting decreased significantly. No effect of feverfew was reported in one study.There is tentative evidence for melatonin as an add-on therapy for prevention and treatment of migraine. The data on melatonin are mixed and certain studies have had negative results. The reasons for the mixed findings are unclear but may stem from differences in study design and dosage. Melatonin's possible mechanisms of action in migraine are not completely clear, but may include improved sleep, direct action on melatonin receptors in the brain, and anti-inflammatory properties.  Devices and surgery  Medical devices, such as biofeedback and neurostimulators, have some advantages in migraine prevention, mainly when common anti-migraine medications are contraindicated or in case of medication overuse. Biofeedback helps people be conscious of some physiological parameters so as to control them and try to relax and may be efficient for migraine treatment. Neurostimulation uses noninvasive or implantable neurostimulators similar to pacemakers for the treatment of intractable chronic migraine with encouraging results for severe cases. A transcutaneous electrical nerve stimulator and a transcranial magnetic stimulator are approved in the United States for the prevention of migraines. There is also tentative evidence for transcutaneous electrical nerve stimulation decreases the frequency of migraines. Migraine surgery, which involves decompression of certain nerves around the head and neck, may be an option in certain people who do not improve with medications.  Management  There are three main aspects of treatment: trigger avoidance, acute symptomatic control, and medication for prevention. Medications are more effective if used earlier in an attack. The frequent use of medications may result in medication overuse headache, in which the headaches become more severe and more frequent. This may occur with triptans, ergotamines, and analgesics, especially opioid analgesics. Due to these concerns simple analgesics are recommended to be used less than three days per week at most.  Analgesics  Recommended initial treatment for those with mild to moderate symptoms are simple analgesics such as nonsteroidal anti-inflammatory drugs (NSAIDs) or the combination of paracetamol (also known as acetaminophen), aspirin, and caffeine. Several NSAIDs, including diclofenac and ibuprofen have evidence to support their use. Aspirin (900 to 1000 mg) can relieve moderate to severe migraine pain, with an effectiveness similar to sumatriptan. Ketorolac is available in intravenous and intramuscular formulations.Paracetamol, either alone or in combination with metoclopramide, is another effective treatment with a low risk of adverse effects. Intravenous metoclopramide is also effective by itself. In pregnancy, paracetamol and metoclopramide are deemed safe as are NSAIDs until the third trimester.Naproxen by itself may not be effective as a stand-alone medicine to stop a migraine headache as it is only weakly better than a placebo medication in clinical trials.  Antiemetics   Triptans  Triptans such as sumatriptan are medications used to stop an active migraine headache (an abortive medication). Triptans are the initially recommended treatments for those with moderate to severe pain from an acute migraine headache or those with milder symptoms who do not respond to simple analgesics. Triptans have been shown to be effective for both pain and nausea in up to 75% of people. There are different methods or routes of administration to take sumatriptan including oral (by mouth), injectable (subcutaneous), rectal, nasal spray, and oral dissolving tablets. For people with migraine symptoms such as nausea or vomiting, taking the abortive medicine by mouth or through the nose may be difficult. All route of administration have been shown to be effective at reducing migraine symptoms, however, nasal and injectable subcutaneous administration may result in more side effects. The adverse effects associated with rectal administration have not been well studied. Some people may find that they respond to one type of sumatriptan better than another.Most side effects are mild, including flushing; however, rare cases of myocardial ischemia have occurred. They are thus not recommended for people with cardiovascular disease, who have had a stroke, or have migraines that are accompanied by neurological problems. In addition, triptans should be prescribed with caution for those with risk factors for vascular disease. While historically not recommended in those with basilar migraines there is no specific evidence of harm from their use in this population to support this caution. Triptans are not addictive, but may cause medication-overuse headaches if used more than 10 days per month.Sumatriptan does not prevent other migraine headaches from starting in the future. For increased effectiveness at stopping migraine symptoms, a combined therapy that includes sumatriptan and naproxen may be suggested.  CGRP receptor antagonists  Calcitonin gene-related peptide receptor antagonists (CGRP) target calcitonin gene-related peptide or its receptor to prevent migraine headaches or reduce their severity. CGRP is a signaling molecule as well as a potent vasodilator that is involved in the development of a migraine headache. There are four injectable monoclonal antibodies that target CGRP or its receptor (eptinezumab, erenumab, fremanezumab, and galcanezumab) and the medications have demonstrated efficacy in the preventative treatment of episodic and chronic migraine headaches in phase III randomized clinical trials.Zavegepant was approved for medical use in the United States in March 2023.  Ergotamines  Ergotamine and dihydroergotamine are older medications still prescribed for migraines, the latter in nasal spray and injectable forms. They appear equally effective to the triptans and experience adverse effects that typically are benign. In the most severe cases, such as those with status migrainosus, they appear to be the most effective treatment option. They can cause vasospasm including coronary vasospasm and are contraindicated in people with coronary artery disease.  Magnesium  Magnesium is recognized as an inexpensive, over-the-counter supplement which can be part of a multimodal approach to migraine reduction. Some studies have shown to be effective in both preventing and treating migraine in intravenous form. The intravenous form reduces attacks as measured in approximately 15-45 minutes, 120 minutes, and 24 hour time periods, magnesium taken orally alleviates the frequency and intensity of migraines.  Other  Intravenous metoclopramide, intravenous prochlorperazine, or intranasal lidocaine are other potential options. Metoclopramide or prochlorperazine are the recommended treatment for those who present to the emergency department. Haloperidol may also be useful in this group. A single dose of intravenous dexamethasone, when added to standard treatment of a migraine attack, is associated with a 26% decrease in headache recurrence in the following 72 hours. Spinal manipulation for treating an ongoing migraine headache is not supported by evidence. It is recommended that opioids and barbiturates not be used due to questionable efficacy, addictive potential, and the risk of rebound headache. There is tentative evidence that propofol may be useful if other measures are not effective.Occipital nerve stimulation, may be effective but has the downsides of being cost-expensive and has a significant amount of complications.There is modest evidence for the effectiveness of non-invasive neuromodulatory devices, behavioral therapies and acupuncture in the treatment of migraine headaches. There is little to no evidence for the effectiveness of physical therapy, chiropractic manipulation and dietary approaches to the treatment of migraine headaches. Behavioral treatment of migraine headaches may be helpful for those who may not be able to take medications (for example pregnant women).Feverfew is registered as a traditional herbal medicine in the Nordic countries under the brand name Glitinum, only powdered feverfew is approved in the Herbal community monograph issued by European Medicines Agency (EMA). Sexual activity, particularly orgasm, may provide relief for some migraineurs.  Children  Ibuprofen helps decrease pain in children with migraines and is the initially recommended treatment. Paracetamol does not appear to be effective in providing pain relief. Triptans are effective, though there is a risk of causing minor side effects like taste disturbance, nasal symptoms, dizziness, fatigue, low energy, nausea, or vomiting. Ibuprofen should be used less than half the days in a month and triptans less than a third of the days in a month to decrease the risk of medication overuse headache.  Chronic migraine  Topiramate and botulinum toxin (Botox) have evidence in treating chronic migraine. Botulinum toxin has been found to be useful in those with chronic migraine but not those with episodic ones. The anti-CGRP monoclonal antibody erenumab was found in one study to decrease chronic migraines by 2.4 days more than placebo.  Prognosis  ""Migraine exists on a continuum of different attack frequencies and associated levels of disability."" For those with occasional, episodic migraine, a ""proper combination of drugs for prevention and treatment of migraine attacks"" can limit the disease's impact on patients' personal and professional lives. But fewer than half of people with migraine seek medical care and more than half go undiagnosed and undertreated. ""Responsive prevention and treatment of migraine is incredibly important"" because evidence shows ""an increased sensitivity after each successive attack, eventually leading to chronic daily migraine in some individuals."" Repeated migraine results in ""reorganization of brain circuitry,"" causing ""profound functional as well as structural changes in the brain."" ""One of the most important problems in clinical migraine is the progression from an intermittent, self-limited inconvenience to a life-changing disorder of chronic pain, sensory amplification, and autonomic and affective disruption. This progression, sometimes termed chronification in the migraine literature, is common, affecting 3% of migraineurs in a given year, such that 8% of migraineurs have chronic migraine in any given year."" Brain imagery reveals that the electrophysiological changes seen during an attack become permanent in people with chronic migraine; ""thus, from an electrophysiological point of view, chronic migraine indeed resembles a never-ending migraine attack."" Severe migraine ranks in the highest category of disability, according to the World Health Organization, which uses objective metrics to determine disability burden for the authoritative annual Global Burden of Disease report. The report classifies severe migraine alongside severe depression, active psychosis, quadriplegia, and terminal-stage cancer.Migraine with aura appears to be a risk factor for ischemic stroke doubling the risk. Being a young adult, being female, using hormonal birth control, and smoking further increases this risk. There also appears to be an association with cervical artery dissection. Migraine without aura does not appear to be a factor. The relationship with heart problems is inconclusive with a single study supporting an association. Migraine does not appear to increase the risk of death from stroke or heart disease. Preventative therapy of migraines in those with migraine with aura may prevent associated strokes. People with migraine, particularly women, may develop higher than average numbers of white matter brain lesions of unclear significance.  Epidemiology  Worldwide, migraine affects nearly 15% or approximately one billion people. It is more common in women at 19% than men at 11%. In the United States, about 6% of men and 18% of women experience a migraine attack in a given year, with a lifetime risk of about 18% and 43% respectively. In Europe, migraines affect 12–28% of people at some point in their lives with about 6–15% of adult men and 14–35% of adult women getting at least one yearly. Rates of migraine are slightly lower in Asia and Africa than in Western countries. Chronic migraine occurs in approximately 1.4 to 2.2% of the population.These figures vary substantially with age: onset of migraine is most commonly between 15 and 24 years of age, and occur most frequently in those 35 to 45 years of age. In children, about 1.7% of 7 year olds and 3.9% of those between 7 and 15 experience migraine, with the condition being slightly more common in boys before puberty. Children as young as two years may be affected. During adolescence, migraine becomes more common among women and this persists for the rest of the lifespan, being twice as common among elderly females than males. In women migraine without aura are more common than migraine with aura; however in men the two types occur with similar frequency.During perimenopause symptoms often get worse before decreasing in severity. While symptoms resolve in about two thirds of the elderly, in 3 to 10% they persist.  History  An early description consistent with migraine is contained in the Ebers papyrus, written around 1500 BCE in ancient Egypt. In 200 BCE, writings from the Hippocratic school of medicine described the visual aura that can precede the headache and a partial relief occurring through vomiting.A second-century description by Aretaeus of Cappadocia divided headaches into three types: cephalalgia, cephalea, and heterocrania. Galen of Pergamon used the term hemicrania (half-head), from which the word migraine was eventually derived. He also proposed that the pain arose from the meninges and blood vessels of the head. Migraine was first divided into the two now used types – migraine with aura (migraine ophthalmique) and migraine without aura (migraine vulgaire) in 1887 by Louis Hyacinthe Thomas, a French Librarian. The mystical visions of Hildegard von Bingen, which she described as “reflections of the living light"", are consistent with the visual aura experienced during migraines. Trepanation, the deliberate drilling of holes into a skull, was practiced as early as 7,000 BCE. While sometimes people survived, many would have died from the procedure due to infection. It was believed to work via ""letting evil spirits escape"". William Harvey recommended trepanation as a treatment for migraines in the 17th century. The association between trepanation and headaches in ancient history may simply be a myth or unfounded speculation that originated several centuries later. In 1913, the world-famous American physician William Osler misinterpreted the French anthropologist and physician Paul Broca ’s words about a set of children's skulls from the Neolithic age that he found during the 1870s. These skulls presented no evident signs of fractures that could justify this complex surgery for mere medical reasons. Trepanation was probably born of superstitions, to remove “confined demons” inside the head, or to create healing or fortune talismans with the bone fragments removed from the skulls of the patients. However, Osler wanted to make Broca’s theory more palatable to his modern audiences, and explained that trepanation procedures were used for mild conditions such as “infantile convulsions headache and various cerebral diseases believed to be caused by confined demons.”While many treatments for migraine have been attempted, it was not until 1868 that use of a substance which eventually turned out to be effective began. This substance was the fungus ergot from which ergotamine was isolated in 1918. Methysergide was developed in 1959 and the first triptan, sumatriptan, was developed in 1988. During the 20th century with better study-design, effective preventive measures were found and confirmed.  Society and culture  Migraine is a significant source of both medical costs and lost productivity. It has been estimated that migraine is the most costly neurological disorder in the European Community, costing more than €27 billion per year. In the United States, direct costs have been estimated at $17 billion, while indirect costs — such as missed or decreased ability to work — is estimated at $15 billion. Nearly a tenth of the direct cost is due to the cost of triptans. In those who do attend work during a migraine attack, effectiveness is decreased by around a third. Negative impacts also frequently occur for a person's family.  Research   Potential prevention mechanisms  Transcranial magnetic stimulation shows promise as does transcutaneous supraorbital nerve stimulation. There is preliminary evidence that a ketogenic diet may help prevent episodic and long-term migraine.  Potential gender dependency  While no definitive proof has been found linking migraine to gender, statistical data indicates that women may be more prone to having migraine, showing migraine incidence three times higher among women than men. The Society for Women's Health Research has also mentioned hormonal influences, mainly estrogen, as having a considerable role in provoking migraine pain. Studies and research related to the gender dependencies of migraine are still ongoing, and conclusions have yet to be achieved.  References   Notes  Olesen J (2006). The headaches (3 ed.). Philadelphia: Lippincott Williams & Wilkins. ISBN 9780781754002.  Further reading  Ashina M (November 2020). Ropper AH (ed.). ""Migraine"". The New England Journal of Medicine. 383 (19): 1866–1876. doi:10.1056/nejmra1915327. PMID 33211930. S2CID 227078662. Oskoui M, Pringsheim T, Billinghurst L, Potrebic S, Gersz EM, Gloss D, et al. (September 2019). ""Practice guideline update summary: Pharmacologic treatment for pediatric migraine prevention: Report of the Guideline Development, Dissemination, and Implementation Subcommittee of the American Academy of Neurology and the American Headache Society"". Neurology. 93 (11): 500–509. doi:10.1212/WNL.0000000000008105. PMC 6746206. PMID 31413170. Oskoui M, Pringsheim T, Holler-Managan Y, Potrebic S, Billinghurst L, Gloss D, et al. (September 2019). ""Practice guideline update summary: Acute treatment of migraine in children and adolescents: Report of the Guideline Development, Dissemination, and Implementation Subcommittee of the American Academy of Neurology and the American Headache Society"". Neurology. 93 (11): 487–499. doi:10.1212/WNL.0000000000008095. PMID 31413171. S2CID 199662718.  External links  Migraine at Curlie","A migraine is a medical condition which usually causes a pounding, throbbing headache on one side of the head. The pain may be very bad and hurt so much that a person may have a hard time doing anything. While most people who have migraines get a headache, not everyone does. There are different kinds of migraines, and some do not cause a headache but do have other symptoms. Most migraines cause a headache and nausea and might make the person dizzy or very sensitive to bright lights or loud noises. Some people have ""auras"" before a migraine starts, which means their ability to see becomes different. They may see funny patterns, have blurry vision, or may not be able to see at all. Other senses can change before or during a migraine, and the person may sense funny smells or tastes. Migraines can last a long time. Migraines usually last between four and 72 hours. Migraines have been classified, based on how often they happen in a month: If a person has a headache for less than fifteen days, the migraine is called episodic migraine (EM). If it happens more than fifteen days, it is called chronic migraine (CM). Chronic means it happens over a long amount of time. Some people who start off getting episodic migraines may start to get chronic migraines later. Chronic migraine then may revert or go back to episodic migraine. Scientists have discovered that something called CGRP is the cause of migraines. CGRP stands for ""calcitonin gene-related peptide"". CGRP is a protein that causes migraines when it is released around the brain. What CGRP does, is that it causes a lot of inflammation in the meninges, a covering above the brain. There are different risk factors which make a person more likely to have migraines. Being a female is a risk factor, and so is having family members who had migraines. For a person who has migraines, there are different trigger factors which may set off a migraine attack. In a large group of females who have migraines, one of the main trigger factors is when the amount of the hormone estrogen in their body either drops too low or fluctuates (goes up and down). The World Health Organization says that migraine headache is the most costly brain problem for treatment and disability in the European Union and the United States.  Types   Migraine with aura  Acephalgic migraine, also called a silent migraine, is a kind of migraine with aura but without the head pain. This type of migraine usually starts sometime during middle-age, which is after a person is 40 years old, and becomes more common as a person gets older. Unlike other migraines, males have acephalgic migraines more often then females do. Basilar-type migraine is a type of migraine with aura that causes headache usually in the occipital region of the brain with neurological symptoms that is believed to come from the brainstem, occipital cortex, and cerebellum and/or affects both hemispheres of the brain at the same time. Most people who have basilar-type migraine also experience migraines with aura without the basilar symptoms. This type of migraine usually more common in people under age 20 and young females. Familial hemiplegic migraine (FHM) is a type of migraine with aura that also may cause paralysis on one side of the body. When the migraine stops, the person can move normally again. Retinal migraine has repeated times of vision loss in one eye, that may happen before or during a headache. People who have retinal migraines usually have a history of having one of the other more common types of migraine.  Migraine without aura  Menstrual migraine or catamenial migraine is a type of migraine that happens perimenstrually, which means around the time of menstruation during a woman's monthly menstrual cycle. Menstrual migraine is usually a migraine without aura, but sometimes a menstrual migraine with aura happens. About 7%-14% of women have migraines exclusively at the time of menstruation. These are considered true menstrual migraines. Most female migraneurs experience migraine attacks at all times during the menstrual cycle, with an increased number perimenstrually. These are referred to as menstrually related or menstrually triggered migraine. Both true menstrual migraines and menstrually related migraines are categorized under menstrual migraine.The role of estrogenEstrogen is a hormone that is mostly made in a woman's ovaries. There are three types of estrogen: estrone, estradiol and estriol. In women who have migraines it is usually connected with their menstruation cycle. About 60% of women have these menstrual or menstrually-related migraines and the main trigger is believed to be reduced circulating estrogen levels, i.e. the amount of estrogen in the body, specifically estradiol. In some cases, fluctuation (going up and down) in the amount of circulating estrogen levels may trigger a migraine, i.e. not only too little but sometimes too much estrogen may trigger a migraine.  Childhood periodic syndromes  Childhood periodic syndromes are a group of migraine syndromes that children may have. When a child has one of these child periodic syndromes there is a greater chance that they will get one of the other, more common types of migraines when they become adults. Abdominal migraine is a kind of migraine which causes a very bad pain in the area of the abdomen, usually around the 'belly-button' which is called the periumbilical area. Abdominal migraine usually affects children starting at about age 7, but it may affect younger children and older children, and it may also sometimes affect adults.Benign paroxysmal vertigo of childhood (BPVC for short): (this means harmless dizziness, that happens again and again and happens suddenly) is a medical condition which occurs in children usually starting between two and five years of age; it often disappears by the age of eight. BPVC causes vertigo. Cyclic vomiting syndrome or cyclical vomiting syndrome (CVS), is a medical condition whose main symptoms are nausea and repeated vomiting. CVS happens more often in children, but it can occur at any age.  Chronic vs. episodic migraine  Episodic migraine (EM) is when a person has migraine symptoms for 14 days or less in one month, while chronic migraine (CM) is when a person has migraine symptoms for 15 or more days in one month. When compared to persons with episodic migraine, those with CM where less likely to have full-time jobs and had a larger risk of headache-related disability. Persons with CM are almost twice as likely to have anxiety, chronic pain, and/or depression; they also have a 40% greater chance of having heart disease and angina and are 70% more likely to have a history of stroke. About 7.68% of total migraine cases are chronic migraines and about 1% of people in the United States have CM, with a higher rate among females, middle-aged people, and in those households that had the lowest annual income. (The American Migraine Prevalence and Prevention Study)  Aura  Aura (from the Greek word for breeze) is the word used to describe a series of neurological symptoms that may begin before an epileptic seizure or a migraine headache. About 15% of people who have a migraine will have the kind with an aura. The symptoms may include visual problems such as scotomas (losing vision for a short time, seeing zig-zag lines or floating spots etc.), vertigo, a ringing noise in the ears (tinnitus) and problems speaking. Scotoma (came from the Greek word for darkness: skotos): a blind spot or area of reduced vision surrounded by a normal visual field. i.e.: A person can see normally except where the scotoma is. Scotomas may affect one or both eyes and be either and be either absolute where nothing can be seen within the scotoma or, relative with some ability to see within the area of the scotoma. Scotomas may also have different patterns and shapes like the fortification scotoma; it is called fortification because it looks like the outline of an old fort. Scotomas can start of small and then get bigger, move around to different parts of a person's visual field, and they can also look like flickering lights.  Risk factors and triggers  In medicine a factor is a substance, a condition or an activity, or a lack thereof that increases the chance of a certain outcome or condition happening. If it increases the chance of something unhealthy it is a risk factor. A trigger factor or 'trigger' for short is a factor that may cause an activity or the signs and/or symptoms of a medical condition to begin. Risk factorsGender: Women are three times more likely to have migraine headaches than men. Family history: A person has more of a chance of getting migraines if one of their parents has had them. The International Headache Consortium are doctors from a lot of different countries who study headaches and what causes them. They have found four genetic variations - these are differences in a persons genes - that are risk factors for migraine without aura in people who have these differences. Two of these genetic variations had already been shown to play a role in migraine with aura. Hormonal changes Obesity: has shown to be a risk factor for chronic migraine not episodic migraine.TriggersDietary habits: fasting, dehydration, or skipping meals. Diet: Eating certain foods such as those that contain tyramine which is found in certain foods and is the end result of the natural breakdown of the amino acid tyrosine. Various food contain tyramine such as aged cheeses, smoked fish, some kinds of beer. Tyramine as a trigger for migraine is thought to effect less than 10% of people with migraines.  Diagnosis  There are no specific tests to diagnose migraine but a doctor may use different tests to rule out other causes for a person's symptoms. The diagnosis of migraine is a clinical diagnosis which means it is based upon a person's medical history that a person reports to the doctor. The medical history for a possible migraine diagnosis which can be called the headache history includes information such as: Does anyone else in the person's family have medical problems. If so what kind? What are all the symptoms you have? At what age did the symptoms first start? How often do the headaches and/or other symptoms occur? How long do the symptoms last? Where is the pain? Unilateral: either left or right side of the head - bilateral: both left and right sides  Differential diagnoses  Differential diagnoses are different medical disorders which may cause the same symptoms. Before a doctor makes a final diagnosis, which means they are sure of what medical disorder is causing the problem, they think of what other medical conditions have the same or almost the same symptoms, and make sure it's not one of them. Brain tumor Cluster headache Sinusitis Stroke Subarachnoid hemorrhage Tension headache Vascular pathologies: medical conditions that effect the vascular system such as arteriovenous malformation  Disorders that often occur with migraine  Often, having one medical condition makes it more likely a person will also have one or more other medical or psychiatric disorders. These other disorders are the ""comorbid disorders"" or ""comorbidities"". There are various comorbid medical and psychiatric conditions associated with migraines. The treatment and prognosis (if a disease gets better, worse or stays the same over time) of migraine is affected by the comorbid disorders which may be present and/or the chance of getting comorbid disorders. Asthma Raynaud’s disease: is a circulatory disorder in which the smaller arteries that supply blood to the extremities - most often the hands, but it may also affect the, toes, the tip of the nose and the ears - become narrower reducing blood flow. This causes the extremities to become numb and to be cooler than the core body temperature. It can be triggered by exposure to stress and cold. Epilepsy FibromyalgiaComorbid psychiatric conditions Major depressive disorder Anxiety Bipolar disorder  Complications of migraine  In medicine, a complication is a problem that happens because of, a procedure (like surgery), treatment (like medication), or illness (like migraines). Chronic migraine Status migrainosus is the term used to describe a severe migraine attack which lasts more than 72 hours straight. Persistent aura without stroke Migraine stroke Migraine-triggered seizures  Epidemiology  In medicine epidemiology is the study of what causes diseases and medical conditions, how often they happen, where they happen and who they happen to.Migraine is more common among boys than girls until the beginning of puberty when girls start getting migraines more often than boys. By the later part of the teenage years girls get migraines almost twice as much as boys do. The number of people who get migraines is highest between the ages of 25 to 55 years in both men and women, after which, the risk of getting migraines get lower as a person gets older. Between 65-75% of adult migraine sufferers are women and of these women, about two-thirds have menstrual migraines. Migraines are more common in people who make less money, there may be different reasons why such as stress. About two-thirds of migraines are migraines without aura and the remaining one-third of cases are migraine with aura.  History  Symptoms that mimic those of migraines have been recorded in various cultures throughout written history. The first known mention was found on cuneiform tablets from Babylonia dating to 2000-1880 B.C.E. A treatment for migraine can be found in the Ebers Papyrus, an Ancient Egyptian medical text named after George Ebers, the German Eygptologist who discovered them. In the ancient text dated to 1552 B.C.E. migraine is refereed to as ""suffering in half the head"". The Ancient Greek physician Aretaeus of Cappadocia's description of a type of headache he dubbed heterocrania is considered a description of migraine.  References "
"Tuberculosis (TB) is an infectious disease usually caused by Mycobacterium tuberculosis (MTB) bacteria. Tuberculosis generally affects the lungs, but it can also affect other parts of the body. Most infections show no symptoms, in which case it is known as latent tuberculosis. Around 10% of latent infections progress to active disease which, if left untreated, kill about half of those affected. Typical symptoms of active TB are chronic cough with blood-containing mucus, fever, night sweats, and weight loss. It was historically referred to as consumption due to the weight loss associated with the disease. Infection of other organs can cause a wide range of symptoms.Tuberculosis is spread from one person to the next through the air when people who have active TB in their lungs cough, spit, speak, or sneeze. People with Latent TB do not spread the disease. Active infection occurs more often in people with HIV/AIDS and in those who smoke. Diagnosis of active TB is based on chest X-rays, as well as microscopic examination and culture of body fluids. Diagnosis of Latent TB relies on the tuberculin skin test (TST) or blood tests.Prevention of TB involves screening those at high risk, early detection and treatment of cases, and vaccination with the bacillus Calmette-Guérin (BCG) vaccine. Those at high risk include household, workplace, and social contacts of people with active TB. Treatment requires the use of multiple antibiotics over a long period of time. Antibiotic resistance is a growing problem, with increasing rates of multiple drug-resistant tuberculosis (MDR-TB).In 2018, one quarter of the world's population was thought to have a latent infection of TB. New infections occur in about 1% of the population each year. In 2020, an estimated 10 million people developed active TB, resulting in 1.5 million deaths, making it the second leading cause of death from an infectious disease after COVID-19. As of 2018, most TB cases occurred in the regions of South-East Asia (44%), Africa (24%), and the Western Pacific (18%), with more than 50% of cases being diagnosed in seven countries: India (27%), China (9%), Indonesia (8%), the Philippines (6%), Pakistan (6%), Nigeria (4%), and Bangladesh (4%). By 2021, the number of new cases each year was decreasing by around 2% annually. About 80% of people in many Asian and African countries test positive, while 5–10% of people in the United States test positive via the tuberculin test. Tuberculosis has been present in humans since ancient times.  Signs and symptoms  Tuberculosis may infect any part of the body, but most commonly occurs in the lungs (known as pulmonary tuberculosis). Extrapulmonary TB occurs when tuberculosis develops outside of the lungs, although extrapulmonary TB may coexist with pulmonary TB.General signs and symptoms include fever, chills, night sweats, loss of appetite, weight loss, and fatigue. Significant nail clubbing may also occur.  Pulmonary  If a tuberculosis infection does become active, it most commonly involves the lungs (in about 90% of cases). Symptoms may include chest pain and a prolonged cough producing sputum. About 25% of people may not have any symptoms (i.e., they remain asymptomatic). Occasionally, people may cough up blood in small amounts, and in very rare cases, the infection may erode into the pulmonary artery or a Rasmussen's aneurysm, resulting in massive bleeding. Tuberculosis may become a chronic illness and cause extensive scarring in the upper lobes of the lungs. The upper lung lobes are more frequently affected by tuberculosis than the lower ones. The reason for this difference is not clear. It may be due to either better air flow, or poor lymph drainage within the upper lungs.  Extrapulmonary  In 15–20% of active cases, the infection spreads outside the lungs, causing other kinds of TB. These are collectively denoted as extrapulmonary tuberculosis. Extrapulmonary TB occurs more commonly in people with a weakened immune system and young children. In those with HIV, this occurs in more than 50% of cases. Notable extrapulmonary infection sites include the pleura (in tuberculous pleurisy), the central nervous system (in tuberculous meningitis), the lymphatic system (in scrofula of the neck), the genitourinary system (in urogenital tuberculosis), and the bones and joints (in Pott disease of the spine), among others. A potentially more serious, widespread form of TB is called ""disseminated tuberculosis"", it is also known as miliary tuberculosis. Miliary TB currently makes up about 10% of extrapulmonary cases.  Causes   Mycobacteria  The main cause of TB is Mycobacterium tuberculosis (MTB), a small, aerobic, nonmotile bacillus. The high lipid content of this pathogen accounts for many of its unique clinical characteristics. It divides every 16 to 20 hours, which is an extremely slow rate compared with other bacteria, which usually divide in less than an hour. Mycobacteria have an outer membrane lipid bilayer. If a Gram stain is performed, MTB either stains very weakly ""Gram-positive"" or does not retain dye as a result of the high lipid and mycolic acid content of its cell wall. MTB can withstand weak disinfectants and survive in a dry state for weeks. In nature, the bacterium can grow only within the cells of a host organism, but M. tuberculosis can be cultured in the laboratory.Using histological stains on expectorated samples from phlegm (also called sputum), scientists can identify MTB under a microscope. Since MTB retains certain stains even after being treated with acidic solution, it is classified as an acid-fast bacillus. The most common acid-fast staining techniques are the Ziehl–Neelsen stain and the Kinyoun stain, which dye acid-fast bacilli a bright red that stands out against a blue background. Auramine-rhodamine staining and fluorescence microscopy are also used. The M. tuberculosis complex (MTBC) includes four other TB-causing mycobacteria: M. bovis, M. africanum, M. canetti, and M. microti. M. africanum is not widespread, but it is a significant cause of tuberculosis in parts of Africa. M. bovis was once a common cause of tuberculosis, but the introduction of pasteurized milk has almost eliminated this as a public health problem in developed countries. M. canetti is rare and seems to be limited to the Horn of Africa, although a few cases have been seen in African emigrants. M. microti is also rare and is seen almost only in immunodeficient people, although its prevalence may be significantly underestimated. Other known pathogenic mycobacteria include M. leprae, M. avium, and M. kansasii. The latter two species are classified as ""nontuberculous mycobacteria"" (NTM) or atypical mycobacteria. NTM cause neither TB nor leprosy, but they do cause lung diseases that resemble TB.  Transmission  When people with active pulmonary TB cough, sneeze, speak, sing, or spit, they expel infectious aerosol droplets 0.5 to 5.0 µm in diameter. A single sneeze can release up to 40,000 droplets. Each one of these droplets may transmit the disease, since the infectious dose of tuberculosis is very small (the inhalation of fewer than 10 bacteria may cause an infection).  Risk of transmission  People with prolonged, frequent, or close contact with people with TB are at particularly high risk of becoming infected, with an estimated 22% infection rate. A person with active but untreated tuberculosis may infect 10–15 (or more) other people per year. Transmission should occur from only people with active TB – those with latent infection are not thought to be contagious. The probability of transmission from one person to another depends upon several factors, including the number of infectious droplets expelled by the carrier, the effectiveness of ventilation, the duration of exposure, the virulence of the M. tuberculosis strain, the level of immunity in the uninfected person, and others. The cascade of person-to-person spread can be circumvented by segregating those with active (""overt"") TB and putting them on anti-TB drug regimens. After about two weeks of effective treatment, subjects with nonresistant active infections generally do not remain contagious to others. If someone does become infected, it typically takes three to four weeks before the newly infected person becomes infectious enough to transmit the disease to others.  Risk factors  A number of factors make individuals more susceptible to TB infection and/or disease.  Active disease risk  The most important risk factor globally for developing active TB is concurrent HIV infection; 13% of those with TB are also infected with HIV. This is a particular problem in sub-Saharan Africa, where HIV infection rates are high. Of those without HIV infection who are infected with tuberculosis, about 5–10% develop active disease during their lifetimes; in contrast, 30% of those co-infected with HIV develop the active disease.Use of certain medications, such as corticosteroids and infliximab (an anti-αTNF monoclonal antibody), is another important risk factor, especially in the developed world.Other risk factors include: alcoholism, diabetes mellitus (3-fold increased risk), silicosis (30-fold increased risk), tobacco smoking (2-fold increased risk), indoor air pollution, malnutrition, young age, recently acquired TB infection, recreational drug use, severe kidney disease, low body weight, organ transplant, head and neck cancer, and genetic susceptibility (the overall importance of genetic risk factors remains undefined).  Infection susceptibility  Tobacco smoking increases the risk of infections (in addition to increasing the risk of active disease and death). Additional factors increasing infection susceptibility include young age.  Pathogenesis  About 90% of those infected with M. tuberculosis have asymptomatic, latent TB infections (sometimes called LTBI), with only a 10% lifetime chance that the latent infection will progress to overt, active tuberculous disease. In those with HIV, the risk of developing active TB increases to nearly 10% a year. If effective treatment is not given, the death rate for active TB cases is up to 66%. TB infection begins when the mycobacteria reach the alveolar air sacs of the lungs, where they invade and replicate within endosomes of alveolar macrophages. Macrophages identify the bacterium as foreign and attempt to eliminate it by phagocytosis. During this process, the bacterium is enveloped by the macrophage and stored temporarily in a membrane-bound vesicle called a phagosome. The phagosome then combines with a lysosome to create a phagolysosome. In the phagolysosome, the cell attempts to use reactive oxygen species and acid to kill the bacterium. However, M. tuberculosis has a thick, waxy mycolic acid capsule that protects it from these toxic substances. M. tuberculosis is able to reproduce inside the macrophage and will eventually kill the immune cell. The primary site of infection in the lungs, known as the Ghon focus, is generally located in either the upper part of the lower lobe, or the lower part of the upper lobe. Tuberculosis of the lungs may also occur via infection from the blood stream. This is known as a Simon focus and is typically found in the top of the lung. This hematogenous transmission can also spread infection to more distant sites, such as peripheral lymph nodes, the kidneys, the brain, and the bones. All parts of the body can be affected by the disease, though for unknown reasons it rarely affects the heart, skeletal muscles, pancreas, or thyroid.Tuberculosis is classified as one of the granulomatous inflammatory diseases. Macrophages, epithelioid cells, T lymphocytes, B lymphocytes, and fibroblasts aggregate to form granulomas, with lymphocytes surrounding the infected macrophages. When other macrophages attack the infected macrophage, they fuse together to form a giant multinucleated cell in the alveolar lumen. The granuloma may prevent dissemination of the mycobacteria and provide a local environment for interaction of cells of the immune system. However, more recent evidence suggests that the bacteria use the granulomas to avoid destruction by the host's immune system. Macrophages and dendritic cells in the granulomas are unable to present antigen to lymphocytes; thus the immune response is suppressed. Bacteria inside the granuloma can become dormant, resulting in latent infection. Another feature of the granulomas is the development of abnormal cell death (necrosis) in the center of tubercles. To the naked eye, this has the texture of soft, white cheese and is termed caseous necrosis.If TB bacteria gain entry to the blood stream from an area of damaged tissue, they can spread throughout the body and set up many foci of infection, all appearing as tiny, white tubercles in the tissues. This severe form of TB disease, most common in young children and those with HIV, is called miliary tuberculosis. People with this disseminated TB have a high fatality rate even with treatment (about 30%).In many people, the infection waxes and wanes. Tissue destruction and necrosis are often balanced by healing and fibrosis. Affected tissue is replaced by scarring and cavities filled with caseous necrotic material. During active disease, some of these cavities are joined to the air passages (bronchi) and this material can be coughed up. It contains living bacteria and thus can spread the infection. Treatment with appropriate antibiotics kills bacteria and allows healing to take place. Upon cure, affected areas are eventually replaced by scar tissue.  Diagnosis   Active tuberculosis  Diagnosing active tuberculosis based only on signs and symptoms is difficult, as is diagnosing the disease in those who have a weakened immune system. A diagnosis of TB should, however, be considered in those with signs of lung disease or constitutional symptoms lasting longer than two weeks. A chest X-ray and multiple sputum cultures for acid-fast bacilli are typically part of the initial evaluation. Interferon-γ release assays (IGRA) and tuberculin skin tests are of little use in most of the developing world. IGRA have similar limitations in those with HIV.A definitive diagnosis of TB is made by identifying M. tuberculosis in a clinical sample (e.g., sputum, pus, or a tissue biopsy). However, the difficult culture process for this slow-growing organism can take two to six weeks for blood or sputum culture. Thus, treatment is often begun before cultures are confirmed.Nucleic acid amplification tests and adenosine deaminase testing may allow rapid diagnosis of TB. Blood tests to detect antibodies are not specific or sensitive, so they are not recommended.  Latent tuberculosis  The Mantoux tuberculin skin test is often used to screen people at high risk for TB. Those who have been previously immunized with the Bacille Calmette-Guerin vaccine may have a false-positive test result. The test may be falsely negative in those with sarcoidosis, Hodgkin's lymphoma, malnutrition, and most notably, active tuberculosis. Interferon gamma release assays, on a blood sample, are recommended in those who are positive to the Mantoux test. These are not affected by immunization or most environmental mycobacteria, so they generate fewer false-positive results. However, they are affected by M. szulgai, M. marinum, and M. kansasii. IGRAs may increase sensitivity when used in addition to the skin test, but may be less sensitive than the skin test when used alone.The US Preventive Services Task Force (USPSTF) has recommended screening people who are at high risk for latent tuberculosis with either tuberculin skin tests or interferon-gamma release assays. While some have recommend testing health care workers, evidence of benefit for this is poor as of 2019. The Centers for Disease Control and Prevention (CDC) stopped recommending yearly testing of health care workers without known exposure in 2019.  Prevention  Tuberculosis prevention and control efforts rely primarily on the vaccination of infants and the detection and appropriate treatment of active cases. The World Health Organization (WHO) has achieved some success with improved treatment regimens, and a small decrease in case numbers. Some countries have legislation to involuntarily detain or examine those suspected to have tuberculosis, or involuntarily treat them if infected.  Vaccines  The only available vaccine as of 2021 is bacillus Calmette-Guérin (BCG). In children it decreases the risk of getting the infection by 20% and the risk of infection turning into active disease by nearly 60%.It is the most widely used vaccine worldwide, with more than 90% of all children being vaccinated. The immunity it induces decreases after about ten years. As tuberculosis is uncommon in most of Canada, Western Europe, and the United States, BCG is administered to only those people at high risk. Part of the reasoning against the use of the vaccine is that it makes the tuberculin skin test falsely positive, reducing the test's usefulness as a screening tool. Several vaccines are being developed.Intradermal MVA85A vaccine in addition to BCG injection is not effective in preventing tuberculosis.  Public health  Public health campaigns which have focused on overcrowding, public spitting and regular sanitation (including hand washing) during the 1800s helped to either interrupt or slow spread which when combined with contact tracing, isolation and treatment helped to dramatically curb the transmission of both tuberculosis and other airborne diseases which led to the elimination of tuberculosis as a major public health issue in most developed economies. Other risk factors which worsened TB spread such as malnutrition were also ameliorated, but since the emergence of HIV a new population of immunocompromised individuals was available for TB to infect. The World Health Organization (WHO) declared TB a ""global health emergency"" in 1993, and in 2006, the Stop TB Partnership developed a Global Plan to Stop Tuberculosis that aimed to save 14 million lives between its launch and 2015. A number of targets they set were not achieved by 2015, mostly due to the increase in HIV-associated tuberculosis and the emergence of multiple drug-resistant tuberculosis. A tuberculosis classification system developed by the American Thoracic Society is used primarily in public health programs. In 2015, it launched the End TB Strategy to reduce deaths by 95% and incidence by 90% before 2035. The goal of tuberculosis elimination is hampered by the lack of rapid testing, of short and effective treatment courses, and of completely effective vaccines.The benefits and risks of giving anti-tubercular drugs in those exposed to MDR-TB is unclear. Making HAART therapy available to HIV-positive individuals significantly reduces the risk of progression to an active TB infection by up to 90% and can mitigate the spread through this population.  Treatment  Treatment of TB uses antibiotics to kill the bacteria. Effective TB treatment is difficult, due to the unusual structure and chemical composition of the mycobacterial cell wall, which hinders the entry of drugs and makes many antibiotics ineffective.Active TB is best treated with combinations of several antibiotics to reduce the risk of the bacteria developing antibiotic resistance. The routine use of rifabutin instead of rifampicin in HIV-positive people with tuberculosis is of unclear benefit as of 2007.  Latent TB  Latent TB is treated with either isoniazid or rifampin alone, or a combination of isoniazid with either rifampicin or rifapentine.The treatment takes three to nine months depending on the medications used. People with latent infections are treated to prevent them from progressing to active TB disease later in life.Education or counselling may improve the latent tuberculosis treatment completion rates.  New onset  The recommended treatment of new-onset pulmonary tuberculosis, as of 2010, is six months of a combination of antibiotics containing rifampicin, isoniazid, pyrazinamide, and ethambutol for the first two months, and only rifampicin and isoniazid for the last four months. Where resistance to isoniazid is high, ethambutol may be added for the last four months as an alternative. Treatment with anti-TB drugs for at least 6 months results in higher success rates when compared with treatment less than 6 months, even though the difference is small. Shorter treatment regimen may be recommended for those with compliance issues. There is also no evidence to support shorter anti-tuberculosis treatment regimens when compared to a 6-month treatment regimen. However recently, results from an international, randomized, controlled clinical trial indicate that a four-month daily treatment regimen containing high-dose, or ""optimized"", rifapentine with moxifloxacin (2PHZM/2PHM) is as safe and effective as the existing standard six-month daily regimen at curing drug-susceptible tuberculosis (TB) disease.  Recurrent disease  If tuberculosis recurs, testing to determine which antibiotics it is sensitive to is important before determining treatment. If multiple drug-resistant TB (MDR-TB) is detected, treatment with at least four effective antibiotics for 18 to 24 months is recommended.  Medication administration  Directly observed therapy, i.e., having a health care provider watch the person take their medications, is recommended by the World Health Organization (WHO) in an effort to reduce the number of people not appropriately taking antibiotics. The evidence to support this practice over people simply taking their medications independently is of poor quality. There is no strong evidence indicating that directly observed therapy improves the number of people who were cured or the number of people who complete their medicine. Moderate quality evidence suggests that there is also no difference if people are observed at home versus at a clinic, or by a family member versus a health care worker. Methods to remind people of the importance of treatment and appointments may result in a small but important improvement. There is also not enough evidence to support intermittent rifampicin-containing therapy given two to three times a week has equal effectiveness as daily dose regimen on improving cure rates and reducing relapsing rates. There is also not enough evidence on effectiveness of giving intermittent twice or thrice weekly short course regimen compared to daily dosing regimen in treating children with tuberculosis.  Medication resistance  Primary resistance occurs when a person becomes infected with a resistant strain of TB. A person with fully susceptible MTB may develop secondary (acquired) resistance during therapy because of inadequate treatment, not taking the prescribed regimen appropriately (lack of compliance), or using low-quality medication. Drug-resistant TB is a serious public health issue in many developing countries, as its treatment is longer and requires more expensive drugs. MDR-TB is defined as resistance to the two most effective first-line TB drugs: rifampicin and isoniazid. Extensively drug-resistant TB is also resistant to three or more of the six classes of second-line drugs. Totally drug-resistant TB is resistant to all currently used drugs. It was first observed in 2003 in Italy, but not widely reported until 2012, and has also been found in Iran and India. There is some efficacy for linezolid to treat those with XDR-TB but side effects and discontinuation of medications were common. Bedaquiline is tentatively supported for use in multiple drug-resistant TB.XDR-TB is a term sometimes used to define extensively resistant TB, and constitutes one in ten cases of MDR-TB. Cases of XDR TB have been identified in more than 90% of countries.For those with known rifampicin or MDR-TB, molecular tests such as the Genotype MTBDRsl Assay (performed on culture isolates or smear positive specimens) may be useful to detect second-line anti-tubercular drug resistance.  Prognosis  Progression from TB infection to overt TB disease occurs when the bacilli overcome the immune system defenses and begin to multiply. In primary TB disease (some 1–5% of cases), this occurs soon after the initial infection. However, in the majority of cases, a latent infection occurs with no obvious symptoms. These dormant bacilli produce active tuberculosis in 5–10% of these latent cases, often many years after infection.The risk of reactivation increases with immunosuppression, such as that caused by infection with HIV. In people coinfected with M. tuberculosis and HIV, the risk of reactivation increases to 10% per year. Studies using DNA fingerprinting of M. tuberculosis strains have shown reinfection contributes more substantially to recurrent TB than previously thought, with estimates that it might account for more than 50% of reactivated cases in areas where TB is common. The chance of death from a case of tuberculosis is about 4% as of 2008, down from 8% in 1995.In people with smear-positive pulmonary TB (without HIV co-infection), after 5 years without treatment, 50-60% die while 20-25% achieve spontaneous resolution (cure). TB is almost always fatal in those with untreated HIV co-infection and death rates are increased even with antiretroviral treatment of HIV.  Epidemiology  Roughly one-quarter of the world's population has been infected with M. tuberculosis, with new infections occurring in about 1% of the population each year. However, most infections with M. tuberculosis do not cause disease, and 90–95% of infections remain asymptomatic. In 2012, an estimated 8.6 million chronic cases were active. In 2010, 8.8 million new cases of tuberculosis were diagnosed, and 1.20–1.45 million deaths occurred (most of these occurring in developing countries). Of these, about 0.35 million occur in those also infected with HIV. In 2018, tuberculosis was the leading cause of death worldwide from a single infectious agent. The total number of tuberculosis cases has been decreasing since 2005, while new cases have decreased since 2002.Tuberculosis incidence is seasonal, with peaks occurring every spring and summer. The reasons for this are unclear, but may be related to vitamin D deficiency during the winter. There are also studies linking tuberculosis to different weather conditions like low temperature, low humidity and low rainfall. It has been suggested that tuberculosis incidence rates may be connected to climate change.  At-risk groups  Tuberculosis is closely linked to both overcrowding and malnutrition, making it one of the principal diseases of poverty. Those at high risk thus include: people who inject illicit drugs, inhabitants and employees of locales where vulnerable people gather (e.g., prisons and homeless shelters), medically underprivileged and resource-poor communities, high-risk ethnic minorities, children in close contact with high-risk category patients, and health-care providers serving these patients.The rate of tuberculosis varies with age. In Africa, it primarily affects adolescents and young adults. However, in countries where incidence rates have declined dramatically (such as the United States), tuberculosis is mainly a disease of the elderly and immunocompromised (risk factors are listed above). Worldwide, 22 ""high-burden"" states or countries together experience 80% of cases as well as 83% of deaths.In Canada and Australia, tuberculosis is many times more common among the Indigenous peoples, especially in remote areas. Factors contributing to this include higher prevalence of predisposing health conditions and behaviours, and overcrowding and poverty. In some Canadian Indigenous groups, genetic susceptibility may play a role.Socioeconomic status (SES) strongly affects TB risk. People of low SES are both more likely to contract TB and to be more severely affected by the disease. Those with low SES are more likely to be affected by risk factors for developing TB (e.g., malnutrition, indoor air pollution, HIV co-infection, etc.), and are additionally more likely to be exposed to crowded and poorly ventilated spaces. Inadequate healthcare also means that people with active disease who facilitate spread are not diagnosed and treated promptly; sick people thus remain in the infectious state and (continue to) spread the infection.  Geographical epidemiology  The distribution of tuberculosis is not uniform across the globe; about 80% of the population in many African, Caribbean, South Asian, and eastern European countries test positive in tuberculin tests, while only 5–10% of the U.S. population test positive. Hopes of totally controlling the disease have been dramatically dampened because of many factors, including the difficulty of developing an effective vaccine, the expensive and time-consuming diagnostic process, the necessity of many months of treatment, the increase in HIV-associated tuberculosis, and the emergence of drug-resistant cases in the 1980s.In developed countries, tuberculosis is less common and is found mainly in urban areas. In Europe, deaths from TB fell from 500 out of 100,000 in 1850 to 50 out of 100,000 by 1950. Improvements in public health were reducing tuberculosis even before the arrival of antibiotics, although the disease remained a significant threat to public health, such that when the Medical Research Council was formed in Britain in 1913 its initial focus was tuberculosis research.In 2010, rates per 100,000 people in different areas of the world were: globally 178, Africa 332, the Americas 36, Eastern Mediterranean 173, Europe 63, Southeast Asia 278, and Western Pacific 139.  Russia  Russia has achieved particularly dramatic progress with a decline in its TB mortality rate—from 61.9 per 100,000 in 1965 to 2.7 per 100,000 in 1993; however, mortality rate increased to 24 per 100,000 in 2005 and then recoiled to 11 per 100,000 by 2015.  China  China has achieved particularly dramatic progress, with about an 80% reduction in its TB mortality rate between 1990 and 2010. The number of new cases has declined by 17% between 2004 and 2014.  Africa  In 2007, the country with the highest estimated incidence rate of TB was Eswatini, with 1,200 cases per 100,000 people. In 2017, the country with the highest estimated incidence rate as a % of the population was Lesotho, with 665 cases per 100,000 people.  India  As of 2017, India had the largest total incidence, with an estimated 2,740,000 cases. According to the World Health Organization (WHO), in 2000–2015, India's estimated mortality rate dropped from 55 to 36 per 100,000 population per year with estimated 480 thousand people died of TB in 2015. In India a major proportion of tuberculosis patients are being treated by private partners and private hospitals. Evidence indicates that the tuberculosis national survey does not represent the number of cases that are diagnosed and recorded by private clinics and hospitals in India.  North America  In the United States, Native Americans have a fivefold greater mortality from TB, and racial and ethnic minorities accounted for 84% of all reported TB cases.In the United States, the overall tuberculosis case rate was 3 per 100,000 persons in 2017. In Canada, tuberculosis is still endemic in some rural areas.  Western Europe  In 2017, in the United Kingdom, the national average was 9 per 100,000 and the highest incidence rates in Western Europe were 20 per 100,000 in Portugal.  History  Tuberculosis has existed since antiquity. The oldest unambiguously detected M. tuberculosis gives evidence of the disease in the remains of bison in Wyoming dated to around 17,000 years ago. However, whether tuberculosis originated in bovines, then transferred to humans, or whether both bovine and human tuberculosis diverged from a common ancestor, remains unclear. A comparison of the genes of M. tuberculosis complex (MTBC) in humans to MTBC in animals suggests humans did not acquire MTBC from animals during animal domestication, as researchers previously believed. Both strains of the tuberculosis bacteria share a common ancestor, which could have infected humans even before the Neolithic Revolution. Skeletal remains show some prehistoric humans (4000 BC) had TB, and researchers have found tubercular decay in the spines of Egyptian mummies dating from 3000 to 2400 BC. Genetic studies suggest the presence of TB in the Americas from about AD 100.Before the Industrial Revolution, folklore often associated tuberculosis with vampires. When one member of a family died from the disease, the other infected members would lose their health slowly. People believed this was caused by the original person with TB draining the life from the other family members.Although Richard Morton established the pulmonary form associated with tubercles as a pathology in 1689, due to the variety of its symptoms, TB was not identified as a single disease until the 1820s. Benjamin Marten conjectured in 1720 that consumptions were caused by microbes which were spread by people living close to each other. In 1819, René Laennec claimed that tubercles were the cause of pulmonary tuberculosis. J. L. Schönlein first published the name ""tuberculosis"" (German: Tuberkulose) in 1832. Between 1838 and 1845, John Croghan, the owner of Mammoth Cave in Kentucky from 1839 onwards, brought a number of people with tuberculosis into the cave in the hope of curing the disease with the constant temperature and purity of the cave air; each died within a year. Hermann Brehmer opened the first TB sanatorium in 1859 in Görbersdorf (now Sokołowsko) in Silesia. In 1865, Jean Antoine Villemin demonstrated that tuberculosis could be transmitted, via inoculation, from humans to animals and among animals. (Villemin's findings were confirmed in 1867 and 1868 by John Burdon-Sanderson.) Robert Koch identified and described the bacillus causing tuberculosis, M. tuberculosis, on 24 March 1882. In 1905, he was awarded the Nobel Prize in Physiology or Medicine for this discovery. Koch did not believe the cattle and human tuberculosis diseases were similar, which delayed the recognition of infected milk as a source of infection. During the first half of the 1900s, the risk of transmission from this source was dramatically reduced after the application of the pasteurization process. Koch announced a glycerine extract of the tubercle bacilli as a ""remedy"" for tuberculosis in 1890, calling it ""tuberculin"". Although it was not effective, it was later successfully adapted as a screening test for the presence of pre-symptomatic tuberculosis. World Tuberculosis Day is marked on 24 March each year, the anniversary of Koch's original scientific announcement. Albert Calmette and Camille Guérin achieved the first genuine success in immunization against tuberculosis in 1906, using attenuated bovine-strain tuberculosis. It was called bacille Calmette–Guérin (BCG). The BCG vaccine was first used on humans in 1921 in France, but achieved widespread acceptance in the US, Great Britain, and Germany only after World War II.Tuberculosis caused widespread public concern in the 19th and early 20th centuries as the disease became common among the urban poor. In 1815, one in four deaths in England was due to ""consumption"". By 1918, TB still caused one in six deaths in France. After TB was determined to be contagious, in the 1880s, it was put on a notifiable-disease list in Britain; campaigns started to stop people from spitting in public places, and the infected poor were ""encouraged"" to enter sanatoria that resembled prisons (the sanatoria for the middle and upper classes offered excellent care and constant medical attention). Whatever the benefits of the ""fresh air"" and labor in the sanatoria, even under the best conditions, 50% of those who entered died within five years (c. 1916). When the Medical Research Council formed in Britain in 1913, it initially focused on tuberculosis research.In Europe, rates of tuberculosis began to rise in the early 1600s to a peak level in the 1800s, when it caused nearly 25% of all deaths. In the 18th and 19th century, tuberculosis had become epidemic in Europe, showing a seasonal pattern. By the 1950s mortality in Europe had decreased about 90%. Improvements in sanitation, vaccination, and other public-health measures began significantly reducing rates of tuberculosis even before the arrival of streptomycin and other antibiotics, although the disease remained a significant threat. In 1946, the development of the antibiotic streptomycin made effective treatment and cure of TB a reality. Prior to the introduction of this medication, the only treatment was surgical intervention, including the ""pneumothorax technique"", which involved collapsing an infected lung to ""rest"" it and to allow tuberculous lesions to heal.Because of the emergence of multidrug-resistant tuberculosis (MDR-TB), surgery has been re-introduced for certain cases of TB infections. It involves the removal of infected chest cavities (""bullae"") in the lungs to reduce the number of bacteria and to increase exposure of the remaining bacteria to antibiotics in the bloodstream. Hopes of eliminating TB ended with the rise of drug-resistant strains in the 1980s. The subsequent resurgence of tuberculosis resulted in the declaration of a global health emergency by the World Health Organization (WHO) in 1993.  Society and culture   Names  Tuberculosis has been known by many names from the technical to the familiar. Phthisis (Φθισις) is a Greek word for consumption, an old term for pulmonary tuberculosis; around 460 BCE, Hippocrates described phthisis as a disease of dry seasons. The abbreviation TB is short for tubercle bacillus. Consumption was the most common nineteenth century English word for the disease, and was also in use well into the twentieth century. The Latin root con meaning 'completely' is linked to sumere meaning 'to take up from under'. In The Life and Death of Mr Badman by John Bunyan, the author calls consumption ""the captain of all these men of death."" ""Great white plague"" has also been used.  Art and literature  Tuberculosis was for centuries associated with poetic and artistic qualities among those infected, and was also known as ""the romantic disease"". Major artistic figures such as the poets John Keats, Percy Bysshe Shelley, and Edgar Allan Poe, the composer Frédéric Chopin, the playwright Anton Chekhov, the novelists Franz Kafka, Katherine Mansfield, Charlotte Brontë, Fyodor Dostoevsky, Thomas Mann, W. Somerset Maugham, George Orwell, and Robert Louis Stevenson, and the artists Alice Neel, Jean-Antoine Watteau, Elizabeth Siddal, Marie Bashkirtseff, Edvard Munch, Aubrey Beardsley and Amedeo Modigliani either had the disease or were surrounded by people who did. A widespread belief was that tuberculosis assisted artistic talent. Physical mechanisms proposed for this effect included the slight fever and toxaemia that it caused, allegedly helping them to see life more clearly and to act decisively.Tuberculosis formed an often-reused theme in literature, as in Thomas Mann's The Magic Mountain, set in a sanatorium; in music, as in Van Morrison's song ""T.B. Sheets""; in opera, as in Puccini's La bohème and Verdi's La Traviata; in art, as in Monet's painting of his first wife Camille on her deathbed; and in film, such as the 1945 The Bells of St. Mary's starring Ingrid Bergman as a nun with tuberculosis.  Public health efforts  In 2014, the WHO adopted the ""End TB"" strategy which aims to reduce TB incidence by 80% and TB deaths by 90% by 2030. The strategy contains a milestone to reduce TB incidence by 20% and TB deaths by 35% by 2020. However, by 2020 only a 9% reduction in incidence per population was achieved globally, with the European region achieving 19% and the African region achieving 16% reductions. Similarly, the number of deaths only fell by 14%, missing the 2020 milestone of a 35% reduction, with some regions making better progress (31% reduction in Europe and 19% in Africa). Correspondingly, also treatment, prevention and funding milestones were missed in 2020, for example only 6.3 million people were started on TB prevention short of the target of 30 million.The World Health Organization (WHO), the Bill and Melinda Gates Foundation, and the U.S. government are subsidizing a fast-acting diagnostic tuberculosis test for use in low- and middle-income countries as of 2012. In addition to being fast-acting, the test can determine if there is resistance to the antibiotic rifampicin which may indicate multi-drug resistant tuberculosis and is accurate in those who are also infected with HIV. Many resource-poor places as of 2011 have access to only sputum microscopy.India had the highest total number of TB cases worldwide in 2010, in part due to poor disease management within the private and public health care sector. Programs such as the Revised National Tuberculosis Control Program are working to reduce TB levels among people receiving public health care.A 2014 EIU-healthcare report finds there is a need to address apathy and urges for increased funding. The report cites among others Lucica Ditui ""[TB] is like an orphan. It has been neglected even in countries with a high burden and often forgotten by donors and those investing in health interventions.""Slow progress has led to frustration, expressed by the executive director of the Global Fund to Fight AIDS, Tuberculosis and Malaria – Mark Dybul: ""we have the tools to end TB as a pandemic and public health threat on the planet, but we are not doing it."" Several international organizations are pushing for more transparency in treatment, and more countries are implementing mandatory reporting of cases to the government as of 2014, although adherence is often variable. Commercial treatment providers may at times overprescribe second-line drugs as well as supplementary treatment, promoting demands for further regulations. The government of Brazil provides universal TB care, which reduces this problem. Conversely, falling rates of TB infection may not relate to the number of programs directed at reducing infection rates but may be tied to an increased level of education, income, and health of the population. Costs of the disease, as calculated by the World Bank in 2009 may exceed US$150 billion per year in ""high burden"" countries. Lack of progress eradicating the disease may also be due to lack of patient follow-up – as among the 250 million rural migrants in China.There is insufficient data to show that active contact tracing helps to improve case detection rates for tuberculosis. Interventions such as house-to-house visits, educational leaflets, mass media strategies, educational sessions may increase tuberculosis detection rates in short-term. There is no study that compares new methods of contact tracing such as social network analysis with existing contact tracing methods.  Stigma  Slow progress in preventing the disease may in part be due to stigma associated with TB. Stigma may be due to the fear of transmission from affected individuals. This stigma may additionally arise due to links between TB and poverty, and in Africa, AIDS. Such stigmatization may be both real and perceived; for example, in Ghana, individuals with TB are banned from attending public gatherings.Stigma towards TB may result in delays in seeking treatment, lower treatment compliance, and family members keeping cause of death secret – allowing the disease to spread further. In contrast, in Russia stigma was associated with increased treatment compliance. TB stigma also affects socially marginalized individuals to a greater degree and varies between regions.One way to decrease stigma may be through the promotion of ""TB clubs"", where those infected may share experiences and offer support, or through counseling. Some studies have shown TB education programs to be effective in decreasing stigma, and may thus be effective in increasing treatment adherence. Despite this, studies on the relationship between reduced stigma and mortality are lacking as of 2010, and similar efforts to decrease stigma surrounding AIDS have been minimally effective. Some have claimed the stigma to be worse than the disease, and healthcare providers may unintentionally reinforce stigma, as those with TB are often perceived as difficult or otherwise undesirable. A greater understanding of the social and cultural dimensions of tuberculosis may also help with stigma reduction.  Research  The BCG vaccine has limitations, and research to develop new TB vaccines is ongoing. A number of potential candidates are currently in phase I and II clinical trials. Two main approaches are used to attempt to improve the efficacy of available vaccines. One approach involves adding a subunit vaccine to BCG, while the other strategy is attempting to create new and better live vaccines. MVA85A, an example of a subunit vaccine, is in trials in South Africa as of 2006, is based on a genetically modified vaccinia virus. Vaccines are hoped to play a significant role in treatment of both latent and active disease.To encourage further discovery, researchers and policymakers are promoting new economic models of vaccine development as of 2006, including prizes, tax incentives, and advance market commitments. A number of groups, including the Stop TB Partnership, the South African Tuberculosis Vaccine Initiative, and the Aeras Global TB Vaccine Foundation, are involved with research. Among these, the Aeras Global TB Vaccine Foundation received a gift of more than $280 million (US) from the Bill and Melinda Gates Foundation to develop and license an improved vaccine against tuberculosis for use in high burden countries.A number of medications are being studied as of 2012 for multidrug-resistant tuberculosis, including bedaquiline and delamanid. Bedaquiline received U.S. Food and Drug Administration (FDA) approval in late 2012. The safety and effectiveness of these new agents are uncertain as of 2012, because they are based on the results of relatively small studies. However, existing data suggest that patients taking bedaquiline in addition to standard TB therapy are five times more likely to die than those without the new drug, which has resulted in medical journal articles raising health policy questions about why the FDA approved the drug and whether financial ties to the company making bedaquiline influenced physicians' support for its use.Steroids add-on therapy has not shown any benefits for active pulmonary tuberculosis infection.  Other animals  Mycobacteria infect many different animals, including birds, fish, rodents, and reptiles. The subspecies Mycobacterium tuberculosis, though, is rarely present in wild animals. An effort to eradicate bovine tuberculosis caused by Mycobacterium bovis from the cattle and deer herds of New Zealand has been relatively successful. Efforts in Great Britain have been less successful.As of 2015, tuberculosis appears to be widespread among captive elephants in the US. It is believed that the animals originally acquired the disease from humans, a process called reverse zoonosis. Because the disease can spread through the air to infect both humans and other animals, it is a public health concern affecting circuses and zoos.  References   External links  Tuberculosis at Curlie ""Tuberculosis (TB)"". Centers for Disease Control and Prevention (CDC). 24 October 2018. ""Tuberculosis (TB)"". London: Health Protection Agency. Archived from the original on 5 July 2007. WHO global 2016 TB report (infographic) WHO tuberculosis country profiles ""Tuberculosis Among African Americans"", 1990-11-01, In Black America; KUT Radio, American Archive of Public Broadcasting (WGBH and the Library of Congress) Working Group on New TB drugs, tracking clinical trials and drug candidates","Tuberculosis (TB) is an infectious disease caused by bacteria. In the past, people called it consumption. TB is caused by several types of mycobacteria, usually Mycobacterium tuberculosis. The disease usually attacks the lungs, but it can also affect other parts of the body.  How it spreads  The bacteria can travel through the air and spread from one person to the next. This happens when infected people cough, sneeze, or spit.Of every 100 people with TB, between five and ten people show symptoms. In these people, the disease is called active. Tuberculosis kills more than half of the people who are infected if they do not get treatment.  Detection and treatment  Diagnosis of active TB relies on radiology. Doctors often look at an X-ray of the chest. In addition, they check body fluids. These fluids have microbes in them, which are grown in cell cultures. The cell cultures are then analysed to see if the person is infected with TB. If the patient has TB, but does not show symptoms, the disease is 'latent'. Doctors use a skin test, called the Mantoux test, to detect latent TB. They often do blood tests too. There is a vaccine against some forms of tuberculosis. It is called bacillus Calmette–Guérin vaccine. TB used to be easily treated and cured with antibiotics. However, the bacterium is now highly resistant to most antibiotics. This resistance makes treatment difficult. Many different kinds of antibiotics need to be given over a long period of time. There is a form of tuberculosis that is resistant to all drugs.  Symptoms  Tuberculosis can have many symptoms. The most common include: A cough that does not go away, especially if the person is coughing up blood (this is called hemoptysis) Chest pain Not having any appetite Weakness Weight loss Chills Very pale skin Listless eyes Fever Sweating a lot at night Difficulty breathing Feeling very tired People are also more likely to get tuberculosis if they live close to other people who have TB. For example, TB can spread easily in homeless shelters, prisons, and immigrant communities.  How common is TB?  Experts believe that one third of the world population is infected with M. tuberculosis. New infections occur at a rate of one per second. In 2007, about 13.7 million chronic cases were active globally. In 2010, about 8.8 million new cases developed and nearly 1.5 million people died from the disease, most of them in developing countries. The number of tuberculosis cases has been decreasing since 2006, and new cases have decreased since 2002.Tuberculosis does not happen at the same rate around the world. About eighty percent of the population in many Asian and African countries test positive for TB, but only five to ten percent of people in the United States do.People usually get tuberculosis because of a weakened immune system. Many people with HIV and AIDS can also get tuberculosis.  References   Other websites  Frequently asked Questions about TB at CDC.gov ExplainTB: Multilingual audiovisual information on tuberculosis"
"Pneumonia is an inflammatory condition of the lung primarily affecting the small air sacs known as alveoli. Symptoms typically include some combination of productive or dry cough, chest pain, fever, and difficulty breathing. The severity of the condition is variable.Pneumonia is usually caused by infection with viruses or bacteria, and less commonly by other microorganisms. Identifying the responsible pathogen can be difficult. Diagnosis is often based on symptoms and physical examination. Chest X-rays, blood tests, and culture of the sputum may help confirm the diagnosis. The disease may be classified by where it was acquired, such as community- or hospital-acquired or healthcare-associated pneumonia.Risk factors for pneumonia include cystic fibrosis, chronic obstructive pulmonary disease (COPD), sickle cell disease, asthma, diabetes, heart failure, a history of smoking, a poor ability to cough (such as following a stroke), and a weak immune system.Vaccines to prevent certain types of pneumonia (such as those caused by Streptococcus pneumoniae bacteria, linked to influenza, or linked to COVID-19) are available. Other methods of prevention include hand washing to prevent infection, not smoking, and social distancing.Treatment depends on the underlying cause. Pneumonia believed to be due to bacteria is treated with antibiotics. If the pneumonia is severe, the affected person is generally hospitalized. Oxygen therapy may be used if oxygen levels are low.Each year, pneumonia affects about 450 million people globally (7% of the population) and results in about 4 million deaths. With the introduction of antibiotics and vaccines in the 20th century, survival has greatly improved. Nevertheless, pneumonia remains a leading cause of death in developing countries, and also among the very old, the very young, and the chronically ill. Pneumonia often shortens the period of suffering among those already close to death and has thus been called ""the old man's friend"".  Signs and symptoms  People with infectious pneumonia often have a productive cough, fever accompanied by shaking chills, shortness of breath, sharp or stabbing chest pain during deep breaths, and an increased rate of breathing. In elderly people, confusion may be the most prominent sign.The typical signs and symptoms in children under five are fever, cough, and fast or difficult breathing. Fever is not very specific, as it occurs in many other common illnesses and may be absent in those with severe disease, malnutrition or in the elderly. In addition, a cough is frequently absent in children less than 2 months old. More severe signs and symptoms in children may include blue-tinged skin, unwillingness to drink, convulsions, ongoing vomiting, extremes of temperature, or a decreased level of consciousness.Bacterial and viral cases of pneumonia usually result in similar symptoms. Some causes are associated with classic, but non-specific, clinical characteristics. Pneumonia caused by Legionella may occur with abdominal pain, diarrhea, or confusion. Pneumonia caused by Streptococcus pneumoniae is associated with rusty colored sputum. Pneumonia caused by Klebsiella may have bloody sputum often described as ""currant jelly"". Bloody sputum (known as hemoptysis) may also occur with tuberculosis, Gram-negative pneumonia, lung abscesses and more commonly acute bronchitis. Pneumonia caused by Mycoplasma pneumoniae may occur in association with swelling of the lymph nodes in the neck, joint pain, or a middle ear infection. Viral pneumonia presents more commonly with wheezing than bacterial pneumonia. Pneumonia was historically divided into ""typical"" and ""atypical"" based on the belief that the presentation predicted the underlying cause. However, evidence has not supported this distinction, therefore it is no longer emphasized.  Cause  Pneumonia is due to infections caused primarily by bacteria or viruses and less commonly by fungi and parasites. Although more than 100 strains of infectious agents have been identified, only a few are responsible for the majority of cases. Mixed infections with both viruses and bacteria may occur in roughly 45% of infections in children and 15% of infections in adults. A causative agent may not be isolated in about half of cases despite careful testing. In an active population-based surveillance for community-acquired pneumonia requiring hospitalization in five hospitals in Chicago and Nashville from January 2010 through June 2012, 2259 patients were identified who had radiographic evidence of pneumonia and specimens that could be tested for the responsible pathogen. Most patients (62%) had no detectable pathogens in their sample, and unexpectedly, respiratory viruses were detected more frequently than bacteria. Specifically, 23% had one or more viruses, 11% had one or more bacteria, 3% had both bacterial and viral pathogens, and 1% had a fungal or mycobacterial infection. ""The most common pathogens were human rhinovirus (in 9% of patients), influenza virus (in 6%), and Streptococcus pneumoniae (in 5%).""The term pneumonia is sometimes more broadly applied to any condition resulting in inflammation of the lungs (caused for example by autoimmune diseases, chemical burns or drug reactions); however, this inflammation is more accurately referred to as pneumonitis.Factors that predispose to pneumonia include smoking, immunodeficiency, alcoholism, chronic obstructive pulmonary disease, sickle cell disease (SCD), asthma, chronic kidney disease, liver disease, and biological aging. Additional risks in children include not being breastfed, exposure to cigarette smoke and other air pollution, malnutrition, and poverty. The use of acid-suppressing medications – such as proton-pump inhibitors or H2 blockers – is associated with an increased risk of pneumonia. Approximately 10% of people who require mechanical ventilation develop ventilator-associated pneumonia, and people with a gastric feeding tube have an increased risk of developing aspiration pneumonia. Moreover, the misplacement of a feeding tube can lead to aspiration pneumonia. 28% of tube malposition results in pneumonia. As with Avanos Medical's feeding tube placement system, the CORTRAK 2 EAS, which was recalled in May 2022 by the FDA due to adverse events reported, including pneumonia, caused a total of 60 injuries and 23 patient deaths, as communicated by the FDA. For people with certain variants of the FER gene, the risk of death is reduced in sepsis caused by pneumonia. However, for those with TLR6 variants, the risk of getting Legionnaires' disease is increased.  Bacteria  Bacteria are the most common cause of community-acquired pneumonia (CAP), with Streptococcus pneumoniae isolated in nearly 50% of cases. Other commonly isolated bacteria include Haemophilus influenzae in 20%, Chlamydophila pneumoniae in 13%, and Mycoplasma pneumoniae in 3% of cases; Staphylococcus aureus; Moraxella catarrhalis; and Legionella pneumophila. A number of drug-resistant versions of the above infections are becoming more common, including drug-resistant Streptococcus pneumoniae (DRSP) and methicillin-resistant Staphylococcus aureus (MRSA).The spreading of organisms is facilitated by certain risk factors. Alcoholism is associated with Streptococcus pneumoniae, anaerobic organisms, and Mycobacterium tuberculosis; smoking facilitates the effects of Streptococcus pneumoniae, Haemophilus influenzae, Moraxella catarrhalis, and Legionella pneumophila. Exposure to birds is associated with Chlamydia psittaci; farm animals with Coxiella burnetti; aspiration of stomach contents with anaerobic organisms; and cystic fibrosis with Pseudomonas aeruginosa and Staphylococcus aureus. Streptococcus pneumoniae is more common in the winter, and it should be suspected in persons aspirating a large number of anaerobic organisms.  Viruses  In adults, viruses account for about one third of pneumonia cases, and in children for about 15% of them. Commonly implicated agents include rhinoviruses, coronaviruses, influenza virus, respiratory syncytial virus (RSV), adenovirus, and parainfluenza. Herpes simplex virus rarely causes pneumonia, except in groups such as newborns, persons with cancer, transplant recipients, and people with significant burns. After organ transplantation or in otherwise immunocompromised persons, there are high rates of cytomegalovirus pneumonia. Those with viral infections may be secondarily infected with the bacteria Streptococcus pneumoniae, Staphylococcus aureus, or Haemophilus influenzae, particularly when other health problems are present. Different viruses predominate at different times of the year; during flu season, for example, influenza may account for more than half of all viral cases. Outbreaks of other viruses also occur occasionally, including hantaviruses and coronaviruses. Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) can also result in pneumonia.  Fungi  Fungal pneumonia is uncommon, but occurs more commonly in individuals with weakened immune systems due to AIDS, immunosuppressive drugs, or other medical problems. It is most often caused by Histoplasma capsulatum, Blastomyces, Cryptococcus neoformans, Pneumocystis jiroveci (pneumocystis pneumonia, or PCP), and Coccidioides immitis. Histoplasmosis is most common in the Mississippi River basin, and coccidioidomycosis is most common in the Southwestern United States. The number of cases of fungal pneumonia has been increasing in the latter half of the 20th century due to increasing travel and rates of immunosuppression in the population. For people infected with HIV/AIDS, PCP is a common opportunistic infection.  Parasites  A variety of parasites can affect the lungs, including Toxoplasma gondii, Strongyloides stercoralis, Ascaris lumbricoides, and Plasmodium malariae. These organisms typically enter the body through direct contact with the skin, ingestion, or via an insect vector. Except for Paragonimus westermani, most parasites do not specifically affect the lungs but involve the lungs secondarily to other sites. Some parasites, in particular those belonging to the Ascaris and Strongyloides genera, stimulate a strong eosinophilic reaction, which may result in eosinophilic pneumonia. In other infections, such as malaria, lung involvement is due primarily to cytokine-induced systemic inflammation. In the developed world, these infections are most common in people returning from travel or in immigrants. Around the world, parasitic pneumonia is most common in the immunodeficient.  Noninfectious  Idiopathic interstitial pneumonia or noninfectious pneumonia is a class of diffuse lung diseases. They include diffuse alveolar damage, organizing pneumonia, nonspecific interstitial pneumonia, lymphocytic interstitial pneumonia, desquamative interstitial pneumonia, respiratory bronchiolitis interstitial lung disease, and usual interstitial pneumonia. Lipoid pneumonia is another rare cause due to lipids entering the lung. These lipids can either be inhaled or spread to the lungs from elsewhere in the body.  Mechanisms  Pneumonia frequently starts as an upper respiratory tract infection that moves into the lower respiratory tract. It is a type of pneumonitis (lung inflammation). The normal flora of the upper airway give protection by competing with pathogens for nutrients. In the lower airways, reflexes of the glottis, actions of complement proteins and immunoglobulins are important for protection. Microaspiration of contaminated secretions can infect the lower airways and cause pneumonia. The progress of pneumonia is determined by the virulence of the organism; the amount of organism required to start an infection; and the body's immune response against the infection.  Bacterial  Most bacteria enter the lungs via small aspirations of organisms residing in the throat or nose. Half of normal people have these small aspirations during sleep. While the throat always contains bacteria, potentially infectious ones reside there only at certain times and under certain conditions. A minority of types of bacteria such as Mycobacterium tuberculosis and Legionella pneumophila reach the lungs via contaminated airborne droplets. Bacteria can also spread via the blood. Once in the lungs, bacteria may invade the spaces between cells and between alveoli, where the macrophages and neutrophils (defensive white blood cells) attempt to inactivate the bacteria. The neutrophils also release cytokines, causing a general activation of the immune system. This leads to the fever, chills, and fatigue common in bacterial pneumonia. The neutrophils, bacteria, and fluid from surrounding blood vessels fill the alveoli, resulting in the consolidation seen on chest X-ray.  Viral  Viruses may reach the lung by a number of different routes. Respiratory syncytial virus is typically contracted when people touch contaminated objects and then touch their eyes or nose. Other viral infections occur when contaminated airborne droplets are inhaled through the nose or mouth. Once in the upper airway, the viruses may make their way into the lungs, where they invade the cells lining the airways, alveoli, or lung parenchyma. Some viruses such as measles and herpes simplex may reach the lungs via the blood. The invasion of the lungs may lead to varying degrees of cell death. When the immune system responds to the infection, even more lung damage may occur. Primarily white blood cells, mainly mononuclear cells, generate the inflammation. As well as damaging the lungs, many viruses simultaneously affect other organs and thus disrupt other body functions. Viruses also make the body more susceptible to bacterial infections; in this way, bacterial pneumonia can occur at the same time as viral pneumonia.  Diagnosis  Pneumonia is typically diagnosed based on a combination of physical signs and often a chest X-ray. In adults with normal vital signs and a normal lung examination, the diagnosis is unlikely. However, the underlying cause can be difficult to confirm, as there is no definitive test able to distinguish between bacterial and non-bacterial cause. The overall impression of a physician appears to be at least as good as decision rules for making or excluding the diagnosis.  Diagnosis in children  The World Health Organization has defined pneumonia in children clinically based on either a cough or difficulty breathing and a rapid respiratory rate, chest indrawing, or a decreased level of consciousness. A rapid respiratory rate is defined as greater than 60 breaths per minute in children under 2 months old, greater than 50 breaths per minute in children 2 months to 1 year old, or greater than 40 breaths per minute in children 1 to 5 years old.In children, low oxygen levels and lower chest indrawing are more sensitive than hearing chest crackles with a stethoscope or increased respiratory rate. Grunting and nasal flaring may be other useful signs in children less than five years old.Lack of wheezing is an indicator of Mycoplasma pneumoniae in children with pneumonia, but as an indicator it is not accurate enough to decide whether or not macrolide treatment should be used. The presence of chest pain in children with pneumonia doubles the probability of Mycoplasma pneumoniae.  Diagnosis in adults  In general, in adults, investigations are not needed in mild cases. There is a very low risk of pneumonia if all vital signs and auscultation are normal. C-reactive protein (CRP) may help support the diagnosis. For those with CRP less than 20 mg/L without convincing evidence of pneumonia, antibiotics are not recommended.Procalcitonin may help determine the cause and support decisions about who should receive antibiotics. Antibiotics are encouraged if the procalcitonin level reaches 0.25 μg/L, strongly encouraged if it reaches 0.5 μg/L, and strongly discouraged if the level is below 0.10 μg/L. In people requiring hospitalization, pulse oximetry, chest radiography and blood tests – including a complete blood count, serum electrolytes, C-reactive protein level, and possibly liver function tests – are recommended.The diagnosis of influenza-like illness can be made based on the signs and symptoms; however, confirmation of an influenza infection requires testing. Thus, treatment is frequently based on the presence of influenza in the community or a rapid influenza test.Adults 65 years old or older, as well as cigarette smokers and people with ongoing medical conditions are at increased risk for pneumonia.  Physical exam  Physical examination may sometimes reveal low blood pressure, high heart rate, or low oxygen saturation. The respiratory rate may be faster than normal, and this may occur a day or two before other signs. Examination of the chest may be normal, but it may show decreased expansion on the affected side. Harsh breath sounds from the larger airways that are transmitted through the inflamed lung are termed bronchial breathing and are heard on auscultation with a stethoscope. Crackles (rales) may be heard over the affected area during inspiration. Percussion may be dulled over the affected lung, and increased, rather than decreased, vocal resonance distinguishes pneumonia from a pleural effusion.  Imaging  A chest radiograph is frequently used in diagnosis. In people with mild disease, imaging is needed only in those with potential complications, those not having improved with treatment, or those in which the cause is uncertain. If a person is sufficiently sick to require hospitalization, a chest radiograph is recommended. Findings do not always match the severity of disease and do not reliably separate between bacterial and viral infection.X-ray presentations of pneumonia may be classified as lobar pneumonia, bronchopneumonia, lobular pneumonia, and interstitial pneumonia. Bacterial, community-acquired pneumonia classically show lung consolidation of one lung segmental lobe, which is known as lobar pneumonia. However, findings may vary, and other patterns are common in other types of pneumonia. Aspiration pneumonia may present with bilateral opacities primarily in the bases of the lungs and on the right side. Radiographs of viral pneumonia may appear normal, appear hyper-inflated, have bilateral patchy areas, or present similar to bacterial pneumonia with lobar consolidation. Radiologic findings may not be present in the early stages of the disease, especially in the presence of dehydration, or may be difficult to interpret in the obese or those with a history of lung disease. Complications such as pleural effusion may also be found on chest radiographs. Laterolateral chest radiographs can increase the diagnostic accuracy of lung consolidation and pleural effusion.A CT scan can give additional information in indeterminate cases and provide more details in those with an unclear chest radiograph (for example occult pneumonia in chronic obstructive pulmonary disease). They can be used to exclude pulmonary embolism and fungal pneumonia, and detect lung abscesses in those who are not responding to treatments. However, CT scans are more expensive, have a higher dose of radiation, and cannot be done at bedside.Lung ultrasound may also be useful in helping to make the diagnosis. Ultrasound is radiation free and can be done at bedside. However, ultrasound requires specific skills to operate the machine and interpret the findings. It may be more accurate than chest X-ray.  Microbiology  In people managed in the community, determining the causative agent is not cost-effective and typically does not alter management. For people who do not respond to treatment, sputum culture should be considered, and culture for Mycobacterium tuberculosis should be carried out in persons with a chronic productive cough. Microbiological evaluation is also indicated in severe pneumonia, alcoholism, asplenia, immunosuppression, HIV infection, and those being empirically treated for MRSA of pseudomonas. Although positive blood culture and pleural fluid culture definitively establish the diagnosis of the type of micro-organism involved, a positive sputum culture has to be interpreted with care for the possibility of colonisation of respiratory tract. Testing for other specific organisms may be recommended during outbreaks, for public health reasons. In those hospitalized for severe disease, both sputum and blood cultures are recommended, as well as testing the urine for antigens to Legionella and Streptococcus. Viral infections, can be confirmed via detection of either the virus or its antigens with culture or polymerase chain reaction (PCR), among other techniques. Mycoplasma, Legionella, Streptococcus, and Chlamydia can also be detected using PCR techniques on bronchoalveolar lavage and nasopharyngeal swab. The causative agent is determined in only 15% of cases with routine microbiological tests.  Classification  Pneumonitis refers to lung inflammation; pneumonia refers to pneumonitis, usually due to infection but sometimes non-infectious, that has the additional feature of pulmonary consolidation. Pneumonia is most commonly classified by where or how it was acquired: community-acquired, aspiration, healthcare-associated, hospital-acquired, and ventilator-associated pneumonia. It may also be classified by the area of the lung affected: lobar, bronchial pneumonia and acute interstitial pneumonia; or by the causative organism. Pneumonia in children may additionally be classified based on signs and symptoms as non-severe, severe, or very severe.The setting in which pneumonia develops is important to treatment, as it correlates to which pathogens are likely suspects, which mechanisms are likely, which antibiotics are likely to work or fail, and which complications can be expected based on the person's health status.  Community  Community-acquired pneumonia (CAP) is acquired in the community, outside of health care facilities. Compared with healthcare-associated pneumonia, it is less likely to involve multidrug-resistant bacteria. Although the latter are no longer rare in CAP, they are still less likely. Prior stays in healthcare-related environments such as hospitals, nursing homes, or hemodialysis centers or a history of receiving domiciliary care can increase patients’ risk for CAP caused by multidrug-resistant bacteria.  Healthcare  Health care–associated pneumonia (HCAP) is an infection associated with recent exposure to the health care system, including hospitals, outpatient clinics, nursing homes, dialysis centers, chemotherapy treatment, or home care. HCAP is sometimes called MCAP (medical care–associated pneumonia). People may become infected with pneumonia in a hospital; this is defined as pneumonia not present at the time of admission (symptoms must start at least 48 hours after admission). It is likely to involve hospital-acquired infections, with higher risk of multidrug-resistant pathogens. People in a hospital often have other medical conditions, which may make them more susceptible to pathogens in the hospital. Ventilator-associated pneumonia occurs in people breathing with the help of mechanical ventilation. Ventilator-associated pneumonia is specifically defined as pneumonia that arises more than 48 to 72 hours after endotracheal intubation.  Differential diagnosis  Several diseases can present with similar signs and symptoms to pneumonia, such as: chronic obstructive pulmonary disease, asthma, pulmonary edema, bronchiectasis, lung cancer, and pulmonary emboli. Unlike pneumonia, asthma and COPD typically present with wheezing, pulmonary edema presents with an abnormal electrocardiogram, cancer and bronchiectasis present with a cough of longer duration, and pulmonary emboli present with acute onset sharp chest pain and shortness of breath. Mild pneumonia should be differentiated from upper respiratory tract infection (URTI). Severe pneumonia should be differentiated from acute heart failure. Pulmonary infiltrates that resolved after giving mechanical ventilation should point to heart failure and atelectasis rather than pneumonia. For recurrent pneumonia, underlying lung cancer, metastasis, tuberculosis, a foreign bodies, immunosuppression, and hypersensitivity should be suspected.  Prevention  Prevention includes vaccination, environmental measures, and appropriate treatment of other health problems. It is believed that, if appropriate preventive measures were instituted globally, mortality among children could be reduced by 400,000; and, if proper treatment were universally available, childhood deaths could be decreased by another 600,000.  Vaccination  Vaccination prevents against certain bacterial and viral pneumonias both in children and adults. Influenza vaccines are modestly effective at preventing symptoms of influenza, The Centers for Disease Control and Prevention (CDC) recommends yearly influenza vaccination for every person 6 months and older. Immunizing health care workers decreases the risk of viral pneumonia among their patients.Vaccinations against Haemophilus influenzae and Streptococcus pneumoniae have good evidence to support their use. There is strong evidence for vaccinating children under the age of 2 against Streptococcus pneumoniae (pneumococcal conjugate vaccine). Vaccinating children against Streptococcus pneumoniae has led to a decreased rate of these infections in adults, because many adults acquire infections from children. A Streptococcus pneumoniae vaccine is available for adults, and has been found to decrease the risk of invasive pneumococcal disease by 74%, but there is insufficient evidence to suggest using the pneumococcal vaccine to prevent pneumonia or death in the general adult population. The CDC recommends that young children and adults over the age of 65 receive the pneumococcal vaccine, as well as older children or younger adults who have an increased risk of getting pneumococcal disease. The pneumococcal vaccine has been shown to reduce the risk of community acquired pneumonia in people with chronic obstructive pulmonary disease, but does not reduce mortality or the risk of hospitalization for people with this condition. People with COPD are recommended by a number of guidelines to have a pneumococcal vaccination. Other vaccines for which there is support for a protective effect against pneumonia include pertussis, varicella, and measles.  Medications  When influenza outbreaks occur, medications such as amantadine or rimantadine may help prevent the condition, but they are associated with side effects. Zanamivir or oseltamivir decrease the chance that people who are exposed to the virus will develop symptoms; however, it is recommended that potential side effects are taken into account.  Other  Smoking cessation and reducing indoor air pollution, such as that from cooking indoors with wood, crop residues or dung, are both recommended. Smoking appears to be the single biggest risk factor for pneumococcal pneumonia in otherwise-healthy adults. Hand hygiene and coughing into one's sleeve may also be effective preventative measures. Wearing surgical masks by the sick may also prevent illness.Appropriately treating underlying illnesses (such as HIV/AIDS, diabetes mellitus, and malnutrition) can decrease the risk of pneumonia. In children less than 6 months of age, exclusive breast feeding reduces both the risk and severity of disease. In people with HIV/AIDS and a CD4 count of less than 200 cells/uL the antibiotic trimethoprim/sulfamethoxazole decreases the risk of Pneumocystis pneumonia and is also useful for prevention in those that are immunocompromised but do not have HIV.Testing pregnant women for Group B Streptococcus and Chlamydia trachomatis, and administering antibiotic treatment, if needed, reduces rates of pneumonia in infants; preventive measures for HIV transmission from mother to child may also be efficient. Suctioning the mouth and throat of infants with meconium-stained amniotic fluid has not been found to reduce the rate of aspiration pneumonia and may cause potential harm, thus this practice is not recommended in the majority of situations. In the frail elderly good oral health care may lower the risk of aspiration pneumonia, even though there is no good evidence that one approach to mouth care is better than others in preventing nursing home acquired pneumonia. Zinc supplementation in children 2 months to five years old appears to reduce rates of pneumonia.For people with low levels of vitamin C in their diet or blood, taking vitamin C supplements may be suggested to decrease the risk of pneumonia, although there is no strong evidence of benefit. There is insufficient evidence to recommend that the general population take vitamin C to prevent or treat pneumonia.For adults and children in the hospital who require a respirator, there is no strong evidence indicating a difference between heat and moisture exchangers and heated humidifiers for preventing pneumonia. There is tentative evidence that laying flat on the back compared to semi-raised increases pneumonia risks in people who are intubated.  Management  Antibiotics by mouth, rest, simple analgesics, and fluids usually suffice for complete resolution. However, those with other medical conditions, the elderly, or those with significant trouble breathing may require more advanced care. If the symptoms worsen, the pneumonia does not improve with home treatment, or complications occur, hospitalization may be required. Worldwide, approximately 7–13% of cases in children result in hospitalization, whereas in the developed world between 22 and 42% of adults with community-acquired pneumonia are admitted. The CURB-65 score is useful for determining the need for admission in adults. If the score is 0 or 1, people can typically be managed at home; if it is 2, a short hospital stay or close follow-up is needed; if it is 3–5, hospitalization is recommended. In children those with respiratory distress or oxygen saturations of less than 90% should be hospitalized. The utility of chest physiotherapy in pneumonia has not yet been determined. Over-the-counter cough medicine has not been found to be effective, nor has the use of zinc supplementation in children. There is insufficient evidence for mucolytics. There is no strong evidence to recommend that children who have non-measles related pneumonia take vitamin A supplements. Vitamin D, as of 2018 is of unclear benefit in children. Vitamin C administration in pneumonia needs further research, although it can be given to patient of low plasma vitamin C because it is not expensive and low risk.Pneumonia can cause severe illness in a number of ways, and pneumonia with evidence of organ dysfunction may require intensive care unit admission for observation and specific treatment. The main impact is on the respiratory and the circulatory system. Respiratory failure not responding to normal oxygen therapy may require heated humidified high-flow therapy delivered through nasal cannulae, non-invasive ventilation, or in severe cases mechanical ventilation through an endotracheal tube. Regarding circulatory problems as part of sepsis, evidence of poor blood flow or low blood pressure is initially treated with 30 mL/kg of crystalloid infused intravenously. In situations where fluids alone are ineffective, vasopressor medication may be required.For adults with moderate or severe acute respiratory distress syndrome (ARDS) undergoing mechanical ventilation, there is a reduction in mortality when people lie on their front for at least 12 hours a day. However, this increases the risk of endotracheal tube obstruction and pressure sores.  Bacterial  Antibiotics improve outcomes in those with bacterial pneumonia. The first dose of antibiotics should be given as soon as possible. Increased use of antibiotics, however, may lead to the development of antimicrobial resistant strains of bacteria. Antibiotic choice depends initially on the characteristics of the person affected, such as age, underlying health, and the location the infection was acquired. Antibiotic use is also associated with side effects such as nausea, diarrhea, dizziness, taste distortion, or headaches. In the UK, treatment before culture results with amoxicillin is recommended as the first line for community-acquired pneumonia, with doxycycline or clarithromycin as alternatives. In North America, amoxicillin, doxycycline, and in some areas a macrolide (such as azithromycin or erythromycin) is the first-line outpatient treatment in adults. In children with mild or moderate symptoms, amoxicillin taken by mouth is the first line. The use of fluoroquinolones in uncomplicated cases is discouraged due to concerns about side-effects and generating resistance in light of there being no greater benefit.For those who require hospitalization and caught their pneumonia in the community the use of a β-lactam such as cephazolin plus a macrolide such as azithromycin is recommended. A fluoroquinolone may replace azithromycin but is less preferred. Antibiotics by mouth and by injection appear to be similarly effective in children with severe pneumonia.The duration of treatment has traditionally been seven to ten days, but increasing evidence suggests that shorter courses (3–5 days) may be effective for certain types of pneumonia and may reduce the risk of antibiotic resistance. Research in children showed that a shorter, 3-day course of amoxicillin was as effective as a longer, 7-day course for treating pneumonia in this population. For pneumonia that is associated with a ventilator caused by non-fermenting Gram-negative bacilli (NF-GNB), a shorter course of antibiotics increases the risk that the pneumonia will return. Recommendations for hospital-acquired pneumonia include third- and fourth-generation cephalosporins, carbapenems, fluoroquinolones, aminoglycosides, and vancomycin. These antibiotics are often given intravenously and used in combination. In those treated in hospital, more than 90% improve with the initial antibiotics. For people with ventilator-acquired pneumonia, the choice of antibiotic therapy will depend on the person's risk of being infected with a strain of bacteria that is multi-drug resistant. Once clinically stable, intravenous antibiotics should be switched to oral antibiotics. For those with Methicillin resistant Staphylococcus aureus (MRSA) or Legionella infections, prolonged antibiotics may be beneficial.The addition of corticosteroids to standard antibiotic treatment appears to improve outcomes, reducing death and morbidity for adults with severe community acquired pneumonia, and reducing death for adults and children with non-severe community acquired pneumonia. A 2017 review therefore recommended them in adults with severe community acquired pneumonia. A 2019 guideline however recommended against their general use, unless refractory shock was present. Side effects associated with the use of corticosteroids include high blood sugar. There is some evidence that adding corticosteroids to the standard PCP pneumonia treatment may be beneficial for people who are infected with HIV.The use of granulocyte colony stimulating factor (G-CSF) along with antibiotics does not appear to reduce mortality and routine use for treating pneumonia is not supported by evidence.  Viral  Neuraminidase inhibitors may be used to treat viral pneumonia caused by influenza viruses (influenza A and influenza B). No specific antiviral medications are recommended for other types of community acquired viral pneumonias including SARS coronavirus, adenovirus, hantavirus, and parainfluenza virus. Influenza A may be treated with rimantadine or amantadine, while influenza A or B may be treated with oseltamivir, zanamivir or peramivir. These are of most benefit if they are started within 48 hours of the onset of symptoms. Many strains of H5N1 influenza A, also known as avian influenza or ""bird flu"", have shown resistance to rimantadine and amantadine. The use of antibiotics in viral pneumonia is recommended by some experts, as it is impossible to rule out a complicating bacterial infection. The British Thoracic Society recommends that antibiotics be withheld in those with mild disease. The use of corticosteroids is controversial.  Aspiration  In general, aspiration pneumonitis is treated conservatively with antibiotics indicated only for aspiration pneumonia. The choice of antibiotic will depend on several factors, including the suspected causative organism and whether pneumonia was acquired in the community or developed in a hospital setting. Common options include clindamycin, a combination of a beta-lactam antibiotic and metronidazole, or an aminoglycoside. Corticosteroids are sometimes used in aspiration pneumonia, but there is limited evidence to support their effectiveness.  Follow-up  The British Thoracic Society recommends that a follow-up chest radiograph be taken in people with persistent symptoms, smokers, and people older than 50. American guidelines vary, from generally recommending a follow-up chest radiograph to not mentioning any follow-up.  Prognosis  With treatment, most types of bacterial pneumonia will stabilize in 3–6 days. It often takes a few weeks before most symptoms resolve. X-ray findings typically clear within four weeks and mortality is low (less than 1%). In the elderly or people with other lung problems, recovery may take more than 12 weeks. In persons requiring hospitalization, mortality may be as high as 10%, and in those requiring intensive care it may reach 30–50%. Pneumonia is the most common hospital-acquired infection that causes death. Before the advent of antibiotics, mortality was typically 30% in those that were hospitalized. However, for those whose lung condition deteriorates within 72 hours, the problem is usually due to sepsis. If pneumonia deteriorates after 72 hours, it could be due to nosocomial infection or excerbation of other underlying comorbidities. About 10% of those discharged from hospital are readmitted due to underlying co-morbidities such as heart, lung, or neurological disorders, or due to new onset of pneumonia.Complications may occur in particular in the elderly and those with underlying health problems. This may include, among others: empyema, lung abscess, bronchiolitis obliterans, acute respiratory distress syndrome, sepsis, and worsening of underlying health problems.  Clinical prediction rules  Clinical prediction rules have been developed to more objectively predict outcomes of pneumonia. These rules are often used to decide whether to hospitalize the person. CURB-65 score, which takes into account the severity of symptoms, any underlying diseases, and age Pneumonia severity index (or PSI Score)  Pleural effusion, empyema, and abscess  In pneumonia, a collection of fluid may form in the space that surrounds the lung. Occasionally, microorganisms will infect this fluid, causing an empyema. To distinguish an empyema from the more common simple parapneumonic effusion, the fluid may be collected with a needle (thoracentesis), and examined. If this shows evidence of empyema, complete drainage of the fluid is necessary, often requiring a drainage catheter. In severe cases of empyema, surgery may be needed. If the infected fluid is not drained, the infection may persist, because antibiotics do not penetrate well into the pleural cavity. If the fluid is sterile, it must be drained only if it is causing symptoms or remains unresolved.In rare circumstances, bacteria in the lung will form a pocket of infected fluid called a lung abscess. Lung abscesses can usually be seen with a chest X-ray but frequently require a chest CT scan to confirm the diagnosis. Abscesses typically occur in aspiration pneumonia, and often contain several types of bacteria. Long-term antibiotics are usually adequate to treat a lung abscess, but sometimes the abscess must be drained by a surgeon or radiologist.  Respiratory and circulatory failure  Pneumonia can cause respiratory failure by triggering acute respiratory distress syndrome (ARDS), which results from a combination of infection and inflammatory response. The lungs quickly fill with fluid and become stiff. This stiffness, combined with severe difficulties extracting oxygen due to the alveolar fluid, may require long periods of mechanical ventilation for survival. Other causes of circulatory failure are hypoxemia, inflammation, and increased coagulability.Sepsis is a potential complication of pneumonia but usually occurs in people with poor immunity or hyposplenism. The organisms most commonly involved are Streptococcus pneumoniae, Haemophilus influenzae, and Klebsiella pneumoniae. Other causes of the symptoms should be considered such as a myocardial infarction or a pulmonary embolism.  Epidemiology  Pneumonia is a common illness affecting approximately 450 million people a year and occurring in all parts of the world. It is a major cause of death among all age groups resulting in 4 million deaths (7% of the world's total death) yearly. Rates are greatest in children less than five, and adults older than 75 years. It occurs about five times more frequently in the developing world than in the developed world. Viral pneumonia accounts for about 200 million cases. In the United States, as of 2009, pneumonia is the 8th leading cause of death.  Children  In 2008, pneumonia occurred in approximately 156 million children (151 million in the developing world and 5 million in the developed world). In 2010, it resulted in 1.3 million deaths, or 18% of all deaths in those under five years, of which 95% occurred in the developing world. Countries with the greatest burden of disease include India (43 million), China (21 million) and Pakistan (10 million). It is the leading cause of death among children in low income countries. Many of these deaths occur in the newborn period. The World Health Organization estimates that one in three newborn infant deaths is due to pneumonia. Approximately half of these deaths can be prevented, as they are caused by the bacteria for which an effective vaccine is available. The IDSA has recommended that children and infants with symptoms of CAP should be hospitalized so they have access to pediatric nursing care. In 2011, pneumonia was the most common reason for admission to the hospital after an emergency department visit in the U.S. for infants and children.  History  Pneumonia has been a common disease throughout human history. The word is from Greek πνεύμων (pneúmōn) meaning ""lung"". The symptoms were described by Hippocrates (c. 460–370 BC): ""Peripneumonia, and pleuritic affections, are to be thus observed: If the fever be acute, and if there be pains on either side, or in both, and if expiration be if cough be present, and the sputa expectorated be of a blond or livid color, or likewise thin, frothy, and florid, or having any other character different from the common... When pneumonia is at its height, the case is beyond remedy if he is not purged, and it is bad if he has dyspnoea, and urine that is thin and acrid, and if sweats come out about the neck and head, for such sweats are bad, as proceeding from the suffocation, rales, and the violence of the disease which is obtaining the upper hand."" However, Hippocrates referred to pneumonia as a disease ""named by the ancients"". He also reported the results of surgical drainage of empyemas. Maimonides (1135–1204 AD) observed: ""The basic symptoms that occur in pneumonia and that are never lacking are as follows: acute fever, sticking pleuritic pain in the side, short rapid breaths, serrated pulse and cough."" This clinical description is quite similar to those found in modern textbooks, and it reflected the extent of medical knowledge through the Middle Ages into the 19th century. Edwin Klebs was the first to observe bacteria in the airways of persons having died of pneumonia in 1875. Initial work identifying the two common bacterial causes, Streptococcus pneumoniae and Klebsiella pneumoniae, was performed by Carl Friedländer and Albert Fraenkel in 1882 and 1884, respectively. Friedländer's initial work introduced the Gram stain, a fundamental laboratory test still used today to identify and categorize bacteria. Christian Gram's paper describing the procedure in 1884 helped to differentiate the two bacteria, and showed that pneumonia could be caused by more than one microorganism. In 1887, Jaccond demonstrated pneumonia may be caused by opportunistic bacteria always present in the lung.Sir William Osler, known as ""the father of modern medicine"", appreciated the death and disability caused by pneumonia, describing it as the ""captain of the men of death"" in 1918, as it had overtaken tuberculosis as one of the leading causes of death at the time. This phrase was originally coined by John Bunyan in reference to ""consumption"" (tuberculosis). Osler also described pneumonia as ""the old man's friend"" as death was often quick and painless when there were much slower and more painful ways to die.Viral pneumonia was first described by Hobart Reimann in 1938. Reimann, Chairman of the Department of Medicine at Jefferson Medical College, had established the practice of routinely typing the pneumococcal organism in cases where pneumonia presented. Out of this work, the distinction between viral and bacterial strains was noticed.Several developments in the 1900s improved the outcome for those with pneumonia. With the advent of penicillin and other antibiotics, modern surgical techniques, and intensive care in the 20th century, mortality from pneumonia, which had approached 30%, dropped precipitously in the developed world. Vaccination of infants against Haemophilus influenzae type B began in 1988 and led to a dramatic decline in cases shortly thereafter. Vaccination against Streptococcus pneumoniae in adults began in 1977, and in children in 2000, resulting in a similar decline.  Society and culture   Awareness  Due to the relatively low awareness of the disease, 12 November was declared as the annual World Pneumonia Day, a day for concerned citizens and policy makers to take action against the disease, in 2009.  Costs  The global economic cost of community-acquired pneumonia has been estimated at $17 billion annually. Other estimates are considerably higher. In 2012 the estimated aggregate costs of treating pneumonia in the United States were $20 billion; the median cost of a single pneumonia-related hospitalization is over $15,000. According to data released by the Centers for Medicare and Medicaid Services, average 2012 hospital charges for inpatient treatment of uncomplicated pneumonia in the U.S. were $24,549 and ranged as high as $124,000. The average cost of an emergency room consult for pneumonia was $943 and the average cost for medication was $66. Aggregate annual costs of treating pneumonia in Europe have been estimated at €10 billion.  References  Footnotes Citations  Bibliography   External links ","Pneumonia is a disease of the lungs and the respiratory system. The lung contains many small bulbs, or sacs, called alveoli. These help to take out oxygen from the air. In the case of pneumonia, these bulbs become inflamed. They fill up with a fluid which is called pus, and can no longer absorb as much oxygen as before. This makes it hard for the person with pneumonia to breathe. They may feel out of breath, or like they are drowning. They may also feel pain when they breathe. Sometimes people die of pneumonia, even when they go to a hospital and take medicine.  Background  Pneumonia can be caused by bacteria, viruses, fungi or parasites. It can also be caused by chemical or physical damage done to the lungs. Other illnesses, like alcohol abuse or lung cancer, can also result in pneumonia. People with pneumonia usually have difficulty breathing. They may also cough, or have pains in the chest area. The treatment of pneumonia depends on how the illness was caused. If it was caused by bacteria, antibiotics can be used to treat it. People of all ages can have pneumonia. The disease is dangerous. Many people die from pneumonia, especially old people, or people with a weak immune system. According to some research in 2010, in some parts of the world where people are very poor like India, Nigeria, and Pakistan, pneumonia was the cause of death for more children under the age of five than any other disease. Statistically, however, for every 2,000 children in the developing world who die of pneumonia, only one child in the developed world dies from the disease. This is because of differences in health care and because of differences in rates of breastfeeding, not because of differences in children. Breastfeeding newborn babies greatly increases their ability to survive pneumonia, but some cultures think of breastfeeding as taboo.  Other types of pneumonia  Severe acute respiratory syndrome (SARS) SARS is a highly contagious and deadly type of pneumonia which first occurred in 2002 after initial outbreaks in China. SARS is caused by the SARS coronavirus, a pathogen (disease-causing organism) that was not known until then. New cases of SARS have not been seen since June 2003. Bronchiolitis obliterans organizing pneumonia (BOOP) BOOP is caused by inflammation (swelling or irritation) of the small airways of the lungs. It is also known as cryptogenic organizing pneumonitis (COP). Eosinophilic pneumonia Eosinophilic pneumonia is invasion of the lung by eosinophils. Eosinophils are a particular kind of white blood cells. Eosinophilic pneumonia often occurs in response to infection with a parasite or after exposure to certain types of environmental factors. Chemical pneumonia Chemical pneumonia (usually called chemical pneumonitis) is caused by chemical toxins such as pesticides, which may enter the body by inhalation (breathing in) or by skin contact. When the toxic (poisonous or harmful) substance is an oil, the pneumonia may be called lipoid pneumonia. Aspiration pneumonia Aspiration pneumonia (or aspiration pneumonitis) is caused by accidentally inhaling oral (mouth) or gastric (stomach) contents into the lungs, either while eating, or after reflux or vomiting, and causing damage to the lungs. The lung inflammation from these materials is not an infection but it can eventually cause one, since the material taken into the lungs may contain bacteria. Aspiration is a common cause of death among hospital and nursing home patients, since they sometimes cannot cough hard enough to protect their airways.  References   Other websites  Merck Manual: Pneumonia Merck Manual of Geriatrics: Pneumonia in the elderly British Lung Foundation Archived 2007-10-08 at the Wayback Machine"
"Asthma is a long-term inflammatory disease of the airways of the lungs. It is characterized by variable and recurring symptoms, reversible airflow obstruction, and easily triggered bronchospasms. Symptoms include episodes of wheezing, coughing, chest tightness, and shortness of breath. These may occur a few times a day or a few times per week. Depending on the person, asthma symptoms may become worse at night or with exercise.Asthma is thought to be caused by a combination of genetic and environmental factors. Environmental factors include exposure to air pollution and allergens. Other potential triggers include medications such as aspirin and beta blockers. Diagnosis is usually based on the pattern of symptoms, response to therapy over time, and spirometry lung function testing. Asthma is classified according to the frequency of symptoms, forced expiratory volume in one second (FEV1), and peak expiratory flow rate. It may also be classified as atopic or non-atopic, where atopy refers to a predisposition toward developing a type 1 hypersensitivity reaction.There is no known cure for asthma, but it can be controlled. Symptoms can be prevented by avoiding triggers, such as allergens and respiratory irritants, and suppressed with the use of inhaled corticosteroids. Long-acting beta agonists (LABA) or antileukotriene agents may be used in addition to inhaled corticosteroids if asthma symptoms remain uncontrolled. Treatment of rapidly worsening symptoms is usually with an inhaled short-acting beta-2 agonist such as salbutamol and corticosteroids taken by mouth. In very severe cases, intravenous corticosteroids, magnesium sulfate, and hospitalization may be required.In 2019 asthma affected approximately 262 million people and caused approximately 461,000 deaths. Most of the deaths occurred in the developing world. Asthma often begins in childhood, and the rates have increased significantly since the 1960s. Asthma was recognized as early as Ancient Egypt. The word ""asthma"" is from the Greek ἆσθμα, âsthma, which means ""panting"".  Signs and symptoms  Asthma is characterized by recurrent episodes of wheezing, shortness of breath, chest tightness, and coughing. Sputum may be produced from the lung by coughing but is often hard to bring up. During recovery from an asthma attack (exacerbation), it may appear pus-like due to high levels of white blood cells called eosinophils. Symptoms are usually worse at night and in the early morning or in response to exercise or cold air. Some people with asthma rarely experience symptoms, usually in response to triggers, whereas others may react frequently and readily and experience persistent symptoms.  Associated conditions  A number of other health conditions occur more frequently in people with asthma, including gastroesophageal reflux disease (GERD), rhinosinusitis, and obstructive sleep apnea. Psychological disorders are also more common, with anxiety disorders occurring in between 16 and 52% and mood disorders in 14–41%. It is not known whether asthma causes psychological problems or psychological problems lead to asthma. Current asthma, but not former asthma, is associated with increased all-cause mortality, heart disease mortality, and chronic lower respiratory tract disease mortality. Asthma, particularly severe asthma, is strongly associated with development of chronic obstructive pulmonary disease (COPD). Those with asthma, especially if it is poorly controlled, are at increased risk for radiocontrast reactions.Cavities occur more often in people with asthma. This may be related to the effect of beta 2 agonists decreasing saliva. These medications may also increase the risk of dental erosions.  Causes  Asthma is caused by a combination of complex and incompletely understood environmental and genetic interactions. These influence both its severity and its responsiveness to treatment. It is believed that the recent increased rates of asthma are due to changing epigenetics (heritable factors other than those related to the DNA sequence) and a changing living environment. Asthma that starts before the age of 12 years old is more likely due to genetic influence, while onset after age 12 is more likely due to environmental influence.  Environmental  Many environmental factors have been associated with asthma\'s development and exacerbation, including, allergens, air pollution, and other environmental chemicals. There are some substances that are known to cause asthma in exposed people and they are called asthmagens. Some common asthmagens include ammonia, latex, pesticides, solder and welding fumes, metal or wood dusts, spraying of isocyanate paint in vehicle repair, formaldehyde, glutaraldehyde, anhydrides, glues, dyes, metal working fluids, oil mists, molds. Smoking during pregnancy and after delivery is associated with a greater risk of asthma-like symptoms. Low air quality from environmental factors such as traffic pollution or high ozone levels has been associated with both asthma development and increased asthma severity. Over half of cases in children in the United States occur in areas when air quality is below the EPA standards. Low air quality is more common in low-income and minority communities.Exposure to indoor volatile organic compounds may be a trigger for asthma; formaldehyde exposure, for example, has a positive association. Phthalates in certain types of PVC are associated with asthma in both children and adults. While exposure to pesticides is linked to the development of asthma, a cause and effect relationship has yet to be established. A meta-analysis concluded gas stoves are a major risk factor for asthma, finding around one in eight cases in the U.S. could be attributed to these.The majority of the evidence does not support a causal role between paracetamol (acetaminophen) or antibiotic use and asthma. A 2014 systematic review found that the association between paracetamol use and asthma disappeared when respiratory infections were taken into account. Maternal psychological stress during pregnancy is a risk factor for the child to develop asthma.Asthma is associated with exposure to indoor allergens. Common indoor allergens include dust mites, cockroaches, animal dander (fragments of fur or feathers), and mold. Efforts to decrease dust mites have been found to be ineffective on symptoms in sensitized subjects. Weak evidence suggests that efforts to decrease mold by repairing buildings may help improve asthma symptoms in adults. Certain viral respiratory infections, such as respiratory syncytial virus and rhinovirus, may increase the risk of developing asthma when acquired as young children. Certain other infections, however, may decrease the risk.  Hygiene hypothesis  The hygiene hypothesis attempts to explain the increased rates of asthma worldwide as a direct and unintended result of reduced exposure, during childhood, to non-pathogenic bacteria and viruses. It has been proposed that the reduced exposure to bacteria and viruses is due, in part, to increased cleanliness and decreased family size in modern societies. Exposure to bacterial endotoxin in early childhood may prevent the development of asthma, but exposure at an older age may provoke bronchoconstriction. Evidence supporting the hygiene hypothesis includes lower rates of asthma on farms and in households with pets.Use of antibiotics in early life has been linked to the development of asthma. Also, delivery via caesarean section is associated with an increased risk (estimated at 20–80%) of asthma – this increased risk is attributed to the lack of healthy bacterial colonization that the newborn would have acquired from passage through the birth canal. There is a link between asthma and the degree of affluence which may be related to the hygiene hypothesis as less affluent individuals often have more exposure to bacteria and viruses.  Genetic  Family history is a risk factor for asthma, with many different genes being implicated. If one identical twin is affected, the probability of the other having the disease is approximately 25%. By the end of 2005, 25 genes had been associated with asthma in six or more separate populations, including GSTM1, IL10, CTLA-4, SPINK5, LTC4S, IL4R and ADAM33, among others. Many of these genes are related to the immune system or modulating inflammation. Even among this list of genes supported by highly replicated studies, results have not been consistent among all populations tested. In 2006 over 100 genes were associated with asthma in one genetic association study alone; more continue to be found.Some genetic variants may only cause asthma when they are combined with specific environmental exposures. An example is a specific single nucleotide polymorphism in the CD14 region and exposure to endotoxin (a bacterial product). Endotoxin exposure can come from several environmental sources including tobacco smoke, dogs, and farms. Risk for asthma, then, is determined by both a person\'s genetics and the level of endotoxin exposure.  Medical conditions  A triad of atopic eczema, allergic rhinitis and asthma is called atopy. The strongest risk factor for developing asthma is a history of atopic disease; with asthma occurring at a much greater rate in those who have either eczema or hay fever. Asthma has been associated with eosinophilic granulomatosis with polyangiitis (formerly known as Churg–Strauss syndrome), an autoimmune disease and vasculitis. Individuals with certain types of urticaria may also experience symptoms of asthma.There is a correlation between obesity and the risk of asthma with both having increased in recent years. Several factors may be at play including decreased respiratory function due to a buildup of fat and the fact that adipose tissue leads to a pro-inflammatory state.Beta blocker medications such as propranolol can trigger asthma in those who are susceptible. Cardioselective beta-blockers, however, appear safe in those with mild or moderate disease. Other medications that can cause problems in asthmatics are angiotensin-converting enzyme inhibitors, aspirin, and NSAIDs. Use of acid suppressing medication (proton pump inhibitors and H2 blockers) during pregnancy is associated with an increased risk of asthma in the child.  Exacerbation  Some individuals will have stable asthma for weeks or months and then suddenly develop an episode of acute asthma. Different individuals react to various factors in different ways. Most individuals can develop severe exacerbation from a number of triggering agents.Home factors that can lead to exacerbation of asthma include dust, animal dander (especially cat and dog hair), cockroach allergens and mold. Perfumes are a common cause of acute attacks in women and children. Both viral and bacterial infections of the upper respiratory tract can worsen the disease. Psychological stress may worsen symptoms – it is thought that stress alters the immune system and thus increases the airway inflammatory response to allergens and irritants.Asthma exacerbations in school‐aged children peak in autumn, shortly after children return to school. This might reflect a combination of factors, including poor treatment adherence, increased allergen and viral exposure, and altered immune tolerance. There is limited evidence to guide possible approaches to reducing autumn exacerbations, but while costly, seasonal omalizumab treatment from four to six weeks before school return may reduce autumn asthma exacerbations.  Pathophysiology  Asthma is the result of chronic inflammation of the conducting zone of the airways (most especially the bronchi and bronchioles), which subsequently results in increased contractability of the surrounding smooth muscles. This among other factors leads to bouts of narrowing of the airway and the classic symptoms of wheezing. The narrowing is typically reversible with or without treatment. Occasionally the airways themselves change. Typical changes in the airways include an increase in eosinophils and thickening of the lamina reticularis. Chronically the airways\' smooth muscle may increase in size along with an increase in the numbers of mucous glands. Other cell types involved include T lymphocytes, macrophages, and neutrophils. There may also be involvement of other components of the immune system, including cytokines, chemokines, histamine, and leukotrienes among others.  Diagnosis  While asthma is a well-recognized condition, there is not one universal agreed upon definition. It is defined by the Global Initiative for Asthma as ""a chronic inflammatory disorder of the airways in which many cells and cellular elements play a role. The chronic inflammation is associated with airway hyper-responsiveness that leads to recurrent episodes of wheezing, breathlessness, chest tightness and coughing particularly at night or in the early morning. These episodes are usually associated with widespread but variable airflow obstruction within the lung that is often reversible either spontaneously or with treatment"".There is currently no precise test for the diagnosis, which is typically based on the pattern of symptoms and response to therapy over time. Asthma may be suspected if there is a history of recurrent wheezing, coughing or difficulty breathing and these symptoms occur or worsen due to exercise, viral infections, allergens or air pollution. Spirometry is then used to confirm the diagnosis. In children under the age of six the diagnosis is more difficult as they are too young for spirometry.  Spirometry  Spirometry is recommended to aid in diagnosis and management. It is the single best test for asthma. If the FEV1 measured by this technique improves more than 12% and increases by at least 200 milliliters following administration of a bronchodilator such as salbutamol, this is supportive of the diagnosis. It however may be normal in those with a history of mild asthma, not currently acting up. As caffeine is a bronchodilator in people with asthma, the use of caffeine before a lung function test may interfere with the results. Single-breath diffusing capacity can help differentiate asthma from COPD. It is reasonable to perform spirometry every one or two years to follow how well a person\'s asthma is controlled.  Others  The methacholine challenge involves the inhalation of increasing concentrations of a substance that causes airway narrowing in those predisposed. If negative it means that a person does not have asthma; if positive, however, it is not specific for the disease.Other supportive evidence includes: a ≥20% difference in peak expiratory flow rate on at least three days in a week for at least two weeks, a ≥20% improvement of peak flow following treatment with either salbutamol, inhaled corticosteroids or prednisone, or a ≥20% decrease in peak flow following exposure to a trigger. Testing peak expiratory flow is more variable than spirometry, however, and thus not recommended for routine diagnosis. It may be useful for daily self-monitoring in those with moderate to severe disease and for checking the effectiveness of new medications. It may also be helpful in guiding treatment in those with acute exacerbations.  Classification  Asthma is clinically classified according to the frequency of symptoms, forced expiratory volume in one second (FEV1), and peak expiratory flow rate. Asthma may also be classified as atopic (extrinsic) or non-atopic (intrinsic), based on whether symptoms are precipitated by allergens (atopic) or not (non-atopic). While asthma is classified based on severity, at the moment there is no clear method for classifying different subgroups of asthma beyond this system. Finding ways to identify subgroups that respond well to different types of treatments is a current critical goal of asthma research.Although asthma is a chronic obstructive condition, it is not considered as a part of chronic obstructive pulmonary disease, as this term refers specifically to combinations of disease that are irreversible such as bronchiectasis and emphysema. Unlike these diseases, the airway obstruction in asthma is usually reversible; however, if left untreated, the chronic inflammation from asthma can lead the lungs to become irreversibly obstructed due to airway remodeling. In contrast to emphysema, asthma affects the bronchi, not the alveoli. The combination of asthma with a component of irreversible airway obstruction has been termed the asthma-chronic obstructive disease (COPD) overlap syndrome (ACOS). Compared to other people with ""pure"" asthma or COPD, people with ACOS exhibit increased morbidity, mortality and possibly more comorbidities.  Asthma exacerbation  An acute asthma exacerbation is commonly referred to as an asthma attack. The classic symptoms are shortness of breath, wheezing, and chest tightness. The wheezing is most often when breathing out. While these are the primary symptoms of asthma, some people present primarily with coughing, and in severe cases, air motion may be significantly impaired such that no wheezing is heard. In children, chest pain is often present.Signs occurring during an asthma attack include the use of accessory muscles of respiration (sternocleidomastoid and scalene muscles of the neck), there may be a paradoxical pulse (a pulse that is weaker during inhalation and stronger during exhalation), and over-inflation of the chest. A blue color of the skin and nails may occur from lack of oxygen.In a mild exacerbation the peak expiratory flow rate (PEFR) is ≥200 L/min, or ≥50% of the predicted best. Moderate is defined as between 80 and 200 L/min, or 25% and 50% of the predicted best, while severe is defined as ≤ 80 L/min, or ≤25% of the predicted best.Acute severe asthma, previously known as status asthmaticus, is an acute exacerbation of asthma that does not respond to standard treatments of bronchodilators and corticosteroids. Half of cases are due to infections with others caused by allergen, air pollution, or insufficient or inappropriate medication use.Brittle asthma is a kind of asthma distinguishable by recurrent, severe attacks. Type 1 brittle asthma is a disease with wide peak flow variability, despite intense medication. Type 2 brittle asthma is background well-controlled asthma with sudden severe exacerbations.  Exercise-induced  Exercise can trigger bronchoconstriction both in people with or without asthma. It occurs in most people with asthma and up to 20% of people without asthma. Exercise-induced bronchoconstriction is common in professional athletes. The highest rates are among cyclists (up to 45%), swimmers, and cross-country skiers. While it may occur with any weather conditions, it is more common when it is dry and cold. Inhaled beta2-agonists do not appear to improve athletic performance among those without asthma, however, oral doses may improve endurance and strength.  Occupational  Asthma as a result of (or worsened by) workplace exposures is a commonly reported occupational disease. Many cases, however, are not reported or recognized as such. It is estimated that 5–25% of asthma cases in adults are work-related. A few hundred different agents have been implicated, with the most common being: isocyanates, grain and wood dust, colophony, soldering flux, latex, animals, and aldehydes. The employment associated with the highest risk of problems include: those who spray paint, bakers and those who process food, nurses, chemical workers, those who work with animals, welders, hairdressers and timber workers.  Aspirin-exacerbated respiratory disease  Aspirin-exacerbated respiratory disease (AERD), also known as aspirin-induced asthma, affects up to 9% of asthmatics. AERD consists of asthma, nasal polyps, sinus disease, and respiratory reactions to aspirin and other NSAID medications (such as ibuprofen and naproxen). People often also develop loss of smell and most experience respiratory reactions to alcohol.  Alcohol-induced asthma  Alcohol may worsen asthmatic symptoms in up to a third of people. This may be even more common in some ethnic groups such as the Japanese and those with aspirin-exacerbated respiratory disease. Other studies have found improvement in asthmatic symptoms from alcohol.  Non-atopic asthma  Non-atopic asthma, also known as intrinsic or non-allergic, makes up between 10 and 33% of cases. There is negative skin test to common inhalant allergens. Often it starts later in life, and women are more commonly affected than men. Usual treatments may not work as well. The concept that ""non-atopic"" is synonymous with ""non-allergic"" is called into question by epidemiological data that the prevalence of asthma is closely related to the serum IgE level standardized for age and sex (P<0.0001), indicating that asthma is almost always associated with some sort of IgE-related reaction and therefore has an allergic basis, although not all the allergic stimuli that cause asthma appear to have been included in the battery of aeroallergens studied (the ""missing antigen(s)"" hypothesis). For example, an updated systematic review and meta-analysis of population-attributable risk (PAR) of Chlamydia pneumoniae biomarkers in chronic asthma found that the PAR for C. pneumoniae-specific IgE was 47%.  Infectious asthma  When queried, asthma patients may report that their first asthma symptoms began after an acute lower respiratory tract illness. This type of history has been labelled the ""infectious asthma"" (IA) syndrome, or as ""asthma associated with infection"" (AAWI) to distinguish infection-associated asthma initiation from the well known association of respiratory infections with asthma exacerbations. Reported prevalences of IA for adults range from around 40% in a primary care practice to 70% in a specialty practice treating mainly severe asthma patients. The true population prevalence of IA in adult-onset asthma is unknown because clinicians are not trained to elicit this type of history routinely, and recollection in child-onset asthma is challenging.  Differential diagnosis  Many other conditions can cause symptoms similar to those of asthma. In children, symptoms may be due to other upper airway diseases such as allergic rhinitis and sinusitis, as well as other causes of airway obstruction including foreign body aspiration, tracheal stenosis, laryngotracheomalacia, vascular rings, enlarged lymph nodes or neck masses. Bronchiolitis and other viral infections may also produce wheezing. According to European Respiratory Society, it may not be suitable to label wheezing preschool children with the term ""asthma"" because there is lack of clinical data on inflammation in airways. In adults, COPD, congestive heart failure, airway masses, as well as drug-induced coughing due to ACE inhibitors may cause similar symptoms. In both populations vocal cord dysfunction may present similarly.Chronic obstructive pulmonary disease can coexist with asthma and can occur as a complication of chronic asthma. After the age of 65, most people with obstructive airway disease will have asthma and COPD. In this setting, COPD can be differentiated by increased airway neutrophils, abnormally increased wall thickness, and increased smooth muscle in the bronchi. However, this level of investigation is not performed due to COPD and asthma sharing similar principles of management: corticosteroids, long-acting beta-agonists, and smoking cessation. It closely resembles asthma in symptoms, is correlated with more exposure to cigarette smoke, an older age, less symptom reversibility after bronchodilator administration, and decreased likelihood of family history of atopy.  Prevention  The evidence for the effectiveness of measures to prevent the development of asthma is weak. The World Health Organization recommends decreasing risk factors such as tobacco smoke, air pollution, chemical irritants including perfume, and the number of lower respiratory infections. Other efforts that show promise include: limiting smoke exposure in utero, breastfeeding, and increased exposure to daycare or large families, but none are well supported enough to be recommended for this indication.Early pet exposure may be useful. Results from exposure to pets at other times are inconclusive and it is only recommended that pets be removed from the home if a person has allergic symptoms to said pet.Dietary restrictions during pregnancy or when breast feeding have not been found to be effective at preventing asthma in children and are not recommended. Omega-3 consumption, mediterranean diet and anti-oxidants have been suggested by some studies that might help preventing crisis but the evidence is still inconclusive.Reducing or eliminating compounds known to sensitive people from the work place may be effective. It is not clear if annual influenza vaccinations affects the risk of exacerbations. Immunization, however, is recommended by the World Health Organization. Smoking bans are effective in decreasing exacerbations of asthma.  Management  While there is no cure for asthma, symptoms can typically be improved. The most effective treatment for asthma is identifying triggers, such as cigarette smoke, pets or other allergens, and eliminating exposure to them. If trigger avoidance is insufficient, the use of medication is recommended. Pharmaceutical drugs are selected based on, among other things, the severity of illness and the frequency of symptoms. Specific medications for asthma are broadly classified into fast-acting and long-acting categories. The medications listed below have demonstrated efficacy in improving asthma symptoms, however ""real world"" use-effectiveness is limited as around half of people with asthma worldwide remain sub-optimally controlled, even when treated. People with asthma may remain sub-optimally controlled either because optimum doses of asthma medications do not work (called ""refractory"" asthma) or because individuals are either unable (e.g. inability to afford treatment, poor inhaler technique) or unwilling (e.g., wish to avoid side effects of corticosteroids) to take optimum doses of prescribed asthma medications (called ""difficult to treat"" asthma). In practice, it is not possible to distinguish ""refractory"" from ""difficult to treat"" categories for patients who have never taken optimum doses of asthma medications. A related issue is that the asthma efficacy trials upon which the pharmacological treatment guidelines are based have systematically excluded the majority of people with asthma. For example, asthma efficacy treatment trials always exclude otherwise eligible people who smoke, and smoking blunts the efficacy of inhaled corticosteroids, the mainstay of asthma control management.Bronchodilators are recommended for short-term relief of symptoms. In those with occasional attacks, no other medication is needed. If mild persistent disease is present (more than two attacks a week), low-dose inhaled corticosteroids or alternatively, a leukotriene antagonist or a mast cell stabilizer by mouth is recommended. For those who have daily attacks, a higher dose of inhaled corticosteroids is used. In a moderate or severe exacerbation, corticosteroids by mouth are added to these treatments.People with asthma have higher rates of anxiety, psychological stress, and depression. This is associated with poorer asthma control. Cognitive behavioral therapy may improve quality of life, asthma control, and anxiety levels in people with asthma.Improving people\'s knowledge about asthma and using a written action plan has been identified as an important component of managing asthma. Providing educational sessions that include information specific to a person\'s culture is likely effective. More research is necessary to determine if increasing preparedness and knowledge of asthma among school staff and families using home-based and school interventions results in long term improvements in safety for children with asthma. School-based asthma self-management interventions, which attempt to improve knowledge of asthma, its triggers and the importance of regular practitioner review, may reduce hospital admissions and emergency department visits. These interventions may also reduce the number of days children experience asthma symptoms and may lead to small improvements in asthma-related quality of life. More research is necessary to determine if shared-decision-making is helpful for managing adults with asthma or if a personalized asthma action plan is effective and necessary. Some people with asthma use pulse oximeters to monitor their own blood oxygen levels during an asthma attack. However, there is no evidence regarding the use in these instances.  Lifestyle modification  Avoidance of triggers is a key component of improving control and preventing attacks. The most common triggers include allergens, smoke (from tobacco or other sources), air pollution, non selective beta-blockers, and sulfite-containing foods. Cigarette smoking and second-hand smoke (passive smoke) may reduce the effectiveness of medications such as corticosteroids. Laws that limit smoking decrease the number of people hospitalized for asthma. Dust mite control measures, including air filtration, chemicals to kill mites, vacuuming, mattress covers and others methods had no effect on asthma symptoms. There is insufficient evidence to suggest that dehumidifiers are helpful for controlling asthma.Overall, exercise is beneficial in people with stable asthma. Yoga could provide small improvements in quality of life and symptoms in people with asthma. More research is necessary to determine how effective weight loss is on improving quality of life, the usage of health care services, and adverse effects for people of all ages with asthma.  Medications  Medications used to treat asthma are divided into two general classes: quick-relief medications used to treat acute symptoms; and long-term control medications used to prevent further exacerbation. Antibiotics are generally not needed for sudden worsening of symptoms or for treating asthma at any time.  Medications of asthma exacerbations  Short-acting beta2-adrenoceptor agonists (SABA), such as salbutamol (albuterol USAN) are the first line treatment for asthma symptoms. They are recommended before exercise in those with exercise induced symptoms. Anticholinergic medications, such as ipratropium, provide additional benefit when used in combination with SABA in those with moderate or severe symptoms and may prevent hospitalizations. Anticholinergic bronchodilators can also be used if a person cannot tolerate a SABA. If a child requires admission to hospital additional ipratropium does not appear to help over a SABA. For children over 2 years old with acute asthma symptoms, inhaled anticholinergic medications taken alone is safe but is not as effective as inhaled SABA or SABA combined with inhaled anticholinergic medication. Adults who receive combined inhaled medications that includes short-acting anticholinergics and SABA may be at risk for increased adverse effects such as experiencing a tremor, agitation, and heart beat palpitations compared to people who are treated with SABA by itself. Older, less selective adrenergic agonists, such as inhaled epinephrine, have similar efficacy to SABAs. They are however not recommended due to concerns regarding excessive cardiac stimulation. Corticosteroids can also help with the acute phase of an exacerbation because of their antiinflamatory properties. The benefit of systemic and oral corticosteroids is well established. Inhaled or nebulized corticosteroids can also be used. For adults and children who are in the hospital due to acute asthma, systemic (IV) corticosteroids improve symptoms. A short course of corticosteroids after an acute asthma exacerbation may help prevent relapses and reduce hospitalizations. Other remedies, less established, are intravenous or nebulized magnesium sulfate and helium mixed with oxygen. Aminophylline could be used with caution as well. Mechanical ventilation is the last resort in case of severe hypoxemia. Intravenous administration of the drug aminophylline does not provide an improvement in bronchodilation when compared to standard inhaled beta-2 agonist treatment. Aminophylline treatment is associated with more adverse effects compared to inhaled beta-2 agonist treatment.  Long–term control  Corticosteroids are generally considered the most effective treatment available for long-term control. Inhaled forms are usually used except in the case of severe persistent disease, in which oral corticosteroids may be needed. Dosage depends on the severity of symptoms. High dosage and long term use might lead to the appearance of common adverse effects which are growth delay, adrenal suppression, and osteoporosis. Continuous (daily) use of an inhaled corticosteroid, rather than its intermitted use, seems to provide better results in controlling asthma exacerbations. Commonly used corticosteroids are budesonide, fluticasone, mometasone and ciclesonide. Long-acting beta-adrenoceptor agonists (LABA) such as salmeterol and formoterol can improve asthma control, at least in adults, when given in combination with inhaled corticosteroids. In children this benefit is uncertain. When used without steroids they increase the risk of severe side-effects, and with corticosteroids they may slightly increase the risk. Evidence suggests that for children who have persistent asthma, a treatment regime that includes LABA added to inhaled corticosteroids may improve lung function but does not reduce the amount of serious exacerbations. Children who require LABA as part of their asthma treatment may need to go to the hospital more frequently. Leukotriene receptor antagonists (anti-leukotriene agents such as montelukast and zafirlukast) may be used in addition to inhaled corticosteroids, typically also in conjunction with a LABA. For adults or adolescents who have persistent asthma that is not controlled very well, the addition of anti-leukotriene agents along with daily inhaled corticosteriods improves lung function and reduces the risk of moderate and severe asthma exacerbations. Anti-leukotriene agents may be effective alone for adolescents and adults, however there is no clear research suggesting which people with asthma would benefit from anti-leukotriene receptor alone. In those under five years of age, anti-leukotriene agents were the preferred add-on therapy after inhaled corticosteroids. A 2013 Cochrane systematic review concluded that anti-leukotriene agents appear to be of little benefit when added to inhaled steroids for treating children. A similar class of drugs, 5-LOX inhibitors, may be used as an alternative in the chronic treatment of mild to moderate asthma among older children and adults. As of 2013 there is one medication in this family known as zileuton. Mast cell stabilizers (such as cromolyn sodium) are safe alternatives to corticosteroids but not preferred because they have to be administered frequently. Oral Theophyllines are sometimes used for controlling chronic asthma, but their used is minimized because of their side effects. Omalizumab, a monoclonal Antibody Against IgE, is a novel way to lessen exacerbations by lessening the levels of circulating IgE that play a significant role at allergic asthma. Anticholinergic medications such as ipratropium bromide have not been shown to be beneficial for treating chronic asthma in children over 2 years old, but is not suggested for routine treatment of chronic asthma in adults. There is no strong evidence to recommend chloroquine medication as a replacement for taking corticosteroids by mouth (for those who are not able to tolerate inhaled steroids). Methotrexate is not suggested as a replacement for taking corticosteriods by mouth (""steroid sparing"") due to the adverse effects associated with taking methotrexate and the minimal relief provided for asthma symptoms. Macrolide antibiotics, particularly the azalide macrolide azithromycin, are a recently added GINA-recommended treatment option for both eosinophilic and non-eosinophilic severe, refractory asthma based on azithromycin\'s efficacy in reducing moderate and severe exacerbations combined. Azithromycin\'s mechanism of action is not established, and could involve pathogen- and/or host-directed anti-inflammatory activities. Limited clinical observations suggest that some patients with new-onset asthma and with ""difficult-to-treat"" asthma (including those with the asthma-COPD overlap syndrome - ACOS) may respond dramatically to azithromycin. However, these groups of asthma patients have not been studied in randomized treatment trials and patient selection needs to be carefully individualized.For children with asthma which is well-controlled on combination therapy of inhaled corticosteroids (ICS) and long-acting beta2-agonists (LABA), the benefits and harms of stopping LABA and stepping down to ICS-only therapy are uncertain. In adults who have stable asthma while they are taking a combination of LABA and inhaled corticosteroids (ICS), stopping LABA may increase the risk of asthma exacerbations that require treatment with corticosteroids by mouth. Stopping LABA probably makes little or no important difference to asthma control or asthma-related quality of life. Whether or not stopping LABA increases the risk of serious adverse events or exacerbations requiring an emergency department visit or hospitalisation is uncertain.  Delivery methods  Medications are typically provided as metered-dose inhalers (MDIs) in combination with an asthma spacer or as a dry powder inhaler. The spacer is a plastic cylinder that mixes the medication with air, making it easier to receive a full dose of the drug. A nebulizer may also be used. Nebulizers and spacers are equally effective in those with mild to moderate symptoms. However, insufficient evidence is available to determine whether a difference exists in those with severe disease. For delivering short-acting beta-agonists in acute asthma in children, spacers may have advantages compared to nebulisers, but children with life-threatening asthma have not been studied. There is no strong evidence for the use of intravenous LABA for adults or children who have acute asthma. There is insufficient evidence to directly compare the effectiveness of a metered-dose inhaler attached to a homemade spacer compared to commercially available spacer for treating children with asthma.  Adverse effects  Long-term use of inhaled corticosteroids at conventional doses carries a minor risk of adverse effects. Risks include thrush, the development of cataracts, and a slightly slowed rate of growth. Rinsing the mouth after the use of inhaled steroids can decrease the risk of thrush. Higher doses of inhaled steroids may result in lower bone mineral density.  Others  Inflammation in the lungs can be estimated by the level of exhaled nitric oxide. The use of exhaled nitric oxide levels (FeNO) to guide asthma medication dosing may have small benefits for preventing asthma attacks but the potential benefits are not strong enough for this approach to be universally recommended as a method to guide asthma therapy in adults or children.When asthma is unresponsive to usual medications, other options are available for both emergency management and prevention of flareups. Additional options include: Humidified Oxygen to alleviate hypoxia if saturations fall below 92%. Corticosteroid by mouth are recommended with five days of prednisone being the same 2 days of dexamethasone. One review recommended a seven-day course of steroids. Magnesium sulfate intravenous treatment increases bronchodilation when used in addition to other treatment in moderate severe acute asthma attacks. In adults intravenous treatment results in a reduction of hospital admissions. Low levels of evidence suggest that inhaled (nebulised) magnesium sulfate may have a small benefit for treating acute asthma in adults. Overall, high quality evidence do not indicate a large benefit for combining magnesium sulfate with standard inhaled treatments for adults with asthma. Heliox, a mixture of helium and oxygen, may also be considered in severe unresponsive cases. Intravenous salbutamol is not supported by available evidence and is thus used only in extreme cases. Methylxanthines (such as theophylline) were once widely used, but do not add significantly to the effects of inhaled beta-agonists. Their use in acute exacerbations is controversial. The dissociative anesthetic ketamine is theoretically useful if intubation and mechanical ventilation is needed in people who are approaching respiratory arrest; however, there is no evidence from clinical trials to support this. For those with severe persistent asthma not controlled by inhaled corticosteroids and LABAs, bronchial thermoplasty may be an option. It involves the delivery of controlled thermal energy to the airway wall during a series of bronchoscopies. While it may increase exacerbation frequency in the first few months it appears to decrease the subsequent rate. Effects beyond one year are unknown. Monoclonal antibody injections such as mepolizumab, dupilumab, or omalizumab may be useful in those with poorly controlled atopic asthma. However, as of 2019 these medications are expensive and their use is therefore reserved for those with severe symptoms to achieve cost-effectiveness. Monoclonal antibodies targeting interleukin-5 (IL-5) or its receptor (IL-5R), including mepolizumab, reslizumab or benralizumab, in addition to standard care in severe asthma is effective in reducing the rate of asthma exacerbations. There is limited evidence for improved health-related quality of life and lung function. Evidence suggests that sublingual immunotherapy in those with both allergic rhinitis and asthma improve outcomes. It is unclear if non-invasive positive pressure ventilation in children is of use as it has not been sufficiently studied.  Alternative medicine  Many people with asthma, like those with other chronic disorders, use alternative treatments; surveys show that roughly 50% use some form of unconventional therapy. There is little data to support the effectiveness of most of these therapies. Evidence is insufficient to support the usage of vitamin C or vitamin E for controlling asthma. There is tentative support for use of vitamin C in exercise induced bronchospasm. Fish oil dietary supplements (marine n-3 fatty acids) and reducing dietary sodium do not appear to help improve asthma control. In people with mild to moderate asthma, treatment with vitamin D supplementation may reduce the risk of asthma exacerbations, however, it is not clear if this is only helpful for people who have low vitamin D levels to begin with (low baseline vitamin D). There is no strong evidence to suggest that vitamin D supplements improve day-to-day asthma symptoms or a person\'s lung function. There is no strong evidence to suggest that adults with asthma should avoid foods that contain monosodium glutamate (MSG). There have not been enough high-quality studies performed to determine if children with asthma should avoid eating food that contains MSG.Acupuncture is not recommended for the treatment as there is insufficient evidence to support its use. Air ionisers show no evidence that they improve asthma symptoms or benefit lung function; this applied equally to positive and negative ion generators. Manual therapies, including osteopathic, chiropractic, physiotherapeutic and respiratory therapeutic maneuvers, have insufficient evidence to support their use in treating asthma. The Buteyko breathing technique for controlling hyperventilation may result in a reduction in medication use; however, the technique does not have any effect on lung function. Thus an expert panel felt that evidence was insufficient to support its use. There is no clear evidence that breathing exercises are effective for treating children with asthma.  Prognosis  The prognosis for asthma is generally good, especially for children with mild disease. Mortality has decreased over the last few decades due to better recognition and improvement in care. In 2010 the death rate was 170 per million for males and 90 per million for females. Rates vary between countries by 100 fold.Globally it causes moderate or severe disability in 19.4 million people as of 2004 (16 million of which are in low and middle income countries). Of asthma diagnosed during childhood, half of cases will no longer carry the diagnosis after a decade. Airway remodeling is observed, but it is unknown whether these represent harmful or beneficial changes. Early treatment with corticosteroids seems to prevent or ameliorates a decline in lung function. Asthma in children also has negative effects on quality of life of their parents.  Epidemiology  In 2019, approximately 262 million people worldwide were affected by asthma and approximately 461,000 people died from the disease. Rates vary between countries with prevalences between 1 and 18%. It is more common in developed than developing countries. One thus sees lower rates in Asia, Eastern Europe and Africa. Within developed countries it is more common in those who are economically disadvantaged while in contrast in developing countries it is more common in the affluent. The reason for these differences is not well known. Low and middle income countries make up more than 80% of the mortality.While asthma is twice as common in boys as girls, severe asthma occurs at equal rates. In contrast adult women have a higher rate of asthma than men and it is more common in the young than the old. In 2010, children with asthma experienced over 900,000 emergency department visits, making it the most common reason for admission to the hospital following an emergency department visit in the US in 2011.Global rates of asthma have increased significantly between the 1960s and 2008 with it being recognized as a major public health problem since the 1970s. Rates of asthma have plateaued in the developed world since the mid-1990s with recent increases primarily in the developing world. Asthma affects approximately 7% of the population of the United States and 5% of people in the United Kingdom. Canada, Australia and New Zealand have rates of about 14–15%.The average death rate from 2011 to 2015 from asthma in the UK was about 50% higher than the average for the European Union and had increased by about 5% in that time. Children are more likely see a physician due to asthma symptoms after school starts in September.Population-based epidemiological studies describe temporal associations between acute respiratory illnesses, asthma, and development of severe asthma with irreversible airflow limitation (known as the asthma-chronic obstructive pulmonary disease ""overlap"" syndrome, or ACOS). Additional prospective population-based data indicate that ACOS seems to represent a form of severe asthma, characterised by more frequent hospitalisations, and to be the result of early-onset asthma that has progressed to fixed airflow obstruction.  Economics  From 2000 to 2010, the average cost per asthma-related hospital stay in the United States for children remained relatively stable at about $3,600, whereas the average cost per asthma-related hospital stay for adults increased from $5,200 to $6,600. In 2010, Medicaid was the most frequent primary payer among children and adults aged 18–44 years in the United States; private insurance was the second most frequent payer. Among both children and adults in the lowest income communities in the United States there is a higher rate of hospital stays for asthma in 2010 than those in the highest income communities.","Asthma (or Asthma bronchiale) is a disease that hurts the airways inside the lungs. It causes the tissue inside the airways to swell. Asthma also causes the bands of muscle around the airways to become narrow. This makes it hard for enough air to pass through and for the person to breathe normally. Asthma also causes mucus-making cells inside the airways to make more mucus than normal. This blocks the airways, which are already very narrow during an asthma attack, and makes it even more difficult to breathe. A person having an asthma attack often makes wheezing sounds when trying to breathe. This is the sound of air trying to pass through the very narrow airway. They also have shortness of breath, which means they cannot take a full deep breath. Chest tightness may happen which feels like their chest is being squeezed. They may also cough a lot. Asthma attacks can be a medical emergency because they can be fatal (cause a person to die). There is no cure for asthma. There are treatments such as different kinds of medicines to help people with asthma. There are also things that people with asthma can do to help themselves to keep their asthma from getting worse. There are a lot of risk factors for getting asthma. The exact reasons for each is not yet clearly understood. Some of the factors are believed to come from genetics. A person inherits genetic mutations from one or both of their parents that may increase the chances of developing asthma. Epigenetics, which are changes in the way a gene acts, may also increase their chances of getting asthma. These epigenetic changes may also be inherited. They may happen when a baby is still growing inside its mother, or during childhood. Socioeconomic status (SES) is also believed to play a part in developing asthma. A person's socioeconomic status is based on such things as how much money their family makes, where they live, and their education level. Race and ethnicity also may play a part. It also is related to access to medical care, personal beliefs, and dietary habits. People of lower socioeconomic status suffer higher rates of asthma, have worse outcomes, and also have higher asthma-related death rates than people of higher economic status.  Causes  The exact cause of asthma is not yet known. It is believed that it may be because of a of many different reasons: Genetics: When changes happen in a person's genes (called mutations) these changes are passed on to their children. One or both parents may have these changes or mutations in their genes, and some or all of their children may be born with them, which means they inherited them. These mutations, once they happen, run in families from one generation to the next and are permanent mutations, they change the gene in the DNA. These changes can make a person more likely to get certain diseases like asthma. In some diseases it may be only one change in one gene that may make a person get that disease, in asthma it may be changes in many different genes that may make a person more likely to get asthma.Epigenetics changes or modifications cause different kind of changes that affect how a person's genes work or 'express themselves' in three different ways (called epigenetic mechanisms), but do not change the gene in the DNA. These epigenetic changes may be inherited, or they may happen in utero which is when a baby is still inside its mother. They may also happen in childhood, because of different reasons, like a respiratory infection, being exposed to chemicals or drugs, diet etc. These changes can be passed from one generation to the next but are not permanent and might only be passed down one or two generations. Even though epigenetic changes affect how a person's genes work they do not permanently change a person's genes. It is believed epigenetic changes may also make a person more likely to get certain diseases like asthma.Environmental factors are things that affect a person; which can be either healthy or unhealthy. Unhealthy environmental factors are things like living in an area where there is a lot of air pollution, or living somewhere where there are lots of bugs in the house, or being around cigarette smoke. If a person who has genetic or epigentic changes in their genes that makes them have a bigger chance of getting asthma (genetic predisposition), also has unhealthy environmental factors in their life, like living in a home that has a lot of dust mites, then it is more likely that they will get asthma. Atopy Atopy is when there are changes in some of the genes a person is born with (genetic inheritance). These genetic changes make their body produce more Immunoglobulin E (IgE), a type of antibody. They are also more sensitive to things things like chemicals, smoke and dust (environmental antigens). This hypersensitivity means they are more sensitive or allergic to things in the environment than people who do not have these changes in their genes and are not hypersensitive or allergic. This hypersensitivity causes their body to react in certain ways. Usually a person who is atopic develops allergic rhinitis which affects the nasal passages which are behind the nose and they are also more likely to get atopic dermatitis which causes skin rashes and atopic asthma. Up to 40% of people with allergic rhinitis also have asthma. These three medical problems, allergic rhinitis, atopic dermatitis and atopic asthma are called the Atopic Triad (a triad is when there is three of something). People who are atopic may also have other medical problems including food and drug allergies, stinging-insect hypersensitivity, hives (urticaria), Quincke's edema (angioedema), and contact dermatitis. If a person has one parent who is atopic they have a chance of being atopic too. If they have two parents who are atopic they have an even bigger chance of being atopic. Acetaminophen and asthma There have been studies that show a link between acetaminophen (Tylenol) and asthma. For instance a 2008 analysis of information collected from a very large study called the International Study of Asthma and Allergies in Childhood, or the ""Isaac study"" for short, showed that children who had taken acetaminophen for a fever during the first year of their life had a 50% higher risk of getting asthma later on. The more acetaminophen children took the higher their risk of getting asthma. Children who took it once a month had threefold increase in their risk of getting asthma. An increase in asthma rates in multiple countries corresponded with increased sales of drugs which contained acetaminophen. Previously the American College of Physicians reported a link between non-atopic asthma and acetaminophen use based on results of The Third National Health and Nutrition Examination Survey. Not all doctors are convinced of the link between acetaminophen and asthma. ""Children with asthma or at risk for asthma should avoid the use of acetaminophen."" (McBride JT, 2011).  Types of Asthma  Atopic asthma Atopic asthma is the most common form of asthma. Cough-variant asthma Cough-variant asthma is a type of asthma in which a cough is the main, and sometimes only sign. Cough-variant asthma usually does not cause wheezing or breathlessness and causes a dry, scratchy, mostly nonproductive cough (this means little or no phlegm is coughed up). About 30% of people who have cough-variant asthma will develop typical asthma.Work-related asthma Work related asthma are types of asthma that are caused or made worse by irritants in the environment at a person's place of work. The kind of jobs that may cause work related asthma are usually those in which there is a lot of smoke or chemicals are used. There are different types of work-related asthma (WRA):1. Occupational asthma with latency: this asthma type is when the signs and symptoms of asthma occur after a period of time (latency) after being exposed to the environmental irritants. e.g.: John starts working at a factory where chemicals are used the first week of January. At the end of March he starts developing the signs and symptoms of asthma. The period of time from when he started the job in January to when the signs and symptoms of asthma started in March is the latency period.2. Irritant-Induced Asthma (IIA) is occupational asthma without latency: this is an asthma type is when the signs and symptoms of asthma can occur immediately (without latency) after being exposed to the environmental irritants. e.g. Frank starts a new job working as a janitor where he uses ammonia to clean. After opening the bottle of ammonia and breathing the fumes Frank starts finding it difficult to breath, his chest tightens up and he develops other signs and symptoms of asthma. 3. Reactive Airways Dysfunction Syndrome (RADS):4. Work-aggravated asthma: this is when a person already has asthma and environmental triggers at their place of work makes it worse. Exercise induced asthma Exercise induced asthma (EIA) - also called exercise induced bronchospasm - is the term used to describe asthma cases in which exercise is the main, and many times the only trigger for an asthma attack. If a person already has a form of asthma or they are atopic there is more of a chance of getting EIA. Nocturnal asthma Nocturnal asthma: is the term used to describe asthma cases that get worse at night (nocturnal). Premenstrual asthma (PMA): is when asthma symptoms get worse during the premenstrual period. This condition may affect up to 40% of female asthma sufferers. For a diagnosis of PMA to be made it is necessary to have a detailed history of the timing of menstrual cycles along with asthma symptoms experienced, and the peak expiratory flow rate (PMA may cause the PEF to be lowered in the premenstrual period). It is helpful in making a diagnosis to keep a diary of symptoms and peak expiratory flow (PEF) rates.Status asthmaticus Status asthmaticus is a severe form of asthma in which an asthma attack gets worse as it goes along and the medicines that are usually used to treat asthma do not work. Status asthmaticus can be fatal.  Signs and symptoms  Signs and symptoms in medicine are the way a medical condition affects a person's body. Sometimes the signs and symptoms of asthma may be mild which does not bother the person too much. At other times they may be severe which may make the person feel very sick. Not every person with asthma has all the signs and symptoms of asthma all the time. A person may have some signs and symptoms during one asthma attack and have different symptoms during another asthma attack. Some people with asthma may have long periods of time between asthma attacks where they show no signs and experience no symptoms of asthma, while others may have some or all of the signs and symptoms everyday which become more severe during an attack. It also depends on what type of asthma a person has and whether they have a mild, moderate or severe case. There are also some people with asthma who might only have signs and symptoms during certain times, such as those with exercise induced asthma, where the exercise triggers the symptoms. For some the signs and symptoms of asthma may be triggered or made worse (exacerbated) when they have viral respiratory tract infections, often the type casued by human rhinoviruses.Early warning signs of an asthma attack are physical changes in health that a person with asthma has before they have the attack. By knowing the early warning signs a person may be able to take steps to keep from having an asthma attack or if they do have one, to keep it from getting worse. Early warning signs The early warning signs of asthma may include: Coughing a lot, especially at night Losing your breath easily Shortness of breath: this is when a person cannot take a deep breath which means they cannot fill their lungs all the way with air. They may be only able to take short, shallow breaths which does give their lungs enough air. When a person has shortness of breath they may also have chest tightness. Getting tired easily during exercise and feeling weak and wheezing or coughing after exercise Feeling the symptoms of a cold or allergies coming on like sneezing, a runny or stuffed up nose, coughing, sore throat, and headache  Triggers  A trigger factor or trigger for short, is something that causes the signs and symptoms of a medical condition to begin in a person who already has that medical condition. Common triggers for asthma are: Tobacco smoke: a person does not need to smoke themselves, second-hand smoke can trigger an asthma attack. Second-hand smoke is the smoke from the end of a burning cigarette, cigar or pipe that someone else is smoking, or the smoke that they breathe out (exhale). Pets: animals give off chemicals called proteins which are allergens; people can be allergic to them. These allergens can act as irritants and make someone's asthma worse and trigger an asthma attack. The proteins are in the pet's dander which is the dead flakes of skin that animals (and people) shed. They are also in their urine, feces, saliva, and sebum which is made by glands in the skin called sebaceous glands. Sebum is what makes hair and skin oily. When dander, urine, feces, saliva, and sebum dry out their proteins can become airborne and breathed in. Some of the types of pets people can be allergic to are, dogs, cats, gerbils, hamsters, guinea pigs and pet birds. Bugs: different types of bugs which may be found inside homes may trigger asthma attacks. They may trigger asthma symptoms in the same way as pets; the proteins they give off are allergens and become airborne. Some of the more common bugs which may trigger asthma are dust mites, cockroaches and also bedbugs and fleas. Many other species that may infest a home may serve as a source of allegens such as Pharaoh ants. Fungus spores (mold): fungus reproduce by releasing spores into the air, if the spores land in a good place form them to grow then a new fungus starts. Breathing in these spores can trigger asthma. One of the most common types of fungus spores found in both outside and outside environments are from a group (genus) known as aspergillus. Strong emotions such as anger, stress and even laughter may worsen asthma symptoms. Outdoor air pollution can come from many sources such as car and truck fumes in areas of heavy traffic and chemicals in the air near factories and refineries. Weather: changes in the weather can trigger an asthma attack. Changes in air temperature can trigger an attack not just cold air. If a person goes from being outside in the cold into a warm house the sudden change can cause a broncospasm. Sudden changes in humidity also plays a part.The best way to deal with asthma triggers is to learn what they are and avoid them if possible, and if not totally avoidable then adjust one's behavior to deal with them. Example: running on a cold winter day right up to the doorstep of a warm house and going immediately inside; the sudden temperature change can cause an attack and could have been avoided. In general but especially with a medical condition such as asthma it is necessary to be aware of one's environment and what's in it, both indoors and outdoors. Most often the Asthma is triggered by allergens. One big source of allergens is the carpet. Totally replace it with a tiles floor reduce the possibility to create a good environment for the allergens and it is more simple to clean and disinfect.  Asthma attack  An asthma attack is when, after a period of time when a person has had only a few or no symptoms of asthma, the asthma gets worse all of a sudden, usually because of being exposed to one or more triggers. When the asthma attack happens, the tissue inside the airways swell because of inflammation - which is how the body tries to protect itself from harmful things, like germs and irritants. When the tissues swell the opening (called the lumen) in the airway gets very narrow. The smooth muscles (which are the kind of muscles in the body that do not contract voluntarily, like the ones in the arm) around the bronchi and bronchioles begin to spasm or contract which makes the opening in the airway even narrower. This is called a bronchospasm. Inside the lining of the airways are glands called, submucosal glands, and above them, closer to the opening in the airway are cells called goblet cells - because they are shaped kind of like a goblet, which is a type of cup. The submucosal glands and the goblet cells make mucous which helps protect the inside of the airways. The mucous in the airways of healthy lungs is a thin film which traps irritants such as dust particles and pollen so they do not damage the airways and keep them from entering the air sacs (alveoli). There are tiny hairs lining the airway called cilia. The cilia wave back and forth like a liitle whips, and help push the mucous and the trapped particles up the airways to the ""pharynx. From there the mucous, the trapped particles from the lower airways can be coughed up (this is called sputum). During an asthma attack the submucosal glands and the goblet cells start making much more mucous than normal, and the mucous is also thicker than normal. This makes it very hard for the cilia to do their job, and bring the mucous up out of the airways. So now there is too much mucous being made, and not enough being brought up by the cilia. The airways are already to narrow to breathe properly because of the tissue swelling caused by inflammation and the constriction caused by the bronchospasms, so the extra mucous blocks the airway even more. This makes breathing very difficult. In fatal asthma attacks the airways can become so constricted and/or plugged with mucous that no air can get through at all. There are other signs of breathing difficulty as in an asthma attack, which are important to learn, and knowing them can help tell if someone who cannot talk is having breathing problems. People who may not be able to let somebody know they are having breathing problems include babies and young children. Some of the other signs of asthma include: Chest and neck retractions; which cause muscles within the chest and neck not normally used too much when breathing, to begin contracting as they try and help to take in more air. Retractions are how the body tries to get enough air because of the difficulty in breathing normally because of the asthma attack. These retractions cause the skin of the chest wall, the skin of the neck and or the breastbone (sternum) to move in when breathing. There are different types of retractions which depend on which muscles start contracting, and this depends on how much difficulty a person is having breathing during an attack.Nasal flaring is when the opening of the nostrils get larger than normal during breathing. It is often a sign that a person is having difficulty in breathing.Blue lips and fingertips: oxygen which is in the air we breathe, is what makes blood have a red color. Blood without oxygen has a blue color. Oxygen enters the body through the air sacs (alveoli) which are at the end of the airways. During an asthma attack it difficult for the body to get enough oxygen because it is difficult to get enough air. As less air with oxygen in it makes it to the air sacs and into the blood, there is less red blood (blood with oxygen in it) and more blue blood (blood without oxygen in it). The blue color of the lips and under the fingernails is because of the blue blood, which can be seen in the small blood vessels under the skin. More parts of the body start turning blue the longer the body goes without oxygen. When parts of the body turn blue because of lack of oxygen it is called cyanosis.Sweating : sweating may be noticed especially on the forehead, but the skin does not feel warm, it may feel cool and clammy to touch. Rapid breathing (tachypnea); breathing in and out much faster than normal. Rapid heart beat: (tachycardia): the heart starts beating much faster than normal.  Diagnosis  A diagnosis of asthma is based on a person's: Medical history; information such as what signs and symptoms of asthma have they had Family medical history; has anyone they are related to had asthma or related conditions such as occur with those who are atopic Physical examination and testingDiagnostic Tests There is no specific test that can tell if a person has asthma, however there are tests that can help in the diagnosis when the results are considered along with the medical and family history and physical exam Lung function tests [Pulmonary function tests (PFTs)] Spirometry; measures how much air the lungs are able to breathe in and how much air they breathe out and how fast a person can exhale. Bronchoprovocation test; in this test the airways (bronchi and bronchioles) are provoked (to try and make something happen) into having a bronchospasm (make the airways constrict) this is to see how sensitive they are. Some of the things done to provoke a bronchospasm are making the person exercise, breathing cold air that gets colder, or breathing in a special chemical called methacholine. The results of bronchoprovocation are checked using spirometry.  Differential diagnoses  Differential diagnoses are different medical disorders which may cause the same symptoms. Before a doctor makes a final diagnosis, which means they are sure of what medical disorder is causing the problem, they think of what other medical conditions have the same or almost the same symptoms, and make sure it's not one of them.The differential diagnoses of asthma include: Bronchiectasis Chronic obstructive pulmonary disease (COPD)  Airway remodeling  Airway remodeling is when there are permanent physical changes to the airways that also affects how they work. This may happen after chronic long-term asthma. After cycles of inflammation, damage and repair to the airways. permanent remodeling of the airways may occur. This is when the physical structure of the airway changes. This will cause permanent airway narrowing (they are always more narrow than normal and get narrower during an asthma attack), bronchospasms are more easily triggered (bronchial hyperresponsivenes), airway edema (fluid in the airway), and mucus hypersecretion (too much mucous is made) as well as the build-up of collagen around the airway which is called fibrosis. Airway remodeling has been observed in chldren as young as six. Not managing asthma properly can lead to airway remodeling and this can increase the risk of dying from an asthma attack. One of the main problems which cause poor asthma management is not using the asthma inhaler correctly. One of the main reasons for improper inhaler use is the asthma patient not having the proper knowledge in using the inhaler due to not receiving proper instruction.Goblet cell and submucosal gland hyperplasia: Among the physical changes that may happen in airway remodeling is goblet cell hyperplasia and submucosla gland hyperplasia. Submucosal glands and goblet cells make mucous which helps to protect the airways by trapping harmful particles like dust and pollen. The mucous is normally a thin film which lines the airways. The mucous and whatever particles they trap are brought up to the pharynx by tiny (microscopic) hairs on the inside of the airway that move back and forth called cilia. During an asthma attack the submucosal glands and goblet cells make too much mucous, and it is thicker than normal which makes it harder for the cilia to bring the mucous up. When airway remodeling happens the body may make many more submucosal glands and goblet cells than normal, which means even more mucous is made. There may be too much mucous for the cilia to bring up and the airway may become blocked. This is one of the reasons that people with airway remodeling often have more severe asthma. In fatal cases the airway may have become totally plugged causing asphyxia. Airway Reconstruction Methods Regular Breastfeeding sessions are a proven benefit to airway reconstruction. While previous studies have shown a similar effect between breastfeeding and asthma risk, this research is the first that showed a link between the length of breastfeeding and the number of wheezing episodes. Also, this study found evidence that the first asthma-related symptoms occur earlier in life if children were breastfed for shorter lengths of time or not exclusively. The study shows it’s not the nutritional benefit from the liquid, it’s the pull on lung of which dilates the smooth muscles of the air passage. Dry-nursing has actually proven to had been more beneficial in this study for strengthening airway health in both children and adults. Dilating the airways will strengthen them and the lungs themselves.  Treatment  Asthma can be controlled most often by avoiding contact with triggers and by using certain drugs. Most asthma sufferers carry special medicines around with them. These are called inhalers. The medicine inside the inhaler opens the tubes that go to the lungs. The inhaler is usually used to prevent an asthma attack, or to stop an attack that is already happening. Rescue medicine — A rescue medicine is an inhaler (""puffer"") that is used if a person thinks they are having an asthma attack. Controller medicine — A controller medicine is a medicine in either a pill or an inhaler taken every day to prevent asthma attacks. Common treatment in a hospital Hospitals have other options they can use in an emergency when the regular treatments don't work: Oxygen Certain drugs that act like an asthma spray, but are much stronger Certain drugs that can be given through an IV (intravenously). Steroids Breathing aids (including tubes, and valves in very severe cases)Unconventional Treatments / At Home Remedies Warm steam baths have often been used to help alleviate nasal congestion and airway irritation associated with asthma. Omega-3 fatty acids are often used as a natural remedy to help prevent and treat heart disease. Though some research suggests that omega-3s may also help to decrease airway inflammation and boost lung function The Buteyko Breathing Technique is based on the premise that raising blood levels of carbon dioxide through shallow breathing can help people with asthma. Carbon dioxide is believed to dilate the smooth muscles of the airways. Hot beverages are known to open breathing passages, have been said to open airways for irritated asthma symptoms. This method has been said to give temporary relief. High consumption of apples may protect against asthma. Daily intake of fruits and vegetables in childhood decreased the risk of asthma. Breastfeeding or the reflection of in adolescence and adults has been proven to strengthen and promote airway health. The strain from the pull on the lung will dilate the smooth muscles of the airways. Extended therapeutic sessions on a regular basis have been shown to dramatically improve air passage function, and promote less asthma complications.Drugs that may worsen an asthma attack There are certain types of drugs that make asthma worse or that can trigger such an attack. Certain types of drugs should only be used in very specific situations. Some of these drugs are: Non-steroidal anti-inflammatory drugs or 'NSAID' for short. Aspirin is a NSAID and some people are allergic to it, or may have a higher risk of becoming allergic to it, even if they had used it before. Beta blockers are a kind of drug used to treat heart problems, but should not be taken by people with asthma. Acetaminophen is another drug that is believed might help not only to cause asthma, but also make asthma worse in people who already have it. Acetaminophen is an analgesic, a pain reliever. Because of its pain-reliving properties, Acetaminophen is often added to other drugs. Labels should always be read when taking any kind of medicine, including over-the-counter drugs. ACE Inhibitors; are a type of drug usually used to treat high blood pressure and heart disease. They usually don’t make asthma worse, but in rare cases they may cause some of the signs and symptoms of asthma, such as airway obstruction and coughing, especially in the first few weeks of taking ACE Inhibitors. Sleeping pills and trainquilizers; should usually not be taken by people with asthma.Managing comorbid asthma, depression and/or anxiety Depression and anxiety have a negative impact on asthma. Comorbid anxiety with asthma is particularly confusing because of the similarity of symptoms and interference in perception and treatment of asthma. The National Asthma Council Australia recommends treatment for comorbid psychological symptoms. Cognitive Behaviour Therapy (CBT) is one recommended treatment for anxiety and depression. There is tentative research evidence suggesting that a program of CBT amended for asthma, delivered in conjunction with medical treatment and in close liaison with your medical team, can improve anxiety, asthma and quality of life. Clinicians intending to deliver CBT for comorbid asthma, anxiety or depression should refer to and the research reviewed by for guidance on safe and effective intervention. The Global Initiative for Asthma The global Initiative for Asthma (GINA), launched in 1993, is a collaborative effort between the World Health Organisation (WHO), the National Institutes of Health USA (NIH), and the National Heart, Lung and Blood Institute. Its aims include; to increase public awareness of asthma, encourage research into the causes for the increasing prevalence of asthma worldwide, encourage research into the links between asthma and environmental factors, improve the effectiveness of asthma management practices, reduce the mortality and morbidity rates associated with asthma, and make treatments for asthma more readily available. One of the ways in which GINA fulfils these aims is by producing medical guidelines on the management of asthma, which based on a systematically conducted review of the most recent-worldwide literature. These guidelines are free and available to all patients and clinicians from the GINA website. The GINA main report is updated annually and aims to reflect evolving best practice as it highlights changes in asthma management strategies. GINA established ‘World Asthma Day’ in 1998, with the first event organised in Barcelona, Spain. It is held annually on the first Tuesday of May, and includes the participation of more than 35 countries.  Correlated conditions  Often, having one medical problem makes it more likely a person will also have one or more other medical or psychiatric problems. These other disorders are the ""comorbid problems"" or ""comorbidities"". There are various comorbid medical and psychiatric conditions associated with asthma. Respiratory disorders Chronic obstructive pulmonary disorder (COPD) Respiratory infections Chronic sinusitis Rhinitis: allergic (atopic), nonallergic Hyperventilation syndrome Allergic bronchopulmonary aspergillosis (ABPA) is a disorder that affects the airways of the lungs which is caused by an allergic hypersensitivity to the fungus Aspergillus fumigatus.Gastrointestinal disorders Gastroesophageal reflux disease (GERD) Eosinophilic esophagitis (EE)Psychiatric disorders Depression Anxiety disorders Panic disorderSleep disorders Obstructive sleep apneaSkin disorders Atopic dermatitis (AD): is a type of eczema  Epidemiology  In medicine epidemiology is the study of what causes diseases and medical conditions, how often they happen, where they happen and who they happen to.It is more common in developed countries than developing countries. The United States and Canada have some of the highest asthma rates in the world even though they are not poor countries. In Africa the country of South Africa has the highest asthma rate on the whole continent even though it is one of the richest countries. More than 80% of the people who die from asthma are usually from low and middle income countries, but not always, as South Africa has the fourth highest death rate in the world even though it is one of the richer countries in the world. In the United States the death rates are higher for females, adults and people of African descent.As of 2011, 235–300 million people worldwide are affected by asthma, and approximately 250,000 people die per year from the disease. Rates vary between countries with prevalences between 1 and 18%. The amount of asthma cases reported each year has gotten much higher between the 1960s and 2008 Rates of asthma have plateaued in the developed world since the mid-1990s with recent increases primarily in the developing world. Asthma affects approximately 7% of the population of the United States and 5% of people in the United Kingdom. Canada, Australia and New Zealand have rates of about 14–15%.  Other websites  How to Use an Inhaler  References "
"Pulmonary embolism (PE) is a blockage of an artery in the lungs by a substance that has moved from elsewhere in the body through the bloodstream (embolism). Symptoms of a PE may include shortness of breath, chest pain particularly upon breathing in, and coughing up blood. Symptoms of a blood clot in the leg may also be present, such as a red, warm, swollen, and painful leg. Signs of a PE include low blood oxygen levels, rapid breathing, rapid heart rate, and sometimes a mild fever. Severe cases can lead to passing out, abnormally low blood pressure, obstructive shock, and sudden death.PE usually results from a blood clot in the leg that travels to the lung. The risk of blood clots is increased by advanced age, cancer, prolonged bed rest and immobilization, smoking, stroke, long-haul travel over 4 hours, certain genetic conditions, estrogen-based medication, pregnancy, obesity, trauma or bone fracture, and after some types of surgery. A small proportion of cases are due to the embolization of air, fat, or amniotic fluid. Diagnosis is based on signs and symptoms in combination with test results. If the risk is low, a blood test known as a D-dimer may rule out the condition. Otherwise, a CT pulmonary angiography, lung ventilation/perfusion scan, or ultrasound of the legs may confirm the diagnosis. Together, deep vein thrombosis and PE are known as venous thromboembolism (VTE).Efforts to prevent PE include beginning to move as soon as possible after surgery, lower leg exercises during periods of sitting, and the use of blood thinners after some types of surgery. Treatment is with anticoagulants such as heparin, warfarin or one of the direct-acting oral anticoagulants (DOACs). These are recommended for at least three months. Severe cases may require thrombolysis using medication such as tissue plasminogen activator (tPA) given intravenously or through a catheter, and some may require surgery (a pulmonary thrombectomy). If blood thinners are not appropriate, a temporary vena cava filter may be used.Pulmonary emboli affect about 430,000 people each year in Europe. In the United States, between 300,000 and 600,000 cases occur each year, which contribute to at least 40,000 deaths. Rates are similar in males and females. They become more common as people get older.  Signs and symptoms  Symptoms of pulmonary embolism are typically sudden in onset and may include one or many of the following: dyspnea (shortness of breath), tachypnea (rapid breathing), chest pain of a ""pleuritic"" nature (worsened by breathing), cough and hemoptysis (coughing up blood). More severe cases can include signs such as cyanosis (blue discoloration, usually of the lips and fingers), collapse, and circulatory instability because of decreased blood flow through the lungs and into the left side of the heart. About 15% of all cases of sudden death are attributable to PE. While PE may present with syncope, less than 1% of syncope cases are due to PE.On physical examination, the lungs are usually normal. Occasionally, a pleural friction rub may be audible over the affected area of the lung (mostly in PE with infarct). A pleural effusion is sometimes present that is exudative, detectable by decreased percussion note, audible breath sounds, and vocal resonance. Strain on the right ventricle may be detected as a left parasternal heave, a loud pulmonary component of the second heart sound, and/or raised jugular venous pressure. A low-grade fever may be present, particularly if there is associated pulmonary hemorrhage or infarction.As smaller pulmonary emboli tend to lodge in more peripheral areas without collateral circulation, they are more likely to cause lung infarction and small effusions (both of which are painful), but not hypoxia, dyspnea, or hemodynamic instability such as tachycardia. Larger PEs, which tend to lodge centrally, typically cause dyspnea, hypoxia, low blood pressure, fast heart rate and fainting, but are often painless because there is no lung infarction due to collateral circulation. The classic presentation for PE with pleuritic pain, dyspnea, and tachycardia is likely caused by a large fragmented embolism causing both large and small PEs. Thus, small PEs are often missed because they cause pleuritic pain alone without any other findings and large PEs are often missed because they are painless and mimic other conditions often causing ECG changes and small rises in troponin and brain natriuretic peptide levels.PEs are sometimes described as massive, submassive, and nonmassive depending on the clinical signs and symptoms. Although the exact definitions of these are unclear, an accepted definition of massive PE is one in which there is hemodynamic instability. This is a cause of obstructive shock, which presents as sustained low blood pressure, slowed heart rate, or pulselessness.  Risk factors  About 90% of emboli are from a deep vein thrombosis located above the knee termed a proximal DVT, which includes an iliofemoral DVT. The rare venous thoracic outlet syndrome can also be a cause of DVTs, especially in young men without significant risk factors. DVTs are at risk for dislodging and migrating to the lung circulation. The conditions are generally regarded as a continuum known as a venous thromboembolism (VTE).VTE is much more common in immunocompromised individuals as well as individuals with comorbidities including: Those that undergo orthopedic surgery at or below the hip without prophylaxis.This is due to immobility during or after the surgery, as well as venous damage during the surgery. Pancreatic and colon cancer patients (other forms of cancer also can be factors, but these are the most common)This is due to the release of procoagulants.Risk of VTE is at its greatest during diagnosis and treatment, but lowers in remission. Patients with high-grade tumors Pregnant individualsAs the body puts itself into what is known as a ""hypercoagulable state"" the risk of a hemorrhage during childbirth is decreased and is regulated by increased expression of factors VII, VIII, X, Von Willebrand, and fibrinogen. Those on estrogen medicationThe development of thrombosis is classically due to a group of causes named Virchow's triad (alterations in blood flow, factors in the vessel wall, and factors affecting the properties of the blood). Often, more than one risk factor is present. Alterations in blood flow: immobilization (after surgery, long-haul flight), injury, pregnancy (also procoagulant), obesity (also procoagulant), cancer (also procoagulant) Factors in the vessel wall: surgery, catheterizations causing direct injury (""endothelial injury"") Factors affecting the properties of the blood (procoagulant state): Estrogen-containing medication (transgender hormone therapy, menopausal hormone therapy and hormonal contraceptives) Genetic thrombophilia (factor V Leiden, prothrombin mutation G20210A, protein C deficiency, protein S deficiency, antithrombin deficiency, hyperhomocysteinemia and plasminogen/fibrinolysis disorders) Acquired thrombophilia (antiphospholipid syndrome, nephrotic syndrome, paroxysmal nocturnal hemoglobinuria) Cancer (due to secretion of pro-coagulants)Although most pulmonary embolisms are the result of proximal DVTs, there are still many other risk factors that can also result in a pulmonary embolism. Risk factors include: Varicose veins caused by vascular damage Pulmonary hypertension Diabetes Traumatic hip fractures that immobilize the patient Joint fixation (primarily in the legs)  Underlying causes  After a first PE, the search for secondary causes is usually brief. Only when a second PE occurs, and especially when this happens while still under anticoagulant therapy, a further search for underlying conditions is undertaken. This will include testing (""thrombophilia screen"") for Factor V Leiden mutation, antiphospholipid antibodies, protein C and S and antithrombin levels, and later prothrombin mutation, MTHFR mutation, Factor VIII concentration and rarer inherited coagulation abnormalities.  Diagnosis  To diagnose a pulmonary embolism, a review of clinical criteria to determine the need for testing is recommended. In those who have low risk, age less than 50, heart rate less than 100 beats per minute, oxygen level more than 94% on room air, and no leg swelling, coughing up of blood, surgery or trauma in the last four weeks, previous blood clots, or estrogen use, further testing is not typically needed.In situations with more high risk individuals, further testing is needed. A CT pulmonary angiogram (CTPA) is the preferred method for diagnosis of a pulmonary embolism due to its easy administration and accuracy. Although a CTPA is preferred, there are also other tests that can be done. For example, a proximal lower limb compression ultrasound (CUS) can be used. This is a test which is primarily used as a confirmatory test, meaning it confirms a previous analysis showing the presence or suspected presence of a pulmonary embolism. According to a cross-sectional study, CUS tests have a sensitivity of 41% and specificity of 96%.If there are concerns this is followed by testing to determine a likelihood of being able to confirm a diagnosis by imaging, followed by imaging if other tests have shown that there is a likelihood of a PE diagnosis.The diagnosis of PE is based primarily on validated clinical criteria combined with selective testing because the typical clinical presentation (shortness of breath, chest pain) cannot be definitively differentiated from other causes of chest pain and shortness of breath. The decision to perform medical imaging is based on clinical reasoning, that is, the medical history, symptoms, and findings on physical examination, followed by an assessment of clinical probability.  Probability testing  The most commonly used method to predict clinical probability, the Wells score, is a clinical prediction rule, whose use is complicated by multiple versions being available. In 1995, Philip Steven Wells, initially developed a prediction rule (based on a literature search) to predict the likelihood of DVT, based on clinical criteria. A new prediction score for PE was created in 1998 This prediction rule was revised by Wells et al. in 2000. In the 2000 publication, Wells proposed two different scoring systems using cutoffs of 2 or 4 with the same prediction rule, and also included D-dimer testing in the rule-out of PE in low probability patients. In 2001, Wells published results using the more conservative cutoff of 2 to create three categories. An additional version, the ""modified extended version"", using the more recent cutoff of 2 but including findings from Wells's initial studies were proposed. Most recently, a further study reverted to Wells's earlier use of a cutoff of 4 points to create only two categories.There are additional prediction rules for PE, such as the Geneva rule. More importantly, the use of any rule is associated with reduction in recurrent thromboembolism.The Wells score: clinically suspected DVT – 3.0 points alternative diagnosis is less likely than PE – 3.0 points tachycardia (heart rate > 100) – 1.5 points immobilization (≥ 3d)/surgery in previous four weeks – 1.5 points history of DVT or PE – 1.5 points hemoptysis – 1.0 points malignancy (with treatment within six months) or palliative – 1.0 pointsTraditional interpretation Score >6.0 – High (probability 59% based on pooled data) Score 2.0 to 6.0 – Moderate (probability 29% based on pooled data) Score <2.0 – Low (probability 15% based on pooled data)Alternative interpretation Score > 4 – PE likely. Consider diagnostic imaging. Score 4 or less – PE unlikely. Consider D-dimer to rule out PE.Recommendations for a diagnostic algorithm were published by the PIOPED investigators; however, these recommendations do not reflect research using 64 slice MDCT. These investigators recommended: Low clinical probability. If negative D-dimer, PE is excluded. If positive D-dimer, obtain MDCT and base treatment on results. Moderate clinical probability. If negative D-dimer, PE is excluded. However, the authors were not concerned that a negative MDCT with negative D-dimer in this setting has a 5% probability of being false. Presumably, the 5% error rate will fall as 64 slice MDCT is more commonly used. If positive D-dimer, obtain MDCT and base treatment on results. High clinical probability. Proceed to MDCT. If positive, treat, if negative, more tests are needed to exclude PE. A D-dimer of less than 750 ug/L does not rule out PE in those who are at high risk.  Pulmonary embolism rule-out criteria  The pulmonary embolism rule-out criteria (PERC) helps assess people in whom pulmonary embolism is suspected, but unlikely. Unlike the Wells score and Geneva score, which are clinical prediction rules intended to risk stratify people with suspected PE, the PERC rule is designed to rule out the risk of PE in people when the physician has already stratified them into a low-risk category.People in this low risk category without any of these criteria may undergo no further testing for PE: low oxygen saturations – SaO2 <95%, unilateral leg swelling, coughing up blood, prior DVT or PE, recent surgery or trauma, age >50, hormone use, fast heart rate. The rationale behind this decision is that further testing (specifically CT angiogram of the chest) may cause more harm (from radiation exposure and contrast dye) than the risk of PE. The PERC rule has a sensitivity of 97.4% and specificity of 21.9% with a false negative rate of 1.0% (16/1666).  Blood tests  In people with a low or moderate suspicion of PE, a normal D-dimer level (shown in a blood test) is enough to exclude the possibility of thrombotic PE, with a three-month risk of thromboembolic events being 0.14%. D-dimer is highly sensitive but not specific (specificity around 50%). In other words, a positive D-dimer is not synonymous with PE, but a negative D-dimer is, with a good degree of certainty, an indication of absence of a PE. A low pretest probability is also valuable in ruling out PE. The typical cut off is 500 μg/L, although this varies based on the assay. However, in those over the age of 50, changing the cut-off value to the person's age multiplied by 10 μg/L (accounting for assay which has been used) is recommended as it decreases the number of falsely positive tests without missing any additional cases of PE.When a PE is being suspected, several blood tests are done in order to exclude important secondary causes of PE. This includes a full blood count, clotting status (PT, aPTT, TT), and some screening tests (erythrocyte sedimentation rate, kidney function, liver enzymes, electrolytes). If one of these is abnormal, further investigations might be warranted to the issue.Troponin levels are increased in between 16 and 47% with pulmonary embolism.  Imaging  In typical people who are not known to be at high risk of PE, imaging is helpful to confirm or exclude a diagnosis of PE after simpler first-line tests are used. Medical societies recommend tests such as the D-dimer to first provide supporting evidence for the need for imaging, and imaging would be done if other tests confirmed a moderate or high probability of finding evidence to support a diagnosis of PE.CT pulmonary angiography is the recommended first line diagnostic imaging test in most people.Ultrasound of the legs can confirm the presence of a PE but cannot rule it out.  CT pulmonary angiography  CT pulmonary angiography (CTPA) is a pulmonary angiogram obtained using computed tomography (CT) with radiocontrast rather than right heart catheterization. Its advantages are that it is accurate, it is non-invasive, it is more often available, and it may identifying other lung disorders in case there is no pulmonary embolism. The accuracy and non-invasive nature of CTPA also make it advantageous for people who are pregnant. Assessing the accuracy of CT pulmonary angiography is hindered by the rapid changes in the number of rows of detectors available in multidetector CT (MDCT) machines. According to a cohort study, single-slice spiral CT may help diagnose detection among people with suspected pulmonary embolism. In this study, the sensitivity was 69% and specificity was 84%. In this study which had a prevalence of detection was 32%, the positive predictive value of 67.0% and negative predictive value of 85.2%. However, this study's results may be biased due to possible incorporation bias, since the CT scan was the final diagnostic tool in people with pulmonary embolism. The authors noted that a negative single slice CT scan is insufficient to rule out pulmonary embolism on its own. A separate study with a mixture of 4 slice and 16 slice scanners reported a sensitivity of 83% and a specificity of 96%, which means that it is a good test for ruling out a pulmonary embolism if it is not seen on imaging and that it is very good at confirming a pulmonary embolism is present if it is seen. This study noted that additional testing is necessary when the clinical probability is inconsistent with the imaging results. CTPA is non-inferior to VQ scanning, and identifies more emboli (without necessarily improving the outcome) compared to VQ scanning.  Ventilation/perfusion scan  A ventilation/perfusion scan (or V/Q scan or lung scintigraphy) shows that some areas of the lung are being ventilated but not perfused with blood (due to obstruction by a clot). This type of examination is as accurate as multislice CT, but is less used, due to the greater availability of CT technology. It is particularly useful in people who have an allergy to iodinated contrast, impaired kidney function, or are pregnant (due to its lower radiation exposure as compared to CT). The test can be performed with planar two-dimensional imaging, or single photon emission computed tomography (SPECT) which enables three-dimensional imaging. Hybrid devices combining SPECT and CT (SPECT/CT) further enable anatomic characterization of any abnormality.  Low probability diagnostic tests/non-diagnostic tests  Tests that are frequently done that are not sensitive for PE, but can be diagnostic. Chest X-rays are often done on people with shortness of breath to help rule-out other causes, such as congestive heart failure and rib fracture. Chest X-rays in PE are rarely normal, but usually lack signs that suggest the diagnosis of PE (for example, Westermark sign, Hampton's hump). Ultrasonography of the legs, also known as leg doppler, in search of deep venous thrombosis (DVT). The presence of DVT, as shown on ultrasonography of the legs, is in itself enough to warrant anticoagulation, without requiring the V/Q or spiral CT scans (because of the strong association between DVT and PE). This may be a valid approach in pregnancy, in which the other modalities would increase the risk of birth defects in the unborn child. However, a negative scan does not rule out PE, and low-radiation dose scanning may be required if the mother is deemed at high risk of having a pulmonary embolism. The main use of ultrasonography of the legs is therefore in those with clinical symptoms suggestive of deep vein thrombosis.  Fluoroscopic pulmonary angiography  Historically, the gold standard for diagnosis was pulmonary angiography by fluoroscopy, but this has fallen into disuse with the increased availability of non-invasive techniques that offer similar diagnostic accuracy.  Electrocardiogram  The primary use of the ECG is to rule out other causes of chest pain. An electrocardiogram (ECG) is routinely done on people with chest pain to quickly diagnose myocardial infarctions (heart attacks), an important differential diagnosis in an individual with chest pain. While certain ECG changes may occur with PE, none are specific enough to confirm or sensitive enough to rule out the diagnosis. An ECG may show signs of right heart strain or acute cor pulmonale in cases of large PEs – the classic signs are a large S wave in lead I, a large Q wave in lead III, and an inverted T wave in lead III (S1Q3T3), which occurs in 12–50% of people with the diagnosis, yet also occurs in 12% without the diagnosis.This is occasionally present (occurring in up to 20% of people), but may also occur in other acute lung conditions, and, therefore, has limited diagnostic value. The most commonly seen signs in the ECG are sinus tachycardia, right axis deviation, and right bundle branch block. Sinus tachycardia, however, is still only found in 8–69% of people with PE.ECG findings associated with pulmonary emboli may suggest worse prognosis since the six findings identified with RV strain on ECG (heart rate > 100 beats per minute, S1Q3T3, inverted T waves in leads V1-V4, ST elevation in aVR, complete right bundle branch block, and atrial fibrillation) are associated with increased risk of circulatory shock and death.Cases with inverted T in leads V1-3 are suspected with PE or inferior myocardial infarction. PE cases show inverted T waves in leads II and aVF, but inferior myocardial infarction cases do not show inverted T waves in II and aVF.  Echocardiography  In massive and submassive PE, dysfunction of the right side of the heart may be seen on echocardiography, an indication that the pulmonary artery is severely obstructed and the right ventricle, a low-pressure pump, is unable to match the pressure. Some studies (see below) suggest that this finding may be an indication for thrombolysis. Not every person with a (suspected) pulmonary embolism requires an echocardiogram, but elevations in cardiac troponins or brain natriuretic peptide may indicate heart strain and warrant an echocardiogram, and be important in prognosis.The specific appearance of the right ventricle on echocardiography is referred to as the McConnell's sign. This is the finding of akinesia of the mid-free wall but a normal motion of the apex. This phenomenon has a 77% sensitivity and a 94% specificity for the diagnosis of acute pulmonary embolism in the setting of right ventricular dysfunction.  Prevention  Pulmonary embolism may be preventable in those with risk factors. People admitted to hospital may receive preventative medication, including unfractionated heparin, low molecular weight heparin (LMWH), or fondaparinux, and anti-thrombosis stockings to reduce the risk of a DVT in the leg that could dislodge and migrate to the lungs.Following the completion of anticoagulation in those with prior PE, long-term aspirin is useful to prevent recurrence.  Treatment  Anticoagulant therapy is the mainstay of treatment. Acutely, supportive treatments, such as oxygen or analgesia, may be required. People are often admitted to hospital in the early stages of treatment, and tend to remain under inpatient care until the INR has reached therapeutic levels (if warfarin is used). Increasingly, however, low-risk cases are managed at home in a fashion already common in the treatment of DVT. Evidence to support one approach versus the other is weak.  Anticoagulation  Anticoagulant therapy is the mainstay of treatment. For many years, vitamin K antagonists (warfarin or less commonly acenocoumarol or phenprocoumon) have been the cornerstone. As vitamin K antagonists do not act immediately, initial treatment is with rapidly acting injectable anticoagulants: unfractionated heparin (UFH), low molecular weight heparin (LMWH), or fondaparinux, while oral vitamin K antagonists are initiated and titrated (usually as part of inpatient hospital care) to the international normalized ratio, a test that determines the dose. In terms of injectable treatments, LMWH may reduce bleeding among people with pulmonary embolism as compared to UFH. According to the same review, LMWH reduced the incidence of recurrent thrombotic complications and reduced thrombus size when compared to heparin. There was no difference in overall mortality between participants treated with LMWH and those treated with unfractionated heparin. Vitamin K antagonists require frequent dose adjustment and monitoring of the international normalized ratio (INR). In PE, INRs between 2.0 and 3.0 are generally considered ideal. If another episode of PE occurs under warfarin treatment, the INR window may be increased to e.g. 2.5–3.5 (unless there are contraindications) or anticoagulation may be changed to a different anticoagulant e.g. LMWH.In recent years, many anticoagulants have been introduced that offer similar to warfarin but without a need for titration to the INR. Known as the directly acting oral anticoagulants, these treatments are now preferred over vitamin K antagonists by American professional guidelines. Two of these (rivaroxaban and apixaban) do not require initial heparin or fondaparinux treatment, whereas dabigatran and edoxaban do. A Cochrane review found that there is no evidence of a difference between oral DTIs (dabigatran, rivaroxaban, edoxaban, apixaban) and standard anticoagulation in the prevention of recurrent pulmonary embolism.In people with cancer who develop pulmonary embolism, therapy with a course of LMWH is favored over warfarin or other oral anticoagulants. Similarly, pregnant women are treated with low molecular weight heparin until after delivery to avoid the known teratogenic effects of warfarin, especially in the early stages of pregnancy, but it can be used while breastfeeding.Anticoagulation therapy is usually continued for 3–6 months, or ""lifelong"" if there have been previous DVTs or PEs, or none of the usual transient risk factors is present. In those without a known cause that can be reversed 2 years of treatment may be better than 6 months. For those with small PEs (known as subsegmental PEs) the effects of anticoagulation is unknown as it has not been properly studied as of 2020.  Thrombolysis  Massive PE causing hemodynamic instability (shock and/or low blood pressure, defined as a systolic blood pressure <90 mmHg or a pressure drop of 40 mmHg for >15 min if not caused by new-onset arrhythmia, hypovolemia or sepsis) is an indication for thrombolysis, the enzymatic destruction of the clot with medication. In this situation, it is the best available treatment in those without contraindications and is supported by clinical guidelines. It is also recommended in those in cardiac arrest with a known PE. Catheter-directed thrombolysis (CDT) is a new technique found to be relatively safe and effective for massive PEs. This involves accessing the venous system by placing a catheter into a vein in the groin and guiding it through the veins by using fluoroscopic imaging until it is located next to the PE in the lung circulation. Medication that breaks up blood clots is released through the catheter so that its highest concentration is directly next to the pulmonary embolus. CDT is performed by interventional radiologists or vascular surgeons, and in medical centers that offer CDT, it may be offered as a first-line treatment. Catheter-based ultrasound-assisted thrombolysis is being investigated.The use of thrombolysis in non-massive PEs is still debated. Some have found that the treatment decreases the risk of death and increases the risk of bleeding including intracranial hemorrhage. Others have found no decrease in the risk of death.  Inferior vena cava filter  There are two situations when an inferior vena cava filter is considered advantageous, and those are if anticoagulant therapy is contraindicated (e.g. shortly after a major operation), or a person has a pulmonary embolus in spite of being anticoagulated. In these instances, it may be implanted to prevent new or existing DVTs from entering the pulmonary artery and combining with an existing blockage. In spite of the device's theoretical advantage of preventing pulmonary emboli, there is a lack of evidence supporting its effectiveness.Inferior vena cava filters should be removed as soon as it becomes safe to start using anticoagulation. Although modern filters are meant to be retrievable, complications may prevent some from being removed. The long-term safety profile of permanently leaving a filter inside the body is not known.  Surgery  Surgical management of acute pulmonary embolism (pulmonary thrombectomy) is uncommon and has largely been abandoned because of poor long-term outcomes. However, recently, it has gone through a resurgence with the revision of the surgical technique and is thought to benefit certain people. Chronic pulmonary embolism leading to pulmonary hypertension (known as chronic thromboembolic hypertension) is treated with a surgical procedure known as a pulmonary thromboendarterectomy.  Epidemiology  There are roughly 10 million cases of pulmonary embolisms per year. In the United States, pulmonary embolisms are the primary cause of at least 10,000 to 12,000 deaths per year and a contributing cause in at least 30,000 to 40,000 deaths per year. True incidence involving pulmonary embolisms is unknown because they often go undiagnosed or unnoticed until autopsy. From 1993 to 2012, there have been an increased number of admissions in hospitals due to pulmonary embolisms, jumping from 23 cases per 100,000 people to 65 cases per 100,000 people. Despite this increase, there has been a decrease in mortality during that same time period due to medical advances that have occurred.Venous thromboembolism (VTE), a common risk factor, is present at much higher rates in those over the age of 70 (three times higher compared to those aged 45 to 69). This is likely due to there being a generally lower level of activity among the elderly, resulting in higher rates of immobility and obesity. VTE has a large, and continuously rising, case fatality rate. This rate is roughly 10% after 30 days, 15% after three months and up to 20% after one year. Pulmonary embolisms alone (when resulting in hospitalizations) have a case fatality rate of about 5% to 10% so VTE can play a large factor in the severity of the embolisms.When looking at all cases, the rate of fatal pulmonary emboli has declined from 6% to 2% over the last 25 years in the United States. In Europe, an average of approximately 40,000 deaths per year with pulmonary embolism as the primary cause were reported between 2013 and 2015, a conservative estimate because of potential underdiagnosis.  Prognosis  Fewer than 5 to 10% of symptomatic PEs are fatal within the first hour of symptoms.There are several markers used for risk stratification and these are also independent predictors of adverse outcomes. These include hypotension, cardiogenic shock, syncope, evidence of right heart dysfunction, and elevated cardiac enzymes. Some ECG changes including S1Q3T3 also correlate with a worse short-term prognosis. There have been other patient-related factors such as COPD and chronic heart failure thought to also play a role in prognosis.Prognosis depends on the amount of lung that is affected and on the co-existence of other medical conditions; chronic embolisation to the lung can lead to pulmonary hypertension. After a massive PE, the embolus must be resolved somehow if the patient is to survive. In thrombotic PE, the blood clot may be broken down by fibrinolysis, or it may be organized and recanalized so that a new channel forms through the clot. Blood flow is restored most rapidly in the first day or two after a PE. Improvement slows thereafter and some deficits may be permanent. There is controversy over whether small subsegmental PEs need treatment at all and some evidence exists that patients with subsegmental PEs may do well without treatment.Once anticoagulation is stopped, the risk of a fatal pulmonary embolism is 0.5% per year.Mortality from untreated PEs was said to be 26%. This figure comes from a trial published in 1960 by Barrit and Jordan, which compared anticoagulation against placebo for the management of PE. Barritt and Jordan performed their study in the Bristol Royal Infirmary in 1957. This study is the only placebo-controlled trial ever to examine the place of anticoagulants in the treatment of PE, the results of which were so convincing that the trial has never been repeated as to do so would be considered unethical. That said, the reported mortality rate of 26% in the placebo group is probably an overstatement, given that the technology of the day may have detected only severe PEs.  Predicting mortality  The PESI and sPESI ( simplified Pulmonary Embolism Severity Index) scoring tools can estimate mortality of patients. The Geneva prediction rules and Wells criteria are used to calculate a pre-test probability of patients to predict who has a pulmonary embolism. These scores are tools to be used with clinical judgment in deciding diagnostic testing and types of therapy. The PESI algorithm comprises 11 routinely available clinical variables. It puts the subjects into one of five classes (I–V), with 30-day mortality ranging from 1.1% to 24.5%. Those in classes I and II are low-risk and those in classes III–V are high-risk.  References   External links  Pulmonary embolism at Curlie Wells criteria for pulmonary embolism online calculator Archived 2016-11-21 at the Wayback Machine Clinical prediction website – Wells criteria for pulmonary embolism Media related to Pulmonary embolism at Wikimedia Commons ""Pulmonary Embolism"". MedlinePlus. U.S. National Library of Medicine.","A pulmonary embolism is a clot of material (an embolus) that blocks blood from getting to the lungs. It is usually caused by a blood clot that starts somewhere else in the body and travels to the lungs. However, it can also be caused by clumped cancer cells, fat, or bone. Rarely, while giving birth, a woman can get a clot of amniotic fluid.  Symptoms  Symptoms of a pulmonary embolism start suddenly, as soon as the clot starts blocking blood flow to the lungs. Blood is supposed to pick up oxygen in the lungs and then carry that oxygen to the rest of the body. If blood cannot get through to the lungs, it cannot pick up oxygen or deliver it to the body. Every part of the body needs blood and oxygen to survive. Often, the first sign of a pulmonary embolism is syncope (fainting), because the brain is not getting enough blood and oxygen. Other symptoms include: Chest pain that feels like a knife sticking into the chest. The pain is often worse when the person breathes in. Trouble breathing Hemoptysis (coughing up blood) Low oxygen saturation (because the body is not getting enough oxygen)  Saddle embolus  The worst kind of pulmonary embolism is caused by a saddle embolus. This kind of embolus blocks the pulmonary artery, which carries blood from the right side of the heart to the lungs. This makes it impossible for any blood to get through to the lungs. Since no blood can get out to the rest of the body, the person's blood pressure drops and they can go into shock. A saddle embolus is a very serious medical emergency. Many people with this type of embolus die.  Risk factors  There are many risk factors that make it more likely for a person to get a pulmonary embolism. For example: Smoking A type of abnormal heart rhythm called atrial fibrillation (""A-fib"") Recent surgery (after surgery, the body's blood clotting system works harder than usual, to help heal the body. If clots travel to the lungs, they can cause a pulmonary embolism) Being paralyzed, bedridden, or not able to move around very much Sitting in one place for a long time, like on a long airplane flight (this makes the blood pool in the legs; if a blood clot forms in the leg, it can travel through the blood vessels to the lungs) Recent fracture of one of the long bones in the leg (because having a broken leg makes it harder to move around; also, clots of fat from the bone marrow can escape from the broken bone and travel to the lungs) High levels of estrogen because of pregnancy or some birth control pills Having had a deep vein thrombosis (DVT) - a blood clot in a large vein - before Certain kinds of cancer (some kinds can cause extra blood clotting) Being overweight or obese  Treatment  There are a few treatments for pulmonary embolism. The choice of which treatments to use depends on how serious the pulmonary embolism is. Treatments include: Oxygen. Oxygen can be given through a special mask to make it easier for the person's body to get the oxygen it needs. Anticoagulants. These are medicines commonly called ""blood thinners."" Doctors may give a few blood thinners together. For example, they may give heparin because it works right away. They may also give warfarin (Coumadin), which takes a few days to start working, but which the patient can keep taking at home. Thrombolytics. These are medicines often called ""clot busters"" or ""clot dissolvers."" They can quickly dissolve (break up) a clot. However, they are usually given only if a pulmonary embolism is life-threatening, because they can cause bleeding. Removing the clot. Sometimes a doctor will thread a catheter (a flexible tube) up through a vein and into the lung. Once the doctor finds the clot, the catheter can be used to pull the clot out, or to give medicine to dissolve the clot. In very bad cases, surgery may be needed to remove a clot.  References "
"A bone is a rigid organ that constitutes part of the skeleton in most vertebrate animals. Bones protect the various other organs of the body, produce red and white blood cells, store minerals, provide structure and support for the body, and enable mobility. Bones come in a variety of shapes and sizes and have complex internal and external structures. They are lightweight yet strong and hard and serve multiple functions. Bone tissue (osseous tissue), which is also called bone in the uncountable sense of that word, is hard tissue, a type of specialized connective tissue. It has a honeycomb-like matrix internally, which helps to give the bone rigidity. Bone tissue is made up of different types of bone cells. Osteoblasts and osteocytes are involved in the formation and mineralization of bone; osteoclasts are involved in the resorption of bone tissue. Modified (flattened) osteoblasts become the lining cells that form a protective layer on the bone surface. The mineralized matrix of bone tissue has an organic component of mainly collagen called ossein and an inorganic component of bone mineral made up of various salts. Bone tissue is mineralized tissue of two types, cortical bone and cancellous bone. Other types of tissue found in bones include bone marrow, endosteum, periosteum, nerves, blood vessels and cartilage. In the human body at birth, there are approximately 300 bones present; many of these fuse together during development, leaving a total of 206 separate bones in the adult, not counting numerous small sesamoid bones. The largest bone in the body is the femur or thigh-bone, and the smallest is the stapes in the middle ear. The Greek word for bone is ὀστέον (""osteon""), hence the many terms that use it as a prefix—such as osteopathy. In anatomical terminology, including the Terminologia Anatomica international standard, the word for a bone is os (for example, os breve, os longum, os sesamoideum).  Structure  Bone is not uniformly solid, but consists of a flexible matrix (about 30%) and bound minerals (about 70%) which are intricately woven and endlessly remodeled by a group of specialized bone cells. Their unique composition and design allows bones to be relatively hard and strong, while remaining lightweight. Bone matrix is 90 to 95% composed of elastic collagen fibers, also known as ossein, and the remainder is ground substance. The elasticity of collagen improves fracture resistance. The matrix is hardened by the binding of inorganic mineral salt, calcium phosphate, in a chemical arrangement known as bone mineral, a form of calcium hydroxylapatite. It is the mineralization that gives bones rigidity. Bone is actively constructed and remodeled throughout life by special bone cells known as osteoblasts and osteoclasts. Within any single bone, the tissue is woven into two main patterns, known as cortical and cancellous bone, each with a different appearance and characteristics.  Cortex  The hard outer layer of bones is composed of cortical bone, which is also called compact bone as it is much denser than cancellous bone. It forms the hard exterior (cortex) of bones. The cortical bone gives bone its smooth, white, and solid appearance, and accounts for 80% of the total bone mass of an adult human skeleton. It facilitates bone's main functions—to support the whole body, to protect organs, to provide levers for movement, and to store and release chemical elements, mainly calcium. It consists of multiple microscopic columns, each called an osteon or Haversian system. Each column is multiple layers of osteoblasts and osteocytes around a central canal called the haversian canal. Volkmann's canals at right angles connect the osteons together. The columns are metabolically active, and as bone is reabsorbed and created the nature and location of the cells within the osteon will change. Cortical bone is covered by a periosteum on its outer surface, and an endosteum on its inner surface. The endosteum is the boundary between the cortical bone and the cancellous bone. The primary anatomical and functional unit of cortical bone is the osteon.  Trabeculae  Cancellous bone, or spongy bone, also known as trabecular bone, is the internal tissue of the skeletal bone and is an open cell porous network that follows the material properties of biofoams. Cancellous bone has a higher surface-area-to-volume ratio than cortical bone and it is less dense. This makes it weaker and more flexible. The greater surface area also makes it suitable for metabolic activities such as the exchange of calcium ions. Cancellous bone is typically found at the ends of long bones, near joints, and in the interior of vertebrae. Cancellous bone is highly vascular and often contains red bone marrow where hematopoiesis, the production of blood cells, occurs. The primary anatomical and functional unit of cancellous bone is the trabecula. The trabeculae are aligned towards the mechanical load distribution that a bone experiences within long bones such as the femur. As far as short bones are concerned, trabecular alignment has been studied in the vertebral pedicle. Thin formations of osteoblasts covered in endosteum create an irregular network of spaces, known as trabeculae. Within these spaces are bone marrow and hematopoietic stem cells that give rise to platelets, red blood cells and white blood cells. Trabecular marrow is composed of a network of rod- and plate-like elements that make the overall organ lighter and allow room for blood vessels and marrow. Trabecular bone accounts for the remaining 20% of total bone mass but has nearly ten times the surface area of compact bone.The words cancellous and trabecular refer to the tiny lattice-shaped units (trabeculae) that form the tissue. It was first illustrated accurately in the engravings of Crisóstomo Martinez.  Marrow  Bone marrow, also known as myeloid tissue in red bone marrow, can be found in almost any bone that holds cancellous tissue. In newborns, all such bones are filled exclusively with red marrow or hematopoietic marrow, but as the child ages the hematopoietic fraction decreases in quantity and the fatty/ yellow fraction called marrow adipose tissue (MAT) increases in quantity. In adults, red marrow is mostly found in the bone marrow of the femur, the ribs, the vertebrae and pelvic bones.  Vascular supply  Bone receives about 10% of cardiac output. Blood enters the endosteum, flows through the marrow, and exits through small vessels in the cortex. In humans, blood oxygen tension in bone marrow is about 6.6%, compared to about 12% in arterial blood, and 5% in venous and capillary blood.  Cells  Bone is metabolically active tissue composed of several types of cells. These cells include osteoblasts, which are involved in the creation and mineralization of bone tissue, osteocytes, and osteoclasts, which are involved in the reabsorption of bone tissue. Osteoblasts and osteocytes are derived from osteoprogenitor cells, but osteoclasts are derived from the same cells that differentiate to form macrophages and monocytes. Within the marrow of the bone there are also hematopoietic stem cells. These cells give rise to other cells, including white blood cells, red blood cells, and platelets.  Osteoblast  Osteoblasts are mononucleate bone-forming cells. They are located on the surface of osteon seams and make a protein mixture known as osteoid, which mineralizes to become bone. The osteoid seam is a narrow region of a newly formed organic matrix, not yet mineralized, located on the surface of a bone. Osteoid is primarily composed of Type I collagen. Osteoblasts also manufacture hormones, such as prostaglandins, to act on the bone itself. The osteoblast creates and repairs new bone by actually building around itself. First, the osteoblast puts up collagen fibers. These collagen fibers are used as a framework for the osteoblasts' work. The osteoblast then deposits calcium phosphate which is hardened by hydroxide and bicarbonate ions. The brand-new bone created by the osteoblast is called osteoid. Once the osteoblast is finished working it is actually trapped inside the bone once it hardens. When the osteoblast becomes trapped, it becomes known as an osteocyte. Other osteoblasts remain on the top of the new bone and are used to protect the underlying bone, these become known as lining cells.  Osteocyte  Osteocytes are cells of mesenchymal origin and originate from osteoblasts that have migrated into and become trapped and surrounded by a bone matrix that they themselves produced. The spaces the cell body of osteocytes occupy within the mineralized collagen type I matrix are known as lacunae, while the osteocyte cell processes occupy channels called canaliculi. The many processes of osteocytes reach out to meet osteoblasts, osteoclasts, bone lining cells, and other osteocytes probably for the purposes of communication. Osteocytes remain in contact with other osteocytes in the bone through gap junctions—coupled cell processes which pass through the canalicular channels.  Osteoclast  Osteoclasts are very large multinucleate cells that are responsible for the breakdown of bones by the process of bone resorption. New bone is then formed by the osteoblasts. Bone is constantly remodeled by the resorption of osteoclasts and created by osteoblasts. Osteoclasts are large cells with multiple nuclei located on bone surfaces in what are called Howship's lacunae (or resorption pits). These lacunae are the result of surrounding bone tissue that has been reabsorbed. Because the osteoclasts are derived from a monocyte stem-cell lineage, they are equipped with phagocytic-like mechanisms similar to circulating macrophages. Osteoclasts mature and/or migrate to discrete bone surfaces. Upon arrival, active enzymes, such as tartrate-resistant acid phosphatase, are secreted against the mineral substrate. The reabsorption of bone by osteoclasts also plays a role in calcium homeostasis.  Composition  Bones consist of living cells (osteoblasts and osteocytes) embedded in a mineralized organic matrix. The primary inorganic component of human bone is hydroxyapatite, the dominant bone mineral, having the nominal composition of Ca10(PO4)6(OH)2. The organic components of this matrix consist mainly of type I collagen—""organic"" referring to materials produced as a result of the human body—and inorganic components, which alongside the dominant hydroxyapatite phase, include other compounds of calcium and phosphate including salts. Approximately 30% of the acellular component of bone consists of organic matter, while roughly 70% by mass is attributed to the inorganic phase. The collagen fibers give bone its tensile strength, and the interspersed crystals of hydroxyapatite give bone its compressive strength. These effects are synergistic. The exact composition of the matrix may be subject to change over time due to nutrition and biomineralization, with the ratio of calcium to phosphate varying between 1.3 and 2.0 (per weight), and trace minerals such as magnesium, sodium, potassium and carbonate also be found.Type I collagen composes 90–95% of the organic matrix, with the remainder of the matrix being a homogenous liquid called ground substance consisting of proteoglycans such as hyaluronic acid and chondroitin sulfate, as well as non-collagenous proteins such as osteocalcin, osteopontin or bone sialoprotein. Collagen consists of strands of repeating units, which give bone tensile strength, and are arranged in an overlapping fashion that prevents shear stress. The function of ground substance is not fully known. Two types of bone can be identified microscopically according to the arrangement of collagen: woven and lamellar. Woven bone (also known as fibrous bone), which is characterized by a haphazard organization of collagen fibers and is mechanically weak. Lamellar bone, which has a regular parallel alignment of collagen into sheets (""lamellae"") and is mechanically strong. Woven bone is produced when osteoblasts produce osteoid rapidly, which occurs initially in all fetal bones, but is later replaced by more resilient lamellar bone. In adults, woven bone is created after fractures or in Paget's disease. Woven bone is weaker, with a smaller number of randomly oriented collagen fibers, but forms quickly; it is for this appearance of the fibrous matrix that the bone is termed woven. It is soon replaced by lamellar bone, which is highly organized in concentric sheets with a much lower proportion of osteocytes to surrounding tissue. Lamellar bone, which makes its first appearance in humans in the fetus during the third trimester, is stronger and filled with many collagen fibers parallel to other fibers in the same layer (these parallel columns are called osteons). In cross-section, the fibers run in opposite directions in alternating layers, much like in plywood, assisting in the bone's ability to resist torsion forces. After a fracture, woven bone forms initially and is gradually replaced by lamellar bone during a process known as ""bony substitution."" Compared to woven bone, lamellar bone formation takes place more slowly. The orderly deposition of collagen fibers restricts the formation of osteoid to about 1 to 2 µm per day. Lamellar bone also requires a relatively flat surface to lay the collagen fibers in parallel or concentric layers.  Deposition  The extracellular matrix of bone is laid down by osteoblasts, which secrete both collagen and ground substance. These synthesise collagen within the cell and then secrete collagen fibrils. The collagen fibers rapidly polymerise to form collagen strands. At this stage, they are not yet mineralised, and are called ""osteoid"". Around the strands calcium and phosphate precipitate on the surface of these strands, within days to weeks becoming crystals of hydroxyapatite.In order to mineralise the bone, the osteoblasts secrete vesicles containing alkaline phosphatase. This cleaves the phosphate groups and acts as the foci for calcium and phosphate deposition. The vesicles then rupture and act as a centre for crystals to grow on. More particularly, bone mineral is formed from globular and plate structures.  Types  There are five types of bones in the human body: long, short, flat, irregular, and sesamoid. Long bones are characterized by a shaft, the diaphysis, that is much longer than its width; and by an epiphysis, a rounded head at each end of the shaft. They are made up mostly of compact bone, with lesser amounts of marrow, located within the medullary cavity, and areas of spongy, cancellous bone at the ends of the bones. Most bones of the limbs, including those of the fingers and toes, are long bones. The exceptions are the eight carpal bones of the wrist, the seven articulating tarsal bones of the ankle and the sesamoid bone of the kneecap. Long bones such as the clavicle, that have a differently shaped shaft or ends are also called modified long bones. Short bones are roughly cube-shaped, and have only a thin layer of compact bone surrounding a spongy interior. The bones of the wrist and ankle are short bones. Flat bones are thin and generally curved, with two parallel layers of compact bone sandwiching a layer of spongy bone. Most of the bones of the skull are flat bones, as is the sternum. Sesamoid bones are bones embedded in tendons. Since they act to hold the tendon further away from the joint, the angle of the tendon is increased and thus the leverage of the muscle is increased. Examples of sesamoid bones are the patella and the pisiform. Irregular bones do not fit into the above categories. They consist of thin layers of compact bone surrounding a spongy interior. As implied by the name, their shapes are irregular and complicated. Often this irregular shape is due to their many centers of ossification or because they contain bony sinuses. The bones of the spine, pelvis, and some bones of the skull are irregular bones. Examples include the ethmoid and sphenoid bones.  Terminology  In the study of anatomy, anatomists use a number of anatomical terms to describe the appearance, shape and function of bones. Other anatomical terms are also used to describe the location of bones. Like other anatomical terms, many of these derive from Latin and Greek. Some anatomists still use Latin to refer to bones. The term ""osseous"", and the prefix ""osteo-"", referring to things related to bone, are still used commonly today. Some examples of terms used to describe bones include the term ""foramen"" to describe a hole through which something passes, and a ""canal"" or ""meatus"" to describe a tunnel-like structure. A protrusion from a bone can be called a number of terms, including a ""condyle"", ""crest"", ""spine"", ""eminence"", ""tubercle"" or ""tuberosity"", depending on the protrusion's shape and location. In general, long bones are said to have a ""head"", ""neck"", and ""body"". When two bones join, they are said to ""articulate"". If the two bones have a fibrous connection and are relatively immobile, then the joint is called a ""suture"".  Development  The formation of bone is called ossification. During the fetal stage of development this occurs by two processes: intramembranous ossification and endochondral ossification. Intramembranous ossification involves the formation of bone from connective tissue whereas endochondral ossification involves the formation of bone from cartilage. Intramembranous ossification mainly occurs during formation of the flat bones of the skull but also the mandible, maxilla, and clavicles; the bone is formed from connective tissue such as mesenchyme tissue rather than from cartilage. The process includes: the development of the ossification center, calcification, trabeculae formation and the development of the periosteum.Endochondral ossification occurs in long bones and most other bones in the body; it involves the development of bone from cartilage. This process includes the development of a cartilage model, its growth and development, development of the primary and secondary ossification centers, and the formation of articular cartilage and the epiphyseal plates.Endochondral ossification begins with points in the cartilage called ""primary ossification centers."" They mostly appear during fetal development, though a few short bones begin their primary ossification after birth. They are responsible for the formation of the diaphyses of long bones, short bones and certain parts of irregular bones. Secondary ossification occurs after birth and forms the epiphyses of long bones and the extremities of irregular and flat bones. The diaphysis and both epiphyses of a long bone are separated by a growing zone of cartilage (the epiphyseal plate). At skeletal maturity (18 to 25 years of age), all of the cartilage is replaced by bone, fusing the diaphysis and both epiphyses together (epiphyseal closure). In the upper limbs, only the diaphyses of the long bones and scapula are ossified. The epiphyses, carpal bones, coracoid process, medial border of the scapula, and acromion are still cartilaginous.The following steps are followed in the conversion of cartilage to bone: Zone of reserve cartilage. This region, farthest from the marrow cavity, consists of typical hyaline cartilage that as yet shows no sign of transforming into bone. Zone of cell proliferation. A little closer to the marrow cavity, chondrocytes multiply and arrange themselves into longitudinal columns of flattened lacunae. Zone of cell hypertrophy. Next, the chondrocytes cease to divide and begin to hypertrophy (enlarge), much like they do in the primary ossification center of the fetus. The walls of the matrix between lacunae become very thin. Zone of calcification. Minerals are deposited in the matrix between the columns of lacunae and calcify the cartilage. These are not the permanent mineral deposits of bone, but only a temporary support for the cartilage that would otherwise soon be weakened by the breakdown of the enlarged lacunae. Zone of bone deposition. Within each column, the walls between the lacunae break down and the chondrocytes die. This converts each column into a longitudinal channel, which is immediately invaded by blood vessels and marrow from the marrow cavity. Osteoblasts line up along the walls of these channels and begin depositing concentric lamellae of matrix, while osteoclasts dissolve the temporarily calcified cartilage.  Functions  Bones have a variety of functions:  Mechanical  Bones serve a variety of mechanical functions. Together the bones in the body form the skeleton. They provide a frame to keep the body supported, and an attachment point for skeletal muscles, tendons, ligaments and joints, which function together to generate and transfer forces so that individual body parts or the whole body can be manipulated in three-dimensional space (the interaction between bone and muscle is studied in biomechanics). Bones protect internal organs, such as the skull protecting the brain or the ribs protecting the heart and lungs. Because of the way that bone is formed, bone has a high compressive strength of about 170 MPa (1,700 kgf/cm2), poor tensile strength of 104–121 MPa, and a very low shear stress strength (51.6 MPa). This means that bone resists pushing (compressional) stress well, resist pulling (tensional) stress less well, but only poorly resists shear stress (such as due to torsional loads). While bone is essentially brittle, bone does have a significant degree of elasticity, contributed chiefly by collagen. Mechanically, bones also have a special role in hearing. The ossicles are three small bones in the middle ear which are involved in sound transduction.  Synthetic  The cancellous part of bones contain bone marrow. Bone marrow produces blood cells in a process called hematopoiesis. Blood cells that are created in bone marrow include red blood cells, platelets and white blood cells. Progenitor cells such as the hematopoietic stem cell divide in a process called mitosis to produce precursor cells. These include precursors which eventually give rise to white blood cells, and erythroblasts which give rise to red blood cells. Unlike red and white blood cells, created by mitosis, platelets are shed from very large cells called megakaryocytes. This process of progressive differentiation occurs within the bone marrow. After the cells are matured, they enter the circulation. Every day, over 2.5 billion red blood cells and platelets, and 50–100 billion granulocytes are produced in this way.As well as creating cells, bone marrow is also one of the major sites where defective or aged red blood cells are destroyed.  Metabolic  Mineral storage – bones act as reserves of minerals important for the body, most notably calcium and phosphorus.Determined by the species, age, and the type of bone, bone cells make up to 15 percent of the bone. Growth factor storage—mineralized bone matrix stores important growth factors such as insulin-like growth factors, transforming growth factor, bone morphogenetic proteins and others. Fat storage – marrow adipose tissue (MAT) acts as a storage reserve of fatty acids. Acid-base balance – bone buffers the blood against excessive pH changes by absorbing or releasing alkaline salts. Detoxification – bone tissues can also store heavy metals and other foreign elements, removing them from the blood and reducing their effects on other tissues. These can later be gradually released for excretion. Endocrine organ – bone controls phosphate metabolism by releasing fibroblast growth factor 23 (FGF-23), which acts on kidneys to reduce phosphate reabsorption. Bone cells also release a hormone called osteocalcin, which contributes to the regulation of blood sugar (glucose) and fat deposition. Osteocalcin increases both the insulin secretion and sensitivity, in addition to boosting the number of insulin-producing cells and reducing stores of fat. Calcium balance – the process of bone resorption by the osteoclasts releases stored calcium into the systemic circulation and is an important process in regulating calcium balance. As bone formation actively fixes circulating calcium in its mineral form, removing it from the bloodstream, resorption actively unfixes it thereby increasing circulating calcium levels. These processes occur in tandem at site-specific locations.  Remodeling  Bone is constantly being created and replaced in a process known as remodeling. This ongoing turnover of bone is a process of resorption followed by replacement of bone with little change in shape. This is accomplished through osteoblasts and osteoclasts. Cells are stimulated by a variety of signals, and together referred to as a remodeling unit. Approximately 10% of the skeletal mass of an adult is remodelled each year. The purpose of remodeling is to regulate calcium homeostasis, repair microdamaged bones from everyday stress, and to shape the skeleton during growth. Repeated stress, such as weight-bearing exercise or bone healing, results in the bone thickening at the points of maximum stress (Wolff's law). It has been hypothesized that this is a result of bone's piezoelectric properties, which cause bone to generate small electrical potentials under stress.The action of osteoblasts and osteoclasts are controlled by a number of chemical enzymes that either promote or inhibit the activity of the bone remodeling cells, controlling the rate at which bone is made, destroyed, or changed in shape. The cells also use paracrine signalling to control the activity of each other. For example, the rate at which osteoclasts resorb bone is inhibited by calcitonin and osteoprotegerin. Calcitonin is produced by parafollicular cells in the thyroid gland, and can bind to receptors on osteoclasts to directly inhibit osteoclast activity. Osteoprotegerin is secreted by osteoblasts and is able to bind RANK-L, inhibiting osteoclast stimulation.Osteoblasts can also be stimulated to increase bone mass through increased secretion of osteoid and by inhibiting the ability of osteoclasts to break down osseous tissue. Increased secretion of osteoid is stimulated by the secretion of growth hormone by the pituitary, thyroid hormone and the sex hormones (estrogens and androgens). These hormones also promote increased secretion of osteoprotegerin. Osteoblasts can also be induced to secrete a number of cytokines that promote reabsorption of bone by stimulating osteoclast activity and differentiation from progenitor cells. Vitamin D, parathyroid hormone and stimulation from osteocytes induce osteoblasts to increase secretion of RANK-ligand and interleukin 6, which cytokines then stimulate increased reabsorption of bone by osteoclasts. These same compounds also increase secretion of macrophage colony-stimulating factor by osteoblasts, which promotes the differentiation of progenitor cells into osteoclasts, and decrease secretion of osteoprotegerin.  Volume  Bone volume is determined by the rates of bone formation and bone resorption. Recent research has suggested that certain growth factors may work to locally alter bone formation by increasing osteoblast activity. Numerous bone-derived growth factors have been isolated and classified via bone cultures. These factors include insulin-like growth factors I and II, transforming growth factor-beta, fibroblast growth factor, platelet-derived growth factor, and bone morphogenetic proteins. Evidence suggests that bone cells produce growth factors for extracellular storage in the bone matrix. The release of these growth factors from the bone matrix could cause the proliferation of osteoblast precursors. Essentially, bone growth factors may act as potential determinants of local bone formation. Research has suggested that cancellous bone volume in postmenopausal osteoporosis may be determined by the relationship between the total bone forming surface and the percent of surface resorption.  Clinical significance  A number of diseases can affect bone, including arthritis, fractures, infections, osteoporosis and tumors. Conditions relating to bone can be managed by a variety of doctors, including rheumatologists for joints, and orthopedic surgeons, who may conduct surgery to fix broken bones. Other doctors, such as rehabilitation specialists may be involved in recovery, radiologists in interpreting the findings on imaging, and pathologists in investigating the cause of the disease, and family doctors may play a role in preventing complications of bone disease such as osteoporosis. When a doctor sees a patient, a history and exam will be taken. Bones are then often imaged, called radiography. This might include ultrasound X-ray, CT scan, MRI scan and other imaging such as a Bone scan, which may be used to investigate cancer. Other tests such as a blood test for autoimmune markers may be taken, or a synovial fluid aspirate may be taken.  Fractures  In normal bone, fractures occur when there is significant force applied or repetitive trauma over a long time. Fractures can also occur when a bone is weakened, such as with osteoporosis, or when there is a structural problem, such as when the bone remodels excessively (such as Paget's disease) or is the site of the growth of cancer. Common fractures include wrist fractures and hip fractures, associated with osteoporosis, vertebral fractures associated with high-energy trauma and cancer, and fractures of long-bones. Not all fractures are painful. When serious, depending on the fractures type and location, complications may include flail chest, compartment syndromes or fat embolism. Compound fractures involve the bone's penetration through the skin. Some complex fractures can be treated by the use of bone grafting procedures that replace missing bone portions. Fractures and their underlying causes can be investigated by X-rays, CT scans and MRIs. Fractures are described by their location and shape, and several classification systems exist, depending on the location of the fracture. A common long bone fracture in children is a Salter–Harris fracture. When fractures are managed, pain relief is often given, and the fractured area is often immobilised. This is to promote bone healing. In addition, surgical measures such as internal fixation may be used. Because of the immobilisation, people with fractures are often advised to undergo rehabilitation.  Tumors  There are several types of tumor that can affect bone; examples of benign bone tumors include osteoma, osteoid osteoma, osteochondroma, osteoblastoma, enchondroma, giant-cell tumor of bone, and aneurysmal bone cyst.  Cancer  Cancer can arise in bone tissue, and bones are also a common site for other cancers to spread (metastasise) to. Cancers that arise in bone are called ""primary"" cancers, although such cancers are rare. Metastases within bone are ""secondary"" cancers, with the most common being breast cancer, lung cancer, prostate cancer, thyroid cancer, and kidney cancer. Secondary cancers that affect bone can either destroy bone (called a ""lytic"" cancer) or create bone (a ""sclerotic"" cancer). Cancers of the bone marrow inside the bone can also affect bone tissue, examples including leukemia and multiple myeloma. Bone may also be affected by cancers in other parts of the body. Cancers in other parts of the body may release parathyroid hormone or parathyroid hormone-related peptide. This increases bone reabsorption, and can lead to bone fractures. Bone tissue that is destroyed or altered as a result of cancers is distorted, weakened, and more prone to fracture. This may lead to compression of the spinal cord, destruction of the marrow resulting in bruising, bleeding and immunosuppression, and is one cause of bone pain. If the cancer is metastatic, then there might be other symptoms depending on the site of the original cancer. Some bone cancers can also be felt. Cancers of the bone are managed according to their type, their stage, prognosis, and what symptoms they cause. Many primary cancers of bone are treated with radiotherapy. Cancers of bone marrow may be treated with chemotherapy, and other forms of targeted therapy such as immunotherapy may be used. Palliative care, which focuses on maximising a person's quality of life, may play a role in management, particularly if the likelihood of survival within five years is poor.  Other painful conditions  Osteomyelitis is inflammation of the bone or bone marrow due to bacterial infection. Osteomalacia is a painful softening of adult bone caused by severe vitamin D deficiency. Osteogenesis imperfecta Osteochondritis dissecans Ankylosing spondylitis Skeletal fluorosis is a bone disease caused by an excessive accumulation of fluoride in the bones. In advanced cases, skeletal fluorosis damages bones and joints and is painful.  Osteoporosis  Osteoporosis is a disease of bone where there is reduced bone mineral density, increasing the likelihood of fractures. Osteoporosis is defined in women by the World Health Organization as a bone mineral density of 2.5 standard deviations below peak bone mass, relative to the age and sex-matched average. This density is measured using dual energy X-ray absorptiometry (DEXA), with the term ""established osteoporosis"" including the presence of a fragility fracture. Osteoporosis is most common in women after menopause, when it is called ""postmenopausal osteoporosis"", but may develop in men and premenopausal women in the presence of particular hormonal disorders and other chronic diseases or as a result of smoking and medications, specifically glucocorticoids. Osteoporosis usually has no symptoms until a fracture occurs. For this reason, DEXA scans are often done in people with one or more risk factors, who have developed osteoporosis and are at risk of fracture.One of the most important risk factors for osteoporosis is advanced age. Accumulation of oxidative DNA damage in osteoblastic and osteoclastic cells appears to be a key factor in age-related osteoporosis.Osteoporosis treatment includes advice to stop smoking, decrease alcohol consumption, exercise regularly, and have a healthy diet. Calcium and trace mineral supplements may also be advised, as may Vitamin D. When medication is used, it may include bisphosphonates, Strontium ranelate, and hormone replacement therapy.  Osteopathic medicine  Osteopathic medicine is a school of medical thought originally developed based on the idea of the link between the musculoskeletal system and overall health, but now very similar to mainstream medicine. As of 2012, over 77,000 physicians in the United States are trained in osteopathic medical schools.  Osteology  The study of bones and teeth is referred to as osteology. It is frequently used in anthropology, archeology and forensic science for a variety of tasks. This can include determining the nutritional, health, age or injury status of the individual the bones were taken from. Preparing fleshed bones for these types of studies can involve the process of maceration. Typically anthropologists and archeologists study bone tools made by Homo sapiens and Homo neanderthalensis. Bones can serve a number of uses such as projectile points or artistic pigments, and can also be made from external bones such as antlers.  Other animals  Bird skeletons are very lightweight. Their bones are smaller and thinner, to aid flight. Among mammals, bats come closest to birds in terms of bone density, suggesting that small dense bones are a flight adaptation. Many bird bones have little marrow due to them being hollow.A bird's beak is primarily made of bone as projections of the mandibles which are covered in keratin. Some bones, primarily formed separately in subcutaneous tissues, include headgears (such as bony core of horns, antlers, ossicones), osteoderm, and os penis/ os clitoris. A deer's antlers are composed of bone which is an unusual example of bone being outside the skin of the animal once the velvet is shed.The extinct predatory fish Dunkleosteus had sharp edges of hard exposed bone along its jaws.The proportion of cortical bone that is 80% in the human skeleton may be much lower in other animals, especially in marine mammals and marine turtles, or in various Mesozoic marine reptiles, such as ichthyosaurs, among others. This proportion can vary quickly in evolution; it often increases in early stages of returns to an aquatic lifestyle, as seen in early whales and pinnipeds, among others. It subsequently decreases in pelagic taxa, which typically acquire spongy bone, but aquatic taxa that live in shallow water can retain very thick, pachyostotic, osteosclerotic, or pachyosteosclerotic bones, especially if they move slowly, like sea cows. In some cases, even marine taxa that had acquired spongy bone can revert to thicker, compact bones if they become adapted to live in shallow water, or in hypersaline (denser) water.Many animals, particularly herbivores, practice osteophagy—the eating of bones. This is presumably carried out in order to replenish lacking phosphate. Many bone diseases that affect humans also affect other vertebrates—an example of one disorder is skeletal fluorosis.  Society and culture  Bones from slaughtered animals have a number of uses. In prehistoric times, they have been used for making bone tools. They have further been used in bone carving, already important in prehistoric art, and also in modern time as crafting materials for buttons, beads, handles, bobbins, calculation aids, head nuts, dice, poker chips, pick-up sticks, arrows, scrimshaw, ornaments, etc. Bone glue can be made by prolonged boiling of ground or cracked bones, followed by filtering and evaporation to thicken the resulting fluid. Historically once important, bone glue and other animal glues today have only a few specialized uses, such as in antiques restoration. Essentially the same process, with further refinement, thickening and drying, is used to make gelatin. Broth is made by simmering several ingredients for a long time, traditionally including bones. Bone char, a porous, black, granular material primarily used for filtration and also as a black pigment, is produced by charring mammal bones. Oracle bone script was a writing system used in Ancient China based on inscriptions in bones. Its name originates from oracle bones, which were mainly ox clavicle. The Ancient Chinese (mainly in the Shang dynasty), would write their questions on the oracle bone, and burn the bone, and where the bone cracked would be the answer for the questions. To point the bone at someone is considered bad luck in some cultures, such as Australian aborigines, such as by the Kurdaitcha. The wishbones of fowl have been used for divination, and are still customarily used in a tradition to determine which one of two people pulling on either prong of the bone may make a wish. Various cultures throughout history have adopted the custom of shaping an infant's head by the practice of artificial cranial deformation. A widely practised custom in China was that of foot binding to limit the normal growth of the foot.  Additional images   See also  Artificial bone Bone health Distraction osteogenesis National Bone Health Campaign Skeleton  References   Further reading  Katja Hoehn; Marieb, Elaine Nicpon (2007). Human Anatomy & Physiology (7th ed.). San Francisco: Benjamin Cummings. ISBN 978-0-8053-5909-1. Bryan H. Derrickson; Tortora, Gerard J. (2005). Principles of anatomy and physiology. New York: Wiley. ISBN 978-0-471-68934-8. Davidson, Stanley (2010). Colledge, Nicki R.; Walker, Brian R.; Ralston, Stuart H. (eds.). Davidson's principles and practice of medicine. Illustrated by Robert Britton (21st ed.). Edinburgh: Churchill Livingstone/Elsevier. ISBN 978-0-7020-3085-7. Deakin, Barbara Young; et al. (2006). Wheater's functional histology : a text and colour atlas (5th ed.). London: Churchill Livingstone/Elsevier. ISBN 978-0-443-068-508. – drawings by Philip J. Hall, Arthur C.; Guyton, John E. (2005). Textbook of medical physiology (11th ed.). Philadelphia: W.B. Saunders. ISBN 978-0-7216-0240-0. Anthony, S. Fauci; Harrison, T.R.; et al. (2008). Harrison's principles of internal medicine (17th ed.). New York [etc.]: McGraw-Hill Medical. ISBN 978-0-07-147692-8. – Anthony edits the current version; Harrison edited previous versions.  External links  Educational resource materials (including animations) by the American Society for Bone and Mineral Research Review (including references) of piezoelectricity and bone remodelling A good basic overview of bone biology from the Science Creative Quarterly Usha Kini; B. N. Nandeesh (3 January 2013). ""Ch 2: Physiology of Bone Formation, Remodeling, and Metabolism"" (PDF). In Ignac Fogelman; Gopinath Gnanasegaran; Hans van der Wall (eds.). Radionuclide and hybrid bone imaging. Berlin: Springer. pp. 29–57. ISBN 978-3-642-02399-6. Archived from the original (PDF) on 6 November 2020. Retrieved 28 August 2017. Bone histology photomicrographs","Bones are parts of the skeleton of vertebrates. They also protect organs inside our body.The bones are the framework of the body. Without them we would be a pile of organs and skin on the ground and would not be able to move. Bones also protect us. The skull protects the brain and the ribs protect the heart and lungs. The jaw and skull support the facial muscles, which help us eat and move our mouth. The pelvis protects the reproductive organs, and vertebrae protect the spinal cord. Bone is living tissue, and must be maintained by taking regular exercise and by having calcium from foods like milk, and dark leafy greens such as spinach. The bone marrow in the middle of the bigger bones makes our red blood cells.  Structure   Bone marrow  Long bones are hollow, with a central core which is not strong like the rest of the bone. It contains the bone marrow, one of the most important tissues in the vertebrate body. It produces blood cells for the blood system, and lymphocytes for the immune system.  Osteons  Osteons are the small units of which the hardest parts of human bones are made. They are roughly cylindrical, and about 0.2mm wide and a few millimeters long. They are found in the bone in most mammals, and many reptiles, birds and amphibians. Inside the osteons are bone cells called osteocytes, each living in its own small space. Osteocytes make contact with each other by cytoplasmic processes through a network of tiny canals. This allows the exchange of nutrients and metabolic waste. Collagen fibers in each ring of cells ('lamellae') give them structure.Osteons have a hole down the middle, called the haversian canal. This canal contains the bone's blood supply. It also contains capillaries, and nerve fibres.The details of osteon structure varies between bones and parts of bones, from species to species, between sexes, and by age and environmental factors.  References "
"Sickle cell disease (SCD) is a group of blood disorders typically inherited. The most common type is known as sickle cell anaemia. It results in an abnormality in the oxygen-carrying protein haemoglobin found in red blood cells. This leads to a rigid, sickle-like shape under certain circumstances. Problems in sickle cell disease typically begin around 5 to 6 months of age. A number of health problems may develop, such as attacks of pain (known as a sickle cell crisis), anemia, swelling in the hands and feet, bacterial infections, and stroke. Long-term pain may develop as people get older. The average life expectancy in the developed world is 40 to 60 years.Sickle cell disease occurs when a person inherits two abnormal copies of the β-globin gene (HBB) that makes haemoglobin, one from each parent. This gene occurs in chromosome 11. Several subtypes exist, depending on the exact mutation in each haemoglobin gene. An attack can be set off by temperature changes, stress, dehydration, and high altitude. A person with a single abnormal copy does not usually have symptoms and is said to have sickle cell trait. Such people are also referred to as carriers. Diagnosis is by a blood test, and some countries test all babies at birth for the disease. Diagnosis is also possible during pregnancy.The care of people with sickle cell disease may include infection prevention with vaccination and antibiotics, high fluid intake, folic acid supplementation, and pain medication. Other measures may include blood transfusion and the medication hydroxycarbamide (hydroxyurea). A small percentage of people can be cured by a transplant of bone marrow cells.As of 2015, about 4.4 million people have sickle cell disease, while an additional 43 million have sickle cell trait. About 80% of sickle cell disease cases are believed to occur in Sub-Saharan Africa. It also occurs to a lesser degree in parts of India, Southern Europe, West Asia, North Africa and among people of African origin (sub-Saharan) living in other parts of the world. In 2015, it resulted in about 114,800 deaths. The condition was first described in the medical literature by American physician James B. Herrick in 1910. In 1949, its genetic transmission was determined by E. A. Beet and J. V. Neel. In 1954, the protective effect against malaria of sickle cell trait was described.  Signs and symptoms  Signs of sickle cell disease usually begin in early childhood. The severity of symptoms can vary from person to person. Sickle cell disease may lead to various acute and chronic complications, several of which have a high mortality rate.  Sickle cell crisis  The terms ""sickle cell crisis"" or ""sickling crisis"" may be used to describe several independent acute conditions occurring in patients with SCD, which results in anaemia and crises that could be of many types, including the vaso-occlusive crisis, aplastic crisis, splenic sequestration crisis, haemolytic crisis, and others. Most episodes of sickle cell crises last between five and seven days. ""Although infection, dehydration, and acidosis (all of which favor sickling) can act as triggers, in most instances, no predisposing cause is identified.""  Vaso-occlusive crisis  The vaso-occlusive crisis is caused by sickle-shaped red blood cells that obstruct capillaries and restrict blood flow to an organ, resulting in ischaemia, pain, necrosis, and often organ damage. The frequency, severity, and duration of these crises vary considerably. Painful crises are treated with hydration, analgesics, and blood transfusion; pain management requires opioid drug administration at regular intervals until the crisis has settled. For milder crises, a subgroup of patients manages on nonsteroidal anti-inflammatory drugs such as diclofenac or naproxen. For more severe crises, most patients require inpatient management for intravenous opioids; patient-controlled analgesia devices are commonly used in this setting. Vaso-occlusive crisis involving organs such as the penis or lungs are considered an emergency and treated with red blood cell transfusions. Incentive spirometry, a technique to encourage deep breathing to minimise the development of atelectasis, is recommended.  Splenic sequestration crisis  The spleen is frequently affected in sickle cell disease, as the sickle-shaped red blood cells cause narrowing of blood vessels and reduced function in clearing the defective cells. It is usually infarcted before the end of childhood in individuals with sickle cell anaemia. This spleen damage increases the risk of infection from encapsulated organisms; preventive antibiotics and vaccinations are recommended for those lacking proper spleen function. Splenic sequestration crises are acute, painful enlargements of the spleen, caused by intrasplenic trapping of red cells and resulting in a precipitous fall in haemoglobin levels with the potential for hypovolemic shock. Sequestration crises are considered an emergency. If not treated, patients may die within 1–2 hours due to circulatory failure. Management is supportive, sometimes with blood transfusion. These crises are transient; they continue for 3–4 hours and may last for one day.  Acute chest syndrome  Acute chest syndrome is defined by at least two of these signs or symptoms: chest pain, fever, pulmonary infiltrate or focal abnormality, respiratory symptoms, or hypoxemia. It is the second-most common complication and it accounts for about 25% of deaths in patients with SCD. Most cases present with vaso-occlusive crises, and then develop acute chest syndrome. Nevertheless, about 80% of people have vaso-occlusive crises during acute chest syndrome.  Aplastic crisis  Aplastic crises are instances of an acute worsening of the patient\'s baseline anaemia, producing pale appearance, fast heart rate, and fatigue. This crisis is normally triggered by parvovirus B19, which directly affects production of red blood cells by invading the red cell precursors and multiplying in and destroying them. Parvovirus infection almost completely prevents red blood cell production for two to three days. In normal individuals, this is of little consequence, but the shortened red cell life of SCD patients results in an abrupt, life-threatening situation. Reticulocyte counts drop dramatically during the disease (causing reticulocytopenia), and the rapid turnover of red cells leads to the drop in haemoglobin. This crisis takes 4 to 7 days to disappear. Most patients can be managed supportively; some need a blood transfusion.  Haemolytic crisis  Haemolytic crises are acute accelerated drops in haemoglobin level. The red blood cells break down at a faster rate. This is particularly common in people with coexistent G6PD deficiency. Another influence of hemolytic crises in sickle cell disease is oxidative stress on the erythrocytes, leukocytes, and platelets. When there is not enough red blood cell production in the bone marrow, the oxygen that the body receives, processes, and transports is unbalanced with the body’s antioxidants. There is an imbalance in the oxygen reactive species in the cells, which leads to more production of red blood cells that are not properly oxygenated or formed. Oxidative stress may lead to anemia because of the imbalance of oxygen in the tissue.Management is supportive, sometimes with blood transfusions.  Other  One of the earliest clinical manifestations is dactylitis, presenting as early as six months of age, and may occur in children with sickle cell trait. The crisis can last up to a month. Given that pneumonia and sickling in the lung can both produce symptoms of acute chest syndrome, the patient is treated for both conditions. It can be triggered by painful crisis, respiratory infection, bone-marrow embolisation, or possibly by atelectasis, opiate administration, or surgery. Hematopoietic ulcers may also occur.  Complications  Sickle cell anaemia can lead to various complications, including: Increased risk of severe bacterial infections is due to loss of functioning spleen tissue (and comparable to the risk of infections after having the spleen removed surgically). These infections are typically caused by encapsulated organisms such as Streptococcus pneumoniae and Haemophilus influenzae. Daily penicillin prophylaxis is the most commonly used treatment during childhood, with some haematologists continuing treatment indefinitely. Patients benefit today from routine vaccination for S. pneumoniae. Stroke, which can result from a progressive narrowing of blood vessels, prevents oxygen from reaching the brain. Cerebral infarction occurs in children and cerebral haemorrhage in adults. Silent stroke causes no immediate symptoms, but is associated with damage to the brain. Silent stroke is probably five times as common as symptomatic stroke. About 10–15% of children with SCD have strokes, with silent strokes predominating in the younger patients. Cholelithiasis (gallstones) and cholecystitis may result from excessive bilirubin production and precipitation due to prolonged haemolysis. Avascular necrosis (aseptic bone necrosis) of the hip and other major joints may occur as a result of ischaemia. Decreased immune reactions due to hyposplenism (malfunctioning of the spleen) Priapism and infarction of the penis Osteomyelitis (bacterial bone infection), the most common cause of osteomyelitis in SCD is Salmonella (especially the atypical serotypes Salmonella typhimurium, Salmonella enteritidis, Salmonella choleraesuis, and Salmonella paratyphi B), followed by Staphylococcus aureus and Gram-negative enteric bacilli perhaps because intravascular sickling of the bowel leads to patchy ischaemic infarction. Acute papillary necrosis in the kidneys Leg ulcers In eyes, background retinopathy, proliferative retinopathy, vitreous haemorrhages, and retinal detachments can result in blindness. Regular annual eye checks are recommended. During pregnancy, intrauterine growth restriction, spontaneous abortion, and pre-eclampsia Chronic pain: Even in the absence of acute vaso-occlusive pain, many patients have unreported chronic pain. Pulmonary hypertension (increased pressure on the pulmonary artery) can lead to strain on the right ventricle and a risk of heart failure; typical symptoms are shortness of breath, decreased exercise tolerance, and episodes of syncope. 21% of children and 30% of adults have evidence of pulmonary hypertension when tested; this is associated with reduced walking distance and increased mortality. Cardiomyopathy and left ventricular diastolic dysfunction caused by fibrosis or scarring of cardiac tissues. This also contributes to pulmonary hypertension, decreased exercise capacity, and arrhythmias. Chronic kidney failure due to sickle-cell nephropathy manifests itself with hypertension, protein loss in the urine, loss of red blood cells in urine and worsened anaemia. If it progresses to end-stage kidney failure, it carries a poor prognosis.  Genetics  Normally, humans have haemoglobin A, which consists of two alpha and two beta chains, haemoglobin A2, which consists of two alpha and two delta chains, and haemoglobin F (HbF), consisting of two alpha and two gamma chains in their bodies. Of these three types, haemoglobin F dominates until about 6 weeks of age. Afterwards, haemoglobin A dominates throughout life. In people diagnosed with sickle cell disease, at least one of the β-globin subunits in haemoglobin A is replaced with what is known as haemoglobin S. In sickle cell anaemia, a common form of sickle cell disease, haemoglobin S replaces both β-globin subunits in the haemoglobin.Sickle cell disease has an autosomal recessive pattern of inheritance from parents. The types of haemoglobin a person makes in the red blood cells depend on what haemoglobin genes are inherited from her or his parents. If one parent has sickle cell anaemia and the other has sickle cell trait, then the child has a 50% chance of having sickle cell disease and a 50% chance of having sickle cell trait. When both parents have sickle cell trait, a child has a 25% chance of sickle cell disease; 25% do not carry any sickle cell alleles, and 50% have the heterozygous condition.Sickle cell gene mutation probably arose spontaneously in different geographic areas, as suggested by restriction endonuclease analysis. These variants are known as Cameroon, Senegal, Benin, Bantu, and Saudi-Asian. Their clinical importance is because some are associated with higher HbF levels, e.g., Senegal and Saudi-Asian variants, and tend to have milder disease.The gene defect is a single nucleotide mutation (see single-nucleotide polymorphism – SNP) (GAG codon changing to GTG) of the β-globin gene, which results in glutamate (E/Glu) being substituted by valine (V/Val) at position 6 (E6V substitution). Haemoglobin S with this mutation is referred to as HbS, as opposed to the normal adult HbA. This is normally a benign mutation, causing no apparent effects on the secondary, tertiary, or quaternary structures of haemoglobin in conditions of normal oxygen concentration. However, under low oxygen concentration, HbS polymerizes and forms fibrous precipitates because the deoxy form of haemoglobin exposes a hydrophobic patch on the protein between the E and F helices (Phe 85, Leu 88).In people heterozygous for HbS (carriers of sickling haemoglobin), the polymerisation problems are minor because the normal allele can produce half of the haemoglobin. In people homozygous for HbS, the presence of long-chain polymers of HbS distort the shape of the red blood cell from a smooth, doughnut-like shape to ragged and full of spikes, making it fragile and susceptible to breaking within capillaries. Carriers have symptoms only if they are deprived of oxygen (for example, while climbing a mountain) or while severely dehydrated. The allele responsible for sickle cell anaemia can be found on the short arm of chromosome 11, more specifically 11p15.5. A person who receives the defective gene from both father and mother develops the disease; a person who receives one defective and one healthy allele remains healthy, but can pass on the disease and is known as a carrier or heterozygote. Heterozygotes are still able to contract malaria, but their symptoms are generally less severe.Due to the adaptive advantage of the heterozygote, the disease is still prevalent, especially among people with recent ancestry in malaria-stricken areas, such as Africa, the Mediterranean, India, and the Middle East. Malaria was historically endemic to southern Europe, but it was declared eradicated in the mid-20th century, with the exception of rare sporadic cases.The malaria parasite has a complex lifecycle and spends part of it in red blood cells. In a carrier, the presence of the malaria parasite causes the red blood cells with defective haemoglobin to rupture prematurely, making the Plasmodium parasite unable to reproduce. Further, the polymerization of Hb affects the ability of the parasite to digest Hb in the first place. Therefore, in areas where malaria is a problem, people\'s chances of survival actually increase if they carry sickle cell traits (selection for the heterozygote).In the United States, with no endemic malaria, the prevalence of sickle cell anaemia among people of African ancestry is lower (about 0.25%) than among people in West Africa (about 4.0%) and is falling. Without endemic malaria, the sickle cell mutation is purely disadvantageous and tends to decline in the affected population by natural selection, and now artificially through prenatal genetic screening. However, the African American community descends from a significant admixture of several African and non-African ethnic groups and also represents the descendants of survivors of slavery and the slave trade. Thus, a degree of genetic dilution via crossbreeding with non-African people and high health-selective pressure through slavery (especially the slave trade and the frequently deadly Middle Passage) may be the most plausible explanations for the lower prevalence of sickle cell anaemia (and, possibly, other genetic diseases) among African Americans compared to West Africans. Another factor that limits the spread of sickle cell genes in North America is the relative absence of polygamy. In polygamous societies, affected males may father many children with multiple partners.  Pathophysiology  The loss of red blood cell elasticity is central to the pathophysiology of sickle cell disease. Normal red blood cells are quite elastic and have a biconcave disc shape, which allows the cells to deform to pass through capillaries. In sickle cell disease, low oxygen tension promotes red blood cell sickling and repeated episodes of sickling damage the cell membrane and decrease the cell\'s elasticity. These cells fail to return to normal shape when normal oxygen tension is restored. As a consequence, these rigid blood cells are unable to deform as they pass through narrow capillaries, leading to vessel occlusion and ischaemia.The actual anaemia of the illness is caused by haemolysis, the destruction of the red cells, because of their shape. Although the bone marrow attempts to compensate by creating new red cells, it does not match the rate of destruction. Healthy red blood cells typically function for 90–120 days, but sickled cells only last 10–20 days.  Diagnosis  In HbS, the complete blood count reveals haemoglobin levels in the range of 6–8 g/dl with a high reticulocyte count (as the bone marrow compensates for the destruction of sickled cells by producing more red blood cells). In other forms of sickle cell disease, Hb levels tend to be higher. A blood film may show features of hyposplenism (target cells and Howell-Jolly bodies).Sickling of the red blood cells, on a blood film, can be induced by the addition of sodium metabisulfite. The presence of sickle haemoglobin can also be demonstrated with the ""sickle solubility test"" (also called ""sickledex""). A mixture of haemoglobin S (HbS) in a reducing solution (such as sodium dithionite) gives a turbid appearance, whereas normal Hb gives a clear solution.Abnormal haemoglobin forms can be detected on haemoglobin electrophoresis, a form of gel electrophoresis on which the various types of haemoglobin move at varying speeds. Sickle cell haemoglobin (HgbS) and haemoglobin C with sickling (HgbSC)—the two most common forms—can be identified from there. The diagnosis can be confirmed with high-performance liquid chromatography. Genetic testing is rarely performed, as other investigations are highly specific for HbS and HbC.An acute sickle cell crisis is often precipitated by infection. Therefore, a urinalysis to detect an occult urinary tract infection, and chest X-ray to look for occult pneumonia should be routinely performed.People who are known carriers of the disease or at risk of having a child with sickle cell anemia may undergo genetic counseling. Genetic counselors work with families to discuss the benefits, limitations, and logistics of genetic testing options as well as the potential impact of testing and test results on the individual. During pregnancy, genetic testing can be done on either a blood sample from the fetus or a sample of amniotic fluid. During the first trimester of pregnancy, chorionic villus sampling (CVS) is also a technique used for SCD prenatal diagnosis. Since taking a blood sample from a fetus has greater risks, the latter test is usually used. Neonatal screening sometimes referred to as newborn screening, provides not only a method of early detection for individuals with sickle cell disease but also allows for the identification of the groups of people who carry the sickle cell trait. Genetic counselors can help individuals of colour and their families tackle the racial and ethnic disparities that exist in healthcare.In 2010, there was significant consideration and debate in the US surrounding comprehensive screening of athletes for SCD. The American Society of Hematology concluded in a statement in 2012 that they do not support testing or disclosure of sickle cell trait status as a prerequisite for participation in athletic activities due to lack of scientific evidence, inconsistency with good medical practice, and inconsistency with public health ethics. They recommended universal interventions to reduce exertion-related injuries and deaths effective for all athletes irrespective of their sickle cell status.  Management  Treatment involves a number of measures. While it has been historically recommended that people with sickle cell disease avoid exercise, regular exercise may benefit people. Dehydration should be avoided. A diet high in calcium is recommended but the effectiveness of vitamin D supplementation remains uncertain. L-glutamine use was supported by the FDA starting at the age of five, as it decreases complications.  Folic acid and penicillin  From birth to five years of age, penicillin daily, due to the immature immune system that makes them more prone to early childhood illnesses, is recommended. Dietary supplementation of folic acid had been previously recommended by the WHO. A 2016 Cochrane review of its use found ""the effect of supplementation on anaemia and any symptoms of anaemia remains unclear"" due to a lack of medical evidence.  Malaria prevention  The protective effect of sickle cell trait does not apply to people with sickle cell disease; in fact, they are more vulnerable to malaria, since the most common cause of painful crises in malarial countries is infection with malaria. People with sickle cell disease living in malarial countries should receive lifelong medication for prevention.  Vaso-occlusive crisis  Most people with sickle cell disease have intensely painful episodes called vaso-occlusive crises. However, the frequency, severity, and duration of these crises vary tremendously. Painful crises are treated symptomatically with pain medications; pain management requires opioid drug administration at regular intervals until the crisis has settled. For milder crises, a subgroup of patients manages on NSAIDs (such as diclofenac or naproxen). For more severe crises, most patients require inpatient management for intravenous opioids.Extra fluids, administered either orally or intravenously, are a routine part of treatment of vaso-occlusive crises but the evidence about the most effective route, amount and type of fluid replacement remains uncertain.Crizanlizumab, a monoclonal antibody target towards p-selectin was approved in 2019 in the United States to reduce the frequency of vaso-occlusive crisis in those 16 years and older.  Stroke prevention  Transcranial Doppler ultrasound (TCD) can detect children with sickle cell that have a high risk for stroke. The ultrasound test detects blood vessels partially obstructed by sickle cells by measuring the rate of blood into the brain, as blood flow velocity is inversely related to arterial diameter, and consequently, high blood-flow velocity is correlated with narrowing of the arteries. In 2002 the National Institute of Health (NIH) issued a statement recommending that children with sickle cell get the Transcranial Doppler ultrasound screen annually, and in 2014 a panel of experts convened by the NIH issued guidelines reiterating the same recommendation. One review of medical records, by hematologist Dr. Julie Kanter at the University of Alabama at Birmingham, showed that on average only 48.4 percent of children with sickle cell get the recommended ultrasound test.A 1994 NIH study showed that children at risk for strokes who received blood transfusions had an annual stroke rate of less than 1 percent, whereas those children who did not receive blood transfusions had a 10 percent stroke rate per year. (Also see 1998 study in the New England Journal of Medicine.) In addition to ultrasounds and blood transfusions, the inexpensive generic drug hydroxyurea can reduce the risk of irreversible organ and brain damage. Guidelines from NIH published in 2014 state that all children and adolescents should take hydroxyurea, as should adults with serious complications or three or more pain crises in a year.  Acute chest syndrome  Management is similar to vaso-occlusive crisis, with the addition of antibiotics (usually a quinolone or macrolide, since cell wall-deficient [""atypical""] bacteria are thought to contribute to the syndrome), oxygen supplementation for hypoxia, and close observation. In the absence of high quality evidence regarding the effectiveness of antibiotics for acute chest syndrome in people with sickle cell disease, there is no standard antibiotic treatment as of 2019. It is recommended that people with suspected acute chest syndrome should be admitted to the hospital with worsening A-a gradient an indication for ICU admission.Should the pulmonary infiltrate worsen or the oxygen requirements increase, simple blood transfusion or exchange transfusion is indicated. The latter involves the exchange of a significant portion of the person\'s red cell mass for normal red cells, which decreases the level of haemoglobin S in the patient\'s blood. However, there is currently uncertain evidence about the possible benefits or harms of blood transfusion for acute chest syndrome in people with sickle cell disease.  Hydroxyurea  Hydroxyurea, also known as hydroxycarbamide, probably reduces the frequency of painful episodes and the risk of life-threatening illness or death but there is currently insufficient evidence regarding the risk of adverse effects. Hydroxyurea and phlebotomy combined may be more effective than transfusion and chelation combined in terms of pain, life-threatening illness and risk of death.It was the first approved drug for the treatment of sickle cell anaemia, and was shown to decrease the number and severity of attacks in 1995 and shown to possibly increase survival time in a study in 2003. This is achieved, in part, by reactivating fetal haemoglobin production in place of the haemoglobin S that causes sickle cell anaemia. Hydroxyurea had previously been used as a chemotherapy agent, and some concern exists that long-term use may be harmful, but this risk is either absent or very small and the benefits likely outweigh the risks.Voxelotor was approved in the United States in 2019 to increase hemoglobin in people with SS disease.  Blood transfusion  Blood transfusions are often used in the management of sickle cell disease in acute cases and to prevent complications by decreasing the number of red blood cells (RBCs) that can sickle by adding normal red blood cells. In children, preventive RBC transfusion therapy has been shown to reduce the risk of first stroke or silent stroke when transcranial Doppler ultrasonography shows abnormal cerebral blood flow. In those who have sustained a prior stroke event, it also reduces the risk of recurrent stroke and additional silent strokes.  Bone marrow transplant  Bone marrow transplants have proven effective in children; they are the only known cure for SCD. However, bone marrow transplants are difficult to obtain because of the specific HLA typing necessary. Ideally, a close relative (allogeneic) would donate the bone marrow necessary for transplantation. Some gene therapies are under development that would alter the patient\'s own bone marrow stem cells ex vivo, which can then be transplanted back into the patient after chemotherapy eliminates the original unmodified cells.  Avascular necrosis  When treating avascular necrosis of the bone in people with sickle cell disease, the aim of treatment is to reduce or stop the pain and maintain joint mobility. Current treatment options include resting the joint, physical therapy, pain-relief medicine, joint-replacement surgery, or bone grafting. High quality, randomized, controlled trials are needed to assess the most effective treatment option and determine if a combination of physical therapy and surgery is more effective than physical therapy alone.  Psychological therapies  Psychological therapies such as patient education, cognitive therapy, behavioural therapy, and psychodynamic psychotherapy, that aim to complement current medical treatments, require further research to determine their effectiveness.  Prognosis  About 90% of people survive to age 20, and close to 50% survive beyond age 50. In 2001, according to one study performed in Jamaica, the estimated mean survival for people was 53 years for men and 58 years for women with homozygous SCD. The specific life expectancy in much of the developing world is unknown. In 1975 about 7.3% of people with SCD died before their 23rd birthday; while in 1989 2.6% of people with SCD died by the age of 20.: 348  Epidemiology  The highest frequency of sickle cell disease is found in tropical regions, particularly sub-Saharan Africa, tribal regions of India, and the Middle East. Migration of substantial populations from these high-prevalence areas to low-prevalence countries in Europe has dramatically increased in recent decades and in some European countries, sickle cell disease has now overtaken more familiar genetic conditions such as haemophilia and cystic fibrosis. In 2015, it resulted in about 114,800 deaths.Sickle cell disease occurs more commonly among people whose ancestors lived in tropical and subtropical sub-Saharan regions where malaria is or was common. Where malaria is common, carrying a single sickle cell allele (trait) confers a heterozygote advantage; humans with one of the two alleles of sickle cell disease show less severe symptoms when infected with malaria.This condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. The parents each carry one copy of the mutated gene, but they typically do not show signs and symptoms of the condition.  Africa  Three-quarters of sickle cell cases occur in Africa. A recent WHO report estimated that around 2% of newborns in Nigeria were affected by sickle cell anaemia, giving a total of 150,000 affected children born every year in Nigeria alone. The carrier frequency ranges between 10 and 40% across equatorial Africa, decreasing to 1–2% on the North African coast and <1% in South Africa. Studies in Africa show a significant decrease in infant mortality rate, ages 2–16 months, because of the sickle cell trait. This happened in areas of predominant malarial cases.Uganda has the fifth-highest sickle cell disease burden in Africa. One study indicates that 20 000 babies per year are born with sickle cell disease with the sickle cell trait at 13·3% and with disease 0·7%.  United States  The number of people with the disease in the United States is about 100,000 (one in 3,300), mostly affecting Americans of sub-Saharan African descent. In the United States, about one out of 365 African-American children and one in every 16,300 Hispanic-American children have sickle cell anaemia. The life expectancy for men with SCD is approximately 42 years of age while women live approximately six years longer. An additional 2 million are carriers of the sickle cell trait. Most infants with SCD born in the United States are identified by routine neonatal screening. As of 2016 all 50 states include screening for sickle cell disease as part of their newborn screen. The newborn\'s blood is sampled through a heel-prick and is sent to a lab for testing. The baby must have been eating for a minimum of 24 hours before the heel-prick test can be done. Some states also require a second blood test to be done when the baby is two weeks old to ensure the results. Sickle cell anemia is the most common genetic disorder among African Americans. Approximately 8% are carriers and 1 in 375 are born with the disease. Patient advocates for sickle cell disease have complained that it gets less government and private research funding than similar rare diseases such as cystic fibrosis, with researcher Elliott Vichinsky saying this shows racial discrimination or the role of wealth in health care advocacy.  France  As a result of population growth in African-Caribbean regions of overseas France and immigration from North and sub-Saharan Africa to mainland France, sickle cell disease has become a major health problem in France. SCD has become the most common genetic disease in the country, with an overall birth prevalence of one in 2,415 in metropolitan France, ahead of phenylketonuria (one in 10,862), congenital hypothyroidism (one in 3,132), congenital adrenal hyperplasia (one in 19,008) and cystic fibrosis (one in 5,014) for the same reference period. Since 2000, neonatal screening of SCD has been performed at the national level for all newborns defined as being ""at-risk"" for SCD based on ethnic origin (defined as those born to parents originating from sub-Saharan Africa, North Africa, the Mediterranean area (South Italy, Greece, and Turkey), the Arabic peninsula, the French overseas islands, and the Indian subcontinent).  United Kingdom  In the United Kingdom, between 12,000 and 15,000 people are thought to have sickle cell disease with an estimated 250,000 carriers of the condition in England alone. As the number of carriers is only estimated, all newborn babies in the UK receive a routine blood test to screen for the condition. Due to many adults in high-risk groups not knowing if they are carriers, pregnant women and both partners in a couple are offered screening so they can get counselling if they have the sickle cell trait. In addition, blood donors from those in high-risk groups are also screened to confirm whether they are carriers and whether their blood filters properly. Donors who are found to be carriers are then informed and their blood, while often used for those of the same ethnic group, is not used for those with sickle cell disease who require a blood transfusion.  West Asia  In Saudi Arabia, about 4.2% of the population carry the sickle cell trait and 0.26% have sickle cell disease. The highest prevalence is in the Eastern province, where approximately 17% of the population carry the gene and 1.2% have sickle cell disease. In 2005, Saudi Arabia introduced a mandatory premarital test including HB electrophoresis, which aimed to decrease the incidence of SCD and thalassemia.In Bahrain, a study published in 1998 that covered about 56,000 people in hospitals in Bahrain found that 2% of newborns have sickle cell disease, 18% of the surveyed people have the sickle cell trait, and 24% were carriers of the gene mutation causing the disease. The country began screening of all pregnant women in 1992 and newborns started being tested if the mother was a carrier. In 2004, a law was passed requiring couples planning to marry to undergo free premarital counseling. These programs were accompanied by public education campaigns.  India and Nepal  Sickle cell disease is common in some ethnic groups of central India, where the prevalence has ranged from 9.4 to 22.2% in endemic areas of Madhya Pradesh, Rajasthan, and Chhattisgarh. It is also endemic among Tharu people of Nepal and India; however, they have a sevenfold lower rate of malaria despite living in a malaria infested zone.  Caribbean Islands  In Jamaica, 10% of the population carry the sickle cell gene, making it the most prevalent genetic disorder in the country.  History  The first modern report of sickle cell disease may have been in 1846, where the autopsy of an executed runaway slave was discussed; the key finding was the absence of the spleen. Reportedly, African slaves in the United States exhibited resistance to malaria, but were prone to leg ulcers. The abnormal characteristics of the red blood cells, which later lent their name to the condition, was first described by Ernest E. Irons (1877–1959), intern to Chicago cardiologist and professor of medicine James B. Herrick (1861–1954), in 1910. Irons saw ""peculiar elongated and sickle-shaped"" cells in the blood of a man named Walter Clement Noel, a 20-year-old first-year dental student from Grenada. Noel had been admitted to the Chicago Presbyterian Hospital in December 1904 with anaemia. Noel was readmitted several times over the next three years for ""muscular rheumatism"" and ""bilious attacks"" but completed his studies and returned to the capital of Grenada (St. George\'s) to practice dentistry. He died of pneumonia in 1916 and is buried in the Catholic cemetery at Sauteurs in the north of Grenada. Shortly after the report by Herrick, another case appeared in the Virginia Medical Semi-Monthly with the same title, ""Peculiar Elongated and Sickle-Shaped Red Blood Corpuscles in a Case of Severe Anemia."" This article is based on a patient admitted to the University of Virginia Hospital on 15 November 1910. In the later description by Verne Mason in 1922, the name ""sickle cell anemia"" is first used. Childhood problems related to sickle cells disease were not reported until the 1930s, despite the fact that this cannot have been uncommon in African-American populations.Memphis physician Lemuel Diggs, a prolific researcher into sickle cell disease, first introduced the distinction between sickle cell disease and trait in 1933, although until 1949, the genetic characteristics had not been elucidated by James V. Neel and E.A. Beet. 1949 was the year when Linus Pauling described the unusual chemical behaviour of haemoglobin S, and attributed this to an abnormality in the molecule itself. The molecular change in HbS was described in 1956 by Vernon Ingram. The late 1940s and early 1950s saw further understanding in the link between malaria and sickle cell disease. In 1954, the introduction of haemoglobin electrophoresis allowed the discovery of particular subtypes, such as HbSC disease.Large-scale natural history studies and further intervention studies were introduced in the 1970s and 1980s, leading to widespread use of prophylaxis against pneumococcal infections amongst other interventions. Bill Cosby\'s Emmy-winning 1972 TV movie, To All My Friends on Shore, depicted the story of the parents of a child with sickle cell disease. The 1990s had the development of hydroxycarbamide, and reports of cure through bone marrow transplantation appeared in 2007.Some old texts refer to it as drepanocytosis.  Society and culture   United States  Effective 15 September 2017, the U.S. Social Security Administration issued a Policy Interpretation Ruling providing background information on sickle cell disease and a description of how Social Security evaluates the disease during its adjudication process for disability claims.In the U.S., there are stigmas surrounding SCD that discourage people with SCD from receiving necessary care. These stigmas mainly affect people of African American and Latin American ancestries, according to the National Heart, Lung, and Blood Institute. People with SCD experience the impact of stigmas of the disease on multiple aspects of life including social and psychological well-being. Studies have shown that those with SCD frequently feel as though they must keep their diagnosis a secret to avoid discrimination in the workplace and also among peers in relationships. In the 1960s, the US government supported initiatives for workplace screening for genetic diseases in an attempt to be protective towards people with SCD. By having this screening, it was intended that employees would not be placed in environments that could potentially be harmful and trigger SCD.  Uganda  Uganda has the 5th highest sickle cell disease (SCD) burden in the world. In Uganda, social stigma exists for those with sickle cell disease because of the lack of general knowledge of the disease. The general gap in knowledge surrounding sickle cell disease is noted among adolescents and young adults due to the culturally sanctioned secrecy about the disease. While most people have heard generally about the disease, a large portion of the population is relatively misinformed about how SCD is diagnosed or inherited. Those who are informed about the disease learned about it from family or friends and not from health professionals. Failure to provide the public with information about sickle cell disease results in a population with a poor understanding of the causes of the disease, symptoms, and prevention techniques. The differences, physically and socially, that arise in those with sickle cell disease, such as jaundice, stunted physical growth, and delayed sexual maturity, can also lead them to become targets of bullying, rejection, and stigma.  Rate of sickle cell disease in Uganda  The data compiled on sickle cell disease in Uganda has not been updated since the early 1970s. The deficiency of data is due to a lack of government research funds, even though Ugandans die daily from SCD. Data shows that the trait frequency of sickle cell disease is 20% of the population in Uganda. This means that 66 million people are at risk of having a child who has sickle cell disease. It is also estimated that about 25,000 Ugandans are born each year with SCD and 80% of those people don\'t live past five years old. SCD also contributes 25% to the child mortality rate in Uganda. The Bamba people of Uganda, located in the southwest of the country, carry 45% of the gene which is the highest trait frequency recorded in the world. The Sickle Cell Clinic in Mulago is only one sickle cell disease clinic in the country and on average sees 200 patients a day.  Misconceptions about sickle cell disease  The stigma around the disease is particularly bad in regions of the country that are not as affected. For example, Eastern Ugandans tend to be more knowledgeable of the disease than Western Ugandans, who are more likely to believe that sickle cell disease resulted as a punishment from God or witchcraft. Other misconceptions about SCD include the belief that it is caused by environmental factors but, in reality, SCD is a genetic disease. There have been efforts throughout Uganda to address the social misconceptions about the disease. In 2013, the Uganda Sickle Cell Rescue Foundation was established to spread awareness of sickle cell disease and combat the social stigma attached to the disease. In addition to this organization\'s efforts, there is a need for the inclusion of sickle cell disease education in preexisting community health education programs in order to reduce the stigmatization of sickle cell disease in Uganda.  Social isolation of people with sickle cell disease  The deeply rooted stigma of SCD from society causes families to often hide their family members\' sick status for fear of being labeled, cursed, or left out of social events. Sometimes in Uganda, when it is confirmed that a family member has sickle cell disease, intimate relationships with all members of the family are avoided. The stigmatization and social isolation people with sickle cell disease tend to experience is often the consequence of popular misconceptions that people with SCD should not socialize with those free from the disease. This mentality robs people with SCD of the right to freely participate in community activities like everyone else SCD-related stigma and social isolation in schools, especially, can make a life for young people living with sickle cell disease extremely difficult. For school-aged children living with SCD, the stigma they face can lead to peer rejection. Peer rejection involves the exclusion from social groups or gatherings. It often leads the excluded individual to experience emotional distress and may result in their academic underperformance, avoidance of school, and occupational failure later in life. This social isolation is also likely to negatively impact people with SCD\'s self-esteem and overall quality of life.Mothers of children with sickle cell disease tend to receive disproportionate amounts of stigma from their peers and family members. These women will often be blamed for their child\'s diagnosis of SCD, especially if SCD is not present in earlier generations, due to the suspicion that the child\'s poor health may have been caused by the mother\'s failure to implement preventative health measures or promote a healthy environment for her child to thrive. The reliance on theories related to environmental factors to place blame on the mother reflects many Ugandan\'s poor knowledge of how the disease is acquired as it is determined by genetics, not environment. Mothers of children with sickle cell disease are also often left with very limited resources to safeguard their futures against the stigma of having SCD. This lack of access to resources results from their subordinating roles within familial structures as well as the class disparities that hinder many mothers\' ability to satisfy additional childcare costs and responsibilities.Women living with SCD who become pregnant often face extreme discrimination and discouragement in Uganda. These women are frequently branded by their peers as irresponsible for having a baby while living with sickle cell disease or even engaging in sex while living with SCD. The criticism and judgement these women receive, not only from healthcare professionals but also from their families, often leaves them feeling alone, depressed, anxious, ashamed, and with very little social support. Most pregnant women with SCD also go on to be single mothers as it is common for them to be left by their male partners who claim they were unaware of their partner\'s SCD status. Not only does the abandonment experienced by these women cause emotional distress for them, but this low level of parental support can be linked to depressive symptoms and overall lower quality of life for the child once they are born.  United Kingdom  In 2021 many patients were found to be afraid to visit hospitals so purchasing pain relief to treat themselves outside the NHS, such was the level of ignorance among staff. They were often waiting a long time for pain relief, and sometimes suspected of “drugs-seeking” behaviour. Delays to treatment, failure to inform the hospital haematology team and poor pain management had caused deaths. Specialist haematology staff prefer to work in bigger, teaching hospitals, leading to shortages of expertise elsewhere. In 2021 the NHS initiated its first new treatment in 20 years for Sickle Cell. This involved the use of Crizanlizumab, a drug given via transfusion drips, which reduces the number of visits to A and E by sufferers. The treatment can be accessed, via consultants, at any of ten new hubs set up around the country. In the same year, however, an All-Party Parliamentary Group produced a report on Sickle Cell and Thalassaemia entitled \'No-one is listening\'. Partly in response to this, on 19 June 2022, World Sickle Cell Day, the NHS launched a campaign called "" Can you tell it\'s sickle cell?"". The campaign had twin aims. One was to increase awareness of the key signs and symptoms of the blood disorder so that people are as alert to signs of a sickle cell crisis as they are to an imminent heart attack or stroke. The second aim was to set up a new training programme to help paramedics, Accident and Emergency staff, carers and the general public to care effectively for sufferers in crisis.  Research   Umbilical cord blood transplant  While umbilical cord blood transplant can potentially cure the condition, a suitable donor is available in only 10% of people. About 7% of people also die as a result of the procedure and graft versus host disease may occur.  Gene therapy  Diseases such as sickle cell disease for which a person\'s normal phenotype or cell function may be restored in cells that have the disease by a normal copy of the gene that is mutated, may be a good candidate for gene therapy treatment. The risks and benefits related to gene therapy for sickle cell disease are not known.In 2001, sickle cell disease reportedly had been successfully treated in mice using gene therapy. The researchers used a viral vector to make the mice—which have essentially the same defect that causes human sickle cell disease—express production of fetal haemoglobin (HbF), which an individual normally ceases to produce shortly after birth. In humans, using hydroxyurea to stimulate the production of HbF has been known to temporarily alleviate sickle cell disease symptoms.","Sickle cell anaemia is a genetic disease. It affects red blood cells. It changes the cells from flexible disks into rigid crescents. When many red cells take this shape veins get blocked. This can cause damage to many organs. The organ damage increases with time and leads to an early death.  The disease  This is a lifelong disease which starts in childhood. The red blood cells take up an abnormal, rigid, sickle shape. The cells also become sticky. This causes difficult blood flow when cells flow through long narrow capillaries. Low oxygen increases the problem. As they pass through low oxygen areas most cells take up this shape. The cells then stick to the inner wall of blood vessels, especially the branching point of veins. This leads to a blockade of blood flow in many organs. Severe complications may result. The classic example of a sickle cell crisis is ""acute chest syndrome""(ACS). This is unique to sicklers, and can cause death in a day or two unless treated. Historically, acute chest syndrome was considered different from infection (pneumonia). But in treatment there is not much point making that distinction.ACS is a clinical diagnosis helped by at least one chest X-ray. In all other organs low oxygen causes widening of blood vessels. But the lung is a unique organ where blood vessels become narrower when oxygen is low. This unique problem makes the lung a major target of the disease. Fever is the most common symptom of ACS in children because infection is more common. In the adults circulating clots and broken pieces of bone marrow can also add to the blockage of vessels in the lung and lead to ACS. ACS can be partially treated by blood transfusion to dilute the sickled cells with some normal red blood cells. An even better treatment is a procedure called red blood cell exchange. Automated apheresis machines can do RBC exchange. A milder and more frequent problem is 'painful crisis'. Painful crisis involves flank, back and thigh pains that can be relieved by treatment. A painful crisis may evolve into worse problems such as acute chest and other organ failures e.g. strokes, heart attacks. Both strokes and heart attacks are general problems which may happen in older people. But in sickle patients these can happen even in the young. The spleen is involved differently in different ethnic groups with this disease. Spleen is the organ which filters old RBCs and destroys them. Old RBCs are stiff and cannot pass through some very narrow slits in the spleen. But in sickle patients all cells very quickly become stiff and thus keep clogging up the spleen. Starting from a very young age segments of the spleen die because of this problem. In the pure form of this disease the whole spleen is dead and shrunken before the patient become adult. Normal spleen keeps a large store of B cells which make antibodies and protect us from bacteria. Loss of a working spleen leads to loss of protection from such bacteria. In many Asian populations beta thalassaemia occurs together with sickle cell disease. Thalassemia itself is another form of anaemia. But the nature of the two disease are opposite. Thalassemia increases red cell flexibility. However, thalassemia itself can be a serious disease.  Population genetics  The sickling occurs because of a single point mutation in the gene for the beta chain of haemoglobin. Sickle-cell disease occurs more commonly in people (or their descendants) from parts of tropical and sub-tropical regions where malaria is or was common. One quarter of all people of Sub-Saharan African origin carry the gene. We all inherit two copies (alleles) of the hemoglobin beta gene. One comes each parent. Some people are heterozygous: they have the sickle mutation in one copy and the other copy is normal. Such people are called sickle trait or a carrier. People with sickle trait are more resistant to malaria than normal people.When both alleles of a gene are similar (homozygous) a person has copies mutated or both normal. If both alleles have the mutation, it causes the full disease. In malaria prone areas, normal people die frequently of malaria often before they had children. Those with both copies with sickle mutation die of sickle disease before they can reproduce. But the heterozygotes have a better survival (and have more children) than both homozygous groups. Thus, the inheritance of the disease is an example of 'heterozygous advantage'. In the full (homozygous) disease life expectancy is shortened, in fact it is near-fatal in pre-modern societies. Sir Cyril Clarke said (referring to East Africa in the 1960s) ""Almost all the children (with sickle-cell disease) will die in infancy"".p25. Studies in the modern U.S.A. report an average life expectancy of 42 years for males and 48 years for females.  References "
"Deafness has varying definitions in cultural and medical contexts. In medical contexts, the meaning of deafness is hearing loss that precludes a person from understanding spoken language, an audiological condition. In this context it is written with a lower case d. It later came to be used in a cultural context to refer to those who primarily communicate through sign language regardless of hearing ability, often capitalized as Deaf and referred to as ""big D Deaf"" in speech and sign. The two definitions overlap but are not identical, as hearing loss includes cases that are not severe enough to impact spoken language comprehension, while cultural Deafness includes hearing people who use sign language, such as children of deaf adults.  Medical context  In a medical context, deafness is defined as a degree of hearing difference such that a person is unable to understand speech, even in the presence of amplification. In profound deafness, even the highest intensity sounds produced by an audiometer (an instrument used to measure hearing by producing pure tone sounds through a range of frequencies) may not be detected. In total deafness, no sounds at all, regardless of amplification or method of production, can be heard. Neurologically, language is processed in the same areas of the brain whether one is deaf or hearing. The left hemisphere of the brain processes linguistic patterns whether by signed languages or by spoken languages.Deafness can be broken down into four different types of hearing loss: conductive hearing loss, sensorineural hearing loss, mixed hearing loss, and auditory neuropathy spectrum disorder. All of these forms of hearing loss cause an impairment in a person's hearing where they are not able to hear sounds correctly. These different types of hearing loss occur in different parts of the ear, which make it difficult for the information being heard to get sent to the brain properly. To break it down even further, there are three different levels of hearing loss. According to the CDC, the first level is mild hearing loss. This is when someone is still able to hear noises, but it is more difficult to hear the softer sounds. The second level is moderate hearing loss and this is when someone can hear almost nothing when someone is talking to them at a normal volume. The next level is severe hearing loss. Severe hearing loss is when someone can not hear any sounds when they are being produced at a normal level and they can only hear minimum sounds that are being produced at a loud level. The final level is profound hearing loss, which is when someone is not able to hear any sounds except for very loud ones.There are millions of people in the world who are living with deafness or hearing impairments. Survey of Income and Program Participation (SIPP) indicate that fewer than 1 in 20 Americans are currently deaf or hard of hearing. There are a lot of solutions available for people with hearing impairments. Some examples of solutions would be blinking lights on different things like their phones, alarms, and things that are important to alert them. Cochlear implants are an option too. Cochlear implants are surgically placed devices that stimulate the cochlear nerve in order to help the person hear. A cochlear implant is used instead of hearing aids in order to help when someone has difficulties understanding speech.  Cultural context  In a cultural context, Deaf culture refers to a tight-knit cultural group of people whose primary language is signed, and who practice social and cultural norms which are distinct from those of the surrounding hearing community. This community does not automatically include all those who are clinically or legally deaf, nor does it exclude every hearing person. According to Baker and Padden, it includes any person who ""identifies him/herself as a member of the Deaf community, and other members accept that person as a part of the community"", an example being children of deaf adults with normal hearing ability. It includes the set of social beliefs, behaviors, art, literary traditions, history, values, and shared institutions of communities that are influenced by deafness and which use sign languages as the main means of communication. Members of the Deaf community tend to view deafness as a difference in human experience rather than a disability or disease.Many non-disabled people continue to assume that deaf people have no autonomy and fail to provide people with support beyond hearing aids, which is something that must be addressed. Different non-governmental organizations around the world have created programs towards closing the gap between deaf and non-disabled people in developing countries. The Quota International organization with headquarters in the United States provided immense educational support in the Philippines, where it started providing free education to deaf children in the Leganes Resource Center for the Deaf. The Sounds Seekers British organization also provided support by offering audiology maintenance technology, to better assist those who are deaf in hard-to-reach places. The Nippon Foundation also supports deaf students at Gallaudet University and the National Technical Institute for the Deaf, through sponsoring international scholarships programs to encourage students to become future leaders in the deaf community. The more aid these organizations give to the deaf people, the more opportunities and resources disabled people must speak up about their struggles and goals that they aim to achieve. When more people understand how to leverage their privilege for the marginalized groups in the community, then we can build a more inclusive and tolerant environment for the generations that are yet to come.  History  The first known record of sign language in history comes from Plato's Cratylus, written in the fifth century BCE. In a dialogue on the ""correctness of names"", Socrates says, ""Suppose that we had no voice or tongue, and wanted to communicate with one another, should we not, like the deaf and dumb, make signs with the hands and head and the rest of the body?"" His belief that deaf people possessed an innate intelligence for language put him at odds with his student Aristotle, who said, ""Those who are born deaf all become senseless and incapable of reason,"" and that ""it is impossible to reason without the ability to hear"". This pronouncement would reverberate through the ages and it was not until the 17th century when manual alphabets began to emerge, as did various treatises on deaf education, such as Reducción de las letras y arte para enseñar a hablar a los mudos ('Reduction of letters and art for teaching mute people to speak'), written by Juan Pablo Bonet in Madrid in 1620, and Didascalocophus, or, The deaf and dumb mans tutor, written by George Dalgarno in 1680. In 1760, French philanthropic educator Charles-Michel de l'Épée opened the world's first free school for the deaf. The school won approval for government funding in 1791 and became known as the ""Institution Nationale des Sourds-Muets à Paris."" The school inspired the opening of what is today known as the American School for the Deaf, the oldest permanent school for the deaf in the United States, and indirectly, Gallaudet University, the world's first school for the advanced education of the deaf and hard of hearing, and to date, the only higher education institution in which all programs and services are specifically designed to accommodate deaf and hard of hearing students.  See also  Hearing loss Models of deafness Deaf culture Deaf education Deaf history History of sign language  References ","Deafness is when someone cannot hear at all, or cannot hear well. Deafness is also known as 'hearing loss'. There were many famous people who were deaf, such as Ludwig van Beethoven and Helen Keller.  Definition  A person is considered to be deaf if they cannot hear the same range of sounds as a person with normal hearing ability. People that cannot hear any sounds are also deaf. People who are partially deaf may hear some sounds and may hear words. People who cannot hear and understand words well are 'hard of hearing'. And people who cannot hear and speak are called ""deaf-mute"".  Things that help deaf people  Hearing aid, which helps a deaf person to hear sounds. Teletypewriter (TTY), a machine that allows a deaf person to communicate with people. Sign language, a language which allows a deaf person to have a conversation with someone else. Hearing dog, a dog that has been trained to hear sounds and help a deaf person.  Causes  There are different causes of deafness: Age: Many people hear less well as they get older. Few lose all hearing, and when they do, there is a specific reason. Exposure to noise: Being in a noisy environment for a long time may damage ears and cause hearing loss. Genetic conditions: There may be a history of deafness in the family. If the mother and/or father are deaf, their child will have a strong chance of being deaf. Diseases: Certain diseases may cause deafness. Drugs: Certain drugs may cause changes to hearing, including deafness. Chemicals: Certain chemicals can damage the ear. Natural: People are occasionally born deaf. Sometimes there is no explanation why they are deaf.  Categories of deafness  Generally, there are two views of deafness: Medical view: the effects of deafness and measuring type and how much of loss (as seen in categories below). Sign language in deaf culture: includes people who use sign language to communicate and are part of group of people who share life experiences. Referring to people of the cultural group the phrase ""Deaf people"" is used and deaf is capitalized (as shown previously). A person using the medical view would write ""people who are deaf"".These categories may overlap. Unilateral hearing loss – loss of hearing in one ear only Pre-lingual deafness – deafness at birth or deafness that started before language is learned Peri-lingual deafness – deafness that started while learning a first language Post-lingual deafness – deafness that started after a language has been learned Partial loss of hearing – limited hearing loss Progressive hearing loss – hearing loss that becomes worse as time passes Profound hearing loss – complete or near-complete hearing loss Tone deaf – not able to hear differences in relative pitch (in music) Tinnitus – hearing damage that causes high pitched ringing. This makes it so that the person cannot hear other sounds Conductive – hearing loss caused by sound being blocked from going into ears Sensorineural – hearing loss caused by hair cells in ears being damaged  Other websites "
"A cataract is a cloudy area in the lens of the eye that leads to a decrease in vision. Cataracts often develop slowly and can affect one or both eyes. Symptoms may include faded colours, blurry or double vision, halos around light, trouble with bright lights, and difficulty seeing at night. This may result in trouble driving, reading, or recognizing faces. Poor vision caused by cataracts may also result in an increased risk of falling and depression. Cataracts cause 51% of all cases of blindness and 33% of visual impairment worldwide.Cataracts are most commonly due to aging but may also occur due to trauma or radiation exposure, be present from birth, or occur following eye surgery for other problems. Risk factors include diabetes, longstanding use of corticosteroid medication, smoking tobacco, prolonged exposure to sunlight, and alcohol. The underlying mechanism involves accumulation of clumps of protein or yellow-brown pigment in the lens that reduces transmission of light to the retina at the back of the eye. Diagnosis is by an eye examination.Wearing sunglasses and a wide brimmed hat, eating leafy vegetables and fruits, and avoiding smoking may reduce the risk of developing cataracts, or slow down the process. Early on the symptoms may be improved with glasses. If this does not help, surgery to remove the cloudy lens and replace it with an artificial lens is the only effective treatment. Cataract surgery is not readily available in many countries, and surgery is needed only if the cataracts are causing problems and generally results in an improved quality of life.About 20 million people worldwide are blind due to cataracts. It is the cause of approximately 5% of blindness in the United States and nearly 60% of blindness in parts of Africa and South America. Blindness from cataracts occurs in about 10 to 40 per 100,000 children in the developing world, and 1 to 4 per 100,000 children in the developed world. Cataracts become more common with age. In the United States, cataracts occur in 68% of those over the age of 80 years. Additionally they are more common in women, and less common in Hispanic and Black people.  Signs and symptoms  Signs and symptoms vary depending on the type of cataract, though considerable overlap occurs. People with nuclear sclerotic or brunescent cataracts often notice a reduction of vision. Nuclear cataracts typically cause greater impairment of distance vision than of near vision. Those with posterior subcapsular cataracts usually complain of glare as their major symptom.The severity of cataract formation, assuming no other eye disease is present, is judged primarily by a visual acuity test. Other symptoms include frequent changes of glasses and colored halos due to hydration of lens.Congenital cataracts can result in amblyopia if not treated in a timely manner.  Causes   Age  Age is the most common cause of cataracts. Lens proteins denature and degrade over time, and this process is accelerated by diseases such as diabetes mellitus and hypertension. Environmental factors, including toxins, radiation, and ultraviolet light have cumulative effects which are worsened by the loss of protective and restorative mechanisms due to alterations in gene expression and chemical processes within the eye.Oxidative stress is an important pathogenic mechanism in cataract formation. Senile cataracts are associated with a decrease in antioxidant capacity in the lens. An increase in oxidative stress in the lens or a decrease in the ability to remove reactive oxygen species can lead to the lens becoming more opaque.  Trauma  Blunt trauma causes swelling, thickening, and whitening of the lens fibers. While the swelling normally resolves with time, the white color may remain. In severe blunt trauma, or in injuries that penetrate the eye, the capsule in which the lens sits can be damaged. This damage allows fluid from other parts of the eye to rapidly enter the lens leading to swelling and then whitening, obstructing light from reaching the retina at the back of the eye. Cataracts may develop in 0.7 to 8.0% of cases following electrical injuries. Blunt trauma can also result in star- (stellate) or petal-shaped cataracts.  Radiation  Cataracts can arise as an effect of exposure to various types of radiation. X-rays, one form of ionizing radiation, may damage the DNA of lens cells. Ultraviolet light, specifically UVB, has also been shown to cause cataracts, and some evidence indicates sunglasses worn at an early age can slow its development in later life. Microwaves, a type of nonionizing radiation, may cause harm by denaturing protective enzymes (e.g., glutathione peroxidase), by oxidizing protein thiol groups (causing protein aggregation), or by damaging lens cells via thermoelastic expansion. The protein coagulation caused by electric and heat injuries whitens the lens. This same process is what makes the clear albumen of an egg become white and opaque during cooking.  Genetics  The genetic component is strong in the development of cataracts, most commonly through mechanisms that protect and maintain the lens. The presence of cataracts in childhood or early life can occasionally be due to a particular syndrome. Examples of chromosome abnormalities associated with cataracts include 1q21.1 deletion syndrome, cri-du-chat syndrome, Down syndrome, Patau's syndrome, trisomy 18 (Edward's syndrome), and Turner's syndrome, and in the case of neurofibromatosis type 2, juvenile cataract on one or both sides may be noted. Examples of single-gene disorder include Alport's syndrome, Conradi's syndrome, cerebrotendineous xanthomatosis, myotonic dystrophy, and oculocerebrorenal syndrome or Lowe syndrome.  Skin diseases  The skin and the lens have the same embryological origin and so can be affected by similar diseases. Those with atopic dermatitis and eczema occasionally develop shield ulcer cataracts. Ichthyosis is an autosomal recessive disorder associated with cuneiform cataracts and nuclear sclerosis. Basal-cell nevus and pemphigus have similar associations.  Smoking and alcohol  Cigarette smoking has been shown to increase the risk of age-related cataract and nuclear cataract. Evidence is conflicting over the effect of alcohol. Some surveys have shown a link, but others which followed people over longer terms have not.  Inadequate vitamin C  Low vitamin C intake and serum levels have been associated with greater cataract rates. However, use of supplements of vitamin C has not demonstrated benefit.  Medications  Some medications, such as systemic, topical, or inhaled corticosteroids, may increase the risk of cataract development. Corticosteroids most commonly cause posterior subcapsular cataracts. People with schizophrenia often have risk factors for lens opacities (such as diabetes, hypertension, and poor nutrition). Second-generation antipsychotic medications are unlikely to contribute to cataract formation. Miotics and triparanol may increase the risk.  Post-operative  Nearly every person who undergoes a vitrectomy—without ever having had cataract surgery—will experience progression of nuclear sclerosis after the operation. This may be because the native vitreous humor is different from the solutions used to replace the vitreous (vitreous substitutes), such as BSS Plus. This may also be because the native vitreous humour contains ascorbic acid which helps neutralize oxidative damage to the lens and because conventional vitreous substitutes do not contain ascorbic acid. Accordingly, for phakic patients requiring a vitrectomy it is becoming increasingly common for ophthalmologists to offer the vitrectomy combined with prophylactic cataract surgery to prevent cataract formation.  Hyperbaric oxygen therapy  Hyperbaric oxygen therapy (HBOT) is the administration of 100% oxygen at pressures greater than one-atmosphere absolute pressure (1 ATA) for a therapeutic purpose. HBOT can have several side effects, including the long term development of cataracts. This is rare and generally associated with multiple HBOT exposures over a long period. As it does not usually become symptomatic during HBOT, it may often go unrecognised and is probably under-reported. Evidence is emerging that lifetime dosage of oxygen may be a precipitating factor in the development of age-related cataracts. Nuclear cataracts have been hypothesized to be the end stage of the far better known phenomenon of hyperbaric myopic shift.  Other diseases   Diagnosis   Classification  Cataracts may be partial or complete, stationary or progressive, hard or soft. Histologically, the main types of age-related cataracts are nuclear sclerosis, cortical, and posterior subcapsular.Nuclear sclerosis is the most common type of cataract, and involves the central or 'nuclear' part of the lens. This eventually becomes hard, or 'sclerotic', due to condensation on the lens nucleus and the deposition of brown pigment within the lens. In its advanced stages, it is called a brunescent cataract. In early stages, an increase in sclerosis may cause an increase in refractive index of the lens. This causes a myopic shift (lenticular shift) that decreases hyperopia and enables presbyopic patients to see at near without reading glasses. This is only temporary and is called second sight.Cortical cataracts are due to the lens cortex (outer layer) becoming opaque. They occur when changes in the fluid contained in the periphery of the lens causes fissuring. When these cataracts are viewed through an ophthalmoscope, or other magnification system, the appearance is similar to white spokes of a wheel. Symptoms often include problems with glare and light scatter at night.Posterior subcapsular cataracts are cloudy at the back of the lens adjacent to the capsule (or bag) in which the lens sits. Because light becomes more focused toward the back of the lens, they can cause disproportionate symptoms for their size.An immature cataract has some transparent protein, but with a mature cataract, all the lens protein is opaque. In a hypermature or Morgagnian cataract, the lens proteins have become liquid. Congenital cataract, which may be detected in adulthood, has a different classification and includes lamellar, polar, and sutural cataracts.Cataracts can be classified by using the lens opacities classification system LOCS III. In this system, cataracts are classified based on type as nuclear, cortical, or posterior. The cataracts are further classified based on severity on a scale from 1 to 5. The LOCS III system is highly reproducible.  Prevention  Risk factors such as UVB exposure and smoking can be addressed. Although no means of preventing cataracts has been scientifically proven, wearing sunglasses that block ultraviolet light may slow their development. While adequate intake of vitamins A, C, and E may protect against the risk of cataracts, clinical trials have shown no benefit from supplements, although the evidence is mixed, but weakly positive, for a potential protective effect of the carotenoids, lutein and zeaxanthin.  Treatment   Surgical  The appropriateness of surgery depends on a person's particular functional and visual needs and other risk factors. Cataract removal can be performed at any stage and no longer requires ripening of the lens. Surgery is usually ""outpatient"" and usually performed using local anesthesia. About 9 of 10 patients can achieve a corrected vision of 20/40 or better after surgery.Several recent evaluations found that cataract surgery can meet expectations only when significant functional impairment due to cataracts exists before surgery. Visual function estimates such as VF-14 have been found to give more realistic estimates than visual acuity testing alone. In some developed countries, a trend to overuse cataract surgery has been noted, which may lead to disappointing results.Phacoemulsification is the most widely used cataract surgery in the developed world. This procedure uses ultrasonic energy to emulsify the cataract lens. Phacoemulsification typically comprises six steps: Anaesthetic – The eye is numbed with either a subtenon injection around the eye (see: retrobulbar block) or topical anesthetic eye drops. The former also provides paralysis of the eye muscles. Corneal incision – Two cuts are made at the margin of the clear cornea to allow insertion of instruments into the eye. Capsulorhexis – A needle or small pair of forceps is used to create a circular hole in the capsule in which the lens sits. Phacoemulsification – A handheld ultrasonic probe is used to break up and emulsify the lens into liquid using the energy of ultrasound waves. The resulting 'emulsion' is sucked away. Irrigation and aspiration – The cortex, which is the soft outer layer of the cataract, is aspirated or sucked away. Fluid removed is continually replaced with a saline solution to prevent collapse of the structure of the anterior chamber (the front part of the eye). Lens insertion – A plastic, foldable lens is inserted into the capsular bag that formerly contained the natural lens. Some surgeons also inject an antibiotic into the eye to reduce the risk of infection. The final step is to inject salt water into the corneal wounds to cause the area to swell and seal the incision.A Cochrane review found little to no difference in visual acuity as a function of the size of incisions made for phacoemulsification in the range from ≤ 1.5 mm to 3.0 mm. Extracapsular cataract extraction (ECCE) consists of removing the lens manually, but leaving the majority of the capsule intact. The lens is expressed through a 10- to 12-mm incision which is closed with sutures at the end of surgery. ECCE is less frequently performed than phacoemulsification, but can be useful when dealing with very hard cataracts or other situations where emulsification is problematic. Manual small incision cataract surgery (MSICS) has evolved from ECCE. In MSICS, the lens is removed through a self-sealing scleral tunnel wound in the sclera which, ideally, is watertight and does not require suturing. Although ""small"", the incision is still markedly larger than the portal in phacoemulsification. This surgery is increasingly popular in the developing world where access to phacoemulsification is still limited.Intracapsular cataract extraction (ICCE) is rarely performed. The lens and surrounding capsule are removed in one piece through a large incision while pressure is applied to the vitreous membrane. The surgery has a high rate of complications.  Prognosis   Postoperative care  The postoperative recovery period (after removing the cataract) is usually short. The patient is usually ambulatory on the day of surgery, but is advised to move cautiously and avoid straining or heavy lifting for about a month. The eye is usually patched on the day of surgery and use of an eye shield at night is often suggested for several days after surgery.In all types of surgery, the cataractous lens is removed and replaced with an artificial lens, known as an intraocular lens, which stays in the eye permanently. Intraocular lenses are usually monofocal, correcting for either distance or near vision. Multifocal lenses may be implanted to improve near and distance vision simultaneously, but these lenses may increase the chance of unsatisfactory vision.  Complications  Serious complications of cataract surgery include retinal detachment and endophthalmitis. In both cases, patients notice a sudden decrease in vision. In endophthalmitis, patients often describe pain. Retinal detachment frequently presents with unilateral visual field defects, blurring of vision, flashes of light, or floating spots.The risk of retinal detachment was estimated as about 0.4% within 5.5 years, corresponding to a 2.3-fold risk increase compared to naturally expected incidence, with older studies reporting a substantially higher risk. The incidence is increasing over time in a somewhat linear manner, and the risk increase lasts for at least 20 years after the procedure. Particular risk factors are younger age, male sex, longer axial length, and complications during surgery. In the highest risk group of patients, the incidence of pseudophakic retinal detachment may be as high as 20%.The risk of endophthalmitis occurring after surgery is less than one in 1000.Corneal edema and cystoid macular edema are less serious but more common, and occur because of persistent swelling at the front of the eye in corneal edema or back of the eye in cystoid macular edema. They are normally the result of excessive inflammation following surgery, and in both cases, patients may notice blurred, foggy vision. They normally improve with time and with application of anti-inflammatory drops. The risk of either occurring is around one in 100. It is unclear whether NSAIDs or corticosteroids are superior at reducing postoperative inflammation.Posterior capsular opacification, also known as after-cataract, is a condition in which months or years after successful cataract surgery, vision deteriorates or problems with glare and light scattering recur, usually due to thickening of the back or posterior capsule surrounding the implanted lens, so-called 'posterior lens capsule opacification'. Growth of natural lens cells remaining after the natural lens was removed may be the cause, and the younger the patient, the greater the chance of this occurring. Management involves cutting a small, circular area in the posterior capsule with targeted beams of energy from a laser, called Nd:YAG laser capsulotomy, after the type of laser used. The laser can be aimed very accurately, and the small part of the capsule which is cut falls harmlessly to the bottom of the inside of the eye. This procedure leaves sufficient capsule to hold the lens in place, but removes enough to allow light to pass directly through to the retina. Serious side effects are rare. Posterior capsular opacification is common and occurs following up to one in four operations, but these rates are decreasing following the introduction of modern intraocular lenses together with a better understanding of the causes.Vitreous touch syndrome is a possible complication of intracapsular cataract extraction.  Epidemiology  Age-related cataracts are responsible for 51% of world blindness, about 20 million people. Globally, cataracts cause moderate to severe disability in 53.8 million (2004), 52.2 million of whom are in low and middle income countries.In many countries, surgical services are inadequate, and cataracts remain the leading cause of blindness. Even where surgical services are available, low vision associated with cataracts may still be prevalent as a result of long waits for, and barriers to, surgery, such as cost, lack of information and transportation problems. In the United States, age-related lens changes have been reported in 42% between the ages of 52 and 64, 60% between the ages 65 and 74, and 91% between the ages of 75 and 85. Cataracts affect nearly 22 million Americans age 40 and older. By age 80, more than half of all Americans have cataracts. Direct medical costs for cataract treatment are estimated at $6.8 billion annually.In the eastern Mediterranean region, cataracts are responsible for over 51% of blindness. Access to eye care in many countries in this region is limited. Childhood-related cataracts are responsible for 5–20% of world childhood blindness.  History  Cataract surgery was first described by the Ayurvedic physician, Suśruta (about 5th century BCE) in Sushruta Samhita in ancient India. Most of the methods mentioned focus on hygiene. Follow-up treatments include bandaging of the eye and covering the eye with warm butter. References to cataracts and their treatment in Ancient Rome are also found in 29 AD in De Medicinae, the work of the Latin encyclopedist Aulus Cornelius Celsus. Archaeological evidence of eye surgery in the Roman era also exists.Galen of Pergamon (ca. 2nd century CE), a prominent Greek physician, surgeon and philosopher, performed an operation similar to modern cataract surgery. Using a needle-shaped instrument, Galen attempted to remove the cataract-affected lens of the eye.Muslim ophthalmologist Ammar Al-Mawsili, in his The Book of Choice in Ophthalmology, written circa 1000 CE, wrote of his invention of a syringe and the technique of cataract extraction while experimenting with it on a patient.  Etymology  ""Cataract"" is derived from the Latin cataracta, meaning ""waterfall"", and from the Ancient Greek καταρράκτης (katarrhaktēs), ""down-rushing"", from καταράσσω (katarassō) meaning ""to dash down"" (from kata-, ""down""; arassein, ""to strike, dash""). As rapidly running water turns white, so the term may have been used metaphorically to describe the similar appearance of mature ocular opacities. In Latin, cataracta had the alternative meaning ""portcullis"" and the name possibly passed through French to form the English meaning ""eye disease"" (early 15th century), on the notion of ""obstruction"". Early Persian physicians called the term nazul-i-ah, or ""descent of the water""—vulgarised into waterfall disease or cataract—believing such blindness to be caused by an outpouring of corrupt humour into the eye.  Research  N-Acetylcarnosine drops have been investigated as a medical treatment for cataracts. The drops are believed to work by reducing oxidation and glycation damage in the lens, particularly reducing crystallin crosslinking. Some benefit has been shown in small manufacturer-sponsored randomized controlled trials but further independent corroboration is still required.Femtosecond laser mode-locking, used during cataract surgery, was originally used to cut accurate and predictable flaps in LASIK surgery, and has been introduced to cataract surgery. The incision at the junction of the sclera and cornea and the hole in capsule during capsulorhexis, traditionally made with a handheld blade, needle, and forceps, are dependent on skill and experience of the surgeon. Sophisticated three-dimensional images of the eyes can be used to guide lasers to make these incisions. A Nd:YAG laser can also then break up the cataract as in phacoemulsification.Stem cells have been used in a clinical trial for lens regeneration in twelve children under the age of two with cataracts present at birth. The children were followed for six months, so it is unknown what the long-term results will be, and it is unknown if this procedure would work in adults.  See also  Galactosemic cataract – medical conditionPages displaying wikidata descriptions as a fallback Intraocular lens – Lens implanted in the eye to treat cataracts or myopia  References   Further reading  Truscott RJ, Friedrich MG (December 2019). ""Molecular Processes Implicated in Human Age-Related Nuclear Cataract"". Investigative Ophthalmology & Visual Science. 60 (15): 5007–5021. doi:10.1167/iovs.19-27535. OCLC 1141250841. PMC 7043214. PMID 31791064.  External links  Cataract at Curlie Pictures of different types of cataracts","A cataract is when the lens of the eye gets cloudy. It is a treatable medical condition. Cataracts can cause short-sightedness (myopia), which means you cannot see things in the distance but can see things up close. If not fixed by surgery, some types of cataracts will cause blindness (which means you cannot see anything at all). In a simple operation, the old lens can be replaced by a new plastic one. Many thousands of people have had this operation.  Other websites  https://www.mayoclinic.org/diseases-conditions/cataracts/symptoms-causes/syc-20353790"
"Anxiety disorders are a cluster of mental disorders characterized by significant and uncontrollable feelings of anxiety and fear such that a person's social, occupational, and personal function are significantly impaired. Anxiety may cause physical and cognitive symptoms, such as restlessness, irritability, easy fatiguability, difficulty concentrating, increased heart rate, chest pain, abdominal pain, and a variety of other symptoms that may vary based on the individual.In casual discourse, the words anxiety and fear are often used interchangeably. In clinical usage, they have distinct meanings: anxiety is defined as an unpleasant emotional state for which the cause is either not readily identified or perceived to be uncontrollable or unavoidable, whereas fear is an emotional and physiological response to a recognized external threat. The umbrella term anxiety disorder refers to a number of specific disorders that include fears (phobias) or anxiety symptoms. There are several types of anxiety disorders, including generalized anxiety disorder, illness anxiety disorder, specific phobia, social anxiety disorder, separation anxiety disorder, agoraphobia, panic disorder, and selective mutism. The individual disorder can be diagnosed using the specific and unique symptoms, triggering events, and timing. If a person is diagnosed with an anxiety disorder, a medical professional must have evaluated the person to ensure the anxiety cannot be attributed to another medical illness or mental disorder. It is possible for an individual to have more than one anxiety disorder during their life or at the same time and anxiety disorders are marked by a typical persistent course. Anxiety disorders are the most common of mental disorders and affect nearly 30% of adults at some point in their lives. However, anxiety disorders are treatable and a number of effective treatments are available. Treatment helps most people lead normal productive lives.  Types   Generalized anxiety disorder  Generalized anxiety disorder (GAD) is a common disorder, characterized by long-lasting anxiety which is not focused on any one object or situation. Those with generalized anxiety disorder experience non-specific persistent fear and worry, and become overly concerned with everyday matters. Generalized anxiety disorder is ""characterized by chronic excessive worry accompanied by three or more of the following symptoms: restlessness, fatigue, concentration problems, irritability, muscle tension, and sleep disturbance"". Generalized anxiety disorder is the most common anxiety disorder to affect older adults. Anxiety can be a symptom of a medical or substance use disorder problem, and medical professionals must be aware of this. A diagnosis of GAD is made when a person has been excessively worried about an everyday problem for six months or more. These stresses can include family life, work, social life, or their own health. A person may find that they have problems making daily decisions and remembering commitments as a result of lack of concentration and/or preoccupation with worry. A symptom can be a strained appearance, with increased sweating from the hands, feet, and axillae, and they may be tearful, which can suggest depression. Before a diagnosis of anxiety disorder is made, physicians must rule out drug-induced anxiety and other medical causes.In children, GAD may be associated with headaches, restlessness, abdominal pain, and heart palpitations. Typically it begins around 8 to 9 years of age.  Specific phobias  The single largest category of anxiety disorders is that of specific phobias, which includes all cases in which fear and anxiety are triggered by a specific stimulus or situation. Between 5% and 12% of the population worldwide have specific phobias. According to the National Institute of Mental Health, a phobia is an intense fear of or aversion to specific objects or situations. Individuals with a phobia typically anticipate terrifying consequences from encountering the object of their fear, which can be anything from an animal to a location to a bodily fluid to a particular situation. Common phobias are flying, blood, water, highway driving, and tunnels. When people are exposed to their phobia, they may experience trembling, shortness of breath, or rapid heartbeat. Thus meaning that people with specific phobias often go out of their way to avoid encountering their phobia. People understand that their fear is not proportional to the actual potential danger but still are overwhelmed by it.  Panic disorder  With panic disorder, a person has brief attacks of intense terror and apprehension, often marked by trembling, shaking, confusion, dizziness, nausea, and/or difficulty breathing. These panic attacks, defined by the APA as fear or discomfort that abruptly arises and peaks in less than ten minutes, can last for several hours. Attacks can be triggered by stress, irrational thoughts, general fear or fear of the unknown, or even exercise. However, sometimes the trigger is unclear and the attacks can arise without warning. To help prevent an attack, one can avoid the trigger. This can mean avoiding places, people, types of behaviors, or certain situations that have been known to cause a panic attack. This being said, not all attacks can be prevented. In addition to recurrent unexpected panic attacks, a diagnosis of panic disorder requires that said attacks have chronic consequences: either worry over the attacks' potential implications, persistent fear of future attacks, or significant changes in behavior related to the attacks. As such, those with panic disorder experience symptoms even outside specific panic episodes. Often, normal changes in heartbeat are noticed, leading them to think something is wrong with their heart or they are about to have another panic attack. In some cases, a heightened awareness (hypervigilance) of body functioning occurs during panic attacks, wherein any perceived physiological change is interpreted as a possible life-threatening illness (i.e., extreme hypochondriasis).  Agoraphobia  Agoraphobia is the specific anxiety about being in a place or situation where escape is difficult or embarrassing or where help may be unavailable. Agoraphobia is strongly linked with panic disorder and is often precipitated by the fear of having a panic attack. A common manifestation involves needing to be in constant view of a door or other escape route. In addition to the fears themselves, the term agoraphobia is often used to refer to avoidance behaviors that individuals often develop. For example, following a panic attack while driving, someone with agoraphobia may develop anxiety over driving and will therefore avoid driving. These avoidance behaviors can have serious consequences and often reinforce the fear they are caused by. In a severe case of agoraphobia, the person may never leave their home.  Social anxiety disorder  Social anxiety disorder (SAD; also known as social phobia) describes an intense fear and avoidance of negative public scrutiny, public embarrassment, humiliation, or social interaction. This fear can be specific to particular social situations (such as public speaking) or, more typically, is experienced in most (or all) social interactions. Roughly 7% of American adults have social anxiety disorder, and more than 75% of people experience their first symptoms in their childhood or early teenage years. Social anxiety often manifests specific physical symptoms, including blushing, sweating, rapid heart rate, and difficulty speaking. As with all phobic disorders, those with social anxiety often will attempt to avoid the source of their anxiety; in the case of social anxiety this is particularly problematic, and in severe cases can lead to complete social isolation. Children are also affected by social anxiety disorder, although their associated symptoms are different than that of teenagers and adults. They may experience difficulty processing or retrieving information, sleep deprivation, disruptive behaviors in class, and irregular class participation.Social physique anxiety (SPA) is a subtype of social anxiety, involving concern over the evaluation of one's body by others. SPA is common among adolescents, especially females.  Post-traumatic stress disorder  Post-traumatic stress disorder (PTSD) was once an anxiety disorder (now moved to trauma- and stressor-related disorders in DSM-V) that results from a traumatic experience. PTSD affects approximately 3.5% of U.S. adults every year, and an estimated one in eleven people will be diagnosed with PTSD in their lifetime. Post-traumatic stress can result from an extreme situation, such as combat, natural disaster, rape, hostage situations, child abuse, bullying, or even a serious accident. It can also result from long-term (chronic) exposure to a severe stressor— for example, soldiers who endure individual battles but cannot cope with continuous combat. Common symptoms include hypervigilance, flashbacks, avoidant behaviors, anxiety, anger and depression. In addition, individuals may experience sleep disturbances. People who have PTSD often try to detach themselves from their friends and family, and have difficulty maintaining these close relationships. There are a number of treatments that form the basis of the care plan for those with PTSD. Such treatments include cognitive behavioral therapy (CBT), prolonged exposure therapy, stress inoculation therapy, medication, and psychotherapy and support from family and friends.Post-traumatic stress disorder (PTSD) research began with Vietnam veterans, as well as natural and non-natural disaster victims. Studies have found the degree of exposure to a disaster has been found to be the best predictor of PTSD.  Separation anxiety disorder  Separation anxiety disorder (SepAD) is the feeling of excessive and inappropriate levels of anxiety over being separated from a person or place. Separation anxiety is a normal part of development in babies or children, and it is only when this feeling is excessive or inappropriate that it can be considered a disorder. Separation anxiety disorder affects roughly 7% of adults and 4% of children, but the childhood cases tend to be more severe; in some instances, even a brief separation can produce panic. Treating a child earlier may prevent problems. This may include training the parents and family on how to deal with it. Often, the parents will reinforce the anxiety because they do not know how to properly work through it with the child. In addition to parent training and family therapy, medication, such as SSRIs, can be used to treat separation anxiety.  Obsessive–compulsive disorder  Obsessive–compulsive disorder (OCD) is not an anxiety disorder in the DSM-5 or the ICD-11. However older versions: the DSM-IV and ICD-10, classified OCD as anxiety disorder. OCD manifests in the form of as obsessions (distressing, persistent, and intrusive thoughts or images) and compulsions (urges to repeatedly perform specific acts or rituals), that are not caused by drugs or physical disorder, and which cause anxiety or distress plus (more or less important) functional disabilities. OCD affects roughly 1–⁠2% of adults (somewhat more women than men), and under 3% of children and adolescents.A person with OCD knows that the symptoms are unreasonable and struggles against both the thoughts and the behavior. Their symptoms could be related to external events they fear, such as their home burning down because they forgot to turn off the stove, or worry that they will behave inappropriately. The compulsive rituals are personal rules they follow to relieve discomfort, such as needing to verify that the stove is turned off a specific number of times before leaving the house.It is not certain why some people have OCD, but behavioral, cognitive, genetic, and neurobiological factors may be involved. Risk factors include family history, being single (although that may result from the disorder), and higher socioeconomic class or not being in paid employment. Of those with OCD about 20% of people will overcome it, and symptoms will at least reduce over time for most people (a further 50%).  Selective mutism  Selective mutism (SM) is a disorder in which a person who is normally capable of speech does not speak in specific situations or to specific people. Selective mutism usually co-exists with shyness or social anxiety. People with selective mutism stay silent even when the consequences of their silence include shame, social ostracism or even punishment. Selective mutism affects about 0.8% of people at some point in their life.Testing for selective mutism is important because doctors must determine if it is an issue associated with the child's hearing, movements associated with the jaw or tongue, and if the child can understand when others are speaking to them. Generally, Cognitive behavioral therapy (CBT) is the recommended approach for treating Selective Mutism, but prospective long-term outcome studies are lacking.  Diagnosis  The diagnosis of anxiety disorders is made by symptoms, triggers, and a person's personal and family histories. There are no objective biomarkers or laboratory tests that can diagnose anxiety. It is important for a medical professional to evaluate a person for other medical and mental causes for prolonged anxiety because treatments will vary considerably.Numerous questionnaires have been developed for clinical use and can be used for an objective scoring system. Symptoms may be vary between each subtype of generalized anxiety disorder. Generally, symptoms must be present for at least six months, occur more days than not, and significantly impair a person's ability to function in daily life. Symptoms may include: feeling nervous, anxious, or on edge; worrying excessively; difficulty concentrating; restlessness; irritability.Questionnaires developed for clinical use include the State-Trait Anxiety Inventory (STAI), the Generalized Anxiety Disorder 7 (GAD-7), the Beck Anxiety Inventory (BAI), the Zung Self-Rating Anxiety Scale, and the Taylor Manifest Anxiety Scale. Other questionnaires combine anxiety and depression measurement, such as the Hamilton Anxiety Rating Scale, the Hospital Anxiety and Depression Scale (HADS), the Patient Health Questionnaire (PHQ), and the Patient-Reported Outcomes Measurement Information System (PROMIS). Examples of specific anxiety questionnaires include the Liebowitz Social Anxiety Scale (LSAS), the Social Interaction Anxiety Scale (SIAS), the Social Phobia Inventory (SPIN), the Social Phobia Scale (SPS), and the Social Anxiety Questionnaire (SAQ-A30).  Differential diagnosis  Anxiety disorders differ from developmentally normal fear or anxiety by being excessive or persisting beyond developmentally appropriate periods. They differ from transient fear or anxiety, often stress-induced, by being persistent (e.g., typically lasting 6 months or more), although the criterion for duration is intended as a general guide with allowance for some degree of flexibility and is sometimes of shorter duration in children.The diagnosis of an anxiety disorder requires first ruling out an underlying medical cause. Diseases that may present similar to an anxiety disorder, including certain endocrine diseases (hypo- and hyperthyroidism, hyperprolactinemia), metabolic disorders (diabetes), deficiency states (low levels of vitamin D, B2, B12, folic acid), gastrointestinal diseases (celiac disease, non-celiac gluten sensitivity, inflammatory bowel disease), heart diseases, blood diseases (anemia), and brain degenerative diseases (Parkinson's disease, dementia, multiple sclerosis, Huntington's disease).Several drugs can also cause or worsen anxiety, whether in intoxication, withdrawal, or from chronic use. These include alcohol, tobacco, cannabis, sedatives (including prescription benzodiazepines), opioids (including prescription painkillers and illicit drugs like heroin), stimulants (such as caffeine, cocaine and amphetamines), hallucinogens, and inhalants.  Prevention  Focus is increasing on prevention of anxiety disorders. There is tentative evidence to support the use of cognitive behavioral therapy and mindfulness therapy. A 2013 review found no effective measures to prevent GAD in adults. A 2017 review found that psychological and educational interventions had a small benefit for the prevention of anxiety. Research indicates that predictors of the emergence of anxiety disorders partly differ from the factors that predict their persistence.  Perception and Discrimination   Stigma  People with an anxiety disorder may be challenged by prejudices and stereotypes that the world believes, most likely as a result of misconception around anxiety and anxiety disorders. Misconceptions found in a data analysis from the National Survey of Mental Health Literacy and Stigma include (1) many people believe anxiety is not a real medical illness; and (2) many people believe that people with anxiety could turn it off if they wanted to. For people experiencing the physical and mental symptoms of an anxiety disorder, stigma and negative social perception can make an individual less likely to seek treatment.There are two prevalent types of stigmas that surround anxiety disorders: Public and Self-Stigma. Public stigma in this context is the reaction that the general population has to people with an anxiety disorder. Self-Stigma is described as the prejudice which people with mental illness turn against themselves.There is no explicit evidence that announces the exact cause of stigma towards anxiety, however there are three highlighted perspectives. The macro, intermediate, and micro levels. The macro level marks society as whole with the influence from mass media. The intermediate level includes health care professionals and their perspective. The micro level details the individuals contributions to the process through self-stigmatization.Stigma can be described in three conceptual ways: cognitive, emotional, and behavioural. This allows for differentiation between stereotypes, prejudice, and discrimination.  Treatment  Treatment options include lifestyle changes, therapy, and medications. There is no clear evidence as to whether therapy or medication is most effective; the specific medication decision can be made by a doctor and patient with consideration to the patient's specific circumstances and symptoms. If while on treatment with a chosen medication, the person's anxiety does not improve, another medication may be offered. Specific treatments will vary by subtype of anxiety disorder, a person's other medical conditions, and medications.  Lifestyle and diet  Lifestyle changes include exercise, for which there is moderate evidence for some improvement, regularizing sleep patterns, reducing caffeine intake, and stopping smoking. Stopping smoking has benefits in anxiety as large as or larger than those of medications. Omega-3 polyunsaturated fatty acids, such as fish oil, may reduce anxiety, particularly in those with more significant symptoms.  Psychotherapy  Cognitive behavioral therapy (CBT) is effective for anxiety disorders and is a first-line treatment. CBT appears to be equally effective when carried out via the internet compared to sessions completed face to face.Mindfulness-based programs also appear to be effective for managing anxiety disorders. It is unclear if meditation has an effect on anxiety and transcendental meditation appears to be no different than other types of meditation.A 2015 Cochrane review of Morita therapy for anxiety disorder in adults found not enough evidence to draw a conclusion.Adventure-based counseling can be an effective way to anxiety. Using rock-climbing as an example, climbing can often bring on fear or frustration, and tackling these negative feelings in a nurturing environment can help people develop coping mechanisms necessary to deal with these negative feelings.  Medications  First-line choices for medications include SSRIs or SNRIs to treat generalized anxiety disorder. For adults there is no good evidence supporting which specific medication in the SSRI or SNRI class is best for treating anxiety, so cost often drives drug choice. Fluvoxamine is effective in treating a range of anxiety disorders in children and adolescents. Fluoxetine, sertraline and paroxetine can also help with some forms of anxiety in children and adolescents. If the chosen medicine is effective, it is recommended that it is continued for at least a year. Stopping medication results in a greater risk of relapse.Buspirone and pregabalin are second-line treatments for people who do not respond to SSRIs or SNRIs. Pregabalin and gabapentin are effective in treating some anxiety disorders but there is concern regarding their off-label use due to the lack of strong scientific evidence for their efficacy in multiple conditions and their proven side effects.Medications need to be used with care among older adults, who are more likely to have side effects because of coexisting physical disorders. Adherence problems are more likely among older people, who may have difficulty understanding, seeing, or remembering instructions.In general, medications are not seen as helpful in specific phobia, but a benzodiazepine is sometimes used to help resolve acute episodes. In 2007, data were sparse for efficacy of any drug.  Cannabis  As of 2019, there is little evidence for cannabis in treating anxiety disorders.  Children  Both therapy and a number of medications have been found to be useful for treating childhood anxiety disorders. Therapy is generally preferred to medication.Cognitive behavioral therapy (CBT) is a good first therapy approach. Studies have gathered substantial evidence for treatments that are not CBT-based as being effective forms of treatment, expanding treatment options for those who do not respond to CBT. Although studies have demonstrated the effectiveness of CBT for anxiety disorders in children and adolescents, evidence that it is more effective than treatment as usual, medication, or wait list controls is inconclusive. Like adults, children may undergo psychotherapy, cognitive-behavioral therapy, or counseling. Family therapy is a form of treatment in which the child meets with a therapist together with the primary guardians and siblings. Each family member may attend individual therapy, but family therapy is typically a form of group therapy. Art and play therapy are also used. Art therapy is most commonly used when the child will not or cannot verbally communicate, due to trauma or a disability in which they are nonverbal. Participating in art activities allows the child to express what they otherwise may not be able to communicate to others. In play therapy, the child is allowed to play however they please as a therapist observes them. The therapist may intercede from time to time with a question, comment, or suggestion. This is often most effective when the family of the child plays a role in the treatment.If a medication option is warranted, antidepressants such as SSRIs and SNRIs can be effective. Fluvoxamine is effective in treating a range of anxiety disorders in children and adolescents. Minor side effects with medications, however, are common.  Epidemiology  Globally, as of 2010, approximately 273 million (4.5% of the population) had an anxiety disorder. It is more common in females (5.2%) than males (2.8%).In Europe, Africa and Asia, lifetime rates of anxiety disorders are between 9 and 16%, and yearly rates are between 4 and 7%. In the United States, the lifetime prevalence of anxiety disorders is about 29% and between 11 and 18% of adults have the condition in a given year. This difference is affected by the range of ways in which different cultures interpret anxiety symptoms and what they consider to be normative behavior. In general, anxiety disorders represent the most prevalent psychiatric condition in the United States, outside of substance use disorder.Like adults, children can experience anxiety disorders; between 10 and 20 percent of all children will develop a full-fledged anxiety disorder prior to the age of 18, making anxiety the most common mental health issue in young people. Anxiety disorders in children are often more challenging to identify than their adult counterparts, owing to the difficulty many parents face in discerning them from normal childhood fears. Likewise, anxiety in children is sometimes misdiagnosed as attention deficit hyperactivity disorder or, due to the tendency of children to interpret their emotions physically (as stomachaches, headaches, etc.), anxiety disorders may initially be confused with physical ailments.Anxiety in children has a variety of causes; sometimes anxiety is rooted in biology, and may be a product of another existing condition, such as autism spectrum disorder. Gifted children are also often more prone to excessive anxiety than non-gifted children. Other cases of anxiety arise from the child having experienced a traumatic event of some kind, and in some cases, the cause of the child's anxiety cannot be pinpointed.Anxiety in children tends to manifest along age-appropriate themes, such as fear of going to school (not related to bullying) or not performing well enough at school, fear of social rejection, fear of something happening to loved ones, etc. What separates disordered anxiety from normal childhood anxiety is the duration and intensity of the fears involved.  See also  List of people with an anxiety disorder Exposure Therapy Mixed anxiety–depressive disorder  References   External links  Support Group Providers for Anxiety disorder at Curlie","The term anxiety disorder is a term for a number of psychiatric disorders. These disorders can be classified into two very broad groups: Disorders that are marked by extreme worry about the past, present or future. Disorders that are marked by fear of a given object or situation.Anxiety conditions include phobia, social anxiety disorder and generalized anxiety disorder. Other anxiety disorders include agoraphobia and panic disorder. Stress from life events, including past abuse, being intimidated or health worries, can trigger anxiety problems for many people. Symptoms include headache, spasms in the muscle, trembling, fatigue and exhaustion. There are various manners for treating anxiety disorders. These include medication and therapy. There is some recent research.When people talk about feeling, they use the words anxiety and fear without making much of a difference. When professionals talk about them, there is a difference, though: Fear always has a cause, people are afraid of something or of something happening. So fear is the emotional response to an external threat. Anxiety is more general, the cause is either not known, or not controllable easily. Both fear and anxiety are normal reactions, to protect against a threat. Someone feeling fear or anxiety now and then does not have an anxiety disorder. Only when they occur so often that they impact people's lives do they become a disorder.  References "
"Psychotherapy (also psychological therapy, talk therapy, or talking therapy) is the use of psychological methods, particularly when based on regular personal interaction, to help a person change behavior, increase happiness, and overcome problems. Psychotherapy aims to improve an individual\'s well-being and mental health, to resolve or mitigate troublesome behaviors, beliefs, compulsions, thoughts, or emotions, and to improve relationships and social skills. Numerous types of psychotherapy have been designed either for individual adults, families, or children and adolescents. Certain types of psychotherapy are considered evidence-based for treating some diagnosed mental disorders; other types have been criticized as pseudoscience.There are hundreds of psychotherapy techniques, some being minor variations; others are based on very different conceptions of psychology. Most involve one-to-one sessions, between the client and therapist, but some are conducted with groups, including families. Psychotherapists may be mental health professionals such as psychiatrists, psychologists, mental health nurses, clinical social workers, marriage and family therapists, or professional counselors. Psychotherapists may also come from a variety of other backgrounds, and depending on the jurisdiction may be legally regulated, voluntarily regulated or unregulated (and the term itself may be protected or not).  Definitions  The term psychotherapy is derived from Ancient Greek psyche (ψυχή meaning ""breath; spirit; soul"") and therapeia (θεραπεία ""healing; medical treatment""). The Oxford English Dictionary defines it as ""The treatment of disorders of the mind or personality by psychological means..."", however, in earlier use it denoted the treatment of disease through hypnotic suggestion. Psychotherapy is often dubbed as a ""talking therapy"" or ""talk therapy"", particularly for a general audience, though not all forms of psychotherapy rely on verbal communication. Children or adults who do not engage in verbal communication (or not in the usual way) are not excluded from psychotherapy; indeed some types are designed for such cases. The American Psychological Association adopted a resolution on the effectiveness of psychotherapy in 2012 based on a definition developed by American psychologist John C. Norcross: ""Psychotherapy is the informed and intentional application of clinical methods and interpersonal stances derived from established psychological principles for the purpose of assisting people to modify their behaviors, cognitions, emotions, and/or other personal characteristics in directions that the participants deem desirable"". Influential editions of a work by psychiatrist Jerome Frank defined psychotherapy as a healing relationship using socially authorized methods in a series of contacts primarily involving words, acts and rituals—which Frank regarded as forms of persuasion and rhetoric. Historically, psychotherapy has sometimes meant ""interpretative"" (i.e. Freudian) methods, namely psychoanalysis, in contrast with other methods to treat psychiatric disorders such as behavior modification.Some definitions of counseling overlap with psychotherapy (particularly in non-directive client-centered approaches), or counseling may refer to guidance for everyday problems in specific areas, typically for shorter durations with a less medical or ""professional"" focus. Somatotherapy refers to the use of physical changes as injuries and illnesses, and sociotherapy to the use of a person\'s social environment to effect therapeutic change. Psychotherapy may address spirituality as a significant part of someone\'s mental / psychological life, and some forms are derived from spiritual philosophies, but practices based on treating the spiritual as a separate dimension are not necessarily considered as traditional or \'legitimate\' forms of psychotherapy.  Delivery  Psychotherapy may be delivered in person (one on one, or with couples, or in groups) or via telephone counseling or online counseling (see also § Telepsychotherapy). There have also been developments in computer-assisted therapy, such as virtual reality therapy for behavioral exposure, multimedia programs to teach cognitive techniques, and handheld devices for improved monitoring or putting ideas into practice (see also § Computer-supported).Most forms of psychotherapy use spoken conversation. Some also use various other forms of communication such as the written word, artwork, drama, narrative story or music. Psychotherapy with children and their parents often involves play, dramatization (i.e. role-play), and drawing, with a co-constructed narrative from these non-verbal and displaced modes of interacting.  Regulation  Psychotherapists traditionally may be mental health professionals like psychologists and psychiatrists; professionals from other backgrounds (family therapists, social workers, nurses, etc.) who have trained in a specific psychotherapy; or (in some cases) academic or scientifically trained professionals. Psychiatrists are trained first as physicians, and as such they may prescribe prescription medication; and specialist psychiatric training begins after medical school in psychiatric residencies: however, their specialty is in mental disorders or forms of mental illness. Clinical psychologists have specialist doctoral degrees in psychology with some clinical and research components. Other clinical practitioners, social workers, mental health counselors, pastoral counselors, and nurses with a specialization in mental health, also often conduct psychotherapy. Many of the wide variety of psychotherapy training programs and institutional settings are multi-professional. In most countries, psychotherapy training is completed at a postgraduate level, often at a master\'s degree (or doctoral) level, over four years, with significant supervised practice and clinical placements. Mental health professionals that choose to specialize in psychotherapeutic work also require a program of continuing professional education after basic professional training.A listing of the extensive professional competencies of a European psychotherapist was developed by the European Association of Psychotherapy (EAP) in 2013.As sensitive and deeply personal topics are often discussed during psychotherapy, therapists are expected, and usually legally bound, to respect client or patient confidentiality. The critical importance of client confidentiality—and the limited circumstances in which it may need to be broken for the protection of clients or others—is enshrined in the regulatory psychotherapeutic organizations\' codes of ethical practice. Examples of when it is typically accepted to break confidentiality include when the therapist has knowledge that a child or elder is being physically abused; when there is a direct, clear and imminent threat of serious physical harm to self or to a specific individual.  Europe  As of 2015, there are still a lot of variations between different European countries about the regulation and delivery of psychotherapy. Several countries have no regulation of the practice or no protection of the title. Some have a system of voluntary registration, with independent professional organizations, while other countries attempt to restrict the practice of psychotherapy to \'mental health professionals\' (psychologists and psychiatrists) with state-certified training. The titles that are protected also vary. The European Association for Psychotherapy (EAP) established the 1990 Strasbourg Declaration on Psychotherapy, which is dedicated to establishing an independent profession of psychotherapy in Europe, with pan-European standards. The EAP has already made significant contacts with the European Union & European Commission towards this end. Given that the European Union has a primary policy about the free movement of labor within Europe, European legislation can overrule national regulations that are, in essence, forms of restrictive practices. In Germany, the practice of psychotherapy for adults is restricted to qualified psychologists and physicians (including psychiatrists) who have completed several years of specialist practical training and certification in psychotherapy. As psychoanalysis, psychodynamic therapy, and cognitive behavioral therapy meet the requirements of German health insurance companies, mental health professionals regularly opt for one of these three specializations in their postgraduate training. For psychologists, this includes three years of full-time practical training (4,200 hours), encompassing a year-long internship at an accredited psychiatric institution, six months of clinical work at an outpatient facility, 600 hours of supervised psychotherapy in an outpatient setting, and at least 600 hours of theoretical seminars. Social workers may complete the specialist training for child and teenage clients. Similarly in Italy, the practice of psychotherapy is restricted to graduates in psychology or medicine who have completed four years of recognised specialist training. Sweden has a similar restriction on the title ""psychotherapist"", which may only be used by professionals who have gone through a post-graduate training in psychotherapy and then applied for a licence, issued by the National Board of Health and Welfare.Legislation in France restricts the use of the title ""psychotherapist"" to professionals on the National Register of Psychotherapists, which requires a training in clinical psychopathology and a period of internship which is only open to physicians or titulars of a master\'s degree in psychology or psychoanalysis.Austria and Switzerland (2011) have laws that recognize multi-disciplinary functional approaches.In the United Kingdom, the government and Health and Care Professions Council considered mandatory legal registration but decided that it was best left to professional bodies to regulate themselves, so the Professional Standards Authority for Health and Social Care (PSA) launched an Accredited Voluntary Registers scheme. Counseling and psychotherapy are not protected titles in the United Kingdom. Counsellors and psychotherapists who have trained and qualify to a certain standard (usually a level 4 Diploma) can apply to be members of the professional bodies who are listed on the PSA Accredited Registers.  United States  In some states, counselors or therapists must be licensed to use certain words and titles on self-identification or advertising. In some other states, the restrictions on practice are more closely associated with the charging of fees. Licensing and regulation are performed by various states. Presentation of practice as licensed, but without such a license, is generally illegal. Without a license, for example, a practitioner cannot bill insurance companies. Information about state licensure is provided by the American Psychological Association.In addition to state laws, the American Psychological Association requires its members to adhere to its published Ethical Principles of Psychologists and Code of Conduct. The American Board of Professional Psychology examines and certifies ""psychologists who demonstrate competence in approved specialty areas in professional psychology"".  Canada  Regulation of psychotherapy is in the jurisdiction of, and varies among, the provinces and territories. In Quebec, psychotherapy is a regulated activity which is restricted to psychologists, medical doctors, and holders of a psychotherapy permit issued by the Ordre des psychologues du Québec, the Quebec order of psychologists. Members of certain specified professions, including social workers, couple and family therapists, occupational therapists, guidance counsellors, criminologists, sexologists, psychoeducators, and registered nurses may obtain a psychotherapy permit by completing certain educational and practice requirements; their professional oversight is provided by their own professional orders. Some other professionals who were practising psychotherapy before the current system came into force continue to hold psychotherapy permits alone.On 1 July 2019, Ontario\'s Missing Persons Act came into effect, with the purpose of giving police more power to investigate missing persons. It allows police to require (as opposed to permit) health professionals, including psychotherapists, to share otherwise confidential documents about their client, if there is reason to believe their client is missing. Some have expressed concern that this legislation undermines psychotherapy confidentiality and could be abused maliciously by police, while others have praised the act for how it respects privacy and includes checks and balances.  History  Psychotherapy can be said to have been practiced through the ages, as medics, philosophers, spiritual practitioners and people in general used psychological methods to heal others.In the Western tradition, by the 19th century, a moral treatment movement (then meaning morale or mental) developed based on non-invasive non-restraint therapeutic methods. Another influential movement was started by Franz Mesmer (1734–1815) and his student Armand-Marie-Jacques de Chastenet, Marquis of Puységur (1751–1825). Called Mesmerism or animal magnetism, it would have a strong influence on the rise of dynamic psychology and psychiatry as well as theories about hypnosis. In 1853, Walter Cooper Dendy introduced the term ""psycho-therapeia"" regarding how physicians might influence the mental states of patients and thus their bodily ailments, for example by creating opposing emotions to promote mental balance. Daniel Hack Tuke cited the term and wrote about ""psycho-therapeutics"" in 1872, in which he also proposed making a science of animal magnetism. Hippolyte Bernheim and colleagues in the ""Nancy School"" developed the concept of ""psychotherapy"" in the sense of using the mind to heal the body through hypnotism, yet further. Charles Lloyd Tuckey\'s 1889 work, Psycho-therapeutics, or Treatment by Hypnotism and Suggestion popularized the work of the Nancy School in English. Also in 1889 a clinic used the word in its title for the first time, when Frederik van Eeden and Albert Willem van Renterghem in Amsterdam renamed theirs ""Clinique de Psycho-thérapeutique Suggestive"" after visiting Nancy. During this time, travelling stage hypnosis became popular, and such activities added to the scientific controversies around the use of hypnosis in medicine. Also in 1892, at the second congress of experimental psychology, van Eeden attempted to take the credit for the term psychotherapy and to distance the term from hypnosis. In 1896, the German journal Zeitschrift für Hypnotismus, Suggestionstherapie, Suggestionslehre und verwandte psychologische Forschungen changed its name to Zeitschrift für Hypnotismus, Psychotherapie sowie andere psychophysiologische und psychopathologische Forschungen, which is probably the first journal to use the term. Thus psychotherapy initially meant ""the treatment of disease by psychic or hypnotic influence, or by suggestion"". Sigmund Freud visited the Nancy School and his early neurological practice involved the use of hypnotism. However following the work of his mentor Josef Breuer—in particular a case where symptoms appeared partially resolved by what the patient, Bertha Pappenheim, dubbed a ""talking cure""—Freud began focusing on conditions that appeared to have psychological causes originating in childhood experiences and the unconscious mind. He went on to develop techniques such as free association, dream interpretation, transference and analysis of the id, ego and superego. His popular reputation as the father of psychotherapy was established by his use of the distinct term ""psychoanalysis"", tied to an overarching system of theories and methods, and by the effective work of his followers in rewriting history. Many theorists, including Alfred Adler, Carl Jung, Karen Horney, Anna Freud, Otto Rank, Erik Erikson, Melanie Klein and Heinz Kohut, built upon Freud\'s fundamental ideas and often developed their own systems of psychotherapy. These were all later categorized as psychodynamic, meaning anything that involved the psyche\'s conscious/unconscious influence on external relationships and the self. Sessions tended to number into the hundreds over several years. Behaviorism developed in the 1920s, and behavior modification as a therapy became popularized in the 1950s and 1960s. Notable contributors were Joseph Wolpe in South Africa, M.B. Shapiro and Hans Eysenck in Britain, and John B. Watson and B.F. Skinner in the United States. Behavioral therapy approaches relied on principles of operant conditioning, classical conditioning and social learning theory to bring about therapeutic change in observable symptoms. The approach became commonly used for phobias, as well as other disorders.Some therapeutic approaches developed out of the European school of existential philosophy. Concerned mainly with the individual\'s ability to develop and preserve a sense of meaning and purpose throughout life, major contributors to the field (e.g., Irvin Yalom, Rollo May) and Europe (Viktor Frankl, Ludwig Binswanger, Medard Boss, R.D.Laing, Emmy van Deurzen) attempted to create therapies sensitive to common ""life crises"" springing from the essential bleakness of human self-awareness, previously accessible only through the complex writings of existential philosophers (e.g., Søren Kierkegaard, Jean-Paul Sartre, Gabriel Marcel, Martin Heidegger, Friedrich Nietzsche). The uniqueness of the patient-therapist relationship thus also forms a vehicle for therapeutic inquiry. A related body of thought in psychotherapy started in the 1950s with Carl Rogers. Based also on the works of Abraham Maslow and his hierarchy of human needs, Rogers brought person-centered psychotherapy into mainstream focus. The primary requirement was that the client receive three core ""conditions"" from his counselor or therapist: unconditional positive regard, sometimes described as ""prizing"" the client\'s humanity; congruence [authenticity/genuineness/transparency]; and empathic understanding. This type of interaction was thought to enable clients to fully experience and express themselves, and thus develop according to their innate potential. Others developed the approach, like Fritz and Laura Perls in the creation of Gestalt therapy, as well as Marshall Rosenberg, founder of Nonviolent Communication, and Eric Berne, founder of transactional analysis. Later these fields of psychotherapy would become what is known as humanistic psychotherapy today. Self-help groups and books became widespread. During the 1950s, Albert Ellis originated rational emotive behavior therapy (REBT). Independently a few years later, psychiatrist Aaron T. Beck developed a form of psychotherapy known as cognitive therapy. Both of these included relatively short, structured and present-focused techniques aimed at identifying and changing a person\'s beliefs, appraisals and reaction-patterns, by contrast with the more long-lasting insight-based approach of psychodynamic or humanistic therapies. Beck\'s approach used primarily the socratic method, and links have been drawn between ancient stoic philosophy and these cognitive therapies.Cognitive and behavioral therapy approaches were increasingly combined and grouped under the umbrella term cognitive behavioral therapy (CBT) in the 1970s. Many approaches within CBT are oriented towards active/directive yet collaborative empiricism (a form of reality-testing), and assessing and modifying core beliefs and dysfunctional schemas. These approaches gained widespread acceptance as a primary treatment for numerous disorders. A ""third wave"" of cognitive and behavioral therapies developed, including acceptance and commitment therapy and dialectical behavior therapy, which expanded the concepts to other disorders and/or added novel components and mindfulness exercises. However the ""third wave"" concept has been criticized as not essentially different from other therapies and having roots in earlier ones as well. Counseling methods developed include solution-focused therapy and systemic coaching. Postmodern psychotherapies such as narrative therapy and coherence therapy do not impose definitions of mental health and illness, but rather see the goal of therapy as something constructed by the client and therapist in a social context. Systemic therapy also developed, which focuses on family and group dynamics—and transpersonal psychology, which focuses on the spiritual facet of human experience. Other orientations developed in the last three decades include feminist therapy, brief therapy, somatic psychology, expressive therapy, applied positive psychology and the human givens approach. A survey of over 2,500 US therapists in 2006 revealed the most utilized models of therapy and the ten most influential therapists of the previous quarter-century.  Types  There are hundreds of psychotherapy approaches or schools of thought. By 1980 there were more than 250; by 1996 more than 450; and at the start of the 21st century there were over a thousand different named psychotherapies—some being minor variations while others are based on very different conceptions of psychology, ethics (how to live) or technique. In practice therapy is often not of one pure type but draws from a number of perspectives and schools—known as an integrative or eclectic approach. The importance of the therapeutic relationship, also known as therapeutic alliance, between client and therapist is often regarded as crucial to psychotherapy. Common factors theory addresses this and other core aspects thought to be responsible for effective psychotherapy. Sigmund Freud (1856–1939), a Viennese neurologist who studied with Jean-Martin Charcot in 1885, is often considered the father of modern psychotherapy. His methods included analyzing his patient\'s dreams in search of important hidden insights into their unconscious minds. Other major elements of his methods, which changed throughout the years, included identification of childhood sexuality, the role of anxiety as a manifestation of inner conflict, the differentiation of parts of the psyche (id, ego, superego), transference and countertransference (the patient\'s projections onto the therapist, and the therapist\'s emotional responses to that). Some of his concepts were too broad to be amenable to empirical testing and invalidation, and he was critiqued for this by Jaspers. Numerous major figures elaborated and refined Freud\'s therapeutic techniques including Melanie Klein, Donald Winnicott, and others. Since the 1960s, however, the use of Freudian-based analysis for the treatment of mental disorders has declined substantially. Different types of psychotherapy have been created along with the advent of clinical trials to test them scientifically. These incorporate subjective treatments (after Beck), behavioral treatments (after Skinner and Wolpe) and additional time-constrained and centered structures, for example, interpersonal psychotherapy. In youth issue and in schizophrenia, the systems of family treatment hold esteem. A portion of the thoughts emerging from therapy are presently pervasive and some are a piece of the tool set of ordinary clinical practice. They are not just medications, they additionally help to understand complex conduct. Therapy may address specific forms of diagnosable mental illness, or everyday problems in managing or maintaining interpersonal relationships or meeting personal goals. A course of therapy may happen before, during or after pharmacotherapy (e.g. taking psychiatric medication). Psychotherapies are categorized in several different ways. A distinction can be made between those based on a medical model and those based on a humanistic model. In the medical model, the client is seen as unwell and the therapist employs their skill to help the client back to health. The extensive use of the DSM-IV, the diagnostic and statistical manual of mental disorders in the United States is an example of a medically exclusive model. The humanistic or non-medical model in contrast strives to depathologise the human condition. The therapist attempts to create a relational environment conducive to experiential learning and help build the client\'s confidence in their own natural process resulting in a deeper understanding of themselves. The therapist may see themselves as a facilitator/helper. Another distinction is between individual one-to-one therapy sessions, and group psychotherapy, including couples therapy and family therapy.Therapies are sometimes classified according to their duration; a small number of sessions over a few weeks or months may be classified as brief therapy (or short-term therapy), others, where regular sessions take place for years, may be classified as long-term. Some practitioners distinguish between more ""uncovering"" (or ""depth"") approaches and more ""supportive"" psychotherapy. Uncovering psychotherapy emphasizes facilitating the client\'s insight into the roots of their difficulties. The best-known example is classical psychoanalysis. Supportive psychotherapy by contrast stresses strengthening the client\'s coping mechanisms and often providing encouragement and advice, as well as reality-testing and limit-setting where necessary. Depending on the client\'s issues and situation, a more supportive or more uncovering approach may be optimal.  Humanistic  These psychotherapies, also known as ""experiential"", are based on humanistic psychology and emerged in reaction to both behaviorism and psychoanalysis, being dubbed the ""third force"". They are primarily concerned with the human development and needs of the individual, with an emphasis on subjective meaning, a rejection of determinism, and a concern for positive growth rather than pathology. Some posit an inherent human capacity to maximize potential, ""the self-actualizing tendency""; the task of therapy is to create a relational environment where this tendency might flourish. Humanistic psychology can, in turn, be rooted in existentialism—the belief that human beings can only find meaning by creating it. This is the goal of existential therapy. Existential therapy is in turn philosophically associated with phenomenology.Person-centered therapy, also known as client-centered, focuses on the therapist showing openness, empathy and ""unconditional positive regard"", to help clients express and develop their own self.Humanistic Psychodrama (HPD) is based on the human image of humanistic psychology. So all rules and methods follow the axioms of humanistic psychology. The HPD sees itself as development-oriented psychotherapy and has completely moved away from the psychoanalytic catharsis theory. Self-awareness and self-realization are essential aspects in the therapeutic process. Subjective experiences, feelings and thoughts and one\'s own experiences are the starting point for a change or reorientation in experience and behavior in the direction of more self-acceptance and satisfaction. Dealing with the biography of the individual is closely related to the sociometry of the group.Gestalt therapy, originally called ""concentration therapy"", is an existential/experiential form that facilitates awareness in the various contexts of life, by moving from talking about relatively remote situations to action and direct current experience. Derived from various influences, including an overhaul of psychoanalysis, it stands on top of essentially four load-bearing theoretical walls: phenomenological method, dialogical relationship, field-theoretical strategies, and experimental freedom.A briefer form of humanistic therapy is the human givens approach, introduced in 1998–99. It is a solution-focused intervention based on identifying emotional needs—such as for security, autonomy and social connection—and using various educational and psychological methods to help people meet those needs more fully or appropriately.  Insight-oriented  Insight-oriented psychotherapies focus on revealing or interpreting unconscious processes. Most commonly referring to psychodynamic therapy, of which psychoanalysis is the oldest and most intensive form, these applications of depth psychology encourage the verbalization of all the patient\'s thoughts, including free associations, fantasies, and dreams, from which the analyst formulates the nature of the past and present unconscious conflicts which are causing the patient\'s symptoms and character problems. There are six main schools of psychoanalysis, which all influenced psychodynamic theory: Freudian, ego psychology, object relations theory, self psychology, interpersonal psychoanalysis, and relational psychoanalysis. Techniques for analytic group therapy have also developed.  Cognitive-behavioral  Behavior therapies use behavioral techniques, including applied behavior analysis (also known as behavior modification), to change maladaptive patterns of behavior to improve emotional responses, cognitions, and interactions with others. Functional analytic psychotherapy is one form of this approach. By nature, behavioral therapies are empirical (data-driven), contextual (focused on the environment and context), functional (interested in the effect or consequence a behavior ultimately has), probabilistic (viewing behavior as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analyzing bidirectional interactions).Cognitive therapy focuses directly on changing the thoughts, in order to improve the emotions and behaviors. Cognitive behavioral therapy attempts to combine the above two approaches, focused on the construction and reconstruction of people\'s cognitions, emotions and behaviors. Generally in CBT, the therapist, through a wide array of modalities, helps clients assess, recognize and deal with problematic and dysfunctional ways of thinking, emoting and behaving. The concept of ""third wave"" psychotherapies reflects an influence of Eastern philosophy in clinical psychology, incorporating principles such as meditation into interventions such as mindfulness-based cognitive therapy, acceptance and commitment therapy, and dialectical behavior therapy for borderline personality disorder.Interpersonal psychotherapy (IPT) is a relatively brief form of psychotherapy (deriving from both CBT and psychodynamic approaches) that has been increasingly studied and endorsed by guidelines for some conditions. It focuses on the links between mood and social circumstances, helping to build social skills and social support. It aims to foster adaptation to current interpersonal roles and situations. Exposure and response prevention (ERP) is primarily deployed by therapists in the treatment of OCD. The American Psychiatric Association (APA) state that CBT drawing primarily on behavioral techniques (such as ERP) has the ""strongest evidence base"" among psychosocial interventions. By confronting feared scenarios (i.e., exposure) and refraining from performing rituals (i.e., responsive prevention), patients may gradually feel less distress in confronting feared stimuli, while also feeling less inclination to use rituals to relieve that distress. Typically, ERP is delivered in ""hierarchical fashion"", meaning patients confront increasingly anxiety-provoking stimuli as they progress through a course of treatment.Other types include reality therapy/choice theory, multimodal therapy, and therapies for specific disorders including PTSD therapies such as cognitive processing therapy and EMDR; substance abuse therapies such as relapse prevention and contingency management; and co-occurring disorders therapies such as Seeking Safety.  Systemic  Systemic therapy seeks to address people not just individually, as is often the focus of other forms of therapy, but in relationship, dealing with the interactions of groups, their patterns and dynamics (includes family therapy and marriage counseling). Community psychology is a type of systemic psychology. The term group therapy was first used around 1920 by Jacob L. Moreno, whose main contribution was the development of psychodrama, in which groups were used as both cast and audience for the exploration of individual problems by reenactment under the direction of the leader. The more analytic and exploratory use of groups in both hospital and out-patient settings was pioneered by a few European psychoanalysts who emigrated to the US, such as Paul Schilder, who treated severely neurotic and mildly psychotic out-patients in small groups at Bellevue Hospital, New York. The power of groups was most influentially demonstrated in Britain during the Second World War, when several psychoanalysts and psychiatrists proved the value of group methods for officer selection in the War Office Selection Boards. A chance to run an Army psychiatric unit on group lines was then given to several of these pioneers, notably Wilfred Bion and Rickman, followed by S. H. Foulkes, Main, and Bridger. The Northfield Hospital in Birmingham gave its name to what came to be called the two ""Northfield Experiments"", which provided the impetus for the development since the war of both social therapy, that is, the therapeutic community movement, and the use of small groups for the treatment of neurotic and personality disorders. Today group therapy is used in clinical settings and in private practice settings.  Expressive  Expressive psychotherapy is a form of therapy that utilizes artistic expression (via improvisational, compositional, re-creative, and receptive experiences) as its core means of treating clients. Expressive psychotherapists use the different disciplines of the creative arts as therapeutic interventions. This includes the modalities dance therapy, drama therapy, art therapy, music therapy, writing therapy, among others. This may include techniques such as affect labeling. Expressive psychotherapists believe that often the most effective way of treating a client is through the expression of imagination in creative work and integrating and processing what issues are raised in the act.  Postmodernist  Also known as post-structuralist or constructivist. Narrative therapy gives attention to each person\'s ""dominant story"" through therapeutic conversations, which also may involve exploring unhelpful ideas and how they came to prominence. Possible social and cultural influences may be explored if the client deems it helpful. Coherence therapy posits multiple levels of mental constructs that create symptoms as a way to strive for self-protection or self-realization. Feminist therapy does not accept that there is one single or correct way of looking at reality and therefore is considered a postmodernist approach.  Other  Transpersonal psychology addresses the client in the context of a spiritual understanding of consciousness. Positive psychotherapy (PPT) (since 1968) is a method in the field of humanistic and psychodynamic psychotherapy and is based on a positive image of humans, with a health-promoting, resource-oriented and conflict-centered approach. Hypnotherapy is undertaken while a subject is in a state of hypnosis. Hypnotherapy is often applied in order to modify a subject\'s behavior, emotional content, and attitudes, as well as a wide range of conditions including: dysfunctional habits, anxiety, stress-related illness, pain management, and personal development.Psychedelic therapy are therapeutic practices involving psychedelic drugs, such as LSD, psilocybin, DMT, and MDMA. In psychedelic therapy, in contrast to conventional psychiatric medication taken by the patient regularly or as needed, patients generally remain in an extended psychotherapy session during the acute psychedelic activity with additional sessions both before and after in order to help integrate experiences with the psychedelics. Psychedelic therapy has been compared with the shamanic healing rituals of indigenous people. Researchers identified two main differences: the first is the shamanic belief that multiple realities exist and can be explored through altered states of consciousness, and second the belief that spirits encountered in dreams and visions are real. The charitable initiative Founders Pledge has written a research report on cost-effective giving opportunities for funding psychedelic-assisted mental health treatments.Body psychotherapy, part of the field of somatic psychology, focuses on the link between the mind and the body and tries to access deeper levels of the psyche through greater awareness of the physical body and emotions. There are various body-oriented approaches, such as Reichian (Wilhelm Reich) character-analytic vegetotherapy and orgonomy; neo-Reichian bioenergetic analysis; somatic experiencing; integrative body psychotherapy; Ron Kurtz\'s Hakomi psychotherapy; sensorimotor psychotherapy; Biosynthesis psychotherapy; and Biodynamic psychotherapy. These approaches are not to be confused with body work or body-therapies that seek to improve primarily physical health through direct work (touch and manipulation) on the body, rather than through directly psychological methods. Some non-Western indigenous therapies have been developed. In African countries this includes harmony restoration therapy, meseron therapy and systemic therapies based on the Ubuntu philosophy.Integrative psychotherapy is an attempt to combine ideas and strategies from more than one theoretical approach. These approaches include mixing core beliefs and combining proven techniques. Forms of integrative psychotherapy include multimodal therapy, the transtheoretical model, cyclical psychodynamics, systematic treatment selection, cognitive analytic therapy, internal family systems model, multitheoretical psychotherapy and conceptual interaction. In practice, most experienced psychotherapists develop their own integrative approach over time.  Child  Psychotherapy needs to be adapted to meet the developmental needs of children. Depending on age, it is generally held to be one part of an effective strategy to help the needs of a child within the family setting. Child psychotherapy training programs necessarily include courses in human development. Since children often do not have the ability to articulate thoughts and feelings, psychotherapists will use a variety of media such as musical instruments, sand and toys, crayons, paint, clay, puppets, bibliocounseling (books), or board games. The use of play therapy is often rooted in psychodynamic theory, but other approaches also exist. In addition to therapy for the child, sometimes instead of it, children may benefit if their parents work with a therapist, take parenting classes, attend grief counseling, or take other action to resolve stressful situations that affect the child. Parent management training is a highly effective form of psychotherapy that teaches parenting skills to reduce their child\'s behavior problems. In many cases a different psychotherapist will work with the care taker of the child, while a colleague works with the child. Therefore, contemporary thinking on working with the younger age group has leaned towards working with parent and child simultaneously, as well as individually as needed.  Computer-supported  Research on computer-supported and computer-based interventions has increased significantly over the course of the last two decades. The following applications frequently have been investigated: Virtual reality: VR is a computer-generated scenario that simulates experience. The immersive environment, used for simulated exposure, can be similar to the real world or it can be fantastical, creating a new experience. Computer-based interventions (or online interventions or internet interventions): These interventions can be described as interactive self-help. They usually entail a combination of text, audio or video elements. Computer-supported therapy (or blended therapy): Classical psychotherapy is supported by means of online or software application elements. The feasibility of such interventions has been investigated for individual and group therapy.  Telepsychotherapy   Effects   Evaluation  There is considerable controversy about whether, or when, psychotherapy efficacy is best evaluated by randomized controlled trials or more individualized idiographic methods.One issue with trials is what to use as a placebo treatment group or non-treatment control group. Often, this group includes patients on a waiting list, or those receiving some kind of regular non-specific contact or support. Researchers must consider how best to match the use of inert tablets or sham treatments in placebo-controlled studies in pharmaceutical trials. Several interpretations and differing assumptions and language remain. Another issue is the attempt to standardize and manualize therapies and link them to specific symptoms of diagnostic categories, making them more amenable to research. Some report that this may reduce efficacy or gloss over individual needs. Fonagy and Roth\'s opinion is that the benefits of the evidence-based approach outweighs the difficulties.There are several formal frameworks for evaluating whether a psychotherapist is a good fit for a patient. One example is the Scarsdale Psychotherapy Self-Evaluation (SPSE). However, some scales, such as the SPS, elicit information specific to certain schools of psychotherapy alone (e.g. the superego). Many psychotherapists believe that the nuances of psychotherapy cannot be captured by questionnaire-style observation, and prefer to rely on their own clinical experiences and conceptual arguments to support the type of treatment they practice. Psychodynamic therapists increasingly believe that evidence-based approaches are appropriate to their methods and assumptions, and have increasingly accepted the challenge to implement evidence-based approaches in their methods.A pioneer in investigating the results of different psychological therapies was psychologist Hans Eysenck, who argued that psychotherapy does not produce any improvement in patients. He held that behavior therapy is the only effective one. However, it was revealed that Eysenck (who died in 1997) falsified data in his studies about this subject, fabricating data that would indicate that behavioral therapy enables achievements that are impossible to believe. Fourteen of his papers were retracted by journals in 2020, and journals issued 64 statements of concern about publications by him. Rod Buchanan, a biographer of Eysenck, has argued that 87 publications by Eysenck should be retracted.  Outcomes in relation with selected kinds of treatment  Large-scale international reviews of scientific studies have concluded that psychotherapy is effective for numerous conditions.One line of research consistently finds that supposedly different forms of psychotherapy show similar effectiveness. According to The Handbook of Counseling Psychology: ""Meta-analyses of psychotherapy studies have consistently demonstrated that there are no substantial differences in outcomes among treatments"". The handbook states that there is ""little evidence to suggest that any one psychological therapy consistently outperforms any other for any specific psychological disorders. This is sometimes called the Dodo bird verdict after a scene/section in Alice in Wonderland where every competitor in a race was called a winner and is given prizes"".Further analyses seek to identify the factors that the psychotherapies have in common that seem to account for this, known as common factors theory; for example the quality of the therapeutic relationship, interpretation of problem, and the confrontation of painful emotions.Outcome studies have been critiqued for being too removed from real-world practice in that they use carefully selected therapists who have been extensively trained and monitored, and patients who may be non-representative of typical patients by virtue of strict inclusionary/exclusionary criteria. Such concerns impact the replication of research results and the ability to generalize from them to practicing therapists.However, specific therapies have been tested for use with specific disorders, and regulatory organizations in both the UK and US make recommendations for different conditions.The Helsinki Psychotherapy Study was one of several large long-term clinical trials of psychotherapies that have taken place. Anxious and depressed patients in two short-term therapies (solution-focused and brief psychodynamic) improved faster, but five years long-term psychotherapy and psychoanalysis gave greater benefits. Several patient and therapist factors appear to predict suitability for different psychotherapies.Meta-analyses have established that cognitive behavioural therapy (CBT) and psychodynamic psychotherapy are equally effective in treating depression.A 2014 meta analysis over 11,000 patients reveals that Interpersonal Psychotherapy (IPT) is of comparable effectiveness to CBT for depression but is inferior to the latter for eating disorders. For children and adolescents, interpersonal psychotherapy and CBT are the best methods according to a 2014 meta analysis of almost 4000 patients.  Mechanisms of change  It is not yet understood how psychotherapies can succeed in treating mental illnesses. Different therapeutic approaches may be associated with particular theories about what needs to change in a person for a successful therapeutic outcome. In general, processes of emotional arousal and memory have long been held to play an important role. One theory combining these aspects proposes that permanent change occurs to the extent that the neuropsychological mechanism of memory reconsolidation is triggered and is able to incorporate new emotional experiences.  Adherence  Patient adherence to a course of psychotherapy—continuing to attend sessions or complete tasks—is a major issue. The dropout level—early termination—ranges from around 30% to 60%, depending partly on how it is defined. The range is lower for research settings for various reasons, such as the selection of clients and how they are inducted. Early termination is associated on average with various demographic and clinical characteristics of clients, therapists and treatment interactions. The high level of dropout has raised some criticism about the relevance and efficacy of psychotherapy.Most psychologists use between-session tasks in their general therapy work, and cognitive behavioral therapies in particular use and see them as an ""active ingredient"". It is not clear how often clients do not complete them, but it is thought to be a pervasive phenomenon.From the other side, the adherence of therapists to therapy protocols and techniques—known as ""treatment integrity"" or ""fidelity""—has also been studied, with complex mixed results. In general, however, it is a hallmark of evidence-based psychotherapy to use fidelity monitoring as part of therapy outcome trials and ongoing quality assurance in clinical implementation.  Adverse effects  Research on adverse effects of psychotherapy has been limited, yet worsening of symptoms may be expected to occur in 3% to 15% of patients, with variability across patient and therapist characteristics. Potential problems include deterioration of symptoms or developing new symptoms, strains in other relationships, social stigma, and therapy dependence. Some techniques or therapists may carry more risks than others, and some client characteristics may make them more vulnerable. Side-effects from properly conducted therapy should be distinguished from harms caused by malpractice.  General critiques  Some critics are skeptical of the healing power of psychotherapeutic relationships. Some dismiss psychotherapy altogether in the sense of a scientific discipline requiring professional practitioners, instead favoring either nonprofessional help or biomedical treatments. Others have pointed out ways in which the values and techniques of therapists can be harmful as well as helpful to clients (or indirectly to other people in a client\'s life).Many resources available to a person experiencing emotional distress—the friendly support of friends, peers, family members, clergy contacts, personal reading, healthy exercise, research, and independent coping—all present considerable value. Critics note that humans have been dealing with crises, navigating severe social problems and finding solutions to life problems long before the advent of psychotherapy.On the other hand, some argue psychotherapy is under-utilized and under-researched by contemporary psychiatry despite offering more promise than stagnant medication development. In 2015, the US National Institute of Mental Health allocated only 5.4% of its budget to new clinical trials of psychotherapies (medication trials are largely funded by pharmaceutical companies), despite plentiful evidence they can work and that patients are more likely to prefer them.Further critiques have emerged from feminist, constructionist and discourse-analytical sources. Key to these is the issue of power. In this regard there is a concern that clients are persuaded—both inside and outside the consulting room—to understand themselves and their difficulties in ways that are consistent with therapeutic ideas. This means that alternative ideas (e.g., feminist, economic, spiritual) are sometimes implicitly undermined.","Psychotherapy describes the way specially skilled people called psychotherapists help people who have problems and unhappiness in their lives or who want to improve the quality of their lives and relationships with others. Psychotherapy means treatment of the mind. It aims to help the person feel better, be braver, happier and more in control of their lives. The main way they do this is by talking to the person who has the problems in a way that they begin to be able to understand themselves better. Some psychotherapists may work with a group of people such as a family who have problems and are unhappy.  Training  Psychotherapists usually complete their training at the doctoral level through doctor of philosophy programs or medical school, although, some are trained at the master's level. Psychotherapists do not use surgery, or give drugs or electric shocks to the people they help. These methods are used by special medical doctors called psychiatrists, who may also sometimes give psychotherapy.  How it started  Psychotherapy was started in the west in 1886 by Sigmund Freud, the first modern psychotherapist. Freud was a medical doctor who was trained in neurology. He became certain that hidden thoughts in the brain (which he called the Unconscious) could cause physical symptoms and strange behavior in some people. He believed that human behavior was not all caused by the brain, but by things that happened to people when they were babies and young children. His research of this theory -the idea he had- led him to create ""talking therapy"" , where he tried to figure out what could cause the mind to do things like this. Freud thought that his figuring things out and telling the patients what had caused the behavior would cure the patient. Unfortunately, it usually made no lasting changes. This is why modern psychologists have gradually figured out many other ways of helping their patients and modified their techniques through methods other than psychotherapy. Hans Eysenck has suggested psychotherapy is discredited."
"Schizophrenia is a mental disorder characterized by continuous or relapsing episodes of psychosis. Major symptoms include hallucinations (typically hearing voices), delusions, and disorganized thinking. Other symptoms include social withdrawal, decreased emotional expression, and apathy. Symptoms typically develop gradually, begin during young adulthood, and in many cases never become resolved. There is no objective diagnostic test; diagnosis is based on observed behavior, a psychiatric history that includes the person\'s reported experiences, and reports of others familiar with the person. To be diagnosed with schizophrenia, symptoms and functional impairment need to be present for six months (DSM-5) or one month (ICD-11). Many people with schizophrenia have other mental disorders, especially substance use disorders, depressive disorders, anxiety disorders, and obsessive–compulsive disorder.About 0.3% to 0.7% of people are diagnosed with schizophrenia during their lifetime. In 2017, there were an estimated 1.1 million new cases and in 2022 a total of 24 million cases globally. Males are more often affected and on average have an earlier onset. The causes of schizophrenia may include genetic and environmental factors. Genetic factors include a variety of common and rare genetic variants. Possible environmental factors include being raised in a city, childhood adversity, cannabis use during adolescence, infections, the ages of a person\'s mother or father, and poor nutrition during pregnancy.About half of those diagnosed with schizophrenia will have a significant improvement over the long term with no further relapses, and a small proportion of these will recover completely. The other half will have a lifelong impairment. In severe cases, people may be admitted to hospitals. Social problems such as long-term unemployment, poverty, homelessness, exploitation, and victimization are commonly correlated with schizophrenia. Compared to the general population, people with schizophrenia have a higher suicide rate (about 5% overall) and more physical health problems, leading to an average decrease in life expectancy by 20 to 28 years. In 2015, an estimated 17,000 deaths were linked to schizophrenia.The mainstay of treatment is antipsychotic medication, along with counseling, job training, and social rehabilitation. Up to a third of people do not respond to initial antipsychotics, in which case clozapine may be used. In a network comparative meta-analysis of 15 antipsychotic drugs, clozapine was significantly more effective than all other drugs, although clozapine\'s heavily multimodal action may cause more side effects. In situations where doctors judge that there is a risk of harm to self or others, they may impose short involuntary hospitalization. Long-term hospitalization is used on a small number of people with severe schizophrenia. In some countries where supportive services are limited or unavailable, long-term hospital stays are more common.  Signs and symptoms  Schizophrenia is a mental disorder characterized by significant alterations in perception, thoughts, mood, and behavior. Symptoms are described in terms of positive, negative, and cognitive symptoms. The positive symptoms of schizophrenia are the same for any psychosis and are sometimes referred to as psychotic symptoms. These may be present in any of the different psychoses, and are often transient making early diagnosis of schizophrenia problematic. Psychosis noted for the first time in a person who is later diagnosed with schizophrenia is referred to as a first-episode psychosis (FEP).  Positive symptoms  Positive symptoms are those symptoms that are not normally experienced, but are present in people during a psychotic episode in schizophrenia. They include delusions, hallucinations, and disorganized thoughts and speech, typically regarded as manifestations of psychosis. Hallucinations occur at some point in the lifetimes of 80% of those with schizophrenia and most commonly involve the sense of hearing (most often hearing voices) but can sometimes involve any of the other senses of taste, sight, smell, and touch. The frequency of hallucinations involving multiple senses is double the rate of those involving only one sense. They are also typically related to the content of the delusional theme. Delusions are bizarre or persecutory in nature. Distortions of self-experience such as feeling as if one\'s thoughts or feelings are not really one\'s own, to believing that thoughts are being inserted into one\'s mind, sometimes termed passivity phenomena, are also common. Thought disorders can include thought blocking, and disorganized speech. Positive symptoms generally respond well to medication, and become reduced over the course of the illness, perhaps related to the age-related decline in dopamine activity.  Negative symptoms  Negative symptoms are deficits of normal emotional responses, or of other thought processes. The five recognized domains of negative symptoms are: blunted affect – showing flat expressions or little emotion; alogia – a poverty of speech; anhedonia – an inability to feel pleasure; asociality – the lack of desire to form relationships, and avolition – a lack of motivation and apathy. Avolition and anhedonia are seen as motivational deficits resulting from impaired reward processing. Reward is the main driver of motivation and this is mostly mediated by dopamine. It has been suggested that negative symptoms are multidimensional and they have been categorised into two subdomains of apathy or lack of motivation, and diminished expression. Apathy includes avolition, anhedonia, and social withdrawal; diminished expression includes blunt affect and alogia. Sometimes diminished expression is treated as both verbal and non-verbal.Apathy accounts for around 50 percent of the most often found negative symptoms and affects functional outcome and subsequent quality of life. Apathy is related to disrupted cognitive processing affecting memory and planning including goal-directed behaviour. The two subdomains have suggested a need for separate treatment approaches. A lack of distress – relating to a reduced experience of depression and anxiety is another noted negative symptom. A distinction is often made between those negative symptoms that are inherent to schizophrenia, termed primary; and those that result from positive symptoms, from the side effects of antipsychotics, substance use disorder, and social deprivation – termed secondary negative symptoms. Negative symptoms are less responsive to medication and the most difficult to treat. However, if properly assessed, secondary negative symptoms are amenable to treatment.Scales for specifically assessing the presence of negative symptoms, and for measuring their severity, and their changes have been introduced since the earlier scales such as the PANNS that deals with all types of symptoms. These scales are the Clinical Assessment Interview for Negative Symptoms (CAINS), and the Brief Negative Symptom Scale (BNSS) also known as second-generation scales. In 2020, ten years after its introduction, a cross-cultural study of the use of BNSS found valid and reliable psychometric evidence for the five-domain structure cross-culturally. The BNSS is designed to assess both the presence and severity and change of negative symptoms of the five recognized domains, and the additional item of reduced normal distress. BNSS can register changes in negative symptoms concerning psychosocial and pharmacological intervention trials. BNSS has also been used to study a proposed non-D2 treatment called SEP-363856. Findings supported the favouring of five domains over the two-dimensional proposition.  Cognitive symptoms  An estimated 70% of those with schizophrenia have cognitive deficits, and these are most pronounced in early onset and late-onset illness. These are often evident long before the onset of illness in the prodromal stage, and may be present in early adolescence, or childhood. They are a core feature but not considered to be core symptoms, as are positive and negative symptoms. However, their presence and degree of dysfunction is taken as a better indicator of functionality than the presentation of core symptoms. Cognitive deficits become worse at first episode psychosis but then return to baseline, and remain fairly stable over the course of the illness.The deficits in cognition are seen to drive the negative psychosocial outcome in schizophrenia, and are claimed to equate to a possible reduction in IQ from the norm of 100 to 70–85. Cognitive deficits may be of neurocognition (nonsocial) or of social cognition. Neurocognition is the ability to receive and remember information, and includes verbal fluency, memory, reasoning, problem solving, speed of processing, and auditory and visual perception. Verbal memory and attention are seen to be the most affected. Verbal memory impairment is associated with a decreased level of semantic processing (relating meaning to words). Another memory impairment is that of episodic memory. An impairment in visual perception that is consistently found in schizophrenia is that of visual backward masking. Visual processing impairments include an inability to perceive complex visual illusions. Social cognition is concerned with the mental operations needed to interpret, and understand the self and others in the social world. This is also an associated impairment, and facial emotion perception is often found to be difficult. Facial perception is critical for ordinary social interaction. Cognitive impairments do not usually respond to antipsychotics, and there are a number of interventions that are used to try to improve them; cognitive remediation therapy is of particular help.Neurological soft signs of clumsiness and loss of fine motor movement are often found in schizophrenia, which may resolve with effective treatment of FEP.  Onset  Onset typically occurs between the late teens and early 30s, with the peak incidence occurring in males in the early to mid-twenties, and in females in the late twenties. Onset before the age of 17 is known as early-onset, and before the age of 13, as can sometimes occur, is known as childhood schizophrenia or very early-onset. Onset can occur between the ages of 40 and 60, known as late-onset schizophrenia. Onset over the age of 60, which may be difficult to differentiate as schizophrenia, is known as very-late-onset schizophrenia-like psychosis. Late onset has shown that a higher rate of females are affected; they have less severe symptoms and need lower doses of antipsychotics. The tendency for earlier onset in males is later seen to be balanced by a post-menopausal increase in the development in females. Estrogen produced pre-menopause has a dampening effect on dopamine receptors but its protection can be overridden by a genetic overload. There has been a dramatic increase in the numbers of older adults with schizophrenia.Onset may happen suddenly or may occur after the slow and gradual development of a number of signs and symptoms, a period known as the prodromal stage. Up to 75% of those with schizophrenia go through a prodromal stage. The negative and cognitive symptoms in the prodrome stage can precede FEP (first episode psychosis) by many months and up to five years. The period from FEP and treatment is known as the duration of untreated psychosis (DUP) which is seen to be a factor in functional outcome. The prodromal stage is the high-risk stage for the development of psychosis. Since the progression to first episode psychosis is not inevitable, an alternative term is often preferred of at risk mental state. Cognitive dysfunction at an early age impacts a young person\'s usual cognitive development. Recognition and early intervention at the prodromal stage would minimize the associated disruption to educational and social development and has been the focus of many studies.  Risk factors  Schizophrenia is described as a neurodevelopmental disorder with no precise boundary, or single cause, and is thought to develop from gene–environment interactions with involved vulnerability factors. The interactions of these risk factors are complex, as numerous and diverse insults from conception to adulthood can be involved. A genetic predisposition on its own, without interacting environmental factors, will not give rise to the development of schizophrenia. The genetic component means that prenatal brain development is disturbed, and environmental influence affects the postnatal development of the brain. Evidence suggests that genetically susceptible children are more likely to be vulnerable to the effects of environmental risk factors.  Genetic  Estimates of the heritability of schizophrenia are between 70% and 80%, which implies that 70% to 80% of the individual differences in risk of schizophrenia are associated with genetics. These estimates vary because of the difficulty in separating genetic and environmental influences, and their accuracy has been queried. The greatest risk factor for developing schizophrenia is having a first-degree relative with the disease (risk is 6.5%); more than 40% of identical twins of those with schizophrenia are also affected. If one parent is affected the risk is about 13% and if both are affected the risk is nearly 50%. However, the DSM-5 indicates that most people with schizophrenia have no family history of psychosis. Results of candidate gene studies of schizophrenia have generally failed to find consistent associations, and the genetic loci identified by genome-wide association studies explain only a small fraction of the variation in the disease.Many genes are known to be involved in schizophrenia, each with small effects and unknown transmission and expression. The summation of these effect sizes into a polygenic risk score can explain at least 7% of the variability in liability for schizophrenia. Around 5% of cases of schizophrenia are understood to be at least partially attributable to rare copy number variations (CNVs); these structural variations are associated with known genomic disorders involving deletions at 22q11.2 (DiGeorge syndrome) and 17q12 (17q12 microdeletion syndrome), duplications at 16p11.2 (most frequently found) and deletions at 15q11.2 (Burnside–Butler syndrome). Some of these CNVs increase the risk of developing schizophrenia by as much as 20-fold, and are frequently comorbid with autism and intellectual disabilities.The genes CRHR1 and CRHBP are associated with the severity of suicidal behavior. These genes code for stress response proteins needed in the control of the HPA axis, and their interaction can affect this axis. Response to stress can cause lasting changes in the function of the HPA axis possibly disrupting the negative feedback mechanism, homeostasis, and the regulation of emotion leading to altered behaviors.The question of how schizophrenia could be primarily genetically influenced, given that people with schizophrenia have lower fertility rates, is a paradox. It is expected that genetic variants that increase the risk of schizophrenia would be selected against, due to their negative effects on reproductive fitness. A number of potential explanations have been proposed, including that alleles associated with schizophrenia risk confers a fitness advantage in unaffected individuals. While some evidence has not supported this idea, others propose that a large number of alleles each contributing a small amount can persist.A meta-analysis found that oxidative DNA damage was significantly increased in schizophrenia.  Environmental  Environmental factors, each associated with a slight risk of developing schizophrenia in later life include oxygen deprivation, infection, prenatal maternal stress, and malnutrition in the mother during prenatal development. A risk is associated with maternal obesity, in increasing oxidative stress, and dysregulating the dopamine and serotonin pathways. Both maternal stress and infection have been demonstrated to alter fetal neurodevelopment through an increase of pro-inflammatory cytokines. There is a slighter risk associated with being born in the winter or spring possibly due to vitamin D deficiency or a prenatal viral infection. Other infections during pregnancy or around the time of birth that have been linked to an increased risk include infections by Toxoplasma gondii and Chlamydia. The increased risk is about five to eight percent. Viral infections of the brain during childhood are also linked to a risk of schizophrenia during adulthood.Adverse childhood experiences (ACEs), severe forms of which are classed as childhood trauma, range from being bullied or abused, to the death of a parent. Many adverse childhood experiences can cause toxic stress and increase the risk of psychosis. Chronic trauma, including ACEs, can promote lasting inflammatory dysregulation throughout the nervous system. It is suggested that early stress may contribute to the development of schizophrenia through these alterations in the immune system. Schizophrenia was the last diagnosis to benefit from the link made between ACEs and adult mental health outcomes.Living in an urban environment during childhood or as an adult has consistently been found to increase the risk of schizophrenia by a factor of two, even after taking into account drug use, ethnic group, and size of social group. A possible link between the urban environment and pollution has been suggested to be the cause of the elevated risk of schizophrenia. Other risk factors include social isolation, immigration related to social adversity and racial discrimination, family dysfunction, unemployment, and poor housing conditions. Having a father older than 40 years, or parents younger than 20 years are also associated with schizophrenia.  Substance use  About half of those with schizophrenia use recreational drugs, including alcohol, tobacco, and cannabis excessively. Use of stimulants such as amphetamine and cocaine can lead to a temporary stimulant psychosis, which presents very similarly to schizophrenia. Rarely, alcohol use can also result in a similar alcohol-related psychosis. Drugs may also be used as coping mechanisms by people who have schizophrenia, to deal with depression, anxiety, boredom, and loneliness. The use of cannabis and tobacco are not associated with the development of cognitive deficits, and sometimes a reverse relationship is found where their use improves these symptoms. However, substance use disorders are associated with an increased risk of suicide, and a poor response to treatment.Cannabis use may be a contributory factor in the development of schizophrenia, potentially increasing the risk of the disease in those who are already at risk. The increased risk may require the presence of certain genes within an individual. Its use is associated with doubling the rate.  Mechanism  The mechanisms of schizophrenia are unknown, and a number of models have been put forward to explain the link between altered brain function and schizophrenia.The prevailing model of schizophrenia is that of a neurodevelopmental disorder, and the underlying changes that occur before symptoms become evident are seen as arising from the interaction between genes and the environment. Extensive studies support this model. Maternal infections, malnutrition and complications during pregnancy and childbirth are known risk factors for the development of schizophrenia, which usually emerges between the ages of 18–25, a period that overlaps with certain stages of neurodevelopment. Gene-environment interactions lead to deficits in the neural circuitry that affect sensory and cognitive functions.The common dopamine and glutamate models proposed are not mutually exclusive; each is seen to have a role in the neurobiology of schizophrenia. The most common model put forward was the dopamine hypothesis of schizophrenia, which attributes psychosis to the mind\'s faulty interpretation of the misfiring of dopaminergic neurons. This has been directly related to the symptoms of delusions and hallucinations. Abnormal dopamine signaling has been implicated in schizophrenia based on the usefulness of medications that affect the dopamine receptor and the observation that dopamine levels are increased during acute psychosis. A decrease in D1 receptors in the dorsolateral prefrontal cortex may also be responsible for deficits in working memory.The glutamate hypothesis of schizophrenia links alterations between glutamatergic neurotransmission and the neural oscillations that affect connections between the thalamus and the cortex. Studies have shown that a reduced expression of a glutamate receptor – NMDA receptor, and glutamate blocking drugs such as phencyclidine and ketamine can mimic the symptoms and cognitive problems associated with schizophrenia. Post-mortem studies consistently find that a subset of these neurons fail to express GAD67 (GAD1), in addition to abnormalities in brain morphometry. The subsets of interneurons that are abnormal in schizophrenia are responsible for the synchronizing of neural ensembles needed during working memory tasks. These give the neural oscillations produced as gamma waves that have a frequency of between 30 and 80 hertz. Both working memory tasks and gamma waves are impaired in schizophrenia, which may reflect abnormal interneuron functionality. An important process that may be disrupted in neurodevelopment is astrogenesis – the formation of astrocytes. Astrocytes are crucial in contributing to the formation and maintenance of neural circuits and it is believed that disruption in this role can result in a number of neurodevelopmental disorders including schizophrenia. Evidence suggests that reduced numbers of astrocytes in deeper cortical layers are assocociated with a diminished expression of EAAT2, a glutamate transporter in astrocytes; supporting the glutamate hypothesis.Deficits in executive functions, such as planning, inhibition, and working memory, are pervasive in schizophrenia. Although these functions are separable, their dysfunction in schizophrenia may reflect an underlying deficit in the ability to represent goal related information in working memory, and to use this to direct cognition and behavior. These impairments have been linked to a number of neuroimaging and neuropathological abnormalities. For example, functional neuroimaging studies report evidence of reduced neural processing efficiency, whereby the dorsolateral prefrontal cortex is activated to a greater degree to achieve a certain level of performance relative to controls on working memory tasks. These abnormalities may be linked to the consistent post-mortem finding of reduced neuropil, evidenced by increased pyramidal cell density and reduced dendritic spine density. These cellular and functional abnormalities may also be reflected in structural neuroimaging studies that find reduced grey matter volume in association with deficits in working memory tasks.Positive symptoms have been linked to cortical thinning in the superior temporal gyrus. The severity of negative symptoms has been linked to reduced thickness in the left medial orbitofrontal cortex. Anhedonia, traditionally defined as a reduced capacity to experience pleasure, is frequently reported in schizophrenia. However, a large body of evidence suggests that hedonic responses are intact in schizophrenia, and that what is reported to be anhedonia is a reflection of dysfunction in other processes related to reward. Overall, a failure of reward prediction is thought to lead to impairment in the generation of cognition and behavior required to obtain rewards, despite normal hedonic responses.Another theory links abnormal brain lateralization to the development of being left-handed which is significantly more common in those with schizophrenia. This abnormal development of hemispheric asymmetry is noted in schizophrenia. Studies have concluded that the link is a true and verifiable effect that may reflect a genetic link between lateralization and schizophrenia.Bayesian models of brain functioning have been used to link abnormalities in cellular functioning to symptoms. Both hallucinations and delusions have been suggested to reflect improper encoding of prior expectations, thereby causing expectation to excessively influence sensory perception and the formation of beliefs. In approved models of circuits that mediate predictive coding, reduced NMDA receptor activation, could in theory result in the positive symptoms of delusions and hallucinations.  Diagnosis   Criteria  Schizophrenia is diagnosed based on criteria in either the Diagnostic and Statistical Manual of Mental Disorders (DSM) published by the American Psychiatric Association or the International Statistical Classification of Diseases and Related Health Problems (ICD) published by the World Health Organization (WHO). These criteria use the self-reported experiences of the person and reported abnormalities in behavior, followed by a psychiatric assessment. The mental status examination is an important part of the assessment. An established tool for assessing the severity of positive and negative symptoms is the Positive and Negative Syndrome Scale (PANSS). This has been seen to have shortcomings relating to negative symptoms, and other scales – the Clinical Assessment Interview for Negative Symptoms (CAINS), and the Brief Negative Symptoms Scale (BNSS) have been introduced. The DSM-5, published in 2013, gives a Scale to Assess the Severity of Symptom Dimensions outlining eight dimensions of symptoms.DSM-5 states that to be diagnosed with schizophrenia, two diagnostic criteria have to be met over the period of one month, with a significant impact on social or occupational functioning for at least six months. One of the symptoms needs to be either delusions, hallucinations, or disorganized speech. A second symptom could be one of the negative symptoms, or severely disorganized or catatonic behaviour. A different diagnosis of schizophreniform disorder can be made before the six months needed for the diagnosis of schizophrenia.In Australia, the guideline for diagnosis is for six months or more with symptoms severe enough to affect ordinary functioning. In the UK diagnosis is based on having the symptoms for most of the time for one month, with symptoms that significantly affect the ability to work, study, or carry on ordinary daily living, and with other similar conditions ruled out.The ICD criteria are typically used in European countries; the DSM criteria are used predominantly in the United States and Canada, and are prevailing in research studies. In practice, agreement between the two systems is high. The current proposal for the ICD-11 criteria for schizophrenia recommends adding self-disorder as a symptom.A major unresolved difference between the two diagnostic systems is that of the requirement in DSM of an impaired functional outcome. WHO for ICD argues that not all people with schizophrenia have functional deficits and so these are not specific for the diagnosis.  Comorbidities  Many people with schizophrenia may have one or more other mental disorders, such as panic disorder, obsessive–compulsive disorder, or substance use disorder. These are separate disorders that require treatment. When comorbid with schizophrenia, substance use disorder and antisocial personality disorder both increase the risk for violence. Comorbid substance use disorder also increases the risk of suicide.Sleep disorders often co-occur with schizophrenia, and may be an early sign of relapse. Sleep disorders are linked with positive symptoms such as disorganized thinking and can adversely affect cortical plasticity and cognition. The consolidation of memories is disrupted in sleep disorders. They are associated with severity of illness, a poor prognosis, and poor quality of life. Sleep onset and maintenance insomnia is a common symptom, regardless of whether treatment has been received or not. Genetic variations have been found associated with these conditions involving the circadian rhythm, dopamine and histamine metabolism, and signal transduction.Schizophrenia is also associated with a number of somatic comorbidities including diabetes mellitus type 2, autoimmune diseases, and cardiovascular diseases. The association of these with schizophrenia may be partially due to medications (e.g. dyslipidemia from antipsychotics), environmental factors (e.g. complications from an increased rate of cigarette smoking), or associated with the disorder itself (e.g. diabetes mellitus type 2 and some cardiovascular diseases are thought to be genetically linked). These somatic comorbidities contribute to reduced life expectancy among persons with the disorder.  Differential diagnosis  To make a diagnosis of schizophrenia other possible causes of psychosis need to be excluded.: 858 Psychotic symptoms lasting less than a month may be diagnosed as brief psychotic disorder, or as schizophreniform disorder. Psychosis is noted in Other specified schizophrenia spectrum and other psychotic disorders as a DSM-5 category. Schizoaffective disorder is diagnosed if symptoms of mood disorder are substantially present alongside psychotic symptoms. Psychosis that results from a general medical condition or substance is termed secondary psychosis.Psychotic symptoms may be present in several other conditions, including bipolar disorder, borderline personality disorder, substance intoxication, substance-induced psychosis, and a number of drug withdrawal syndromes. Non-bizarre delusions are also present in delusional disorder, and social withdrawal in social anxiety disorder, avoidant personality disorder and schizotypal personality disorder. Schizotypal personality disorder has symptoms that are similar but less severe than those of schizophrenia. Schizophrenia occurs along with obsessive–compulsive disorder (OCD) considerably more often than could be explained by chance, although it can be difficult to distinguish obsessions that occur in OCD from the delusions of schizophrenia. There can be considerable overlap with the symptoms of post-traumatic stress disorder.A more general medical and neurological examination may be needed to rule out medical illnesses which may rarely produce psychotic schizophrenia-like symptoms, such as metabolic disturbance, systemic infection, syphilis, HIV-associated neurocognitive disorder, epilepsy, limbic encephalitis, and brain lesions. Stroke, multiple sclerosis, hyperthyroidism, hypothyroidism, and dementias such as Alzheimer\'s disease, Huntington\'s disease, frontotemporal dementia, and the Lewy body dementias may also be associated with schizophrenia-like psychotic symptoms. It may be necessary to rule out a delirium, which can be distinguished by visual hallucinations, acute onset and fluctuating level of consciousness, and indicates an underlying medical illness. Investigations are not generally repeated for relapse unless there is a specific medical indication or possible adverse effects from antipsychotic medication. In children hallucinations must be separated from typical childhood fantasies. It is difficult to distinguish childhood schizophrenia from autism.  Prevention  Prevention of schizophrenia is difficult as there are no reliable markers for the later development of the disorder. It is unclear as of 2011 whether treating patients in the prodrome phase of schizophrenia provides benefits.: 43 There is a discrepancy between the growth in the implementation of early intervention programmes for psychosis and the underlying empirical evidence.: 44 There is some evidence as of 2009 that early intervention in those with first-episode psychosis may improve short-term outcomes, but there is little benefit from these measures after five years. Cognitive behavioral therapy may reduce the risk of psychosis in those at high risk after a year and is recommended in this group, by the National Institute for Health and Care Excellence (NICE). Another preventive measure is to avoid drugs that have been associated with development of the disorder, including cannabis, cocaine, and amphetamines.Antipsychotics are prescribed following a first-episode psychosis, and following remission, a preventive maintenance use is continued to avoid relapse. However, it is recognized that some people do recover following a single episode and that long-term use of antipsychotics will not be needed but there is no way of identifying this group.  Management  The primary treatment of schizophrenia is the use of antipsychotic medications, often in combination with psychosocial interventions and social supports. Community support services including drop-in centers, visits by members of a community mental health team, supported employment, and support groups are common. The time between the onset of psychotic symptoms to being given treatment – the duration of untreated psychosis (DUP) – is associated with a poorer outcome in both the short term and the long term.Voluntary or involuntary admission to hospital may be imposed by doctors and courts who deem a person to be having a severe episode. In the UK, large mental hospitals termed asylums began to be closed down in the 1950s with the advent of antipsychotics, and with an awareness of the negative impact of long-term hospital stays on recovery. This process was known as deinstitutionalization, and community and supportive services were developed to support this change. Many other countries followed suit with the US starting in the 60s. There still remain a smaller group of people who do not improve enough to be discharged. In some countries that lack the necessary supportive and social services, long-term hospital stays are more usual.  Medication  The first-line treatment for schizophrenia is an antipsychotic. The first-generation antipsychotics, now called typical antipsychotics, are dopamine antagonists that block D2 receptors, and affect the neurotransmission of dopamine. Those brought out later, the second-generation antipsychotics known as atypical antipsychotics, can also have an effect on another neurotransmitter, serotonin. Antipsychotics can reduce the symptoms of anxiety within hours of their use but for other symptoms they may take several days or weeks to reach their full effect. They have little effect on negative and cognitive symptoms, which may be helped by additional psychotherapies and medications. There is no single antipsychotic suitable for first-line treatment for everyone, as responses and tolerances vary between people. Stopping medication may be considered after a single psychotic episode where there has been a full recovery with no symptoms for twelve months. Repeated relapses worsen the long-term outlook and the risk of relapse following a second episode is high, and long-term treatment is usually recommended.About half of those with schizophrenia will respond favourably to antipsychotics, and have a good return of functioning. However, positive symptoms persist in up to a third of people. Following two trials of different antipsychotics over six weeks, that also prove ineffective, they will be classed as having treatment resistant schizophrenia (TRS), and clozapine will be offered. Clozapine is of benefit to around half of this group although it has the potentially serious side effect of agranulocytosis (lowered white blood cell count) in less than 4% of people.About 30 to 50 percent of people with schizophrenia do not accept that they have an illness or comply with their recommended treatment. For those who are unwilling or unable to take medication regularly, long-acting injections of antipsychotics may be used, which reduce the risk of relapse to a greater degree than oral medications. When used in combination with psychosocial interventions, they may improve long-term adherence to treatment.  Adverse effects  Extrapyramidal symptoms, including akathisia, are associated with all commercially available antipsychotic to varying degrees.: 566 There is little evidence that second generation antipsychotics have reduced levels of extrapyramidical symptoms compared to typical antipsychotics.: 566 Tardive dyskinesia can occur due to long-term use of antipsychotics, developing after months or years of use. The antipsychotic clozapine is also associated with thromboembolism (including pulmonary embolism), myocarditis, and cardiomyopathy.  Psychosocial interventions  A number of psychosocial interventions that include several types of psychotherapy may be useful in the treatment of schizophrenia such as: family therapy, group therapy, cognitive remediation therapy (CRT), cognitive behavioral therapy (CBT), and metacognitive training. Skills training, help with substance use, and weight management – often needed as a side effect of an antipsychotic – are also offered. In the US, interventions for first episode psychosis have been brought together in an overall approach known as coordinated speciality care (CSC) and also includes support for education. In the UK care across all phases is a similar approach that covers many of the treatment guidelines recommended. The aim is to reduce the number of relapses and stays in the hospital.Other support services for education, employment, and housing are usually offered. For people with severe schizophrenia, who are discharged from a stay in the hospital, these services are often brought together in an integrated approach to offer support in the community away from the hospital setting. In addition to medicine management, housing, and finances, assistance is given for more routine matters such as help with shopping and using public transport. This approach is known as assertive community treatment (ACT) and has been shown to achieve positive results in symptoms, social functioning and quality of life. Another more intense approach is known as intensive care management (ICM). ICM is a stage further than ACT and emphasises support of high intensity in smaller caseloads, (less than twenty). This approach is to provide long-term care in the community. Studies show that ICM improves many of the relevant outcomes including social functioning.Some studies have shown little evidence for the effectiveness of CBT in either reducing symptoms or preventing relapse. However, other studies have found that CBT does improve overall psychotic symptoms (when in use with medication) and it has been recommended in Canada, but has been seen to have no effect on social function, relapse, or quality of life. In the UK it is recommended as an add-on therapy in the treatment of schizophrenia. Arts therapies are seen to improve negative symptoms in some people, and are recommended by NICE in the UK. This approach is criticised as having not been well-researched, and arts therapies are not recommended in Australian guidelines for example. Peer support, in which people with personal experience of schizophrenia, provide help to each other, is of unclear benefit.  Other  Exercise including aerobic exercise has been shown to improve positive and negative symptoms, cognition, working memory, and improve quality of life. Exercise has also been shown to increase the volume of the hippocampus in those with schizophrenia. A decrease in hippocampal volume is one of the factors linked to the development of the disease. However, there still remains the problem of increasing motivation for, and maintaining participation in physical activity. Supervised sessions are recommended. In the UK healthy eating advice is offered alongside exercise programs.An inadequate diet is often found in schizophrenia, and associated vitamin deficiencies including those of folate, and vitamin D are linked to the risk factors for the development of schizophrenia and for early death including heart disease. Those with schizophrenia possibly have the worst diet of all the mental disorders. Lower levels of folate and vitamin D have been noted as significantly lower in first episode psychosis. The use of supplemental folate is recommended. A zinc deficiency has also been noted. Vitamin B12 is also often deficient and this is linked to worse symptoms. Supplementation with B vitamins has been shown to significantly improve symptoms, and to put in reverse some of the cognitive deficits. It is also suggested that the noted dysfunction in gut microbiota might benefit from the use of probiotics.  Prognosis  Schizophrenia has great human and economic costs. It decreases life expectancy by between 20 and 28 years. This is primarily because of its association with heart disease, diabetes, obesity, poor diet, a sedentary lifestyle, and smoking, with an increased rate of suicide playing a lesser role. Side effects of antipsychotics may also increase the risk.Almost 40% of those with schizophrenia die from complications of cardiovascular disease which is seen to be increasingly associated. An underlying factor of sudden cardiac death may be Brugada syndrome (BrS) – BrS mutations that overlap with those linked with schizophrenia are the calcium channel mutations. BrS may also be drug-induced from certain antipsychotics and antidepressants. Primary polydipsia, or excessive fluid intake, is relatively common in people with chronic schizophrenia. This may lead to hyponatremia which can be life-threatening. Antipsychotics can lead to a dry mouth, but there are several other factors that may contribute to the disorder; it may reduce life expectancy by 13 percent. Barriers to improving the mortality rate in schizophrenia are poverty, overlooking the symptoms of other illnesses, stress, stigma, and medication side effects.Schizophrenia is a major cause of disability. In 2016, it was classed as the 12th most disabling condition. Approximately 75% of people with schizophrenia have ongoing disability with relapses. Some people do recover completely and others function well in society. Most people with schizophrenia live independently with community support. About 85% are unemployed. In people with a first episode of psychosis in schizophrenia a good long-term outcome occurs in 31%, an intermediate outcome in 42% and a poor outcome in 31%. Males are affected more often than females, and have a worse outcome. Studies showing that outcomes for schizophrenia appear better in the developing than the developed world have been questioned. Social problems, such as long-term unemployment, poverty, homelessness, exploitation, stigmatization and victimization are common consequences, and lead to social exclusion.There is a higher than average suicide rate associated with schizophrenia estimated at 5% to 6%, most often occurring in the period following onset or first hospital admission. Several times more (20 to 40%) attempt suicide at least once. There are a variety of risk factors, including male sex, depression, a high IQ, heavy smoking, and substance use. Repeated relapse is linked to an increased risk of suicidal behavior. The use of clozapine can reduce the risk of suicide, and of aggression.A strong association between schizophrenia and tobacco smoking has been shown in worldwide studies. Smoking is especially high in those diagnosed with schizophrenia, with estimates ranging from 80 to 90% being regular smokers, as compared to 20% of the general population. Those who smoke tend to smoke heavily, and additionally smoke cigarettes with high nicotine content. Some propose that this is in an effort to improve symptoms. Among people with schizophrenia use of cannabis is also common.Schizophrenia leads to an increased risk of dementia.  Violence  Most people with schizophrenia are not aggressive, and are more likely to be victims of violence rather than perpetrators. People with schizophrenia are commonly exploited and victimized by violent crime as part of a broader dynamic of social exclusion. People diagnosed with schizophrenia are also subject to forced drug injections, seclusion, and restraint at high rates.The risk of violence by people with schizophrenia is small. There are minor subgroups where the risk is high. This risk is usually associated with a comorbid disorder such as a substance use disorder – in particular alcohol, or with antisocial personality disorder. Substance use disorder is strongly linked, and other risk factors are linked to deficits in cognition and social cognition including facial perception and insight that are in part included in theory of mind impairments. Poor cognitive functioning, decision-making, and facial perception may contribute to making a wrong judgement of a situation that could result in an inappropriate response such as violence. These associated risk factors are also present in antisocial personality disorder which when present as a comorbid disorder greatly increases the risk of violence.  Epidemiology  In 2017, the Global Burden of Disease Study estimated there were 1.1 million new cases; in 2022 the World Health Organization (WHO) reported a total of 24 million cases globally. Schizophrenia affects around 0.3–0.7% of people at some point in their life. In areas of conflict this figure can rise to between 4.0 and 6.5%. It occurs 1.4 times more frequently in males than females and typically appears earlier in men.Worldwide, schizophrenia is the most common psychotic disorder. The frequency of schizophrenia varies across the world, within countries, and at the local and neighborhood level; this variation in prevalence between studies over time, across geographical locations, and by gender is as high as fivefold.Schizophrenia causes approximately one percent of worldwide disability adjusted life years and resulted in 17,000 deaths in 2015.In 2000, WHO found the percentage of people affected and the number of new cases that develop each year is roughly similar around the world, with age-standardized prevalence per 100,000 ranging from 343 in Africa to 544 in Japan and Oceania for men, and from 378 in Africa to 527 in Southeastern Europe for women.  History   Conceptual development  Accounts of a schizophrenia-like syndrome are rare in records before the 19th century; the earliest case reports were in 1797 and 1809. Dementia praecox, meaning premature dementia, was used by German psychiatrist Heinrich Schüle in 1886, and then in 1891 by Arnold Pick in a case report of hebephrenia. In 1893 Emil Kraepelin used the term in making a distinction, known as the Kraepelinian dichotomy, between the two psychoses – dementia praecox, and manic depression (now called bipolar disorder). When it became evident that the disorder was not a degenerative dementia, it was renamed schizophrenia by Eugen Bleuler in 1908.The word schizophrenia translates as \'splitting of the mind\' and is Modern Latin from the Greek words schizein (Ancient Greek: σχίζειν, lit. \'to split\') and phrēn, (Ancient Greek: φρήν, lit. \'mind\') Its use was intended to describe the separation of function between personality, thinking, memory, and perception.In the early 20th century, the psychiatrist Kurt Schneider categorized the psychotic symptoms of schizophrenia into two groups – hallucinations and delusions. The hallucinations were listed as specific to auditory and the delusions included thought disorders. These were seen as important symptoms, termed first-rank. The most common first-rank symptom was found to belong to thought disorders. In 2013 the first-rank symptoms were excluded from the DSM-5 criteria; while they may not be useful in diagnosing schizophrenia, they can assist in differential diagnosis.Subtypes of schizophrenia – classified as paranoid, disorganized, catatonic, undifferentiated, and residual – were difficult to distinguish and are no longer recognized as separate conditions by DSM-5 (2013) or ICD-11.","Schizophrenia is a condition which may be diagnosed by a psychiatrist. It is a lifelong mental disorder where people may see, hear or believe things which are not real. It can be a big problem for people who have it. It may occur at almost any age, but typical onset is between late teens to early 30s. It can show in young people aged from 16 to 30. Self-harm is likely, and confused speech which seems meaningless is a common characteristic. The condition definitely needs psychiatric assessment. Because of the self-harm possibility, no time should be wasted if a young person begins to show the signs. There is a genetic component (which is not well understood). If one child shows clear signs, other children in the family may show some symptoms. Some similar mental illnesses include schizotypal personality disorder, schizoaffective disorder, and schizoid personality disorder. It is a relatively common condition affecting one in 200 people. It is not infectious in any way. There is a danger that the sufferer may self-harm. Its cause is not exactly known. Very often it first appears in teenage years when the sufferer goes through puberty. There is no cure, but there is treatment which can help most of the sufferers. People with this disorder often do not behave the way most people do towards others. They also may not know what is real (this is called psychosis). Some common signs are strange beliefs, unclear or confused thinking and language, hallucinations (such as hearing voices that aren't there), poor interaction with others, less expression of feelings, and not doing much. They also may not care about many things.Schizophrenia is a chronic condition. There is no cure, but a combination of a therapy and certain drugs can allow most people suffering from it to lead a normal life.  Meaning  The word schizophrenia comes from two Greek words that mean to split and mind, because there is a 'split' between what's going on in the person's mind and what is actually happening. A person with schizophrenia does not change between different personalities: they have only one. The condition in which a person has more than one personality, meaning they act like a different person at different times, is dissociative identity disorder. There are no medical tests that can be used to say if a person has schizophrenia or not, so getting a diagnosis depends on which list of symptoms are used. It also depends on the doctor or psychologist who talks to the person. The lists of symptoms include wording like ""Disorganized [not organized, or oddly organized] speech present for a significant portion of time"". It is difficult to agree on what exactly ""disorganized speech"" is and how disorganized it has to be. It is also difficult to agree on how long a ""significant portion of time"" is. Because of this, two doctors or psychologists trying to make a diagnosis may often disagree. One will say that the person is schizophrenic and the other will say he or she is not.  About schizophrenia  Schizophrenia has many different symptoms, and not everyone with schizophrenia has all of them. For this reason, some scientists think that schizophrenia is several separate illnesses that have some of the same symptoms. These scientists claim that the research done on schizophrenia is not accurate since different researchers mean different things when they use the word ""schizophrenia"" in scientific studies. Many medications (licensed drugs to cure or treat an illness) may also cause the same symptoms as schizophrenia. The most common ones are antidepressants (medicines to treat depression) and ADHD medication (medication to treat ADHD, a condition affecting the brain, including memory and focusing on surroundings.) If a person has taken anti-vomiting medication (medication to stop them being sick) for some time and suddenly stops, he or she may get schizophrenia symptoms. Hundreds of medications have schizophrenia symptoms as rare side effects (unintended effects of taking them). Illegal drugs such as LSD, amphetamines, magic mushrooms and cocaine may cause schizophrenia symptoms.Medical illnesses, and treatment with certain medicines, can cause symptoms very similar to that of schizophrenia. In fact, there are over a hundred medical problems that can cause the same symptoms of schizophrenia. For this reason, it is important to rule out the possibility of either of these things being the cause for the person's symptoms. For this reason, the person should have a thorough medical exam to rule out problems like; Not having enough vitamin B12, magnesium, sodium, or other chemicals the body needs Sleep disorders A stroke or brain tumor A metabolism (chemical reactions keeping the person alive) that is too high or too low  Delusions and hallucinations  People with schizophrenia often have delusions or hallucinations. A schizophrenic delusion is a belief that is very different from what other people with the same way of life believe. Hallucinations are usually experiences of hearing voices that don't exist. These voices often say unpleasant things to the person. Many people can hear voices like this without being schizophrenic, for instance right before falling asleep. This is called a hypnagogic hallucination. The brain cannot tell them apart from normal sounds that are heard. This is not yet fully understood by science.  Risk factors  There are many risk factors that may cause a person to develop schizophrenia. They include trauma (damage caused by stressful events) and genetics (schizophrenia running in families). Having a schizophrenic parent may be very stressful, and there may also be genes that influence the development of schizophrenia. It is very easy to show that trauma, such as sexual abuse (forced unwanted sexual behaviour towards somebody) increases the risk, but 40 years of searching for the right genes has not found anything that has been confirmed by independent research groups.  Hope  People with schizophrenia may also have other mental health disorders, like depression, anxiety and drug abuse. They often have problems functioning in society, and have difficulty keeping a job. However, there are a number of people with schizophrenia who get well and have earned college degrees and had professional careers. For example, Elyn. R. Saks successfully became a law professor at the University of Southern California and a published author. In a family treatment called ""Open dialog"" in Finland, eight out of every ten people with schizophrenia ""get well."" In developing countries, where doctors use less drugs, 2 out of 3 patients get well from schizophrenia. In western countries, where medications are used as treatment, 1 of 3 get well, but many suffer from drug side effects such as diabetes, obesity, and brain damage.  Treatment  Treatment of schizophrenia may include medication to help treat the symptoms, different types of psychotherapy (therapy by a professional), such as cognitive-behavioral therapy and many rehabilitation therapies (therapies restoring things to how they were before), such as cognitive remediation therapy. Cognitive behavioral therapy, CBT, is a talk therapy that focuses on helping the person to think about their strange ideas (delusions) in more realistic ways. The therapist may design a behavioral experiment for paranoia (false beliefs of danger) that will help the person to find out for example, if there really are cameras everywhere in the house. For hallucinations, cognitive therapy focuses on normalizing: many people hear voices without being stressed, and we all hear voices in the form of thoughts, it is just that people with schizophrenia hear them a bit more clearly than most people.  Official guidelines  The British national guidelines for treatment (NICE) suggest the following treatments: Check for reactions to traumatic experiences Decide together with a doctor about using medication, taking into account the side effect risk of getting diabetes, becoming seriously overweight, getting brain damage (tardive dyskinesia, 5% risk pr year), men growing breasts, and feelings described as inner torture (akathesia).The guidelines also warn against using more than one antipsychotic drug at the same time. Both for people who are at risk for getting schizophrenia and for people who have got it, they recommend cognitive behavioral therapy (CBT) and family therapy. Getting support from people who have become well from schizophrenia is also strongly recommended. In a family oriented treatment program in Finland, Open Dialog, 8 out of 10 people with schizophrenia get well with no medication or very limited drug use, often only with anxiety medication.  Symptoms  The symptoms of schizophrenia fall into three main categories: positive symptoms, negative symptoms, and cognitive symptoms. Positive symptomsPositive symptoms are thoughts, behaviors, or anything experienced by the senses that are not shared by others - like hearing voices that are not really there. They are called 'positive' not because they are good but because they are ""added on"". These symptoms may include having strange thoughts that do not make sense (delusions), disorganized thoughts and speech, and feeling, hearing, seeing, smelling, or tasting things that do not exist (hallucinations). Positive symptoms often respond to drug treatment and cognitive behavioral therapy, CBT. Stopping anti-psychotic or anti-vomiting drugs too quickly may also cause these symptoms. Negative symptomsNegative symptoms are thoughts, behaviors or emotions normally present in a healthy person that a person with a mental disorder has less of or may not have at all; they are 'minus' these. The sign for minus is -; it is also the sign for the word ""negative"". Negative symptoms includes a 'flat affect'; having a blank inexpressive look on the face and/or monosyllabic speech (speech always sounding the same) spoken in a slow monotone, few gestures, lack of interest in anything including other people, and an inability to act spontaneously or feel pleasure. These problems are also side effects of anti-psychoctic drugs. They may also be symptoms of many medical problems such as a metabolism that is too low. Cognitive symptoms (or cognitive deficits)Cognitive symptoms are problems with attention, certain types of memory, the concept of time, and with the ability to plan and organize. Cognitive deficits caused by schizophrenia can also be difficult to recognize as part of the disorder. They are the most disabling of the symptoms because cognitive problems affect everyday functioning. These problems may also be side effects of anti-psychotic drugs, antidepressants, sleeping medication and anti-anxiety drugs.  Causes  A combination of what has happened to a person and the person’s genes may play a role in the development of schizophrenia. People who have family members with schizophrenia and who experienced a brief period of psychotic symptoms have a 20 to 40 percent chance of being diagnosed one year later. This may be both the result of stressful events because of the family member and possibly a genetic effect. Inherited factorsIt is difficult to know if schizophrenia is inherited because it is hard to find out whether something comes from genes or the environment. Those who have a parent, a brother or sister with schizophrenia have a higher risk of developing schizophrenia. The risk is even higher if you have an identical twin with schizophrenia. This may seem to show that schizophrenia is inherited. However, it may be the stress of living with a schizophrenic family member that is traumatic. Identical twins are much closer and are treated much more in the same way, and this may be the reason why one of them is more likely to get schizophrenia if the other has it. Dr Jay Joseph has found many problems with the scientific studies of inheriting schizophrenia, including false reporting of results. Joseph also claims that 40 years of the search for the schizophrenia gene has not found a single gene that independent research groups have confirmed. Environmental factorsThere are may environmental risk factors factors for schizophrenia such as drug use, stress before birth and in some cases exposure to infectious diseases (a disease that spreads from person to person). In addition, living in a city during childhood or as an adult has been found to double the risk of schizophrenia . This is true even after taking into account drug use, race, and the size of one’s social group. Other factors that play an important role include whether the person feels socially isolated, as well as social adversity, racial discrimination (treating a person badly because of their race), the person's family not working properly, unemployment, and poor housing conditions. There is evidence that childhood experiences of abuse or trauma are risk factors for developing schizophrenia later in life. Substance abuseSeveral drugs have been linked with the development of schizophrenia and the abuse (harmful use) of certain drugs can cause symptoms like those of schizophrenia. About half of those people who have schizophrenia use too much drugs or alcohol, possibly to deal with depression, anxiety, boredom, or loneliness. Frequent marijuana use may double the risk of serious mental illness, including schizophrenia. SmokingMore people with schizophrenia smoke than the general population; it is estimated that at least 60% to as many as 90% of people with schizophrenia smoke. Recent research suggests that cigarette smoking may be a risk factor for developing schizophrenia. Smoking also reduces the effects and side effects of anti-psychotic drugs, and this may be one of the reasons for the high smoking rate. Patients taking anti-psychotic drugs die up to 20 years earlier than others, possibly because the medication makes them overweight, gives diabetes and leads to them smoking. Pre-birth factorsFactors such as lack of oxygen, infection, or stress and lack of healthy foods in the mother during pregnancy, might result in a slight increase in the risk of schizophrenia later in life. People who have schizophrenia are more likely to have been born in winter or spring (at least in the northern half of the world). This might relate to increased rates of exposures to viruses before birth. This difference is about 5 to 8 percent. Brain structure Some people who have schizophrenia have differences in their brain structure compared to those who do not have the disorder. These differences are often in the parts of the brain that manage memory, organization, emotions, the control of impulsive behavior, and language. For example, there is less brain volume in the frontal cortex and temporal lobes, and problems within the corpus callosum, the band of nerve fibers which connects the left side and the right side of the brain. People with schizophrenia also tend to have larger lateral and third ventricles. The ventricles are spaces within the brain filled with cerebrospinal fluid. Brain wiringThe human brain has 100 billion neurons; each one of these neurons are connected to many other neurons. One neuron may have as many as 20,000 connections; there is between 100 trillion and 500 trillion neural connections in the adult human brain. There are many different parts or 'regions' of the brain. To complete a task - like recalling a memory - usually more than one region of the brain is involved, and they are connected by neural networks which is like the brain's wiring. It is believed that there are problems with the brain's wiring in schizophrenia.  Diagnosis  The DSM-IV-TR or the ICD-10 criteria are used to determine whether a person has schizophrenia. These criteria use the self-reported experiences of the person and reported abnormalities (unusual occurrences) in the behavior of the person, followed by a clinical assessment. A person can be determined to have the disease only if the symptoms are severe.  Differential diagnosis  There are various medical conditions, other psychiatric conditions and drug abuse related reactions that may mimic the symptoms of schizophrenia (meaning they have some or all of the same symptoms). For example, delirium can cause visual hallucinations, or an unpredictable changing levels of consciousness. Schizophrenia occurs along with obsessive-compulsive disorder (OCD), a disorder in which a person becomes obsessed with certain ideas or actions. However, separating the obsessions of OCD from the delusions of schizophrenia can be difficult.  Prevention  There is no clear evidence that treating schizophrenia with anti-psychotic drugs early is effective. The British NICE guidelines recommend cognitive behavioural talk therapy for all people at risk. In recent research, 76 patients at risk for schizophrenia were divided into two groups. One group got omega3 for 3 months and the other got a dummy pill (food oil). After 12 months only 4.9% of the omega 3 group had got schizophrenia compared to 27.5% in the other group. There is some evidence which shows that early treatment with drugs improves short term outcomes for people who have a serious episode of mental illness. These measures show little benefit five years later. Attempting to prevent schizophrenia in the pre-onset phase with anti-psychotic drugs is of uncertain benefit and so is not recommended (as of 2009). Prevention is difficult because there is no reliable way to find out in advance who will get schizophrenia.  Management  The treatment of schizophrenia is based upon the phase of the illness the person is in. There are three treatment phases: Acute PhaseThere are some goals during the acute phase of treatment. Some of these goals are to prevent harm. To prevent harm, the person being treated will have the severity of psychosis and it's symptoms reduced. These symptoms include agitation, aggression, negative symptoms, self-disorder, and thought disorders. Another goal is to find and treat the things that led to the episode of psychosis. Then, the person will be treated by trying to go back to how they were before psychosis. Lastly, the person will be helped by forming social connections and finding out what treatment plans work for them. Some treatment plans can be for a long time, and others can be for a short time. Stabilization PhaseThe stabilization phase also has goals. One is to reduce the stress the person feels. Another is to prevent the person from experiencing psychosis again. Then, the person is helped further with social connection and getting better. If the person has improved with a medication, it is recommended they keep taking it for at least 6 months. Stable PhaseThe last phase of treatment is to make sure that the person is improving. If the treatment has bad side effects, it may be changed in this phase. Some treatments during this stage are psychotherapy and medication. Antipsychotic medications greatly reduce the risk of the person experiencing psychosis again. They are strongly recommended.  Medication  The first-line psychiatric treatment for schizophrenia is antipsychotic medication, which can reduce the positive symptoms in about seven to fourteen days. However, medication fails to improve negative symptoms or problems in thinking significantly. Many antipsychotics are Dopamine antagonists (a substance interfering with how another substance works.) High concentrations of Dopamine are thought to be the cause of hallucinations and delusions. For this reason blocking Dopamine reception helps against hallucinations and delusions. The British national guidelines for treatment (NICE) suggest checking for reactions to traumatic experiences, deciding together with a doctor about using medication, taking into account the side effect risks of getting diabetes, becoming seriously overweight, getting brain damage (tardive dyskinesia, 5% risk per year), men growing breasts, and feelings described as inner torture (akathesia). The guidelines warn against using more than one antipsychotic drug at the same time. Some reviews of research sponsored by the makers of antipsychotic drugs claim that about 40 to 50 percent of people have a good response to medication, 30 to 40 percent have a partial response, and 20 percent have an unsatisfactory response (after 6 weeks on two or three different drugs). Other research from The British Journal of Psychiatry were more negative and claimed that ""the clinical relevance of antipsychotics is in fact limited"". This study included 22 428 patients and 11 antipsychotic drugs. A drug called clozapine is an effective treatment for people who respond poorly to other drugs, but clozapine can lower the white blood cell count in 1 to 4 percent of people who take it. This is a serious side effect.For people who are unwilling or unable to take drugs regularly, injectable long-acting preparations of antipsychotics can be used. When used in combination with mental and social interventions (treatment), such preparations can help people to continue their treatment.  Psychosocial therapies  Numerous mental and social interventions can be useful in treating schizophrenia. Such interventions include various types of therapy, community-based treatments, supported employment, skills training, token economic interventions, and mental interventions for drug or alcohol use and weight management. Family therapy or education, which addresses the whole family system of an individual, might reduce a return of symptoms or the need for hospitalizations (having to go into hospital.) There is growing evidence for the effectiveness of cognitive behavioral therapy (also known as “talk therapy”) .The British national guidelines for treatment (NICE) recommend for both people are at risk of getting schizophrenia and people who have got it, cognitive behavioral therapy (CBT) and family therapy. Getting support from people who have become well from schizophrenia is also strongly recommended. In a family oriented treatment program in Finland, Open Dialog, 8 out of 10 people with schizophrenia get well with no medication or very limited drug use, often only anxiety medication.  Outlook  Schizophrenia has great human and economic costs. The condition results in a decreased life expectancy of 12 to 15 years, primarily because of its association with being overweight, not exercising, and smoking cigarettes. An increased rate of suicide (a person killing themself) plays a lesser role. These differences in life expectancy increased between the 1970s and 1990s.Schizophrenia is a major cause of disability, with active psychosis ranked as the third-most-disabling condition. Approximately three-fourths of people with schizophrenia have an ongoing disability with symptoms that keep coming back. Some people do recover completely and others function well in society. Most people with schizophrenia live independently, with community support. In people with a first episode of serious mental symptoms, 42 percent have a good long-term outcome, 35 percent have an intermediate outcome and 27 percent have a poor outcome. Outcomes for schizophrenia appear better in the developing world than in the developed world, although that conclusion has been questioned.The suicide rate of people who have schizophrenia is estimated to be about 4.9 percent, most often occurring in the period following the first appearance of symptoms or the first hospital admission. 20 to 40 percent try to kill themselves at least once.Schizophrenia and smoking have shown a strong association in studies worldwide. Use of cigarettes is especially high in individuals who have schizophrenia, with estimates ranging from 80 to 90 percent of these people being regular smokers, compared to 20 percent of the general population. Those individuals who smoke tend to smoke heavily and to smoke cigarettes with a high nicotine content.Research continues on schizophrenia. In the spring of 2013, genetics associations were shown between five major psychiatric disorders: autism, ADHD, bipolar disorder, depression, and schizophrenia per recent study. In the summer of 2013, for the first time, brain tissue development was replicated in three dimensions by scientists cloning a human ""mini-brain"" using stem cells. This could help with schizophrenia and autism neurological research (research related to the brain.)  Likelihood  As of 2011, schizophrenia affects around 0.3% to 0.7% of people, or 24 million people worldwide, at some point in their lives. More men are affected than women: the number of males with the disorder is 1.4 times greater than that of females. Schizophrenia usually appears earlier in men. For males the symptoms usually start from 20 to 28 years of age, and in females it is 26 to 32 years of age. Symptoms that start in childhood, middle or old age are much rarer. Despite the received wisdom that schizophrenia occurs at similar rates worldwide, its rate of likelihood varies across the world, within countries, and at the local level. The disorder causes approximately 1% of worldwide disability adjusted life years (in other words, years spent with a disability). The rate of schizophrenia varies depending on how it is defined.  History  Accounts of a schizophrenia-like syndrome are rare before the 19th century. Detailed case reports from 1797 and 1809, are regarded as the earliest cases of the disorder. Schizophrenia was first described as a distinct syndrome affecting teenagers and young adults by Bénédict Morel in 1853, termed démence précoce (literally 'early dementia'). The term dementia praecox was used in 1891 by Arnold Pick in a case report of a psychotic disorder. In 1893 Emil Kraepelin introduced a new distinction in the classification of mental disorders between dementia praecox and mood disorder (termed manic depression and including both unipolar and bipolar depression). Kraepelin believed that dementia praecox was primarily a disease of the brain, and a form of dementia, different from other forms of dementia such as Alzheimer's disease which usually happen later in life.Eugen Bleuler coined the term ”schizophrenia”, which translates roughly as ""split mind"", in 1908. The word was intended to describe the separation of functioning between personality, thinking, memory, and perception. Bleuler realized that the illness was not a dementia because some of his patients improved rather than got worse. In the early 1970s, the criteria for determining schizophrenia were the subject of numerous controversies. Schizophrenia was diagnosed far more often in the United States than in Europe. This difference was partly the result of looser criteria for determining whether someone had the condition in the United States, where the DSM-II manual was used. In Europe, the ICD-9 manual was used. A 1972 study, published in the journal Science, concluded that the diagnosis of schizophrenia in the United States was often unreliable. These factors resulted in the publication of the DSM-III in 1980 with a stricter and more defined criteria for the diagnosis.  Society and culture  Negative social judgment has been identified as a major obstacle in the recovery of people who have schizophrenia.In 2002, the term for schizophrenia in Japan was changed from “Seishin-Bunretsu-Byō” 精神分裂病 (“mind-split-disease”) to “Tōgō-shitchō-shō” 統合失調症 (“integration disorder”), in an attempt to reduce feelings of shame or embarrassment. The idea that the disease is caused by multiple factors (not just one mental cause) inspired the new name. The change increased the percentage of people who were informed of the diagnosis from 37 percent to 70 percent over three years.In the United States in 2002, the cost of schizophrenia, including direct costs (people who were not hospitalized, people who were hospitalized, medicines, and long-term care) and non-healthcare costs (law enforcement, reduced workplace productivity, and unemployment), was estimated to be $62.7 billion.The book “A Beautiful Mind” and the film of the same name are about the life of John Forbes Nash, an American mathematician and Nobel Prize winner who has schizophrenia. The movie “The Soloist” is based on the life of Nathaniel Ayers, a gifted musician who dropped out of the Julliard School, in New York City after the symptoms of schizophrenia began. He later became homeless in Los Angeles, California, in the notorious Skid Row section.  References "
"Crohn\'s disease is a type of inflammatory bowel disease (IBD) that may affect any segment of the gastrointestinal tract. Symptoms often include abdominal pain, diarrhea (which may be bloody if inflammation is severe), fever, abdominal distension, and weight loss. Complications outside of the gastrointestinal tract may include anemia, skin rashes, arthritis, inflammation of the eye, and fatigue. The skin rashes may be due to infections as well as pyoderma gangrenosum or erythema nodosum. Bowel obstruction may occur as a complication of chronic inflammation, and those with the disease are at greater risk of colon cancer and small bowel cancer.While the precise causes of Crohn\'s disease (CD) are unknown, it is believed to be caused by a combination of environmental, immune, and bacterial factors in genetically susceptible individuals. It results in a chronic inflammatory disorder, in which the body\'s immune system defends the gastrointestinal tract, possibly targeting microbial antigens. While Crohn\'s is an immune-related disease, it does not appear to be an autoimmune disease (the immune system is not triggered by the body itself). The exact underlying immune problem is not clear; however, it may be an immunodeficiency state.About half of the overall risk is related to genetics, with more than 70 genes involved. Tobacco smokers are twice as likely to develop Crohn\'s disease as nonsmokers. It often begins after gastroenteritis. Diagnosis is based on biopsy and appearance of the bowel wall, medical imaging, and description of the disease. Other conditions with similar symptoms include irritable bowel syndrome and Behçet\'s disease.There is no known cure for Crohn\'s disease. Treatment options are intended to help with symptoms, maintain remission, and prevent relapse. In those newly diagnosed, a corticosteroid may be used for a brief period of time to rapidly improve symptoms, alongside another medication such as either methotrexate or a thiopurine used to prevent recurrence. Cessation of smoking is recommended for people with Crohn\'s disease. One in five people with the disease is admitted to the hospital each year, and half of those with the disease will require surgery at some point over a ten-year period. While surgery should be used as little as possible, it is necessary to address some abscesses, certain bowel obstructions, and cancers. Checking for bowel cancer via colonoscopy is recommended every few years, starting eight years after the disease has begun.Crohn\'s disease affects about 3.2 per 1,000 people in Europe, North America, and the UK. It is less common in Asia and Africa. It has historically been more common in the developed world. Rates have, however, been increasing, particularly in the developing world, since the 1970s. Inflammatory bowel disease resulted in 47,400 deaths in 2015, and those with Crohn\'s disease have a slightly reduced life expectancy. It tends to start in adolescence and young adulthood, though it can occur at any age. Males and females are equally affected.  Name  The disease was named after gastroenterologist Burrill Bernard Crohn, who in 1932, together with two colleagues at Mount Sinai Hospital in New York, described a series of patients with inflammation of the terminal ileum of the small intestine, the area most commonly affected by the illness.  Signs and symptoms   Gastrointestinal  Many people with Crohn\'s disease have symptoms for years before the diagnosis. The usual onset is in the teens and twenties, but can occur at any age. Because of the \'patchy\' nature of the gastrointestinal disease and the depth of tissue involvement, initial symptoms can be more subtle than those of ulcerative colitis. People with Crohn\'s disease experience chronic recurring periods of flare-ups and remission. The symptoms experienced can change over time as inflammation increases and spreads. Symptoms can also be different depending on which organs are involved. It is generally thought that the presentation of Crohn\'s disease is different for each patient due to the high variability of symptoms, organ involvement, and initial presentation.  Perianal  Perianal discomfort may also be prominent in Crohn\'s disease. Itchiness or pain around the anus may be suggestive of inflammation of the anus, or perianal complications such as anal fissures, fistulae, or abscesses around the anal area. Perianal skin tags are also common in Crohn\'s disease, and may appear with or without the presence of colorectal polyps. Fecal incontinence may accompany perianal Crohn\'s disease.  Intestines  The intestines, especially the colon and terminal ileum, are the most commonly affected areas of the body. Abdominal pain is a common initial symptom of Crohn\'s disease, especially in the lower right abdomen. Flatulence, bloating, and abdominal distension are additional symptoms and may also add to the intestinal discomfort. Pain is often accompanied by diarrhea, which may or may not be bloody. Inflammation in different areas of the intestinal tract can affect the quality of the feces. Ileitis typically results in large-volume, watery feces, while colitis may result in a smaller volume of feces of higher frequency. Fecal consistency may range from solid to watery. In severe cases, an individual may have more than 20 bowel movements per day, and may need to awaken at night to defecate. Visible bleeding in the feces is less common in Crohn\'s disease than in ulcerative colitis, but is not unusual. Bloody bowel movements are usually intermittent, and may be bright red, dark maroon, or even black in color. The color of bloody stool depends on the location of the bleed. In severe Crohn\'s colitis, bleeding may be copious.  Stomach and esophagus  The stomach is rarely the sole or predominant site of CD. To date there are only a few documented case reports of adults with isolated gastric CD and no reports in the pediatric population. Isolated stomach involvement is very unusual presentation accounting for less than 0.07% of all gastrointestinal CD. Rarely, the esophagus and stomach may be involved in Crohn\'s disease. These can cause symptoms including difficulty swallowing (dysphagia), upper abdominal pain, and vomiting.  Oropharynx (mouth)  The mouth may be affected by recurrent sores (aphthous ulcers). Recurrent aphthous ulcers are common; however, it is not clear whether this is due to Crohn\'s disease or simply that they are common in the general population. Other findings may include diffuse or nodular swelling of the mouth, a cobblestone appearance inside the mouth, granulomatous ulcers, or pyostomatitis vegetans. Medications that are commonly prescribed to treat CD, such as anti-inflammatory and sulfa-containing drugs, may cause lichenoid drug reactions in the mouth. Fungal infection such as candidiasis is also common due to the immunosuppression required in the treatment of the disease. Signs of anemia such as pallor and angular cheilitis or glossitis are also common due to nutritional malabsorption.People with Crohn\'s disease are also susceptible to angular stomatitis, an inflammation of the corners of the mouth, and pyostomatitis vegetans.  Systemic  Like many other chronic, inflammatory diseases, Crohn\'s disease can cause a variety of systemic symptoms. Among children, growth failure is common. Many children are first diagnosed with Crohn\'s disease based on inability to maintain growth. As it may manifest at the time of the growth spurt in puberty, up to 30% of children with Crohn\'s disease may have retardation of growth. Fever may also be present, though fevers greater than 38.5 °C (101.3 °F) are uncommon unless there is a complication such as an abscess. Among older individuals, Crohn\'s disease may manifest as weight loss, usually related to decreased food intake, since individuals with intestinal symptoms from Crohn\'s disease often feel better when they do not eat and might lose their appetite. People with extensive small intestine disease may also have malabsorption of carbohydrates or lipids, which can further exacerbate weight loss.  Extraintestinal  Crohn\'s disease can affect many organ systems beyond the gastrointestinal tract.  Visual  Inflammation of the interior portion of the eye, known as uveitis, can cause blurred vision and eye pain, especially when exposed to light (photophobia). Uveitis can lead to loss of vision if untreated.Inflammation may also involve the white part of the eye (sclera) or the overlying connective tissue (episclera), which causes conditions called scleritis and episcleritis, respectively.Other very rare ophthalmological manifestations include: conjunctivitis, glaucoma, and retinal vascular disease.  Gallbladder and liver  Crohn\'s disease that affects the ileum may result in an increased risk of gallstones. This is due to a decrease in bile acid resorption in the ileum, and the bile gets excreted in the stool. As a result, the cholesterol/bile ratio increases in the gallbladder, resulting in an increased risk for gallstones. Although the association is greater in the context of ulcerative colitis, Crohn\'s disease may also be associated with primary sclerosing cholangitis, a type of inflammation of the bile ducts.Liver involvement of Crohn\'s disease can include cirrhosis and steatosis. Nonalcoholic fatty liver disease (Nonalcoholic Steatohepatitis, NAFLD) are relatively common and can slowly progress to end-stage liver disease. NAFLD sensitizes the liver to injury and increases the risk of developing acute or chronic liver failure following another liver injury.Other rare hepatobiliary manifestations of Crohn\'s disease include: cholangiocarcinoma, granulomatous hepatitis, cholelithiasis, autoimmune hepatitis, hepatic abscess, and pericholangitis.  Renal and urological  Nephrolithiasis, obstructive uropathy, and fistulization of the urinary tract directly result from the underlying disease process. Nephrolithiasis is due to calcium oxalate or uric acid stones. Calcium oxalate is due to hyperoxaluria typically associated with either distal ileal CD or ileal resection. Oxalate absorption increases in the presence of unabsorbed fatty acids in the colon. The fatty acids compete with oxalate to bind calcium, displacing the oxalate, which can then be absorbed as unbound sodium oxalate across colonocytes and excreted into the urine. Because sodium oxalate only is absorbed in the colon, calcium-oxalate stones form only in patients with an intact colon. Patients with an ileostomy are prone to formation of uric-acid stones because of frequent dehydration. The sudden onset of severe abdominal, back, or flank pain in patients with IBD, particularly if different from the usual discomfort, should lead to inclusion of a renal stone in the differential diagnosis.Urological manifestations in patients with IBD may include ureteral calculi, enterovesical fistula, perivesical infection, perinephric abscess, and obstructive uropathy with hydronephrosis. Ureteral compression is associated with retroperitoneal extension of the phlegmonous inflammatory process involving the terminal ileum and cecum, and may result in hydronephrosis severe enough to cause hypertension.Immune complex glomerulonephritis presenting with proteinuria and hematuria has been described in children and adults with CD or UC. Diagnosis is by renal biopsy, and treatment parallels the underlying IBD.Amyloidosis (see endocrinological involvement) secondary to Crohn\'s disease has been described and is known to affect the kidneys.  Pancreatic  Pancreatitis may be associated with both UC and CD. The most common cause is iatrogenic and involves sensitivity to medications used to treat IBD (3% of patients), including sulfasalazine, mesalamine, 6-mercaptopurine, and azathioprine. Pancreatitis may present as symptomatic (in 2%) or more commonly asymptomatic (8–21%) disease in adults with IBD.  Cardiovascular and circulatory  Children and adults with IBD have been rarely (<1%) reported developing pleuropericarditis either at initial presentation or during active or quiescent disease. The pathogenesis of pleuropericarditis is unknown, although certain medications (e.g., sulfasalazine and mesalamine derivatives) have been implicated in some cases. The clinical presentation may include chest pain, dyspnea, or in severe cases pericardial tamponade requiring rapid drainage. Nonsteroidal anti-inflammatory drugs have been used as therapy, although this should be weighed against the hypothetical risk of exacerbating the underlying IBD.In rare cases, cardiomyopathy, endocarditis, and myocarditis have been described.Crohn\'s disease also increases the risk of blood clots; painful swelling of the lower legs can be a sign of deep venous thrombosis, while difficulty breathing may be a result of pulmonary embolism.  Respiratory  Laryngeal involvement in inflammatory bowel disease is extremely rare. Only 12 cases of laryngeal involvement in Crohn disease have been reported as of 2019. Moreover, only one case of laryngeal manifestations in ulcerative colitis has been reported as of that date. 9 patients complained of difficulty in breathing due to edema and ulceration from the larynx to the hypopharynx Hoarseness, sore throat, and odynophagia are other symptoms of laryngeal involvement of Crohn\'s disease.Considering extraintestinal manifestations of CD, those involving the lung are relatively rare. However, there is a wide array of lung manifestations, ranging from subclinical alterations, airway diseases and lung parenchymal diseases to pleural diseases and drug-related diseases. The most frequent manifestation is bronchial inflammation and suppuration with or without bronchiectasis. There are a number of mechanisms by which the lungs may become involved in CD. These include the same embryological origin of the lung and gastrointestinal tract by ancestral intestine, similar immune systems in the pulmonary and intestinal mucosa, the presence of circulating immune complexes and auto-antibodies, and the adverse pulmonary effects of some drugs. A complete list of known pulmonary manifestations include: Fibrosing alveolitis, Pulmonary vasculitis, Apical fibrosis, Bronchiectasis, Bronchitis, Bronchiolitis, Tracheal stenosis, Granulomatous lung disease, and Abnormal pulmonary function.  Musculoskeletal  Crohn\'s disease is associated with a type of rheumatologic disease known as seronegative spondyloarthropathy. This group of diseases is characterized by inflammation of one or more joints (arthritis) or muscle insertions (enthesitis). The arthritis in Crohn\'s disease can be divided into two types. The first type affects larger weight-bearing joints such as the knee (most common), hips, shoulders, wrists, or elbows. The second type symmetrically involves five or more of the small joints of the hands and feet. The arthritis may also involve the spine, leading to ankylosing spondylitis if the entire spine is involved, or simply sacroiliitis if only the sacroiliac joint is involved. The symptoms of arthritis include painful, warm, swollen, stiff joints, and loss of joint mobility or function.Crohn\'s disease increases the risk of osteoporosis or thinning of the bones. Individuals with osteoporosis are at increased risk of bone fractures.  Dermatological  Crohn\'s disease may also involve the skin, blood, and endocrine system. Erythema nodosum is the most common type of skin problem, occurring in around 8% of people with Crohn\'s disease, producing raised, tender red nodules usually appearing on the shins. Erythema nodosum is due to inflammation of the underlying subcutaneous tissue, and is characterized by septal panniculitis.Pyoderma gangrenosum is a less common skin problem, occurring in under 2%, and is typically a painful ulcerating nodule.Clubbing, a deformity of the ends of the fingers, may also be a result of Crohn\'s disease. Other very rare dermatological manifestations include: Pyostomatitis vegetans, Psoriasis, Erythema multiforme, Epidermolysis bullosa acquista (described in a case report), and Metastatic CD (the spread of Crohn\'s inflammation to the skin). It is unknown if Sweet\'s Syndrome is connected to Crohn\'s disease.  Neurological  Crohn\'s disease can also cause neurological complications (reportedly in up to 15%). The most common of these are seizures, stroke, myopathy, peripheral neuropathy, headache, and depression.Central and peripheral neurological disorders are described in patients with IBD and include peripheral neuropathies, myopathies, focal central nervous system defects, convulsions, confusional episodes, meningitis, syncope, optic neuritis, and sensorineural loss. Autoimmune mechanisms are proposed for involvement with IBD. Nutritional deficiencies associated with neurological manifestations, such as vitamin B12 deficiency, should be investigated. Spinal abscess has been reported in both a child and an adult with initial complaints of severe back pain due to extension of a psoas abscess from the epidural space to the subarachnoid space.  Psychiatric and psychological  Crohn\'s disease is linked to many psychological disorders, including depression and anxiety, denial of your disease, the need for dependence or dependent behaviors, feeling overwhelmed, and having a poor self-image.  Endocrinological or hematological  Autoimmune hemolytic anemia, a condition in which the immune system attacks the red blood cells, is also more common in Crohn\'s disease and may cause fatigue, a pale appearance, and other symptoms common in anemia. Secondary amyloidosis (AA) is another rare but serious complication of inflammatory bowel disease (IBD), generally seen in Crohn\'s disease. At least 1% of patients with Crohn\'s disease develop amyloidosis. In the literature, the time lapse between the onset of Crohn\'s disease and the diagnosis of amyloidosis has been reported to range from 1 to 21 years. Leukocytosis and thrombocytopenia are usually due to immunosuppressant treatments or sulfasalazine. Plasma erythropoietin levels often are lower in patients with IBD than expected, in conjunction with severe anemia.Thrombocytosis and thromboembolic events resulting from a hypercoagulable state in patients with IBD can lead to pulmonary embolism or thrombosis elsewhere in the body. Thrombosis has been reported in 1.8% of patients with UC and 3.1% of patients with CD. Thromboembolism and thrombosis are less frequently reported among pediatric patients, with three patients with UC and one with CD described in case reports.In rare cases, hypercoagulation disorders and portal vein thrombosis have been described.  Malnutrition symptoms  People with Crohn\'s disease may develop anemia due to vitamin B12, folate, iron deficiency, or due to anemia of chronic disease. The most common is iron deficiency anemia from chronic blood loss, reduced dietary intake, and persistent inflammation leading to increased hepcidin levels, restricting iron absorption in the duodenum. As Crohn\'s disease most commonly affects the terminal ileum where the vitamin B12/intrinsic factor complex is absorbed, B12 deficiency may be seen. This is particularly common after surgery to remove the ileum. Involvement of the duodenum and jejunum can impair the absorption of many other nutrients including folate. People with Crohn\'s often also have issues with small bowel bacterial overgrowth syndrome, which can produce micronutrient deficiencies.  Complications   Intestinal damage  Crohn\'s disease can lead to several mechanical complications within the intestines, including obstruction, fistulae, and abscesses. Obstruction typically occurs from strictures or adhesions that narrow the lumen, blocking the passage of the intestinal contents. A fistula can develop between two loops of bowel, between the bowel and bladder, between the bowel and vagina, and between the bowel and skin. Abscesses are walled-off concentrations of infection, which can occur in the abdomen or in the perianal area. Crohn\'s is responsible for 10% of vesicoenteric fistulae, and is the most common cause of ileovesical fistulae.Symptoms caused by intestinal stenosis, or the tightening and narrowing of the bowel, are also common in Crohn\'s disease. Abdominal pain is often most severe in areas of the bowel with stenosis. Persistent vomiting and nausea may indicate stenosis from small bowel obstruction or disease involving the stomach, pylorus, or duodenum.Intestinal granulomas are a walled-off portions of the intestine by macrophages in order to isolate infections. Granuloma formation is more often seen in younger patients, and mainly in the severe, active penetrating disease. Granuloma is considered the hallmark of microscopic diagnosis in Crohn\'s disease (CD), but granulomas can be detected in only 21–60% of CD patients.  Cancer  Crohn\'s disease also increases the risk of cancer in the area of inflammation. For example, individuals with Crohn\'s disease involving the small bowel are at higher risk for small intestinal cancer. Similarly, people with Crohn\'s colitis have a relative risk of 5.6 for developing colon cancer. Screening for colon cancer with colonoscopy is recommended for anyone who has had Crohn\'s colitis for at least eight years.Some studies suggest there is a role for chemoprotection in the prevention of colorectal cancer in Crohn\'s involving the colon; two agents have been suggested, folate and mesalamine preparations. Also, immunomodulators and biologic agents used to treat this disease may promote developing extra-intestinal cancers.Some cancers, such as Acute Myelocytic Leukaemia have been described in cases of Crohn\'s disease. Hepatosplenic T-cell lymphoma (HSTCL) is a rare, lethal disease generally seen in young male patients with inflammatory bowel disease. TNF-α Inhibitor treatments (infliximab, adalimumab, certolizumab, natalizumab, and etanercept) are thought to be the cause of this rare disease.  Major complications  Major complications of Crohn\'s disease include bowel obstruction, abscesses, free perforation, and hemorrhage, which in rare cases may be fatal.  Other complications  Individuals with Crohn\'s disease are at risk of malnutrition for many reasons, including decreased food intake and malabsorption. The risk increases following resection of the small bowel. Such individuals may require oral supplements to increase their caloric intake, or in severe cases, total parenteral nutrition (TPN). Most people with moderate or severe Crohn\'s disease are referred to a dietitian for assistance in nutrition.Small intestinal bacterial overgrowth (SIBO) is characterized by excessive proliferation of colonic bacterial species in the small bowel. Potential causes of SIBO include fistulae, strictures, or motility disturbances. Hence, patients with Crohn\'s disease are especially predisposed to develop SIBO. As result, CD patients may experience malabsorption and report symptoms such as weight loss, watery diarrhea, meteorism, flatulence, and abdominal pain, mimicking acute flare in these patients.  Pregnancy  Crohn\'s disease can be problematic during pregnancy, and some medications can cause adverse outcomes for the fetus or mother. Consultation with an obstetrician and gastroenterologist about Crohn\'s disease and all medications facilitates preventive measures. In some cases, remission occurs during pregnancy. Certain medications can also lower sperm count or otherwise adversely affect a man\'s fertility.  Ostomy-related complications  Common complications of an ostomy (a common surgery in Crohn\'s disease) are: Mucosal edema, Peristomal dermatitis, Retraction, Ostomy prolapse, Mucosal/skin detachment, Hematoma, Necrosis, Parastomal hernia, and Stenosis.  Etiology  The etiology of Crohn\'s disease is unknown. Many theories have been disputed, with four main theories hypothesized to be the primary mechanism of Crohn\'s disease. In autoimmune diseases, antibodies and T lymphocytes are the primary mode of inflammation. These cells and bodies are part of the adaptive immune system, or the part of the immune system that learns to fight foreign bodies when first identified. Autoinflammatory diseases are diseases where the innate immune system, or the immune system we are genetically coded with, is designed to attack our own cells. Crohn\'s disease likely has involvement of both the adaptive and innate immune systems.  Autoinflammatory theory  Crohn\'s disease can be described as a multifactorial autoinflammatory disease. The etiopathogenesis of Crohn\'s disease is still unknown. In any event, a loss of the regulatory capacity of the immune apparatus would be implicated in the onset of the disease. In this respect interestingly enough, as for Blau\'s disease (a monogenic autoinflammatory disease), the NOD2 gene mutations have been linked to Crohn\'s disease. However, in Crohn\'s disease, NOD2 mutations act as a risk factor, being more common among Crohn\'s disease patients than the background population, while in Blau\'s disease NOD2 mutations are linked directly to this syndrome, as it is an autosomal-dominant disease. All this new knowledge in the pathogenesis of Crohn\'s disease allows us to put this multifactorial disease in the group of autoinflammatory syndromes.Some examples of how the innate immune system affects bowel inflammation have been described. A meta-analysis of CD genome-wide association studies revealed 71 distinct CD-susceptibility loci. Interestingly, three very important CD-susceptibility genes (the intracellular pathogen-recognition receptor, NOD2; the autophagy-related 16-like 1, ATG16L1 and the immunity-related GTPase M, IRGM) are involved in innate immune responses against gut microbiota, while one (the X-box binding protein 1) is involved in regulation of the [adaptive] immune pathway via MHC class II, resulting in autoinflammatory inflammation. Studies have also found that increased ILC3 can overexpress major histocompatibility complex (MHC) II. MHC class II can induce CD4+ T cell apoptosis, thus avoiding the T cell response to normal bowel micro bacteria. Further studies of IBD patients compared with non-IBD patients found that the expression of MHC II by ILC3 was significantly reduced in IBD patients, thus causing an immune reaction against intestinal cells or normal bowel bacteria and damaging the intestines. This can also make the intestines more susceptible to environmental factors, such as food or bacteria.The thinking is, that because Crohn\'s disease has strong innate immune system involvement and has NOD2 mutations as a predisposition, Crohn\'s disease is more likely an autoinflammatory disease than an autoimmune disease.  Immunodeficiency theory  A substantial body of data has emerged in recent years to suggest that the primary defect in Crohn\'s disease is actually one of relative immunodeficiency. This view has been bolstered recently by novel immunological and clinical studies that have confirmed gross aberrations in this early response, consistent with subsequent genetic studies that highlighted molecules important for innate immune function. The suggestion therefore is that Crohn\'s pathogenesis actually results from partial immunodeficiency, a theory that coincides with the frequent recognition of a virtually identical, non-infectious inflammatory bowel disease arising in patients with congenital monogenic disorders impairing phagocyte function.  Risk factors  While the exact cause or causes are unknown, Crohn\'s disease seems to be due to a combination of environmental factors and genetic predisposition. Crohn\'s is the first genetically complex disease in which the relationship between genetic risk factors and the immune system is understood in considerable detail. Each individual risk mutation makes a small contribution to the overall risk of Crohn\'s (approximately 1:200). The genetic data, and direct assessment of immunity, indicates a malfunction in the innate immune system. In this view, the chronic inflammation of Crohn\'s is caused when the adaptive immune system tries to compensate for a deficient innate immune system.  Genetics  Crohn\'s has a genetic component. Because of this, siblings of known people with Crohn\'s are 30 times more likely to develop Crohn\'s than the general population.The first mutation found to be associated with Crohn\'s was a frameshift in the NOD2 gene (also known as the CARD15 gene), followed by the discovery of point mutations. Over 30 genes have been associated with Crohn\'s; a biological function is known for most of them. For example, one association is with mutations in the XBP1 gene, which is involved in the unfolded protein response pathway of the endoplasmic reticulum. The gene variants of NOD2/CARD15 seem to be related with small-bowel involvement. Other well documented genes which increase the risk of developing Crohn\'s disease are ATG16L1, IL23R, IRGM, and SLC11A1. There is considerable overlap between susceptibility loci for IBD and mycobacterial infections. Genome-wide association studies have shown that Crohn\'s disease is genetically linked to coeliac disease.Crohn\'s has been linked to the gene LRRK2 with one variant potentially increasing the risk of developing the disease by 70%, while another lowers it by 25%. The gene is responsible for making a protein, which collects and eliminates waste product in cells, and is also associated with Parkinson\'s disease.  Immune system  There was a prevailing view that Crohn\'s disease is a primary T cell autoimmune disorder; however, a newer theory hypothesizes that Crohn\'s results from an impaired innate immunity. The later hypothesis describes impaired cytokine secretion by macrophages, which contributes to impaired innate immunity and leads to a sustained microbial-induced inflammatory response in the colon, where the bacterial load is high. Another theory is that the inflammation of Crohn\'s was caused by an overactive Th1 and Th17 cytokine response.In 2007, the ATG16L1 gene was implicated in Crohn\'s disease, which may induce autophagy and hinder the body\'s ability to attack invasive bacteria. Another study theorized that the human immune system traditionally evolved with the presence of parasites inside the body and that the lack thereof due to modern hygiene standards has weakened the immune system. Test subjects were reintroduced to harmless parasites, with positive responses.  Microbes  It is hypothesized that maintenance of commensal microorganism growth in the GI tract is dysregulated, either as a result or cause of immune dysregulation.There is an apparent connection between Crohn\'s disease, Mycobacterium, other pathogenic bacteria, and genetic markers. A number of studies have suggested a causal role for Mycobacterium avium subspecies paratuberculosis (MAP), which causes a similar disease, Johne\'s disease, in cattle. In many individuals, genetic factors predispose individuals to Mycobacterium avium subsp. paratuberculosis infection. This bacterium may produce certain compounds containing mannose, which may protect both itself and various other bacteria from phagocytosis, thereby possibly causing a variety of secondary infections.NOD2 is a gene involved in Crohn\'s genetic susceptibility. It is associated with macrophages\' diminished ability to phagocytize MAP. This same gene may reduce innate and adaptive immunity in gastrointestinal tissue and impair the ability to resist infection by the MAP bacterium. Macrophages that ingest the MAP bacterium are associated with high production of TNF-α.Other studies have linked specific strains of enteroadherent E. coli to the disease. Adherent-invasive Escherichia coli (AIEC), more common in people with CD, have the ability to make strong biofilms compared to non-AIEC strains correlating with high adhesion and invasion indices of neutrophils and the ability to block autophagy at the autolysosomal step, which allows for intracellular survival of the bacteria and induction of inflammation. Inflammation drives the proliferation of AIEC and dysbiosis in the ileum, irrespective of genotype. AIEC strains replicate extensively inside macrophages inducing the secretion of very large amounts of TNF-α.Mouse studies have suggested some symptoms of Crohn\'s disease, ulcerative colitis, and irritable bowel syndrome have the same underlying cause. Biopsy samples taken from the colons of all three patient groups were found to produce elevated levels of a serine protease. Experimental introduction of the serine protease into mice has been found to produce widespread pain associated with irritable bowel syndrome, as well as colitis, which is associated with all three diseases. Regional and temporal variations in those illnesses follow those associated with infection with the protozoan Blastocystis.The ""cold-chain"" hypothesis is that psychrotrophic bacteria such as Yersinia and Listeria species contribute to the disease. A statistical correlation was found between the advent of the use of refrigeration in the United States and various parts of Europe and the rise of the disease.There is also a tentative association between Candida colonization and Crohn\'s disease.Still, these relationships between specific pathogens and Crohn\'s disease remain unclear.  Environmental factors  The increased incidence of Crohn\'s in the industrialized world indicates an environmental component. Crohn\'s is associated with an increased intake of animal protein, milk protein, and an increased ratio of omega-6 to omega-3 polyunsaturated fatty acids. Those who consume vegetable proteins appear to have a lower incidence of Crohn\'s disease. Consumption of fish protein has no association.Smoking increases the risk of the return of active disease (flares). The introduction of hormonal contraception in the United States in the 1960s is associated with a dramatic increase in incidence, and one hypothesis is that these drugs work on the digestive system in ways similar to smoking. Isotretinoin is associated with Crohn\'s.Although stress is sometimes claimed to exacerbate Crohn\'s disease, there is no concrete evidence to support such claim. Still, it is well known that immune function is related to stress. Dietary microparticles, such as those found in toothpaste, have been studied as they produce effects on immunity, but they were not consumed in greater amounts in patients with Crohn\'s. The use of doxycycline has also been associated with increased risk of developing inflammatory bowel diseases. In one large retrospective study, patients who were prescribed doxycycline for their acne had a 2.25-fold greater risk of developing Crohn\'s disease.  Pathophysiology  During a colonoscopy, biopsies of the colon are often taken to confirm the diagnosis. Certain characteristic features of the pathology seen point toward Crohn\'s disease; it shows a transmural pattern of inflammation, meaning the inflammation may span the entire depth of the intestinal wall. Ulceration is an outcome seen in highly active disease. There is usually an abrupt transition between unaffected tissue and the ulcer—a characteristic sign known as skip lesions. Under a microscope, biopsies of the affected colon may show mucosal inflammation, characterized by focal infiltration of neutrophils, a type of inflammatory cell, into the epithelium. This typically occurs in the area overlying lymphoid aggregates. These neutrophils, along with mononuclear cells, may infiltrate the crypts, leading to inflammation (crypititis) or abscess (crypt abscess).Granulomas, aggregates of macrophage derivatives known as giant cells, are found in 50% of cases and are most specific for Crohn\'s disease. The granulomas of Crohn\'s disease do not show ""caseation"", a cheese-like appearance on microscopic examination characteristic of granulomas associated with infections, such as tuberculosis. Biopsies may also show chronic mucosal damage, as evidenced by blunting of the intestinal villi, atypical branching of the crypts, and a change in the tissue type (metaplasia). One example of such metaplasia, Paneth cell metaplasia, involves the development of Paneth cells (typically found in the small intestine and a key regulator of intestinal microbiota) in other parts of the gastrointestinal system.  Diagnosis  The diagnosis of Crohn\'s disease can sometimes be challenging, and many tests are often required to assist the physician in making the diagnosis. Even with a full battery of tests, it may not be possible to diagnose Crohn\'s with complete certainty; a colonoscopy is approximately 70% effective in diagnosing the disease, with further tests being less effective. Disease in the small bowel is particularly difficult to diagnose, as a traditional colonoscopy allows access to only the colon and lower portions of the small intestines; introduction of the capsule endoscopy aids in endoscopic diagnosis. Giant (multinucleate) cells, a common finding in the lesions of Crohn\'s disease, are less common in the lesions of lichen nitidus.  Classification  Crohn\'s disease is one type of inflammatory bowel disease (IBD). It typically manifests in the gastrointestinal tract and can be categorized by the specific tract region affected. A disease of both the ileum (the last part of the small intestine that connects to the large intestine), and the large intestine, Ileocolic Crohn\'s accounts for fifty percent of cases. Crohn\'s ileitis, manifest in the ileum only, accounts for thirty percent of cases, while Crohn\'s colitis, of the large intestine, accounts for the remaining twenty percent of cases and may be particularly difficult to distinguish from ulcerative colitis.Gastroduodenal Crohn\'s disease causes inflammation in the stomach and the first part of the small intestine called the duodenum. Jejunoileitis causes spotty patches of inflammation in the top half of the small intestine, called the jejunum. The disease can attack any part of the digestive tract, from mouth to anus. However, individuals affected by the disease rarely fall outside these three classifications, with presentations in other areas.Crohn\'s disease may also be categorized by the behavior of disease as it progresses. These categorizations formalized in the Vienna classification of the disease. There are three categories of disease presentation in Crohn\'s disease: stricturing, penetrating, and inflammatory. Stricturing disease causes narrowing of the bowel that may lead to bowel obstruction or changes in the caliber of the feces. Penetrating disease creates abnormal passageways (fistulae) between the bowel and other structures, such as the skin. Inflammatory disease (or nonstricturing, nonpenetrating disease) causes inflammation without causing strictures or fistulae.  Endoscopy  A colonoscopy is the best test for making the diagnosis of Crohn\'s disease, as it allows direct visualization of the colon and the terminal ileum, identifying the pattern of disease involvement. On occasion, the colonoscope can travel past the terminal ileum, but it varies from person to person. During the procedure, the gastroenterologist can also perform a biopsy, taking small samples of tissue for laboratory analysis, which may help confirm a diagnosis. As 30% of Crohn\'s disease involves only the ileum, cannulation of the terminal ileum is required in making the diagnosis. Finding a patchy distribution of disease, with involvement of the colon or ileum, but not the rectum, is suggestive of Crohn\'s disease, as are other endoscopic stigmata. The utility of capsule endoscopy for this, however, is still uncertain. A ""cobblestone""-like appearance is seen in approximately 40% of cases of Crohn\'s disease upon colonoscopy, representing areas of ulceration separated by narrow areas of healthy tissue.  Radiologic tests  A small bowel follow-through may suggest the diagnosis of Crohn\'s disease and is useful when the disease involves only the small intestine. Because colonoscopy and gastroscopy allow direct visualization of only the terminal ileum and beginning of the duodenum, they cannot be used to evaluate the remainder of the small intestine. As a result, a barium follow-through X-ray, wherein barium sulfate suspension is ingested and fluoroscopic images of the bowel are taken over time, is useful for looking for inflammation and narrowing of the small bowel. Barium enemas, in which barium is inserted into the rectum and fluoroscopy is used to image the bowel, are rarely used in the work-up of Crohn\'s disease due to the advent of colonoscopy. They remain useful for identifying anatomical abnormalities when strictures of the colon are too small for a colonoscope to pass through, or in the detection of colonic fistulae (in this case contrast should be performed with iodate substances).CT and MRI scans are useful for evaluating the small bowel with enteroclysis protocols. They are also useful for looking for intra-abdominal complications of Crohn\'s disease, such as abscesses, small bowel obstructions, or fistulae. Magnetic resonance imaging (MRI) is another option for imaging the small bowel as well as looking for complications, though it is more expensive and less readily available. MRI techniques such as diffusion-weighted imaging and high-resolution imaging are more sensitive in detecting ulceration and inflammation compared to CT.  Blood tests  A complete blood count may reveal anemia, which commonly is caused by blood loss leading to iron deficiency or by vitamin B12 deficiency, usually caused by ileal disease impairing vitamin B12 absorption. Rarely autoimmune hemolysis may occur. Ferritin levels help assess if iron deficiency is contributing to the anemia. Erythrocyte sedimentation rate (ESR) and C-reactive protein help assess the degree of inflammation, which is important as ferritin can also be raised in inflammation. Serum iron, total iron binding capacity and transferrin saturation may be more easily interpreted in inflammation. Anemia of chronic disease results in a normocytic anemia.Other causes of anemia include medication used in treatment of inflammatory bowel disease, like azathioprine, which can lead to cytopenia, and sulfasalazine, which can also result in folate deficiency. Testing for Saccharomyces cerevisiae antibodies (ASCA) and antineutrophil cytoplasmic antibodies (ANCA) has been evaluated to identify inflammatory diseases of the intestine and to differentiate Crohn\'s disease from ulcerative colitis. Furthermore, increasing amounts and levels of serological antibodies such as ASCA, antilaminaribioside [Glc(β1,3)Glb(β); ALCA], antichitobioside [GlcNAc(β1,4)GlcNAc(β); ACCA], antimannobioside [Man(α1,3)Man(α)AMCA], antiLaminarin [(Glc(β1,3))3n(Glc(β1,6))n; anti-L] and antichitin [GlcNAc(β1,4)n; anti-C] associate with disease behavior and surgery, and may aid in the prognosis of Crohn\'s disease.Low serum levels of vitamin D are associated with Crohn\'s disease. Further studies are required to determine the significance of this association.  Comparison with ulcerative colitis  The most common disease that mimics the symptoms of Crohn\'s disease is ulcerative colitis, as both are inflammatory bowel diseases that can affect the colon with similar symptoms. It is important to differentiate these diseases, since the course of the diseases and treatments may be different. In some cases, however, it may not be possible to tell the difference, in which case the disease is classified as indeterminate colitis.  Differential diagnosis  Other conditions with similar symptoms as Crohn\'s disease includes intestinal tuberculosis, Behçet\'s disease, ulcerative colitis, nonsteroidal anti-inflammatory drug enteropathy, irritable bowel syndrome and celiac disease. Irritable bowel syndrome is excluded when there are inflammatory changes. Celiac disease cannot be excluded if specific antibodies (anti-transglutaminase antibodies) are negative, nor in absence of intestinal villi atrophy.  Management  There is no cure for Crohn\'s disease and remission may not be possible or prolonged if achieved. In cases where remission is possible, relapse can be prevented and symptoms controlled with medication, lifestyle and dietary changes, changes to eating habits (eating smaller amounts more often), reduction of stress, moderate activity, and exercise. Surgery is generally contraindicated and has not been shown to prevent relapse. Adequately controlled, Crohn\'s disease may not significantly restrict daily living. Treatment for Crohn\'s disease involves first treating the acute problem and its symptoms, then maintaining remission of the disease.  Lifestyle changes  Certain lifestyle changes can reduce symptoms, including dietary adjustments, elemental diet, proper hydration, and smoking cessation. Patients with Crohn\'s disease are very interested in diet. Recent reviews underlined the importance to adopt diets that are best supported by evidence, even if little is known about the impact of diets on these patients. Diets that include higher levels of fiber and fruit are associated with reduced risk, while diets rich in total fats, polyunsaturated fatty acids, meat, and omega-6 fatty acids may increase the risk of Crohn\'s. Maintaining a balanced diet with proper portion control can help manage symptoms of the disease. Eating small meals frequently instead of big meals may also help with a low appetite. A food diary may help with identifying foods that trigger symptoms. Despite the recognized importance of dietary fiber for intestinal health, some people should follow a low residue diet to control acute symptoms especially if foods high in insoluble fiber cause symptoms, e.g., due to obstruction or irritation of the bowel. Some find relief in eliminating casein (a protein found in cow\'s milk) and gluten (a protein found in wheat, rye and barley) from their diets. They may have specific dietary intolerances (not allergies), for example, lactose. Fatigue can be helped with regular exercise, a healthy diet, and enough sleep, and for those with malabsorption of vitamin B12 due to disease or surgical resection of the terminal ileum, cobalamin injections. Smoking may worsen symptoms and the course of the disease, and stopping is recommended. Alcohol consumption can also worsen symptoms, and moderation or cessation is advised.  Medication  Acute treatment uses medications to treat any infection (normally antibiotics) and to reduce inflammation (normally aminosalicylate anti-inflammatory drugs and corticosteroids). When symptoms are in remission, treatment enters maintenance, with a goal of avoiding the recurrence of symptoms. Prolonged use of corticosteroids has significant side-effects; as a result, they are, in general, not used for long-term treatment. Alternatives include aminosalicylates alone, though only a minority are able to maintain the treatment, and many require immunosuppressive drugs. It has been also suggested that antibiotics change the enteric flora, and their continuous use may pose the risk of overgrowth with pathogens such as Clostridium difficile.Medications used to treat the symptoms of Crohn\'s disease include 5-aminosalicylic acid (5-ASA) formulations, prednisone, immunomodulators such as azathioprine (given as the prodrug for 6-mercaptopurine), methotrexate, and anti-TNF therapies and monoclonal antibodies, such as infliximab, adalimumab, certolizumab, vedolizumab, ustekinumab, and natalizumab. Hydrocortisone should be used in severe attacks of Crohn\'s disease. Biological therapies are medications used to avoid long-term steroid use, decrease inflammation, and treat people who have fistulas with abscesses. The monoclonal antibody ustekinumab appears to be a safe treatment option, and may help people with moderate to severe active Crohn\'s disease. The long term safety and effectiveness of monoclonal antibody treatment is not known. The monoclonal antibody briakinumab is not effective for people with active Crohn\'s disease and it is no longer being manufactured.The gradual loss of blood from the gastrointestinal tract, as well as chronic inflammation, often leads to anemia, and professional guidelines suggest routinely monitoring for this. Adequate disease control usually improves anemia of chronic disease, but iron deficiency may require treatment with iron supplements. Guidelines vary as to how iron should be administered. Besides, other problems include a limitation in possible daily resorption and an increased growth of intestinal bacteria. Some advise parenteral iron as first line as it works faster, has fewer gastrointestinal side effects, and is unaffected by inflammation reducing enteral absorption.","Crohn's disease is a disease that causes the intestines to become swollen. It is a type of inflammatory bowel disease (IBD). The intestines may also develop ulcers. People with Crohn's disease often have pain in the stomach, diarrhea, vomiting, and weight loss. Crohn's can also cause skin rashes, arthritis, and swollen eyes. It is named after Burrill Bernard Crohn, who described cases in 1932. It was first described by Giovanni Battista Morgagni (1682–1771) in the 18th century. Nobody knows exactly what causes Crohn's disease. In the disease, the person's body attacks itself. The immune system attacks healthy parts of the digestive tract. This causes swelling in the digestive tract. Though Crohn's is an immune-related disease, it is not an autoimmune disease (the immune system is not triggered by the body itself). The exact underlying immune problem is not clear. Crohn's disease seems to be connected to the person's genes. People whose brothers or sisters have the disease are the most likely to get it. Men and women can both be affected by Crohn's disease. Managing Crohn's disease includes both lifestyle changes and various kind of medication. It is a chronic condition for which there is no cure. Certain parasitic intestinal worms appear to make the bowel less inflamed. It is supposed that the worms modify the immune reactions in the parts of the intestine where they live. Alternative medicine of various kinds has been tried, with uncertain results.  References   Other websites  Crohn's disease information and tools for patients Archived 2015-05-22 at the Wayback Machine Crohn's disease facts from the National Institutes of Health Archived 2014-06-09 at the Wayback Machine Crohns Disease Resource Site Archived 2006-04-24 at the Wayback Machine"
"Type 1 diabetes (T1D), formerly known as juvenile diabetes, is an autoimmune disease that originates when cells that make insulin (beta cells) are destroyed by the immune system. Insulin is a hormone required for the cells to use blood sugar for energy and it helps regulate glucose levels in the bloodstream. Before treatment this results in high blood sugar levels in the body. The common symptoms of this elevated blood sugar are frequent urination, increased thirst, increased hunger, weight loss, and other serious complications. Additional symptoms may include blurry vision, tiredness, and slow wound healing. Symptoms typically develop over a short period of time, often a matter of weeks.The cause of type 1 diabetes is unknown, but it is believed to involve a combination of genetic and environmental factors. The underlying mechanism involves an autoimmune destruction of the insulin-producing beta cells in the pancreas. Diabetes is diagnosed by testing the level of sugar or glycated hemoglobin (HbA1C) in the blood. Type 1 diabetes can be distinguished from type 2 by testing for the presence of autoantibodies.There is no known way to prevent type 1 diabetes. Treatment with insulin is required for survival. Insulin therapy is usually given by injection just under the skin but can also be delivered by an insulin pump. A diabetic diet and exercise are important parts of management. If left untreated, diabetes can cause many complications. Complications of relatively rapid onset include diabetic ketoacidosis and nonketotic hyperosmolar coma. Long-term complications include heart disease, stroke, kidney failure, foot ulcers and damage to the eyes. Furthermore, since insulin lowers blood sugar levels, complications may arise from low blood sugar if more insulin is taken than necessary.Type 1 diabetes makes up an estimated 5–10% of all diabetes cases. The number of people affected globally is unknown, although it is estimated that about 80,000 children develop the disease each year. Within the United States the number of people affected is estimated at one to three million. Rates of disease vary widely, with approximately one new case per 100,000 per year in East Asia and Latin America and around 30 new cases per 100,000 per year in Scandinavia and Kuwait. It typically begins in children and young adults.  Signs and symptoms  Type 1 diabetes begins suddenly, typically in childhood or adolescence. The major sign of type 1 diabetes is very high blood sugar, which typically manifests in children as a few days to weeks of polyuria (increased urination), polydipsia (increased thirst), and weight loss. Children may also experience increased appetite, blurred vision, bedwetting, recurrent skin infections, candidiasis of the perineum, irritability, and performance issues at school. Adults with type 1 diabetes tend to have more varied symptoms that come on over months rather than days to weeks.Prolonged lack of insulin can also result in diabetic ketoacidosis, characterized by persistent fatigue, dry or flushed skin, abdominal pain, nausea or vomiting, confusion, trouble breathing, and a fruity breath odor. Blood and urine tests reveal unusually high glucose and ketones in the blood and urine. Untreated ketoacidosis can rapidly progress to loss of consciousness, coma, and death. The percentage of children whose type 1 diabetes begins with an episode of diabetic ketoacidosis varies widely by geography, as low as 15% in parts of Europe and North America, and as high as 80% in the developing world.  Cause  Type 1 diabetes is caused by the destruction of β-cells – the only cells in the body that produce insulin – and the consequent progressive insulin deficiency. Without insulin, the body is unable to respond effectively to increases in blood sugar. Due to this, people with diabetes have persistent hyperglycemia. In 70–90% of cases, β-cells are destroyed by someone's own immune system, for reasons that are not entirely clear. The best-studied components of this autoimmune response are β-cell-targeted antibodies that begin to develop in the months or years before symptoms arise. Typically someone will first develop antibodies against insulin or the protein GAD65, followed eventually by antibodies against the proteins IA-2, IA-2β, and/or ZNT8. People with more of these antibodies, and who develop them earlier in life, are at higher risk for developing symptomatic type 1 diabetes. The trigger for the development of these antibodies remains unclear. A number of explanatory theories have been put forward, and the cause may involve genetic susceptibility, a diabetogenic trigger, and/or exposure to an antigen. The remaining 10–30% of type 1 diabetics have β-cell destruction but no sign of autoimmunity; this is called idiopathic type 1 diabetes and its cause is unknown.  Environmental  Various environmental risks have been studied in an attempt to understand what triggers β-cell autoimmunity. Many aspects of environment and life history are associated with slight increases in type 1 diabetes risk, however the connection between each risk and diabetes often remains unclear. Type 1 diabetes risk is slightly higher for children whose mothers are obese or older than 35, or for children born by caesarean section. Similarly, a child's weight gain in the first year of life, total weight, and BMI are associated with slightly increased type 1 diabetes risk. Some dietary habits have also been associated with type 1 diabetes risk, namely consumption of cow's milk and dietary sugar intake. Animal studies and some large human studies have found small associations between type 1 diabetes risk and intake of gluten or dietary fiber; however, other large human studies have found no such association. Many potential environmental triggers have been investigated in large human studies and found to be unassociated with type 1 diabetes risk including duration of breastfeeding, time of introduction of cow milk into the diet, vitamin D consumption, blood levels of active vitamin D, and maternal intake of omega-3 fatty acids.A longstanding hypothesis for an environmental trigger is that some viral infection early in life contributes to type 1 diabetes development. Much of this work has focused on enteroviruses, with some studies finding slight associations with type 1 diabetes, and others finding none. Large human studies have searched for, but not yet found an association between type 1 diabetes and various other viral infections, including infections of the mother during pregnancy. Conversely, some have postulated that reduced exposure to pathogens in the developed world increases the risk of autoimmune diseases, often called the hygiene hypothesis. Various studies of hygiene-related factors – including household crowding, daycare attendance, population density, childhood vaccinations, antihelminth medication, and antibiotic usage during early life or pregnancy – show no association with type 1 diabetes.  Genetics  Type 1 diabetes is partially caused by genetics, and family members of type 1 diabetics have a higher risk of developing the disease themselves. In the general population, the risk of developing type 1 diabetes is around 1 in 250. For someone whose parent has type 1 diabetes, the risk rises to 1–9%. If a sibling has type 1 diabetes, the risk is 6–7%. If someone's identical twin has type 1 diabetes, they have a 30–70% risk of developing it themselves.About half of the disease's heritability is due to variations in three HLA class II genes involved in antigen presentation: HLA-DRB1, HLA-DQA1, and HLA-DQB1. The variation patterns associated with increased risk of type 1 diabetes are called HLA-DR3 and HLA-DR4-HLA-DQ8, and are common in people of European descent. A pattern associated with reduced risk of type 1 diabetes is called HLA-DR15-HLA-DQ6. Large genome-wide association studies have identified dozens of other genes associated with type 1 diabetes risk, mostly genes involved in the immune system.  Chemicals and drugs  Some medicines can reduce insulin production or damage β cells, resulting in disease that resembles type 1 diabetes. The antiviral drug didanosine triggers pancreas inflammation in 5 to 10% of those who take it, sometimes causing lasting β-cell damage. Similarly, up to 5% of those who take the anti-protozoal drug pentamidine experience β-cell destruction and diabetes. Several other drugs cause diabetes by reversibly reducing insulin secretion, namely statins (which may also damage β cells), the post-transplant immunosuppressants cyclosporin A and tacrolimus, the leukemia drug L-asparaginase, and the antibiotic gatifloxicin. Pyrinuron (Vacor), a rodenticide introduced in the United States in 1976, selectively destroys pancreatic beta cells, resulting in type 1 diabetes after accidental poisoning. Pyrinuron was withdrawn from the U.S. market in 1979. Cancer Immunotherapy Drugs have also destroyed pancreatic beta cells, such as Opdivo among others.  Diagnosis  Diabetes is typically diagnosed by a blood test showing unusually high blood sugar. The World Health Organization defines diabetes as blood sugar levels at or above 7.0 mmol/L (126 mg/dL) after fasting for at least eight hours, or a glucose level at or above 11.1 mmol/L (200 mg/dL) two hours after an oral glucose tolerance test. The American Diabetes Association additionally recommends a diagnosis of diabetes for anyone with symptoms of hyperglycemia and blood sugar at any time at or above 11.1 mmol/L, or glycated hemoglobin (hemoglobin A1C) levels at or above 48 mmol/mol.Once a diagnosis of diabetes is established, type 1 diabetes is distinguished from other types by a blood test for the presence of autoantibodies that target various components of the beta cell. The most commonly available tests detect antibodies against glutamic acid decarboxylase, the beta cell cytoplasm, or insulin, each of which are targeted by antibodies in around 80% of type 1 diabetics. Some healthcare providers also have access to tests for antibodies targeting the beta cell proteins IA-2 and ZnT8; these antibodies are present in around 58% and 80% of type 1 diabetics respectively. Some also test for C-peptide, a byproduct of insulin synthesis. Very low C-peptide levels are suggestive of type 1 diabetes.  Management  The mainstay of type 1 diabetes treatment is the regular injection of insulin to manage hyperglycemia. Injections of insulin – via subcutaneous injection using either a syringe or an insulin pump – are necessary multiple times per day, adjusting dosages to account for food intake, blood glucose levels and physical activity. The goal of treatment is to maintain blood sugar in a normal range – 80–130 mg/dL before a meal; <180 mg/dL after – as often as possible. To achieve this, people with diabetes often monitor their blood glucose levels at home. Around 83% of type 1 diabetics monitor their blood glucose by capillary blood testing – pricking the finger to draw a drop of blood, and determining blood glucose with a glucose meter. The American Diabetes Association recommends testing blood glucose around 6–10 times per day: before each meal, before exercise, at bedtime, occasionally after a meal, and any time someone feels the symptoms of hypoglycemia. Around 17% of people with type 1 diabetes use a continuous glucose monitor, a device with a sensor under the skin that constantly measures glucose levels and communicates those levels to an external device. Continuous glucose monitoring is associated with better blood sugar control than capillary blood testing alone; however, continuous glucose monitoring tends to be substantially more expensive. Healthcare providers can also monitor someone's hemoglobin A1C levels which reflect the average blood sugar over the last three months. The American Diabetes Association recommends a goal of keeping hemoglobin A1C levels under 7% for most adults and 7.5% for children.The goal of insulin therapy is to mimic normal pancreatic insulin secretion: low levels of insulin constantly present to support basic metabolism, plus the two-phase secretion of additional insulin in response to high blood sugar – an initial spike in secreted insulin, then an extended phase with continued insulin secretion. This is accomplished by combining different insulin preparations that act with differing speeds and durations. The standard of care for type 1 diabetes is a bolus of rapid-acting insulin 10–15 minutes before each meal or snacks, and as-needed to correct hyperglycemia. In addition, constant low levels of insulin are achieved with one or two daily doses of long-acting insulin, or by steady infusion of low insulin levels by an insulin pump. The exact dose of insulin appropriate for each injection depends on the content of the meal/snack, and the individual person's sensitivity to insulin, and is therefore typically calculated by the individual with diabetes or a family member by hand or assistive device (calculator, chart, mobile app, etc.). People unable to manage these intensive insulin regimens are sometimes prescribed alternate plans relying on mixtures of rapid- or short-acting and intermediate-acting insulin, which are administered at fixed times along with meals of pre-planned times and carbohydrate composition.A non-insulin medication approved by the U.S. Food and Drug Administration for treating type 1 diabetes is the amylin analog pramlintide, which replaces the beta-cell hormone amylin. Addition of pramlintide to mealtime insulin injections reduces the boost in blood sugar after a meal, improving blood sugar control. Occasionally, metformin, GLP-1 receptor agonists, Dipeptidyl peptidase-4 inhibitors, or SGLT2 inhibitor are prescribed off-label to people with type 1 diabetes, although fewer than 5% of type 1 diabetics use these drugs.  Lifestyle  Besides insulin, the major way type 1 diabetics control their blood sugar is by learning how various foods impact their blood sugar levels. This is primarily done by tracking their intake of carbohydrates – the type of food with the greatest impact on blood sugar. In general, people with type 1 diabetes are advised to follow an individualized eating plan rather than a pre-decided one. There are camps for children to teach them how and when to use or monitor their insulin without parental help. As psychological stress may have a negative effect on diabetes, a number of measures have been recommended including: exercising, taking up a new hobby, or joining a charity, among others.Regular exercise is important for maintaining general health, though the effect of exercise on blood sugar can be challenging to predict. Exogenous insulin can drive down blood sugar, leaving those with diabetes at risk of hypoglycemia during and immediately after exercise, then again seven to eleven hours after exercise (called the ""lag effect""). Conversely, high-intensity exercise can result in a shortage of insulin, and consequent hyperglycemia. The risk of hypoglycemia can be managed by beginning exercise when blood sugar is relatively high (above 100 mg/dL), ingesting carbohydrates during or shortly after exercise, and reducing the amount of injected insulin within two hours of the planned exercise. Similarly, the risk of exercise-induced hyperglycemia can be managed by avoiding exercise when insulin levels are very low, when blood sugar is extremely high (above 350 mg/dL), or when one feels unwell.  Transplant  In some cases, people can receive transplants of the pancreas or isolated islet cells to restore insulin production and alleviate diabetic symptoms. Transplantation of the whole pancreas is rare, due in part to the few available donor organs, and to the need for lifelong immunosuppressive therapy to prevent transplant rejection. The American Diabetes Association recommends pancreas transplant only in people who also require a kidney transplant, or who struggle to perform regular insulin therapy and experience repeated severe side effects of poor blood sugar control. Most pancreas transplants are done simultaneously with a kidney transplant, with both organs from the same donor. The transplanted pancreas continues to function for at least five years in around three quarters of recipients, allowing them to stop taking insulin.Transplantations of islets alone have become increasingly common. Pancreatic islets are isolated from a donor pancreas, then injected into the recipient's portal vein from which they implant onto the recipient's liver. In nearly half of recipients, the islet transplant continues to work well enough that they still don't need exogenous insulin five years after transplantation. If a transplant fails, recipients can receive subsequent injections of islets from additional donors into the portal vein. Like with whole pancreas transplantation, islet transplantation requires lifelong immunosuppression and depends on the limited supply of donor organs; it is therefore similarly limited to people with severe poorly controlled diabetes and those who have had or are scheduled for a kidney transplant.  Pathogenesis  Type 1 diabetes is a result of the destruction of pancreatic beta cells, although what triggers that destruction remains unclear. People with type 1 diabetes tend to have more CD8+ T-cells and B-cells that specifically target islet antigens than those without type 1 diabetes, suggesting a role for the adaptive immune system in beta cell destruction. Type 1 diabetics also tend to have reduced regulatory T cell function, which may exacerbate autoimmunity. Destruction of beta cells results in inflammation of the islet of Langerhans, called insulitis. These inflamed islets tend to contain CD8+ T-cells and – to a lesser extent – CD4+ T cells. Abnormalities in the pancreas or the beta cells themselves may also contribute to beta-cell destruction. The pancreases of people with type 1 diabetes tend to be smaller, lighter, and have abnormal blood vessels, nerve innervations, and extracellular matrix organization. In addition, beta cells from people with type 1 diabetes sometimes overexpress HLA class I molecules (responsible for signaling to the immune system) and have increased endoplasmic reticulum stress and issues with synthesizing and folding new proteins, any of which could contribute to their demise.The mechanism by which the beta cells actually die likely involves both necroptosis and apoptosis induced or exacerbated by CD8+ T-cells and macrophages. Necroptosis can be triggered by activated T cells – which secrete toxic granzymes and perforin – or indirectly as a result of reduced blood flow or the generation of reactive oxygen species. As some beta cells die, they may release cellular components that amplify the immune response, exacerbating inflammation and cell death. Pancreases from people with type 1 diabetes also have signs of beta cell apoptosis, linked to activation of the janus kinase and TYK2 pathways.Partial ablation of beta-cell function is enough to cause diabetes; at diagnosis, people with type 1 diabetes often still have detectable beta-cell function. Once insulin therapy is started, many people experience a resurgence in beta-cell function, and can go some time with little-to-no insulin treatment – called the ""honeymoon phase"". This eventually fades as beta-cells continue to be destroyed, and insulin treatment is required again. Beta-cell destruction is not always complete, as 30–80% of type 1 diabetics produce small amounts of insulin years or decades after diagnosis.  Alpha cell dysfunction  Onset of autoimmune diabetes is accompanied by impaired ability to regulate the hormone glucagon, which acts in antagonism with insulin to regulate blood sugar and metabolism. Progressive beta cell destruction leads to dysfunction in the neighboring alpha cells which secrete glucagon, exacerbating excursions away from euglycemia in both directions; overproduction of glucagon after meals causes sharper hyperglycemia, and failure to stimulate glucagon upon hypoglycemia prevents a glucagon-mediated rescue of glucose levels.  Hyperglucagonemia  Onset of type 1 diabetes is followed by an increase in glucagon secretion after meals. Increases have been measured up to 37% during the first year of diagnosis, while c-peptide levels (indicative of islet-derived insulin), decline by up to 45%. Insulin production will continue to fall as the immune system destroys beta cells, and islet-derived insulin will continue to be replaced by therapeutic exogenous insulin. Simultaneously, there is measurable alpha cell hypertrophy and hyperplasia in the early stage of the disease, leading to expanded alpha cell mass. This, together with failing beta cell insulin secretion, begins to account for rising glucagon levels that contribute to hyperglycemia. Some researchers believe glucagon dysregulation to be the primary cause of early stage hyperglycemia. Leading hypotheses for the cause of postprandial hyperglucagonemia suggest that exogenous insulin therapy is inadequate to replace the lost intraislet signalling to alpha cells previously mediated by beta cell-derived pulsatile insulin secretion. Under this working hypothesis intensive insulin therapy has attempted to mimic natural insulin secretion profiles in exogenous insulin infusion therapies.  Hypoglycemic glucagon impairment  Glucagon secretion is normally increased upon falling glucose levels, but normal glucagon response to hypoglycemia is blunted in type 1 diabetics. Beta cell glucose sensing and subsequent suppression of administered insulin secretion is absent, leading to islet hyperinsulinemia which inhibits glucagon release.Autonomic inputs to alpha cells are much more important for glucagon stimulation in the moderate to severe ranges of hypoglycemia, yet the autonomic response is blunted in a number of ways. Recurrent hypoglycemia leads to metabolic adjustments in the glucose sensing areas of the brain, shifting the threshold for counter regulatory activation of the sympathetic nervous system to lower glucose concentration. This is known as hypoglycemic unawareness. Subsequent hypoglycemia is met with impairment in sending of counter regulatory signals to the islets and adrenal cortex. This accounts for the lack of glucagon stimulation and epinephrine release that would normally stimulate and enhance glucose release and production from the liver, rescuing the diabetic from severe hypoglycemia, coma, and death. Numerous hypotheses have been produced in the search for a cellular mechanism of hypoglycemic unawareness, and a consensus has yet to be reached. The major hypotheses are summarized in the following table: In addition, autoimmune diabetes is characterized by a loss of islet specific sympathetic innervation. This loss constitutes an 80–90% reduction of islet sympathetic nerve endings, happens early in the progression of the disease, and is persistent though the life of the patient. It is linked to the autoimmune aspect of type 1 diabetics and fails to occur in type 2 diabetics. Early in the autoimmune event, the axon pruning is activated in islet sympathetic nerves. Increased BDNF and ROS that result from insulitis and beta cell death stimulate the p75 neurotrophin receptor (p75NTR), which acts to prune off axons. Axons are normally protected from pruning by activation of tropomyosin receptor kinase A (Trk A) receptors by NGF, which in islets is primarily produced by beta cells. Progressive autoimmune beta cell destruction, therefore, causes both the activation of pruning factors and the loss of protective factors to the islet sympathetic nerves. This unique form of neuropathy is a hallmark of type 1 diabetes, and plays a part in the loss of glucagon rescue of severe hypoglycemia.  Complications  The most pressing complication of type 1 diabetes are the always present risks of poor blood sugar control: severe hypoglycemia and diabetic ketoacidosis. Hypoglycemia – typically blood sugar below 70 mg/dL – triggers the release of epinephrine, and can cause people to feel shaky, anxious, or irritable. People with hypoglycemia may also experience hunger, nausea, sweats, chills, dizziness, and a fast heartbeat. Some feel lightheaded, sleepy, or weak. Severe hypoglycemia can develop rapidly, causing confusion, coordination problems, loss of consciousness, and seizure. On average, people with type 1 diabetes experience a hypoglycemia event that requires assistance of another 16–20 times in 100 person-years, and an event leading to unconsciousness or seizure 2–8 times per 100 person-years. The American Diabetes Association recommends treating hypoglycemia by the ""15-15 rule"": eat 15 grams of carbohydrates, then wait 15 minutes before checking blood sugar; repeat until blood sugar is at least 70 mg/dL. Severe hypoglycemia that impairs someone's ability to eat is typically treated with injectable glucagon, which triggers glucose release from the liver into the bloodstream. People with repeated bouts of hypoglycemia can develop hypoglycemia unawareness, where the blood sugar threshold at which they experience symptoms of hypoglycemia decreases, increasing their risk of severe hypoglycemic events. Rates of severe hypoglycemia have generally declined due to the advent of rapid-acting and long-acting insulin products in the 1990s and early 2000s; however, acute hypoglycemic still causes 4–10% of type 1 diabetes-related deaths.The other persistent risk is diabetic ketoacidosis – a state where lack of insulin results in cells burning fat rather than sugar, producing toxic ketones as a byproduct. Ketoacidosis symptoms can develop rapidly, with frequent urination, excessive thirst, nausea, vomiting, and severe abdominal pain all common. More severe ketoacidosis can result in labored breathing, and loss of consciousness due to cerebral edema. People with type 1 diabetes experience diabetic ketoacidosis 1–5 times per 100 person-years, the majority of which result in hospitalization. 13–19% of type 1 diabetes-related deaths are caused by ketoacidosis, making ketoacidosis the leading cause of death in people with type 1 diabetes less than 58 years old.  Long-term complications  In addition to the acute complications of diabetes, long-term hyperglycemia results in damage to the small blood vessels throughout the body. This damage tends to manifest particularly in the eyes, nerves, and kidneys causing diabetic retinopathy, diabetic neuropathy, and diabetic nephropathy respectively. In the eyes, prolonged high blood sugar causes the blood vessels in the retina to become fragile.People with type 1 diabetes also have increased risk of cardiovascular disease, which is estimated to shorten the life of the average type 1 diabetic by 8–13 years. Cardiovascular disease as well as neuropathy may have an autoimmune basis, as well. Women with type 1 DM have a 40% higher risk of death as compared to men with type 1 DM.About 12 percent of people with type 1 diabetes have clinical depression. About 6 percent of people with type 1 diabetes also have celiac disease, but in most cases there are no digestive symptoms or are mistakenly attributed to poor control of diabetes, gastroparesis or diabetic neuropathy. In most cases, celiac disease is diagnosed after onset of type 1 diabetes. The association of celiac disease with type 1 diabetes increases the risk of complications, such as retinopathy and mortality. This association can be explained by shared genetic factors, and inflammation or nutritional deficiencies caused by untreated celiac disease, even if type 1 diabetes is diagnosed first.  Urinary tract infection  People with diabetes show an increased rate of urinary tract infection. The reason is bladder dysfunction is more common in people with diabetes than people without diabetes due to diabetes nephropathy. When present, nephropathy can cause a decrease in bladder sensation, which in turn, can cause increased residual urine, a risk factor for urinary tract infections.  Sexual dysfunction  Sexual dysfunction in people with diabetes is often a result of physical factors such as nerve damage and poor circulation, and psychological factors such as stress and/or depression caused by the demands of the disease. The most common sexual issues in males with diabetes are problems with erections and ejaculation: ""With diabetes, blood vessels supplying the penis's erectile tissue can get hard and narrow, preventing the adequate blood supply needed for a firm erection. The nerve damage caused by poor blood glucose control can also cause ejaculate to go into the bladder instead of through the penis during ejaculation, called retrograde ejaculation. When this happens, semen leaves the body in the urine."" Another cause of erectile dysfunction is reactive oxygen species created as a result of the disease. Antioxidants can be used to help combat this. Sexual problems are common in women who have diabetes, including reduced sensation in the genitals, dryness, difficulty/inability to orgasm, pain during sex, and decreased libido. Diabetes sometimes decreases estrogen levels in females, which can affect vaginal lubrication. Less is known about the correlation between diabetes and sexual dysfunction in females than in males.Oral contraceptive pills can cause blood sugar imbalances in women who have diabetes. Dosage changes can help address that, at the risk of side effects and complications.Women with type 1 diabetes show a higher than normal rate of polycystic ovarian syndrome (PCOS). The reason may be that the ovaries are exposed to high insulin concentrations since women with type 1 diabetes can have frequent hyperglycemia.  Autoimmune disorders  People with type 1 diabetes are at an increased risk for developing several autoimmune disorders, particularly thyroid problems – around 20% of people with type 1 diabetes have hypothyroidism or hyperthyroidism, typically caused by Hashimoto thyroiditis or Graves' disease respectiveley. Celiac disease affects 2–8% of people with type 1 diabetes, and is more common in those who were younger at diabetes diagnosis, and in white people. Type 1 diabetics are also at increased risk of rheumatoid arthritis, lupus, autoimmune gastritis, pernicious anemia, vitiligo, and Addison's disease. Conversely, complex autoimmune syndromes caused by mutations in the immunity-related genes AIRE (causing autoimmune polyglandular syndrome), FoxP3 (causing IPEX syndrome), or STAT3 include type 1 diabetes in their effects.  Prevention  There is no way to prevent type 1 diabetes; however, the development of diabetes symptoms can be delayed in some people who are at high risk of developing the disease. In 2022 the FDA approved an intravenous injection of teplizumab to delay the progression of type 1 diabetes in those older than eight who have already developed diabetes-related autoantibodies and problems with blood sugar control. In that population, the anti-CD3 monoclonal antibody teplizumab can delay the development of type 1 diabetes symptoms by around two years.In addition to anti-CD3 antibodies, several other immunosuppressive agents have been trialled with the aim of preventing beta cell destruction. Large trials of cyclosporine treatment suggested that cyclosporine could improve insulin secretion in those recently diagnosed with type 1 diabetes; however, people who stopped taking cyclosporine rapidly stopped making insulin, and cyclosporine's kidney toxicity and increased risk of cancer prevented people from using it long-term. Several other immunosuppressive agents – prednisone, azathioprine, anti-thymocyte globulin, mycophenolate, and antibodies against CD20 and IL2 receptor α – have been the subject of research, but none have provided lasting protection from development of type 1 diabetes. There have also been clinical trials attempting to induce immune tolerance by vaccination with insulin, GAD65, and various short peptides targeted by immune cells during type 1 diabetes; none have yet delayed or prevented development of disease.Several trials have attempted dietary interventions with the hope of reducing the autoimmunity that leads to type 1 diabetes. Trials that withheld cow's milk or gave infants formula free of bovine insulin decreased the development of β-cell-targeted antibodies, but did not prevent the development of type 1 diabetes. Similarly, trials that gave high-risk individuals injected insulin, oral insulin, or nicotinamide did not prevent diabetes development.  Epidemiology  Type 1 diabetes makes up an estimated 10–15% of all diabetes cases or 11–22 million cases worldwide. Symptoms can begin at any age, but onset is most common in children, with diagnoses slightly more common in 5 to 7 year olds, and much more common around the age of puberty. In contrast to most autoimmune diseases, type 1 diabetes is slightly more common in males than in females.In 2006, type 1 diabetes affected 440,000 children under 14 years of age and was the primary cause of diabetes in those less than 15 years of age.Rates vary widely by country and region. Incidence is highest in Scandinavia, at 30–60 new cases per 100,000 children per year, intermediate in the U.S. and Southern Europe at 10–20 cases per 100,000 per year, and lowest in China, much of Asia, and South America at 1–3 cases per 100,000 per year.In the United States, type 1 and 2 diabetes affected about 208,000 youths under the age of 20 in 2015. Over 18,000 youths are diagnosed with Type 1 diabetes every year. Every year about 234,051 Americans die due to diabetes (type I or II) or diabetes-related complications, with 69,071 having it as the primary cause of death.In Australia, about one million people have been diagnosed with diabetes and of this figure 130,000 people have been diagnosed with type 1 diabetes. Australia ranks 6th-highest in the world with children under 14 years of age. Between 2000 and 2013, 31,895 new cases were established, with 2,323 in 2013, a rate of 10–13 cases per 100,00 people each year. Aboriginals and Torres Strait Islander people are less affected.Since the 1950s, the incidence of type 1 diabetes has been gradually increasing across the world by an average 3–4% per year. The increase is more pronounced in countries that began with a lower incidence of type 1 diabetes.  History  The connection between diabetes and pancreatic damage was first described by the German pathologist Martin Schmidt, who in a 1902 paper noted inflammation around the pancreatic islet of a child who had died of diabetes. The connection between this inflammation and diabetes onset was further developed through the 1920s by Shields Warren, and the term ""insulitis"" was coined by Hanns von Meyenburg in 1940 to describe the phenomenon.Type 1 diabetes was described as an autoimmune disease in the 1970s, based on observations that autoantibodies against islets were discovered in diabetics with other autoimmune deficiencies. It was also shown in the 1980s that immunosuppressive therapies could slow disease progression, further supporting the idea that type 1 diabetes is an autoimmune disorder. The name juvenile diabetes was used earlier as it often first is diagnosed in childhood.  Society and culture  Type 1 and 2 diabetes was estimated to cause $10.5 billion in annual medical costs ($875 per month per diabetic) and an additional $4.4 billion in indirect costs ($366 per month per person with diabetes) in the U.S. In the United States $245 billion every year is attributed to diabetes. Individuals diagnosed with diabetes have 2.3 times the health care costs as individuals who do not have diabetes. One in ten health care dollars are spent on individuals with type 1 and 2 diabetes.  Research  Funding for research into type 1 diabetes originates from government, industry (e.g., pharmaceutical companies), and charitable organizations. Government funding in the United States is distributed via the National Institutes of Health, and in the UK via the National Institute for Health and Care Research or the Medical Research Council. The Juvenile Diabetes Research Foundation (JDRF), founded by parents of children with type 1 diabetes, is the world's largest provider of charity-based funding for type 1 diabetes research. Other charities include the American Diabetes Association, Diabetes UK, Diabetes Research and Wellness Foundation, Diabetes Australia, the Canadian Diabetes Association.  Organ replacement  Pluripotent stem cells can be used to generate beta cells but previously these cells did not function as well as normal beta cells. In 2014 more mature beta cells were produced which released insulin in response to blood sugar when transplanted into mice. Before these techniques can be used in humans more evidence of safety and effectiveness is needed.There has also been substantial effort to develop a fully automated insulin delivery system or ""artificial pancreas"" that could sense glucose levels and inject appropriate insulin without conscious input from the user. Current ""hybrid closed-loop systems"" use a continuous glucose monitor to sense blood sugar levels, and a subcutaneous insulin pump to deliver insulin; however, due to the delay between insulin injection and its action, current systems require the user to initiate insulin before taking meals. Several improvements to these systems are currently undergoing clinical trials in humans, including a dual-hormone system that injects glucagon in addition to insulin, and an implantable device that injects insulin intraperitoneally where it can be absorbed more quickly.  Disease models  Various animal models of disease are used to understand the pathogenesis and etiology of type 1 diabetes. Currently available models of T1D can be divided into spontaneously autoimmune, chemically induced, virus induced and genetically induced.The nonobese diabetic (NOD) mouse is the most widely studied model of type 1 diabetes. It is an inbred strain that spontaneously develops type 1 diabetes in 30–100% of female mice depending on housing conditions. Diabetes in NOD mice is caused by several genes, primarily MHC genes involved in antigen presentation. Like diabetic humans, NOD mice develop islet autoantibodies and inflammation in the islet, followed by reduced insulin production and hyperglycemia. Some features of human diabetes are exaggerated in NOD mice, namely the mice have more severe islet inflammation than humans, and have a much more pronounced sex bias, with females developing diabetes far more frequently than males. In NOD mice the onset of insulitis occurs at 3–4 weeks of age. The islets of Langerhans are infiltrated by CD4+, CD8+ T lymphocytes, NK cells, B lymphocytes, dendritic cells, macrophages and neutrophils, similar to the disease process in humans. In addition to sex, breeding conditions, gut microbiome composition or diet also influence the onset of T1D.The BioBreeding Diabetes-Prone (BB) rat is another widely used spontaneous experimental model for T1D. The onset of diabetes occurs, in up to 90% of individuals (regardless of sex) at 8–16 weeks of age. During insulitis, the pancreatic islets are infiltrated by T lymphocytes, B lymphocytes, macrophages, and NK cells, with the difference from the human course of insulitis being that CD4 + T lymphocytes are markedly reduced and CD8 + T lymphocytes are almost absent. The aforementioned lymphopenia is the major drawback of this model. The disease is characterized by hyperglycemia, hypoinsulinemia, weight loss, ketonuria, and the need for insulin therapy for survival. BB Rats are used to study the genetic aspects of T1D and are also used for interventional studies and diabetic nephropathy studies.LEW-1AR1 / -iddm rats are derived from congenital Lewis rats and represent a rarer spontaneous model for T1D. These rats develop diabetes at about 8–9 weeks of age with no sex differences unlike NOD mice. In LEW mice, diabetes presents with hyperglycemia, glycosuria, ketonuria, and polyuria. The advantage of the model is the progression of the prediabetic phase, which is very similar to human disease, with infiltration of islet by immune cells about a week before hyperglycemia is observed. This model is suitable for intervention studies or for the search for predictive biomarkers. It is also possible to observe individual phases of pancreatic infiltration by immune cells. The advantage of congenic LEW mice is also the good viability after the manifestation of T1D (compared to NOD mice and BB rats).  Chemically induced  The chemical compounds aloxan and streptozotocin (STZ) are commonly used to induce diabetes and destroy β-cells in mouse/rat animal models. In both cases, it is a cytotoxic analog of glucose that passes GLUT2 transport and accumulates in β-cells, causing their destruction. The chemically induced destruction of β-cells leads to decreased insulin production, hyperglycemia and weight loss in the experimental animal. The animal models prepared in this way are suitable for research into blood sugar-lowering drugs and therapies (e.g. for testing new insulin preparations). They are also the most commonly used genetically induced T1D model is the so-called AKITA mouse (originally C57BL/6NSIc mouse). The development of diabetes in AKITA mice is caused by a spontaneous point mutation in the Ins2 gene, which is responsible for the correct composition of insulin in the endoplasmic reticulum. Decreased insulin production is then associated with hyperglycemia, polydipsia and polyuria. If severe diabetes develops within 3–4 weeks, AKITA mice survive no longer than 12 weeks without treatment intervention. The description of the etiology of the disease shows that, unlike spontaneous models, the early stages of the disease are not accompanied by insulitis. AKITA mice are used to test drugs targeting endoplasmic reticulum stress reduction, to test islet transplants, and to study diabetes-related complications such as nephropathy, sympathetic autonomic neuropathy, and vascular disease. for testing transplantation therapies. Their advantage is mainly the low cost, the disadvantage is the cytotoxicity of the chemical compounds.  Genetically induced   Virally induced  Viral infections play a role in the development of a number of autoimmune diseases, including human type 1 diabetes. However, the mechanisms by which viruses are involved in the induction of type 1 DM are not fully understood. Virus-induced models are used to study the etiology and pathogenesis of the disease, in particular the mechanisms by which environmental factors contribute to or protect against the occurrence of type 1 DM. Among the most commonly used are Coxsackie virus, lymphocytic choriomeningitis virus, encephalomyocarditis virus, and Kilham rat virus. Examples of virus-induced animals include NOD mice infected with coxsackie B4 that developed type 1 DM within two weeks.  References   Works cited   External links  National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) – Diabetes in America Textbook (PDFs) IDF Diabetes Atlas Type 1 Diabetes Archived 30 October 2009 at the Wayback Machine at the American Diabetes Association ADA's Standards of Medical Care in Diabetes 2019","Type 1 diabetes, also called diabetes mellitus type 1, is an autoimmune disease that results in high blood sugar. This is because the body cannot create enough of the hormone insulin. People with type 1 diabetes need to take insulin injections to stay healthy. If they do not get enough insulin, they can become very sick or even die. People with type 1 diabetes are at increased risk of of diseases involing blood vessels such as stroke, heart disease or gangrene. About 15% of people with diabetes have type 1.  Cause  Type 1 diabetes is a condition caused by a lack of insulin in the body. Insulin is a hormone produced by cells in the pancreas. Insulin is responsible for moving sugars out of the blood and into cells to be used by the body for energy. If insulin is not made, the body will search for other ways to get the sugars needed to feed the body's cells, including breaking down muscle and fat, leading to a loss of weight.Insulin is not being produced in the pancreas due to an autoimmune condition attacking its cells. The body's immune system mistakenly attacks the cells responsible for producing insulin in the pancreas, the beta cell. The beta cells are damaged in a way that prevents them from producing more insulin. As more and more of these cells are damaged, less insulin is produced in the body. This means that more sugar remains in the bloodstream rather than being moved into cells. This high blood sugar causes the symptoms seen in type 1 diabetes.The disease is thought to be strongly linked to genetic factors, but the trigger that starts the autoimmune disease is not currently known.  Epidemiology  In the past, type 1 diabetes was generally thought to be a disorder in children and teenagers. However, it's now been found that adults can be diagnosed with the disease.Although type 1 diabetes can now be diagnosed at any age, it is one of the most common chronic conditions in children and young adults. Being diagnosed at ages 5–7 or at the start of puberty is particularly common. Type 1 diabetes is also slightly more common in boys. Cases of type 1 diabetes have been increasing across the world for several decades. Approximately 1 in 300 people are diagnosed with type 1 diabetes by the age of 18 in the United States.  Symptoms  In type 1 diabetes, symptoms generally develop over a few days or weeks, though may take longer in adults. The main symptoms are: Feeling very thirsty Urinating more often than normal Exhaustion Loss of weight Itchiness around the genital area Blurring of sight Slow healing of wounds and grazesNausea, vomiting and heavy breathing are more serious symptoms that occur at a later stage in the disease.  Complications  People with type 1 diabetes may have to deal with both short-term and long-term complications, particularly if the disease is not well managed.  Short-term complications   Hypoglycaemia  Hypoglycaemia is when blood sugar levels decrease to below normal. This is most commonly due to overuse of medications for diabetes type 1 like insulin or from poor diet control. The risk of suffering from low blood sugar is increased by drinking alcohol. This may lead to various other symptoms, including confusion, loss of consciousness, clumsiness, seizures or death.  Diabetic ketoacidosis  Diabetic ketoacidosis (DKA) is a very serious complication of type 1 diabetes. It is a medical emergency and requires rapid medical attention to prevent further damage to a patient, if left untreated it can potentially lead to death. DKA occurs when there is not enough insulin in the body to supply sugars to the body's cells. In order to give its cells enough energy to survive, the body begins to produce acidic ketone bodies which are then used to feed energy to the cells.If too many ketone bodies build up the blood becomes acidic, damaging the body and leading to the symptoms: Vomiting Dehydration Difficult breathing Fast heartbeat Confusion Coma  Long-term complications  If diabetes is not treated, even mildly raised blood sugar levels can damage nerves, organs and blood vessels in the body.  Small blood vessel complications  Diabetic retinopathy, damage to the blood vessels prevent enough blood from reaching the eye. This can lead the eye's retina being damaged, resulting in loss of vision or blindness. Diabetic neuropathy, damage to blood vessels near nerves can result in reduced blood flow. This can damage the nerves, leading to a loss in the sense of touch, normally starting from the hands or feet, before spreading up the body. Diabetic nephropathy, blood vessels in the kidney become damaged, making the kidney work less effectively. In severe cases. this can result in kidney failure. Sexual dysfunction  Large blood vessel complications  Increased risk of heart disease and stroke Narrowing of blood vessels (peripheral arterial disease). Diabetic foot, narrowing of blood vessels reduces sensitivity and slows wound healing in the foot. If not managed appropriately, can lead to ulceration and gangrene in the foot. In very severe cases, amputation may be required.  Management  There is no known cure for diabetes. Instead, treatment is designed to help keep blood sugar levels normal in order to reduce the chances of complications developing as the disease progresses. There are two main method that are combined to manage diabetes type 1:  Lifestyle  Healthy eating: eating a diet focused on fruit and vegetables, whilst limiting fats, salt and sugar helps keep blood sugar levels in check. Exercise: regular physical activity helps to lower your blood sugar level. A good goal to aim for is 150 minutes of exercise a week. Stopping smoking: smoking further increases the risk of heart disease, peripheral arterial disease and stroke. Stopping or reducing smoking will reduce the risk of these complications. Reducing alcohol: alcohol can either raise or lower blood sugar, and makes it difficult to monitor your own blood sugar levels. Drinking less alcohol can reduce these risks.  Insulin injections  Type 1 diabetes occurs due to the bodies inability to produce its own insulin. To counter this, insulin can be injected into the blood manually. When diabetes is first diagnosed, a plan should be made for insulin treatment in order to not under or overdose, which can lead to serious complications. A sufferer should monitor their own blood sugar levels continuously to know whether they need a dose of insulin to lower their blood sugar.There are different kinds of insulin that can be taken: Rapid-acting insulin and short-acting insulin get insulin into the bloodstream very quickly. They are typically taken before a meal to prepare for the rise in blood sugar that follows eating food. Long acting insulin provides insulin in the system for up to 24 hours. It is generally taken once a day  References "
"Immunology is a branch of medicine and biology that covers the medical study of immune systems in all organisms. In such we can see there is a difference of human immunology and comparative immunology in veterinary medicine and animal biosciences.Immunology measures, uses charts and differentiate in context in medicine the studies of immunity on cell and molecular level, and the immune system as part of the physiological level as its functioning is of major importance. In the different states of both health, occurring symptoms and diseases; the functioning of the immune system and immunological responses such as autoimmune diseases, allergic hypersensitivities, or in some cases malfunctioning of immune system as for example in immunological disorders or in immune deficiency, and the specific transplant rejection) Immunology has applications in numerous disciplines of medicine, particularly in the fields of rheumatology, virology, allergology (dermatology), bacteriology, oncology and further transplantation medicine. The term was coined by Russian biologist Ilya Ilyich Mechnikov, who advanced studies on immunology and received the Nobel Prize for his work in 1908. He pinned small thorns into starfish larvae and noticed unusual cells surrounding the thorns. This was the active response of the body trying to maintain its integrity. It was Mechnikov who first observed the phenomenon of phagocytosis, in which the body defends itself against a foreign body. Immunology has importance in reproductive medicine as the physical, chemical, and physiological characteristics of the components of the immune system in vitro, in situ, and in vivo.In psychiatry it is said that psychiatric disorders lead to low levels of immunology but are not encountered any specific characteristics of immunological deficiencies. Prior to the designation of immunity, from the etymological root immunis, which is Latin for 'exempt', early physicians characterized organs that would later be proven as essential components of the immune system. The important lymphoid organs of the immune system are the thymus, bone marrow, and chief lymphatic tissues such as spleen, tonsils, lymph vessels, lymph nodes, adenoids, and liver. However, many components of the immune system are cellular in nature, and not associated with specific organs, but rather embedded or circulating in various tissues located throughout the body.  Classical immunology  Classical immunology ties in with the fields of epidemiology and medicine. It studies the relationship between the body systems, pathogens, and immunity. The earliest written mention of immunity can be traced back to the plague of Athens in 430 BCE. Thucydides noted that people who had recovered from a previous bout of the disease could nurse the sick without contracting the illness a second time. Many other ancient societies have references to this phenomenon, but it was not until the 19th and 20th centuries before the concept developed into scientific theory. The study of the molecular and cellular components that comprise the immune system, including their function and interaction, is the central science of immunology. The immune system has been divided into a more primitive innate immune system and, in vertebrates, an acquired or adaptive immune system. The latter is further divided into humoral (or antibody) and cell-mediated components.The immune system has the capability of self and non-self-recognition. An antigen is a substance that ignites the immune response. The cells involved in recognizing the antigen are Lymphocytes. Once they recognize, they secrete antibodies. Antibodies are proteins that neutralize the disease-causing microorganisms. Antibodies do not directly kill pathogens, but instead, identify antigens as targets for destruction by other immune cells such as phagocytes or NK cells. The (antibody) response is defined as the interaction between antibodies and antigens. Antibodies are specific proteins released from a certain class of immune cells known as B lymphocytes, while antigens are defined as anything that elicits the generation of antibodies (antibody generators). Immunology rests on an understanding of the properties of these two biological entities and the cellular response to both. It is now getting clear that the immune responses contribute to the development of many common disorders not traditionally viewed as immunologic, including metabolic, cardiovascular, cancer, and neurodegenerative conditions like Alzheimer's disease. Besides, there are direct implications of the immune system in the infectious diseases (tuberculosis, malaria, hepatitis, pneumonia, dysentery, and helminth infestations) as well. Hence, research in the field of immunology is of prime importance for the advancements in the fields of modern medicine, biomedical research, and biotechnology. Immunological research continues to become more specialized, pursuing non-classical models of immunity and functions of cells, organs and systems not previously associated with the immune system (Yemeserach 2010).  Diagnostic immunology  The specificity of the bond between antibody and antigen has made the antibody an excellent tool for the detection of substances by a variety of diagnostic techniques. Antibodies specific for a desired antigen can be conjugated with an isotopic (radio) or fluorescent label or with a color-forming enzyme in order to detect it. However, the similarity between some antigens can lead to false positives and other errors in such tests by antibodies cross-reacting with antigens that are not exact matches.  Immunotherapy  The use of immune system components or antigens to treat a disease or disorder is known as immunotherapy. Immunotherapy is most commonly used to treat allergies, autoimmune disorders such as Crohn's disease, Hashimoto's thyroiditis and rheumatoid arthritis, and certain cancers. Immunotherapy is also often used for patients who are immunosuppressed (such as those with HIV) and people with other immune deficiencies. This includes regulating factors such as IL-2, IL-10, GM-CSF B, IFN-α.  Clinical immunology  Clinical immunology is the study of diseases caused by disorders of the immune system (failure, aberrant action, and malignant growth of the cellular elements of the system). It also involves diseases of other systems, where immune reactions play a part in the pathology and clinical features. The diseases caused by disorders of the immune system fall into two broad categories: immunodeficiency, in which parts of the immune system fail to provide an adequate response (examples include chronic granulomatous disease and primary immune diseases); autoimmunity, in which the immune system attacks its own host's body (examples include systemic lupus erythematosus, rheumatoid arthritis, Hashimoto's disease and myasthenia gravis).Other immune system disorders include various hypersensitivities (such as in asthma and other allergies) that respond inappropriately to otherwise harmless compounds. The most well-known disease that affects the immune system itself is AIDS, an immunodeficiency characterized by the suppression of CD4+ (""helper"") T cells, dendritic cells and macrophages by the Human Immunodeficiency Virus (HIV). Clinical immunologists also study ways to prevent the immune system's attempts to destroy allografts (transplant rejection).Clinical Immunology and Allergy is usually a subspecialty of Internal Medicine or Pediatrics. Fellows in Clinical Immunology are typically exposed to many of the different aspects of the specialty and get to treat Allergic conditions, Primary Immunodeficiencies and systemic autoimmune and autoinflammatory conditions. As part of their training fellows may do additional rotations in Rheumatology, Pulmonology, Otorhinolaryngology, Dermatology and the Immunologic lab.  Clinical and pathology immunology  When health conditions worsen to emergency status, portions of immune system organs, including the thymus, spleen, bone marrow, lymph nodes, and other lymphatic tissues, can be surgically excised for examination while patients are still alive.  Theoretical immunology  Immunology is strongly experimental in everyday practice but is also characterized by an ongoing theoretical attitude. Many theories have been suggested in immunology from the end of the nineteenth century up to the present time. The end of the 19th century and the beginning of the 20th century saw a battle between ""cellular"" and ""humoral"" theories of immunity. According to the cellular theory of immunity, represented in particular by Elie Metchnikoff, it was cells – more precisely, phagocytes – that were responsible for immune responses. In contrast, the humoral theory of immunity, held by Robert Koch and Emil von Behring, among others, stated that the active immune agents were soluble components (molecules) found in the organism's ""humors"" rather than its cells.In the mid-1950s, Macfarlane Burnet, inspired by a suggestion made by Niels Jerne, formulated the clonal selection theory (CST) of immunity. On the basis of CST, Burnet developed a theory of how an immune response is triggered according to the self/nonself distinction: ""self"" constituents (constituents of the body) do not trigger destructive immune responses, while ""nonself"" entities (e.g., pathogens, an allograft) trigger a destructive immune response. The theory was later modified to reflect new discoveries regarding histocompatibility or the complex ""two-signal"" activation of T cells. The self/nonself theory of immunity and the self/nonself vocabulary have been criticized, but remain very influential.More recently, several theoretical frameworks have been suggested in immunology, including ""autopoietic"" views, ""cognitive immune"" views, the ""danger model"" (or ""danger theory""), and the ""discontinuity"" theory. The danger model, suggested by Polly Matzinger and colleagues, has been very influential, arousing many comments and discussions.  Developmental immunology  The body's capability to react to antigens depends on a person's age, antigen type, maternal factors and the area where the antigen is presented. Neonates are said to be in a state of physiological immunodeficiency, because both their innate and adaptive immunological responses are greatly suppressed. Once born, a child's immune system responds favorably to protein antigens while not as well to glycoproteins and polysaccharides. In fact, many of the infections acquired by neonates are caused by low virulence organisms like Staphylococcus and Pseudomonas. In neonates, opsonic activity and the ability to activate the complement cascade is very limited. For example, the mean level of C3 in a newborn is approximately 65% of that found in the adult. Phagocytic activity is also greatly impaired in newborns. This is due to lower opsonic activity, as well as diminished up-regulation of integrin and selectin receptors, which limit the ability of neutrophils to interact with adhesion molecules in the endothelium. Their monocytes are slow and have a reduced ATP production, which also limits the newborn's phagocytic activity. Although, the number of total lymphocytes is significantly higher than in adults, the cellular and humoral immunity is also impaired. Antigen-presenting cells in newborns have a reduced capability to activate T cells. Also, T cells of a newborn proliferate poorly and produce very small amounts of cytokines like IL-2, IL-4, IL-5, IL-12, and IFN-g which limits their capacity to activate the humoral response as well as the phagocitic activity of macrophage. B cells develop early during gestation but are not fully active. Maternal factors also play a role in the body's immune response. At birth, most of the immunoglobulin present is maternal IgG. These antibodies are transferred from the placenta to the fetus using the FcRn (neonatal Fc receptor). Because IgM, IgD, IgE and IgA do not cross the placenta, they are almost undetectable at birth. Some IgA is provided by breast milk. These passively-acquired antibodies can protect the newborn for up to 18 months, but their response is usually short-lived and of low affinity. These antibodies can also produce a negative response. If a child is exposed to the antibody for a particular antigen before being exposed to the antigen itself then the child will produce a dampened response. Passively acquired maternal antibodies can suppress the antibody response to active immunization. Similarly, the response of T-cells to vaccination differs in children compared to adults, and vaccines that induce Th1 responses in adults do not readily elicit these same responses in neonates. Between six and nine months after birth, a child's immune system begins to respond more strongly to glycoproteins, but there is usually no marked improvement in their response to polysaccharides until they are at least one year old. This can be the reason for distinct time frames found in vaccination schedules.During adolescence, the human body undergoes various physical, physiological and immunological changes triggered and mediated by hormones, of which the most significant in females is 17-β-estradiol (an estrogen) and, in males, is testosterone. Estradiol usually begins to act around the age of 10 and testosterone some months later. There is evidence that these steroids not only act directly on the primary and secondary sexual characteristics but also have an effect on the development and regulation of the immune system, including an increased risk in developing pubescent and post-pubescent autoimmunity. There is also some evidence that cell surface receptors on B cells and macrophages may detect sex hormones in the system.The female sex hormone 17-β-estradiol has been shown to regulate the level of immunological response, while some male androgens such as testosterone seem to suppress the stress response to infection. Other androgens, however, such as DHEA, increase immune response. As in females, the male sex hormones seem to have more control of the immune system during puberty and post-puberty than during the rest of a male's adult life. Physical changes during puberty such as thymic involution also affect immunological response.  Ecoimmunology and behavioural immunity  Ecoimmunology, or ecological immunology, explores the relationship between the immune system of an organism and its social, biotic and abiotic environment. More recent ecoimmunological research has focused on host pathogen defences traditionally considered ""non-immunological"", such as pathogen avoidance, self-medication, symbiont-mediated defenses, and fecundity trade-offs. Behavioural immunity, a phrase coined by Mark Schaller, specifically refers to psychological pathogen avoidance drivers, such as disgust aroused by stimuli encountered around pathogen-infected individuals, such as the smell of vomit. More broadly, ""behavioural"" ecological immunity has been demonstrated in multiple species. For example, the Monarch butterfly often lays its eggs on certain toxic milkweed species when infected with parasites. These toxins reduce parasite growth in the offspring of the infected Monarch. However, when uninfected Monarch butterflies are forced to feed only on these toxic plants, they suffer a fitness cost as reduced lifespan relative to other uninfected Monarch butterflies. This indicates that laying eggs on toxic plants is a costly behaviour in Monarchs which has probably evolved to reduce the severity of parasite infection.Symbiont-mediated defenses are also heritable across host generations, despite a non-genetic direct basis for the transmission. Aphids, for example, rely on several different symbionts for defense from key parasites, and can vertically transmit their symbionts from parent to offspring. Therefore, a symbiont that successfully confers protection from a parasite is more likely to be passed to the host offspring, allowing coevolution with parasites attacking the host in a way similar to traditional immunity. The preserved immune tissues of extinct species, such as the thylacine (Thylacine cynocephalus) can also provide insights into their biology.  Cancer immunology  The study of the interaction of the immune system with cancer cells can lead to diagnostic tests and therapies with which to find and fight cancer. The immunology concerned with physiological reaction characteristic of the immune state.  Reproductive immunology  This area of the immunology is devoted to the study of immunological aspects of the reproductive process including fetus acceptance. The term has also been used by fertility clinics to address fertility problems, recurrent miscarriages, premature deliveries and dangerous complications such as pre-eclampsia.  See also  List of immunologists Immunomics International Reviews of Immunology Outline of immunology History of immunology Osteoimmunology  References   External links  Media related to Immunology at Wikimedia Commons American Association of Immunologists British Society for Immunology Federation of Clinical Immunology Societies","Immunology is the study of the immune system. The immune system is the parts of the body which work against infection and parasitism by other living things. Immunology deals with the working of the immune system in health and diseases, and with malfunctions of the immune system. An immune system is present in all plants and animals. We know this because biologists have found genes coding for toll-like receptors in many different metazoans. These toll-like receptors can recognise bacteria as 'foreign', and are the starting-point for immune reactions. The type of immunity which is triggered by the toll-like receptors is called innate immunity. This is because it is entirely inherited in our genome, and is fully working as soon as our tissues and organs are properly developed. Vertebrates, and only vertebrates, have a second type of immunity. This is called adaptive immunity, because it 'remembers' previous infections. Then, if the same infection occurs again, the reaction is much stronger and faster. This immunological memory ""confers a tremendous survival advantage"" and with it vertebrates ""can survive over a long lifetime in a pathogen-filled environment"".  Types of immunity in vertebrates   Innate immune response  The innate immune system is usually means all of the cells and systems that does not have to be exposed to a particular pathogen before they can work. Innate immunity starts with the skin, which is an excellent barrier to infection.  Adaptive immune response  The adaptive immune system includes cells and systems that do require previous exposure to a pathogen. It explains the unique ability of the mammalian immune system to remember previous infections and mount a rapid and robust reaction to secondary infections. This immunological memory is due to the biology of T-cells and B-cells.  Other aspects of immunity  Vaccines boost the acquired immune system by offering weak forms of infection that the body can fight off. The system remembers how to do it again when a stronger infection happens. If the vaccine works, the body can then fight off a serious infection. The distribution of vaccines and other immune system affecting cures can be considered another level of acquired immune system, one governed by access to vaccination and medicine in general. The intersection of this with the spread of disease (as studied in epidemiology) is part of the field of public health.  Errors and weaknesses  Errors of the immune system may cause damage. In autoimmune diseases, the body attacks parts of itself because the system mistakes some parts of the body as 'foreign'. Some kinds of arthritis are caused this way. Sometimes serious pathogens slip in because their surface is disguised as something the host cell walls can accept. That is how viruses work. Once inside a cell, their genetic material controls the cell. Infections like HIV get in this way, and then attack cells which are the basis of the immune system. Artificial means are often used to restore immune system function in an HIV-challenged body, and prevent the onset of AIDS. This is one of the most complex issues in immunology as it involves every level of that system. This research during the 1980s and 1990s radically changed the view of the human immune system and its functions and integration in the human body.  History of immunology  Immunology is a science that examines the structure and function of the immune system. It originates from medicine and early studies on the causes of immunity to disease. The earliest known mention of immunity was during the plague of Athens in 430 BC. Thucydides (460–395 BC) noted that people who had recovered from a previous bout of some diseases could nurse the sick without contracting the illness a second time.In the 18th century, Pierre-Louis Moreau de Maupertuis made experiments with scorpion venom and observed that certain dogs and mice were immune to this venom. This and other observations of acquired immunity led to Louis Pasteur (1822–1895) developing vaccination and the germ theory of disease. Pasteur's theory was in direct opposition to contemporary theories of disease, such as the miasma theory. It was not until the proofs Robert Koch (1843–1910) published in 1891 (for which he was awarded a Nobel Prize in 1905) that microorganisms were confirmed as the cause of infectious disease. Viruses were confirmed as human pathogens in 1901, when the yellow fever virus was discovered by Walter Reed (1851–1902).Immunology made a great advance towards the end of the 19th century, through rapid developments, in the study of humoral immunity and cellular immunity. Particularly important was the work of Paul Ehrlich (1854–1915), who proposed the side-chain theory to explain the specificity of the antigen-antibody reaction. The Nobel Prize for 1908 was jointly awarded to Ehrlich and the founder of cellular immunology, Ilya Mechnikov (1845–1916).The simplest form of immunity is the DNA restriction system in bacteria that prevents infection by bacteriophages.  References   Related pages  Lymphatic system White blood cell"
"Epidemiology is the study and analysis of the distribution (who, when, and where), patterns and determinants of health and disease conditions in a defined population. It is a cornerstone of public health, and shapes policy decisions and evidence-based practice by identifying risk factors for disease and targets for preventive healthcare. Epidemiologists help with study design, collection, and statistical analysis of data, amend interpretation and dissemination of results (including peer review and occasional systematic review). Epidemiology has helped develop methodology used in clinical research, public health studies, and, to a lesser extent, basic research in the biological sciences.Major areas of epidemiological study include disease causation, transmission, outbreak investigation, disease surveillance, environmental epidemiology, forensic epidemiology, occupational epidemiology, screening, biomonitoring, and comparisons of treatment effects such as in clinical trials. Epidemiologists rely on other scientific disciplines like biology to better understand disease processes, statistics to make efficient use of the data and draw appropriate conclusions, social sciences to better understand proximate and distal causes, and engineering for exposure assessment. Epidemiology, literally meaning ""the study of what is upon the people"", is derived from Greek epi 'upon, among', demos 'people, district', and logos 'study, word, discourse', suggesting that it applies only to human populations. However, the term is widely used in studies of zoological populations (veterinary epidemiology), although the term ""epizoology"" is available, and it has also been applied to studies of plant populations (botanical or plant disease epidemiology).The distinction between ""epidemic"" and ""endemic"" was first drawn by Hippocrates, to distinguish between diseases that are ""visited upon"" a population (epidemic) from those that ""reside within"" a population (endemic). The term ""epidemiology"" appears to have first been used to describe the study of epidemics in 1802 by the Spanish physician Villalba in Epidemiología Española. Epidemiologists also study the interaction of diseases in a population, a condition known as a syndemic. The term epidemiology is now widely applied to cover the description and causation of not only epidemic, infectious disease, but of disease in general, including related conditions. Some examples of topics examined through epidemiology include as high blood pressure, mental illness and obesity. Therefore, this epidemiology is based upon how the pattern of the disease causes change in the function of human beings.  History  The Greek physician Hippocrates, known as the father of medicine, sought a logic to sickness; he is the first person known to have examined the relationships between the occurrence of disease and environmental influences. Hippocrates believed sickness of the human body to be caused by an imbalance of the four humors (black bile, yellow bile, blood, and phlegm). The cure to the sickness was to remove or add the humor in question to balance the body. This belief led to the application of bloodletting and dieting in medicine. He coined the terms endemic (for diseases usually found in some places but not in others) and epidemic (for diseases that are seen at some times but not others).  Modern era  In the middle of the 16th century, a doctor from Verona named Girolamo Fracastoro was the first to propose a theory that these very small, unseeable, particles that cause disease were alive. They were considered to be able to spread by air, multiply by themselves and to be destroyable by fire. In this way he refuted Galen's miasma theory (poison gas in sick people). In 1543 he wrote a book De contagione et contagiosis morbis, in which he was the first to promote personal and environmental hygiene to prevent disease. The development of a sufficiently powerful microscope by Antonie van Leeuwenhoek in 1675 provided visual evidence of living particles consistent with a germ theory of disease.During the Ming Dynasty, Wu Youke (1582–1652) developed the idea that some diseases were caused by transmissible agents, which he called Li Qi (戾气 or pestilential factors) when he observed various epidemics rage around him between 1641 and 1644. His book Wen Yi Lun (瘟疫论，Treatise on Pestilence/Treatise of Epidemic Diseases) can be regarded as the main etiological work that brought forward the concept. His concepts were still being considered in analysing SARS outbreak by WHO in 2004 in the context of traditional Chinese medicine.Another pioneer, Thomas Sydenham (1624–1689), was the first to distinguish the fevers of Londoners in the later 1600s. His theories on cures of fevers met with much resistance from traditional physicians at the time. He was not able to find the initial cause of the smallpox fever he researched and treated.John Graunt, a haberdasher and amateur statistician, published Natural and Political Observations ... upon the Bills of Mortality in 1662. In it, he analysed the mortality rolls in London before the Great Plague, presented one of the first life tables, and reported time trends for many diseases, new and old. He provided statistical evidence for many theories on disease, and also refuted some widespread ideas on them. John Snow is famous for his investigations into the causes of the 19th-century cholera epidemics, and is also known as the father of (modern) Epidemiology. He began with noticing the significantly higher death rates in two areas supplied by Southwark Company. His identification of the Broad Street pump as the cause of the Soho epidemic is considered the classic example of epidemiology. Snow used chlorine in an attempt to clean the water and removed the handle; this ended the outbreak. This has been perceived as a major event in the history of public health and regarded as the founding event of the science of epidemiology, having helped shape public health policies around the world. However, Snow's research and preventive measures to avoid further outbreaks were not fully accepted or put into practice until after his death due to the prevailing Miasma Theory of the time, a model of disease in which poor air quality was blamed for illness. This was used to rationalize high rates of infection in impoverished areas instead of addressing the underlying issues of poor nutrition and sanitation, and was proven false by his work.Other pioneers include Danish physician Peter Anton Schleisner, who in 1849 related his work on the prevention of the epidemic of neonatal tetanus on the Vestmanna Islands in Iceland. Another important pioneer was Hungarian physician Ignaz Semmelweis, who in 1847 brought down infant mortality at a Vienna hospital by instituting a disinfection procedure. His findings were published in 1850, but his work was ill-received by his colleagues, who discontinued the procedure. Disinfection did not become widely practiced until British surgeon Joseph Lister 'discovered' antiseptics in 1865 in light of the work of Louis Pasteur.In the early 20th century, mathematical methods were introduced into epidemiology by Ronald Ross, Janet Lane-Claypon, Anderson Gray McKendrick, and others. In a parallel development during the 1920s, German-Swiss pathologist Max Askanazy and others founded the International Society for Geographical Pathology to systematically investigate the geographical pathology of cancer and other non-infectious diseases across populations in different regions. After World War II, Richard Doll and other non-pathologists joined the field and advanced methods to study cancer, a disease with patterns and mode of occurrences that could not be suitably studied with the methods developed for epidemics of infectious diseases. Geography pathology eventually combined with infectious disease epidemiology to make the field that is epidemiology today.Another breakthrough was the 1954 publication of the results of a British Doctors Study, led by Richard Doll and Austin Bradford Hill, which lent very strong statistical support to the link between tobacco smoking and lung cancer. In the late 20th century, with the advancement of biomedical sciences, a number of molecular markers in blood, other biospecimens and environment were identified as predictors of development or risk of a certain disease. Epidemiology research to examine the relationship between these biomarkers analyzed at the molecular level and disease was broadly named ""molecular epidemiology"". Specifically, ""genetic epidemiology"" has been used for epidemiology of germline genetic variation and disease. Genetic variation is typically determined using DNA from peripheral blood leukocytes.  21st century  Since the 2000s, genome-wide association studies (GWAS) have been commonly performed to identify genetic risk factors for many diseases and health conditions.While most molecular epidemiology studies are still using conventional disease diagnosis and classification systems, it is increasingly recognized that disease progression represents inherently heterogeneous processes differing from person to person. Conceptually, each individual has a unique disease process different from any other individual (""the unique disease principle""), considering uniqueness of the exposome (a totality of endogenous and exogenous / environmental exposures) and its unique influence on molecular pathologic process in each individual. Studies to examine the relationship between an exposure and molecular pathologic signature of disease (particularly cancer) became increasingly common throughout the 2000s. However, the use of molecular pathology in epidemiology posed unique challenges, including lack of research guidelines and standardized statistical methodologies, and paucity of interdisciplinary experts and training programs. Furthermore, the concept of disease heterogeneity appears to conflict with the long-standing premise in epidemiology that individuals with the same disease name have similar etiologies and disease processes. To resolve these issues and advance population health science in the era of molecular precision medicine, ""molecular pathology"" and ""epidemiology"" was integrated to create a new interdisciplinary field of ""molecular pathological epidemiology"" (MPE), defined as ""epidemiology of molecular pathology and heterogeneity of disease"". In MPE, investigators analyze the relationships between (A) environmental, dietary, lifestyle and genetic factors; (B) alterations in cellular or extracellular molecules; and (C) evolution and progression of disease. A better understanding of heterogeneity of disease pathogenesis will further contribute to elucidate etiologies of disease. The MPE approach can be applied to not only neoplastic diseases but also non-neoplastic diseases. The concept and paradigm of MPE have become widespread in the 2010s.By 2012, it was recognized that many pathogens' evolution is rapid enough to be highly relevant to epidemiology, and that therefore much could be gained from an interdisciplinary approach to infectious disease integrating epidemiology and molecular evolution to ""inform control strategies, or even patient treatment.""Modern epidemiological studies can use advanced statistics and machine learning to create predictive models as well as to define treatment effects. There is increasing recognition that a wide range of modern data sources, many not originating from healthcare or epidemiology, can be used for epidemiological study. Such digital epidemiology can include data from internet searching, mobile phone records and retail sales of drugs.  Types of studies  Epidemiologists employ a range of study designs from the observational to experimental and generally categorized as descriptive (involving the assessment of data covering time, place, and person), analytic (aiming to further examine known associations or hypothesized relationships), and experimental (a term often equated with clinical or community trials of treatments and other interventions). In observational studies, nature is allowed to ""take its course"", as epidemiologists observe from the sidelines. Conversely, in experimental studies, the epidemiologist is the one in control of all of the factors entering a certain case study. Epidemiological studies are aimed, where possible, at revealing unbiased relationships between exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity. The identification of causal relationships between these exposures and outcomes is an important aspect of epidemiology. Modern epidemiologists use informatics as a tool.Observational studies have two components, descriptive and analytical. Descriptive observations pertain to the ""who, what, where and when of health-related state occurrence"". However, analytical observations deal more with the 'how' of a health-related event. Experimental epidemiology contains three case types: randomized controlled trials (often used for a new medicine or drug testing), field trials (conducted on those at a high risk of contracting a disease), and community trials (research on social originating diseases).The term 'epidemiologic triad' is used to describe the intersection of Host, Agent, and Environment in analyzing an outbreak.  Case series  Case-series may refer to the qualitative study of the experience of a single patient, or small group of patients with a similar diagnosis, or to a statistical factor with the potential to produce illness with periods when they are unexposed.The former type of study is purely descriptive and cannot be used to make inferences about the general population of patients with that disease. These types of studies, in which an astute clinician identifies an unusual feature of a disease or a patient's history, may lead to a formulation of a new hypothesis. Using the data from the series, analytic studies could be done to investigate possible causal factors. These can include case-control studies or prospective studies. A case-control study would involve matching comparable controls without the disease to the cases in the series. A prospective study would involve following the case series over time to evaluate the disease's natural history.The latter type, more formally described as self-controlled case-series studies, divide individual patient follow-up time into exposed and unexposed periods and use fixed-effects Poisson regression processes to compare the incidence rate of a given outcome between exposed and unexposed periods. This technique has been extensively used in the study of adverse reactions to vaccination and has been shown in some circumstances to provide statistical power comparable to that available in cohort studies.  Case-control studies  Case-control studies select subjects based on their disease status. It is a retrospective study. A group of individuals that are disease positive (the ""case"" group) is compared with a group of disease negative individuals (the ""control"" group). The control group should ideally come from the same population that gave rise to the cases. The case-control study looks back through time at potential exposures that both groups (cases and controls) may have encountered. A 2×2 table is constructed, displaying exposed cases (A), exposed controls (B), unexposed cases (C) and unexposed controls (D). The statistic generated to measure association is the odds ratio (OR), which is the ratio of the odds of exposure in the cases (A/C) to the odds of exposure in the controls (B/D), i.e. OR  (AD/BC). If the OR is significantly greater than 1, then the conclusion is ""those with the disease are more likely to have been exposed,"" whereas if it is close to 1 then the exposure and disease are not likely associated. If the OR is far less than one, then this suggests that the exposure is a protective factor in the causation of the disease. Case-control studies are usually faster and more cost-effective than cohort studies but are sensitive to bias (such as recall bias and selection bias). The main challenge is to identify the appropriate control group; the distribution of exposure among the control group should be representative of the distribution in the population that gave rise to the cases. This can be achieved by drawing a random sample from the original population at risk. This has as a consequence that the control group can contain people with the disease under study when the disease has a high attack rate in a population.A major drawback for case control studies is that, in order to be considered to be statistically significant, the minimum number of cases required at the 95% confidence interval is related to the odds ratio by the equation: total cases  A + C  1.96 2 ( 1 + N ) ( 1 ln ⁡ ( O R ) ) 2 ( O R + 2 O R + 1 O R ) ≈ 15.5 ( 1 + N ) ( 1 ln ⁡ ( O R ) ) 2 {displaystyle {text{total cases}}A+C1.96^{2}(1+N)left({frac {1}{ln(OR)}}right)^{2}left({frac {OR+2{sqrt {OR}}+1}{sqrt {OR}}}right)approx 15.5(1+N)left({frac {1}{ln(OR)}}right)^{2}} where N is the ratio of cases to controls. As the odds ratio approaches 1, the number of cases required for statistical significance grows towards infinity; rendering case-control studies all but useless for low odds ratios. For instance, for an odds ratio of 1.5 and cases  controls, the table shown above would look like this: For an odds ratio of 1.1:  Cohort studies  Cohort studies select subjects based on their exposure status. The study subjects should be at risk of the outcome under investigation at the beginning of the cohort study; this usually means that they should be disease free when the cohort study starts. The cohort is followed through time to assess their later outcome status. An example of a cohort study would be the investigation of a cohort of smokers and non-smokers over time to estimate the incidence of lung cancer. The same 2×2 table is constructed as with the case control study. However, the point estimate generated is the relative risk (RR), which is the probability of disease for a person in the exposed group, Pe  A / (A + B) over the probability of disease for a person in the unexposed group, Pu  C / (C + D), i.e. RR  Pe / Pu. As with the OR, a RR greater than 1 shows association, where the conclusion can be read ""those with the exposure were more likely to develop the disease."" Prospective studies have many benefits over case control studies. The RR is a more powerful effect measure than the OR, as the OR is just an estimation of the RR, since true incidence cannot be calculated in a case control study where subjects are selected based on disease status. Temporality can be established in a prospective study, and confounders are more easily controlled for. However, they are more costly, and there is a greater chance of losing subjects to follow-up based on the long time period over which the cohort is followed. Cohort studies also are limited by the same equation for number of cases as for cohort studies, but, if the base incidence rate in the study population is very low, the number of cases required is reduced by 1⁄2.  Causal inference  Although epidemiology is sometimes viewed as a collection of statistical tools used to elucidate the associations of exposures to health outcomes, a deeper understanding of this science is that of discovering causal relationships. ""Correlation does not imply causation"" is a common theme for much of the epidemiological literature. For epidemiologists, the key is in the term inference. Correlation, or at least association between two variables, is a necessary but not sufficient criterion for the inference that one variable causes the other. Epidemiologists use gathered data and a broad range of biomedical and psychosocial theories in an iterative way to generate or expand theory, to test hypotheses, and to make educated, informed assertions about which relationships are causal, and about exactly how they are causal. Epidemiologists emphasize that the ""one cause – one effect"" understanding is a simplistic mis-belief. Most outcomes, whether disease or death, are caused by a chain or web consisting of many component causes. Causes can be distinguished as necessary, sufficient or probabilistic conditions. If a necessary condition can be identified and controlled (e.g., antibodies to a disease agent, energy in an injury), the harmful outcome can be avoided (Robertson, 2015). One tool regularly used to conceptualize the multicausality associated with disease is the causal pie model.  Bradford Hill criteria  In 1965, Austin Bradford Hill proposed a series of considerations to help assess evidence of causation, which have come to be commonly known as the ""Bradford Hill criteria"". In contrast to the explicit intentions of their author, Hill's considerations are now sometimes taught as a checklist to be implemented for assessing causality. Hill himself said ""None of my nine viewpoints can bring indisputable evidence for or against the cause-and-effect hypothesis and none can be required sine qua non."" Strength of Association: A small association does not mean that there is not a causal effect, though the larger the association, the more likely that it is causal. Consistency of Data: Consistent findings observed by different persons in different places with different samples strengthens the likelihood of an effect. Specificity: Causation is likely if a very specific population at a specific site and disease with no other likely explanation. The more specific an association between a factor and an effect is, the bigger the probability of a causal relationship. Temporality: The effect has to occur after the cause (and if there is an expected delay between the cause and expected effect, then the effect must occur after that delay). Biological gradient: Greater exposure should generally lead to greater incidence of the effect. However, in some cases, the mere presence of the factor can trigger the effect. In other cases, an inverse proportion is observed: greater exposure leads to lower incidence. Plausibility: A plausible mechanism between cause and effect is helpful (but Hill noted that knowledge of the mechanism is limited by current knowledge). Coherence: Coherence between epidemiological and laboratory findings increases the likelihood of an effect. However, Hill noted that ""... lack of such [laboratory] evidence cannot nullify the epidemiological effect on associations"". Experiment: ""Occasionally it is possible to appeal to experimental evidence"". Analogy: The effect of similar factors may be considered.  Legal interpretation  Epidemiological studies can only go to prove that an agent could have caused, but not that it did cause, an effect in any particular case: Epidemiology is concerned with the incidence of disease in populations and does not address the question of the cause of an individual's disease. This question, sometimes referred to as specific causation, is beyond the domain of the science of epidemiology. Epidemiology has its limits at the point where an inference is made that the relationship between an agent and a disease is causal (general causation) and where the magnitude of excess risk attributed to the agent has been determined; that is, epidemiology addresses whether an agent can cause disease, not whether an agent did cause a specific plaintiff's disease. In United States law, epidemiology alone cannot prove that a causal association does not exist in general. Conversely, it can be (and is in some circumstances) taken by US courts, in an individual case, to justify an inference that a causal association does exist, based upon a balance of probability. The subdiscipline of forensic epidemiology is directed at the investigation of specific causation of disease or injury in individuals or groups of individuals in instances in which causation is disputed or is unclear, for presentation in legal settings.  Population-based health management  Epidemiological practice and the results of epidemiological analysis make a significant contribution to emerging population-based health management frameworks. Population-based health management encompasses the ability to: Assess the health states and health needs of a target population; Implement and evaluate interventions that are designed to improve the health of that population; and Efficiently and effectively provide care for members of that population in a way that is consistent with the community's cultural, policy and health resource values.Modern population-based health management is complex, requiring a multiple set of skills (medical, political, technological, mathematical, etc.) of which epidemiological practice and analysis is a core component, that is unified with management science to provide efficient and effective health care and health guidance to a population. This task requires the forward-looking ability of modern risk management approaches that transform health risk factors, incidence, prevalence and mortality statistics (derived from epidemiological analysis) into management metrics that not only guide how a health system responds to current population health issues but also how a health system can be managed to better respond to future potential population health issues.Examples of organizations that use population-based health management that leverage the work and results of epidemiological practice include Canadian Strategy for Cancer Control, Health Canada Tobacco Control Programs, Rick Hansen Foundation, Canadian Tobacco Control Research Initiative.Each of these organizations uses a population-based health management framework called Life at Risk that combines epidemiological quantitative analysis with demographics, health agency operational research and economics to perform: Population Life Impacts Simulations: Measurement of the future potential impact of disease upon the population with respect to new disease cases, prevalence, premature death as well as potential years of life lost from disability and death; Labour Force Life Impacts Simulations: Measurement of the future potential impact of disease upon the labour force with respect to new disease cases, prevalence, premature death and potential years of life lost from disability and death; Economic Impacts of Disease Simulations: Measurement of the future potential impact of disease upon private sector disposable income impacts (wages, corporate profits, private health care costs) and public sector disposable income impacts (personal income tax, corporate income tax, consumption taxes, publicly funded health care costs).  Applied field epidemiology  Applied epidemiology is the practice of using epidemiological methods to protect or improve the health of a population. Applied field epidemiology can include investigating communicable and non-communicable disease outbreaks, mortality and morbidity rates, and nutritional status, among other indicators of health, with the purpose of communicating the results to those who can implement appropriate policies or disease control measures.  Humanitarian context  As the surveillance and reporting of diseases and other health factors become increasingly difficult in humanitarian crisis situations, the methodologies used to report the data are compromised. One study found that less than half (42.4%) of nutrition surveys sampled from humanitarian contexts correctly calculated the prevalence of malnutrition and only one-third (35.3%) of the surveys met the criteria for quality. Among the mortality surveys, only 3.2% met the criteria for quality. As nutritional status and mortality rates help indicate the severity of a crisis, the tracking and reporting of these health factors is crucial. Vital registries are usually the most effective ways to collect data, but in humanitarian contexts these registries can be non-existent, unreliable, or inaccessible. As such, mortality is often inaccurately measured using either prospective demographic surveillance or retrospective mortality surveys. Prospective demographic surveillance requires much manpower and is difficult to implement in a spread-out population. Retrospective mortality surveys are prone to selection and reporting biases. Other methods are being developed, but are not common practice yet.  Validity: precision and bias  Different fields in epidemiology have different levels of validity. One way to assess the validity of findings is the ratio of false-positives (claimed effects that are not correct) to false-negatives (studies which fail to support a true effect). To take the field of genetic epidemiology, candidate-gene studies produced over 100 false-positive findings for each false-negative. By contrast genome-wide association appear close to the reverse, with only one false positive for every 100 or more false-negatives. This ratio has improved over time in genetic epidemiology as the field has adopted stringent criteria. By contrast, other epidemiological fields have not required such rigorous reporting and are much less reliable as a result.  Random error  Random error is the result of fluctuations around a true value because of sampling variability. Random error is just that: random. It can occur during data collection, coding, transfer, or analysis. Examples of random errors include poorly worded questions, a misunderstanding in interpreting an individual answer from a particular respondent, or a typographical error during coding. Random error affects measurement in a transient, inconsistent manner and it is impossible to correct for random error. There is a random error in all sampling procedures. This is called sampling error. Precision in epidemiological variables is a measure of random error. Precision is also inversely related to random error, so that to reduce random error is to increase precision. Confidence intervals are computed to demonstrate the precision of relative risk estimates. The narrower the confidence interval, the more precise the relative risk estimate. There are two basic ways to reduce random error in an epidemiological study. The first is to increase the sample size of the study. In other words, add more subjects to your study. The second is to reduce the variability in measurement in the study. This might be accomplished by using a more precise measuring device or by increasing the number of measurements. Note, that if sample size or number of measurements are increased, or a more precise measuring tool is purchased, the costs of the study are usually increased. There is usually an uneasy balance between the need for adequate precision and the practical issue of study cost.  Systematic error  A systematic error or bias occurs when there is a difference between the true value (in the population) and the observed value (in the study) from any cause other than sampling variability. An example of systematic error is if, unknown to you, the pulse oximeter you are using is set incorrectly and adds two points to the true value each time a measurement is taken. The measuring device could be precise but not accurate. Because the error happens in every instance, it is systematic. Conclusions you draw based on that data will still be incorrect. But the error can be reproduced in the future (e.g., by using the same mis-set instrument). A mistake in coding that affects all responses for that particular question is another example of a systematic error. The validity of a study is dependent on the degree of systematic error. Validity is usually separated into two components: Internal validity is dependent on the amount of error in measurements, including exposure, disease, and the associations between these variables. Good internal validity implies a lack of error in measurement and suggests that inferences may be drawn at least as they pertain to the subjects under study. External validity pertains to the process of generalizing the findings of the study to the population from which the sample was drawn (or even beyond that population to a more universal statement). This requires an understanding of which conditions are relevant (or irrelevant) to the generalization. Internal validity is clearly a prerequisite for external validity.  Selection bias  Selection bias occurs when study subjects are selected or become part of the study as a result of a third, unmeasured variable which is associated with both the exposure and outcome of interest. For instance, it has repeatedly been noted that cigarette smokers and non smokers tend to differ in their study participation rates. (Sackett D cites the example of Seltzer et al., in which 85% of non smokers and 67% of smokers returned mailed questionnaires.) It is important to note that such a difference in response will not lead to bias if it is not also associated with a systematic difference in outcome between the two response groups.  Information bias  Information bias is bias arising from systematic error in the assessment of a variable. An example of this is recall bias. A typical example is again provided by Sackett in his discussion of a study examining the effect of specific exposures on fetal health: ""in questioning mothers whose recent pregnancies had ended in fetal death or malformation (cases) and a matched group of mothers whose pregnancies ended normally (controls) it was found that 28% of the former, but only 20% of the latter, reported exposure to drugs which could not be substantiated either in earlier prospective interviews or in other health records"". In this example, recall bias probably occurred as a result of women who had had miscarriages having an apparent tendency to better recall and therefore report previous exposures.  Confounding  Confounding has traditionally been defined as bias arising from the co-occurrence or mixing of effects of extraneous factors, referred to as confounders, with the main effect(s) of interest. A more recent definition of confounding invokes the notion of counterfactual effects. According to this view, when one observes an outcome of interest, say Y1 (as opposed to Y0), in a given population A which is entirely exposed (i.e. exposure X  1 for every unit of the population) the risk of this event will be RA1. The counterfactual or unobserved risk RA0 corresponds to the risk which would have been observed if these same individuals had been unexposed (i.e. X  0 for every unit of the population). The true effect of exposure therefore is: RA1 − RA0 (if one is interested in risk differences) or RA1/RA0 (if one is interested in relative risk). Since the counterfactual risk RA0 is unobservable we approximate it using a second population B and we actually measure the following relations: RA1 − RB0 or RA1/RB0. In this situation, confounding occurs when RA0 ≠ RB0. (NB: Example assumes binary outcome and exposure variables.) Some epidemiologists prefer to think of confounding separately from common categorizations of bias since, unlike selection and information bias, confounding stems from real causal effects.  The profession  Few universities have offered epidemiology as a course of study at the undergraduate level. One notable undergraduate program exists at Johns Hopkins University, where students who major in public health can take graduate-level courses, including epidemiology, during their senior year at the Bloomberg School of Public Health.Although epidemiologic research is conducted by individuals from diverse disciplines, including clinically trained professionals such as physicians, formal training is available through Masters or Doctoral programs including Master of Public Health (MPH), Master of Science of Epidemiology (MSc.), Doctor of Public Health (DrPH), Doctor of Pharmacy (PharmD), Doctor of Philosophy (PhD), Doctor of Science (ScD). Many other graduate programs, e.g., Doctor of Social Work (DSW), Doctor of Clinical Practice (DClinP), Doctor of Podiatric Medicine (DPM), Doctor of Veterinary Medicine (DVM), Doctor of Nursing Practice (DNP), Doctor of Physical Therapy (DPT), or for clinically trained physicians, Doctor of Medicine (MD) or Bachelor of Medicine and Surgery (MBBS or MBChB) and Doctor of Osteopathic Medicine (DO), include some training in epidemiologic research or related topics, but this training is generally substantially less than offered in training programs focused on epidemiology or public health. Reflecting the strong historical tie between epidemiology and medicine, formal training programs may be set in either schools of public health or medical schools. As public health/health protection practitioners, epidemiologists work in a number of different settings. Some epidemiologists work 'in the field'; i.e., in the community, commonly in a public health/health protection service, and are often at the forefront of investigating and combating disease outbreaks. Others work for non-profit organizations, universities, hospitals and larger government entities such as state and local health departments, various Ministries of Health, Doctors without Borders, the Centers for Disease Control and Prevention (CDC), the Health Protection Agency, the World Health Organization (WHO), or the Public Health Agency of Canada. Epidemiologists can also work in for-profit organizations such as pharmaceutical and medical device companies in groups such as market research or clinical development.  COVID-19  An April 2020 University of Southern California article noted that ""The coronavirus epidemic... thrust epidemiology – the study of the incidence, distribution and control of disease in a population – to the forefront of scientific disciplines across the globe and even made temporary celebrities out of some of its practitioners.""  See also   References   Citations   Sources   External links ","Epidemiology is the study of factors that influence the health and illness of populations. The three levels of causation of health problems include individual behavioral level, individual biological level, and political-economic ecological level.  Aims  Epidemiologists aim to understand the causes of health problems by looking at the relationship between agents, hosts, and environmental factors that affects health. Using these information, they also design public health interventions to solve various health problems among populations. They regularly evaluate the health of populations, tries to identify which populations have greater risk from specific causes of diseases, and evaluates the effectiveness of the intervention programs or methods that they create. In essence, epidemiology provides the foundation of public health and preventative medicine practices.  Descriptive/analytic epidemiology  There are two types of epidemiology: descriptive and analytic. Descriptive epidemiology aims to describe the distribution of people who gets sick (versus those who don't) with regards to time, place, and person (TPP). TPP can also be thought of as answering the questions of when, who, and what respectively; in other words it investigates when a health issue or disease first emerged in a population, who in the population are getting sick, and where the disease/health condition seems to have first originated and spread from. Analytic epidemiology then uses the data provided by TPP to make and test hypothesis which aim to determine the cause of an outbreak or disease cluster among a population. Epidemiologist evaluate morbidity (people who are sick or injured) and mortality (people who are killed) to understand the burden of disease among populations.  Surveillance studies  A key aspect of epidemiology is surveillance studies, which provides the numerical data and statistics that epidemiologists use. Surveillance studies are done systematically to monitor the health of populations and helps with identifying any new health problems or disease that may develop, as well as evaluating the effectiveness of existing health intervention measures in place. These studies also rely on TPP to collect data and presents it in simple graphs and tables which are easy to summarize and understand. These studies are especially important in helping guide policy making decisions and helping epidemiologists understand which interventions work and which don't. It is also important for donors as they rely on surveillance data to analyze the usefulness of their investments and whether it is being used effectively or not.  Definition and origin of term  Epidemiology means ""the study of what is upon the people"". The word derived from the Greek terms epi  upon, among; demos  people, district; logos  study, word, discourse. It applies only to human populations. But the term is used in studies of zoological populations 'epizoology', and plant populations.  History  Hippocrates was the first who has looked at the relationships between disease and environmental influences. He drew the distinction between 'epidemic' and 'endemic': diseases that are 'visited upon' a population (epidemic) as contrasted with those that 'live within' a population (endemic).  11th century  The Persian physician Avicenna in the 1020s, discovered the contagious nature of tuberculosis and sexually transmitted disease. He noted the distribution of disease through water and soil. Avicenna said that bodily secretion is contaminated by foul foreign earthly bodies before being infected. He introduced the method of quarantine to limit the spread of contagious disease.  Black death  The Black Death (bubonic plague) reached Al Andalus in the 14th century. Ibn Khatima thought infectious diseases were caused by ""minute bodies"" which enter the human body and cause disease. Another Andalusian-Arabian physician, Ibn al-Khatib (1313–1374) in his treatise On the Plague stated how infectious disease can be transmitted through bodily contact and ""through garments, vessels and earrings"". Girolamo Fracastoro from Verona suggested these very small, unseeable, particles that cause disease were alive. They were able to spread by air, and multiply. They could be destroyed by fire. He refuted Galen's miasma theory (poison gas in sick people). In 1543, Fracastoro's book De contagione et contagiosis morbis suggested personal and environmental hygiene to prevent disease. The development of a sufficiently powerful microscope by Anton van Leeuwenhoek in 1675 provided visual evidence of living particles consistent with a germ theory of disease.  Great Plague  In 1662 John Graunt analysed the mortality rolls in London before the Great Plague. This gave statistical evidence for and against various theories of disease. Dr. John Snow investigated the causes of the 19th Century Cholera epidemics. He noticed the significantly higher death rates in two areas supplied by Southwark Water Company. He showed the Broad Street pump was the origin of the Soho epidemic, a classic example of epidemiology He used chlorine in an attempt to clean the water and had the pump handle removed. This stopped the outbreak. It was a major event in the history of public health, and the founding event of the science of epidemiology.  19th century  The term 'epidemiology' was first used in 1802 by the Spanish physician Villalba. The term is used now for the description and causation of epidemic diseases, and of disease in general. It can be used for many non-disease health-related conditions, such as high blood pressure and obesity. In 1847 Hungarian physician Ignaz Semmelweis brought down infant mortality at a Vienna hospital by disinfection. Unfortunately, disinfection did not become widely practiced until British surgeon Joseph Lister 'discovered' antiseptics in 1865 after Louis Pasteur's work. In the early 20th century, mathematical methods were introduced into epidemiology by Ronald Ross and others. In 1954 came the results of a study led by Richard Doll. This gave very strong statistical support to the suspicion that tobacco smoking was linked to lung cancer.  Important concepts/terms  There are several very key terms that epidemiologists use when discussing population health and disease outbreaks. The following, although not a comprehensive list, provides some of the key concepts that are important to understand when discussing epidemiology. Cases: refers specifically to those individual who are sick with a disease/health condition or injured Epidemic / Outbreak: is the occurrence of a disease among a population that is in excess (higher rate) than what is expected for that given time and place Endemic: a disease or health condition that is present in the population at all times during the year Pandemic: a disease that spreads across various regions; also refers to global outbreaks that spreads over multiple continents Cluster: refers to group of cases in a specific time and place that's more than what's expected Population at risk: refers to those within a population who are particularly susceptible to a certain disease or health conditionIt is important to note that an endemic disease or cluster can become an epidemic. An example of this would be with malaria; although malaria is endemic to certain regions in South America, Africa, and South Asia, during certain years or times it can become an epidemic with higher number of cases then usual present in the population. In addition, it is also possible for epidemic or outbreak to progress and become a full-fledged pandemic.  Calculating Disease Rates  Rates refers to the number of cases occurring during a specific period of time and depends on the population size at that time. Calculating disease rates helps epidemiologists to compare health issues among different populations. The general calculation for determining disease rate is to divide the number of cases or health condition by the number of population at risk during a specific period of time, and multiplying that by 100. However, disease rates can also be differentiated into two different types: prevalence rate and incidence rate. Prevalence rate refers to the number of both old and new cases in a population during a specific time period, which is divided by the total number of cases in the population. Prevalence rates are useful when dealing with investigations relating to chronic diseases, which last for more than 3 months. On the other hand, incidence rate refers to the number of new health related conditions or cases which is divided by the population at risk. Incidence rates are important in studies involving acute diseases, where symptoms of a disease peak and subside within days or weeks and generally lasts less than 3 months.  Types of Epidemiological Studies  Epidemiological studies makes use of both experimental and observational studies.  Experimental studies  Experimental studies are ones where the epidemiologist can control and manipulate different variables throughout the experiment. It usually involves a placebo treatment/group. This type of study is used when epidemiologists are trying to determine the cause of a health issue/disease or evaluating the effectiveness of a cure or interventions.  Observational studies  Observational studies include descriptive and analytical studies; descriptive studies investigates epidemiological cases with regards to TPP while analytical study investigates hypothesis regarding relationships between health issues and risk factors. While descriptive studies (TPP) answers questions of when, who, and where, analytical studies tries to answer the question of how a population is affected by a disease and why they are affected. Overall, observational studies do not manipulate any variables and often uses comparison groups for analysis; this type of study is often done in an attempt to discover the links between exposure to certain risk factors and health outcomes. Some examples of observational studies include cohort studies, case-control studies, and cross-sectional studies. Cohort study: participants are categorized based on exposure to disease, risk factor, or presence of a health condition and are observed over time to see if they develop symptoms of the disease Case-control study: Those individuals who are identified as cases (has the disease or health condition) are compared with those who don't have the disease/health condition Cross - sectional study: provides a ""one-shot"" picture of a group at a certain point in time; participants are selected based on a specific characteristic or because they belong to a certain population/group and are examined to see how the disease/health condition has affected their group.  Process of Epidemiological Investigations  Investigating an outbreak is a very involved multi-step process which ranges from first establishing the existence of an outbreak to communicating the findings of the investigation with the scientific community as well as the general population. The following is a rough sequence of the process of these investigations. Establish that there is an outbreak. Epidemiologists look at data (TPP) and surveillance studies to determine if there have been similar cases, like the one being investigated, in the past or if it is a completely new type of disease or health condition. Prepare for field work. Once an outbreak has been established, epidemiologists take preparations, arrange materials/equipment for travel to investigate the outbreak at its place of origin and other locations where it may have spread to. Verify the diagnosis. Researchers review all laboratory/clinical findings and interview patients to get a better sense of what they are dealing with and to confirm their initial diagnosis of an outbreak. Define/identify case. Epidemiologists must come up with a precise and standard definition of what a case is or what a case looks like because that will be used to determine who is a case and who isn't. Descriptive epidemiology. Then next step here is to describe the outbreak in terms of time, person, and place (TPP). Develop a hypothesis. Epidemiologists must formulate a hypothesis about cause/risk factors of the disease, then evaluate the hypothesis and refine it as needed. Implement necessary control & preventative measures. This may include things like social distancing, wearing masks, frequently washing hands, as well as isolation and quarantine. Communicate research/investigation findings. Epidemiologists must determine which information is important and how findings will be communicated. They must also determine who the audience is that needs to know the information (is it something only health care workers need to be on the lookout for or should the general public also be made aware?)  Professions In Epidemiology  Epidemiology is a multidisciplinary subject. Members in this field mostly includes public health care workers and scientists from related fields such as chemists, biologists, geneticists, and anthropologists. People in epidemiology may work in hospital and research settings, as well as for federal organizations such as the Centers for Disease Control and Prevention (CDC). One particular unit that may be of interest for those pursuing epidemiology is with with Epidemic Intelligence Service (EIS), a subgroup within the CDC specializing in epidemiology. Epidemic Intelligence Service officers are field workers who investigate outbreaks in the US and other countries. Their work aids in understanding causes of outbreaks and quickly stopping spread of diseases from one place to another; notably, they have contributed to helping during various pandemics in the past, such as with smallpox, polio, and Ebola.  Medical Anthropology & Epidemiology  One particular field that has had an impact in epidemiology is anthropology. In the past, cultural anthropologists have been a very helpful resource in bridging the gap between different countries/cultures and the epidemiological investigators. They have helped and continues to help with the development and implementation of preventative/control measures in countries in a manner that will not conflict with societal beliefs or values, which may get in the way of treatment or stopping the spread of an outbreak.  Recent studies  In recent years however, medical anthropology in particular has taken on a larger role in the field of epidemiology. Medical anthropology looks at biological, social, cultural, and linguistic anthropology to understand how these factors influence health and well-being, experience and distribution of illness, as well as prevention of treatment. As with cultural anthropologists, medical anthropologists have continued to aid in the development of public health policies. In particular, they have been very helpful in providing a unique perspective on public health discourse. For example, they investigate how culture affects research studies, are able to pick up on seemingly ""irrelevant"" yet important small details that an epidemiologist might miss, and they are able to provide qualitative data whereas epidemiology only focuses on quantitative data. One main thing of importance here is that while epidemiologist has largely ignored cultural factors when looking at the causes of diseases/health conditions, medical anthropology has challenged this notion and contributed to the field by showing how culture and social factors play a big role in people's willingness to follow public health guidelines/interventions or even accept treatment for their illnesses. Whereas the nature of epidemiological investigations may lead to a reductionist or limited point of view, medical anthropology provides a more holistic view of the problem and examines the issue from different angles to best understand and help the populations in need. Another critical contribution of medical anthropology has been with regard to critical qualitative data. While epidemiology is focused mainly on quantitative data and trends in health of the population, medical anthropology provides rich source of information on understanding the population's subjective experiences and providing qualitative data explaining why a particular intervention or treatment may have failed among a particular population. Their main contributions in recent years have come from modifying and helping develop epidemiological surveys by taking into account word choice and the ""social suitability"" of questions, so that responses would be more accurate and thereby helping to increase the validity of the questionnaires. It has also been found that medical anthropologists have played a large role in helping locals better understand the objectives of epidemiologists and thereby helped them become more receptive of their investigations. In addition to all these, one of the major contributions of medical anthropology has come from its ability to help explain health phenomenon and create and test hypothesis relating to such explanations, in a way that epidemiologists have been unable to due to their strict focus on quantitative data. In short, while epidemiology is good at understanding numerical patterns and biological causes for disease/health conditions, it is unable to fully explain all the factors that underlie certain diseases/health conditions, and this is a gap that medical anthropology has been able to pick up on and complement by providing rich qualitative data which looks at health and diseases from a holistic perspective.  Notable works  Some notable mentions of medical anthropologists who have worked and contributed to epidemiology and public health in general include Dr. Jim Kim and Paul Farmer. Dr. Jim Kim served as the president of the World Bank while Paul Farmer is a physician and medical anthropologists who focuses on infectious diseases and treatment. Both of these men co-founded the Partners in Health (PIH) program, which provided free health care to the poorest populations in countries like Haiti, Peru, and Rwanda. Other notable mentions are Amber Wutich and Alexandra Brewis, both of whom are professors and researchers at Arizona State University. They focus on health impacts caused by resource scarcity, specifically relating to lack of access to clean water in developing countries. Wutich is a director of the Global Ethnohydrology study which looks at water knowledge and management in ten countries, while Brewis researches the impact of culture on human biology.  Population-based health management  Epidemiological practice and the results of epidemiological analysis make a significant contribution to health management Assess the health states and needs of a target population Implement and evaluate interventions Provide care for members of that populationModern population-based health management is complex. Epidemiological practice and analysis is a core component. This task requires the forward looking ability to guide how a health system responds to current health issues, and how a health system can respond to future potential population health issues.  References   Additional Bibliography   Related pages  Centers for Disease Control and Prevention World Health Organization"
"Gonorrhoea or gonorrhea, colloquially known as the clap, is a sexually transmitted infection (STI) caused by the bacterium Neisseria gonorrhoeae. Infection may involve the genitals, mouth, or rectum. Infected men may experience pain or burning with urination, discharge from the penis, or testicular pain. Infected women may experience burning with urination, vaginal discharge, vaginal bleeding between periods, or pelvic pain. Complications in women include pelvic inflammatory disease and in men include inflammation of the epididymis. Many of those infected, however, have no symptoms. If untreated, gonorrhea can spread to joints or heart valves.Gonorrhea is spread through sexual contact with an infected person. This includes oral, anal, and vaginal sex. It can also spread from a mother to a child during birth. Diagnosis is by testing the urine, urethra in males, or cervix in females. Testing all women who are sexually active and less than 25 years of age each year as well as those with new sexual partners is recommended; the same recommendation applies in men who have sex with men (MSM).Gonorrhea can be prevented with the use of condoms, having sex with only one person who is uninfected, and by not having sex. Treatment is usually with ceftriaxone by injection and azithromycin by mouth. Resistance has developed to many previously used antibiotics and higher doses of ceftriaxone are occasionally required. Retesting is recommended three months after treatment. Sexual partners from the last two months should also be treated.Gonorrhea affects about 0.8% of women and 0.6% of men. An estimated 33 to 106 million new cases occur each year, out of the 498 million new cases of curable STI – which also includes syphilis, chlamydia, and trichomoniasis. Infections in women most commonly occur when they are young adults. In 2015, it caused about 700 deaths. Descriptions of the disease date back to before the Common Era within the Hebrew Bible/Old Testament (Leviticus 15:2-3). The current name was first used by the Greek physician Galen before AD 200 who referred to it as ""an unwanted discharge of semen"".  Signs and symptoms  Gonorrhea infections of mucosal membranes can cause swelling, itching, pain, and the formation of pus. The time from exposure to symptoms is usually between two and 14 days, with most symptoms appearing between four and six days after infection, if they appear at all. Both men and women with infections of the throat may experience a sore throat, though such infection does not produce symptoms in 90% of cases. Other symptoms may include swollen lymph nodes around the neck. Either sex can become infected in the eyes or rectum if these tissues are exposed to the bacterium.  Women  Half of women with gonorrhea are asymptomatic but the other half experience vaginal discharge, lower abdominal pain, or pain with sexual intercourse associated with inflammation of the uterine cervix. Common medical complications of untreated gonorrhea in women include pelvic inflammatory disease which can cause scars to the fallopian tubes and result in later ectopic pregnancy among those women who become pregnant.  Men  Most infected men with symptoms have inflammation of the penile urethra associated with a burning sensation during urination and discharge from the penis. In men, discharge with or without burning occurs in half of all cases and is the most common symptom of the infection. This pain is caused by a narrowing and stiffening of the urethral lumen. The most common medical complication of gonorrhea in men is inflammation of the epididymis. Gonorrhea is also associated with increased risk of prostate cancer.  Infants  If not treated, gonococcal ophthalmia neonatorum will develop in 28% of infants born to women with gonorrhea.  Spread  If left untreated, gonorrhea can spread from the original site of infection and infect and damage the joints, skin, and other organs. Indications of this can include fever, skin rashes, sores, and joint pain and swelling. In advanced cases, gonorrhea may cause a general feeling of tiredness similar to other infections. It is also possible for an individual to have an allergic reaction to the bacteria, in which case any appearing symptoms will be greatly intensified. Very rarely it may settle in the heart, causing endocarditis, or in the spinal column, causing meningitis. Both are more likely among individuals with suppressed immune systems, however.  Cause  Gonorrhea is caused by the bacterium Neisseria gonorrhoeae. Previous infection does not confer immunity – a person who has been infected can become infected again by exposure to someone who is infected. Infected persons may be able to infect others repeatedly without having any signs or symptoms of their own.  Spread  The infection is usually spread from one person to another through vaginal, oral, or anal sex. Men have a 20% risk of getting the infection from a single act of vaginal intercourse with an infected woman. The risk for men who have sex with men (MSM) is higher. Insertive MSM may get a penile infection from anal intercourse, while receptive MSM may get anorectal gonorrhea. Women have a 60–80% risk of getting the infection from a single act of vaginal intercourse with an infected man.A mother may transmit gonorrhea to her newborn during childbirth; when affecting the infant's eyes, it is referred to as ophthalmia neonatorum. It may be able to spread through the objects contaminated with body fluid from an infected person. The bacteria typically does not survive long outside the body, typically dying within minutes to hours.  Risk factors  It is discovered that sexually active women younger than 25 and men who have sex with men are at increased risk of getting gonorrhea.Other risk factors include: Having a new sex partner Having a sex partner who has other partners Having more than one sex partner Having had gonorrhea or another sexually transmitted infection  Complications  Medically it has been said that Untreated gonorrhea can lead to major complications, such as: Infertility in women. Gonorrhea can spread into the uterus and fallopian tubes, causing pelvic inflammatory disease (PID). PID can result in scarring of the tubes, greater risk of pregnancy complications and infertility. PID requires immediate treatment. Infertility in men. Gonorrhea can cause a small, coiled tube in the rear portion of the testicles where the sperm ducts are located (epididymis) to become inflamed (epididymitis). Untreated epididymitis can lead to infertility. Infection that spreads to the joints and other areas of the body. The bacterium that causes gonorrhea can spread through the bloodstream and infect other parts of the body, including the joints. Fever, rash, skin sores, joint pain, swelling and stiffness are possible results. Increased risk of HIV/AIDS. Having gonorrhea increases the susceptibility to infection with human immunodeficiency virus (HIV), the virus that leads to AIDS. People who have both gonorrhea and HIV (untreated by anti-retroviral therapy) are able to pass both diseases more readily to their partners. Complications in babies. Babies who contract gonorrhea from their mothers during birth can develop blindness, sores on the scalp and infections.  Diagnosis  Traditionally, gonorrhea was diagnosed with Gram stain and culture; however, newer polymerase chain reaction (PCR)-based testing methods are becoming more common. In those failing initial treatment, culture should be done to determine sensitivity to antibiotics.Tests that use PCR (aka nucleic acid amplification) to identify genes unique to N. gonorrhoeae are recommended for screening and diagnosis of gonorrhea infection. These PCR-based tests require a sample of urine, urethral swabs, or cervical/vaginal swabs. Culture (growing colonies of bacteria in order to isolate and identify them) and Gram-stain (staining of bacterial cell walls to reveal morphology) can also be used to detect the presence of N. gonorrhoeae in all specimen types except urine. The swab sample for gonorrhea infections does not show difference whether the sample was collected in home or in clinic in term of number patient treated. The implications in cured patient, reinfection, partner management, and safety are unknown.If Gram-negative, oxidase-positive diplococci are visualized on direct Gram stain of urethral pus (male genital infection), no further testing is needed to establish the diagnosis of gonorrhea infection. However, in the case of female infection direct Gram stain of cervical swabs is not useful because the N. gonorrhoeae organisms are less concentrated in these samples. The chances of false positives are increased as Gram-negative diplococci native to the normal vaginal flora cannot be distinguished from N. gonorrhoeae. Thus, cervical swabs must be cultured under the conditions described above. If oxidase positive, Gram-negative diplococci are isolated from a culture of a cervical/vaginal swab specimen, then the diagnosis is made. Culture is especially useful for diagnosis of infections of the throat, rectum, eyes, blood, or joints—areas where PCR-based tests are not well established in all labs. Culture is also useful for antimicrobial sensitivity testing, treatment failure, and epidemiological purposes (outbreaks, surveillance).In patients who may have disseminated gonococcal infection (DGI), all possible mucosal sites should be cultured (e.g., pharynx, cervix, urethra, rectum). Three sets of blood cultures should also be obtained. Synovial fluid should be collected in cases of septic arthritis.All people testing positive for gonorrhea should be tested for other sexually transmitted diseases such as chlamydia, syphilis, and human immunodeficiency virus. Studies have found co-infection with chlamydia ranging from 46 to 54% in young people with gonorrhea. Among persons in the United States between 14 and 39 years of age, 46% of people with gonorrheal infection also have chlamydial infection. For this reason, gonorrhea and chlamydia testing are often combined. People diagnosed with gonorrhea infection have a fivefold increase risk of HIV transmission. Additionally, infected persons who are HIV positive are more likely to shed and transmit HIV to uninfected partners during an episode of gonorrhea.  Screening  The United States Preventive Services Task Force (USPSTF) recommends screening for gonorrhea in women at increased risk of infection, which includes all sexually active women younger than 25 years. Extragenital gonorrhea and chlamydia are highest in men who have sex with men (MSM). Additionally, the USPSTF also recommends routine screening in people who have previously tested positive for gonorrhea or have multiple sexual partners and individuals who use condoms inconsistently, provide sexual favors for money, or have sex while under the influence of alcohol or drugs.Screening for gonorrhea in women who are (or intend to become) pregnant, and who are found to be at high risk for sexually transmitted diseases, is recommended as part of prenatal care in the United States.  Prevention  As with most sexually transmitted diseases, the risk of infection can be reduced significantly by the correct use of condoms, not having sex, or can be removed almost entirely by limiting sexual activities to a mutually monogamous relationship with an uninfected person.Those previously infected are encouraged to return for follow up care to make sure that the infection has been eliminated. In addition to the use of phone contact, the use of email and text messaging have been found to improve the re-testing for infection.Newborn babies coming through the birth canal are given erythromycin ointment in the eyes to prevent blindness from infection. The underlying gonorrhea should be treated; if this is done then usually a good prognosis will follow.  Treatment   Antibiotics  Antibiotics are used to treat gonorrhea infections. As of 2016, both ceftriaxone by injection and azithromycin by mouth are most effective. However, due to increasing rates of antibiotic resistance, local susceptibility patterns must be taken into account when deciding on treatment. Ertapenem is a potential effective alternative treatment for ceftriaxone-resistant gonorrhea.Adults may have eyes infected with gonorrhoea and require proper personal hygiene and medications. Addition of topical antibiotics have not been shown to improve cure rates compared to oral antibiotics alone in treatment of eye infected gonorrhea. For newborns, erythromycin ointment is recommended as a preventative measure for gonococcal infant conjunctivitis.Infections of the throat can be especially problematic, as antibiotics have difficulty becoming sufficiently concentrated there to destroy the bacteria. This is amplified by the fact that pharyngeal gonorrhoea is mostly asymptomatic, and gonococci and commensal Neisseria species can coexist for long time periods in the pharynx and share anti-microbial resistance genes. Accordingly, an enhanced focus on early detection (i.e., screening of high-risk populations, such as men who have sex with men, PCR testing should be considered) and appropriate treatment of pharyngeal gonorrhoea is important.  Sexual partners  It is recommended that sexual partners be tested and potentially treated. One option for treating sexual partners of people infected is patient-delivered partner therapy (PDPT), which involves providing prescriptions or medications to the person to take to his/her partner without the health care provider's first examining him/her.The United States' Centers for Disease Control and Prevention (CDC) currently recommend that individuals who have been diagnosed and treated for gonorrhea avoid sexual contact with others until at least one week past the final day of treatment in order to prevent the spread of the bacterium.  Antibiotic resistance  Many antibiotics that were once effective including penicillin, tetracycline, and fluoroquinolones are no longer recommended because of high rates of resistance. Resistance to cefixime has reached a level such that it is no longer recommended as a first-line agent in the United States, and if it is used a person should be tested again after a week to determine whether the infection still persists. Public health officials are concerned that an emerging pattern of resistance may predict a global epidemic. In 2016, the WHO published new guidelines for treatment, stating ""There is an urgent need to update treatment recommendations for gonococcal infections to respond to changing antimicrobial resistance (AMR) patterns of N. gonorrhoeae. High-level resistance to previously recommended quinolones is widespread and decreased susceptibility to the extended-spectrum (third-generation) cephalosporins, another recommended first-line treatment in the 2003 guidelines, is increasing and several countries have reported treatment failures.""  Prognosis  Gonorrhea if left untreated may last for weeks or months with higher risks of complications. One of the complications of gonorrhea is systemic dissemination resulting in skin pustules or petechia, septic arthritis, meningitis, or endocarditis. This occurs in between 0.6 and 3% of infected women and 0.4 and 0.7% of infected men.In men, inflammation of the epididymis, prostate gland, and urethra can result from untreated gonorrhea. In women, the most common result of untreated gonorrhea is pelvic inflammatory disease. Other complications include inflammation of the tissue surrounding the liver, a rare complication associated with Fitz-Hugh–Curtis syndrome; septic arthritis in the fingers, wrists, toes, and ankles; septic abortion; chorioamnionitis during pregnancy; neonatal or adult blindness from conjunctivitis; and infertility. Men who have had a gonorrhea infection have an increased risk of getting prostate cancer.  Epidemiology  About 88 million cases of gonorrhea occur each year, out of the 448 million new cases of curable STI each year – that also includes syphilis, chlamydia and trichomoniasis. The prevalence was highest in the African region, the Americas, and Western Pacific, and lowest in Europe. In 2013, it caused about 3,200 deaths, up from 2,300 in 1990.In the United Kingdom, 196 per 100,000 males 20 to 24 years old and 133 per 100,000 females 16 to 19 years old were diagnosed in 2005. In 2013, the CDC estimated that more than 820,000 people in the United States get a new gonorrheal infection each year. Fewer than half of these infections are reported to CDC. In 2011, 321,849 cases of gonorrhea were reported to the CDC. After the implementation of a national gonorrhea control program in the mid-1970s, the national gonorrhea rate declined from 1975 to 1997. After a small increase in 1998, the gonorrhea rate has decreased slightly since 1999. In 2004, the rate of reported gonorrheal infections was 113. 5 per 100,000 persons.In the US, it is the second-most-common bacterial sexually transmitted infections; chlamydia remains first. According to the CDC African Americans are most affected by gonorrhea, accounting for 69% of all gonorrhea cases in 2010.The World Health Organization warned in 2017 of the spread of untreatable strains of gonorrhea, following analysis of at least three cases in Japan, France and Spain, which survived all antibiotic treatment.  History  Some scholars translate the biblical terms zav (for a male) and zavah (for a female) as gonorrhea.It has been suggested that mercury was used as a treatment for gonorrhea. Surgeons' tools on board the recovered English warship the Mary Rose included a syringe that, according to some, was used to inject the mercury via the urinary meatus into crewmen with gonorrhea. The name ""the clap"", in reference to the disease, is recorded as early as the sixteenth century, referring to a medieval red-light district in Paris, Les Clapiers. Translating to ""The rabbit holes"", it was so named for the small huts in which prostitutes worked.In 1854, Dr. Wilhelm Gollmann addressed gonorrhea in his book, Homeopathic Guide to all Diseases Urinary and Sexual Organs. He noted that the disease was common in prostitutes and homosexuals in large cities. Gollmann recommended the following as cures: aconite to cure ""shooting pains with soreness and inflammation;"" mercury ""for stitching pain with purulent discharge;"" nux vomica and sulphur ""when the symptoms are complicated with hemorrhoids and stricture of the rectum. Other remedies include argentum, aurum (gold), belladonna, calcarea, ignatia, phosphorus, and sepia.Silver nitrate was one of the widely used drugs in the 19th century. However, it became replaced by Protargol. Arthur Eichengrün invented this type of colloidal silver, which was marketed by Bayer from 1897 onward. The silver-based treatment was used until the first antibiotics came into use in the 1940s.The exact time of onset of gonorrhea as prevalent disease or epidemic cannot be accurately determined from the historical record. One of the first reliable notations occurs in the Acts of the (English) Parliament. In 1161, this body passed a law to reduce the spread of ""... the perilous infirmity of burning"". The symptoms described are consistent with, but not diagnostic of, gonorrhea. A similar decree was passed by Louis IX in France in 1256, replacing regulation with banishment. Similar symptoms were noted at the siege of Acre by Crusaders. Coincidental to, or dependent on, the appearance of a gonorrhea epidemic, several changes occurred in European medieval society. Cities hired public health doctors to treat affected patients without right of refusal. Pope Boniface rescinded the requirement that physicians complete studies for the lower orders of the Catholic priesthood.Medieval public health physicians in the employ of their cities were required to treat prostitutes infected with the ""burning"", as well as lepers and other epidemic patients. After Pope Boniface completely secularized the practice of medicine, physicians were more willing to treat a sexually transmitted disease.  Research  A vaccine for gonorrhea has been developed that is effective in mice. It will not be available for human use until further studies have demonstrated that it is both safe and effective in the human population. Development of a vaccine has been complicated by the ongoing evolution of resistant strains and antigenic variation (the ability of N. gonorrhoeae to disguise itself with different surface markers to evade the immune system).As N. gonorrhoeae is closely related to N. meningitidis and they have 80–90% homology in their genetic sequences some cross-protection by meningococcal vaccines is plausible. A study published in 2017 showed that MeNZB group B meningococcal vaccine provided a partial protection against gonorrhea. The vaccine efficiency was calculated to be 31%.  References   External links  Gonorrhea at Curlie ""Gonorrhea – CDC Fact Sheet""","Gonorrhea is a disease. It is transmitted by having sex. It is among the most widespread sexually transmitted diseases. Gonorrhea is also sometimes called ""the clap."" Gonorrhea can be cured using antibiotics but the entire course of antibiotics must be used. Its presence was found up to 700 years ago. At that time, this disease was described by coming from the ""Le Clapiers"" part of the city of Paris. This part of the city was known to be where prostitutes lived.  Cleanup  It is caused by a bacterium, Neisseria gonorrheae. Since it is caused by a bacterium, it can be treated with antibiotics. The use of latex condoms when having sex can prevent it from spreading. Sometimes antibiotics do not cure gonorrhea. This is because the bacterium is becoming immune or resistant to the medicine. When this happens, the infection is more difficult to cure.  References "
"Science is a systematic endeavor that builds and organizes knowledge in the form of testable explanations and predictions about the universe.The earliest written records of identifiable predecessors to modern science come from Ancient Egypt and Mesopotamia from around 3000 to 1200 BCE. Their contributions to mathematics, astronomy, and medicine entered and shaped the Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes.: 12 After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages, but was preserved in the Muslim world during the Islamic Golden Age and later by the efforts of Byzantine Greek scholars who brought Greek manuscripts from the dying Byzantine Empire to Western Europe in the Renaissance. The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived ""natural philosophy"", which was later transformed by the Scientific Revolution that began in the 16th century as new ideas and discoveries departed from previous Greek conceptions and traditions. The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape, along with the changing of ""natural philosophy"" to ""natural science"".Modern science is typically divided into three major branches: natural sciences (e.g., biology, chemistry, and physics), which study the physical world; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which study formal systems, governed by axioms and rules. There is disagreement whether the formal sciences are science disciplines, because they do not rely on empirical evidence. Applied sciences are disciplines that use scientific knowledge for practical purposes, such as in engineering and medicine.New knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems. Contemporary scientific research is highly collaborative and is usually done by teams in academic and research institutions, government agencies, and companies. The practical impact of their work has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the ethical and moral development of commercial products, armaments, health care, public infrastructure, and environmental protection.  Etymology  The word science has been used in Middle English since the 14th century in the sense of ""the state of knowing"". The word was borrowed from the Anglo-Norman language as the suffix -cience, which was borrowed from the Latin word scientia, meaning ""knowledge, awareness, understanding"". It is a noun derivative of the Latin sciens meaning ""knowing"", and undisputedly derived from the Latin sciō, the present participle scīre, meaning ""to know"".There are many hypotheses for science's ultimate word origin. According to Michiel de Vaan, Dutch linguist and Indo-Europeanist, sciō may have its origin in the Proto-Italic language as skije- or skijo- meaning ""to know"", which may originate from Proto-Indo-European language as skh1-ie, skh1-io, meaning ""to incise"". The Lexikon der indogermanischen Verben proposed sciō is a back-formation of nescīre, meaning ""to not know, be unfamiliar with"", which may derive from Proto-Indo-European sekH- in Latin secāre, or skh2-, from sḱʰeh2(i)- meaning ""to cut"".In the past, science was a synonym for ""knowledge"" or ""study"", in keeping with its Latin origin. A person who conducted scientific research was called a ""natural philosopher"" or ""man of science"". In 1834, William Whewell introduced the term scientist in a review of Mary Somerville's book On the Connexion of the Physical Sciences, crediting it to ""some ingenious gentleman"" (possibly himself).  History   Early history  Science has no single origin. Rather, systematic methods emerged gradually over the course of tens of thousands of years, taking different forms around the world, and few details are known about the very earliest developments. Women likely played a central role in prehistoric science, as did religious rituals. Some scholars use the term ""protoscience"" to label activities in the past that resemble modern science in some but not all features; however, this label has also been criticized as denigrating or too suggestive of presentism, thinking about those activities only in relation to modern categories.Direct evidence for scientific processes becomes clearer with the advent of writing systems in early civilizations like Ancient Egypt and Mesopotamia, creating the earliest written records in the history of science in around 3000 to 1200 BCE.: 12–15 Although the words and concepts of ""science"" and ""nature"" were not part of the conceptual landscape at the time, the ancient Egyptians and Mesopotamians made contributions that would later find a place in Greek and medieval science: mathematics, astronomy, and medicine.: 12 From the 3rd millennium BCE, the ancient Egyptians developed a decimal numbering system, solved practical problems using geometry, and developed a calendar. Their healing therapies involved drug treatments and the supernatural, such as prayers, incantations, and rituals.: 9 The ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing. They studied animal physiology, anatomy, behavior, and astrology for divinatory purposes. The Mesopotamians had an intense interest in medicine and the earliest medical prescriptions appeared in Sumerian during the Third Dynasty of Ur. They seem to study scientific subjects which have practical or religious applications and have little interest of satisfying curiosity.  Classical antiquity  In classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time. Before the invention or discovery of the concept of phusis or nature by the pre-Socratic philosophers, the same words tend to be used to describe the natural ""way"" in which a plant grows, and the ""way"" in which, for example, one tribe worships a particular god. For this reason, it is claimed that these men were the first philosophers in the strict sense and the first to clearly distinguish ""nature"" and ""convention"".The early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural. The Pythagoreans developed a complex number philosophy: 467–68 and contributed significantly to the development of mathematical science.: 465 The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus. Later, Epicurus would develop a full natural cosmology based on atomism, and would adopt a ""canon"" (ruler, standard) which established physical criteria or standards of scientific truth. The Greek doctor Hippocrates established the tradition of systematic medical science and is known as ""The Father of Medicine"".A turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. The Socratic method searches for general commonly-held truths that shape beliefs and scrutinizes them for consistency. Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism.Aristotle in the 4th century BCE created a systematic program of teleological philosophy. In the 3rd century BCE, Greek astronomer Aristarchus of Samos was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it. Aristarchus's model was widely rejected because it was believed to violate the laws of physics, while Ptolemy's Almagest, which contains a geocentric description of the Solar System, was accepted through the early Renaissance instead. The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus. Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia Natural History.Positional notation for representing numbers likely emerged between the 3rd and 5th centuries CE along Indian trade routes. This numeral system made efficient arithmetic operations more accessible and would eventually become standard for mathematics worldwide.  Middle Ages  Due to the collapse of the Western Roman Empire, the 5th century saw an intellectual decline and knowledge of Greek conceptions of the world deteriorated in Western Europe.: 194 During the period, Latin encyclopedists such as Isidore of Seville preserved the majority of general ancient knowledge. In contrast, because the Byzantine Empire resisted attacks from invaders, they were able to preserve and improve prior learning.: 159 John Philoponus, a Byzantine scholar in the 500s, started to question Aristotle's teaching of physics, introducing the theory of impetus.: 307, 311, 363, 402 His criticism served as an inspiration to medieval scholars and Galileo Galilei, who extensively cited his works ten centuries later.: 307–308 During late antiquity and the early Middle Ages, natural phenomena were mainly examined via the Aristotelian approach. The approach includes Aristotle's four causes: material, formal, moving, and final cause. Many Greek classical texts were preserved by the Byzantine empire and Arabic translations were done by groups such as the Nestorians and the Monophysites. Under the Caliphate, these Arabic translations were later improved and developed by Arabic scientists. By the 6th and 7th centuries, the neighboring Sassanid Empire established the medical Academy of Gondeshapur, which is considered by Greek, Syriac, and Persian physicians as the most important medical center of the ancient world.The House of Wisdom was established in Abbasid-era Baghdad, Iraq, where the Islamic study of Aristotelianism flourished until the Mongol invasions in the 13th century. Ibn al-Haytham, better known as Alhazen, began experimenting as a means to gain knowledge and disproved Ptolemy's theory of vision: Book I, [6.54]. p. 372 Avicenna's compilation of the Canon of Medicine, a medical encyclopedia, is considered to be one of the most important publications in medicine and was used until the 18th century.By the eleventh century, most of Europe had become Christian,: 204 and in 1088, the University of Bologna emerged as the first university in Europe. As such, demand for Latin translation of ancient and scientific texts grew,: 204 a major contributor to the Renaissance of the 12th century. Renaissance scholasticism in western Europe flourished, with experiments done by observing, describing, and classifying subjects in nature. In the 13rd century, medical teachers and students at Bologna began opening human bodies, leading to the first anatomy textbook based on human dissection by Mondino de Luzzi.  Renaissance  New developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. At the start of the Renaissance, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle.: Book I A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.In the sixteenth century, Nicolaus Copernicus formulated a heliocentric model of the Solar System, stating that the planets revolve around the Sun, instead of the geocentric model where the planets and the Sun revolve around the Earth. This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the center of motion, which he found not to agree with Ptolemy's model.Johannes Kepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light. Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres. Galileo had made significant contributions to astronomy, physics and engineering. However, he became persecuted after Pope Urban VIII sentenced him for writing about the heliocentric model.The printing press was widely used to publish scholarly arguments, including some that disagreed widely with contemporary ideas of nature. Francis Bacon and René Descartes published philosophical arguments in favor of a new type of non-Aristotelian science. Bacon emphasized the importance of experiment over contemplation, questioned the Aristotelian concepts of formal and final cause, promoted the idea that science should study the laws of nature and the improvement of all human life. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used to study nature.  Age of Enlightenment  At the start of the Age of Enlightenment, Isaac Newton formed the foundation of classical mechanics by his Philosophiæ Naturalis Principia Mathematica, greatly influencing future physicists. Gottfried Wilhelm Leibniz incorporated terms from Aristotelian physics, now used in a new non-teleological way. This implied a shift in the view of objects: objects were now considered as having no innate goals. Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes.During this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, ""the real and legitimate goal of sciences is the endowment of human life with new inventions and riches"", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond ""the fume of subtle, sublime or pleasing [speculation]"".Science during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centers of scientific research and development. Societies and academies were the backbones of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides to every physical and social field of the day.The 18th century saw significant advancements in the practice of medicine and physics; the development of biological taxonomy by Carl Linnaeus; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline. Ideas on human nature, society, and economics evolved during the Enlightenment. Hume and other Scottish Enlightenment thinkers developed A Treatise of Human Nature, which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement. In 1776, Adam Smith published The Wealth of Nations, which is often considered the first work on modern economics.  19th century  During the nineteenth century, many distinguishing characteristics of contemporary modern science began to take shape. These included the transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms such as ""biologist"", ""physicist"", ""scientist"", increased professionalization of those studying nature, scientists gained cultural authority over many dimensions of society, industrialization of numerous countries, thriving of popular science writings and emergence of science journals. During the late 19th century, psychology emerged as a separate discipline from philosophy when Wilhelm Wundt founded the first laboratory for psychological research in 1879.During the mid-19th century, Charles Darwin and Alfred Russel Wallace independently proposed the theory of evolution by natural selection in 1858, which explained how different plants and animals originated and evolved. Their theory was set out in detail in Darwin's book On the Origin of Species, published in 1859. Separately, Gregor Mendel presented his paper, ""Experiments on Plant Hybridization"" in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.Early in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of indivisible particles called atoms. The laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. However, with the advent of the steam engine and the industrial revolution there was an increased understanding that not all forms of energy have the same energy qualities, the ease of conversion to useful work or to another form of energy. This realization led to the development of the laws of thermodynamics, in which the free energy of the universe is seen as constantly declining: the entropy of a closed universe increases over time.The electromagnetic theory was established in the 19th century by the works of Hans Christian Ørsted, André-Marie Ampère, Michael Faraday, James Clerk Maxwell, Oliver Heaviside, and Heinrich Hertz. The new theory raised questions that could not easily be answered using Newton's framework. The discovery of X-rays inspired the discovery of radioactivity by Henri Becquerel and Marie Curie in 1896, Marie Curie then became the first person to win two Nobel prizes. In the next year came the discovery of the first subatomic particle, the electron.  20th century  In the first half of the century, the development of antibiotics and artificial fertilizers improved human living standards globally. Harmful environmental issues such as ozone depletion, ocean acidification, eutrophication and climate change came to the public's attention and caused the onset of environmental studies.During this period, scientific experimentation became increasingly larger in scale and funding. The extensive technological innovation stimulated by World War I, World War II, and the Cold War led to competitions between global powers, such as the Space Race and nuclear arms race. Substantial international collaborations were also made, despite armed conflicts.In the late 20th century, active recruitment of women and elimination of sex discrimination greatly increased the number of women scientists, but large gender disparities remained in some fields. The discovery of the cosmic microwave background in 1964 led to a rejection of the steady-state model of the universe in favor of the Big Bang theory of Georges Lemaître.The century saw fundamental changes within science disciplines. Evolution became a unified theory in the early 20th-century when the modern synthesis reconciled Darwinian evolution with classical genetics. Albert Einstein's theory of relativity and the development of quantum mechanics complement classical mechanics to describe physics in extreme length, time and gravity. Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modeling.  21st century  The Human Genome Project was completed in 2003 by identifying and mapping all of the genes of the human genome. The first induced pluripotent human stem cells were made in 2006, allowing adult cells to be transformed into stem cells and turn to any cell type found in the body. With the affirmation of the Higgs boson discovery in 2013, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed. In 2019, the international collaboration Event Horizon Telescope presented the first direct image of a black hole's accretion disk.  Branches  Modern science is commonly divided into three major branches: natural science, social science, and formal science. Each of these branches comprises various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise. Both natural and social sciences are empirical sciences, as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.  Natural science  Natural science is the study of the physical world. It can be divided into two main branches: life science and physical science. These two branches may be further divided into more specialized disciplines. For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, ""natural history"" suggests observational descriptions aimed at popular audiences.  Social science  Social science is the study of human behavior and functioning of societies. It has many disciplines that include, but are not limited to anthropology, economics, history, human geography, political science, psychology, and sociology. In the social sciences, there are many competing theoretical perspectives, many of which are extended through competing research programs such as the functionalists, conflict theorists, and interactionists in sociology. Due to the limitations of conducting controlled experiments involving large groups of individuals or complex situations, social scientists may adopt other research methods such as the historical method, case studies, and cross-cultural studies. Moreover, if quantitative information is available, social scientists may rely on statistical approaches to better understand social relationships and processes.  Formal science  Formal science is an area of study that generates knowledge using formal systems. A formal system is an abstract structure used for inferring theorems from axioms according to a set of rules. It includes mathematics, systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts. The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they constitute a science. Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics. Natural and social sciences that rely heavily on mathematical applications include mathematical physics, chemistry, biology, finance, and economics.  Applied science  Applied science is the use of the scientific method and knowledge to attain practical goals and includes a broad range of disciplines such as engineering and medicine. Engineering is the use of scientific principles to invent, design and build machines, structures and technologies. Science may contribute to the development of new technologies. Medicine is the practice of caring for patients by maintaining and restoring health through the prevention, diagnosis, and treatment of injury or disease. The applied sciences are often contrasted with the basic sciences, which are focused on advancing scientific theories and laws that explain and predict events in the natural world.Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. The use of machine learning and artificial intelligence is becoming a central feature of computational contributions to science for example in agent-based computational economics, random forests, topic modeling and various forms of prediction. However, machines alone rarely advance knowledge as they require human guidance and capacity to reason; and they can introduce bias against certain social groups or sometimes underperform against humans.  Interdisciplinary science  Interdisciplinary science involves the combination of two or more disciplines into one, such as bioinformatics, a combination of biology and computer science or cognitive sciences. The concept has existed since the ancient Greek and it became popular again in the 20th century.  Scientific research  Scientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Most understanding comes from basic research, though sometimes applied research targets specific practical problems. This leads to technological advances that were not previously imaginable.  Scientific method  Scientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way. Scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: there is an objective reality shared by all rational observers; this objective reality is governed by natural laws; these laws were discovered by means of systematic observation and experimentation. Mathematics is essential in the formation of hypotheses, theories, and laws, because it is used extensively in quantitative modeling, observing, and collecting measurements. Statistics is used to summarize and analyze data, which allows scientists to assess the reliability of experimental results.In the scientific method, an explanatory thought experiment or hypothesis is put forward as an explanation using parsimony principles and is expected to seek consilience – fitting with other accepted facts related to an observation or scientific question. This tentative explanation is used to make falsifiable predictions, which are typically posted before being tested by experimentation. Disproof of a prediction is evidence of progress.: 4–5 Experimentation is especially important in science to help establish causal relationships to avoid the correlation fallacy, though in some sciences such as astronomy or geology, a predicted observation might be more appropriate.When a hypothesis proves unsatisfactory, it is modified or discarded. If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural events. A theory typically describes the behavior of much broader sets of observations than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. Scientists may generate a model, an attempt to describe or depict an observation in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested by experimentation.While performing experiments to test hypotheses, scientists may have a preference for one outcome over another. Eliminating the bias can be achieved by transparency, careful experimental design, and a thorough peer review process of the experimental results and conclusions. After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be. Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing the effects of subjective and confirmation bias. Intersubjective verifiability, the ability to reach a consensus and reproduce results, is fundamental to the creation of all scientific knowledge.  Scientific literature  Scientific research is published in a range of literature. Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des sçavans followed by Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500.Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is considered necessary to communicate the achievements, news, and ambitions of scientists to a wider population.  Challenges  The replication crisis is an ongoing methodological crisis that affects parts of the social and life sciences. In subsequent investigations, the results of many scientific studies are proven to be unrepeatable. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science. Physicist Richard Feynman coined the term ""cargo cult science"" for cases in which researchers believe and at a glance looks like they are doing science, but lack the honesty allowing their results to be rigorously evaluated. Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as ""the most important tool"" for separating valid claims from invalid ones.There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as ""bad science,"" research that may be well-intended but is incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term ""scientific misconduct"" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.  Philosophy of science  There are different schools of thought in the philosophy of science. The most popular position is empiricism, which holds that knowledge is created by a process involving observation; scientific theories generalize observations. Empiricism generally encompasses inductivism, a position that explains how general theories can be made from the finite amount of empirical evidence available. Many versions of empiricism exist, with the predominant ones being Bayesianism and the hypothetico-deductive method.Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation. Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories: that the only way theory A can be affected by observation is after theory A were to conflict with observation, but theory B were to survive the observation. Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories, replacing induction with falsification as the empirical method. Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error, covering all products of the human mind, including science, mathematics, philosophy, and art.Another approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena. It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should be ignored. Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.Thomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent ""portrait"" of the world that is consistent with observations made from its framing. He characterized normal science as the process of observation and ""puzzle solving"" which takes place within a paradigm, whereas revolutionary science occurs when one paradigm overtakes another in a paradigm shift. Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more ""portraits"" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.Finally, another approach often cited in debates of scientific skepticism against controversial movements like ""creation science"" is methodological naturalism. Naturalists maintain that a difference should be made between natural and supernatural, and science should be restricted to natural explanations. Methodological naturalism maintains that science requires strict adherence to empirical study and independent verification.  Scientific community  The scientific community is a network of interacting scientists who conducts scientific research. The community consists of smaller groups working in scientific fields. By having peer review, through discussion and debate within journals and conferences, scientists maintain the quality of research methodology and objectivity when interpreting results.  Scientists  Scientists are individuals who conduct scientific research to advance knowledge in an area of interest. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy or PhD. Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.Scientists exhibit a strong curiosity about reality and a desire to apply scientific knowledge for the benefit of health, nations, the environment, or industries. Other motivations include recognition by their peers and prestige. In modern times, many scientists have advanced degrees in an area of science and pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit environments. Science has historically been a male-dominated field, with notable exceptions. Women in science faced considerable discrimination in science, much as they did in other areas of male-dominated societies. For example, women were frequently being passed over for job opportunities and denied credit for their work. The achievements of women in science have been attributed to the defiance of their traditional role as laborers within the domestic sphere. Lifestyle choice plays a major role in female engagement in science; female graduate students' interest in careers in research declines dramatically throughout graduate school, whereas that of their male colleagues remains unchanged.  Learned societies  Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance. Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines. Membership may either be open to all, require possession of scientific credentials, or conferred by election. Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some societies act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership.The professionalization of science, begun in the 19th century, was partly enabled by the creation of national distinguished academies of sciences such as the Italian Accademia dei Lincei in 1603, the British Royal Society in 1660, the French Academy of Sciences in 1666, the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Society in 1911, and the Chinese Academy of Sciences in 1949. International scientific organizations, such as the International Science Council, are devoted to international cooperation for science advancement.  Awards  Science awards are usually given to individuals or organizations that have made significant contributions to a discipline. They are often given by prestigious institutions, thus it is considered a great honor for a scientist receiving them. Since the early Renaissance, scientists are often awarded medals, money, and titles. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, and chemistry.  Society   Funding and policies  Scientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP. In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain fields is higher, and it dominates research in social science and humanities. In the lesser-developed nations, government provides the bulk of the funds for their basic scientific research.Many governments have dedicated agencies to support scientific research, such as the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organization in Australia, National Centre for Scientific Research in France, the Max Planck Society in Germany, and National Research Council in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialization possibilities rather than research driven by curiosity.Science policy is concerned with policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care, and environmental monitoring. Science policy sometimes refers to the act of applying scientific knowledge and consensus to the development of public policies. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public. Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research.  Education and awareness  Science education for the general public is embedded in the school curriculum, and is supplemented by online pedagogical content (for example, YouTube and Khan Academy), museums, and science magazines and blogs. Scientific literacy is chiefly concerned with an understanding of the scientific method, units and methods of measurement, empiricism, a basic understanding of statistics (correlations, qualitative versus quantitative observations, aggregate statistics), as well as a basic understanding of core scientific fields, such as physics, chemistry, biology, ecology, geology and computation. As a student advances into higher stages of formal education, the curriculum becomes more in depth. Traditional subjects usually included in the curriculum are natural and formal sciences, although recent movements include social and applied science as well.The mass media face pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter. Few journalists have real scientific knowledge, and even beat reporters who are knowledgeable about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science fiction genre, primarily speculative fiction, can transmit the ideas and methods of science to the general public. Recent efforts to intensify or develop links between science and non-scientific disciplines, such as literature or poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.  Anti-science attitudes  While the scientific method is broadly accepted in the scientific community, some fractions of society reject certain scientific positions or are skeptical about science. Examples are the common notion that COVID-19 is not a major health threat to the US (held by 39% of Americans in August 2021) or the belief that climate change is not a major threat to the US (also held by 40% of Americans, in late 2019 and early 2020). Psychologists have pointed to four factors driving rejection of scientific results: Scientific authorities are sometimes seen as inexpert, untrustworthy, or biased. Some marginalized social groups hold anti-science attitudes, in part because these groups have often been exploited in unethical experiments. Messages from scientists may contradict deeply-held existing beliefs or morals. The delivery of a scientific message may not be appropriately targeted to a recipient's learning style.Anti-science attitudes seem to be often caused by fear of rejection in social groups. For instance, climate change is perceived as a threat by only 22% of Americans on the right side of the political spectrum, but by 85% on the left. That is, if someone on the left would not consider climate change as a threat, this person may face contempt and be rejected in that social group. In fact, people may rather deny a scientifically accepted fact than lose or jeopardize their social status.  Politics  Attitudes towards science are often determined by political opinions and goals. Government, business and advocacy groups have been known to use legal and economic pressure to influence scientific researchers. Many factors can act as facets of the politicization of science such as anti-intellectualism, perceived threats to religious beliefs, and fear for business interests. Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence. Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence. Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.  See also  List of scientific occupations List of years in science  Notes   References   External links  Media related to Science at Wikimedia Commons","Science is what we do to find out about the natural world. Natural sciences include, chemistry, biology, geology, astronomy, and physics. Science uses mathematics and logic, which are sometimes called ""formal sciences"". Natural science makes observations and experiments. Science produces accurate facts, scientific laws and theories. 'Science' also refers to the large amount of knowledge that has been found using this process.Research uses the scientific method. Scientific research uses hypotheses based on ideas or earlier knowledge, which can be categorized through different topics. Then those hypotheses are tested by experiments. People who study and research science and try to find out everything about it are called scientists. Scientists study things by looking at them very carefully, by measuring them, and by doing experiments and tests. Scientists try to explain why things act the way they do, and predict what will happen.  Scientific method  Today, ""science"" usually refers to a way of pursuing knowledge, not just the knowledge itself. It is mainly about the phenomena of the material world. The Greek works into Western Europe from the 6th to 7th century B.C. revived ""Philosophy"". In the 17th and 18th centuries scientists increasingly sought to formulate knowledge in terms of laws of nature such as Newton's laws of motion. And during the 19th century, the word ""science"" became more and more associated with the scientific method itself. It was seen as a way to study the natural world, including physics, chemistry, geology and biology. It was also in the 19th century that the term scientist was created by William Whewell. He meant it to tell the difference between those who looked for knowledge on nature from those who looked for other types of knowledge.The scientific method is the name given to the methods used by scientists to find knowledge. The main features of the scientific method are: Scientists identify a question or a problem about nature. Some problems are simple, such as ""how many legs do flies have?"" and some are very deep, such as ""why do objects fall to the ground?"" Next, scientists investigate the problem. They work at it, and collect facts. Sometimes all it takes is to look carefully. Some questions cannot be answered directly. Then scientists suggest ideas, and test them out. They do experiments and collect data. Eventually, they find what they think is a good answer to the problem. Then they tell people about it. Later, other scientists may agree or not agree. They may suggest another answer. They may do more experiments. Anything in science might be revised if we find out the previous solution was not good enough.  An example  A famous example of science in action was the expedition led by Arthur Eddington to Principe Island in Africa in 1919. He went there to record where the stars were around the Sun during a solar eclipse. The observation of where the stars were shown that the apparent star positions close to the Sun were changed. In effect, the light passing the Sun was pulled towards the Sun by gravitation. This confirmed predictions of gravitational lensing made by Albert Einstein in the general theory of relativity, published in 1915. Eddington's observations were considered to be the first solid proof in favour of Einstein's theory.  Practical impacts of scientific research  Discoveries in fundamental science can be world-changing. For example:  Other features of science  Not everyone completely agrees about how theories should be used or updated. Some philosophers and scientists say that scientific theories are only accepted for the time being. They last as long as they are the best explanation. When theories no longer explain the data, they are removed and replaced. Or, sometimes scientists will make a theory better rather than remove it, or they will keep on using the theory hoping that it will be made better eventually. Science is a way to get knowledge by getting rid of what is not true. Scientists must be very careful to make explanations that fit well with what they observe and measure. They compete to provide better explanations. An explanation might be interesting or pleasing, but if it does not agree with what other scientists really see and measure, they will try to find a better explanation. Before a scientific article is published, other scientists read the article. They decide whether the explanations make sense from the data. This is called peer review. After articles are published, other scientists will also check to see if the same experiments, observations or tests produce the same data again. Peer review and repeating experiments are the only way to be sure the knowledge is correct. Science makes models of nature, models of our universe, and medicine. There are many different sciences with their own names. However it is not right to say ""science says"" any one thing. Science is a process, not just the facts and rules believed at one time.  Some types of science   Related pages  History of science Philosophy of science Science tourism  References   Other websites  ""How Do We Know What Is True?"" (animated video; 2:52)"